company,company_rating,location,job_title,job_description,salary_estimate,company_size,company_type,company_sector,company_industry,company_founded,company_revenue
"Vivante Health, Inc",#N/A,Remote,Data Engineer,"Remote – US and British Columbia Only

About Vivante
Vivante Health is an innovative startup reinventing the way chronic conditions are managed. We’re filling the unmet needs of people with chronic conditions that are invisible, neglected or stigmatized, starting with digestive disease.
Why digestive? Because an astonishing 70 million people in the US are affected—that’s twice the number with diabetes and more than many other chronic conditions combined. Unlike other chronic conditions, though, digestive diseases often go untreated or misdiagnosed…because of stigma.
At Vivante, we think it’s time to bring digestive health to the forefront while providing REAL solutions to the millions who are struggling and don’t know where to turn. Our health management ecosystem, GIThrive, empowers people to spend less time worrying about their digestive symptoms and more time living life.
GIThrive works with our members (patients) to help identify and manage their digestive health conditions with personalized insights & recommendations. Our platform also facilitates interactions with our world-class clinical team to blend our technology with real person-to-person relationships that support each patient throughout their individual journeys.
With a remote-first workforce, backed by leading digital health investors, we’re changing the way healthcare is delivered.
Position Summary
We're looking for an experienced, solution-focused Data Engineer to support our data insights and analytics efforts. If you like designing and building scalable data solutions while collaborating with other great engineers in a test-driven environment, please read on!
There will be a lot of close collaboration with our Data Science team as we continue to evolve and integrate our AI program into our patient-centered experience. This engineer would help us integrate various internal and external data sources, expand our data systems and pipeline capabilities, help automate ML training and deployment workflows, explore ways to enhance data quality and reliability, and help support our self-service BI environment for internal stakeholders.
The ideal candidate is someone who can reason through the interactions of a distributed system and deliver solutions that emphasize simplicity, reliability and supportability.
Why is this a great opportunity for a data engineer?
The problem domain and our approach to solving it is super compelling. We're bringing together data sources that have never been joined, building models of a GI patient that have never been built, and discovering new GI health insights that help real people to manage and support their real medical conditions.
It's still early enough that there’s a lot of decisions and new discoveries to be made, so this is your chance to get in early and help shape our future.
Other things about our environment you should be aware of:
We're still a small company, which means that everyone still wears a lot of hats and we need engineers who are comfortable with ambiguity and working across a wide variety of challenges. That said, our existing engineering team has built an extremely efficient working environment based on best-in-class hosted SaaS frameworks that greatly minimize the overhead in deploying and supporting software in production.
We're all really passionate about improving clinical outcomes for our members and truly advancing the GI health space. Most of us also have personal (direct/family/friend) connections to GI health problems. Whatever it is that fuels you, we're on a mission to build something much larger than ourselves here and looking for another partner in driving that mission forward.
Responsibilities Include:
Develop the kind of software and pipelines that you’d want to inherit from another developer (documentation, test coverage, logging, metrics, etc.)
Collaborate with the rest of your engineering team on design, planning and code reviews
Partner with product stakeholders on ideation, feedback and refinement of solutions that meet our business needs
Keep learning
You'll be a good fit here if you are:
A team player. You like collaborating closely with other engineers, often through pair programming, design & code reviews
Empathetic to our members’ GI health conditions and are driven to improve their outcomes
Security oriented. We take the stewardship of our customer's healthcare data seriously, and take no shortcuts to protect it
Comfortable with a distributed workforce. We interact with each other via video chat, Slack and PR comments
A self motivated, creative problem solver
At least partially obsessed with automating everything
We are proud of the team culture that we foster today, which is extremely friendly and supportive while constantly reaching to raise our own standards of engineering. We're really excited about what we're building, and usually having fun building it together. If all of that sounds fun to you too, we'd love to meet you.
Desired Qualifications
Degree in Computer Science or a related field, or equivalent experience
3+ years of demonstrated experience building and supporting data pipelines, MLOps environments, SaaS solutions or other related technologies
Proficiency with SQL, Python and some form of ELT/ETL solutions
Outstanding communication and interpersonal abilities with colleagues, business partners, and vendors alike
Bonus:
Familiarity with Google Cloud Platform (GCP) frameworks, including, BigQuery, Vertex AI Platform, IAM (fundamentals), Pub/Sub, Dataflow, Cloud Composer, DLP, or any others
Experience with Terraform and/or other infrastructure-as-code frameworks
Experience with medical, healthcare and/or population health data
Experience working in a HIPAA regulated environment (or other regulated industry) and supporting data security and privacy controls
Experience analyzing and optimizing system performance
Vivante Health is an equal opportunity employer.We believe safe spaces where everyone can be their authentic selves is the key to a successful team so we welcome and embrace all identities, cultures, and backgrounds.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"IMG Academy
3.1",3.1,Remote,Data Engineer,"Who We Are:
Who We Are:
IMG Academy is the world’s leading sports education brand, providing a holistic education model that empowers student-athletes to win their future, preparing them for college and for life. IMG Academy offers an innovative suite of on-campus and online experiences, providing growth opportunities for all student-athletes through:
Boarding school and camps, via a 600-acre state-of-the-art campus in Bradenton, Fla. (
IMGAcademy.com
)
Online coaching via the IMG Academy+ brand, with a focus on personal development through the lens of sport and performance (
IMGAcademy.com/Plus
)
Online college recruiting, via the NCSA brand, providing content, tools, coaching and access to a network of 40,000 college coaches (
ncsasports.org
)
Our team has a deep appreciation for the transformative power of sports and holistic personal development. Our leadership is actively investing in the growth of the organization. We continue to broaden and deepen our technology platform and team in pursuit of our vision for empowering youth sports and the path-to-college for student-athletes.
Position Summary:
The Data Engineer is responsible for implementing the technical direction of the Data Engineering team. This is a hands-on, individual contributor role operating on a cross-functional and skill-focused team. The Data Engineering team enables data- and insight-driven decision-making and planning by providing consistent, accurate and timely data to analysts, data scientists and business users. Working closely with platform development managers, Data Engineers design, implement and maintain data infrastructure used by Product and Platform Engineering teams in the form of data pipelines, data lakes and warehouses, business intelligence and visualization tools, and services for data quality and governance. Working with analysts and data scientists, they build custom data integrations, develop and deploy machine learning endpoints, and optimize the performance and scalability of customer-facing and internal data applications. The Data Engineer’s work provides teams with visibility into NCSA’s business performance, product delivery, and the outcomes student athletes, coaches and teams achieve to realize their goals. As one of the Data Engineers in the organization, you are empowered to make significant, impactful technical and cultural decisions, and help shape and guide the evolution of our data platform and company data strategy. Reporting to the Director, Data Engineering, the role requires deep expertise in the design, implementation, and continuous improvement of cloud-native data infrastructure and platforms.
Position Responsibilities:
You have experience (3-5 years) in data engineering, building capabilities with architecture, modeling (physical and logical), storage, resilience, and security.
You have experience in the mechanics of software engineering (preferably Python) practices to write Airflow DAGs and scripts.
You have deep expertise with cloud-based distributed data platforms, preferably in AWS.
You have experience developing data pipelines using Airflow, ELT design, optimization and maintaining data storage systems using S3 and Redshift or similar tools.
You have implemented batch and streaming data pipelines at scale and built platform components with automated testing suites using test-driven development principles for data.
You are familiar with relational databases (e.g. Postgres).
You have knowledge of SQL, Python and DBT.
You know how to create efficiency in data handling by tracking the lineage, maintaining the quality, and improving the discoverability of data.
Knowledge, Skills and Abilities:
Design, develop and maintain automated data pipelines to standardize and refine data collection for existing and new data sources used to power analytics and data science for business teams.
Develop extensive subject-matter expertise around individual and categories of data pipelines to establish operating standards and service-level agreements with analysts and data scientists.
Forecast data utilization and identify potential bottlenecks or optimization opportunities.
Apply test-driven development methods to data platform configuration and deployment.
Work with Software Engineering teams to adopt standard data platform components for their systems with the confidence that event data will be safely collected, stored, and transformed.
Lead technical conversations and decision-making around data architecture and implementation with Engineering teams, helping to identify opportunities and recommend technical solutions.
Partner with Analysts, Data Scientists and Data Program Managers to apply, implement and productionalize descriptive, predictive, and prescriptive statistical models on large datasets.
Define data operations approach and operating methodology for versioning, testing, security, test data management, data migrations, data quality, metadata, and documentation.
Dedicate meaningful time to research, evaluation and implementation of new tools and methods (Open Source and commercial) to meet changing organizational data needs and opportunities.
Serve as part of an on-call support rotation with other engineers to debug, troubleshoot and resolve data platform using the Incident Command System methodology.
Background Requirements:
Requires a background check upon offer.
Don’t meet every single requirement? We are dedicated to building a diverse, inclusive, authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfect with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.
Get to know us better:
www.imgacademy.com
IMG Academy provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",#N/A,501 to 1000 Employees,Company - Private,Education,Education & Training Services,#N/A,Unknown / Non-Applicable
"TheoremOne, LLC
4.2",4.2,Remote,Data Engineer,"Join our global team of 500+ craftspeople! We are a consultancy that solves business problems by designing and building highly complex custom software for the world's leading companies. We are on a mission to dismantle the traditional consulting ecosystem and replace it with an effective framework for innovation that transforms the way businesses think about and solve problems from the inside out.

TheoremOne is the winner of Comparably's Best Work-Life Balance: Top-Rated 100 Small/Mid-Sized Companies
https://www.comparably.com/news/best-work-life-balance-2022/
RESPONSIBILITIES
Designing, constructing, installing, and maintaining large-scale processing systems and infrastructure.
Managing and optimizing data pipelines, architectures, and data sets.
Working with both streaming and batch data processing.
Handling and analyzing data to identify patterns and trends.
Implementing ETL processes and tools.
Collaborating with AI specialists to ensure the smooth flow and availability of data for AI models.
Implementing mechanisms for data curation, search, and discovery.
Ensuring data architecture will support the requirements of the business.
Building infrastructure for optimal extraction, transformation, and loading (ETL) of data from various sources using cloud technologies.
Keeping up-to-date with the latest data engineering tools, strategies, and best practices.
REQUIREMENTS
Proficient in Python, Java, Scala, or similar programming languages.
Experience with big data tools such as Spark, Kafka, and Hadoop.
Strong knowledge in building and maintaining ETL pipelines.
Familiarity with cloud platforms like AWS, Google Cloud, or Azure, and their data-related services.
Understanding of stream-processing systems, such as Kafka or Storm.
Proven experience with relational SQL and NoSQL databases.
Experience with data warehousing solutions and architectures.
Strong problem-solving skills and attention to detail.
Ability to work in a collaborative environment.
Excellent communication skills for both technical and non-technical audiences.
CERTIFICATIONS
Google Cloud Professional Data Engineer
AWS Certified Big Data - Specialty
Microsoft Certified: Azure Data Engineer Associate
Unsure if your skills meet all of our requirements?
Apply anyway! We would love to meet you and find out more about how your skills could add value. At TheoremOne, we value open communication and feedback. We believe that diversity of identity, perspective, and experience makes us stronger; we would love to hear your perspective too!

Recording disclosure
TheoremOne records interviews so that we can focus on delivering a great interview experience. If you are uncomfortable with being recorded, please let our recruiters know when they reach out to you.

About TheoremOne
Founded in 2007, TheoremOne LLC is a remote-first technology consulting company, globally distributed by design. Our services range from:
New product development
Pure R & D
Legacy modernization
Revenue generation
Process optimization
Organizational transformation

If it’s cool and engaging in technology, we are likely working on it.

Customers come to us because they need to change to succeed and are looking for a solution that isn't just about technology — but also people, process, and leadership. We consult, form a diverse team of experts, and deliver strategy and execution under one roof. Consultants come to us for the autonomy, depth of project, and challenge of working with a wide range of clients across multiple platforms and industries.

Our contributors are master puzzle solvers in a vast range of technologies.

Benefits and Perks
100% REMOTE - We're fully distributed
EDUCATION AND CAREER GROWTH - We encourage our team to undertake any professional growth opportunities available, and we offer programs and financial assistance to achieve this!
HEALTHY BODY, HEALTHY MIND - HAPPY TEAM - We offer paid vacation and support healthy lifestyles through our physical fitness benefits program.
COMPANYWIDE VISIBILITY - We operate in a fully transparent environment to ensure we as a company and team have full understanding of where we came from, and where we are going.
HEALTHCARE & FINANCE - For US, UK, Canada, and Spain based full time employees; we have comprehensive benefits.

#LI-Remote

TheoremOne expects all team members to be honest, trustworthy, and operate with integrity. Discrimination and all unlawful harassment (including sexual harassment) in employment is not tolerated. We encourage success based on our individual merits and abilities, and all decisions regarding recruitment, hiring, promotion, compensation, employee development decisions such as training, and all other terms and conditions of employment, are based on business needs, job requirements and individual qualifications without regard to race, genetics, nationality, national origin, citizenship status, employment status, ethnicity, ethnic origin, color, creed, religion, belief, age, family or parental status, pregnancy, marital status, sex, gender, sex or gender assigned at birth, gender identity, gender expression, sexual orientation, sexual preference, romantic orientation, romantic preference, pairing orientation, pairing preference, language, lifestyle, social class, socio-economic status, political affiliation, military or veteran status, physical and mental ability, disability, hairstyle, physical features, medical condition, or any other other status protected by the laws or regulations in the locations where we operate. We oppose all forms of unlawful or unfair discrimination. TheoremOne encourages applicants of all ages. We've created a competitive rewards model for our team members around the world. TheoremOne's benefit and compensation offerings vary depending on geographic location, are subject to eligibility requirements, and may be modified from time to time. TheoremOne is an equal opportunity employer.","$127,500 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2007,$25 to $100 million (USD)
"Fictiv
3.6",3.6,Remote,Data Engineer,"Fictiv Exists to Enable Hardware Innovators to Build Better Products, Faster
Fictiv, coined the ""AWS of manufacturing,"" is a leading technology company transforming the $350 billion manufacturing industry. Our cutting-edge cloud platform uses AI and machine learning algorithms to help companies build hardware at the speed of software. Come join our growing team!

What's in it for you?
Opportunity To Unlock Your Creativity
Think of all the times you were held back from trying new ideas because you were boxed in by bureaucratic legacy processes or old-school tactics. Having a growth mindset is deeply ingrained into our company culture since day one so Fictiv is an environment where you have the creative liberty and support of the team to try big bold ideas to achieve our sales and customer goals.
Opportunity To Grow Your Career
There are plenty of jobs out there. The question is whether any of them will help you grow in your career. Will you be challenged by teammates to achieve your potential? Or are they roles that will ask you to do more of what you've already mastered? At Fictiv, you'll be surrounded by supportive teammates who will push you to be your best through their curiosity and passion.
Impact in this Role
The Data Engineering & Analytics team develops a centralized data warehouse and produces reports and dashboards for Fictiv, that are to provide strategic insights that impact multiple functional areas including: Operations, Finance, Sales, Marketing, Engineering, Product, Architecture, and Customer Support. The Data & Analytics team partners closely with cross functional stakeholders to ensure that data is accurate, timely, secure and has properly managed change control.
This team sets the stage for ensuring Fictiv's business is delivering on KPIs and goals. This team provides all the inputs for Fictiv's strategic decision making.
This team works very closely with cross-functional stakeholders, and leverages multiple different Business Intelligence (BI) technologies to achieve these goals.
As a Data Engineer for the data team, you will support the Data Engineering Lead, Data Analysts and Product Owners in the everyday management of our data warehouse. You will serve as a facilitator between the business and technology in understanding the technical requirements and ensure that solutions address the business problems.
Our company understands the importance of utilizing data to make informed decisions. We are looking for someone that gets excited about data and continues to drive a data driven culture.
What You'll Be Doing
Desired traits
Responsible for understanding end-to-end data flows and identifying data dependencies in support of delivery, release, and change management
Responsible for monitoring, alerting and on-call duties for all data warehouse operations
Follow and contribute to SQL coding standards, change control practices, and data warehouse practices
Collaborate with Software Engineering and Product Owners to ensure changes to event implementations are gracefully handled in the data warehouse
Available to work with remote teams
Research, Diagnose, and Monitor performance bottlenecks
Document development that is to be moved to production
Assemble and modify large complex datasets to meet business requirements
Identifying, designing, and implementing internal process improvements for greater scalability, optimizing data delivery and automating manual processes
Building BI reports to utilize datasets to provide actionable insights into key business performance metrics including operational efficiency
Create data tools for analytics and data team that assist in building and optimizing our product into an innovative industry leader.
Working with stakeholders including data, design, product, and executive teams and assisting them with data-related technical issues.
Desired Traits, Qualifications, Education and Experience Equivalency
Have proven experience working with large and complex datasets and are comfortable writing queries directly or utilizing BI tools. Experience with Snowflake, Sigma, and Heap is a bonus
Extensive knowledge of BI concepts and database query languages (i.e. SQL or Python), dimensional modeling, data warehouse design, dash-boarding)
Ability to build and optimize datasets and data pipelines
Ability to perform root cause analysis on internal processes and data to identify opportunities for improvement and answer questions
Excellent analytic skills associated with working with structured and unstructured datasets
Ability to build processes that support data transformation, workload management, data structures, dependency and metadata
You are a clear communicator. You can provide business context for engineers as well as highlight technical challenges for non-engineers
Ability to present to groups of mixed technical ability
Comfortable not knowing answers, but resourceful and able to resolve issues.
Willing to learn and understand new ways of doing things
Preferred Experience/ Minimum Qualifications
Graduate in Data Science, Data Analysis, or a related field.
3 years experience as a Data Engineer using BI tools.
2 years of providing complex analysis reports in any one of finance, sales, marketing, logistics, user adoption or similar fields.
Experience with Snowflake, Redshift, Heap, Fivetran and SigmaComputing (or similar BI tools such as Tableau, Looker or Quicksight).
Proven experience working with complex datasets and writing SQL queries with multiple levels of CTEs directly.
Extensive knowledge of BI concepts (regressions, sliding window functions, financial metrics, marketing funnel metrics, logistics and fulfillment metrics)
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience with leading and coordinating cross-functional initiatives, conducting interviews and performing analyses to create business cases for projects.
Experience performing live training sessions for internal and external stakeholders during system and process implementation.
Experience using Salesforce, Marketo, Netsuite or similar core business systems.
Must have strong communication skills and possess the ability to interact effectively with co-workers.
Must have strong leadership skills.
Perks and Benefits
Competitive medical, dental, and vision insurance
401K plan
Monthly Virtual Work stipend for things like food, internet, travel, pet care, health and wellness
Annual Education stipend
Parental leave programs
Paid volunteer days
Onboarding setup, including: standing desk, laptop, monitor, and chair, and a stipend for additional items such as headphones, blue light glasses, or any other ergonomic supplies you may want or need
And much, much more!
Fictiv is continuing to expand our remote US workforce. Recent hires include professionals located in:
Arizona (AZ), California (CA), District of Columbia, (DC), Delaware (DE), Florida (FL), Georgia (GA), Hawaii (HI), Iowa (IA), Illinois (IL), Indiana (IN), Kansas (KS), Massachusetts (MA), Maryland (MD), Michigan (MI), Minnesota (MN), Missouri (MO), North Carolina (NC), New Hampshire (NH), New Jersey (NJ), Nevada (NV), New York (NY), Ohio (OH), Oregon (OR), South Carolina (SC), Texas (TX), Tennessee (TN), Utah (UT), Virginia (VA), Washington (WA), West Virginia (WV), Wisconsin (WI), Wyoming (WY)70,
Base Salary Range: $110,000 (min) to $129,000 (max)
Interested in learning more? We look forward to hearing from you soon.

About Fictiv
Our Digital Manufacturing Ecosystem is transforming how the next rockets, self-driving cars, and life-saving robots are designed, developed and delivered to customers around the world.
This transformation is made possible through our technology-backed platform, our global network of manufacturing partners, and our people with deep expertise in hardware and software development.
We're actively seeking potential teammates who can bring diverse perspectives and experience to our culture and company. We believe inclusion is the best way to create a strong, empathetic team. Our belief is that the best team is born from an environment that emphasizes respect, honesty, collaboration, and growth.
We encourage applications from members of underrepresented groups, including but not limited to women, members of the LGBTQ community, people of color, people with disabilities, and veterans.","$110,000 /yr (est.)",51 to 200 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,2013,Unknown / Non-Applicable
"Resideo
4.2",4.2,"Austin, TX",Junior Data Engineer,"Resideo is seeking a Junior Data Engineer to join our AI team. Resideo engineers strive to provide peace of mind to millions of homeowners through a robust and capable set of products that safeguard the home and simplify everyday life.
Unusual compared to most data engineering roles, the AI team is dealing with millions of unstructured data events per day. We need to build robust ETL and data pipelines to continuously improve our ML models. Those ML models enable a range of next-generation of Resideo home security products, including video doorbells, outdoor cameras, and other security sensors.
As part of this initiative, we are looking for a junior data engineer who is excited to work with cloud unstructured data pipelines and the challenges associated with them . You will be taking POC pipelines and expanding them to work with big data, helping build out MLOps for Resideo. Work with a cross-functional team of embedded engineers, data scientists, and cloud developers to deliver a best-in-class solution.
This role will have the opportunity to impact newly developed consumer products with high business visibility.
JOB DUTIES:
As a Data Engineer, you will be tasked with building data acquisition and processing to building video machine-learning products
Unstructured data comes with unique challenges and problems that you will be responsible for researching and helping solve
You will work closely with engineers and scientists contributing to the ongoing development and monitoring of ML products
Decompose complex problems and pipelines into simple, straight-forward solutions
Work with a geographically and culturally dispersed team
YOU MUST HAVE:
Bachelor's degree in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience
One or more in each of these categories:
Python, PySpark, SQL, etc.
Experience manipulating and curating large image and video datasets
Experience with CI/CD workflows, including Github and Terraform
Technical exposure across video/image topics including image processing, ML/DL, encodings
Excellent written and oral communication skills
Demonstrated ability to achieve goals in a fast-paced environment
WE VALUE:
Computer vision , CNNs, and Machine learning workflows
Domain knowledge of security cameras or home IOT devices
Understanding with embedded SoC devices and edge deployment
Experience with a variety of vision, depth or audio sensors
Knowledge and experience with Azure cloud environments, Databricks, Azure Data Factory
WHAT'S IN IT FOR YOU:
Life and health insurance
Life assistance program
Accidental death and dismemberment insurance
Disability insurance
Retirement plan (Immediate eligibility for 401K)
Vacation & holidays. (Enjoy work-life balance)
In compliance with applicable laws, Resideo provides a reasonable range of compensation for roles that may be performed in Colorado, New York City, Washington, or California. Actual compensation is influenced by various factors, including, but not limited to, skills, experience, and the specific office location.
The expected base salary range for this role in Colorado is $90,373-$150,621.
The expected base salary range for this role in NYC is $108,448-$180,745.
The expected base salary range for this role in Washington is $99,410-$165,683.
The expected base salary range for this role in California is $103,929-$173,214.
#LI-AL1
#SWE

Resideo is a leading global provider of critical comfort and security solutions primarily in residential environments and distributor of low-voltage electronic and security products. Building on a 130-year heritage, Resideo has a presence in more than 150 million homes, with 15 million systems installed in homes each year. We continue to serve more than 110,000 professionals through leading distributors, including our ADI Global Distribution business, which exports to more than 100 countries from more than 200 stocking locations around the world. Resideo is a $5.0 billion company with approximately 13,000 global employees. For more information about Resideo, please visit www.resideo.com .
At Resideo, we bring together diverse individuals to build the future of homes. Resideo is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status. For more information on applicable U.S. equal employment regulations, refer to the ""EEO is the Law"" poster , ""EEO is the Law"" Supplement Poster and the Pay Transparency Nondiscrimination Provision . Resideo complies with applicable equal employment laws in all countries where we do business. For more information on how we process your information in the job application process, please refer to Recruitment Privacy Notice . If you require a reasonable accommodation to apply for a job, please use Contact Us form for assistance.","$82,225 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,2018,$5 to $10 billion (USD)
"eTeam Inc.
4.2",4.2,"Austin, TX",Data Analyst / Data Engineer / BI Developer,"Skills: Advanced SQL is a must, additionally preferred to have Python/Java. Candidates will need to take a 45 minute SQL, Python, and analytics knowledge technical assessment.
Primary Responsibilities : Develop and support data pipelines to extract, transform and load data into Google Data Center data warehouse. Maintain data reports and dashboards. Analyze data and perform statistical analysis.
Job Description
Develop ETL/data pipelines to populate the data warehouse from a variety of custom and 3rd-party systems.
Design, build, launch, optimize and extend full-stack Data and business intelligence solutions spanning extraction, storage, transformation and visualization layers.
Implement and maintain data analysis scripts using SQL and Python.
Develop and support reports and dashboards using Google Plx/Tableau/Looker/Data Studio.
Improve and develop new and existing dashboards supporting business growth.
Analyze data and perform statistical analysis.
Monitor performance and implement the necessary infrastructure optimization.
Demonstrate ability and willingness to learn quickly and complete large volumes of work with high quality.
Demonstrate excellent collaboration, interpersonal communication and written skills with the ability to work in a team environment.
Minimum Qualifications
4+ years of solid hands-on experience with SQL scripting, dashboard development, and data analysis.
Hands-on experience with design, development and support of data analysis.
Hands-on experience using statistical methods for data analysis.
Familiarity with machine learning and advanced analytics methods.
Understanding of Google Cloud Platform (GCP) technologies in the big data and data warehousing space (BigQuery, Cloud Functions, etc.).
Experience with data platform and visualization technologies such as Google plx dashboards, Data Studio, GoogleSQL, and BigQuery.
Strong design and development skills with meticulous attention to detail.
Familiarity with Agile Software Development practices and working in an agile environment.
Strong analytical, troubleshooting and organizational skills.
Ability to analyze and troubleshoot complex issues, and proficiency in multitasking.
BS degree in Computer Science, Math, Statistics or equivalent academic credentials.",$62.50 /hr (est.),5001 to 10000 Employees,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,1999,$100 to $500 million (USD)
AV Technologies,#N/A,"North Las Vegas, NV",Data Engineer,"Seeking for a strong data analyst who can perform independent.
Good to have Prior experience in banking domain is plus and understanding the finance various data transactions.
Should have strong SQL analytical (RDBMS & Cloud platform), problem-solving skills, data optimization, and strong communications in showcasing to business.
Must have experience with building SQL queries, data profiling, analysis, and mapping activities.
Should have experience in understanding ETL packages, reports, use cases and converting into technical aspects.
Strong understanding of data modeling, data warehouse & data lake concepts such as logical & physical models (OLTP & OLAP), data marts, entity relationship diagrams, normalization, source target mapping, and data classification.
Must have experience in data cleansing rules, writing transformation logics, Data quality activities.
Good to have experience in multiple query engines SQL server, Oracle, Postgres Sql, HUE query engine is helpful.
Good to have strong knowledge in cloud technologies, extracting & reading multiple inbound files (Json, API, Kafka topics)
Job Type: Full-time
Salary: $83,639.52 - $190,886.77 per year
Benefits:
Health insurance
Paid time off
Compensation package:
Yearly pay
Experience level:
6 years
7 years
8 years
Schedule:
8 hour shift
Ability to commute/relocate:
North Las Vegas, NV 89030: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person","$137,263 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Living Security
4.0",4.0,Remote,Data Engineer,"Company Description:

Named one of Austin’s Best Places to Work for two years in a row, the Living Security team is composed of 50+ cybersecurity professionals committed to transforming security awareness training as we know it and turning end users into the enterprise’s greatest asset against cybercrime. Living Security is trusted by security-minded organizations like CVS Health, MasterCard, Verizon, MassMutual, Biogen, AmerisourceBergen, Hewlett Packard, JP Morgan, and Target.
Who we're looking for:
We are looking for a Data Engineer for the Living Security engineering team. As a member of the engineering team, you will:
Build integrations that retrieve data from a variety of security products via third-party APIs
Engage in data modeling efforts to align new and existing data sources with Living Security data models
Collaborate with data scientists to ensure ingested data supports core business needs
Support ongoing maintenance of the data processing infrastructure
Assist in monitoring data processing pipelines to ensure their availability, accuracy, and security
Have a direct impact on the success and direction of the product and the future of human risk management
Qualifications:
2+ years professional experience developing data processing pipelines
Solid understanding of data engineering concepts and best practices
Fluency in Python
Knowledge of SQL and experience working with relational databases
Familiarity with AWS; experience with Athena, DynamoDB, or Step Functions is a plus
Effective communication skills and the ability to work collaboratively in a team
Bachelor's degree in computer science, software engineering, or related field is preferred
Exposure to data integration tools like Airflow and DBT is a plus
Perks of Living Security:
Growth opportunities throughout the company
Open, inclusive, and fun environment
Benefits, including medical, dental and vision insurance, short & long term disability, life insurance, 401(k), HSA with employer contribution, FSA
Financial Wellness Program/Financial Adviser
Competitive salary plus stock options
Responsible unlimited PTO policy and paid holidays
Work remote and flex-time options
Opportunity to be a part of a company that is revolutionizing the cybersecurity industry
More about Living Security:
Living Security believes empowering people is the key to ending cybersecurity breaches, picking up where traditional security awareness training drops off. Gamified learning and immersive experiences engage and educate users, while the science-backed, tech-enabled platform uniquely provides CISOs the ability to measure training efficacy and program ROI.
While we take our mission seriously, we have a lot of fun while executing!
We are an equal opportunity employer and value diversity. We do not discriminate on the basis of ethnicity, religion, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
All your information will be kept confidential according to EEO guidelines.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2017,Unknown / Non-Applicable
"eTeam Inc.
4.2",4.2,"Irving, TX",Data Engineer,"Scala ,Python, PySpark, Kudo ,Kafka and Data Engineering background

""Experience in data engineer , Data Analytics; Big Data Technologies Expert in Python. (Developer level Expertise expected), Programming experience in Python, R programming , Algorithms Spark, Kafka Good experience in the Data Models for Client; Reporting, Dash boarding; Client tools H2O, Tensor Flow, Prediction.io; Distributed Data Platforms HDFS, Knowledge of data cleaning, wrangling, visualization and reporting, with an understanding of the best, most efficient use of associated tools and applications to complete these tasks. Experience in MapReduce is a plus. Deep knowledge of data mining, machine learning, natural language processing, or information retrieval. Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources. A willingness to explore new alternatives or options to solve data mining issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done. Good to have Elasticsearch, Splunk, Casandra; Good to have Cluster Compute Technologies Spark, Akka, NoSql DB; Good to have Distributed data; Hortonworks toolset, Zookeeper, HDFS""
(1.) To be responsible for providing technical guidance or solutions ;define, advocate, and implement best practices and coding standards for the team.
(2.) To ensure process compliance in the assigned module, and participate in technical discussion sor review as a technical consultant for feasibility study (technical alternatives, best packages, supporting architecture best practices, technical risks, breakdown into components, estimations).
(3.) To develop and guide the team members in enhancing their technical capabilities and increasing productivity
(4.) To prepare and submit status reports for minimizing exposure and risks on the project or closure of escalations.



Looking for a talent who has an expertise in below skills and years of experience :
spark Scala programming
spark real time streaming - Kafka,Kudu,Impala,HBase spark scala batch pipelines
GCP ,AWS - data pipelines
Oozie , Airlfow, composer - scheduling tools
CICD Jenkins basic java/springboot",$62.50 /hr (est.),5001 to 10000 Employees,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,1999,$100 to $500 million (USD)
"Rightway
3.9",3.9,Remote,Data Engineer II,"ABOUT THE ROLE:
Rightway, a leading healthcare technology company dedicated to transforming the healthcare landscape, is seeking a seasoned full-time Data Engineer III to take on pivotal responsibilities in defining, deploying, and enhancing our mission-critical data infrastructure. Leveraging your deep expertise in AWS ecosystem and Python, you will play a significant role in processing extensive healthcare datasets. This will empower Rightway to yield powerful insights aimed at improving the healthcare experiences of our growing member base that's already over 1 million strong. While familiarity with medical data is beneficial, it's not a requisite for this role.
WHAT YOU'LL DO:
Craft robust, efficient Python and SQL code for production.
Utilize AWS and other services such as Lambda and Glue to handle data operations.
Build and maintain large-scale data pipelines using Apache Airflow.
Oversee the maintenance of Extract, Load, and Transform (ELT) processes using DBT.
Design optimized database schemas in PostgreSQL to ensure data integrity and high performance.
WHO YOU ARE:
A seasoned data engineer with 3+ years of industry experience.
Skilled in working with AWS systems in a production environment.
Proficient in writing SQL and Python code in a production environment.
Experienced in scaling data infrastructure to handle high volumes of data.
EXTRA CREDIT:
Experience working with medical and pharmacy claims data.
Knowledge in deploying applications using serverless architecture.
Hands-on experience managing AWS services such as Lambda and Glue.
Familiarity with infrastructure-as-code services such as Terraform or CloudFormation.
BASE SALARY: $110,000 - $145,000
CYBERSECURITY AWARENESS NOTICE
In response to ongoing and industry-wide fraudulent recruitment activities (i.e., job scams), Rightway wants to inform potential candidates that we will only contact them from the @rightwayhealthcare.com email domain. We will never ask for bank details or deposits of any kind as a condition of employment. If you have any questions about a suspicious interaction with Rightway, please feel free to reach out to us at hr@rightwayhealthcare.com.
ABOUT RIGHTWAY:
Rightway is on a mission to harmonize healthcare for everyone, everywhere. Our products guide patients to the best care and medications by inserting clinicians and pharmacists into a patient's care journey through a modern, mobile app. Rightway is a front door to healthcare, giving patients the tools they need along with on-demand access to Rightway health guides, human experts that answer their questions and manage the frustrating parts of healthcare for them.
Since its founding in 2017, Rightway has raised over $130mm from investors including Khosla Ventures, Thrive Capital, and Tiger Global at a valuation of $1 billion. We're headquartered in New York City, with a satellite office in Denver. Our clients rely on us to transform the healthcare experience, improve outcomes for their teams, and decrease their healthcare costs.
HOW WE LIVE OUR VALUES TO OUR TEAMMATES:
We're seeking those with passion for healthcare and relentless devotion to our goal. We need team members who will:
We are human first
Our humanity binds us together. We bring the same empathetic approach to every individual we engage with, whether it be our members, our clients, or each other. We are all worthy of respect and understanding and we engage in our interactions with care and intention. We honor our stories. We listen to—and hear—each other, we celebrate our differences and similarities, we are present for each other, and we strive for mutual understanding.
We redefine what is possible
We always look beyond the obstacles in front of us to imagine new solutions. We approach our work with inspiration from other industries, other leaders, and other challenges. We use ingenuity and resourcefulness when faced with tough problems.
We debate then commit
We believe that a spirit of open discourse is part of a healthy culture. We understand and appreciate different perspectives and we challenge our assumptions. When working toward a decision or a new solution, we actively listen to one another, approach it with a ""yes, and"" mentality, and assume positive intent. Once a decision is made, we align and champion it as one team.
We cultivate grit
Changing healthcare doesn't happen overnight. We reflect and learn from challenges and approach the future with a determination to strive for better. In the face of daunting situations, we value persistence. We embrace failure as a stepping stone to future success. On this journey, we seek to act with guts, resilience, initiative, and tenacity.
We seek to delight
Healthcare is complicated and personal. We work tirelessly to meet the goals of our clients while also delivering the best experience to our members. We recognize that no matter the role or team, we each play a crucial part in our members' care and take that responsibility seriously. When faced with an obstacle, we are kind, respectful, and solution-oriented in our approach. We hold ourselves accountable to our clients and our members' success.
Rightway is a healthcare company looking to improve healthcare outcomes for everyone, everywhere. With that in mind, we have to consider what is good for the health of our team, the company, and the communities we operate in. As such, Rightway has determined a mandatory COVID-19 vaccination policy for all employees, in combination with other safety precautions, is the best way forward.

Rightway is PROUDLY an Equal Opportunity Employer that believes in strength in the diversity of thought processes, beliefs, background and education and fosters an inclusive culture where differences are celebrated to drive the best business decisions possible. We do not discriminate on any basis covered by appropriate law. All employment is decided on the consideration of merit, qualifications, need and performance.","$127,500 /yr (est.)",51 to 200 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2016,Unknown / Non-Applicable
Avevotech,#N/A,"Irving, TX",GCP Data engineer,"We have multiple location - CT, RI, VA, TX, NY/NJ
Must Have Skills: Google BigQuery, Google cloud, Data Warehouse, ETL, Python, Pyspark
· Possess excellent knowledge of SQL along with its variation for popular database like BigQuery etc.
· Experience writing Python & Pyspark scripts.
· Strong experience in data analytics and business intelligence.
· Development experience building ETL pipelines using cloud tools like dataflow, lambda.
· Experience in tuning SQL queries to maximize performance.
· Working knowledge on implementing Data quality checks.
· Experience with Airflow or Tidal to orchestrate the data pipelines.
· Excellent critical reasoning, problem-solving skills and teamwork skills.
· Solid written and verbal communication skills and able to articulate complex solutions to technical and non-technical personnel.
· Experience with VCS such as git and build tools such as Jenkins or Maven.
· Experience working for clients in healthcare space.
Job Types: Full-time, Permanent
Pay: $60.00 - $65.00 per hour
Work Location: In person",$62.50 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
TekValue IT Solutions,#N/A,"Vicksburg, MS",AWS Data Engineer,"Required Skills:
· Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.
· Extensive hands-on experience designing, developing, and maintaining data pipelines and ETL
· processes on AWS Redshift, including data lakes and data warehouses.
· Proficiency in SQL programming and Redshift stored procedures for efficient data manipulation and
· transformation.
· Hands-on experience with AWS services such as AWS DMS, Amazon S3, AWS Glue, Redshift,
· Airflow, and other pertinent data technologies.
· Strong understanding of ETL best practices, data integration, data modeling, and data transformation.
· Experience with complex ETL scenarios, such as CDC and SCD logics, and integrating data from
· multiple source systems.
· Demonstrated expertise in AWS DMS for seamless ingestion from on-prem databases to AWS cloud.
· Proficiency in Python programming with a focus on developing efficient Airflow DAGs and operators.
· Experience in converting Oracle scripts and Stored Procedures to Redshift equivalents.
· Familiarity with version control systems, particularly Git, for maintaining a structured code repository.
· Proficiency in identifying and resolving performance bottleneck and fine-tuning Redshift queries,
· Strong coding and problem-solving skills, and attention to detail in data quality and accuracy.
· Ability to work collaboratively in a fast-paced, agile environment and effectively communicate technical
· concepts to non-technical stakeholders.
· Proven track record of delivering high-quality data solutions within designated timelines.
· Experience working with large-scale, high-volume data environments.
· The ideal candidate possesses several years of hands-on experience working with Redshift and other
· AWS services and a proven track record of delivering high-performing, scalable data platforms and
· solutions within the AWS cloud.
· AWS certifications related to data engineering or databases are a plus.
Job Type: Contract
Salary: $130.00 - $140.00 per hour
Ability to commute/relocate:
Vicksburg, MS 39180: Reliably commute or planning to relocate before starting work (Required)
Experience:
AWS: 5 years (Preferred)
SQL: 5 years (Preferred)
Data warehouse: 5 years (Preferred)
Work Location: In person",$135.00 /hr (est.),Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Frontline Education
4.0",4.0,"Naperville, IL",Data Engineer,"Location Requirements: This role is Hybrid to our office in Naperville, IL. Remote candidates will be considered.
Your role on the team:
We are looking for an enthusiastic, experienced, and highly driven Data Engineer to play an instrumental role in creating and evolving complex data-centric solutions that improve decision-making for the company’s clients and internal staff. You will be part of a data engineering team responsible for building and maintaining scalable data systems and pipelines. The team manages the acquisition, storage, and processing of data from internal and external data sources for multiple analytical products. This also includes data mapping, geocoding, validation, metadata management, and automation processes. The team uses Python scripting to implement and automate data workflows on top of relational and columnar databases.
You will collaborate with stakeholders and development teams to provide decision-making solutions from idea through design, deployment, operations, and validation - all while working in an exciting, fast-paced, agile environment.
This role reports to the Data Team Lead and works closely with Development, Product Management, and strategic partners to deliver solutions that simplify the daily work life of the front line of education.
You can expect to:
Create, optimize, maintain, and improve data integration pipelines
Create and implement complex transformations of regular and large datasets
Ensure data quality, reliability, scalability, and integrity
Prepare data for prescriptive and predictive modeling
Automate and improve the performance and efficiency of data management processes
Collaborate with engineering and product development teams on architecting, building, and deploying the data analysis systems
Provide feedback on the work of other data engineers
Communicate with clarity across the organization and influence decisions as appropriate
What you bring to the role:
Ability and willingness to learn new languages and technologies
Fast learner, detail-oriented, and capable of working in a fast-paced work environment
Excellent oral and written communication skills
This role requires:
2+ years of progressive experience with data-intensive systems and applications
Proficiency with T-SQL and data modeling
Experience with database technologies (MS SQL, PostgreSQL, Snowflake)
Excellent command of Python and scripting
Hands-on experience with ETL/ELT tools
Experience with BI Tools including Tableau.
Experience with cloud-based environments – AWS preferred
Familiarity with DevOps, Linux and/or Windows
Familiarity with Agile development methodologies
Who we are:
Frontline Education is a pioneer of school administration software purpose-built for K-12 districts. We provide innovative, connected solutions for student and special programs, business operations, and human capital management with powerful data and analytics to empower educators and administrators. We earn the trust of K-12 leaders across the U.S. by serving as a consistently high-performing, forthright partner of school districts through every dimension of the company.
We're a group of unique and talented individuals who love what we do. We've been lucky enough to land jobs with a rapidly growing tech company that supports an appreciative and friendly customer base. We work hard to make our customers happy, but we like to have a good time in the process. We are a company that strives to think in terms of “we” instead of “me.” We believe in the philosophy of servant leadership and that it’s all about putting others first. We also value the balance between family and work.
Frontline embraces diversity, equity, and inclusivity. We are intentionally building a workplace that respects, supports, and values the identities of all our employees. We believe this to be foundational in developing a strong community in our company. Frontline Education is an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
The perks of being a Frontliner:
Frontline offers a competitive compensation package including a base salary, rewarding bonus structure, 401k match, and unlimited PTO! Our company growth has created a promising environment for career advancement and rewarding challenges. We offer a tuition reimbursement program for eligible college credit coursework available to employees depending on their status and length of employment.","$85,475 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Software Development,1998,$100 to $500 million (USD)
"Mobile Integration Workgroup
2.9",2.9,"Provo, UT",Data Engineer,"Job Summary:
The Warehouse Data Engineer is responsible for designing, implementing, and maintaining data warehouse solutions that enable efficient data storage, retrieval, and analysis. This role involves collaborating with data analysts, data scientists, and other stakeholders to ensure the availability and accessibility of high-quality data for business intelligence and analytics purposes.

The position will be responsible for implementing a new data warehouse for a small company and migrating from our existing Snowflake instance. The role will be a combination of both development work and consulting to determine the overall architecture and systems for the data warehouse implementation.

Responsibilities:

1. Data Modeling and Architecture:
Design and develop data warehouse architectures that align with business needs and industry best practices.
Create and manage data models, ETL (Extract, Transform, Load) pipelines, and data integration processes.

2. ETL Development:
Develop and maintain ETL processes to extract data from various sources, transform it into a usable format, and load it into the data warehouse.
Optimize ETL workflows for performance, scalability, and reliability.

3. Data Quality and Governance:
Implement data quality checks and validation processes to ensure accuracy and consistency of data in the warehouse.
Collaborate with data stewards to establish data governance practices and standards.
4. Performance Tuning and Optimization:
Monitor and fine-tune the data warehouse performance for efficient query execution and data retrieval.
Identify and resolve performance bottlenecks and optimize data processing pipelines.

5. Collaboration:
Work closely with cross-functional teams including data analysts and business stakeholders to understand data requirements and deliver actionable insights.
Collaborate with the IT team to ensure data infrastructure aligns with overall technology strategies.

6. Data Security and Compliance:
Implement security measures to protect sensitive data within the data warehouse.
Ensure compliance with data privacy regulations and industry standards.

7. Documentation:
Document data warehouse architecture, ETL processes, and data flow for future reference and knowledge sharing.

8. Continuous Learning:
Stay updated with the latest trends and technologies in data engineering, cloud services, and data warehousing.
Qualification
Proven experience as a Data Engineer or similar role, with a focus on data warehouse development and ETL processes.
Proficiency in SQL and experience with ETL tools (e.g., Apache Spark, Apache NiFi, Talend, Informatica, etc.).
Familiarity with cloud platforms such as Snowflake for building and deploying data solutions.
Strong understanding of data modeling concepts and techniques.
Knowledge of data warehousing best practices and performance optimization.
Excellent problem-solving skills and attention to detail.
Effective communication and collaboration skills","$100,092 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,1999,$5 to $25 million (USD)
"Scott’s Cheap Flights
4.8",4.8,Remote,Data Engineer I,"At Going, we rely heavily on data to make informed decisions. As a Data Engineer I, you will play a crucial role in shaping our data-driven culture. Your contributions will directly impact strategic decisions and the continual improvement of our products, helping more people travel and experience the world.
In this role, you'll work closely with other members of the Data Engineering Team to optimize and streamline our data pipelines, boosting efficiency and accelerating data processing for seamless operations. Your knack for sharing innovative ideas will play a vital role in refining data engineering processes fostering a more streamlined and effective workflow. As you cultivate expertise in our data systems, you'll become an invaluable asset, readily tackling intricate technical challenges and providing optimal solutions. Additionally, you'll manage complex, high-impact data engineering projects, each contributing significantly to our strategic goals and propelling the company toward greater success.
Due to the high volume of applicants we receive for this role, we will be closing initial applications on Friday, September 8th to ensure we can review and respond to all candidates that have applied.
In the short term, you will:
Familiarize yourself with our technology stack and codebase, enabling you to contribute effectively to ongoing projects.
Understand the intricacies of our existing data models, ensuring you can seamlessly work within our data ecosystem.
Actively engage in code review processes, offering valuable feedback and contributing to code quality enhancement.
Identify and resolve issues within our data pipelines, ensuring smooth data flow and accurate results.
Engage with stakeholders to understand their data needs, promoting collaboration and alignment.
In the long term, you will:
Optimize and streamline our data pipelines, enhancing efficiency and data processing speed.
Share innovative ideas to improve data engineering processes, contributing to a more streamlined and effective workflow.
Achieve expertise in our data systems, becoming a key resource for complex technical challenges and solutions.
Manage complex, high-impact data engineering projects, significantly contributing to our strategic goals.
What you know:
Demonstrable experience in data engineering, showcasing your ability to handle real-world data challenges.
Proven skill in developing, debugging, and optimizing code in Python for tasks like data transformation, aggregation, and automation.
A track record of writing, optimizing, and troubleshooting SQL queries for ETL processes and data extraction.
Ability to build, test, and deploy dbt models for data transformation, version control, and documentation within a data warehouse environment.
Excellent communication skills that empower you to collaborate seamlessly with business stakeholders, translating their needs into actionable data solutions.
Who you'll work with
You will report to Pedro Pereira, our Data Engineer II
You will work closely with Laura Cissell-Wyberneit and Chris Pranger on our Data & Insights team
You will also work closely with our Engineering Team
Tools we use:
We have a pretty cool tech stack at Going, which includes Posthog, Airbyte, Airflow, dbt, Snowflake, Preset, Google Analytics, Braze, Notion, GitHub, and Slack.
Why you might love working here
The salary for this role is $99,446 + equity.
100% remote work environment, so go ahead and bring your dog to work or wear your PJ's to the office!
$500/Quarter Remote Work Stipend
$75/month Physical & Mental Wellness Stipend
Open vacation policy, with a 15 days minimum!
Comprehensive health, vision, dental, and life insurance
401(k) with a 5% match
Up to 12-weeks of paid family leave
No Meeting/Flex Fridays
Meetup stipend when you cross paths with a co-worker
Continuing education & development reimbursement
Bi-annual team retreats (In April, we went to Mexico City. In October we're headed to Vancouver!)
Challenging problems to solve and an awesome team to collaborate with every single day
‍
We want you to bring your authentic self to work every single day. We accept you for who you are and consider everyone on an equal opportunity basis without regard to ancestry; age; appearance; color; gender identity and/or expression; genetics; family or parental status; marital, civil union, or domestic partnership status; mental, physical, or sensory disability; national, social or ethnic origin; past or present military service; sexual orientation; socioeconomic status; race; religion or belief. Going is an E-Verify employer.
‍If you require a reasonable accommodation or assistance for any part of the interview and employment process, please contact us at careers@going.com and let us know the nature of your request.","$99,446 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Internet & Web Services,2015,Unknown / Non-Applicable
"Qualified Recruiter Pvt Ltd
4.5",4.5,"Atlanta, GA",Data Engineer,"We are looking for an Azure Data Engineer to be part of our data & analytics team. You will develop solutions leveraging Azure cloud platform to create a Modern Enterprise data platform. You will work with cross-functional teams to ensure data is collected, stored, processed, and analyzed in a timely, efficient, and accurate manner. You will support digital transformation journey of data and analytics team. This exciting transformation will enable new cloud technologies that will transform the way we derive value from our data assets.
Bachelor’s Degree in Computer Science or Data Analytics/engineering related streams
0 – 2 years of experience
Strong Understanding of Data Warehouse/Lakehouse, Data Mesh, Dimensional data Modelling, ETL/ELT, CDC concepts.
Knowledge of Cloud Infrastructure and services including Azure Data Factory(ADF), Azure Synapse, Azure Synapse Pipeline, Spark Notebooks, Azure Synapse Dedicated SQL Pool Warehouse ,Azure Databricks, Azure Functions, Power BI and Azure Data Lake storage
Understanding of with various data formats like relational, json, parquet, delta, streaming and others
Proficiency in SQL,T-SQL and Python/PySpark
Excellent problem-solving and analytical skills. Aptitude to adapt to new technologies
Excellent business facing and internal communication skills
Job Type: Full-time
Salary: $76,081.22 - $80,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Compensation package:
Bonus opportunities
Yearly pay
Experience level:
2 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Atlanta, GA 30312: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
Are you a US Citizen OR a Green Card Holder?
Education:
Bachelor's (Required)
Experience:
Synapse: 2 years (Required)
Work Location: In person","$78,041 /yr (est.)",201 to 500 Employees,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,2017,Unknown / Non-Applicable
"Charles Schwab
3.8",3.8,"Austin, TX",Associate - Data Engineer,"Your Opportunity

Your opportunity
This full-time role is part of a nine-month NERD (New Employee Recruitment and Development) program that blends on-the-job experience with an extensive training curriculum that covers tools, technologies, processes, and soft skills required to be successful in Schwab Technology Services. By pairing the curriculum, on-the-job experience, and a web-of-support from others, NERDs are well prepared to succeed in their role which sets the table for future opportunities at Schwab.

What you will get out of the program
Mentorship
Challenging Career Opportunities
Continuous Training and Development
Certification Opportunities
Hands-on Technology Experience
Knowledge Sharing and Presentation Opportunities
Exposure to Leadership
Community of Dedicated and Welcoming Peers

What you’ll do
As a member of the NERD program, you will be working in our Data and Rep Technology (DaRT) organization that governs the strategy and implementation of the enterprise data warehouse and emerging data platforms. You will collaborate with partners across the firm to build the next generation analytics platform and capabilities for Charles Schwab. DaRT supports executive leadership, Sales, Marketing, and Finance teams by integrating and analyzing data to help them make data-based decisions through four primary opportunities:

Data Science Frameworks
This team partners with our data scientists and business stakeholders to design intuitive data solutions and create the best-suited serving pipelines for their modeling and analysis needs. You will help drive the deployment of cross-functional applications, determine platform design and architecture, and set the vision to build and scale our machine learning and experimentation platforms.

Data Engineering
This team designs, develops, and implements enterprise data integration solutions. You will have the opportunity to partner with other developers to set the future of the Data Warehouse through exciting and challenging projects and learning and using emerging technologies.

Data Analytics
This team performs data analysis of enterprise integration solutions to transform data into actionable insights leveraging best-in-class technologies, analytics, and visualization tools.

Platform and Production Support
This team builds next-gen enterprise data platforms, manages currency upkeep of existing platform assets, and matures those investments. The core functions include platform engineering, tenant-focused governance, capacity management, software upgrades, performance optimization, administration, lifecycle management, and maintenance.

What you are good at
You enjoy problem solving
You have a hunger for knowledge
You work well with others
You are a good communicator
What you have

What you have
Undergraduate or graduate degree in Computer Science, Management Information Systems, or related discipline with a graduation date of December 2023 or earlier and/or
Workforce training certifications through coding bootcamps with a graduation date of December 2023 or earlier
Ability to start full-time with the program on January 22, 2024
Basic understanding of data modeling
Understanding of SQL development principles
Experience with algorithm design
Basic understanding of object-oriented analysis and design
Familiarity with data structures
Experience with data engineering, Extract, Transform, Load (ETL), Hadoop, MongoDB, Unix, Sqoop, HiveQL, or Pig Scripting is a plus
Inventiveness and eagerness to work with experimental technology
Demonstrated leadership potential
Passion and interest in solving problems applying innovation and experimentation
Workplace Flexibility Program
We're proud to support our employees in a working approach that allows you to bring your best self to work – whether that’s in the office or remote.
Employees will have the flexibility of a hybrid work environment, spending some time working remotely and sometimes in the office.
Employees and managers can discuss and decide what works best for them, with flexibility available based on their role, business needs, and individual circumstances.

Subject to change as Schwab is continually evaluating the current environment to best care for the safety and well-being of our employees.

Why work for us?
Own Your Tomorrow embodies everything we do! We are committed to helping our employees ignite their potential and achieve their dreams. Our employees get to play a vital role in reinventing a multi- trillion-dollar industry, creating a better, more modern way to build and manage wealth.

Benefits: A competitive and flexible package designed to empower you for today and tomorrow. We offer a competitive and flexible package designed to help you make the most of your life at work and at home—today and in the future. Explore further.

Schwab is committed to building a diverse and inclusive workplace where everyone feels valued. As an Equal Opportunity Employer, our policy is to provide equal employment opportunities to all employees and applicants without regard to any status protected by law. Please click here to see the policy. Schwab is an affirmative action employer, focused on advancing women, racial and ethnic minorities, veterans, and individuals with disabilities in the workplace. If you have a disability and require reasonable accommodations in the application process, contact Human Resources at applicantaccessibility@schwab.com or call 800-275-1281.

TD Ameritrade, a subsidiary of Charles Schwab, is an Equal Opportunity Employer. At TD Ameritrade we believe People Matter. We value diversity and believe that it goes beyond all protected classes, thoughts, ideas, and perspectives.","$79,900 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1973,$10+ billion (USD)
"Loon
3.6",3.6,"Boulder, CO","Senior Data Engineer, Chorus, X","X is Alphabet’s moonshot factory. We are a diverse group of inventors and entrepreneurs who build and launch technologies that aim to improve the lives of millions, even billions, of people. Our goal: 10x impact on the world’s most intractable problems, not just 10% improvement. We approach projects that have the aspiration and riskiness of research with the speed and ambition of a startup.
X is Alphabet’s moonshot factory. We are a diverse group of inventors and entrepreneurs who build and launch technologies that aim to improve the lives of millions, even billions, of people. Our goal: 10x impact on the world’s most intractable problems, not just 10% improvement. We approach projects that have the aspiration and riskiness of research with the speed and ambition of a startup.
About The Team:
Chorus intends to transform the way we make, move, and manage the world’s goods.
About The Role:
We are a diverse team of hardware, firmware, software, and data experts that are seeking to transform the way the world's goods are made, moved and managed. The job of our Data/ML team is to turn the raw data that flows off of our system into actionable, optimal decision making at scale for thousands of businesses.
You will be a key member of the Data Science and Machine Learning team at Chorus. You will help architect and build the data warehouse that turns raw data into important insights that are consumed by various applications (APIs, ML models, UI/UX) with various requirements (online, streaming, batch) to make our network of sensors feel like magic. In this role you will have the scope and mandate to lead the way on warehouse architecture, infrastructure and data modeling. You will work intensively with members of multiple teams to build data/ML-driven systems from end-to-end. You will help set the bar for data excellence and manage the full data life cycle, working on issues of consistency, explainability, governance, reliability, extensibility, etc.
How You Will Make 10x Impact:
Work Collaboratively with stakeholders from multiple Chorus teams. Communicate effectively to ensure your platform has a huge impact. Contribute positively to team/org culture. Mentor team members to increase data expertise around the org.
Design and implement an analytics data architecture that effectively serves a variety of consumers (ML models, Alerts, Reports, APIs, Pub-Sub).
Managing the end-to-end data lifecycle of our OLAP data warehouse (ingest, storage, transformation, serving)
Instituting important data quality practices (validation, monitoring, alerting, governance)
Building solid foundations that are flexible to change (schema evolution, data versioning)
Innovate and experiment with new technologies to unlock more data magic.
What You Should Have:
We are looking for a motivated and versatile Senior Data Engineer who is keen to build the data-driven systems that will turn raw data into actionable insights.
Masters Degree in CS or equivalent practical experience.
Experience working cross functionally in dynamic environments (startups etc.).
4+ years of experience building data-intensive systems.
Expert knowledge of SQL, and comfortable with general languages (Python, Java).
Experience managing, administering, operating databases.
Experience building and maintaining data pipelines (ETL, ELT).
It would be great if you also had these:
Experience leading/managing cross functional projects
Experience building systems in the Cloud (AWS, Azure, we use GCP).
Experience designing/managing data architectures and models.
Experience building systems that consume and serve data with a variety of requirements.
Basic familiarity with ML-driven systems and design patterns.
The US base salary range for this full-time position is $140,000 - $216,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your location during the hiring process.
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.
At X, we don't just accept difference - we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. We are proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.
If you have a disability or special need that requires accommodation, please contact us at: x-accommodation-request@x.team.","$124,356 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Internet & Web Services,#N/A,Unknown / Non-Applicable
"Phusion Projects
4.4",4.4,Remote,Data Engineer,"Description:
Phusion Projects: Redefining the alcoholic beverage arena since 2005, Phusion Projects casts a global footprint across 40+ countries. Our portfolio? Iconic brands echoing innovation and inspiration.
Our Culture: At Phusion, we believe in the power of insights. Dive deep, and what emerges isn't just data, but stories - compelling narratives that drive growth and impact. With our eyes set on standing out among a vast network of suppliers, we aim for stories that resonate.
Role: Data Engineer
What You'll Do:
Architect & Innovate: Design, construct, and evolve scalable pipelines, ensuring our analytics reach their zenith.
Streamline with Azure: Specialize in developing ELT processes within Azure, ensuring data is efficiently transformed and loaded to its destination.
Collaborate: Act as a nexus between business units, ensuring data demands are not only met but surpassed.
Safeguard & Standardize: Ensure robust data architecture that aligns with compliance norms, while championing best practices in database and data processing management.
Stay Ahead: Immerse yourself in emerging technologies, ensuring Phusion remains at the cutting edge of data engineering.
Requirements:
Who You Are:
Azure Virtuoso: You’ve hands-on experience with Azure ELT processes and related Azure Data Services.
Tech Maestro: Beyond Azure, you're familiar with tools like Snowflake, BigQuery, Kafka, and other cloud solutions like AWS or GCP.
Scripting Sage: Fluent in SQL, with proficiency in scripting languages like Python or Java.
Detail Dynamo: Your work is defined by precision and efficiency, coupled with innovative flare.
Collaborative Catalyst: A synergistic force who believes in collective growth and shared success.
Join the Journey: At Phusion Projects, insights aren't just numbers; they're the narrative. Be the storyteller, shape the narrative, drive the impact. Ready for a story like no other?",#N/A,51 to 200 Employees,Company - Private,Manufacturing,Food & Beverage Manufacturing,2005,$100 to $500 million (USD)
"Intone Networks
4.3",4.3,Remote,data Engineer,"- Bachelor's degree (Master's preferred) in Computer Science, Data Science, Engineering, Information Systems, Mathematics, Statistics, or related field. Equivalent experience will be considered in lieu of a degree. - 5+ years of experience in a technical role engineering data and/or analytics solutions. - Ability to produce high quality documentation of business and system requirements, system design, data architecture, and training materials. - Expert data skills, including complex queries, performance tuning, expertise in a variety of approaches (e.g., relational, dimensional, unstructured). -5+ years of experience in Snowflake, Oracle, and SQL Server data platforms -3-5 years of experience in cloud technologies – primarily AWS; highly skilled in developing and maintaining cloud-based solutions. - Highly skilled in building data and semantic layers utilizing enterprise analytic tools such as Tableau, MicroStrategy or PowerBI. Essential Duties and Responsibilities: - Responsible for delivery of business intelligence (BI) information to the entire organization, including the assessment of business requirements, collection and identification of technical specifications, and the subsequent development of technology solutions. - Develop and maintain data integration solutions (including ETL/ELT design and architecture), semantic layer objects, presentation objects, reports, and dashboards for delivery of analytic solutions. - Translate business needs and requirements to system requirements, data mapping, and data and semantic model design. Produce and document standard and best practices. - Analyze requirements and apply architectural and engineering concepts to develop solutions that meet business needs while maintaining sustainability objectives, including scalability, maintainability, security, reliability, extensibility, flexibility, availability, and manageability. - Provide training and consulting for various technical and non-technical internal teams. - Produce work breakdowns and task estimates (scoping and tracking activities). - Provide level 1-3 support for production systems and participate in on-call rotations, providing occasional evening/weekend/holiday support for projects",#N/A,201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,$5 to $25 million (USD)
"Serenity Healthcare
2.8",2.8,"Lehi, UT",Junior Data Engineer,"Junior Data Engineer
Serenity Healthcare is hiring a Junior Data Engineer for our Lehi, UT headquarters. While previous ETL experience is preferred, we are open to exceptional entry-level talent for this role.
We intend to provide on the job training in data-skills: SQL, BI (PowerBI), ETL (SSIS), Warehousing (SQL Stored Procedures), Exploratory Data Analysis, etc. It’s our intention to train you in Microsoft’s new tool: PowerApps.
Desired skill sets:
Must be a quick learner
SSIS experience strongly preferred
Skills used in the role:
SQL 20%
SSIS 40%
PowerApps 40%
Day-to-day work description:
The Junior Data Engineer will be responsible for keeping the data flowing, building new data pipelines, and creating business applications using MS-PowerApps. You’ll need to be comfortable with SQL, SQL Server, and SSIS. You’ll be reading API documentation to establish new ETL flows, as well as automating report delivery.
Job Fit:
Capable of “Deep Work”
Problem Solver
Reliable and consistent
Attention to detail
What We Offer to You:
Competitive pay (DOE), including additional target compensation
Opportunity to work and grow your career in a fast-paced environment
Medical, Dental, Vision Insurance (90% coverage for you and codependents)
Life Insurance
Flexible spending account
Paid time off
Vision insurance
401k
Open and friendly, professional office environment
Who We Are:
We have helped thousands of patients take back their lives from mental illness with specialized clinical expertise and the foremost cutting-edge technology available in mental health today. Serenity’s approach to treating mental illnesses is to offer holistic options and treat the whole person by providing an atmosphere of positivity, support, and healing in an outpatient setting.
We believe people should live their best lives, and mental health is a substantial segment of total well-being. We bring the same passion we have for improving our patient’s lives to providing a work experience that will help you do your best work, enjoy the time you invest at work, and succeed in life outside of work. We take our people and culture seriously and make it a priority to invest in both.
Serenity Mental Health Centers is an equal opportunity employer. This position is contingent on successfully completing a criminal background check and drug screen upon hire.","$89,950 /yr (est.)",201 to 500 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2017,Unknown / Non-Applicable
EDR Technology,#N/A,"Fairfax, VA",Data Engineer,"Data Engineer
Location: Fairfax, VA
Primary Responsibilities
Take responsibility for the delivery of Data Migration for multiple systems: analysis, design, implementation, testing, validation, and acceptance.
Assembling large, complex sets of data that meet non-functional and functional business requirements.
Communicate with key stakeholders to understand the data migration needs and requirements and troubleshoot data inconsistencies that might arise.
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies
Working with stakeholders including data, design, product, and executive teams and assisting them with data-related technical issues
Develop logical and conceptual data models.
Develop data migration strategies and plans.
Develop scripts to extract, transform and load data.
Perform data analysis and cleansing activities to ensure data quality, as needed.
Troubleshoot and resolve issues related to data migration.
Participate in data migration testing including data-level validation and application-level validation.
Document data migration processes, procedures, and outcome.
Required Skills and Experience
8+ years of work experience with a combination of data modeling, ETL, database operations, data services, data analytics, ETL and data migration tools.
5+ years of work experience with coding in one of mainstream programming languages: Python, Java, Node.js etc.
Experience in design and development of ETL process using AWS ETL tools like AWS DMS, Glue, Athena, AWS Aurora PostgreSQL, etc.
Experience in designing data migration solutions, archival processes, and reconciliation.
Experience with data quality checks, data de-duplication and data validation processes.
Perform data migration audit, reconciliation, and exception reporting.
Experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
Experience operating production workloads on Oracle/PostgreSQL (preferred)
Solid understanding of data elements and their relationships between the source and target systems
Experience working on real-time data and streaming applications.
Experience with NoSQL implementation (DynamoDB, Mongo, Cassandra)
Clearance – Ability to obtain and maintain public trust. Must be a US Citizen
Job Type: Full-time
Pay: $100,000.00 - $110,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Health savings account
Paid time off
Retirement plan
Vision insurance
Compensation package:
Yearly pay
Experience level:
8 years
Schedule:
8 hour shift
Application Question(s):
Are you a US Citizen? (REQUIRED) if you are not, please do not apply.
Are you willing and able to obtain Security Clearance?
Are you willing and able to commute to the position location on a daily basis?
Education:
Bachelor's (Preferred)
Experience:
ETL: 8 years (Preferred)
Data Modeling: 8 years (Preferred)
Python or Java: 5 years (Preferred)
AWS ETL Tools: 3 years (Preferred)
Work Location: In person","$105,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
Qloo,#N/A,"New York, NY",Data Engineer,"About Us:
At Qloo, we are dedicated to harnessing the power of data and machine learning to drive innovation and solve complex problems. Our team is composed of top-notch engineers and scientists who are passionate about creating data-driven solutions that make a lasting impact. We are currently seeking an experienced Data Engineer to join our growing team and help us advance our mission.

Job Description:
As a Data Engineer at Qloo, you are responsible for architecting, developing, and improving our automated data pipelines. You understand the intricacies of data quality and have a keen eye for catching and rectifying quality issues in the underlying data. Your role emphasizes designing and optimizing data processing systems for maximum performance, efficiency, and accuracy.

The ideal candidate has a robust background in data engineering, a solid grasp of data processing technologies like Spark and PySpark, and a passion for ensuring the integrity and accuracy of the data that drives our solutions.

Responsibilities:
+ Design, develop, and maintain automated data pipelines using Python, Spark, PySpark, and related technologies.
+ Ensure data quality by being proactive in catching and rectifying quality issues in underlying data.
+ Collaborate with data scientists and other engineers to define data requirements and structures.
+ Write unit tests and conduct system testing to ensure the reliability and integrity of data.
+ Optimize data pipelines for maximum speed, scalability, and accuracy.
+ Stay up to date with emerging trends and technologies in data engineering, data processing, distributed computing, and data quality assurance.

Qualifications:
+ Bachelor's degree in computer science, software engineering, or a related field.
+ Experience with Spark, PySpark, or other data processing frameworks.
+ Experience with SQL and NoSQL database technologies.
+ Experience with automating data processing through Python libraries like Airflow
+ Strong problem-solving and analytical skills with keen attention to detail.
+ Experience with AWS or other cloud platforms.
+ Ability to manage multiple projects simultaneously and meet tight deadlines.

We Offer:
+ Competitive salary and benefits package, including health insurance, retirement plan, and paid time off.
+ Opportunities for professional development and growth.
+ A collaborative and supportive work environment: Experience a culture that fosters teamwork, open communication, and mutual respect, where your ideas are valued and your contributions recognized.
+ Work-life balance: We prioritize a healthy work-life balance, offering flexible work arrangements, remote and hybrid work options, and encouraging employees to maintain a well-rounded lifestyle.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Inclusively
5.0",5.0,"San Francisco, CA",Senior Data Engineer,"Inclusively is partnering with one of the largest transportation networks to hire a Senior Data Engineer.
ABOUT INCLUSIVELY:
Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD). Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability.
The expected range of pay for this position in the San Francisco Bay Area is $162,000 - $180,000.
Responsibilities:
Owner of the core company data pipeline, responsible for scaling up data processing flow to meet our rapid data growth.
Evolve data model and data schema based on business and engineering needs
Implement systems tracking data quality and consistency
Develop tools supporting self-service data pipeline management (ETL)
SQL and MapReduce job tuning to improve data processing performance
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge
Unblock, support and communicate with internal & external partners to achieve results
Experience:
5+ years of relevant professional experience
Strong experience with Spark
Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet)
Strong skills in a scripting language (Python, Ruby, Bash)
Good understanding of SQL Engine and able to conduct advanced performance tuning
Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)
1+ years of experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)
Comfortable working directly with data analytics to bridge our business goals with data engineering
Job Type: Full-time
Pay: $162,000.00 - $180,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Parental leave
Vision insurance
Experience level:
5 years
Schedule:
Monday to Friday
Work Location: In person","$171,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Snapchat
4.0",4.0,"Los Angeles, CA",Data Engineer,"Snap Inc
is a technology company. We believe the camera presents the greatest opportunity to improve the way people live and communicate. Snap contributes to human progress by empowering people to express themselves, live in the moment, learn about the world, and have fun together. The Company’s three core products are
Snapchat
, a visual messaging app that enhances your relationships with friends, family, and the world;
Lens Studio
, an augmented reality platform that powers AR across Snapchat and other services; and its AR glasses,
Spectacles
.
Snapchat
is a camera and messaging app that connects people to their friends and the world. Every day around the globe, millions of people use Snapchat to communicate with friends, build relationships, play, and learn. No matter where you are or how you express yourself, it’s always the fastest way to share a moment!
We’re looking for a Data Engineer to join our Core Growth Team!
What you’ll do:
Work closely with stakeholders in engineering, finance, sales, marketing, strategy, and governance to make high quality datasets available to consumers in a timely manner
Develop data pipelines adhering with privacy and governance principles
Become familiar with our data consumption portals and their capabilities
Build expertise and ownership of data quality for supported domains
Build tooling and implement systems to overcome limitations of the data consumption portals when appropriate
Drive adoption of the data sets you’ve produced
Knowledge, Skills & Abilities:
Experience in building data pipelines to serve reporting needs
Experience owning all or part of a team roadmap
Ability to prioritize requests from multiple stakeholders in disparate domains
Ability to effectively communicate complex projects to non-technical stakeholders

Minimum Qualifications:
BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ year experience in SQL or similar languages
3+ years development experience in at least one object-oriented or scripting language (Python, Java, Scala, etc)
Preferred Qualifications:
Hands on experience with Google BigQuery
Experience in version control systems such as Git
Data architecture and warehousing experience
Experience leading a small team of data or software engineers
Experience with Airflow
Experience in ETL / Data application development
Compensation
In the United States, work locations are assigned a pay zone which determines the salary range for the position. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These pay zones may be modified in the future.
Zone A (CA, WA, NYC)
: The base salary range for this position is $165,,000 - 230,000 annually
Zone B
: The base salary range for this position is $157,000 - 219,000 annually
Zone C
: The base salary range for this position is $140,000 - $196,000 annually
This position is eligible for equity in the form of RSUs
""Default Together"" Policy at Snap. At Snap Inc. we believe that being together in person helps us build our culture faster, reinforce our values, and serve our community, customers and partners better through dynamic collaboration. To reflect this, we practice a “default together” approach and expect our team members to work in an office at least 80% of the time (an average of 4 days per week).
If you are not based in the same location(s) listed for this role and are open to relocation, we encourage you to apply to take advantage of our generous relocation policy.

At Snap, we believe that having a team of diverse backgrounds and voices working together will enable us to create innovative products that improve the way people live and communicate. Snap is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets. If you have a disability or special need that requires accommodation, please don’t be shy and contact us at
accommodations-ext@snap.com
.
Our Benefits
: Snap Inc. is its own community, so we’ve got your back! We do our best to make sure you and your loved ones have everything you need to be happy and healthy, on your own terms. Our benefits are built around your needs and include paid parental leave, comprehensive medical coverage, emotional and mental health support programs, and compensation packages that let you share in Snap’s long-term success!","$168,000 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Computer Hardware Development,2011,Unknown / Non-Applicable
"MoveDocs
1.3",1.3,Remote,Data Engineer,"The Data Engineer will be responsible for delivering data warehouse, ETL, and reporting solutions for our business users. The qualified candidate will play a key role in solving business problems by building strong relationships with stakeholders and end users, and establishing best practices that produce high-quality data products and services. The successful candidate will possess a continuous learning mindset, be self-motivated, be able to work both autonomously and collaboratively with a team, and enjoy working in a fast-paced, high-volume environment. This position also may require occasional after-hours support.
This position will report to the Director, Software Engineering and is based in our Las Vegas, NV headquarters. Strong Remote candidates will also be considered.
Responsibilities:
Responsible for the conception, design, development, and deployment of scalable, maintainable data architecture and high-quality data models.
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data and report delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other technologies.
Gather requirements and business process knowledge to transform the data in a way that’s geared towards the needs of end-users.
Work with the business in designing and delivering correct, high-quality data.
Work with data and analytics experts to strive for greater functionality in our data systems.
Create data tools for analytics team members that assist them in providing actionable insights into financial performance, operational efficiency, and other key business metrics.
Investigate data to identify potential issues within ETL pipelines, notify end-users, and propose adequate solutions.
Perform basic database administration tasks when needed.
Perform other duties or tasks as assigned.
Requirements:
5-7 years of experience in a Data Engineer role.
Strong teaming skills, professional attitude, enthusiastic, collaborative, and approachable.
Analytical, inquisitive, and innovative with excellent attention to detail.
Creative problem-solving and troubleshooting skills.
Excellent written and verbal communication skills.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Strong MS-SQL background is required.
Broad understanding of Data Modeling, OLAP, SQL and ETL.
Practical experience with one or more ETL tools, such as SSIS.
Experience building and optimizing data pipelines, architectures, and data sets.
Database administration experience preferred.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Knowledgeable of Source Control and Project Management tools like Bitbucket, JIRA, and Azure DevOps.
Familiarity with DevOps best practices and automation of documentation, testing, build, deployment, configuration, and monitoring.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Azure PaaS experience is a plus.
Must be authorized to work in the U.S
Benefits:
MoveDocs offers competitive compensation, and benefits that include medical, dental, vision and life insurance plans, plus 401k with company match and paid time off.
About Us:
MoveDocs is a cloud-based fintech company designed to be an end-to-end solution for personal injury law firms and healthcare providers. We’re fast-growing, and profitable. Founded in 2003, we’re focused on helping uninsured and under-insured patients gain access to healthcare they need but cannot afford. We have relationships with hundreds of medical providers across the country and we’re just getting started. We are proud of our mission and passionate about applying technology to the challenge of making healthcare more accessible.
Job Type: Full-time
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Employee discount
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Referral program
Vision insurance
Compensation package:
Performance bonus
Yearly pay
Experience level:
5 years
Schedule:
Day shift
Monday to Friday
Experience:
C++: 3 years (Preferred)
SQL: 3 years (Required)
Work Location: Remote",#N/A,Unknown,Company - Public,Information Technology,Software Development,#N/A,Unknown / Non-Applicable
"R1 RCM, Inc.
3.4",3.4,Remote,Senior Data Engineer,"Sr. Data Engineer, you will design, develop, and maintain data processing solutions in an Azure Databricks environment. You will collaborate with cross-functional teams to build scalable and efficient data pipelines, perform data analysis, and contribute to the overall architecture of our data infrastructure.
Responsibilities:
Design, develop, and optimize data pipelines using Azure Databricks and Scala.
Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and implement effective solutions.
Perform data analysis, modeling, and transformation to ensure data quality and integrity.
Develop and maintain data engineering best practices, standards, and guidelines.
Troubleshoot and resolve data processing, performance, and scalability issues.
Stay up-to-date with the latest trends and advancements in data engineering and cloud technologies.
Mentor and provide technical guidance to junior members of the team.
Requirements:
Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field.
Proven experience working with Azure Databricks for data engineering tasks.
Strong proficiency in Scala programming language.
Solid understanding of data modeling, data warehousing, and ETL concepts.
Experience with .NET development is highly desirable.
Familiarity with Angular or other front-end frameworks would be an added benefit.
Strong problem-solving and analytical skills.
Excellent communication and collaboration abilities.
Ability to work independently and in a team-oriented, agile environment.
Azure certifications related to data engineering would be a plus.
Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests.

Our associates are given valuable opportunities to contribute, to innovate and create meaningful work that makes an impact in the communities we serve around the world. We also offer a culture of excellence that drives customer success and improves patient care. We believe in giving back to the community and offer a competitive benefits package including:
Comprehensive Medical, Dental, Vision & RX Coverage
Paid Time Off, Volunteer Time & Holidays
401K with Company Match
Company-Paid Life Insurance, Short-Term Disability & Long-Term Disability
Tuition Reimbursement
Parental Leave
R1 RCM Inc. (“the Company”) is dedicated to the fundamentals of equal employment opportunity. The Company’s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person’s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.
If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.
CA PRIVACY NOTICE: California resident job applicants can learn more about their privacy rights California Consent",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2003,Unknown / Non-Applicable
"Smart IMS
4.2",4.2,"Chicago, IL",Sr. Data Engineer,"Position: Sr. Data Engineer (3 Roles)

Location: Chicago, IL (100% REMOTE)

Duration: 9-12 Months

100% REMOTE ROLES ……

Client Signals application AWS to Azure – Client is migrating an application from AWS to Azure, they are looking for a partner to start ASAP to carry out this migration.

We are in search of an experienced Sr. Data Engineer with a rich background in data migration projects. The ideal candidate should possess advanced skills in Azure-based technologies and be capable of leading and managing complex migration projects.

Primary Responsibilities:
Lead and architect data migration projects, ensuring data accuracy and integrity.

Design and develop data solutions using Azure, Azure Data Factory (ADF), and Synapse Data Warehouse.

Implement data processes using Azure Functions and Python.

Utilize Databricks and Spark for data processing tasks.

Collaborate closely with other data professionals and stakeholders to define requirements and deliver optimal solutions.

Mentor junior engineers and ensure adherence to best practices in all data projects.

Knowledge in PostGreSQL and AWS is preferred, but not must.

Knowledge in AWS to Azure migration is preferred, but not must.

Skills & Qualifications:
A Bachelor's/Master's degree in Computer Science, Data Science, or a related field.

Strong experience in Azure, ADF, Synapse Data Warehouse, Azure Functions, Python, Databricks, and Spark.

Proven track record of managing and executing data migration projects.

Exceptional analytical, problem-solving, and communication skills.","$110,348 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,1994,$100 to $500 million (USD)
"Seven Hills Group Technologies inc.
3.0",3.0,"Reston, VA",AWS Data Engineer,"Project Location: Reston, VA
Please share Only 10+yrs Profile.
The need is to have a strong developer who has good working experience in AWS services such as Lambda, EMR, Step Functions, Glue, Athena and Python for data processing pipelines.
Job Description :
Advanced knowledge of AWS Services/Architecture
Experience in AWS Compute such as EC2, Lambda, Beanstalk, Batch or ECS
Experience with AWS Storage services such as: S3, EFS, Glacier.
Experience in AWS Management and Governance suite of products such as CloudTrail, CloudWatch
Experience in AWS Analytics such as Athena, EMR, Glue, Redshift, Kinesis
Strong knowledge in Python object-oriented programming
Strong experience with AWS Database services such as: RDS, DynamoDB
Experience using APIs for developing or programming software
Experience using AWS Application Integration Services such as: Simple Notification Service (SNS), Simple Queue Service (SQS), Step Functions.
Experience with AWS Developer tools such as: CodeDeploy, CodePipeline
Experience with JSON
Strong experience with SQL
Experience with enterprise data lakes, data warehouses, data marts, and big data.
Strong experience with data migration, cloud migration, and ETL processes.
Thanks and Regards
Nick Awasth
Job Type: Contract
Schedule:
8 hour shift
Experience:
AWS: 4 years (Preferred)
Python: 1 year (Preferred)
Total: 10 years (Preferred)
Work Location: In person","$106,102 /yr (est.)",Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Sanametrix
3.8",3.8,Remote,Data Engineer,"***US Citzenship is Required******
Sanametrix, Inc. is a fast-growing small business headquartered in Arlington, VA. We are dedicated to providing federal agencies with legendary customer service and focused solutions for their business and technology needs.
This role is responsible for building data pipelines for transferring data from source systems (virtual machines, Microsoft SQL Server) into AWS Cloud using AWS Native Tools. This resource has strong data modeling and scripting experience and has a strong knowledge of AWS Data Services.
Responsibilities:
Perform data processing, algorithm / structures, pipeline orchestration, data quality, governance, discovery
Work with structured and unstructured data, blob data
Develop and work with APIs
Collect and organize data using data warehousing technique and file storage technologies • Perform ELT and ETL processes
Gather data requirements
Develop and maintain scalable data pipelines and build out new API integrations to support continuing increases in data volume and complexity.
Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Implement processes and systems to monitor data quality, to ensure production data accuracy, and ensure key stakeholder and business process access.
Write unit/integration tests, contribute to engineering wiki, and documents.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Work closely with a team of front-end and back-end engineers, product managers, and analysts.
Design data integrations and data quality framework based on established requirements.
Qualifications & Skills:
Scripting • SQL • Python • Spark • Linux / shell scripting
Services / Tools (six or more)
S3
Lambda
Redshift
Lake Formation
Glue ETL
Kinesis
DMS
Glue catalog/Crawlers
Git
Jira
Airflow /Orchestration
Education, Experience, and Licensing Requirements:
BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL or NoSQL experience
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building, and maintaining data processing systems
AWS Certified is preferred
Job Type: Full-time
Pay: $110,656.51 - $120,080.95 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Tuition reimbursement
Compensation package:
Yearly pay
Experience level:
4 years
Schedule:
8 hour shift
Day shift
Monday to Friday
Experience:
Informatica: 4 years (Preferred)
SQL: 4 years (Required)
Data warehouse: 4 years (Preferred)
Work Location: Remote","$115,369 /yr (est.)",Unknown,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
Energy Solutions - USA,#N/A,Remote,Data Engineer I,"Interested in joining a growing company where you will work with talented colleagues, enhance a supportive and energetic culture, and be part of the climate solution? At Energy Solutions, we focus on the big impacts. And we believe that market-based programs can be a powerful force to deliver large-scale energy, carbon, and water-use savings. For 28 years, we've harnessed that power to offer proven, performance-based solutions for our utility, government, and institutional customers.
Energy Solutions (ES) is currently seeking a full-time Data Engineer I to join our Business Operations Team. The Data Engineer role is part of the Business Operations Team and will work on critical projects such as the Corporate Operational Data Warehouse (CODW) and the new ERP system. The CODW project is one of ES's strategic goals, to build and maintain a system that enables ES to centralize, integrate, and analyze internal data from various sources. The goal is to provide a single source of truth for ES internal data and enable data-driven decision-making across the organization. This role will potentially lead the design and implementation of the infrastructure for internal reporting needs, driving operational efficiencies and helping our company's transition to operating internationally with 1000+ employees.
Energy Solutions has a remote-friendly work environment for staff located throughout the United States. We also have offices in Oakland and Orange, California, Boston, Massachusetts, New York, and Chicago, IL, for those that wish to work from one of our offices.

Daily responsibilities include but are not limited to:
Collaborate with stakeholders to understand data requirements and develop data-driven solutions that support business goals
Analyze data sources and pipelines needed for the CODW project
Design and implement scalable data pipelines, ETL processes, and data integration solutions for the CODW project using Python, SQL, and AWS technologies
Develop and maintain a data warehouse and optimize data storage, processing, and retrieval
Build schema, populate the database, and automate reporting
Document and maintain technical specifications, ETL processes, data mappings, and dictionaries
Support the Data Science Center of Excellence (DSCOE) with other data engineering needs

Minimum Qualifications:
BS/BA in Computer Science, Physics/Engineering, Business or Mathematics
Experience in building ETL data pipelines, real-time pipelines are a plus
Strong programming skills in Python and SQL
Minimum 2 years of data warehouse development and strong fundamentals in dimensional data modeling
Minimum 2 years of experience creating SQL queries and ETL design, implementation, and maintenance
Minimum 2 years of experience developing data pipelines using Python
Minimum 2 years of experience with AWS, AWS Redshift, AWS Data Engineering and ML Ops tools and services (ie: S3, Redshift, RDS)
Proven ability to aggregate, normalize, munge, analyze, and summarize value from disparate datasets
Strong oral, written, and interpersonal communication skills
High degree of accuracy and attention to detail
Ability to establish priorities, work independently with minimum supervision
Preferred Qualifications:
Ability to manage and communicate data warehouse plans to a non-technical audience
Expertise in cloud services architecting and designing secure AWS environments
Experience using BI tools like Tableau and Looker
Experienced in analyzing and troubleshooting data quality issues
Self-driven, highly motivated, and able to learn quickly
Familiarity with large data sets, cloud-based development and deployment, open-source practices and frameworks, and intelligent applications is desirable
Proven success in migrating data from legacy systems

Salary DOE: $90k - $120k / Annually
Compensation is commensurate with experience and includes a generous retirement package. Energy Solutions provides an excellent benefits package including medical, dental and vision insurance, other pre-tax contribution plans and an Employee Stock Ownership Plan (ESOP).
To see this and our other open positions, please visit https://energy-solution.com/company/careers/.
We encourage candidates from diverse backgrounds to apply. For more information about Energy Solutions and our Diversity, Equity and Inclusion efforts, please visit us on our website at www.energy-solution.com.
Background Check Information
Information will be requested to perform the compulsory background check. A drug screen and authorization to work in the U.S. indefinitely are preconditions of employment. Energy Solutions is an equal opportunity employer.
Reasonable Accommodations
Energy Solutions is committed to providing access and reasonable accommodation for individuals with disabilities. If you require an accommodation in completing this application, interviewing, and/or completing any pre-employment testing, or otherwise participating in the employee selection process, please email accommodation@energy-solution.com.
Privacy Notice for Job Applicants","$105,000 /yr (est.)",51 to 200 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,2018,Unknown / Non-Applicable
"Division of Information Technology - NYC Department of Health and Mental Hygiene
3.2",3.2,"Long Island City, NY",Data Engineer,"The New York City Department of Health and Mental Hygiene (DOHMH) is the nation's leading public health agency protecting and promoting health of all New Yorkers. Our 7,000-plus team members bring an extraordinary array of languages, cultures, and experiences to bear on the work of public health. Our diversity fuels creativity because all perspectives are heard and valued. DOHMH aims to improve the health outcomes of all New Yorkers by centering persistent racial inequities and promotion of social justice at the core of its work.
The Division of Information Technology aims to align technology solutions with the DOHMH mission by prioritizing resource use and deploying innovations that facilitate the agency’s day-to-day activities and enhance staff productivity and efficiency. Our goal is to provide users with a reliable, stable, and safe computing environment, through the collaboration of the Bureau of Technology Strategy & Project Management provides business analysis and IT project management services to define and deliver IT solutions that meet all program needs.
**This a grant-funded W-2 position with full employment benefits that expires 6/30/2025 (possibility for extension) hired through Public Health Solutions and will be assigned to NYC DOHMH. Only those with authorization to work in the U.S. without sponsorship should apply. Remote or hybrid option available. Professional references are required. **
The agency is seeking a Data Engineer (Azure, SQL, Python) to help in the infrastructure, process, and procedures to create “data lakes” in the cloud for large amounts of public health data including but not limited to syndromic surveillance, electronic laboratory and case reporting, notifiable diseases, vital records, mental health, maternal mortality, chronic diseases, as well as agency operational data such as finance, human resources, emergency operations, and information technology data. This data will be made available to analysts across DOHMH to consume and process in analytic platforms such as R, Python, SAS and visualize them in tools like Tableau, Power BI, Data Wrapper. In addition, the data can be processed with machine learning algorithms to help make more informed policy and operational decisions.
Job Duties:
Engineer data pipelines using a variety of technologies including Azure Synapse, SQL, SSIS, Python to extract, transform and load data.
Load and transform data from external sources and partners in a variety of different structured and unstructured file formats as well as internal on-premises data and applications primarily in SQL databases and CSV file formats.
Process public health data requests following applicable procedures and document changes in an electronic repository.
Apply technical knowledge to architect solutions that meet business needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics and AI technologies where appropriate (e.g., Azure ML, ML Server, BOT framework, Cognitive Services, Big Data, Data Lake, Azure Databricks, etc.).
Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability, and reliability upon deployment
Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates.
Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.
For senior data engineers, supervisor or mentor junior data engineer and analysts.
Qualifications and Requirements:
5+years of experience with Azure data platform including Azure SQL, Azure Data Factory, Azure Databricks, Azure SQL Data Warehouse (Synapse Analytics), Azure Data Lake Storage, Azure Cosmos DB, SQL Server, SSIS, SSRS, etc.
Strong Object relational mapping experience with UML modeling and OO modeling.
Experience with T-SQL, SSIS, Power BI and Azure Analysis Services
Experience with developing data pipelines using python.
Strong problem solving and analytical skills.
Passion for public health and solving problems and creating new insights through data.
Experience working with Healthcare data and proven track of implementation experience in EDI data formats.
Experience in job roles involving metadata management, relational dimensional modeling and big data solution approaches with native Azure Data Platform tools or 1st party services.
Excellent communication, presentation skills with the right attitude towards problem solving in diverse teams.
Strong aptitude and technical skills with conceptual strength in logical solutions driven towards balanced optimal considerations.
Solid knowledge in SQL, security standards, BI tools, ETL tools and Microsoft Azure specific technologies.
Certifications in Azure, data modeling and metadata management.
Ability to use BI tools like Power BI to represent insights and other presentation techniques.
Job Type: Full-time
Pay: $100,000.00 - $130,000.00 per year
Benefits:
Health insurance
Schedule:
8 hour shift
Work Location: In person","$115,000 /yr (est.)",Unknown,Government,Government & Public Administration,State & Regional Agencies,#N/A,Unknown / Non-Applicable
Fontainebleau Las Vegas,#N/A,"Las Vegas, NV",Data Engineer,"POSITION OVERVIEW
The Data Engineer will be responsible for developing, implementing, and managing the Company’s data solutions on the Amazon Web Services (AWS) platform. This position will play a vital role in designing and building scalable data pipelines, optimizing data workflows, and ensuring the availability and integrity of our data infrastructure.
ESSENTIAL DUTIES AND RESPONSIBILITIES
The following and other duties may be assigned as necessary:
Design, develop, and maintain robust and scalable data pipelines on the AWS platform using services such as AWS Glue, AWS Lambda, and AWS Step Functions
Collaborate with data architects and business stakeholders to understand data requirements and translate them into technical specifications and data engineering solutions
Implement data ingestion, transformation, and integration processes to extract data from various sources and load it into data lakes, data warehouses, or other target systems
Develop and optimize data workflows, ETL/ELT processes, and data integration solutions to ensure efficient data processing and reliable data delivery
Monitor and troubleshoot data pipelines to ensure data quality, integrity, and optimal performance
Implement and maintain data governance practices, including data lineage, data quality checks, and data cataloging
Work closely with data scientists, analysts, and other stakeholders to provide them with clean, reliable, and accessible data for their analytics and reporting needs
Collaborate with cross-functional teams to ensure seamless integration of data engineering solutions with other systems and applications
Stay up to date with the latest AWS services and technologies related to data engineering and propose their adoption to enhance our data capabilities
Continuously identify and implement opportunities for automation, optimization, and streamlining of data engineering processes
Temporary or permanent duties and responsibilities may be added to or modified as deemed necessary
QUALIFICATION REQUIREMENTS
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Must be at least 21 years of age.
Bachelor’s degree in computer science or related field, or equivalent work experience and/or equivalent combination of education and experience
At least two (2) years in data engineering, with a demonstrated track record of deploying and supporting more complex solutions
Proven experience as a Data Engineer with a strong focus on AWS technologies and services
Proficiency in AWS services such as Glue, Lambda, Step Functions, S3, Redshift, and Kinesis
Strong programming skills in languages such as Python, Scala, or Java
Experience with data modeling, ETL/ELT processes, and data integration techniques and tools
Familiarity with SQL and NoSQL databases
Solid understanding of data warehousing concepts and best practices
Knowledge of data governance, data quality, and data security principles
Experience with data orchestration and workflow management tools such as Apache Airflow or AWS Data Pipeline
Excellent problem-solving and analytical abilities
Strong communication skills and the ability to collaborate effectively with both technical and non-technical stakeholders
Strong organizational skills and attention to detail with the ability to set clear priorities in a fast-paced environment
Must be willing and able to work a flexible schedule to include holidays, nights, and weekends
Work in a fast-paced, busy, and somewhat stressful environment
SUPERVISORY RESPONSIBILITIES
This position does not have supervisory responsibilities.
DIVERSITY COMMITMENT
Fontainebleau Las Vegas is committed to ensuring an inclusive space and sense of belonging for our Members. We believe our workforce should reflect the vast diversity of the communities we serve, and that diverse voices should be intentionally integrated into our work. We foster a culture of difference and diversity of identity, experience, and perspective, while actively striving for inclusive behaviors across our Company. By promoting these values and continuously pushing for better, we aim to create a positive work environment that encourages equality, inclusion, empowerment, and respect.
CERTIFICATES, LICENSES, REGISTRATIONS
Member must be able to qualify for licenses and permits required by federal, state, and local regulations.
LANGUAGE SKILLS
Ability to read and interpret documents in English, such as safety rules, operating and maintenance instructions, and procedure manuals. Ability to read and communicate verbally in English. Written communication skills in English may also be required.
REASONING ABILITY
Ability to apply commonsense understanding to carry out instructions furnished in written, oral, or diagram form. Ability to deal with problems involving several concrete variables in standardized situations.
PHYSICAL DEMANDS
The physical demands described here are representative of those that must be met by a Member to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the Member is regularly required to stand and use hands and fingers to handle or utilize objects, tools, or controls. The Member frequently is required to reach with hands and arms and talk or hear. Specific vision abilities required by this job include close vision and peripheral vision.
The Member must regularly lift and/or move up to 10 pounds, frequently lift and/or move up to 25 pounds, and occasionally lift and/or move up to 50 pounds, and must have the ability to push, pull, reach, bend, twist, stoop, stack, crouch, kneel and balance when performing job duties in varying work areas such as confined spaces.
WORK ENVIRONMENT
The work environment characteristics described here are representative of those a Member encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The noise level in the work environment is usually moderate.
Member could be exposed to an environment containing unrestricted secondhand tobacco smoke.
PAY TRANSPARENCY
Fontainebleau Las Vegas believes in developing and supporting our talent into the future. Our compensation program is designed to attract, motivate, and retain talented Members who are the driving force behind the Company's success. We strive to provide market-competitive compensation. Salary will be commensurate with experience and skill set, considering a candidate's qualifications, skills, competencies, and experience, as well as internal equity and market data alignment.

In alignment with our Company culture, we will strive to communicate openly about the goals of the Company and the design of the compensation program. The compensation process is designed to be fair and simple so that all Members and managers understand the Company's goals and future career development opportunities for upward mobility.
SALARY
$72000 per year - $102000 per year","$102,000 /yr (est.)",Unknown,Company - Public,Hotels & Travel Accommodation,Hotels & Resorts,#N/A,Unknown / Non-Applicable
"APPIC Solutions LLC
5.0",5.0,"Minneapolis, MN",Data Engineer,"Data Engineer
Not open for C2C-ONLY W2
Location: ON-SITE, DAY ONE IN Minneapolis, MN (preferred), Dallas, TX or Atlanta, GA
Job Description:
We are looking for an experienced Senior Data Engineer who will be responsible for designing, building, and maintaining our data infrastructure. The ideal candidate will have a proven track record of at least 5 years in data analysis and will be proficient in Pyspark/Spark, Azure Synapse, and Azure Databricks. The Senior Data Engineer will play a critical role in our data-driven decision-making process by ensuring the availability, quality, and reliability of our data.
Key Responsibilities:
-Design and implement efficient and scalable data pipelines using Pyspark/Spark to ingest, transform, and load data from various sources into our data warehouse.
-Leverage Azure Synapse and Azure Databricks to manage and optimize data processing workloads, ensuring high performance and cost-efficiency.
-Utilize your 5+ years of data analysis experience to work closely with data scientists and analysts to understand business requirements and provide data-driven insights.
-Implement data quality checks, data profiling, and data validation processes to maintain the integrity of our data.
-Continuously monitor and optimize data pipelines and processing tasks to ensure they meet performance and scalability requirements.
-Maintain comprehensive documentation of data engineering processes, data models, and pipeline configurations.
- Collaborate with cross-functional teams to understand data requirements, troubleshoot issues, and provide technical expertise.
Qualifications:
- Bachelor's degree in Computer Science, Engineering, or a related field. Master's degree preferred.
- Minimum of 5 years of professional experience in data analysis.
- Strong proficiency in Pyspark/Spark and experience with distributed computing frameworks.
- Hands-on experience with Azure Synapse.
-Hands-on experience with Azure Databricks.
- Proficiency in SQL and database design principles.
- Knowledge of data warehousing concepts and ETL processes.
- Excellent problem-solving skills and attention to detail.
- Strong communication and teamwork skills.
- Experience with version control systems (e.g., Git) is a plus.
Job Type: Full-time
Pay: $90,000.00 - $95,000.00 per year
Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Application Question(s):
This role is NOT open for C2C. Please confirm you are seeking a W2 role to be considered for this position.
This role is on-site, day one in ON-SITE, DAY ONE IN Minneapolis, MN (preferred), Dallas, TX or Atlanta, GA. Please confirm that you already live in one of the mentioned cities to be considered
Education:
Bachelor's (Required)
Experience:
data analysis: 5 years (Required)
Pyspark/Spark: 5 years (Required)
Azure Synapse: 5 years (Required)
Azure Databricks: 5 years (Required)
SQL: 5 years (Preferred)
Work Location: In person","$92,500 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Software Development,2017,$1 to $5 million (USD)
"Symmetry Lending
3.9",3.9,"Anaheim, CA",Data Engineer,"**This position is a majority Remote role with occasional in-office meetings on an as-needed basis. Because of this, interested applicants must live within a reasonable driving distance of Symmetry Lending's office in Anaheim, CA.**
Job Description
This role will play a pivotal role in assisting the IT team with the evolution of the company data architecture. In addition to supporting extensions to the data warehouse design, this role will design and develop ETL required to onboard new types of business data. Finally, this role will also provide support for Analytics assignments as needed.
Responsibilities
Display sense of ownership over assigned work, requiring minimal direction and driving to completion in a sometimes fuzzy and uncharted environment.
Designing and building new data pipelines that support business requirements.
Work with IT and other business partners to support the evolution of the enterprise data architecture.
Work with IT to build new ETLs to take data from various operational systems and extend existing data warehouse data model for analytics and reporting.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for business constituents.
Support the development of the company BI infrastructure, including the construction of scalable analytic solutions, and on-premises reporting tools.
Utilize Power BI development to build scalable reporting models to serve BI reporting needs.
Demonstrate the ability to gather requirements, extract and manipulate data residing in multiple disparate databases, and articulate solutions to support the business.
Design, develop, and maintain performant data models in Power BI utilizing best practices.
Serve as a subject matter expert for all data warehouse and enterprise systems
Use new or existing technologies to produce analytics solutions (in the form of excel spreadsheets, dashboards, etc.).
Work with IT and Analytics team to architect and build data pipelines to optimize for performance, data quality, scalability, ease of future development, and cost.
Gather requirements, assess gaps and build roadmaps to help the analytics driven organization achieve its goals.
Develop data-related Proof of Concepts in order to demonstrate feasibility and value to Symmetry business constituents.
Qualifications / Requirements
Bachelor’s degree in Information Systems, Computer Science, Finance, or similar education from an accredited college
2-3 years Accounting and Finance background preferred
Strong skillset in Microsoft Excel (2-3 years, financial formulas & VBA is a plus) and familiarity with Microsoft Office Productivity Suite (Excel, Word, etc.)
5+years’ experience with advanced SQL concepts and writing SQL statements (SQL Server or similar).
Prefer 2 years’ experience with Microsoft Data Tools/BIDS (Business Intelligence Development Studio), Microsoft BI Suite, Power BI, Power Query, PowerPivot, Reporting Service (SSRS), SQL Server Integration Services (SSIS), and SharePoint
Experience in mentoring other team members in development best practice, and methodologies.
You are passionate about data quality control and know how and where to anticipate potential errors.
Knowledge of the software development lifecycle, agile methodologies, and structured software development methodologies.
Experience performing analysis with large datasets in a cloud-based environment.
Ability to work effectively with stakeholders at all levels within the organization
Strong communication and time management skills and a self-motivated approach
Ability to work independently, detail-oriented, and execution focused
Highly collaborative and team oriented
Tenacious (doesn’t give up easily)
Genuine passion for clean and reliable data
At least 5 years of work experience
About Symmetry
Symmetry Lending, specializes in providing mortgage fulfillment services to include origination, servicing, and capital markets needs to various Lenders across the country with whom we partner. We have offices in Atlanta, GA, Eden Prairie, MN, Denver, CO, Orlando, FL, and Anaheim, CA, and we do business from coast to coast. We take great pride in building a diverse team of motivated professionals that contribute to an exciting work atmosphere. We provide a competitive benefits package including medical, dental, and vision plan options, paid time off, and more.
California Disclosure - Employee Notice at Collection
This disclosure is intended to comply with the California Consumer Privacy Act (CCPA), which gives California residents who are applicants, employees, or contractors of Symmetry Lending (“Symmetry”) the right to know what categories of personal information Symmetry collects about them and the purposes for which Symmetry uses that information. As used in this Privacy Notice, “Personal Information” means information that identifies, relates to, describes, is reasonably capable of being associated with, or could reasonably be linked, directly or indirectly, with a particular individual or household. Personal Information includes, but is not limited to, the categories of personal information identified below if such information identifies, relates to, describes, is reasonably capable of being associated with, or could be reasonably linked, directly or indirectly, with a particular individual or household.
The following is a list of the categories of Personal Information that we may collect about consumers:
Identifiers. This may include a real name, alias, postal address, unique personal identifier, online identifier, Internet Protocol address, email address, account name, Social Security number, driver's license number, passport number, or other similar identifiers.
Personal information described in the California Customer Records Statute (Cal. Civ. Code § 1798.80(e)). This may include a name, signature, Social Security number, physical characteristics or description, address, telephone number, passport number, driver's license or state identification card number, insurance policy number, education, employment, employment history, bank account number, or any other financial information, medical information, or health insurance information.
Characteristics of Protected Classification under California or Federal Law. This may include age, race, color, ancestry, national or ethnic origin, citizenship status, religion or belief, marital status, a childbirth or related medical condition, physical or mental disability, sex (including gender, gender identity, gender expression, pregnancy or childbirth, and related medical conditions), sexual orientation, veteran or military status.
Biometric information. This may include voice and video recordings.
Sensory data. This may include audio, electronic, visual, or similar information, including photos.
Professional or employment-related information. This may include current or past job history, compensation data, performance evaluations, or employee benefits.
Beneficiaries, dependents, and emergency contact information. This may include the name, gender, phone number, and relationship of beneficiaries, dependents, and emergency contacts.
We may use the categories of Personal Information for the following business or commercial purposes:
To perform background checks necessary to comply with licensing requirements, to perform reference checks, to verify eligibility to work in the United States, for contact purposes, to assess your qualification for employment, to conduct performance evaluations, for payrolls and budgeting purposes, for implementation of employee benefits, for internal organizational purposes to establish proper accommodations for sick time, PTO, leaves of absences, or emergency situations, and to conduct health screenings as allowed by OSHA and the CDC to protect the safety of our employee during pandemic situations.
For internal use, such as tracking access into buildings, timekeeping, activity logs, etc.
To comply with laws and regulations, including but not limited to applicable tax, health and safety, anti-discrimination, immigration, labor and employment, and social welfare laws.
For security or the prevention, detection, or investigation of fraud, suspected or actual illegal activity, violations of company policy or rules, or other misconduct.
To comply with civil, criminal, judicial, or regulatory inquiries, investigations, subpoenas, or summons.
To comply with all licensing requirements necessary for our business operations, including state exam audits.
To exercise or defend the legal rights of Symmetry and its employees, affiliates, customers, contractors, and agents.
To seek advice from lawyers, auditors, or other professional advisors.
If Symmetry uses Personal Information of an applicant, employee, or contractor for a purpose materially different than those disclosed in this notice, Symmetry will notify the employee and obtain explicit consent from the employee to use the Personal Information for this new purpose.
Job Type: Full-time
Pay: $115,000.00 - $135,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Flexible spending account
Health insurance
Health savings account
Paid time off
Vision insurance
Experience level:
5 years
Schedule:
Monday to Friday
Education:
Bachelor's (Preferred)
Experience:
Accounting and Finance: 2 years (Preferred)
advanced SQL concepts and writing SQL statements: 5 years (Preferred)
Work Location: Hybrid remote in Anaheim, CA 92807","$125,000 /yr (est.)",51 to 200 Employees,Company - Public,Financial Services,Banking & Lending,#N/A,$5 to $25 million (USD)
Mind Mint,#N/A,"Scottsdale, AZ",Data Engineer,"JOIN AN AMAZING COMPANY AND GLOBALLY RECOGNIZED BRAND
DIVE INTO INTRIGUING PROJECTS AND LEVEL UP YOUR SKILLS
WORK WITH A FUN TEAM ONSITE IN SCOTTSDALE ARIZONA

Are you ready to embark on an exciting challenge in the field of data engineering?

Do you possess a genuine passion for unraveling patterns and crafting insightful solutions through data engineering?

Can you envision yourself delivering impactful outcomes that align with our company's objectives through data-driven solutions?

If so, we have an opportunity that will ignite your enthusiasm for data engineering and propel your career to new heights.

Mastermind.com, created in partnership by Dean Graziosi and Tony Robbins, is the #1 online platform for people who are looking to market and monetize their knowledge base. Mastermind has a worldwide following and touches lives all over the world.

We are seeking a world-class Data Engineer to join our IT team. Here is your chance to help take our company to new heights.

THE ROLE

️ Build tools and solutions that automate complex workflows

️ Create data pipelines and maintain the infrastructure and architecture for data generation, storage, and processing

Build systems that collect, manage, and convert raw data into usable information

This is a role that involves solving complex technical issues and working collaboratively with our team. You will report directly to the Chief Technology Officer.

Our interview process will include a technical assessment and peer code review to assess your technical proficiency.

This Data Engineer position is based in Phoenix, Arizona, and will require you to work from the Mastermind headquarters in Scottsdale, AZ.

We provide an excellent compensation model based on experience ranging from $100k-120k.

This opportunity is only available for USA residents with valid work authorization. We DO NOT offer sponsorship or relocation.

REQUIREMENTS
You must have 5 years experience in designing and maintaining MySQL
You must have experience with cloud data warehouses (preferably BigQuery), dbt, or Python experience
You must have SQL development experience
You must have experience with spreadsheet manipulation in SQL
You must be able to write custom queries to answer any question about the data without leaving a SQL environment.
You must have experience querying and manipulating large datasets
Bachelor’s degree in a technical field or equivalent related work experience
Ability to utilize Fivetran and Stitch for extracting and loading data into BigQuery
Strong understanding of database design
Experience with Web APIs and pulling data from them, preferably in Python, is a plus
Excellent problem-solving and communication skills
Experience querying and manipulating large datasets
Experience with data parsing, scripting, and automation

RESPONSIBILITIES

Design and create database objects, such as tables, stored procedures, and views.
Conduct technical research and data profiling on various data sources, utilizing technologies like Python, APIs, and SQL.
Innovatively propose technical data solutions to address business challenges.
Perform dimensional data modeling and optimize database objects for accessibility, performance, and consistency.
Collaborate with business stakeholders to gather and understand data requirements.
Communicate data concepts, reports, KPIs, and other technical subjects in a business-friendly language.
Develop ETL applications using SQL, Python, etc., for data extraction, transformation, and loading.
Document development standards, KPI calculations, business terms, table diagrams, and other relevant information related to data and reports.
Keep up-to-date with emerging technologies and trends in data engineering
Perform other duties as assigned.

PERKS & BENEFITS

Competitive salary and compensation
Excellent Medical benefits
EOY Profit Sharing
401(k) administration and matching program
Incredible opportunities for growth and development
Amazing in-office culture
Become part of a mission-team making a difference!

HOW TO APPLY

Ready to dive into the fascinating realm of data engineering and take your skills to new heights as a Data Engineer?

If so, we invite you to join our exceptional team, where you'll have the opportunity to unleash the power of data, shape the future of data-driven decision-making, and embark on a fulfilling career journey.

Click the ""Apply Now"" button below to take the first step toward an exciting future.
We can't wait to review your application and explore the endless possibilities of working together.

About Mastermind.com
Mastermind.com, created in partnership by Dean Graziosi and Tony Robbins, is the #1 online platform for people who are looking to market and monetize their knowledge base. We are redefining what ""Self-Education"" means to the world.

Mastermind is not just ""another software"" but an all-in-one platform for Education, Entertainment, Implementation & Community. Mastermind serves people worldwide who seek transformation, fulfillment, and success outside the traditional education path.

The Mastermind software empowers and enables you to implement what you learn & actually get paid, in addition providing a community where you are surrounded by like-minded individuals cheering you on to YOUR NEXT LEVEL.","$110,000 /yr (est.)",Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Orion First
5.0",5.0,"Gig Harbor, WA",Data Engineer (100% Remote),"OUR COMPANY

Committed to the growth of our clients, Orion First appreciates the importance of its own team development. Orion’s culture is built around empowering each employee to channel their drive and exercise his or her own judgment, care, and leadership. Our employees are continually leading our industry forward through active roles throughout the industry association's various councils and committees. We work hard to provide motivated and talented individuals an opportunity to achieve their career goals. We cultivate employees that express an earnest desire to learn and grow within the organization, filling new roles as they gain experience. We are always seeking to connect with driven individuals, because we know our growth and success is the result of talented, focused, and persistent hard work.

OUR BENEFITS

In addition to a salary that is competitive for both the industry and the region, Orion First offers the following benefits and perquisites:
Health Insurance
Dental Insurance
Vision Insurance
Time Off
Retirement
WFH Benefit
And More!

JOB SUMMARY

The Orion Insights team works with executives, managers, and subject matter experts to help them better understand small business portfolio performance. We partner with internal and external stakeholders to build data products (interactive dashboards, KPIs, reports, etc.) that drive essential business decisions and expand access to capital for small businesses.

The Data Engineer will play a key role within our organization’s Insights team, contributing to developing and supporting our data products. Tasks will involve developing and owning all data pipelines supporting environments including SQL server, Azure, Salesforce, Snowflake, Matillion. This critical position on a small team can influence Orion First’s overall data strategy.

REPORTS TO:

VP/ Data & Analytics

KEY RESPONSIBILITIES

Design, develop, document, test, and maintain data pipelines.
Collaborate with data analysts, engineers, and stakeholders to identify and document requirements/needs for data pipelines.
Manage and create API endpoints for clients to interact with Orion data products & access their data.
Monitor the performance, scalability, and security of data systems; performs analysis required to troubleshoot data related issues and assists in resolving them.
Validate source data quality and drive improvements.
Assist in the deployment of analytics products
Performs other duties as assigned.

REQUIRED QUALIFICATIONS

Demonstrated ability to take projects from system design to implementation.
Experience using cloud workflow orchestrator (Prefect, Airflow, AzureData Factory, etc.) to manage data pipelines.
2+ years building efficient data pipelines, performance tuning, and integrating disparate data sources.
2+ years using Python to structure and analyze data.
2+ years using SQL to query and structure data.
1+ year Matillion ETL or similar tool (like Talend, Qlik, Alteryx)
1+ years developing solutions with API endpoints.
1+ year Snowflake with exposure to snowSQL, snowpipe
1+ year with DBT for data transformation
At least 1 data migration project, preferably SQL server to Azure Cloud.
Experience working within Microsoft Azure managing compute and storage resources.
Experience using GitHub.
Experience in designing data architecture and familiarity with data governance concepts.

PREFERRED QUALIFICATIONS

At least 4 years of relevant work experience.
Knowledge of Power BI or any other reporting tools.
Desire to cross-train and learn reporting tools.
Ability to adapt to changing requirements.
Ability to cross-train peers.
Bachelor’s degree in relevant field.","$115,000 /yr (est.)",51 to 200 Employees,Company - Private,Financial Services,Banking & Lending,2001,$5 to $25 million (USD)
"Xplor
3.5",3.5,"Saint Louis, MO",Data Engineer,"Company Description

Take a seat on the Xplor rocketship and join us as a Data Engineer to help people succeed across the world.

We’re a global team of builders, listeners and problem-solvers who are relentlessly focused on making life simple, so our customers can get back to growing their business, engaging consumers and doing what they love.

Job Description

About the opportunity
At Xplor, the Central Technology Team has one main purpose: to enable and complement the business strategies and goals while solving real problems for our customers and users.
We have dozens of applications in our everyday-life verticals that all have their technology uniqueness and their individual purpose. We also use some of the latest technology in Microsoft Azure, AWS, and Containers and are constantly looking to find innovative new ways to meet the challenges of running a unique global business.
As a member of the global data engineering team, reporting to the Data and Analytics Manager (US), this role has a primary focus on contributing to our enterprise data warehousing and reporting deliverables.
Responsibilities include designing, creating, and maintaining business intelligence assets and reports that drive innovation, client value and business efficiency.
This position will be working across our largest business units and experience with multi-terabyte database systems is required. Assisting primarily through maintaining and implementing an array of data synchronization efforts across numerous systems both on-premises and in the cloud. You will coordinate with our data architects, product management, and IT management to ensure that our data pipelines for both internal operations and customer reporting are accurate, scalable, and secure.
The primary tasks, duties, and responsibilities are:
Building our enterprise data movement capability for ingestion to snowflake.
ELT development primarily with a mixture of SQL and Python.
Contribute to cloud migration and ensure system uptime for data warehouse products.
Centralising orchestration of scheduled data pipelines and automated processes.
Participate in Agile work planning, testing, and quality assurance.

Qualifications

Essential Job Skills
Proven experience working at enterprise scale with multi-terabyte database systems.
Security focused development practices, particularly with egress of On-Prem data to cloud.
Expertise with Microsoft SQL Server and SQL Server Integration Services.
Experience in automation using coding/scripting languages such as Python and PowerShell.
Proficiency with source control, CI/CD practices and pipeline deployment methods.
Strong prioritisation, time management and organisational skills
Technical Skills
Proficiency with Python is a must.
Experienced level knowledge - Business Intelligence/reporting tools including Microsoft SQL, SRSS, SSIS, SSAS, Power BI, DAX.
Adept at designing and implementing effective data models and Extract, Transform, Load (ETL) processes slowly changing dimensions for transforming and loading data into the data warehouse.
Experience incorporating data from varied relational systems (e.g. MySQL, Postgres etc), flat-file, API, and No-SQL sources.
Understanding of data governance practices, data lineage, and data quality management to ensure accurate, consistent, and reliable data.
Prior use of orchestration tools such as Prefect or Dagster would be an advantage.
Familiarity with cloud base tooling – Snowflake, DBT or Coalesce, Fivetran.
Containerisation experience such as Docker is also advantageous.
Education/Qualifications
BA/BS degree in Computer Science, Computer Engineering, or related field, or equivalent practical experience.
Preferred Qualifications include:
Expertise in parallel processing warehouses (Snowflake/Redshift),
high-frequency differential ETL processes,
and Agile development methodology.
At Xplor, we believe that the best innovation and ideas happen at the intersection of differences - people of different cultures, generations, disciplines, and lived experiences. So even if you think you don’t quite tick all the boxes, we still encourage you to apply.

Additional Information

Joining Xplor’s Central Technology (CT) team
There are over 600 Xplorers in our CT team that work as one team across the world. You'll get the chance to engage through Communities of Interest in Technologies (CIT), our Architectural Advisory Board or work on DOOR (Develop Only Once and Reuse).
Being a technology company selling SaaS-based software solutions, you can see your work clearly in the success of the business. You'll be a strategic enabler via world-class capabilities fostering product development and innovation.
Some of the other perks and benefits:
o 12 weeks Gender Neutral Paid Parental Leave for both primary and secondary carer
o #GiveBackDays/Commitment to social impact – 3 extra days off to volunteer and give back
to your local community
o Ongoing dedication to Diversity & Inclusion initiatives such as D&I Council, Global
Mentorship Program
o Access to free mental health support
o Flexible working arrangements
The average base salary pay for this role is $100-125k USD.
May be considered for a discretionary bonus
#LI-Remote

More about us
Xplor Technologies is a global platform integrating SaaS solutions, embedded payments, and Commerce Accelerating Technologies to help businesses succeed. Xplor provides enterprise-grade SaaS solutions for businesses in “everyday life” verticals: Childcare & Education; Fitness & Wellbeing, Field Services and Personal Services – and a global cloud-based payment processing platform.
Xplor Technologies serves over 78,000 customers that processed over $36 billion in payments, operating across 20 markets in 2022.
Good to know
To be considered for employment in the United States, you must be legally authorized to work in the US. Xplor does not sponsor visas, either at the time of hire or at any later time.
To learn more about us and our products, please visit www.xplortechnologies.com/us/careers.
We also invite you to check out our Candidate FAQs for more information about our recruitment process www.xplortechnologies.com/us/recruitment-faqs.
Xplor is proud to be an Equal Employment Opportunity employer. We're dedicated to attracting, retaining and developing our people regardless of gender identity, ethnicity, sexual orientation, disability, veteran status and age. Applications are encouraged from all sectors of the community.
All Information will be kept confidential according to EEO guidelines.
Xplor is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Xplor will take the steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please contact us via talent@xplortechnologies.com.
We are a 2023 Circle Back Initiative Employer – we commit to respond to every applicant.","$112,500 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,1994,Unknown / Non-Applicable
Alphataraxia,#N/A,"Washington, DC",Data Engineer,"Company
Alphataraxia Management (ATX) is a fast-growing quantitative investment management group with offices in both Washington, DC and Los Angeles, CA. We specialize in wholesale electricity markets, where extreme volatility is the norm and the marketplace is constantly evolving, presenting new opportunities for growth and insight. We are currently one of the top participants in the power markets and are looking for hard-working candidates with genuine enthusiasm for solving complex problems to join our collaborative and high-caliber team.

Job Description
We are hiring a Data Engineer to join our team! In this role you will help us create the data engineering practices that will scale our data infrastructure, automation, and tools to meet growing business needs.
At Alphataraxia, we build data-powered proprietary systems that are the backbone of our business in trading speculative wholesale power contracts and hedging risk in our existing portfolios. As a Senior Data Engineer, your job will be to facilitate our collective development work to build out critical trade flows and transact on the best data available.
We are looking for a motivated individual with a mind for data organization and accessibility and creating and implementing engineering practices on a firm-wide level. You will excel in this role if you enjoy analyzing data as well as building tools and models that enable our firm's investment decisions. If this sounds like you, we'd love to meet you!
Responsibilities:
Building out proprietary systems that are the backbone of our business in trading speculative wholesale power contracts and hedging out risk in our existing portfolios
Defining goals for data management and strategizing how to use data resources most effectively
Design, build, and maintain critical tools and processes used to transact in energy markets
Ensure robust data handling data of new and existing resources
Collaborate closely with Power Market Analysts and Investment Analysts on your team to deliver needed tools and improve existing infrastructure
Collaborate with Data Engineers from other teams to ensure firm-wide continuity and efficiency
Note: if you are incredibly interested in the financial transactions side of this role, see our Power Market Analyst position
Applicant Requirements:
3+ years of experience in a Data Engineering or similar role
Professional experience using Snowflake
Experience with data transformation tooling and spinning up workflow management tooling
Experience with complex data modeling
Experience using dbt in a personal or professional setting
Proficiency coding with the following languages: Python, PHP, SQL experience
An ability to grapple with quantitative concepts and systems, as this role interfaces with largely technical and quantitative peers
Comfort working both individually as well as collaboratively, at times in a fast-paced and dynamic environment

A Little More About Us:
We play with vast amounts of data and turn our findings into actionable trading decisions.
We try to explain how things work both fundamentally and quantitatively.
We build all our own proprietary tools, enabling us to prototype, iterate quickly, and pivot when necessary.
We automate as many redundant processes as possible to maximize time spent on analysis.
We move quickly with minimal bureaucracy and a high level of ownership.
We have a team-first mindset, and focus on developing our team members.
We believe strongly in the value of maintaining a variety of perspectives and experiences within our team.
We work in a collaborative, casual environment, yet also expect high throughput from each member of our team.
We pride ourselves on our openness, transparency, and horizontal structure
-across the firm, we all work closely together to tackle difficult problems.

Benefits:
We strive to offer best-in-class compensation and benefits alongside an unrivaled work-life balance.
Competitive annual salary and bonus
19 paid vacation days + 7 paid federal holidays and 5 floating holidays
Excellent health, dental, and vision insurance (including HSA option) with no monthly premiums for best-in-class platinum individual plan
401k match
- 100% company matching on the first 4% of deferrals with immediate vesting
Annual firmwide weeklong summit
Hybrid remote work environment
- most of the year we are in the office Tuesday to Thursday with remote flexibility Monday and Friday
Flexible remote work months
- fully remote option for the month of July and between Thanksgiving and New Years
Casual environment (informal attire)
Snacks and unlimited coffee in the office
Firm sponsored social events including happy hours, lunches, book club, and more!

Application:
Please note that we can only extend offers to individuals that are authorized to work in the US; we are unable to sponsor visa applications at this time. California Consumer Privacy Act Notice available on request. The base salary range for this position is $140,000 - 170,000.","$155,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"WorldLink
3.6",3.6,"Frisco, TX",Data Engineer,"WorldLink is a rapidly growing information technology company at the forefront of technical revolution. From custom software development to cloud hosting, from big data to cognitive computing, we help companies harness and leverage today’s most cutting-edge digital technologies to create value and grow.
Collaborative. Respectful. Work hard Play hard. A place to dream and do. These are just a few words that describe what life is like at WorldLink. We embrace a culture of experimentation and constantly strive for improvement and learning.
We take pride in our employees and their future with continued growth and career advancement. We put TEAM first. We are a competitive group that like to win. We're grounded by humility and driven by ambition. we're passionate, and we love tough problems and new challenges. You don't hear a lot of ""I don't know how"" or ""I can't"" at WorldLink. If you are passionate about what you do and having fun while doing it; tired of rigid and strict work environments and would like to work in a non-bureaucratic startup cultural environment, WorldLink may be the place for you.
For more information about our craft, visit https://worldlink-us.com.
The Impact you will have:
Build data pipeline frameworks to automate high-volume and real-time data delivery. (20%)
Building data APIs and data delivery services to support critical operational and analytical applications. (20%)
Transform complex analytical models in scalable, production-ready solutions. (10%)
Provide support and enhancements for an advanced anomaly detection machine learning platform. (5%)
Contributing to the design of robust systems with an eye on the long-term maintenance and support of the application. (5%)
Defining, executing, and continuously improving our internal software architecture processes. (5%)
Continuously integrate and ship code. (20%)
Develop applications from the ground up using a modern technology stack. (5%)
Work directly with Product Owners and customers to deliver data products in a collaborative and agile environment. (10%)
What we are Looking for:
BS degree in Computer Science, Data Engineering or similar with Intermediate to senior level experience in an Apps Development role. Demonstrated strong execution capabilities.
Experienced with Python, search and ETL.
Search engine integration and data catalog/metadata store experience is preferred (Coveo).
5+ years of experience on designing and developing Data Pipelines for Data Ingestion or transformation using Java or Scala or Python.
4+ years of experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC), Resource Management, Distributed Processing and RDBMS.
5+ years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps.
2+ years of experience with SQL and Shell Scripting experience.
Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Apache Beam, Apache Airflow etc).
Experience with Spark programming (pyspark or scala or java) and troubleshooting JVM-related issues.
Experience and strategies to deal with mutable data in Hadoop.
2+ years of experience working with Streaming and Stream Sets using Spark or Flink or Kafka or NoSQL
Familiarity with machine learning implementation using PySpark.
Experience in data visualization tools like Cognos, Arcadia, Tableau.
Experience with various noSQL databases (Hive, MongoDB, Couchbase, Cassandra, and Neo4j) will be a plus.
Preferred Experience and Skills:
Angular.JS 4 Development and React.JS Development expertise in an up-to-date Java Development Environment with Cloud Technologies.
1+ years’ experience with Amazon Web Services (AWS), Google Compute or another public cloud service.
2+ years of experience working with Dimensional Data Model and pipelines in relation with the same.
Physical Demands:
The physical demands described here are representative of those that must be met by contract employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the contract employee is occasionally required to stand, clean, crawl, kneel, sit, sort, hold, squat, stoop, stand, twist the body, walk, use hands to finger, handle, or feel objects, tools or controls, reach with hands and arms, climb stairs or ladders and scaffolding, talk or hear, and lift up to 20 pounds. Specific vision abilities required by the job include ability to distinguish the nature of objects by using the eye.
WHAT we’ll bring:
During your interview process, our team can fill you in on all the details of our industry-competitive benefits and career development opportunities. A few highlights include:
Medical Plans
Dental Plans
Vision Plan
Life & Accidental Death & Dismemberment
Short-Term Disability
Long-Term Disability
Critical Illness/ Accident/ Hospital Indemnity/ Identity Theft Protection
401(k)
WHAT you should know:
Our success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. WorldLink is an Equal Employment Opportunity and Affirmative Action employer. All employment at WorldLink is decided on the basis of qualifications, merit, and business need. We endeavor to continue our footprint as a diverse organization by highlighting opportunities for all people. WorldLink considers applicants for all positions without regard to race, color, religion or belief, sex, (including pregnancy and gender identity), age, national origin, political affiliation, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws. People with disabilities who need assistance with any part of the application process should contact us.
This job description is designed to cover the main responsibilities and duties of the role but is not designed to be a comprehensive list of all.
Job Type: Full-time
Pay: $120,000.00 - $140,000.00 per year
Benefits:
401(k)
Dental insurance
Flexible schedule
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Application Question(s):
Do you live in the Dallas, TX area or are you open to relocation?
Education:
Bachelor's (Required)
Experience:
Data Pipelines: 5 years (Required)
Big data: 4 years (Required)
Application development: 5 years (Required)
HDFS/Hadoop: 4 years (Required)
Cassandra: 2 years (Required)
Work Location: Hybrid remote in Frisco, TX 75034","$130,000 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1998,$100 to $500 million (USD)
"Knowesis
4.5",4.5,"Alexandria, VA",Data Engineer,"Position: Data Engineer
Location: Remote, DMV Metro preferred
Clearance Required: Secret
Knowesis is seeking a skilled Data Engineer to join our team, supporting the Department of Defense (DoD) Office of Inspector General (OIG). The candidate will be responsible for designing, building, and maintaining the infrastructure that supports data storage, processing, and retrieval in the Cloudera Data Platform. They will work with large data sets and develop data pipelines that move data from source systems to data warehouses, data lakes, and other data storage and processing systems. The candidate will also develop and maintain data APIs, ETL processes, and data integration systems.

This position requires eligibility for a Secret Clearance and requires U.S. Citizenship (applicants without proof of US citizenship will not be considered due to the position’s security clearance requirement).
Duties and Responsibilities:
Data Infrastructure Design: Design and implement robust and scalable data infrastructure solutions within the Cloudera Data Platform.
Data Pipeline Development: Create and maintain data pipelines to efficiently move data from source systems to data storage and processing systems.
Data Storage Management: Manage and optimize data storage solutions, including data warehouses and data lakes.
ETL (Extract, Transform, Load) Processes: Develop and maintain ETL processes to cleanse, transform, and load data into appropriate storage systems.
Data Integration: Design, develop, and maintain data integration systems to ensure seamless data flow between different components.
Data API Development: Build and maintain data APIs to facilitate data access for various applications and users.
Performance Optimization: Continuously monitor and optimize data processes and infrastructure for maximum performance and efficiency.
Data Security: Implement and maintain data security measures to protect sensitive information.
Required Skills & Qualifications:
Proven experience in data engineering, including data pipeline development and infrastructure design.
Proficiency in Cloudera Data Platform or similar big data technologies.
Strong programming skills in languages such as Python, Java, or Scala.
Knowledge of database systems and SQL.
Familiarity with data warehousing concepts and tools.
Experience with ETL tools and processes.
Understanding of data security and compliance standards.
Excellent problem-solving and communication skills.
Preferred Skills & Qualifications:
Certification in relevant data engineering technologies.
Experience working with the Department of Defense (DoD) or government agencies.
Knowledge of cloud-based data solutions (e.g., AWS, Azure, GCP).
Education:
A Bachelor’s degree, preferably in Computer Science, Engineering, Business, or related field, demonstrating your commitment to continuous learning and professional growth.
Knowesis is an Equal Opportunity Employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.","$91,849 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,2007,$25 to $100 million (USD)
Artisys Corporation,#N/A,"Baltimore, MD",Data Engineer,"Artisys Corporation is seeking a Baltimore-based Data Engineer for our client, The State of Maryland . This is a long term position that is set to extend through June 2026, with a review period to extend through June 2028. We are seeking a highly skilled Data Engineer that meets the following qualifications:
Duties:
Designing, implementing, and maintaining batch and streaming data pipelines between various SQL sources, including Aurora and SQL Server, and a target data lake in S3, as well as enterprise data stored in Redshift/Snowflake.
Expertise in AWS cloud services, such as Kinesis, S3, Lake Formation, Glue, and Step Functions, to build scalable, reliable, and high-performance data pipelines that enable seamless data integration and empower data-driven insights.
Data Pipeline Design: Design end-to-end data pipelines that efficiently extract, transform, and load data from SQL sources (Aurora, SQL Server) to the target data lake in S3 and the enterprise data in Redshift/Snowflake.
Batch and Streaming Integration: Implement both batch and real-time streaming data integration solutions using AWS Kinesis and other relevant technologies.
Data Transformation: Develop data transformation processes using AWS Glue or other ETL tools to harmonize, cleanse, and enrich data for analytical use.
Data Lake Management: Oversee the setup and configuration of the data lake in S3, applying AWS Lake Formation best practices for data organization, cataloging, and
access control.
Data Governance: Ensure adherence to data governance and security standards across the data pipelines, guaranteeing data privacy and compliance.
Performance Optimization: Continuously monitor and optimize the performance of the data pipelines, addressing bottlenecks and ensuring efficient data processing and
delivery.
Error Handling and Monitoring: Implement error handling mechanisms and robust data monitoring to identify and resolve data pipeline issues proactively.
Data Cataloging and Lineage: Establish and maintain data cataloging and lineage information using AWS Glue Data Catalog to enable data discoverability and traceability.
Documentation: Create comprehensive technical documentation, including design specifications, data flow diagrams, and operational guides.
Collaboration: Collaborate with data analysts, data scientists, and other stakeholders to understand data requirements and deliver reliable data solutions.
Data Governance: Ensure data governance principles are implemented throughout the data pipelines to maintain data quality and integrity.
Education Qualifications:
Bachelor's Degree from an accredited college or university with a major in Computer Science, Information Systems, Engineering, Business, or other related scientific or
technical discipline.


General Experience:
At least six (6) years of experience working on AWS cloud-based batch and streaming data pipelines.
Strong proficiency in AWS cloud services, including Kinesis, S3, Lake Formation, Glue, and Step Functions.
In-depth knowledge of SQL databases, such as Aurora and SQL Server, and data lakes in S3, as well as enterprise data in Redshift/Snowflake.
Hands-on experience with ETL tools, data transformation, and data integration techniques.
Familiarity with data governance, data privacy, and security best practices in AWS environments.
Strong problem-solving skills and the ability to troubleshoot complex data pipeline issues.
Excellent communication and teamwork skills to collaborate effectively with crossfunctional teams.
AWS certifications, such as AWS Certified Data Analytics - Specialty or AWS Certified Big Data - Specialty, are advantageous
Note: The candidate must be flexible to work overtime as needed, including weekends, holidays, and off-hours.
If you meet the qualifications for this position and would like to be considered, Aritsys Corporation would like to introduce you to this Baltimore, MD based client! After you've applied, feel free to learn more about Artisys Corporation at our website: Artisys.com","$98,147 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"NexGen IOT Solutions
4.7",4.7,"New York, NY",Data Visualization Engineer,"Published
September 3, 2023
Location
New York, United States of America
Category
Default
Job Type
Full-time
Experience
3+ Years
DESCRIPTION
Position: Data Visualization Engineer
Location: Remote (New York)
Type: Full Time
Experience: 3+ Yrs
Must: Data Warehouse like redshift etc ,Power BI, tableau or Looker experience, GA /Fire base experience, Sports, OTT, DTC is a plus.
Must have requirements:
Minimum 3 years of web analytics experience using GA and Firebase
Experience with Looker or similar to build custom dashboards for clients
Experience working with high-profile clients
Excellent written and verbal communication skills
Ability to meet clients in person as needed in their office person
Experience with GA4 and conversion
Responsibilities:
Leverage data to gain insights into trends, user behavior, and user pathing to drive our digital marketing strategies.
Take various sources of data and condense them down to a coherent story with a clear conclusion and actionable insights.
Manage client relationships and serve as the SME for web analytics.
Contribute to building an analytics strategy and elevate the analytics platform to achieve a data-driven digital marketing culture.
Data analysis for web projects, mobile, and OTT platforms.
A/B and multivariate testing, and ad hoc requests
Oversee tag management services and maintain integrity across multiple sources of data.
Communicate project status, risks, dependencies, and roadblocks for technical audiences and business stakeholders.
Requirements:
Minimum 3 years of web analytics experience
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Implementation experience with analytics platforms such as a web reporting tool and tag management software preferred.
Expert knowledge of Excel and PowerPoint
Experience with business intelligence tools a plus
Experience with offline/online data integration is a plus.
Up to date with current analytics trends and tools
Critical thinker whom can problem solve
Excellent communication skills; proven written and oral presentation skills.
Ability to work independently and is a motivated self-starter.
Detail-oriented and organized.
Experience working with data from data warehouses like Redshift etc.
Nice to Have:
Strong Adobe marketing cloud experience desired (Workspace, ReportBuilder, Data Warehouse, Target, etc.)
Strong Adobe marketing cloud experience desired (Workspace, Report Builder, Data Warehouse, Target, etc.)
Bachelor’s Degree in Business, Marketing, Economics, or a related field.
Experience with SQL and pulling data from Data Warehouses and Databases.
Experience working with data and data warehouse teams and building reporting with multiple data sources.","$86,862 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $25 million (USD)
"Skylight
4.5",4.5,Remote,Data Engineer,"About Skylight
Skylight is a digital consultancy using design and technology to help government agencies deliver better public services.
We're at the forefront of a civic movement to reinvent how all levels of government serve families, patients, and many others in today's digital world.
If you want to play a part in driving this critical movement forward, we'd love for you to join our growing team of public interest technologists.
The work we do matters.
About the job
At Skylight, data engineers work closely with product managers, researchers, designers, engineers, and data scientists to design ways to ingest, optimize, synthesize, and analyze data to help users make informed decisions. They build software and infrastructure to process data from a variety of sources and store it in a way that supports analytical and other needs of end users.
What you'll do
Use a variety of data processing tools, languages and libraries to ingest, transform, and enrich data
Work with a variety of data processing and storage infrastructure while optimizing for both performance and cost.
Analyze data for trends and patterns, developing actionable insights that drive business goals and objectives
Write readable, reusable, and performant code to ensure the performance and reliability of data extraction and processing
Preserve privacy, security, and integrity through the entire data life cycle
Engage with stakeholders to identify opportunities for data-driven impact
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
What we're looking for
Minimum qualifications
Ability to write clean, working, and reusable code
Can produce high-quality code by adhering to good practices such as automated testing
Possess a foundational understanding of data engineering, including how to use various datastores to handle persistent data in software systems
Familiar with modern data engineering, including techniques for cleaning and preprocessing data from a variety of sources
Ability to preserve privacy and security when processing and analyzing data
Can clearly communicate your data, models, and findings to technical and non-technical audiences
Ability to use the appropriate visualization tools to highlight actionable insights, trends, and recommendations from data
Ability to work successfully within a professional services environment (e.g., can communicate effectively with clients)
Passionate about creating better public outcomes through great government services
A mindset and work approach that aligns with our core values
Ability to travel for work from time to time
Nice-to-have qualifications
Prior experience working in the civic tech space
Experience working in a remote-team environment
Don't meet 100% of the criteria but think you can do the job? We'd love to chat anyway! We're on a mission to build diverse teams, and studies have shown that women and marginalized folks are less likely to apply to jobs if they don't check every box.
Other requirements
All work must be conducted within the U.S., excluding U.S. territories. Some federal contracts require U.S. citizenship to be eligible for employment.
You must be legally authorized to work in the U.S. now and in the future without sponsorship.
As a government contractor, you may be required to obtain a public trust or security clearance.
Some of our available roles are on federal contracts that require a degree or additional years of experience as a substitute.
Position type
This is a full-time, exempt position.
Location
This is a fully remote position.
Care package
Salary
We want to give you the most competitive salary possible. After all, you deserve it! To that end, we use the results of our interview process to determine what salary is most appropriate given your current level of seniority. For a Data Engineer at Skylight, the current salary ranges are as follows:
Associate Data Engineer: $90,000–$125,000
Data Engineer I: $120,000–$140,000
Data Engineer II: $135,000–$160,000
Senior Data Engineer: $150,000–$185,000
Staff Data Engineer: $170,000–$203,000
Principal Data Engineer: $180,000–$230,000
Benefits
Your well-being is important to us, so we focus on supporting you in a variety of ways:
Medical insurance, dental insurance, vision insurance
Short-term and long-term disability insurance
Life and AD&D insurance
Dependent care FSA, healthcare FSA, health savings account
Dollar-for-dollar 401(k) match up to 10% of your salary with no vesting period
Paid time off, including 20 vacation days, 11 federal holidays, and flexible sick leave
Up to 12 weeks paid time off for all eligible new birth, adoption, or foster parents
Performance rewards, including annual salary increase, annual performance bonus, spot bonuses, and stock options
Business development / sales bonuses
Referral bonuses
Annual $2,000 allowance for professional development
Annual $750 allowance for tech-related purchases
Annual swag budget of $100 to display your Skylight pride with some merchandise (hoodies, hats, and more)
Dollar-for-dollar charity donation matching, up to $500 per year
Access up to $1,000 before payday to cover emergency expenses
Flexible, remote-friendly work environment
An environment that empowers you to unleash your superpowers for public good
Interview preparation
We want you to have a great interview experience with us! Here are some tips to help you prepare for a successful interview:
Visit our join page to learn more about how our interview process works.
Check out our Career Pathways framework to learn more about the different roles within Skylight and the skills needed to do them.
If you'd like to request reasonable accommodations during the application or interviewing process, please contact our recruiting team at recruiting@skylight.digital.
We participate in E-Verify and upon hire, will provide the federal government with your Form I-9 information to confirm that you're authorized to work in the U.S.
We're an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.",#N/A,1 to 50 Employees,Company - Private,Retail & Wholesale,Consumer Electronics & Appliances Stores,2015,$1 to $5 million (USD)
"Attain Partners
4.2",4.2,"Linthicum Heights, MD",Data Engineer,"Who We Seek:
Passion Seekers. You genuinely care about the work that you do and its impact on society.
Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.
Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.
Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients

Duties:
Designing, implementing, and maintaining batch and streaming data pipelines between various SQL sources, including Aurora and SQL Server, and a target data lake in S3, as well as enterprise data stored in Redshift/Snowflake.
Expertise in AWS cloud services, such as Kinesis, S3, Lake Formation, Glue, and Step Functions, to build scalable, reliable, and high-performance data pipelines that enable seamless data integration and empower data-driven insights.
Data Pipeline Design: Design end-to-end data pipelines that efficiently extract, transform, and load data from SQL sources (Aurora, SQL Server) to the target data lake in S3 and the enterprise data in Redshift/Snowflake.
Batch and Streaming Integration: Implement both batch and real-time streaming data integration solutions using AWS Kinesis and other relevant technologies.
Data Transformation: Develop data transformation processes using AWS Glue or other ETL tools to harmonize, cleanse, and enrich data for analytical use.
Data Lake Management: Oversee the setup and configuration of the data lake in S3, applying AWS Lake Formation best practices for data organization, cataloging, and access control.
Data Governance: Ensure adherence to data governance and security standards across the data pipelines, guaranteeing data privacy and compliance.
Performance Optimization: Continuously monitor and optimize the performance of the data pipelines, addressing bottlenecks and ensuring efficient data processing and delivery.
Error Handling and Monitoring: Implement error handling mechanisms and robust data monitoring to identify and resolve data pipeline issues proactively.
Data Cataloging and Lineage: Establish and maintain data cataloging and lineage information using AWS Glue Data Catalog to enable data discoverability and traceability.
Documentation: Create comprehensive technical documentation, including design specifications, data flow diagrams, and operational guides.
Collaboration: Collaborate with data analysts, data scientists, and other stakeholders to understand data requirements and deliver reliable data solutions.
Data Governance: Ensure data governance principles are implemented throughout the data pipelines to maintain data quality and integrity.
Education Qualification:
Bachelor's Degree from an accredited college or university with a major in Computer Science, Information Systems, Engineering, Business, or other related scientific or technical discipline.

General Experience:
At least six (6) years of experience working on AWS cloud-based batch and streaming data pipelines.
Strong proficiency in AWS cloud services, including Kinesis, S3, Lake Formation, Glue, and Step Functions.
In-depth knowledge of SQL databases, such as Aurora and SQL Server, and data lakes in S3, as well as enterprise data in Redshift/Snowflake.
Hands-on experience with ETL tools, data transformation, and data integration techniques.
Familiarity with data governance, data privacy, and security best practices in AWS environments.
Strong problem-solving skills and the ability to troubleshoot complex data pipeline issues.
Excellent communication and teamwork skills to collaborate effectively with cross functional teams.
AWS certifications, such as AWS Certified Data Analytics - Specialty or AWS Certified Big Data - Specialty, are advantageous.

About Us:

Attain Partners is a place for great ideas and the people who have them. As a management, technology, and strategy consulting firm, our professionals provide innovative solutions to revolutionize government, education, health, and nonprofit organizations and positively impact those they serve. We are business analysts, technologists, digital strategists, managers of change, and forward thinkers, with the entrepreneurial drive to shape the future. Our team is present in 35 states and the District of Columbia.

Visit https://attainpartners.com/careers to explore your path forward with Attain Partners.

Attain Partners is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

Applicants have rights under Federal Employment Laws. For more Information visit EEO, EEO Poster Supplement, Family and Medical Leave Act (FMLA), and Employee Polygraph Protection Act (EPPA).

If you are unable to complete this application due to a disability, contact this employer to ask for an accommodation or an alternative application process.","$98,776 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Business Consulting,2009,Unknown / Non-Applicable
"Visualutions, Inc.
3.7",3.7,Remote,Data Engineer,"At Visualutions, we believe in the mission of Community and Public Health, and that everyone should have access to adequate health, dental, vision, and behavioral health services. For more than two decades, Visualutions has provided public health consulting services to community health centers across the country that are passionate about providing the very best healthcare and services to their patients.
Who you are.
A humble team player who gains satisfaction through the promotion and accomplishments of others on your team.
An ambitious self-starter with a learning mindset who is driven to develop your craft further and remain relevant.
A socially intelligent person excited about being part of a fast-growing company that’s trying to make a positive mark on the world.
Our Tech Stack
Azure products (ADF, Azure SQL, Azure Functions, etc.)
SQL Server
Tableau
SSRS
Visual Studios
Power BI
Microsoft Office Products
What You’ll Do.
Develop and manage Business Intelligence Solutions.
Analyze business processes and requirements.
Design and develop data solutions on the Microsoft stack, including Azure Data Factory, Azure Data Lake Storage, Azure Functions, and SQL.
Develop and maintain data models and ETL processes to support data integration and reporting.
Optimize data solutions for performance, scalability, and reliability.
Troubleshoot and resolve data-related issues, including data quality and data integration issues.
Document database architecture and data flows.
Additional duties as assigned.
Essential Skills.
Ability to understand and find appropriate applications for data and analysis results.
Moderate to extensive experience with Azure Cloud technologies.
Have a keen eye for detail and an aptitude for working with data.
Ability to contribute both independently and as part of an agile team.
Excellent listening, communication, interpersonal, and presentation skills.
Ability to thrive in a fast-paced, deadline-driven environment.
Strong understanding of relational database structures, theories, principles, and practices.
Experience creating SQL Queries, Tables, Stored Procedures, Views, Functions, and Triggers.
Working experience with Microsoft SQL Server (2012 +), Enterprise Manager, and admin tools.
Experience in troubleshooting and resolving database integrity issues, performance issues, security issues, etc.
Strong analytical, problem-solving, and troubleshooting skills.
Self-motivated, team player, capable of adapting to a dynamic environment with the ability to complete all assignments as required.
Excellent oral and written communication skills.
Desirable Skills.
Bachelor’s Degree in Business, Business Intelligence, or related fields preferred.
5+ years of professional experience collaborating with customers to develop and employ data solutions across their organization.
Experience in other programming languages other than SQL, such as Python, C#, etc..
Job Type: Full-time
Pay: $68,000.00 - $85,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Life insurance
Paid time off
Vision insurance
Experience level:
1 year
Schedule:
8 hour shift
Monday to Friday
Experience:
COSMOS: 2 years (Required)
Data Engineer: 2 years (Required)
T-SQL: 2 years (Required)
Azure Data Factory: 2 years (Required)
Language:
English (Required)
Work Location: Remote","$76,500 /yr (est.)",Unknown,Company - Public,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"DSM Infocom
4.1",4.1,"Chantilly, VA",Data Engineer,"Position- Data Engineer
Location: Chantilly or Reston, VA
Clearance: TS/SCI
As a Data Engineer, you will support robust and repeatable data manipulation, large scale infrastructure for data ingestion, and stunning data visualization for custom client applications.
Essential Functions:
Work collaboratively with data scientists, business consultants, and software engineers to create and deploy dynamic data applications that help our customers make meaningful business decisions.
Develop and deploy robust data pipelines and end-to-end systems
Participate in every stage of the engineering lifecycle, from ideation and requirements gathering through implementation, testing, deployment, and maintenance
Provide leadership and coordination for certain stages of the engineering lifecycle as needed
Perform other technical tasks as needed, including writing project reports, managing, implementing, and/or maintaining technical infrastructure, etc.
Ability and the willingness to tailor applications to a client’s business goals using an iterative methodology.
Ability to consider both long-term stability and scalability while taking a user-focused approach to development and deployment.
Communicate clearly both verbally and in writing to teammates and clients
Ability to work independently in a collaborative, dynamic, cross-functional environment
Travel to and work on-site at clients both local and non-local. Number of days at client site vary depending on project requirements
Required Skills
Bachelors or Master’s degree in Computer Science or related field, and 5 years of experience
TS/SCI
Ability to work with high-level mathematical concepts and associated code-form representations
Experience with Python, Java, Scala, Familiarity with R O/S: UNIX, Linux, Solaris, ssh, git.
Experience with Data manipulation, SQL, relational databases, and/or NoSWL databases.
Cloud: AWS, stack configuration and management
Focus areas: data manipulation, big data architecture, data structures, database administration, cloud platforms and SaaS, development operations (devops), data visualization and user experience.
Job Type: Full-time
Salary: $170,000.00 - $180,000.00 per year
Experience level:
4 years
Schedule:
8 hour shift
Security clearance:
Top Secret (Required)
Work Location: In person","$175,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,$100 to $500 million (USD)
"Photon
3.8",3.8,"Las Vegas, NV",Data Engineer,"Greetings Everyone

Who are we?

For the past 20 years, we have powered many Digital Experiences for the Fortune 500. Since 1999, we have grown from a few people to more than 4000 team members across the globe that are engaged in various Digital Modernization. For a brief 1 minute video about us, you can check

https://youtu.be/uJWBWQZEA6o

.

What will you do?

List out the Instructions

What are we looking for?

Seeking for a strong data analyst who can perform independent.

Good to have Prior experience in banking domain is plus and understanding the finance various data transactions.

Should be strong in the below:
Python

Pyspark

SQL

Airflow

Trino

Hive

Offshore Cordination

LLD

Agile Scrum

Linux

Openshift

Kubernentes

Superset

Optional skill set:
Linux

Openshift

Kubernentes

Superset","$120,545 /yr (est.)",5001 to 10000 Employees,Company - Private,Information Technology,Information Technology Support Services,2007,$100 to $500 million (USD)
"ESRI, Inc.
4.0",4.0,"Redlands, CA",Python Data Science Software Development Engineer I,"Overview:
ArcGIS Pro provides an industry-leading spatial data science platform, by building specialized geospatial data science tools joined with best of class open source components, such as Python. Be part of the team to expand this connection, by improving our integration with the Python ecosystem and tooling, making our platform more productive for developers who use it, and enhancing the relationship across our systems between the desktop and the cloud.

In this role, you will work with software developers and product engineers from both computer science and GIS backgrounds to find the best approaches for innovating for our customers, by both enhancing the capabilities they are familiar with while also looking to the future for trends which will enrich their ability to solve geospatial data science problems. This work will be building a system which meshes organizations existing data science workflows with the depth and power of the ArcGIS platform system of record.
Responsibilities:
Use Python, JavaScript, and C++ to build functionality which provides a Python programmatic interface for our customer
Support and build software that follows industry-standard design patterns, development approaches, and deployment models
Find, analyze, and fix issues in the software, both in the software we author and third party components
Collaborate with other developers, engineers, and product managers throughout the development process
Work effectively in an Agile Scrum team environment
Requirements:
1+ years of experience developing software in C++/Python or applicable academic work
1+ years of practical experience solving problems using a range of data science tools or applicable academic work
Experience developing software collaboratively
Self-motivated, life-long learner
Strong communication skills, including to non-technical audiences
Bachelor's degree in computer science, geography, statistics, mathematics, physics, or a similar field
Recommended Qualifications:
Experience with Notebooks and their use in workflows
Experience with DataFrames (Pandas or equivalent)
Experience producing data visualizations using tools, such as matplotlib
Experience handling massive batch/streaming data using big data tools, such as Apache Spark
Experience in building and optimizing supervised and unsupervised machine learning models, including deep learning and various other modern data science techniques
Experience with software development best practices, such as version control and code review
Experience with spatial and GIS concepts
Master's degree in computer science, geography, statistics, mathematics, physics or a similar field
The Company:
Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.

Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

If you need a reasonable accommodation for any part of the employment process, please email askcareers@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address.

Esri’s competitive total rewards strategy includes industry-leading health and welfare benefits: medical, dental, vision, basic and supplemental life insurance for employees (and their families), 401(k) and profit-sharing programs, minimum accrual of 80 hours of vacation leave, twelve paid holidays throughout the calendar year, and opportunities for personal and professional growth. Base salary is one component of our total rewards strategy. Compensation decisions and the base range for this role take into account many factors including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs.

A reasonable estimate of the base salary range is $72,800.00 - $124,800.00.

#LI-EL1","$98,800 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,1969,$1 to $5 billion (USD)
"Technuf, LLC
4.2",4.2,"Rockville, MD",Data Engineer,"Data Engineer
Who we are
Technuf, LLC is a Maryland based SBA certified 8(a) small business company providing leading-edge and proven technologies, industry vertical domain expertise and highly skilled and motivated professionals to achieve our customers’ mission critical business needs.
What we’re looking for
Technuf is seeking a skilled and experienced Data Engineer.
Responsibilities:
· Designing, implementing, and maintaining batch and streaming data pipelines between various SQL sources, including Aurora and SQL Server, and a target data lake in S3, as well as enterprise data stored in Redshift/Snowflake.
· Expertise in AWS cloud services, such as Kinesis, S3, Lake Formation, Glue, and Step Functions, to build scalable, reliable, and high-performance data pipelines that enable seamless data integration and empower data-driven insights.
· Data Pipeline Design: Design end-to-end data pipelines that efficiently extract, transform, and load data from SQL sources (Aurora, SQL Server) to the target data lake in S3 and the enterprise data in Redshift/Snowflake.
· Batch and Streaming Integration: Implement both batch and real-time streaming data integration solutions using AWS Kinesis and other relevant technologies.
· Data Transformation: Develop data transformation processes using AWS Glue or other ETL tools to harmonize, cleanse, and enrich data for analytical use.
· Data Lake Management: Oversee the setup and configuration of the data lake in S3, applying AWS Lake Formation best practices for data organization, cataloging, and access control.
· Data Governance: Ensure adherence to data governance and security standards across the data pipelines, guaranteeing data privacy and compliance.
· Performance Optimization: Continuously monitor and optimize the performance of the data pipelines, addressing bottlenecks and ensuring efficient data processing and delivery.
· Error Handling and Monitoring: Implement error handling mechanisms and robust data monitoring to identify and resolve data pipeline issues proactively.
· Data Cataloging and Lineage: Establish and maintain data cataloging and lineage information using AWS Glue Data Catalog to enable data discoverability and traceability.
· Documentation: Create comprehensive technical documentation, including design specifications, data flow diagrams, and operational guides.
· Collaboration: Collaborate with data analysts, data scientists, and other stakeholders to understand data requirements and deliver reliable data solutions.
· Data Governance: Ensure data governance principles are implemented throughout the data pipelines to maintain data quality and integrity.
Skills and Experience:
· At least six (6) years of experience working on AWS cloud-based batch and streaming data pipelines.
· Strong proficiency in AWS cloud services, including Kinesis, S3, Lake Formation, Glue, and Step Functions.
· In-depth knowledge of SQL databases, such as Aurora and SQL Server, and data lakes in S3, as well as enterprise data in Redshift/Snowflake.
· Hands-on experience with ETL tools, data transformation, and data integration techniques.
· Familiarity with data governance, data privacy, and security best practices in AWS environments.
· Strong problem-solving skills and the ability to troubleshoot complex data pipeline issues.
· Excellent communication and teamwork skills to collaborate effectively with crossfunctional teams.
· AWS certifications, such as AWS Certified Data Analytics - Specialty or AWS Certified Big Data - Specialty, are advantageous.
Education:
A Bachelor's Degree from an accredited college or university with a major in Computer Science, Information Systems, Engineering, Business, or other related scientific or technical discipline is required.
Benefits:
We offer a competitive pay and benefits package that includes generous paid-time-off including holidays, short-and-long-term disability; group health insurance including medical, dental and vision coverage, training and 401(k) retirement plan.
Technuf is an Equal Opportunity/Affirmative Action Employer. Members of ethnic minorities, women, special disabled veterans, veterans of the Vietnam-era, recently separated veterans, and other protected veterans, persons of disability and/or persons age 40 and over are encouraged to apply.
Job Type: Full-time
Pay: $85,000.00 - $93,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Experience level:
6 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Rockville, MD: Reliably commute or planning to relocate before starting work (Required)
Work Location: In person","$89,000 /yr (est.)",1 to 50 Employees,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Next College Student Athlete
3.5",3.5,Remote,Data Engineer,"Who We Are:
Who We Are:
IMG Academy is the world’s leading sports education brand, providing a holistic education model that empowers student-athletes to win their future, preparing them for college and for life. IMG Academy offers an innovative suite of on-campus and online experiences, providing growth opportunities for all student-athletes through:
Boarding school and camps, via a 600-acre state-of-the-art campus in Bradenton, Fla. (
IMGAcademy.com
)
Online coaching via the IMG Academy+ brand, with a focus on personal development through the lens of sport and performance (
IMGAcademy.com/Plus
)
Online college recruiting, via the NCSA brand, providing content, tools, coaching and access to a network of 40,000 college coaches (
ncsasports.org
)
Our team has a deep appreciation for the transformative power of sports and holistic personal development. Our leadership is actively investing in the growth of the organization. We continue to broaden and deepen our technology platform and team in pursuit of our vision for empowering youth sports and the path-to-college for student-athletes.
Position Summary:
The Data Engineer is responsible for implementing the technical direction of the Data Engineering team. This is a hands-on, individual contributor role operating on a cross-functional and skill-focused team. The Data Engineering team enables data- and insight-driven decision-making and planning by providing consistent, accurate and timely data to analysts, data scientists and business users. Working closely with platform development managers, Data Engineers design, implement and maintain data infrastructure used by Product and Platform Engineering teams in the form of data pipelines, data lakes and warehouses, business intelligence and visualization tools, and services for data quality and governance. Working with analysts and data scientists, they build custom data integrations, develop and deploy machine learning endpoints, and optimize the performance and scalability of customer-facing and internal data applications. The Data Engineer’s work provides teams with visibility into NCSA’s business performance, product delivery, and the outcomes student athletes, coaches and teams achieve to realize their goals. As one of the Data Engineers in the organization, you are empowered to make significant, impactful technical and cultural decisions, and help shape and guide the evolution of our data platform and company data strategy. Reporting to the Director, Data Engineering, the role requires deep expertise in the design, implementation, and continuous improvement of cloud-native data infrastructure and platforms.
Position Responsibilities:
You have experience (3-5 years) in data engineering, building capabilities with architecture, modeling (physical and logical), storage, resilience, and security.
You have experience in the mechanics of software engineering (preferably Python) practices to write Airflow DAGs and scripts.
You have deep expertise with cloud-based distributed data platforms, preferably in AWS.
You have experience developing data pipelines using Airflow, ELT design, optimization and maintaining data storage systems using S3 and Redshift or similar tools.
You have implemented batch and streaming data pipelines at scale and built platform components with automated testing suites using test-driven development principles for data.
You are familiar with relational databases (e.g. Postgres).
You have knowledge of SQL, Python and DBT.
You know how to create efficiency in data handling by tracking the lineage, maintaining the quality, and improving the discoverability of data.
Knowledge, Skills and Abilities:
Design, develop and maintain automated data pipelines to standardize and refine data collection for existing and new data sources used to power analytics and data science for business teams.
Develop extensive subject-matter expertise around individual and categories of data pipelines to establish operating standards and service-level agreements with analysts and data scientists.
Forecast data utilization and identify potential bottlenecks or optimization opportunities.
Apply test-driven development methods to data platform configuration and deployment.
Work with Software Engineering teams to adopt standard data platform components for their systems with the confidence that event data will be safely collected, stored, and transformed.
Lead technical conversations and decision-making around data architecture and implementation with Engineering teams, helping to identify opportunities and recommend technical solutions.
Partner with Analysts, Data Scientists and Data Program Managers to apply, implement and productionalize descriptive, predictive, and prescriptive statistical models on large datasets.
Define data operations approach and operating methodology for versioning, testing, security, test data management, data migrations, data quality, metadata, and documentation.
Dedicate meaningful time to research, evaluation and implementation of new tools and methods (Open Source and commercial) to meet changing organizational data needs and opportunities.
Serve as part of an on-call support rotation with other engineers to debug, troubleshoot and resolve data platform using the Incident Command System methodology.
Background Requirements:
Requires a background check upon offer.
Don’t meet every single requirement? We are dedicated to building a diverse, inclusive, authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfect with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.
Get to know us better:
www.imgacademy.com
IMG Academy provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",#N/A,1001 to 5000 Employees,Company - Private,"Arts, Entertainment & Recreation",Sports & Recreation,2000,Unknown / Non-Applicable
"Crisis Prevention Institute
3.0",3.0,"Milwaukee, WI",Senior Data Engineer,"Our Story:
Crisis Prevention Institute Inc. is the worldwide leader in evidence-based de-escalation and crisis prevention training, and dementia care services. Since 1980, we’ve helped train more than 15 million people within service-oriented industries including education, healthcare, behavioral health, long-term care, human services, security, corrections, corporate, and retail.

At CPI, we are dedicated to changing behaviors and reducing conflict for the Care, Welfare, Safety, and SecuritySM of everyone. We believe in the power of empathy, compassion, and meaningful connections. We believe personal safety and security are the antidotes to fear and anxiety. It’s a philosophy that is central to everything we do, and traces back to our beginning. It is what defines and differentiates us, and informs our core beliefs.
As a member of the team, you can expect to:
Make a difference through your work – You’ll be proud to tell your family and friends about what you do.
Gain significant career experience only obtained within a fast-growing organization – Entry-level roles through executive leadership.
Feel fulfilled and have fun – We work hard but make the time to build meaningful relationships and celebrate the wins.
The Role:
The Senior Data Engineer will focus on quality engineering best practices to meet and exceed internal and external client expectations. In this position, you will analyze, design, develop, test and document solutions supporting data integration, performance tuning, and data modeling to drive organization growth objectives. The Senior Data Engineer will define the standards for data architecture, platform architecture, and data quality and governance. This role is responsible for ensuring that the function is aligned with the overall CPI organization and continuously works to meet critical service levels in access, delivery and security.
What You Get To Do Everyday:
Co-architect CPI’s next-generation cloud data analytics platform.
Increase operating efficiency and adapt to new requirements.
Monitor and maintain the health of solutions generated.
Support and enhance our data-ops practices.
Provide task breakdowns, identify dependencies, and provide effort estimates.
Model data warehouse entities in Erwin.
Build data transformation pipelines with Data Build Tools (DBT).
Evaluate the latest technology trends and develop proof-of-concept prototypes that align with CPI opportunities.
Develop positive relationships with clients, stakeholders, and internal teams.
Understand business goals, drivers, context, and processes to suggest technology solutions that improve the organization.
Work collaboratively on creative solutions with engineers, product managers, and analysts in an agile like environment.
Perform, design, and code reviews.
Perform other position-related duties as assigned.
You Need to Have:
Bachelor’s degree in computer engineering, computer science, data science, or related field
Two years or more experience designing and implementing data warehouses in Snowflake
Eight years or more experience working with data modeling, architecture and engineering
Experience with all core software development activities, including requirements gathering, design, construction, and testing
Experience performing data transformation using DBT
Experience working with DQ products such as Monte Carlo, BigEye, or Great Expectations
Experience with Azure DevOps (Repos, Pipelines, Boards, Wiki, Test Plans)
Experience with formal software development methodologies including Software Development Life Cycle (SDLC), Agile or SCRUM
Experience building high-performance and highly reliable data pipelines
Experience Knowledge of data warehouse design patterns (star schema, data vault)
Experience building dashboards with business integrations tools
Knowledge of DataOps
with cloud-based compute, storage, integration and security patterns
Knowledge and understanding of RESTful APIs
Knowledge of current data engineering trends, best practices, and standards
Knowledge of SQL and Python
Ability to work in a collaborative environment
Ability to facilitate evaluation of technologies and achieve consensus on technical standards and solutions among a diverse group of information technology professionals
Ability to work in an organization driven by continuous improvement or with equivalent focus on process improvement
Ability to manage multiple, competing priorities and attain the best possible outcomes for the organization
Excellent verbal and written communication and effective listening skills
We'd Love to See:
Experience in delivering an end-to-end data analytics platform using modern data stack components
Experience with AI/ML
SnowPro Advanced Certification
DBT Analytical Engineer Certification
What We Offer:
Competitive salary
Comprehensive benefits package
401k
PTO
Health & Wellness Days
Paid Volunteer Time Off
Continuing education and training
Hybrid work schedule
Crisis Prevention Institute is an Equal Opportunity Employer that does not discriminate against any applicant or employee on the basis of age, race, color, ethnicity, national origin, citizenship, religion, creed, sex, sexual orientation, gender, gender identity, or expression (including against any individual that is transitioning, has transitioned, or is perceived to be transitioning), marital status or civil partnership/union status, physical or mental disability, medical condition, pregnancy, childbirth, genetic information, military and veteran status, or any other basis prohibited by applicable federal, state, or local law. The Company will consider for employment qualified applicants with criminal histories in a manner consistent with local and federal requirements. Our management team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities, and general treatment during employment.","$98,631 /yr (est.)",201 to 500 Employees,Company - Private,Education,Education & Training Services,1980,$25 to $100 million (USD)
"UNIVERSITY OF AZ FOUNDATION
3.8",3.8,"Tucson, AZ",Integration Data Engineer,"Integration Data Engineer plays a critical role in developing and maintaining The University of Arizona Foundation's Data Integration & Interoperability program.
We are seeking a detail-oriented and analytical individual with experience in master data management software, particularly Microsoft Master Data Services or other leading solutions. The ideal candidate will possess a deep understanding of data integration and ETL processes, with the ability to identify patterns, trends, and data discrepancies. As a collaborative team player, you will work closely with cross-functional teams to achieve common goals. Strong troubleshooting and organizational skills are essential in this role to effectively handle multiple tasks and resolve data-related issues in a timely manner.

Essential Functions/Major Responsibilities:

Ability to work in a fast-paced and cross-functional environment and manage multiple priorities across a mix of prioritized projects, operational and ad-hoc requests.
Build ETL pipeline using SQL Server Integration Services (SSIS) in Microsoft Visual Studio.
Knowledge of SQL and experience working with relational databases (e.g., SQL Server).
Strong problem-solving skills with the ability to analyze complex technical challenges and propose effective solutions.
Proficiency in C#, with a good understanding of commonly used object-oriented programming patterns and practices.
Ensure standards and guidelines are used to develop re-usable common frameworks, and processes that address repeatable tasks and organizational needs.
Participate in the prioritization and coordination of responses to requests for assistance or support from end users, including requests made via the Foundation’s help desk tracking system.

Interpersonal contacts:

This position has contact with employees of the Foundation and members of the UA Development Team and campus community who are engaged in the use of Foundation systems and data, as well as vendors of systems, software, and applicable services.

Specific Job Skills:

Knowledge in designing and building data integration solutions and ETL processes.
Strong analytical skills with the ability to identify patterns, trends, and data discrepancies.
Knowledge of SQL and experience working with relational databases (e.g., SQL Server).
Proficiency in C#, with a good understanding of commonly used object-oriented programming.
High attention to detail and accuracy in data handling and analysis.
Collaborative nature and willingness to work with cross-functional teams to achieve common goals.
Ability to troubleshoot and resolve data-related issues in a timely manner.
Strong organizational and time management skills to handle multiple tasks and priorities effectively.
Ability to learn quickly and adapt to changing technologies and business needs.
Proficiency in using version control systems like Git for code management.
Strong problem-solving skills with the ability to analyze complex technical challenges and propose effective solutions.
Willingness to learn and adapt to new technologies and industry trends.
Excellent written and verbal communication skills, with the ability to effectively interact with various stakeholders.
Ability to manage confidential information with discretion and tact required.
Ability to work independently with minimal supervision.

Minimum Qualifications:

Bachelor’s degree or higher and minimum of 1 year of professional work-related experience OR,
Three years of professional work-related experience OR,
Any equivalent combination of experience, training and/or education approved by Human Resources.
Preferred Qualifications:

Demonstrated experiencing implementing and/or supporting an organizational data management program.
Demonstrated experience supporting a data warehouse or business intelligence environment.
Proficiency in data integration and ETL tools, particularly Azure Data Factory, Azure Databricks, Azure Synapse Analytics, and other Azure data-related services is a plus.
Work Environment:

We welcome applications from remote candidates. However, preference will be given to local candidates.","$93,595 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,1985,Unknown / Non-Applicable
"Targa Resources
4.1",4.1,"Houston, TX",Data Analytics Engineer,"POSITION SUMMARY:
The Data Engineer will be responsible for operationalizing data and analytics initiatives for the company. They will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection. The Data Engineer is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, data architects, and data analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.
JOB RESPONSIBILITIES:
Develop, construct, test, and maintain data architectures or data pipelines
Ensure data architecture will support the requirements of the business
Discover opportunities for data acquisition
Develop data set processes for data modeling, mining, and production
Employ a variety of languages and tools to marry systems together
Recommend ways to improve data reliability, efficiency, and quality
Leverage large volumes of data from internal and external sources to answer business demands
Employ sophisticated analytics programs, machine learning, and statistical methods to prepare data for use in predictive and prescriptive modeling while exploring and examining data to find hidden patterns
Drive automation through effective metadata management using innovative and modern tools, techniques, and architectures to partially or completely automate the most common, repeatable, and tedious data preparation and integration tasks to minimize manual and error-prone processes and improve productivity
Propose appropriate (and innovative) data ingestion, preparation, integration, and operationalization techniques in optimally addressing data requirements
Ensure that the data users and consumers use the data provisioned to them responsibly through data governance and compliance initiatives
Promote the available data and analytics capabilities and expertise to business unit leaders and educate them in leveraging these capabilities in achieving their business goals
MINIMUM ESSENTIAL QUALIFICATIONS:
A bachelor's or master's degree in computer science, statistics, applied mathematics, data management, information systems, information science or a related quantitative field or equivalent work experience
At least five years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks
At least three years of experience working in cross-functional teams and collaborating with business stakeholders in support of a departmental and/or multi-departmental data management and analytics initiative
Knowledge and/or familiarity of the midstream services industry and data generated in support of business activities related to the gathering, compressing, treating, processing, and selling natural gas, NGLs and NGL products, and crude oil will be strongly preferred
Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, C++, Scala, and others
Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management
The ability to work with both IT and business in integrating analytics and data science output into business processes and workflows
Strong experience with database programming languages including SQL, PL/SQL, and others for relational databases, and knowledge and/or certifications on upcoming NoSQL/Hadoop-oriented databases like MongoDB, Cassandra, and others for nonrelational databases
Strong experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies.
Knowledge and/or experience in working with SQL on Hadoop tools and technologies including HIVE, Impala, Presto, others from an open source perspective and Hortonworks Data Flow (HDF), Dremio, Informatica, Talend, others from a commercial vendor perspective
Experience in working with both open-source and commercial message queuing technologies such as Kafka, JMS, Azure Service Bus, Amazon Simple Queuing Service, others, stream data integration technologies such as Apache Nifi, Apache Beam, Apache Kafka Streams, Amazon Kinesis, and others
Basic experience working with popular data discovery, analytics, and BI software tools like Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery
Strong experience in working with data science teams in refining and optimizing data science and machine learning models and algorithms
Basic experience in working with data governance/data quality and data security teams and specifically data stewards and security resources in moving data pipelines into production with appropriate data quality, governance and security standards and certification
Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Kubernetes, AWS Elastic Container Service and others
Familiarity with agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization
Strong written and verbal communication skills with an aptitude for problem-solving
Must be able to independently resolve issues and efficiently self-direct work activities based on the ability to capture, organize, and analyze information
Experience troubleshooting complicated issues across multiple systems and driving solutions
Experience providing technical solutions to non-technical individuals
Demonstrated team-building skills
Ability to deal with internal employees and external business contacts while conveying a positive, service-oriented attitude
Willingness to travel to company locations (up to 5%)

EQUAL EMPLOYMENT OPPORTUNITY:
Targa Resources provides equal employment opportunities based on merit, experience, and other work-related criteria and without regard to race, color, ethnicity, religion, national origin, sex, age, pregnancy, disability, veteran status, or any other status protected by applicable law. We also strive to provide reasonable accommodation to employees’ beliefs and practices that do not conflict with Targa’s policies and applicable law. We value the unique contributions that every employee brings to their role with Targa.","$105,001 /yr (est.)",1001 to 5000 Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,2006,$5 to $10 billion (USD)
"OrangePeople
4.1",4.1,"Orlando, FL",Senior Data Engineer,"We are seeking to hire a Contract Senior Data Engineer to work on a Media Ad Sales project. This position will work with the Decision Science Products and Science teams to design and implement a systems Ad Sales space. The work will involve various data engineering activities such as data acquisition and validation, designing and implementing ETL/ELT data pipelines, and designing and implementing databases. If you are ready to steer high-level projects to success, we are excited to have you on our team.
Responsibilities:
Work assignments may cover activities such as data requirements gathering, source-to-target mapping, data validation scripting, and review, developing and monitoring ETL/ELT data pipelines, designing and implementing database schema/tables/views, and producing datasets as input to science models and visualizations.
Technologies generally leveraged to fulfill the work include, but are not limited to, SQL, Python, Docker, Gitlab, Airflow, Lambda, Snowflake, and PostgreSQL.
Basic Qualifications:
3-5 years of experience with ELT/ETL data pipeline development and maintenance.
Proven experience and expertise using Python, SQL, and cloud storage (such as AWS S3).
Experience with developing in a multi-environment (Dev, QA, Prod, etc.) and DevOps procedures for code deployment/promotion.
Strong understanding of relational database design and proficiency utilizing a database such as PostgreSQL, or Snowflake.
Preferred Qualifications:
Experience working with large datasets and big data technologies, preferably cloud-based, such as Snowflake, Databricks, or similar.
Knowledgeable on cloud architecture and product offerings, preferably AWS.
Experience managing and deploying code using a source control product such as GitLab/GitHub.
Experience leveraging containerization technologies such as Docker or Kubernetes.
Hands-on knowledge of job scheduling software like Apache Airflow or UC4.
Required Education:
BS or equivalent work experience.
Benefits:
401(k).
Dental Insurance.
Health insurance.
Vision insurance.
We are an equal opportunity employer and value diversity, equality, inclusion, and respect for people.
The salary will be determined based on several factors including, but not limited to, location, relevant education, qualifications, experience, technical skills, and business needs.
Additional Responsibilities:
Participate in OrangePeople monthly team meetings, and participate in team-building efforts.
Contribute to OrangePeople technical discussions, peer reviews, etc.
Contribute content and collaborate via the OP-Wiki/Knowledge Base.
Provide status reports to OP Account Management as requested.
About us:
OrangePeople is an Enterprise Architecture and Project Management solutions company. Our most valuable asset is our people: dynamic, creative thinkers, who are passionate about doing quality work. As a member of the OrangePeople team, you will have access to industry-leading consulting practices, strategies & and technologies, innovative training & and education. An ideal Orange Person is a technology leader with a proven track record of technical achievements and a strong process/methodology orientation.
Job Type: Contract
Pay: $82.00 - $89.00 per hour
Schedule:
8 hour shift
Work Location: In person",$85.50 /hr (est.),51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2006,$5 to $25 million (USD)
"The Cincinnati Insurance Companies
3.9",3.9,Remote,IT - Data Engineer (Remote),"IT - Data Engineer (Remote) - (2300703)
US-Remote
Description

Make a difference with a career in insurance
At The Cincinnati Insurance Companies, we put people first and apply the Golden Rule to our daily operations. To put this into action, we’re looking for extraordinary people to join our talented team. Our service-oriented, ethical, knowledgeable, caring associates are the heart of our vision to be the best company serving independent agents. We help protect families and businesses as they work to prevent or recover from a loss. Share your talents to help us reach for continued success as we bring value to the communities we serve and demonstrate that Actions Speak Louder in Person®.
If you’re ready to build productive relationships, collaborate within a diverse team, embrace challenges and develop your skills, then Cincinnati may be the place for you. We offer career opportunities where you can contribute and grow.
Start your journey with us
Our IT department is currently seeking an experienced data engineer to build data pipelines that provide peace of mind for people by equipping them to make data-informed business decisions.
The pay range for this position is $65,000 - $132,000 annually. The pay determination is based on the applicant’s education, experience, location, knowledge, skills and abilities. Eligible associates may also receive an annual cash bonus and stock incentives based on company and individual performance.
Be Ready To:
develop reliable, reusable, automated and streamlined ETL code
analyze and organize raw data from multiple sources to produce requested or required data elements
design table structures and ETL to build performant data solutions that are scalable in a fast growing data ecosystem
create reconciliation procedures and data checks to ensure data quality
build in automated audit, balancing and controls
provide production support, including on-call rotation and technical assistance to end-user and IT staff
lead user requirements gathering and documentation designs
proactively conduct data investigations and assist business partners with complex data analysis and ad-hoc queries
lead application and technical architecture analysis, design and implementation, and ensure BI product fulfills requirements
lead efforts with data management and database specialists to troubleshoot and report issues
design new reporting applications to ensure reporting requests can be supported by the underlying data source
adhere to all metadata management and data quality standards by leading quality management reviews
understand configuration dependencies and interrelationships between data warehouse and business intelligence tools and designs; troubleshoot in the area with this knowledge
proactively identify, build and maintain relationships with business process owners and colleagues
identify changes in scope or work effort that could result in budgetary overrun or missing of delivery date, design and implement contingency
demonstrate expert problem solving capabilities
Be Equipped With:
proven experience in designing and implementing ETL processes (preferred tools: IBM's DataStage, SQLSvr SSRS, SAS)
proven experience distilling business requirements into data warehouse design artifacts such as a Facts Qualifier Matrix (FQM), source to target maps and star/snowflake schema data models
preferred five or more years experience with SQL, Data Modeling and Dimensional Modeling
understanding of enterprise technical landscape (property and casualty insurance background a plus)
experience with Test Driven Development (TDD)
knowledge of developing BI dashboards (preferred tools: IBM's Cognos, Microsoft's Power BI); creating data quality scorecards and data lineage
experience with agile teams
mentor development team members in design and development of BI solutions
strong team working skills, an analytical nature, self-motivated and excellent written and oral communication skills
ability to comprehend complex technical and logical concepts and adapt quickly to changes
ability to maintain own workflow and meet deadlines while managing parallel project deliverables with minimal direction
ability to create effective visual models to enable collective understanding of processes, data flow, user interaction and others as needed
prior reporting application support experience
track record of successfully architecting small, medium and enterprise-scale solutions
preferred three or more years of business requirements experience
You’ve earned:
a bachelor's degree or have equivalent experience in computer science or related discipline.
Enhance your talents
Providing outstanding service and developing strong relationships with our independent agents are hallmarks of our company. Whether you have experience from another carrier or you’re new to the insurance industry, we promote a lifelong learning approach. Cincinnati provides you with the tools and training to be successful and to become a trusted, respected insurance professional – all while enjoying a meaningful career.
Enjoy benefits and amenities
Your commitment to providing strong service, sharing best practices and creating solutions that impact lives is appreciated. To increase the well-being and satisfaction of our associates, we offer a variety of benefits and amenities. Learn more about our benefits and amenities packages.
Embrace a diverse team
As a relationship-based organization, we welcome and value a diverse workforce. We provide equal employment opportunity to all qualified persons without regard to race; creed; color; sex, including sexual orientation, gender identity and transgender status; religion; national origin; age; disability; military service; veteran status; pregnancy; AIDS/HIV or genetic information; or any other basis prohibited by law. Learn More.","$98,500 /yr (est.)",1001 to 5000 Employees,Company - Public,Insurance,Insurance Carriers,1968,$5 to $10 billion (USD)
"symplr
3.5",3.5,United States,SQL Data Software Engineer,"Overview:
A SQL Data Software Engineer is responsible for making updates to customer data based on Support tickets created specifically for customer requests. Some of these requests involve writing T-SQL scripts to make the updates to customer data. Other requests involve running internal tools to make changes, import/export data, create reports, etc. In this role, you will be responsible for completing these requests in a timely manner, while taking care to ensure the changes completely align with the customer request. You will primarily work with internal teams but may be required to communicate with customers on occasion.
Duties & Responsibilities:
Create SQL queries to resolve reported issues/requests, and to provide customers with data not readily available in reporting options
Build and Analyze SQL queries with a constant eye on opportunities for optimization and/or automation of frequent requests
Be a champion for department initiatives and values ensuring all actions promote the department's mission statement
Develop high-quality solutions utilizing best of breed technology solutions
Assist Customer Support/IT/DevOps teams in troubleshooting SQL performance issues
Must be a self-starter always looking for opportunities to assist or improve
Other duties and projects as assigned
Skills Required:
Excellent time management, resource organization and priority establishment skills, and ability to multi-task in a fast-paced environment
Strong leadership and interpersonal skills that foster effective and efficient team productivity
Outstanding critical thinking and problem-solving skills
Excellent communication skills, both written and verbal
Demonstrated skills and abilities needed to coordinate, facilitate, and participate in a collaborative approach to the completion of tasks or assignments
Strong Object-Oriented design and implementation skills
Excellent analytical and problem-solving skills
Demonstrated ability working with SQL servers, Microsoft Excel for reporting, and ability to write and maintain complex SQL queries

Qualifications Required:
Every organization has a culture, whether they mean to or not, so why not be intentional about it?

Together, if we shape our intentions, actions, and interactions around a common, purposeful culture, we are able to quickly achieve more, attract others who help realize our goals, and thrive in our professional relationships.

Bachelor's Degree in Computer Science or a related field or an equivalent combination of relevant education and experience
Demonstrated knowledge, education, experience and/or training necessary in the following areas:
SQL Server
Microsoft Excel
HTML, JavaScript, CSS (Preferred)
ASP.NET, XML, jQuery, JSON and Ajax (Preferred)
C# or other Object-Oriented Programming Language (Preferred)
Object-Oriented design and implementation skills (Preferred)
Familiarity with the practical application of SQL databases
Familiarity with Azure DevOps
Min: USD $80,000.00/Yr. Max: USD $95,000.00/Yr.","$80,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2006,$100 to $500 million (USD)
The Swift Group,#N/A,"Herndon, VA",Data Visualization/Tableau Engineer,"Job Description
We are looking for a Tableau developer to join our Prime program. The Developer will join a team supporting data warehousing, business intelligence and reporting professionals. They will gather and analyze business reporting and data requirements; Design highly professional reports, dashboards and visual representation of business and warehouse data for process owners and executive leadership; Develop ad-hoc queries and reports based on requirements gathered from customers utilizing complex, custom-built SQL queries for the purposes of analytical reporting; Test and troubleshoot report and dashboard functionality, validate data and create test data and table structures through use of SQL; Performance tune SQL statements executed by reports and dashboards as required.
Required Skills
Develop and maintain Tableau dashboards, rich interactive visualizations, and reports using backend relational database
Design and develop efficient and optimized Tableau reports by leveraging best practices for data visualization and data blending.
Ensure appropriate data access, data security, and data governance policies are in place for Tableau reporting.
Experience in troubleshooting and resolving issues related to Tableau reports and data sources.
Strong Structured Query Language (SQL) skills and experience optimizing queries.
Experience in developing automated Tableau reports using Tableau Server and Tableau Desktop
About iC-1 Solutions, LLC.
iC-1 Solutions LLC. is a wholly owned subsidiary of The Swift Group. The Swift Group is a privately held, mission-driven and employee-focused services and solutions company headquartered in Reston, Virginia. Founded in 2019, The Swift Group supports Civilian, Defense, and Intelligence Community customers, across the country and around the globe.

The Swift Groups is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status, or any other protected class.","$91,021 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2019,Unknown / Non-Applicable
ZENOTIS,#N/A,"West Pittsburg, PA",Python Data Engineer,"Role: Python – Data Engineer
Type – Fulltime
Location – Pittsburg,PA (Onsite)
Job description:
· Design, develop and implement Machine Learning models.
· Use Python programming language to perform automated tasks to check Capital Analysis and Review.
· Use moules like Pandas, NumPy, for data manipulation and analysis.
· Use Machine Learning tools such as Apache Airflow to perform automated tasks by writing programs in Python.
· Use SQL to retrieve data from Source databases and form a presentation.
· Run models(Machine Learning Models) in Jupyter Hub to run the scripts written in Python.
· Work on creating models that predicts or flags Anatolia in capital risk assessment using Python and Jupyter hub.
· Use Oracle SQL Developer to look and dig into production tables so that automated workflows can be created by establishing database connectivity.
· Revising python scripts by understanding the functionality based on business requirements.
· Attend business meetings to understand CCAR road map to get technical requirements.
Job Type: Contract
Salary: $95,000.00 - $100,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Vision insurance
Experience level:
7 years
Schedule:
Monday to Friday
On call
Work Location: In person","$97,500 /yr (est.)",Unknown,Company - Public,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"CPChem
3.9",3.9,"The Woodlands, TX",Entry Level Data Engineer 2023/2024,"You may not realize it, but you’ve likely used a product today made possible by the plastics and chemicals manufactured by Chevron Phillips Chemical. From medical supplies and electronics to food packaging and cosmetics, we create the building blocks for more than 70,000 consumer and industrial products.

Even as a global company with 5,000 employees, we maintain a “small company feel” and uphold a culture of respect, diversity, and inclusion. Ask any Chevron Phillips Chemical employee what they like best about their job, and universally, the answer is “the people I work with!” We value work-life balance, and love to see our employees thrive both professionally and personally. There has never been a better time to work for Chevron Phillips Chemical. If you’re ready to grow with us and become part of our vision of being the premier Chemical Company, apply today!

Whether you are looking to work in research and development, engineering or a business function, we offer you the chance to hit the ground running from day one. We give you the freedom to design your own career path and provide you with the tools and training you need to develop to your full potential.

You have your degree. Now you want to build your skills as you apply what you have learned in the classroom. Our Graduate Rotation and Development Program (GRAD) is a challenging two-year development opportunity designed to help you obtain valuable company knowledge, hands-on experience and expertise in your chosen discipline.

We are hiring innovative and motivated Computer Science professionals to join our Graduate Rotation and Development program (GRAD) for the upcoming year. If you thrive on problem solving, project management and teamwork in a diverse workplace, the Chevron Phillips GRAD program is the right opportunity for you!

The Data Engineer will work on within an agile team to ensure data requirements are met for the value case. Involved in building data pipelines to support multiple data analytics/science/ business intelligence teams. The Data Engineer will develop systems for ingesting and processing data.

Responsibilities:
Analyze and organize raw data
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct complex data analysis and report on results
Prepare data for prescriptive and predictive modeling
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects

Minimum Qualifications:
18 years of age or older
Legally authorized to work in the United States and will not now or in the future require sponsorship by the employer
Bachelor’s Degree in Computer Science, Finance, Math, Engineering, Statistics, or related discipline
Relevant class work including data warehousing tools, techniques and technology

Preferred:
Familiarity with statistical concepts desired
Exposure to big data processing and using databases (SQL, Azure DataBricks, or similar)
Basic Knowledge of SQL query design and tuning for performance and accuracy
Basic knowledge of Python, R, or other data relevant scripting languages

Chevron Phillips Chemical offers competitive salaries, a comprehensive benefits package and at most locations, alternate work schedules.

Paper resumes will not be accepted. All job seekers must go to the web site to be considered for positions. If you are interested in applying for this position and need an accommodation to apply, please contact our Human Resources Service Center at 1-800-446-1422, option 4.

Chevron Phillips Chemical Company is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, ancestry, age, disability, veteran status or marital status.

To all recruitment agencies: We are not responsible for any fee related to unsolicited resumes from 3rd party staffing and recruiting agencies (whether submitted through this website or sent directly to employees) unless a written agreement is in place between the agency and Chevron Phillips Chemical Company LP (“Company”) and an authorized Company representative makes a written request to the agency to assist with this requisition. Similarly, no fee will be paid for candidates who apply and claim to be represented by an agency. Any unsolicited resumes, CVs, or other candidate information submitted by an agency will become the property of Company, and no fee will be paid in the event such candidate is hired.

Travel Requirements: Up to 5%
Eligibility for Relocation: Yes
Closing Date: 10/06/2023


Nearest Major Market: Houston
Job Segment: R&D Engineer, Entry Level Engineer, Database, Computer Science, Engineering, Entry Level, Technology","$55,066 /yr (est.)",1001 to 5000 Employees,Company - Private,Manufacturing,Chemical Manufacturing,2000,$10+ billion (USD)
"Infinitive Inc
3.3",3.3,"Ashburn, VA",AWS Data Engineer,"About Infinitive:
Infinitive is a transformation and technology consultancy that enables global brands to deliver results through insights, innovation, and efficiency. We possess deep industry and technology expertise to drive and sustain adoption of new capabilities. We match our people and personalities to our clients' culture while bringing the right mix of talent and skills to enable high return on investment.
Infinitive has been named “Best Small Firms to Work For” by Consulting Magazine 6 times. Infinitive has also been named a Washington Post “Top Workplace,” Washington Business Journal “Best Places to Work,” and Virginia Business “Best Places to Work.”
About this Role:
Infinitive is looking for candidates who are accountable, passionate, assertive, proactive, open & honest, results oriented, and adaptable. The ideal candidate will drive client growth, foster deep relationships, drive account/client financial management, and lead end to end execution of projects/programs.
We are currently looking for a AWS Engineer who will:
Write effective, scalable code and be able to improve responsiveness and overall performance of the code
Support Data Warehouse development operations, Data Analytics and Visualizations development as well as developing reports and dashboards
Apply natural language processing, data mining techniques, statistical analysis, and machine learning integrated with our analytical and visualization tools.
Support Analytics and Business Intelligence development while providing development support to a team of data analysts.
Integrate user-facing elements into applications
Improve functionality of existing systems
Additionally, the ideal candidate has:
3+ years of experience developing with object-oriented programming concepts (Python, R)
3+ years of experience working with distributed scalable Big Data storage, including AWS EMR, Spark, Terraform, Scala.
3+ years of experience with data query and analysis using relational databases and query languages (SQL)
Implementation knowledge of, or desire to learn AWS / Azure data science capabilities.
Ability to test and debug programs/tools/applications
Fluent in Python libraries for Data Analysis (Pandas, Numpy, etc.)
Experience with Open Source technologies such as Apache Tomcat and Web Server, Elasticsearch, etc.
Ability to maintain source code and utilize configuration management systems such as CodeFoundry or GitLab
Technical degree in computer science or related field (preferred)
Experience working in an Agile environment
Background in management consulting (preferred)
Desire to become an AWS Certified architect / engineer
Strong analytical, conceptual, organizational, and problem-solving skills.
Have a Kick-Ass Attitude
Desire to Be Great and strive for continual growth
Required Qualifications:
Bachelor’s degree in business or related field of study.
Excellent verbal and written communication skills.
The ability and desire to function in a hybrid capacity, supporting both delivery and sales.
Experience managing multiple projects/programs in a fast-paced, dynamic, and sometimes ambiguous environment.
Desire and ability to provide mentorship and consistent, timely feedback to support the growth and success of others.
Desired Qualifications
Located in the DC Metro, Richmond, or New York City area with the ability to regularly be onsite in client offices in McLean, Richmond, or NYC.
Previous experience at a small-midsize consulting firm.
Applicants for employment in the U.S. must possess work authorization which does not require sponsorship by the employer for a visa.
Infinitive is an Equal Opportunity Employer.

q3YJaiLrEw","$100,376 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,2003,$25 to $100 million (USD)
"Deloitte
4.0",4.0,"Washington, DC",Data Engineer,"Position Summary
Data Engineer
Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client’s most complex business problems. Join our team and play a key role in helping to design our clients’ roadmap to the future and help transform the Federal marketplace.

Work you’ll do
The Data Analytics Architect will have overall responsibility of planning how work within different teams will integrate into one solution. The Data Analytics Architect will also have overall responsibility of being the primary representative on all architecture matters and the leading member of the Architecture Team. The Architect will:
Work closely with various software development team(s) to migrate and architect data to meet client needs
Work directly with clients to validate migrated data
Work with Agile development teams to understand changes and their impacts towards data migration efforts
Leading developers, managing database administrators’ workload and activities, among other tasks.
Create and manage schedules for data management (e.g. migration, integration, etc.) efforts
Build processes and scripts required to transform and stage data necessary to develop products and analyses
The team
Deloitte’s Government and Public Services (GPS) practice – our people, ideas, technology and outcomes—is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications
Required:
Must have an active Secret clearance
2+ years of hands-on experience with ETL/data pipeline development experience, leveraging industry-standard tools, ideally Informatica
2+ years of experience working with relational databases and data lakes, with an emphasis on data warehousing, performance tuning, and analytics use cases
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
Preferred:
Experience integrating them into custom web applications
Data modeling and solution design experience
Familiarity programming in languages commonly used for data management and data science/statistics, such as Python
A general interest in relevant emerging technologies such as cloud-native services, and a constant thirst to further your own technical abilities
Experience working in an Agile development environment
Hands-on experience with full suite of software lifecycle tools (Confluence, Jira, Stash, Jenkins, Artifactory, etc.)
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters.
Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.
Our people and culture

Our diverse, equitable, and inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our client most complex challenges. This makes Deloitte one of the most rewarding places to work. Learn more about our inclusive culture.
Our purpose

Deloitte’s purpose is to make an impact that matters for our clients, our people, and in our communities. We are creating trust and confidence in a more equitable society. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. We are focusing our collective efforts to advance sustainability, equity, and trust that come to life through our core commitments. Learn more about Deloitte's purpose, commitments, and impact.
Professional development

From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Requisition code: 157467","$103,786 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,1850,$10+ billion (USD)
"Creative Information Technology India
3.3",3.3,"Falls Church, VA",AWS Data Engineer,"Role and Responsibilities
Designing, implementing, and maintaining batch and streaming data pipelines between various SQL sources, including Aurora and SQL Server, and a target data lake in S3, as well as enterprise data stored in Redshift/Snowflake.
Expertise in AWS cloud services, such as Kinesis, S3, Lake Formation, Glue, and Step Functions, to build scalable, reliable, and high-performance data pipelines that enable seamless data integration and empower data-driven insights.
Data Pipeline Design: Design end-to-end data pipelines that efficiently extract, transform, and load data from SQL sources (Aurora, SQL Server) to the target data lake in S3 and the enterprise data in Redshift/Snowflake.
Batch and Streaming Integration: Implement both batch and real-time streaming data integration solutions using AWS Kinesis and other relevant technologies.
Data Transformation: Develop data transformation processes using AWS Glue or other ETL tools to harmonize, cleanse, and enrich data for analytical use.
Data Lake Management: Oversee the setup and configuration of the data lake in S3, applying AWS Lake Formation best practices for data organization, cataloging, and access control.
Data Governance: Ensure adherence to data governance and security standards across the data pipelines, guaranteeing data privacy and compliance.
Performance Optimization: Continuously monitor and optimize the performance of the data pipelines, addressing bottlenecks and ensuring efficient data processing and delivery.
Error Handling and Monitoring: Implement error handling mechanisms and robust data monitoring to identify and resolve data pipeline issues proactively.
Data Cataloging and Lineage: Establish and maintain data cataloging and lineage information using AWS Glue Data Catalog to enable data discoverability and traceability.
Documentation: Create comprehensive technical documentation, including design specifications, data flow diagrams, and operational guides.
Collaboration: Collaborate with data analysts, data scientists, and other stakeholders to understand data requirements and deliver reliable data solutions.
Data Governance: Ensure data governance principles are implemented throughout the data pipelines to maintain data quality and integrity.

Education Qualification
Bachelor's Degree from an accredited college or university with a major in Computer Science, Information Systems, Engineering, Business, or other related scientific or technical discipline.

General Qualification
At least six (6) years of experience working on AWS cloud-based batch and streaming data pipelines.
Strong proficiency in AWS cloud services, including Kinesis, S3, Lake Formation, Glue, and Step Functions.
In-depth knowledge of SQL databases, such as Aurora and SQL Server, and data lakes in S3, as well as enterprise data in Redshift/Snowflake.
Hands-on experience with ETL tools, data transformation, and data integration techniques.
Familiarity with data governance, data privacy, and security best practices in AWS environments.
Strong problem-solving skills and the ability to troubleshoot complex data pipeline issues.
Excellent communication and teamwork skills to collaborate effectively with cross functional teams.
AWS certifications, such as AWS Certified Data Analytics - Specialty or AWS Certified Big Data - Specialty, are advantageous.","$98,591 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,1996,$25 to $100 million (USD)
"Wahl Clipper Corporation
4.1",4.1,"Sterling, IL",Associate Data Engineer,"WAHL EMPOWERS PEOPLE TO BE THEIR BEST!
Wahl Clipper Corporation, a global manufacturer of branded Consumer and Professional products, has an exciting opportunity for an IT professional to fill the role of Associate Data Engineer at our Global Headquarters in Sterling, Illinois.
As an Associate Data Engineer at Wahl Clipper Corporation, you will be instrumental in building, maintaining, and optimizing our data pipelines. You will work closely with data scientists, analysts, and other stakeholders to ensure data availability, quality, and integrity. This role provides a unique opportunity for a budding engineer to grow, learn, and contribute to a data-driven culture. The Associate Data Engineer reports directly to the Global Director of Applications, BI & Analytics. There are no direct reports to this position.
ESSENTIAL FUNCTIONS:
Collaborate with data architects and IT teams to build and maintain data infrastructure.
Assist in designing, constructing, installing, and maintaining large-scale processing systems and other infrastructure.
Ensure that all systems meet the business/company requirements, as well as industry practices.
Integrate new data management technologies and software engineering tools into existing structures.
Develop and implement data retrieval and storage strategies.
Create and maintain optimal data pipeline architecture.
Assemble and process complex datasets that meet both functional and non-functional business requirements.
Work with data and analytics experts to strive for greater functionality in our data systems.
Provide support to our data scientists and analysts, ensuring data accessibility and quality.
MINIMUM REQUIREMENTS:
Bachelor's degree in Computer Science, Engineering, Mathematics or related field.
1-3 years of experience in a data engineering or similar role.
Proficient understanding of distributed computing principles.
Experience with big data tools like Hadoop, Spark, or Kafka.
Familiarity with data architectures, including ETL processes, warehousing, and data integration.
Knowledge of SQL and experience with relational databases.
Experience with Data Warehousing platforms like Snowflake and Azure Synapse.
Experience with AWS, Azure, GCP, or similar cloud platforms is a plus.
Strong analytical and problem-solving skills.
Experience with data pipeline and workflow management tools like SSIS and Azure Data Factory preferred.
Familiarity with data visualization tools and platforms preferred.
Good understanding of data quality principles and best practices.
Why Wahl?
We are proud to celebrate over 100 years as the standard for grooming products used by barbers and hairdressers all over the world. Professionals and home users have relied on our innovative clippers, trimmers and personal care products for an entire century.
Today, the fourth generation of the Wahl Family remains deeply rooted in the daily operations and management of the organization. Living beyond the footsteps of their great-grandfather, the family continues to ensure that everything that Wahl produces aligns with the same core family values.
When you work at Wahl, you join a community that is proud of its heritage of excellence and ground-breaking innovations and a company that focuses on creating value for the customer and long-term growth.
Perks & Benefits:
BCBSIL Medical coverage offered as low as $11 per week, INCLUDING pharmacy
In & Out-of-network BCBSIL Dental coverage, with orthodontics for as low as $4 per week
In & Out-of-network BCBSIL by EyeMed, Vision coverage, $3 per week for family coverage
Employer funded health savings account -up to $2000!
Biometric testing with wellness credits
401(k) and Roth 401(k) with generous company match
Profit Sharing
Tuition Reimbursement program - up to $10,000 per calendar year
Scholarship Program
Daycare discounts
Free Employee Assistance Program (EAP) with legal consultative services and discounts
Company paid Life Insurance
Company paid Short-Term Disability/Long Term Disability
10 paid holidays per year
Casual work environment

https://www.youtube.com/watch?v=9kHEqxtZYaU","$60,595 /yr (est.)",1001 to 5000 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1919,$100 to $500 million (USD)
"Amazee Global Ventures Inc
5.0",5.0,"Dallas, TX",Sr. Data Engineer,"This is NOT a C2C Role. This is the Full-Time/ Contract W2 opportunity with Amazee Global Ventures Inc.
Responsibilities
Under limited supervision, designs, develops, tests, implements, documents, and supports operational and analytical reporting platforms. Leverages modeling tool and patterns to design, develop, and deploy data models, data ingest/ egress flows, ELT/ETL flows, and metadata. Is in the process of broadening those capabilities, as well as broadening knowledge of source and target technologies, as well as related datastore, data warehouse, and cloud technologies and processes,
to execute responsibilities.
Creates and supports the ELT process to prepare data from source systems for reporting, and also place it into operational and analytical reporting databases.
Performs ELT design and testing, including data design, ELT architecture, metadata, and repository creation
Works with business and IT stakeholders to optimize reporting information by refining business requirements and populating the data warehouse table structure
Designs, develops, and maintains relational databases for data storage and data mining
Assists with the creation of data warehouse schematics and layouts
Implements effective metrics and monitoring processes, as directed
Leverages existing standards, processes, and procedures for data warehousing systems
Acts as a resource for colleagues with less experience
Performs other duties as assigned
Technical Skills
Required
Erwin Data Modeler (or equivalent)
Data analysis skills
SQL Server
SQL writing skills
Amazee Global Ventures Inc, is an equal opportunity employer. We will not discriminate and will follow all measures to ensure no discrimination in employment, recruitment, advertisements for employment, compensation, termination, upgrading, promotions, and other conditions of employment against any employee or job applicant on the bases of race, color, gender, national origin, age, religion, creed, disability, veteran's status, sexual orientation, gender identity or gender expression. We are committed to providing an inclusive and welcoming environment for all members of our staff, clients, volunteers, subcontractors, vendors, and clients.
Job Type: Full-time
Salary: $50.00 - $60.00 per hour
Experience level:
10 years
11+ years
9 years
Work Location: In person",$55.00 /hr (est.),1 to 50 Employees,Company - Public,#N/A,#N/A,2019,Less than $1 million (USD)
"Visa
4.1",4.1,"Austin, TX",Senior Tableau Data Engineer,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

To ensure that Visa’s payment technology is truly available to everyone, everywhere requires the success of our key bank or merchant partners and internal business units. The Global Data Science group supports these partners by using our extraordinarily rich data set that spans more than 3 billion cards globally and captures more than 100 billion transactions in a single year. Our focus lies on building creative solutions that have an immediate impact on the business of our highly analytical partners. We work in complementary teams comprising members from Data Science and various groups at Visa. To support our rapidly growing group we are looking for data engineers who are equally passionate about the opportunity to use Visa’s rich data to tackle meaningful business problems.

This position will be part of VCA (Visa Consulting & Analytics) function in building and maintaining global data assets and engineering solutions. In this role, you will be responsible for helping to develop a global engineering and solutions team focused in standardized development of Consulting Solutions. You will partner closely with Global stake holders in Visa consulting, data Science and data engineering teams. You will get chance to leverage your strategic planning, business analysis and technical knowledge of data engineering, tools and data architecture solutions. In addition to managing our portfolio of data engineering assets and solutions globally, you will play key roles in building relationships with Consulting partners to develop effective market response strategies. You will also be a hands-on expert able to direct & navigate both data engineering and data science teams to build effective data engineering solutions.
Essential Functions
Exposure working with Global teams & Fortune 500 companies and possess strong experience working directly in client facing roles.
Execute and manage large scale ETL processes to support development and publishing of reports, Datamart’s and predictive models.
Strong Data Analytical and Visualization skills along with experience in self-service reporting tools like Tableau or Power BI with KPIs and facilitate Visa Consulting engagements including data exchange.
Deliver small to medium complexity dashboard projects either individually or as part of a project team.
Use design prototyping rigor and consultative best practices with our stakeholders
Develop solutions leveraging agile principles
Provide operational production support for the dashboards on Tableau Server.
Should have strong problem-solving capabilities and ability to quickly propose feasible solutions and effectively communicate strategy and risk mitigation approaches to leadership.
Build and maintain high performing ETL processes, including data quality and testing aligned across technology, internal reporting and other functional teams
Create data dictionaries, setup/monitor data validation alerts and execute periodic jobs like performance dashboards, predictive models scoring for client’s deliverables
Define and build technical/data documentation and experience with code version control systems (e.g. git). Ensure data accuracy, integrity and consistency
Find opportunities to create, automate and scale repeatable financial and statistical analysis for Visa Consulting and Analytics.
Collaborate with Data Engineering teams in North America and other Global regions to production and maintenance of key data assets.
Strong written, verbal, and interpersonal skills needed to effectively communicate technical insights and recommendations with business customers and leadership team.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:

5 or more years of relevant work experience with a Bachelors Degree or at
least 2 years of work experience with an Advanced degree (e.g. Masters, MBA,
JD, MD) or 0 years of work experience with a PhD

Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD
Minimum of 6+ years of work experience with a Bachelor's Degree or 4+ years of experience with a Master’s or Advanced Degree in a Quantitative field such as Statistics, Mathematics, Operational Research, Computer Science, Economics, Engineering, or equivalent with analytics expertise in applying statistical solutions to business problems
Technical expertise in leading business intelligence and data visualization projects
Working knowledge of Hadoop ecosystem and associated technologies, (For e.g. Apache Spark, MLlib, GraphX, iPython, sci-kit, Pandas etc.)
Good business acumen to orient data analysis to business needs of clients.
Ability to translate data and technical concepts into requirements documents, business cases and user stories.
Good understanding of agile working practices and related program management skills.
Good communication and presentation skills with ability to interact with different cross-functional team members at varying levels
Ability to learn new tools and paradigms as data science continues to evolve at Visa and elsewhere.
Demonstrated intellectual and analytical rigor, team oriented, energetic, collaborative, diplomatic, and flexible style.
Intellectually curious and continuously striving to learn.

Technical skills:

A strong BI/data visualization portfolio and hands-on experience
Expert proficiency with visualization software, preferably Tableau, is required
Knowledge of interactive data visualization best practices
Experience leading design discovery meetings with end-users is preferred
Excellent grasp of the design thinking and the prototyping process
Have a good understanding of data management systems and processes
within the ecosystem (source systems, data feeds, reference data
management, ETL, Data Warehouses and Marts, data cube design, etc.) and
has experience working with SQL or Tableau Prep. Experience with any script
language (R/Python) is a plus.
Experience working in an Agile or fast-paced and dynamic environment is a
plus
Experience working with any prototyping tool
Visa experience or knowledge of payments industry is a plus, but not
mandatory

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$102,342 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"INADEV
4.4",4.4,"McLean, VA",Sr Data Engineer,"Description:

*****CANDIDATES MUST BE OPEN TO A HYBRID SCHEDULE (2-3 DAYS) IN MCLEAN, VA*****
Formed in 2011, INADEV is focused on its founding principle to build innovative customer-centric solutions incredibly fast, secure, and at scale. We deliver world-class digital experiences to some of the largest federal agencies and commercial companies. Our technical expertise and innovations are comprised of codeless automation, identity intelligence, immersive technology, artificial intelligence/machine learning (AI/ML), virtualization, and digital transformation.
POSITION DESCRIPTION:
Prepare data migration strategy, Integration plans, DB Performance, business sign-off plan, Live Confidence Plan (LCT plan - all data is migrated successfully).
Provide support for data migration, data engineering, and integration of existing systems.
Developing and integrating multiple data types across a range of data sets and sources.
Performing day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner.
Evaluate current system designs and identify areas for improvement to create a system that is highly available and has low data latency.
Plan and design the integration of various source systems and the migration of data between systems.
Build and implement the source system integration and data migration plan.
Developing, managing, manipulating, storing and parsing data across a data pipeline for variety of target sources and data consumers
Writing code to ensure the performance and reliability of data extraction and processing
Supporting continuous process automation for data ingestion
Assisting with the maintenance of applications and tools that reside on the data driven systems (upgrades, patches, configuration changes, etc.)
Working with program management and engineers to implement and document complex and evolving requirements
Actively and collaboratively participating as a member of a cross-functional Agile/Scrum team while following all Agile/Scrum best practices
Advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
Helping cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
Demonstrating significant technical competence and ownership to broad audiences while driving progress on company strategic objectives at multiple levels.
Generating and articulating technical strategy to diverse audiences, both technical and non-technical.
PHYSICAL DEMANDS:
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions
INADEV Corporation does not discriminate against qualified individuals based on their status as protected veterans or individuals with disabilities and prohibits discrimination against all individuals based on their race, color, religion, sex, sexual orientation/gender identity, or national origin.
Requirements:

NON-TECHNICAL REQUIREMENTS:
Ability to pass a 7 year background check and have the ability to obtain a U.S. Government clearance.
Must be local to the DC/MD/VA area and be open to working a HYBRID Schedule (2-3 days) in McLean, VA.
Must possess good communication (written/verbal) skills and the ability to perform stakeholder management
MANDATORY REQUIREMENTS:
Must have a Bachelor's Degree in a technical discipline and 10+ years pertinent experience with the design, management, and solutioning of large, complex data sets and models.
Must have at least 2+ years of experience working with/in public cloud environments.
Must have proven experience leading data migration project from on-prem to cloud.
Must have extensive experience/knowledge of data integration.
Must have experience with Cloud Native databases
Experience with Enterprise Architecture & Distributed Systems
DESIRED SKILLS:
Experience with AWS DMS/MGN
Technical knowledge of Datalake/DeltaLake/Lakehouse","$118,954 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,2011,$5 to $25 million (USD)
DataDelivers LLC,#N/A,"Schaumburg, IL",Big Data Engineer I,"The Big Data Engineer's primary responsibilities are to build, integrate data from various resources, and support DataDelivers big data ecosystem. The Engineer will work closely with other teammates to design optimum solutions using best practices. The Engineer is responsible to ensure the data ecosystem is built to be highly scalable and responsive through writing queries and ensuring optimal performance and availability.

The Big Data Engineer also creates ETL, batch, and automated processes on top of big datasets and creates big data warehouses to be used for reporting and analysis by DataDelivers data scientists. This role will provide build and support ingestion and connection solutions for the businesses' data science teams as well as outside partners and clients.

Responsibilities:
Work closely with SMEs and implement agreed upon solutions using best practices
Select and integrate any Big Data tools and frameworks required to provide requested capabilities
Implement ETL processes
Monitor performance and advising any necessary infrastructure changes
Monitor AWS landscape of EC2 clusters, Glue Jobs, Athena Tables, S3 data lakes and related services.
Design, implement, and tune tables, queries, stored procedures, indexes, etc.
Provide technical support to members of TS and SA team, as well as project support across client engagements
Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value
Stays current with relevant technology in order to maintain and/or improve functionality for authored applications.
Assume other responsibilities as requested/required

Qualifications:
Bachelor's or advanced degree in Computer Science/IT or related field
3 years of relevant experience) or (1 years of relevant experience and an advanced degree in Computer Science/IT or related field)
Proficient understanding of distributed computing principles
Ability to solve any ongoing issues with operating the cluster
Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce.
Experience building stream-processing systems, using solutions such as Storm or Spark-Streaming
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Some experience with integration of data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.
Experience with NoSQL databases, such as DynamoDB, Redshift, Databricks, etc.
Experience with various ETL techniques and frameworks, such as Glue Jobs, Step Functions, etc.
Good understanding of Lambda Architecture, along with its advantages and drawbacks
Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.
Extensive experience with Python scripts & libraries
Experience desired with Database Warehousing Design Concepts; Dimensional Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques
Experience working with Agile software development methodologies, namely Scrum
Proven experience with team collaboration, release management, system, and performance monitoring
Ability to work well with people from many different disciplines and varying degrees of technical experience
Strong organizational, presentation and customer service skills. Excellent problem-solving skills to assist in detecting potential issues and issue resolution
Excellent analytical, problem resolution, organization, and time management skills.
Ability to handle multiple tasks at a time",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Karsun Solutions, LLC
4.1",4.1,"Herndon, VA",Data Engineer,"Overview:
As a Data Engineer, you will be responsible for the maintenance, synchronization, cleaning, and migration of transactional data in a hybrid environment with both on-prem and highly modern cloud based microservices environment. You will work with the product teams to understand, analyze, document and efficiently implement to deliver streaming as well as batch oriented data for synchronizing legacy and modern data stores ensuring data integrity. You will provide support to the application database design to aid in eliminating data duplication and other issues and enabling selective event based and scheduled based data transfer to endpoints within the cloud and legacy environment as required. Using out of the box thinking, AWS native capabilities and CI/CD tools, you will drive towards programmatic pipeline generation and orchestration to enhance repeatability and rapid deployment while utilizing established design patterns and methods.

The successful candidate will be able to rapidly develop technical solutions working closely with the integrated product teams and developers with minimal direction from senior or lead resources

Responsibilities:
Understand data needs and be able to construct data pipelines for automating event driven bi-directional selective data replication, along with micro-batch and batch- based data pipelines
Standardization of data processing modules to deliver modularity and enhance reusability
Understand, maintain and perform operation on datasets stored in relational databases such as MySQL, SQL Server and Redshift, as well as in AWS S3
Utilize data processing tools and services such as StreamSets, Python, Java and shell scripting, AWS tools such as Glue, Step functions and Lambda and DB tools such as MySQL Workbench and SQL Server Management Studio
Create and maintain standards and best practices for data and pipeline standards
Support a variety of structured, semi-structured and unstructured data in streaming and batch frameworks
Design, create and support the data pipeline ETL processes across various data assets within the current scope of the system
Monitor, troubleshoot and coordinate defect resolution related to data processing & preparation
Qualifications and Education:
Required:
Typically requires a bachelor's degree or higher in Computer Science or related discipline and 8+ years of related experience including:
4+ years of hands-on experience in data transformation, creation of complex SQL queries and functions as well as data processing, cleanup and migration (MySQL and SQL Server preferred)
3+ years of hands-on experience in with Python and various Python toolkits and libraries for data processing and pipelines
3+ years of Database operations and administration (MySQL and SQL Server preferred)
2+ years of hands-on experience in with ETL tools such as Streamsets, AWS Glue, Pentaho etc.
1+ year of hands-on experience in AWS
1+ year of experience in Java and Linux scripting
1+ year experience working with CI/CD tools including Git
Successful track record in data migrations, database operations and maintenance and ETL job design and development, as well as scripting and automation activities with minimal supervision.
Proven skills in database operations, such as export/import, backup/restore etc. as well as proven experience with AWS data tools and services related to data processing.
Ability to monitor, troubleshoot and coordinate defect resolution related to data processing & preparation.
Ability to obtain and maintain a Public Trust clearance
Desired:
Experience of working with multiple AWS tools and any AWS certification is highly desired
Advanced Database Administration skills in SQL Server, MySQL and Redshift is highly desired
Experience with big data tools such as EMR/Spark, Databricks/PySpark is an advantage
Experience working with database versioning tools and tools like SSRS is an advantage
Experience in Ansible and Jenkins scripting is an advantage
Highly prefer candidates residing in the DC Metro area or Eastern time zone
#LI-SR1#FLEET","$97,368 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2009,Unknown / Non-Applicable
"KPMG
3.8",3.8,"Austin, TX","Associate, Data Engineer","Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today’s most important industries. Our growth is driven by delivering real results for our clients. It’s also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it’s no wonder we’re consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you’re as passionate about your future as we are, join our team.
KPMG is currently seeking an Associate, Data Engineering to join our Audit Technology organization.
Responsibilities:
Create artificial intelligence or generative artificial intelligence applications to support the execution of a high-quality audit and/or audit support activity
Define insights in large datasets by identifying trends and patterns and create data visualizations and dashboards to communicate insights to key stakeholders
Assist cross-functional teams with data-driven solutions
Support the execution of a high-quality audit and/or audit support through the diligent performance of assigned tasks and professional client and engagement team interactions
Qualifications:
Minimum one year of recent experience developing integrations using Jira, Python, REST API framework and SQL Alchemy
Bachelor’s degree from an accredited college or university
Strong technical aptitude and critical thinking and research skills
Ability to navigate various computer applications and technologies, including MS Office, ERP systems and data analysis tools
Excellent communication, time management and relationship-building skills
Able to employ sound professional judgment and professional skepticism; flexible and adaptable team player; leadership experience and resourceful in delivering high quality work
KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the salary range(s) are displayed via the URL below. The range is specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, performance, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your emotion and mental health. KPMG provides personal days off per fiscal year depending on job classification, standard work hours and years of service. Additionally, each year the firm publishes a calendar of holidays to be observed during the year. Available benefits are based on eligibility.
Albany Salary Range: Low: $67900 - High: $116700
Colorado Salary Range: Low: $71300 - High: $122500
New York City Salary Range: Low: $78100 - High: $134200
Rochester Salary Range: Low: $6900 - High: $119000

Follow this link to obtain salary ranges by city:

https://www.kpmg.us/work-for-kpmg/pay-transparency.html/?id=6727-9
KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.
KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).","$67,900 /yr (est.)",10000+ Employees,Company - Private,Management & Consulting,Business Consulting,1987,$1 to $5 billion (USD)
"Aura
4.4",4.4,"Boston, MA",Data Engineer,"Aura is on a mission to create a safer internet. In a world where our lives are increasingly online, Aura's category-defining suite of intelligent digital safety products help millions of customers protect themselves against digital threats, and that number is growing rapidly. This is an exciting phase at Aura, and our team of over 500 people worldwide is guided by a leadership slate that's successfully grown startups into multi-billion dollar organizations.
Come join us for the ride!
The Role
At Pango, data is at the core of most of our decision making and our Data Platform is one of the pillars supporting the company's growth. The data that pass through the Platform are used by both internal and external customers. We are looking for a Data Engineer to help us continue improving the architecture, enhancing, and maintaining the Data Platform.
Responsibilities
Design, build, deploy, and support scalable pipelines (scaling in both volume and variety of data sources) confirming data privacy and security requirements are met.
Administer and maintain the infrastructure powering our analytics and data assets by continuously monitoring and improving system performance and cost.
Provide technical mentorship to other team members ensuring knowledge is disseminated and high quality assets are delivered.
Drive data quality across the organization; develop best practices and frameworks for driving high quality work.
Define and manage SLAs for data sets and processes running in production
Evaluate, recommend, and build prototypes of new data engineering technology
Participate in technical architecture discussions and peer code reviews
Manage data migrations/conversions and troubleshoot data processing issues, assisting other team members when necessary.
Other duties and responsibilities as needed.
Qualifications
5+ years of experience in the data space with several years in Data Engineering working with a modern, cloud-hosted tech stack; AWS experience critical
Proficiency in Spark and Distributed Computing, Databricks a plus
Track record of architecting, designing and deploying high performance systems with reliable monitoring and logging practicesStrong Knowledge of Python and SQL, Scala a plus
Experience with job orchestration technologies like Airflow
Strong communication skills and the ability to work asynchronously across multiple time zones; open to shifted work hours to accommodate team meetings
Knowledge of CI/CD, version control and the command line
Experience working with third party APIs for ingestion and integration
Experience with Stream-processing systems (Kafka, or equivalent)
Preferred Qualifications
Knowledge of container services (Docker/Kubernetes)
Infrastructure as Code tools like Terraform
#LI-Remote
Aura is proud to be an equal employment workplace. All qualified applicants will be considered for employment without regard to, and will not be discriminated against based on race, color, ancestry, national origin, religion, age, sex, gender, marital status, sexual orientation, gender identity, disability status, veteran status, or any protected category. Beyond equal employment opportunity, Aura is committed to being an inclusive community where all feel welcome.
Aura is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment. If you need accessibility assistance and/or a reasonable accommodation due to a disability, please let your Talent Acquisition Partner know.
Important privacy information for California job applicants can be found here.","$132,250 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Software Development,2017,$100 to $500 million (USD)
"Sherwin-Williams
3.8",3.8,"Cleveland, OH",Associate Data Engineer,"Job Number: 23000EHS
Cleveland, Ohio | CLEVELAND, Ohio
Primary Location: Cleveland, Ohio 44115
Travel: Yes, 5 % of the Time
Schedule: Full-time
Base Salary: $63117.60 - $87345.69 per year
Posted: 9/4/2023
Description
Here, we believe there’s not one path to success, we believe in careers that grow with you. Whoever you are or wherever you come from in the world, there’s a place for you at Sherwin-Williams. We provide you with the opportunity to explore your curiosity and drive us forward. Sherwin-Williams values the unique talents and abilities from all backgrounds and characteristics. All qualified individuals are encouraged to apply, including individuals with disabilities and Protected Veterans. We’ll give you the space to share your strengths and we want you to show us what you can do. You can innovate, grow, and discover in a place where you can thrive and Let Your Colors Show!
At Sherwin-Williams, part of our mission is to help our employees and their families live healthier, save smarter and feel better. This starts with a wide range of world-class benefits designed for you. From retirement to health care, from total well-being to your daily commute—it matters to us. A general description of benefits offered can be found at www.myswbenefits.com. Click on “Candidates” to view benefit offerings that you may be eligible for if you are hired as a Sherwin-Williams employee.
The Associate Data Engineer is responsible for designing, developing implementing and supporting ETL (Extract, Transform, Load) processes used within custom and packaged applications responsible for loading data into the data warehouse. The Data Engineer is also responsible for the timely data availability and system up-time through support functions and in-depth testing. The incumbent will work with technology partners and business stakeholders to elicit, analyze, communicate, and validate requirements for changes to business processes, policies and information systems.
Essential Functions
Strategy & Planning
Participate and engage with peers in the full software development life cycle experience, focusing on small to medium scope efforts across the Enterprise Data Organization.
Seek out and apply new technologies and skills for ETL improvement in daily work through online training, reading, participation in organizations and user groups, etc.
Develop and resolve tasks of increasing difficulty that will be part of a larger business solution.
Prepare and maintain system documentation.
Execution & Deployment
Support various components and configuration items within the Data Engineering technology stack.
Articulate design decisions.
Understand requirements and interpret those into functional specifications for project efforts.
Understand the impact of code that is introduced into the environments and the impact that it can have to the environment.
Migrate code through various environments and perform basic troubleshooting and avoiding program flas while adhering to best practices.
Operational Management
Participate with the development of team norms and support agile methodologies.
Participate within internal team to identify and implement process improvement initiatives.
Participate in meetings and understand requirements for defects, enhancements, and small to medium size project efforts.
Understand technology components used and be able to articulate how these are used to produce solutions.
Position Requirements
Formal Education & Certification
Bachelor’s degree (or foreign equivalent) in a Computer Science, Computer Engineering, or Information Technology field of study (e.g., Information Technology, Electronics and Instrumentation Engineering, Computer Systems Management, Mathematics) or equivalent experience.
Knowledge & Experience
1+ years of IT experience
1+ years of experience in SQL
1+ years experience with scripting languages (such as Linux shell, python)
Personal Attributes
Strong written and oral communications skills.
Ability and initiative to learn and research new concepts, ideas, and technologies quickly
Ability to work in a team-oriented, collaborative environment.
Ability to quickly pick up new tools and technologies.
Ability to prioritize and execute tasks in a high-pressure environment.
Strong commitment to inclusion and diversity
Minor travel may be required (domestic and international).
Work hours outside the standard office 7.5 hour work day may be required.
Must be legally authorized to work in country of employment without sponsorship for employment visa status now or in the future.
Sherwin-Williams is proud to be an Equal Employment Opportunity/Affirmative Action employer committed to an inclusive and diverse workplace. All qualified candidates will receive consideration for employment and will not be discriminated against based on race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age, pregnancy, genetic information, creed, marital status or any other consideration prohibited by law or by contract.
As a VEVRAA Federal Contractor, Sherwin-Williams requests state and local employment services delivery systems to provide priority referral of Protected Veterans.
Compensation decisions are dependent on the facts and circumstances of each case and will impact where actual compensation may fall within the stated wage range. The wage range listed for this role takes into account the wide range of factors considered in making compensation decisions including skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled.
The wage range, other compensation, and benefits information listed is accurate as of the date of this posting. The Company reserves the right to modify this information at any time, with or without notice, subject to applicable law.","$75,232 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1866,$10+ billion (USD)
"Infusion Software Inc.
3.2",3.2,"Chandler, AZ",Data Engineer,"About Keap
Keap is the leading Sales & Marketing Automation platform for serious small businesses. We are a purpose-driven, values-based company that loves helping small businesses grow and understands how hard it is to run a successful small business. Keap’s vision is to liberate and empower entrepreneurs by automating follow-up, so they can strengthen their families, communities and economies. With tens of thousands of customers and over a hundred thousand users, we are just scratching the surface of our vision.

We are in the process of developing an advanced big data platform designed to offer both real-time and batch analytics tailored for our small business clientele. The individual selected for this role will collaborate intimately with our product management and engineering teams to extract vital data from our principal systems, laying the foundation for a comprehensive data lake. Additionally, the role involves close coordination with data scientists for data modeling, facilitating the integration of machine learning algorithms. This role represents a pivotal opportunity to delve into cutting-edge technologies and contribute significantly to Keap's data-driven future. This is NOT a data science role.
The Work
Build data pipeline(s) and platform(s) for our customer facing products.
Work closely with data scientists in order to provide data to implement descriptive and predictive analytics.
Explore new data technologies and advise the department on best practices.
Daily Execution Excellence
Work closely with developers, data scientists, and product managers to understand the questions that are being asked and how to answer them.
Build highly available, scalable and fault tolerant systems for batch and real-time data analysis.
Explore new technologies and how they might enhance our data solutions.
One Year and Beyond
Build better tools/platforms to help developers take advantage of our data.
Build APIs to expose data and machine learning models for consumption
Expertise
If you can execute the work, you can do the job. That being said, we realize we likely need someone with…

Strong programming ability.
4+ Years of experience
in building data-lake in a cloud environment.
in building real time streaming data ingestion and processing pipeline using Kafka or Pub/Sub.
with data processing tools (e.g. Hadoop, Spark, Dataflow, etc.)
building ETL/ELT pipelines, familiar with Airflow.

You will possess…

A demonstrated understanding of data engineering concepts.
Proficient in writing complex SQL statements.
Ability to program in Python or Java.
Experience with Google Cloud.
Experience with Google BigQuery.
Experience with Snowflake.
Familiarity with machine learning concepts.

At Keap, we celebrate diversity and inclusion to benefit our employees, our products, our community, and to help small businesses succeed. We do not discriminate based on race, color, ethnicity, ancestry, national origin, religion, sex, gender, gender identity, gender expression, sexual orientation, age, disability, veteran status, marital status or any legally protected status.

Keap’s corporate office is located at 1260 South Spectrum Blvd. Chandler AZ 85286.

Legal authorization to work in the U.S. is required. Keap will not sponsor new candidates for employment visas, now or in the future, for this job opening.

Any candidate who misrepresents their identity and/or skills may be subject to civil damages, penalties, and criminal prosecution.","$122,688 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Software Development,2001,$100 to $500 million (USD)
"Amway Inc.
3.9",3.9,"Ada, MI",Associate Data Engineer I/II,"Job title: Associate Data Engineer I/II
Department / Division: Global Supply Chain Analytics / Supply Chain
Salary Range (I): $61,093 - $79,062
Salary Range: (II): $71,540 - $92,581
Location: Ada, MI
This role is a hybrid in-office/remote role. You must be available to report to the Ada, MI office on Tuesdays & Wednesdays.

What do we need:
We are looking for an Associate Data Engineer with a desire to work in AWS or Google Cloud Platform to step into this newly created role to build and scale next generation data platforms for our Supply Chain organization. We need a high energy data wrangler who is ready to support our global team.

What’s special about this role:
As an Associate Data Engineer, you will be responsible for expanding and optimizing our data access and data pipeline analytics processes, as well as optimizing data flow and collection for cross functional teams. You will be a data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.

You will support our global community of data scientists and analysts on enterprise initiatives and will ensure optimal data delivery is consistent throughout ongoing projects. If you are excited by the prospect of optimizing or even re-designing our company’s analytics processes to support our next generation of advanced analytics capabilities, which in-turn translates to implementing strategic enhancements to maintain our competitive edge in the industry, this may be the opportunity for you.

Required qualifications:
Associative Level I: 0-1 years’ experience preferred in Data Engineering, Business Analytics processes
Associate Level II: Minimum 1-year experience in Data Engineer, Business Analytics processes
Preferred Experience with AWS and Google Cloud Platform “big data” technologies
Familiarity or proficiency with technologies like Hadoop (and related ecosystem), Spark, Kafka, EC2, EMR, RDS, and Redshift in supporting data transformation, data structures, metadata, dependency and workload management
BA/BS degree in Computer Science, Finance, Supply Chain or related field

Skills to be successful in the role:
Self-directed and comfortable supporting the data needs of multiple teams, systems, and products within the Amway’s data eco-system
Understanding of distributed systems driving large-scale data processing and analytics with a successful history of manipulating, processing and extracting value from large disconnected datasets
Advanced working database knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases such as Microsoft and Oracle databases to advance analytics capabilities

What’s special about this team:
The Supply Chain Analytics and Demand Planning Analytics business group provides the organization with high quality, innovative data solutions in a focused, fast and fun atmosphere. The team is seeking a tech savvy Data Engineer to work on building, operating, and scaling next generation data platforms and tools that will power data-driven analytics capabilities throughout the entire organization. This newly created role will report to the Manager of Supply Chain Analytics.

This role is “Not” eligible for sponsorship.","$70,078 /yr (est.)",10000+ Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1959,$5 to $10 billion (USD)
"Amadeus
4.0",4.0,"Atlanta, GA",Senior Data Engineer/Developer,"Job Title
Senior Data Engineer/Developer
Job Title: Senior Data Engineer/Developer
Job Description
Amadeus Hospitality Business Intelligence (BI) is looking for Senior Data Engineer for our BI Technology team. This role is responsible for building and supporting components responsible for all data ingestion activities in the Amadeus Hospitality Business Intelligence Product suite.
The Amadeus Hospitality BI products provide critical insights to our customers that assist them in increasing revenue and profitability. Ensuring access to the right data at the right time helps our customers accelerate revenue for long term growth.
With Amadeus’ Hotel Business Intelligence Solutions, customers unlock a complete, 360-degree view of rate, occupancy, and distribution trends with both forward-looking and historical data, as well as data from different competitive sets in their market.
Specific Accountabilities
We are seeking a highly skilled Senior Data Engineer/Developer with extensive experience in Data Ingestion technologies, methods, and cloud technologies. This role will be responsible for
Designing, building, and maintaining large-scale data pipelines, data warehousing/lake in a cloud environment.
Have solid understanding of data architecture, data modelling and data integration principles.
Collaborate with cross-functional teams to identify and implement solutions to complex data problems.
Implement ETL processes to integrate data from various sources and formats, transform and load data into a centralized data repository/store/lake.
Develop and maintain automated data quality checks and data governance processes.
Optimize database systems for performance, scalability, and reliability.
Ensure that all data solutions meet security, compliance, and regulatory requirements.
Required Skills:
Strong programming skills in languages like Python, Java, with experience in big data frameworks
Have abilities to develop common frameworks, common modules for data ingestion.
Have abilities to develop automated data quality and data governance mechanisms in the data ingestion processes.
Experience with cloud platforms such as Azure, AWS, including any cloud resident services tools for data ingestion.
Experience in developing Exceptions and Alerting models for data quality.
Proficiency in SQL and database query optimization.
Experience with data governance, data lineage, and data cataloging tools such as Collibra.
Familiarity with DevOps practices and tools such as Jenkins, Git, Docker, and Kubernetes is a Plus.
Excellent problem-solving skills, with the ability to work in a fast-paced, collaborative environment.
Education:
Bachelor’s or Master’s Degree in Computer Science, Information systems, or related discipline
Relevant work experience:
7+ years of experience as a Data Engineer or Developer.
2+ years in a Senior role
2+ years using Agile software development methodologies.
Technology:
Python
Java
Kubernetes
Kafka
Azure Big Data Solutions
Perl
What we can offer you:
The opportunity to work for one of the world’s top leading travel tech companies; a company that originated in technology innovation and sees the world with a technology-first perspective
Skills development and opportunities to try new ideas
A global diverse work environment
Diversity & Inclusion
Amadeus is an Equal Employment Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy, childbirth, or a related medical condition), ancestry, national origin, age, genetic information, military or veterans status, sexual orientation, gender expression, perception, or identity, marital status, mental or physical disability status, or any other protected federal, state, or local status unrelated to performance of work involved.
Amadeus endeavors to make https://jobs.amadeus.com/ accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at accommodations@amadeus.com. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications.","$114,105 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1987,$1 to $5 billion (USD)
"NVIDIA
4.6",4.6,"Santa Clara, CA",Senior Data and ML Engineer,"As a Senior Data / ML Engineer, you'll join NVIDIA’s Digital Marketing platform team, dedicated to addressing our evolving data-driven marketing and compliance challenges. We value expertise in data science paired with a robust data engineering foundation. Together, we'll architect data pipelines, delve into advanced data analysis, and craft models using ML/AI. We seek someone proficient in programming and scripting for comprehensive data manipulation, analysis, and model creation. Our team thrives on working with Big Data technologies like Hadoop, Spark, and NoSQL databases, efficiently processing vast datasets. If you share a passion for innovation and creating exceptional experiences through the integration and management of large data sets, then you're the one we've been searching for! We believe in proactive problem-solving, minimal supervision, and being exceptional teammates who collaborate, think, and learn as one unit. Join us and let's make a difference together!
What you’ll be doing:
Architect solutions for complex data platforms, and large scale CI/CD data pipelines using a variety of technologies, relational and non-relational databases, and data warehouse solutions for data-driven marketing and compliance requirements.
Responsible for end-to-end design and development, starting from requirements gathering with business and engineering partners to deployment to product systems using Agile development methodology.
Develop and implement ML models: Design, develop, and deploy scalable machine learning models and algorithms that address complex business challenges in the marketing and business domain (e.g. build recommendation models for NVIDIA website). Apply various techniques such as supervised and unsupervised learning, deep learning, and reinforcement learning.
Data pre-processing and analysis: Collaborate with data scientists and data engineers to collect, clean, pre-process, and transform large and wide datasets. Conduct exploratory data analysis (EDA) to uncover insights and identify patterns that boost the model performance.
Model evaluation and optimization: Conduct detailed model evaluation metrics and validation to ensure accuracy, reliability, and scalability. Optimize model performance by fine-tuning hyper parameters, feature engineering, and applying techniques such as ensemble learning and continuous learning.
Deployment and integration: Work closely with software engineers to integrate machine learning models into production systems. Ensure seamless deployment and efficient model inference in real-time environments. Collaborate with DevOps to implement effective monitoring and maintenance strategies.
Collaborate with multidisciplinary teams: Collaborate with product engineers, data scientists, and analysts to understand business requirements and translate them into machine learning solutions. Provide technical guidance and mentorship to junior team members.
What we need to see:
Bachelors Degree in Computer Science or related field or equivalent experience.
8+ years as data engineer, or related experience, in metadata management, and data quality, data retention, and data cleansing with exposure of defining data engineering solutions for emerging compliance requirements such as GDPR/CCPA/Data Localization.
3 years of proven expertise as a Machine Learning Engineer or a similar role, with a consistent record of successfully delivering ML solutions.
Advanced working SQL knowledge and experience working with relational / non-relational databases, schema design, and excellent SQL troubleshooting skills working with large datasets.
Strong programming skills in languages such as Python, Golang, R, or Java. Experience with frameworks like TensorFlow, PyTorch, or scikit-learn.
Proficiency in data manipulation, analysis, and visualization using tools like NumPy, pandas, and matplotlib.
Deep understanding of machine learning algorithms, statistical models, and data structures.
Familiarity with software development practices and version control systems (e.g., Git).
Experience with experimental design, A/B testing, and evaluation metrics for ML models.
Ways to stand out from the crowd:
Architect level experience as a data engineer developing and deploying using Docker and Kubernetes on cloud technologies.
Ability to analyze complicated and wide data sets, identify patterns, and derive significant insights.
Demonstrated skills with AI/ML solutions for various applications, such as recommendation system, predictive analytics, and natural language processing.
Self-motivated with a goal to stay updated on the latest methodologies and machine learning technologies.
With competitive salaries and a generous benefits package, we are widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking people in the world working for us and, due to unprecedented growth, our business development teams are rapidly growing. If you're creative and autonomous with a real passion for you work, we want to hear from you.
The base salary range is $160,000 - $247,250. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.","$203,625 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1993,$5 to $10 billion (USD)
AltaMed,#N/A,"Montebello, CA",Senior Data Engineer,"The Senior Data Engineer works closely with business leaders, managers, staff and vendor to accurately gather and interpret requirements, specifications. Develop technical specifications and recommend, design, develop, test, implement, and support innovative and optimal data solutions. Serves as a coach and mentor to Data engineering team
Responsibilities :
Lead on all aspects of a modern and flexible SDLC approach, applied to data engineering, analytics and data science efforts
Provide business guidance and steer efforts toward desired outcomes; partner with internal stakeholders and external vendors to meet strategic data warehouse goals
Research, evaluate and formally recommend third party software and technology package
Responsible for new & existing integrated system & data flow enterprise architecture
Set standards for data engineering functions; design templates for the data management which are scalable, repeatable, and simple
Defines and develops appropriate controls to monitor quality of the enterprise data warehouse process
Preparation of technical specification
Perform all other related duties as assigned
Required:
Minimum 7 years’ experience in a complex data warehouse role for a mid to large size organization; Health Care industry experience highly desired
Minimum 4 years hands on experience with ETL/Data Integration, BI, data mining and modeling, SSIS strongly preferred
Proficiency in all facets of DW Architecture, data flow strategy, data modeling, metadata and master data management
Mastery expertise in SQL and RDBMS systems such as Microsoft SQL Server
Knowledge of and experience working with reporting tools like SSRS and Tableau
Stay abreast of established and industry emerging data technologies
Demonstrated ability to produce high quality technical documentation.
Experience in implementing a data architecture with separation between storage and compute preferred.
Deep understanding of data architecture and ability to coordinate with the implementation team is highly desired.
Skills and Abilities:
Be able to consult on complex data engineering efforts and lead project teams through the solution design process
Be able to teach and mentor to less-experience technical team members.
Ability to compliance with standards and procedures such as standard of communication, work management, change management, version control, implementation and/or consistency of coding. Recognizes code, process and/or standard inefficiencies and suggests new standards and opportunities for improvement.
Ability to build and integrate a data-driven intelligent solution into our business processes. Manage the innovation development processes, and be responsible for driving the data architecture for the company's products and IT processes.
Ability to research, evaluate and formally recommend third party software and technology package
Keep big picture concepts in mind when designing solutions; fully understand business needs
Strong experience on database technologies, data warehouse, data validation, data quality, metadata management and data governance
Providing proactive technical oversight and advice to application architecture and development teams fostering re-use, design for scale, stability, and operational efficiency of data/analytical solutions
Knowledge of and experienced in rolling out best practices in all facets of DW architecture, data flow strategy, data modeling, metadata and master data management.
Ability to interact and develop relationships with all levels of personnel and management.
Job Type: Full-time
Pay: From $153,035.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee discount
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Vision insurance
Compensation package:
Yearly pay
Experience level:
10 years
Schedule:
8 hour shift
Day shift
Monday to Friday
Ability to commute/relocate:
Montebello, CA 90640: Reliably commute or planning to relocate before starting work (Required)
Work Location: Hybrid remote in Montebello, CA 90640","$153,035 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"CEDARS-SINAI
4.1",4.1,"Los Angeles, CA",Data Engineer - Remote,"Grow your career at Cedars-Sinai!
The Enterprise Information Services (EIS) team at Cedars-Sinai understands that true clinical transformation and the optimization of a clinical information systems implementation is fueled through the alignment of the right people, processes, and technologies.
Why work here?
Cedars-Sinai Medical Center has been ranked the #1 hospital in California by U.S. News & World Report, 2023‑2024. When you join our team, you’ll gain access to our groundbreaking biomedical research facilities and advanced medical education programs. We offer learning programs, tuition reimbursement and performance-improvement projects so you can achieve certifications and degrees while gaining the knowledge and experience needed to advance your career.
We take pride in hiring the best, most hard-working employees. Our dedicated doctors, nurses and staff reflect the culturally and ethnically diverse community we serve. They are proof of our dedication to creating a dynamic, inclusive environment that fuels innovation and the gold standard of patient care we strive for.
What will you be doing in this role:
The Data Engineer is responsible for building data structures, pipelines, access paths for downstream analytics or direct customer use. The Data Engineer is responsible for finding trends in data sets and developing algorithms to help make raw data more useful to the enterprise. This role requires a significant set of technical skills, including a deep knowledge of SQL database design and functional programming languages such as Python. Data Engineers need communication skills to work across departments to understand what business leaders want to gain from the company's large datasets. Data Engineers manage and organize data, while keeping an eye on trends or inconsistencies that will impact business goals. Finally, Data Engineers are responsible for understanding, monitoring and maintaining the applications that comprise the data pipelines.
Develops, tests and maintains data centric pipelines.
Develops and supports data acquisition and data set processes.
Prepares data for predictive and prescriptive modeling.
Debugs and maintains deployments of core applications, databases and utilities.
Demonstrated skill with OS and admin tools such as Linux, Git, AD, etc for system and process maintenance.
Creates enhancements to primary and supporting pipelines, code repos and infrastructures.
Creates component/subsystem documentation. Produces design and technical specifications as needed for technical documentation.
Translates customer requirements, recommends system solutions, and formulates detailed specifications from which programs are written. Works closely with business partners to produce quality products that meet business needs.
Provides and supports technology infrastructure.
Liaisons with end users, research groups and other business support areas.

Experience Requirements:
Two (2) plus years’ experience in databases: Oracle, SQL, PL/SQL, DML, DDL. (Healthcare data use a plus)
Solid knowledge of Python programming, Bash, Powershell or other scripting languages required.
Experience with pipeline or application design, software development, maintenance.
Solid grasp of S3, RedShift, Kinesis, and Glue experience.
IAM for roles and permission, EC2 for VMs, lambda, AppSync, Cloudformation, DynamoDB, React. (preferred)
AWS Cloud Services.
Educational/Certification Requirements:
Bachelor’s Degree in Computer Sciences, Engineering, Mathematics, or related field. (preferred)
Epic Data Model Certification a plus.
Jobs
LI-Remote


Working Title: Data Engineer - Remote
Department: EIS Data Analytics Team
Business Entity: Cedars-Sinai Medical Center
Job Category: Information Technology
Job Specialty: Software/Application Development
Position Type: Full-time
Shift Length: 8 hour shift
Shift Type: Day
Base Pay:$103,900.00 - $166,100.00","$135,000 /yr (est.)",10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1902,$1 to $5 billion (USD)
"Mastercard
4.3",4.3,"O Fallon, MO",Senior Data Engineer,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Senior Data Engineer
Overview:
We are seeking a talented and motivated Senior Data Engineer to join our data engineering team. In this role, you will play a critical part in designing, developing, and optimizing data pipelines and solutions that enable efficient data processing and analysis. As a Senior Data Engineer, you will collaborate with cross-functional teams to drive data-driven decision-making and contribute to the continuous improvement of our data infrastructure.

Role:
Design, develop, and maintain new data capabilities and infrastructure for utilizing Mastercard, third-party, and partner data to enhance Mastercard's data products and solutions
Create new data pipelines, data transfers, and compliance-oriented infrastructure to facilitate seamless data utilization within cloud environments
Identify existing data capability and infrastructure gaps or opportunities within and across initiatives and provide subject matter expertise in support of remediation
Collaborate with technical team and business stakeholders to understand data requirements and translate them into technical solutions
Work with large datasets, ensuring data quality, accuracy, and performance
Implement data transformation, integration, and validation processes to support analytics and reporting needs
Optimize and fine-tune data pipelines for improved speed, reliability, and efficiency
Implement best practices for data storage, retrieval, and archival to ensure data accessibility and security
Troubleshoot and resolve data-related issues, collaborating with the team to identify root causes
Document data processes, data lineage, and technical specifications for future reference
Participate in code reviews, ensuring adherence to coding standards and best practices
Collaborate with DevOps teams to automate deployment and monitoring of data pipelines
Additional tasks as required

All About You:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field
Proven experience in data engineering, with a strong track record of designing and implementing data solutions
Proficiency in programming languages such as Python, Java, or Scala, and experience with data processing frameworks (Spark, Hadoop, etc.)
In-depth understanding of data warehousing concepts, cloud platforms (AWS, Azure, GCP), and data modeling techniques
Strong knowledge of SQL and NoSQL databases, as well as data integration and transformation tools
Passion for and engagement with emerging trends in data, AI/ML, analytics, and digital experiences
Experience in data product development, analytical models, and model governance
Experience in anonymizing data and managing the use of data
Experience in data hygiene procedures, identity resolution capabilities or data management a plus
Ability to create strategies and plans that define how information can be utilized to support an organization's overall business strategy, and how that information and data is organized, and governed inside an organization
Strong project management skills and a demonstrated ability to understand complex information product constructs
Familiarity with industry best practices for collection and use of data
Outstanding problem-solving skills and the ability to navigate complex data challenges
Effective communication and collaboration skills to work with both technical and non-technical stakeholders
Experience with agile methodologies and DevOps practices

What is Data & Services?
The Data & Services Team (D&S) is a key differentiator for Mastercard, providing the cutting-edge services that help our customers grow. Focused on thinking big and scaling fast around the globe, this team is responsible for end-to-end solutions for a diverse global customer base. We combine traditional management consulting with our rich data assets and in-house technology to provide our clients with powerful insights and tools to drive fact-based decision making. Centered on data-driven technologies and innovation, our services include consulting, loyalty and marketing programs, test-and-learn business experimentation, and data-driven information and risk management. While specializing in the payments industry, Mastercard Data & Services also works closely with major retailers, airlines, and other enterprises, leveraging data and insights garnered from within and beyond its network.
D&S is continuously looking for passionate and talented technologists, who share our vision for empowering our customers to make better fact-based decisions, to join us and shape the growth of our team.

#LI-NF1
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Pay Ranges
O'Fallon, Missouri: $112,000 - $173,000 USD
Arlington, Virginia: $129,000 - $199,000 USD
Boston, Massachusetts: $129,000 - $199,000 USD
Miami, Florida: $112,000 - $173,000 USD","$121,132 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Mayo Clinic
3.9",3.9,"Rochester, MN",Data Engineer,"Why Mayo Clinic

Mayo Clinic is top-ranked in more specialties than any other care provider according to U.S. News & World Report. As we work together to put the needs of the patient first, we are also dedicated to our employees, investing in competitive compensation and comprehensive benefit plans – to take care of you and your family, now and in the future. And with continuing education and advancement opportunities at every turn, you can build a long, successful career with Mayo Clinic. You’ll thrive in an environment that supports innovation, is committed to ending racism and supporting diversity, equity and inclusion, and provides the resources you need to succeed.


Responsibilities
Data Engineer gains access to data across the organization and provides ongoing analysis of the data by monitoring, profiling and analyzing databases. Requires a mix of functional, data and technical skills. The right candidate must be able to understand business requirements, translate them into information needs and implement those requirements using data available. The hire will be responsible for expanding and optimizing data architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems. The Data Engineer will support our software developers, database architects, and data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Core job duties include:
Assemble large, complex data sets that meet functional / non-functional business requirements.
Strong knowledge of SQL required. Ability to identify sets and subsets of information across multiple joins or unions of tables is preferred in addition to writing and troubleshooting SQL queries for data mining
Perform complex data analysis and investigation for customer requests to explain results and to make appropriate recommendations.
Strong understanding of data modeling concepts

Problem solver with the initiative to think critically to identify improvement opportunities (error detection, error correction, root cause analysis)
Understand ETL that will aid in verification and testing of data
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Analyze business objectives and develop data solutions to meet customer needs.
Demonstrated ability to effectively participate in multiple, concurrent projects
Improve and customize current data solutions to meet business functional and non-functional requirements.
Research new and existing data sources in order to contribute to new development, improve data management processes, and make recommendations for data quality initiatives.
Perform periodic data quality reviews for internal and external data.
Ensure timely resolution of queries and data issues.
Look for new ways to find and collect data by researching potential new sources of information.
Work with data and analytics experts to strive for greater functionality in our data systems.

Qualifications
Bachelor's degree in Computer Science or Engineering from an accredited University or College; OR an Associate’s degree in Computer Science or Engineering from an accredited University or College with 2 years of experience.Demonstrated ability to analyze and profile data as a means to address various business problems through leveraging advanced data modeling, source system databases, or data mining techniques, is required. May provide consultative services to departments/divisions and committees. Demonstrated application of several problem-solving methodologies, planning techniques, continuous improvement methods, and analytical tools and methodologies (e.g. data analysis, data profiling, modeling, etc.) required. Incumbent must have ability to manage a varied workload of projects with multiple priorities and stay current on healthcare trends and enterprise changes. Interpersonal skills and time management skills are required. Requires strong analytical skills and the ability to identify and recommend solutions, advanced computer application skills and a commitment to customer service. Experience with data analysis, quality, and profiling; including data exploration tools including but not limited to Rapid SQL, AQT, Information Analyzer, and Informatics.N/A

Exemption Status

Exempt

Compensation Detail

$95,492 - $133,681 / year

Benefits Eligible

Yes

Schedule

Full Time

Hours/Pay Period

80

Schedule Details

Monday - Friday, Normal Business Hours 100% Remote. This position may work remotely from any location within the US. 10% travel may be required This vacancy is not eligible for sponsorship/ we will not sponsor or transfer visas for this position.

Weekend Schedule

Not Applicable

International Assignment

No

Site Description
Just as our reputation has spread beyond our Minnesota roots, so have our locations. Today, our employees are located at our three major campuses in Phoenix/Scottsdale, Arizona, Jacksonville, Florida, Rochester, Minnesota, and at Mayo Clinic Health System campuses throughout Midwestern communities, and at our international locations. Each Mayo Clinic location is a special place where our employees thrive in both their work and personal lives. Learn more about what each unique Mayo Clinic campus has to offer, and where your best fit is.

Affirmative Action and Equal Opportunity Employer

As an Affirmative Action and Equal Opportunity Employer Mayo Clinic is committed to creating an inclusive environment that values the diversity of its employees and does not discriminate against any employee or candidate. Women, minorities, veterans, people from the LGBTQ communities and people with disabilities are strongly encouraged to apply to join our teams. Reasonable accommodations to access job openings or to apply for a job are available.


Recruiter

Julie Melton","$114,587 /yr (est.)",10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,#N/A,$10+ billion (USD)
"Carvana
2.9",2.9,"Tempe, AZ",Senior Data Engineer,"ABOUT CARVANA...
If you like disrupting the norm and are looking to join a company revolutionizing an industry then you will LOVE what Carvana has done for the car buying experience. Buying a car the old fashioned way sucks and we are working hard to make it NOT suck. At Carvana, our customers can hop online to...
Search and browse our inventory of over 40,000 vehicles that we own and certify
Narrow down search results using highly intelligent filtering tools/components
View vehicle details, Carfax reports and 360 rotating studio images for every vehicle
Secure financing in minutes using Carvana's in house service or their own bank
Interact with GUI components to easily customize loan length, down payment and monthly payment
Generate, upload and eSign all documents online (no ink necessary)
Schedule front door delivery or pick up at one of our vending machines
Trade in their existing vehicle or just sell it to Carvana (no purchase necessary)
JOB DESCRIPTION...
The NGCP (Next Generation Communications Platform) team is a talented and humble group of people with backgrounds in Product, Design, Data Science, and Engineering, focused on Human-Computer Interaction (HCI). Our core product is a communication platform that car buyers, sellers, and Carvana Advocates rely on every day for a seamless car shopping experience. We are seeking a talented and driven Data Engineer to join our dynamic team, playing a critical role in developing and deploying reliable data systems and pipelines to support the analytics and processing of our communication platform.

As a core member of our NGCP team, you will work to support customer communication pipelines, architecting and maintaining enterprise data resources, and developing data design patterns to support business analytics. You will have the opportunity to work closely with our Product, Experience, and Software Engineering teams to deliver impact on every aspect of the purchase process, from search to vehicle delivery.

RESPONSIBILITIES...
Data System Design and Scalability: Design robust and reusable data solutions for various platforms that include both batch and streaming systems, as well as understand and implement best practices in management of enterprise data.
ETL Pipeline Development: Building production streaming pipelines/ETL jobs to reliably move data between systems and and populate data in event streams and DB tables suitable for downstream consumption.
Deployment and Integration: Full software development lifecycle from design and development to testing and operating in production
Continuous Improvement and Innovation: Continuously improve data solutions to increase data quality and speed of data deliverability.
Improve Business Outcomes: Communicate effectively with engineers, product managers, data scientists, and data analysts to ensure correct and timely implementation of data requests.

REQUIRED SKILLS AND EXPERIENCE...
5+ years experience with Python
3+ years Spark or other big data processing (hadoop, flink) experience
Extensive background in SQL and relational databases like Postgres, MySQL, SQL Server
Experience with stream processing systems for analytics such as Amazon Kinesis, Kafka, RabbitMQ, Google Pub/Sub
Experience with data pipeline management tools such as Databricks Notebooks, Airflow, Prefect, Pachyderm or some other pipeline management system
Experience with CICD processes (GitHub, GitLab, dbx)
Strong experience with cloud APIs (e.g., GCP, AWS, Azure)
Expert knowledge of data integration concepts, business intelligence and data warehousing and implementing large systems
Understand how to be efficient with resource usage (e.g., system hardware, data storage, query optimization, AWS infrastructure, etc.)
Production quality coding standards and patterns
BONUS SKILLS (helpful but not required)...
Snowflake or BigQuery
MLOps tools (Mlflow, Airflow, KServe, Kubeflow)
WHAT YOU CAN EXPECT IN RETURN...
Full-Time Salary Position
Health, Dental and Vision benefits (Employee health 100% covered by Carvana)
Employee car discounts and perks
401K with company match
Access to opportunities to expand your skill set and share your knowledge with others across the organization","$122,683 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,Other Retail Stores,2013,Unknown / Non-Applicable
"Quirch Foods
3.1",3.1,"Lakeland, FL",Data Engineer,"About Quirch Foods
In business for over 50 years, Quirch Foods is a global distributor and exporter of fresh and frozen food products with a unique focus on ethnic cultures. We service our customers from 5 distribution centers strategically located in the United States. We have consistently been ranked among the top 50 exporters in the US and are one of the largest importers of seafood. Our customers include independent grocers, chain supermarkets, foodservice distributors, cruise lines, restaurants and food processors/manufacturers. We have an extensive product list with over 8,000 SKU's and carry niche brands such as Panamei, Mambo and Chiquita along with national brands like Tyson, IBP, Excel, JBS, Iowa Premium, Smithfield, Dietz & Watson, along with many others. We are headquartered in Coral Gables, FL.
Quirch is a portfolio company of Palladium Equity Partners, a leading mid-market private equity fund based in New York City, which partnered with the Executive Team to capitalize on Quirch Foods’ record of excellence and to grow it decisively beyond its current business.
Position Summary
At Quirch Foods we believe in leveraging technology as a source of competitive advantage. This includes customized ERP Solutions, Business Intelligence, EDI, Web and Mobile Solutions. We are currently looking for a Data Engineer to join our development efforts.
Essential Duties and Responsibilities:
Develop, test and maintain custom business solutions by leveraging state of the art software development practices using an agile methodology
Evaluate business requirement and help define problems and develop solutions
Participate in design and architecture discussions with business leaders, end users and IT team members
Document business requirements and solution, document code and provide support for creation of end user documentation
Update business knowledge, technical skills and soft skills, leverage educational opportunities, participate in professional organizations
Experience:
MS SQL Programming
Visual Studio\C#\WPS Experience
Microsoft SSAS, SSIS, SSRS desired but not required
Biztalk experience desired but not required
Skills and Requirements:
Bachelor’s degree in Computer Science, Engineering, Math or equivalent and\or related experience and training preferred
Strong analytical and problem-solving skills
Strong collaborator and team player
Great organizational skills, attention to detail and follow thru
Effective oral and written communication skills
Extensive familiarity with data management principles
Benefits:
Professional growth and developmental opportunities to grow your skills using state of the art technology
Comprehensive benefits package that includes: Medical, Dental, Prescription Drug Plan, Disability Plan, Life insurance Plan
401K savings Plan
Paid Holidays
Personal Time off
Employee Discounts
Quirch Foods is an Equal Opportunity Employer (EOE). Qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, disability, or veteran status. All applicants must be eligible to work in the United States.
Job Type: Full-time
Pay: $90,000.00 - $100,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Life insurance
Paid time off
Vision insurance
Experience level:
3 years
4 years
5 years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Lakeland, FL: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
What is your desired compensation?
Experience:
SQL: 2 years (Required)
Azure: 2 years (Required)
Data Engineering: 2 years (Required)
Work Location: In person","$95,000 /yr (est.)",201 to 500 Employees,Company - Private,Retail & Wholesale,Wholesale,1967,$500 million to $1 billion (USD)
"Booz Allen Hamilton
4.2",4.2,"Chantilly, VA","Cloud Data Engineer, Junior","Job Description
Location:
Chantilly,VA,US
Remote Work:
No
Job Number:
R0179118

Cloud Data Engineer, Junior
The Opportunity:
Everyone is trying to “harness the cloud,” but not everyone knows how. As a cloud data engineer, you know how to create a cloud-based technical architecture that meets client needs and takes advantage of cloud capabilities. We need you to help us develop cloud-based solutions for some of the Intelligence Communities toughest problems.
On our team, you’ll help to guide a multi-disciplinary team of data engineers, developers, and data consumers in a fast-paced, Agile environment. This is an opportunity to use the latest cloud technologies as you look for ways to improve your client’s environment using current cloud capabilities. Using your technical knowledge, you’ll work to deploy and develop pipelines and platforms that organize and make disparate data meaningful.
You’ll recommend tools and solutions based on your research of the current environment and knowledge of various on-premise, cloud-based, and hybrid resources. You’ll learn to help the client overcome their most difficult challenges in the cloud as part of a team. Additionally, you’ll gain skills in areas like implementing data engineering activities on some of the most mission-driven projects in the industry while developing critical systems for the Intelligence Community.
Join us. The world can’t wait.
You Have:
Experience with the data pipeline, including data acquisition, data prep, and database architecture, to make data easily searchable and retrievable
Knowledge of PostgreSQL
Knowledge of Kafka
Ability to work independently and as part of a team
Top Secret clearance
Bachelor’s degree
Nice If You Have:
Experience with AWS services, including RDS and RDS Aurora
Experience using Python, SQL, Scala, or Java
Experience with Kafka Connect, Kafka Streams, and other Kafka ecosystem tools
Experience with Terraform, Ansible, or other infrastructure-as-code tool
Experience with Agile development methodologies
Possession of excellent problem-solving and analytical skills
Possession of strong attention to detail skills
TS/SCI clearance with a polygraph
Bachelor’s degree in Computer Science is preferred
Clearance:
Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Top Secret clearance is required.

Create Your Career:
Grow With Us
Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.
A Place Where You Belong
Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.
Support Your Well-Being
Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.
Your Candidate Journey
At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.
Compensation
At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $49,800.00 to $102,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
Work Model
Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.
EEO Commitment
We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.","$75,900 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1914,$5 to $10 billion (USD)
"BrightSpring Health Services
3.2",3.2,"Louisville, KY",DATA ENGINEER,"Our Company:
BrightSpring Health Services
Overview:
We are looking for a Data Engineer to join our growing team of Data Engineers. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow. The Data Engineer will work on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
Responsibilities:
Creates and maintains optimal data pipeline Patterns/Architecture
Assembles large, complex data sets that meet functional / non-functional business requirements
Builds the Data pipelines that extract, transform, and load data from a wide variety of data sources using Azure technologies
Works with stakeholders to assist with data-related technical issues and support their data infrastructure needs
Keeps our data separated and secure across Azure regions
Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Designs and implements dimensional data models as well as creates automated Data Quality tests to continuously monitor data quality of the data models under the supervision of a designated lead
Qualifications:
Five to seven years of experience in a Data Engineer/Data Analyst role
Graduate degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field
Good working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Familiarity with relational SQL and NoSQL databases; knowledge of data pipeline architecture preferred
Experience with object-oriented/object function scripting languages: Python, C#
Experience with Azure cloud services: Azure Data Factory, Azure SQL db, Azure Synapse Analytics, Azure Data Lake Storage Gen2, Data Bricks, PySpark
Ability to build processes supporting data transformation, data structures, metadata, dependency, and workload management
Eager to learn new technologies and identify opportunities for improvement
Strong analytic skills to perform root cause analysis on internal and external data and processes to answer specific business questions
Detail oriented and possess good organizational skills
Willing to work in a cross-functional team in a dynamic environment
About our Line of Business: BrightSpring Health Services is a leading provider of complementary home and community-based pharmacy and health services for complex populations in need of chronic and/or specialized care. Through the company’s pharmacy and provider services to seniors and specialty (including behavioral) populations, we provide comprehensive care and clinical services in 50 states to over 360,000 customers, clients and patients daily. The company’s services foster greater patient and family satisfaction, improve outcomes and reduce health care system costs, and are supported by industry-leading quality outcomes. For more information, visit www.brightspringhealth.com. Follow us on Facebook, Twitter and LinkedIn. Salary Range: USD $79,200.00 - $110,000.00 / Year","$94,600 /yr (est.)",10000+ Employees,Company - Private,Healthcare,Health Care Services & Hospitals,1974,Unknown / Non-Applicable
"Ascendion
4.3",4.3,"Tampa, FL",Data Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.

Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skill
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience

Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.

About the Role:

Job Title: Data Engineer

Day to Day:
Ascendion is looking for a Data Engineer to focus on QA work for the member data team focusing on work related to building out a loyalty and rewards platform
Must Haves:
3+ years experience with ETL (Talend)
Expertise with SQL Servers & SSIS
Strong Experience with c#

Plus:
MongoDB Experience
HC is a plus

Location: Remote

Salary Range: The salary for this position is between $ 105,000 – $110,000 annually. Factors which may affect pay within this range may include geography/market, skill, education, experience, and other qualifications of the successful candidate.
Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day accrued each calendar year. The
Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day of paid vacation time] [6 paid holiday and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!

Preferred Skills:
Talend
SSIS
SQL
C#
Job details
Job ID
328384
Job Requirements
Data Engineer
Location
Tampa, Florida, US
Recruiter
Poorvi
Email
poorvi.ratre@ascendion.com","$107,500 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Clairvoyant Inc.
4.4",4.4,"Hartford, CT",GCP Data Engineer,"Type: FTE
Location: Hartford, CT
Must-Have
8+ Years of Experience in Data Engineering and building and maintaining large scale data pipelines
Experience with designing and implementing a large scale DataLake on Cloud Infrastructure
Strong technical expertise in Python and SQL
Extremely well-versed in Google Compute Platform including BigQuery, Cloud Storage, Cloud Composer, DataProc, Dataflow, Pub/Sub.
Experience with Big Data Tools such as Hadoop and Apache Spark (Pyspark)
Experience Developing DAGs in Apache Airflow 1.10.x or 2.x
Good Problem Solving Skills
Detail Oriented
Strong Analytical skills working with a large store of Databases and Tables
Ability to work with geographically diverse teams.
Nice to Have
Certification in GCP services
Experience with Kubernetes
Experience with Docker
Experience with CircleCI for Deployment
Experience with Great Expectations
Location:
Hartford, Connecticut.
Education
Bachelors or Masters (preferably BE/B.Tech) - Computer Science/IT
Job Type: Full-time
Salary: $130,000.00 - $150,000.00 per year
Benefits:
Health insurance
Experience level:
11+ years
Schedule:
Monday to Friday
Ability to commute/relocate:
Hartford, CT 06103: Reliably commute or planning to relocate before starting work (Required)
Experience:
GCP: 5 years (Required)
Kubernetes: 2 years (Required)
Docker: 3 years (Required)
Data engineer: 10 years (Required)
Pyspark: 1 year (Required)
Work Location: In person","$140,000 /yr (est.)",51 to 200 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,#N/A,Unknown / Non-Applicable
"WillScot | Mobile Mini
3.4",3.4,"Phoenix, AZ",Data Engineer III,"At WillScot Mobile Mini (NASDAQ WSC), our 4000+ people are at the heart of everything we do. In addition to providing industry-leading pay and benefits, we provide opportunities for development and upward mobility, while investing in the communities we serve.

We are the undisputed leader in providing innovative ﬂexible workspace and portable storage solutions, serving an incredible range of customers across all industries from 240+ locations across the United States, Canada, and Mexico.

Our values are our foundation. We’re constantly striving to diversify our teams to ensure we have the best and brightest talent. We’re deeply committed to creating an inclusive and equitable workplace where each person can contribute while being their authentic self. For more about WillScot Mobile Mini and who we are, click here.

Come build your future with us!

ABOUT THE JOB:
Data Engineer
(Phoenix, AZ)
Maintain, improve and build database solutions to support business operations and analytics. Work with business and Business Intelligence team to translate business requirements into data and analytics solutions and to determine data needs of multiple teams, systems and products. Optimize data pipeline performance and troubleshoot issues. Develop and optimize SQL-based solutions on cloud platforms such as Snowflake. Assemble large, complex data sets that meet functional and non-functional business requirements. Develop and drive standards and best practices on release management technologies, including database schema compares, code check-ins, and merges. Develop new frameworks for tracking and reporting data quality and improving testing efficiency. Manage and direct training on data requirements and system interfaces.
Minimum of Master's degree in Information Technology or closely related technical field and two years experience as Data Engineer, Systems Analyst, Sr. SAP HANA Developer or related position designing, developing and implementing business intelligence and analytical applications, including SAP BW/HANA and Cloud data warehousing solutions.
Please apply to Williams Scotsman, Inc. at https://careers.willscot-mobilemini.com/.
WHAT YOU'LL BE DOING:
EDUCATION AND QUALIFICATIONS:
Disclaimer: This posting describes the general nature and level of work performed and does not represent an exhaustive list of responsibilities, duties, or skills required. Collaboration and teamwork drive our success. Team members may be required to perform duties outside normal responsibilities from time to time as needed.

WillScot Mobile Mini provides equal employment opportunities to employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

WillScot Mobile Mini embraces diversity and is committed to equal opportunity in all aspects of employment, including recruiting, hiring, promotion, termination, leaves of absence, compensation, and training. We are focused on building teams that include a variety of backgrounds, lived experiences, and skills.

The more inclusive we are, the stronger we will be!","$110,745 /yr (est.)",1001 to 5000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Commercial Equipment Services,1955,$1 to $5 billion (USD)
"Open Lending
4.4",4.4,"Austin, TX",Data Engineer,"About Us:
Open Lending provides automated lending services to financial institutions, leveraging the power of Machine Learning and predictive analytics to deliver risk-based pricing – all backed by the security of our insurance carrier partners.
Before taking the company public in 2020, Open Lending ranked among Austin’s fastest-growing, privately held companies. Starting in 2013, the company placed for seven consecutive years on the Austin Business Journal’s Fast 50 list. Additionally, Open Lending has been named as a top workplace by both the Austin Business Journal and the Austin American Statesmen.
The Opportunity
Open Lending is looking for an experienced Data Engineer to join our Data Services team. As a Data Engineer, you will be responsible for the design, build, and deployment of data services to support our Lenders Protection platform, Power BI reporting, and enterprise analytics. As a member of the Data Services team, you will play a key role in contributing to Open Lending’s rapid growth and success.
Three Reasons Why to Apply
Ability to make an impact: Within a small team, you have an opportunity to work in many aspects of data engineering. Our data provides insights into critical business decisions that will unlock Open Lending’s future growth potential.
Engineering culture: We have a tight knit organization with a no blame attitude. Our engineers go out of their way to help fellow team members succeed
Visibility of your work: Collaboration with senior leadership is key to the success of our engineers in meeting organizational goals. Your contributions will be followed closely by all levels of leadership, including VPs and C-suite.
What You’ll Do:
Develop data services to support our Lenders Protection platform
Build data pipelines to ingest, transform, and load data into our Azure data lake
Develop data warehouse ETL processes to support Power BI reporting and enterprise analytics
Build data transformations using Azure Databricks, Azure Data Factory, SQL, SSIS, Python, PySpark, or Scala
Implement enhancements to our data warehouse and data lake
Validate data to support IT compliance and organizational controls
Provide operational support to ensure data services are robust, secure, and reliable
Seek process improvements (e.g., pipeline optimization, automation)
What You’ll Bring:

Bachelor’s degree in Computer Science, Information Technology, or related field
3+ years data engineering and ETL development
3+ years developing SQL for relational databases
2+ years developing pipelines with Azure Databricks
2+ years utilizing Azure tools such as Azure Databricks, Data Factory, Stream Analytics, Event Hubs, or Functions
Previous experience working with SQL Server Integration Services (SSIS)
Previous experience working with data warehouses and data lakes
Previous experience working with NoSQL databases
Familiarity with Github
Excellent communication and teamwork skills
Technologies:
Azure Data Bricks, Azure Data Factory, SSIS, SQL, Python, PySpark, NoSQL
Benefits and Perks:

Medical, dental, life and short-term and long-term disability insurance (company pays 100% of the premium for employee and 100% of the premiums for family plans after 2 years of coverage)
Total annual cash compensation includes base salary and bonus, plus participation in the incentive plan for non-commissioned employees
Unlimited PTO
401k plan with match
Eligible for long-term equity compensation
WFH option
Free onsite covered parking
Paid parental leave for new parents
Onsite gym
Free snack options","$101,231 /yr (est.)",51 to 200 Employees,Company - Public,Information Technology,Software Development,2000,Unknown / Non-Applicable
"AIG
3.7",3.7,"Charlotte, NC",Data Analytics Senior Engineer,"The Data Analytics team at AIG is responsible for developing scalable, resilient, and high-availability solutions to collect and search against massive datasets in a complex, global environment. The Data Analytics organization is also responsible for interfacing directly with data producers in AIG, ensuring high quality, comprehensive data collection in Splunk across a complex, global IT environment. This position provides the day-to-day operations and engineering of the security information and event management (SIEM) solution. This includes configuration management, role-based access controls (RBAC), application and data ingest. The role must demonstrate the knowledge and problem-solving skills to support the daily operations of a SIEM solution. Must be able to solve problems presented by junior engineers and analysts and finding the appropriate resolutions without introducing risk or complexity. This engineer will also be responsible for developing content to support security and operational monitoring and alerting to various teams and lines of business utilizing Splunk and other third-party orchestration software.

Responsibilities

Supports and oversees all the engineering activities to include change management, platform performance and stability, and initial data ingest and normalization.
Maintains and monitors the service tickets and addresses ongoing support for the business units and their data feeds.
Takes an active role in the daily standups and agile frameworks to ensure tasks are being completed/delivered in a timely manner.
Supports the engineering team to help address the day-to-day activities and provides leadership for the team to become more efficient.
Administration of Splunk and Splunk Enterprise Security and underlying infrastructure.
Building automation, dashboards, correlations, key performance indicators, and other various Splunk knowledge objects to empower security operations by improving the quality of their threat detection capabilities.

Qualifications

Bachelor of Science in Computer Science, Information Systems, Software Engineering, or any combination of education and relevant experience
Strong Microsoft Office skills
Experience working in teams.
Good prioritization skills, ability to balance time across key priorities.
Engineering experience with security information and event management (SIEM) solutions
Microsoft and Linux operating system skills
Strong understanding of operating systems and network infrastructures
Prioritized certifications: Splunk Enterprise Certified Architect; Splunk Enterprise Certified Admin; AWS Certified Solutions Architect; Linux Foundation Certified Sysadmin/Engineer
Proven extensive technical experience in Cybersecurity and Information Technology.
Deep hands-on knowledge of Splunk and Splunk Enterprise Security to include the Splunk query language, configuration management, and underlying infrastructure.
Experience working in Linux and Windows based environments, including administration and engineering of solutions running on Linux and Windows OS
Experience with aspects of AWS cloud architecture, including mechanisms for high availability, auto-scaling, and cost efficiency
Strong ability to communicate via written and verbal communication in both formal and casual situations
Demonstrated ability to handle stressful situations with calm effectiveness

A look at our Benefits

We're proud to offer a range of employee benefits and resources that help you protect what matters most - your health care, savings, financial protection and wellbeing. We provide a variety of leaves for personal, health, family and military needs. For example, our ""Giving Back"" program allows you to take up to 16 hours a year to volunteer in your community. Our global mental health and wellness days off provide all colleagues with a paid day off to focus on their mental health and wellbeing.

We also believe in fostering our colleagues' development and offer a range of learning opportunities for colleagues to hone their professional skills to position themselves for the next steps of their careers. We have a tuition reimbursement program for eligible colleagues to enhance their education, skills, and knowledge in areas that relate to their current position or future positions to which they may transfer or progress.

We are an Equal Opportunity Employer

American International Group, Inc., its subsidiaries and affiliates are committed to be an Equal Opportunity Employer and its policies and procedures reflect this commitment. We provide equal opportunity to all qualified individuals regardless of race, color, religion, age, gender, gender expression, national origin, veteran status, disability or any other legally protected categories such as sexual orientation. At AIG, we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation, growth, and profitability. Through a wide variety of programs and initiatives, we invest in each employee, seeking to ensure that our people are not only respected as individuals, but also truly valued for their unique perspectives.

To learn more please visit: https://www.aig.com/about-us/diversity-equity-and-inclusion

AIG is committed to working with and providing reasonable accommodations to job applicants and employees with physical or mental disabilities. If you believe you need a reasonable accommodation in order to search for a job opening or to complete any part of the application or hiring process, please send an email to candidatecare@aig.com. Reasonable accommodations will be determined on a case-by-case basis.

Functional Area:
IT - Information Technology

Estimated Travel Percentage (%): Up to 25%

Relocation Provided: No

AIG Employee Services, Inc.","$106,996 /yr (est.)",10000+ Employees,Company - Public,Insurance,Insurance Carriers,1919,$10+ billion (USD)
Ubiety,#N/A,"Chicago, IL",Senior Data Engineer,"Chicago, IL
Full-Time
Senior Data Engineer
Engineering
Data Team
Summary
Ubiety Technologies, Inc is building a cutting edge AI platform capable of generating world first insights from high velocity Radio Frequency data that will improve the safety and security of homes, businesses, and communities. We offer a fast-paced, highly collaborative startup environment where you will be inventing and developing transformative products to improve the lives of our customers. You will be working alongside extremely talented engineers and creative designers from inception through delivery of a revolutionary product.
We’re looking for a Senior Data Engineer to join Ubiety’s growing Data Team. This is an opportunity to contribute to the development of a high velocity (and high volume) data streaming platform that consumes raw RF data from the world and connects it to our AI capabilities to generate novel insights. This role will contribute directly to building, optimizing, and scaling Ubiety’s data and AI platform effectively as we grow our customer base. This role reports to Ubiety’s Director of Data Science as a member of the Data Team, and will regularly collaborate with the wider Ubiety Engineering team. You will have a significant amount of autonomy and responsibility to own and drive the work. Projects will vary but you will have the opportunity to work with colleagues both across the Data Team and across the wider Engineering team (Backend, Cloud Infrastructure, Embedded/Data Collection, etc).
In addition to a competitive base salary, this position is also eligible for equity awards based on factors such as experience and performance. We believe strongly that if you contribute to adding to Ubiety’s value, you should share in that value.
Standard Salary Range: $150k - $175k annually plus equity
What you'll need
BS or MS Degree in Computer Science or related technical field
3-5 years experience in relevant role (data engineering, software engineering, etc)
Excellent development skills with one or more languages: Python/Go/Rust/Scala/Java
Extensive experience working with SQL and NoSQL databases (Postgres, Snowflake, Redis, Cassandra, MemoryDB)
Strong experience with streaming data and relevant tools, including building real time data streaming applications (e.g. Apache Kafka, Flink, Beam)
Experience working with and building data pipelines to support Machine Learning models and online inference, especially with high-velocity streaming data to generate real-time insights
Experience building metrics and dashboards for monitoring the health and throughput of data streaming pipelines historically and in real-time
Strong background working in cloud environments using relevant services, including building cloud-native applications (AWS and/or GCP)
Experience with version control, Git workflows, CICD pipelines
English language proficiency
What you'll be doing
Lead the development of our data streaming, storage, and query/analysis capabilities - including everything from research/ideation, experimentation, testing, and implementation
Maintain and optimize existing data pipelines to identify and remove bottlenecks, reduce inefficiencies, and prepare for massive scale
Work with the wider engineering team to audit and improve our existing data pipelines and data management practices
Are we using the right database/storage solution for each service?
What should our data retention policies look like for each service?
Where should we handle ETL vs raw data?
Work closely with our Data Scientists to aid in the development of our core analytical engine
Write, audit, and improve our test coverage across all data pipelines and data products
Drive and improve data literacy across the entire company
Note: These responsibilities are just a starting place! We’re a small company, we don’t have rigid roles, and we have a lot to do - we can help you grow wherever your interests take you.
‍
What we'll do for you
A small, tightly-knit team that cares about each other, and cares about leveling everyone up together!
A high level of autonomy, and opportunity to take as much of a leadership role as you are interested in
A highly collaborative environment with an extreme level of transparency and visibility at all levels of the company
A true meritocracy - we care about deliverables, not drama or politics. We’ve got too much to do!
Competitive salary with equity ownership of a fast-growing company
Generous quarterly bonus incentive pool for accomplishing personal and company goals (including both cash and equity)
Continuous learning courses and training offered for free to all employees
Basic health care coverage at no cost to all employees
Flexible schedule
Unlimited PTO policy - Work hard, deliver on your goals, and then take the time to play hard, disconnect, and recharge.","$162,500 /yr (est.)",1 to 50 Employees,Company - Private,Management & Consulting,Security & Protective,2018,Unknown / Non-Applicable
"Deloitte
4.0",4.0,"Washington, DC",Cloud Data Engineer,"Position Summary
Cloud Data Engineer
In this age of disruption, organizations need to navigate the future with confidence by tapping into the power of data analytics, robotics, and cognitive technologies such as Artificial Intelligence (AI). Our Strategy & Analytics portfolio helps clients leverage rigorous analytical capabilities and a pragmatic mindset to solve the most complex of problems. By joining our team, you will play a key role in helping to our clients uncover hidden relationships from vast troves of data and transforming the Government and Public Services marketplace.

Work you’ll do
The Cloud Data Engineer will design future-state, modern data architecture for transformation at the enterprise level using advanced cloud architectural principles. Using tools such as Snowflake and/or Databricks, they will also work with cutting-edge DevOps technologies, develop advanced analytics products, and apply data and statistical programming tools to enterprise data to advance and enable key mission outcomes within cloud environments (GCP, AWS, Azure).
The team
Deloitte’s Government and Public Services (GPS) practice – our people, ideas, technology and outcomes—is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS AI & Data Engineering offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications
Required:
2+ years of data engineering and architecture experience
2+ years of experience cloud analytics (GCP, AWS or Azure)
2+ years experience with Snowflake and/or Databricks
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future
Travel up to 10%

Preferred:
2+ years of prior professional services or federal consulting experience
Creativity and innovation – desire to learn and apply new technologies, products, and libraries
Strong written and verbal communication skills
Strong organizational skills
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters.
Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.
Our people and culture

Our diverse, equitable, and inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our client most complex challenges. This makes Deloitte one of the most rewarding places to work. Learn more about our inclusive culture.
Our purpose

Deloitte’s purpose is to make an impact that matters for our clients, our people, and in our communities. We are creating trust and confidence in a more equitable society. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. We are focusing our collective efforts to advance sustainability, equity, and trust that come to life through our core commitments. Learn more about Deloitte's purpose, commitments, and impact.
Professional development

From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Requisition code: 157460","$104,906 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,1850,$10+ billion (USD)
"Intuit
4.5",4.5,"Mountain View, CA",Senior Software Engineer - Big Data,Come join Intuit as a Senior Software Engineer!,"$159,712 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Software Development,1983,$10+ billion (USD)
"AltaMed Health Services Corporation
3.3",3.3,"Montebello, CA",Senior Data Engineer,"Overview:
Under the direction of Director – Data Engineer, the Senior Data Engineer works closely with business leaders, managers, staff and vendor to accurately gather and interpret requirements, specifications. Develop technical specifications and recommend, design, develop, test, implement, and support innovative and optimal data solutions. Serves as a coach and mentor to Data engineering team
Responsibilities:
Lead on all aspects of a modern and flexible SDLC approach, applied to data engineering, analytics and data science efforts
Provide business guidance and steer efforts toward desired outcomes; partner with internal stakeholders and external vendors to meet strategic data warehouse goals
Research, evaluate and formally recommend third party software and technology package
Responsible for new & existing integrated system & data flow enterprise architecture
Set standards for data engineering functions; design templates for the data management which are scalable, repeatable, and simple
Defines and develops appropriate controls to monitor quality of the enterprise data warehouse process
Preparation of technical specification
Perform all other related duties as assigned
Qualifications:
Minimum 7 years’ experience in a complex data warehouse role for a mid to large size organization; Health Care industry experience highly desired
Minimum 4 years hands on experience with ETL/Data Integration, BI, data mining and modeling, SSIS strongly preferred
Proficiency in all facets of DW Architecture, data flow strategy, data modeling, metadata and master data management
Mastery expertise in SQL and RDBMS systems such as Microsoft SQL Server
Knowledge of and experience working with reporting tools like SSRS and Tableau
Stay abreast of established and industry emerging data technologies
Demonstrated ability to produce high quality technical documentation.
Experience in implementing a data architecture with separation between storage and compute preferred.
Deep understanding of data architecture and ability to coordinate with the implementation team is highly desired.","$126,203 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1969,$5 to $25 million (USD)
Work from Home,#N/A,"Nashville, TN",Data Engineer WFH,"Introduction
Do you have the career opportunities as a Machine Learning Engineer WFH you want with your current employer? We have an exciting opportunity for you to join Parallon which is part of the nation's leading provider of healthcare services, HCA Healthcare.
Benefits
Parallon, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.
We are seeking a highly motivated Data Engineer that is ready to enter the world of MLOps. In this role you will work closely with the Data Scientist and data owners to prepare the data sets and build data pipelines needed for machine learning and statistical models from various data source. You will be with us on our journey as we convert our existing on-prem models to Cloud based models.
Job Summary
We are seeking a highly motivated Data Engineer that is ready to enter the world of MLOps. In this role you will work closely with the Data Scientist and data owners to prepare the data sets and build data pipelines needed for machine learning and statistical models from various data source. You will be with us on our journey as we convert our existing on-prem models to Cloud based models.
Job duties include but not limited to:
Work to understand source systems to pull data from and then build out an ETL process to populate a Data Model that can be used to house the training data
Will need to perform data cleansing and data profiling.
Data Gathering and presentation will use combinations of Python, Azure, BigQuery, Cosmos, Openshift and Vertext AI
Building and maintaining data pipelines that are optimized for machine learning applications
Collaborate with cross-functional teams to ensure successful implementation and deployment of machine learning model
Continuously monitor and evaluate the performance of machine learning models in production
Stay up-to-date with the latest advancements in machine learning and related technologies
As needed, document topology, processes, and solution architecture.
Assist with the training and enablement of end users, including data scientists, program managers, and data consumers.
Utilize benchmarks, metrics, and monitoring to measure and improve services.
Assists with other duties as assigned
Education
Bachelor's degree in Computer Science, Mathematics, Statistics or a related field preferred
Will consider work experience in lieu of Degree or Bachelors Degree
Experience
2-5 years of a solid background in SQL and data modeling with large datasets. Preferably in Teradata or SQL Server
1-2 years of strong programming skills in Python
Familiarity with tools/platforms such as AWS, Azure, Big query, Cosmos, Openshift, Vertext AI
Basic understanding of machine learning algorithms and concepts
Excellent problem-solving and analytical skills
Ability to work independently as well as in a team environment
Strong communication and interpersonal skills
Good track record of presenting findings and analysis to Executives
Proven ability to work with business owners, technical owners and key stakeholders to gather requirements and work through testing scenarios
Parallon provides full-service revenue cycle management, or total patient account resolution, for HCA Healthcare. Our services include scheduling, registration, insurance verification, hospital billing, revenue integrity, collections, payment compliance, credentialing, health information management, customer service, payroll and physician billing. We also provide full-service revenue cycle management as well as targeted solutions, such as Medicaid Eligibility, for external clients across the country. Parallon has over 17,000 colleagues, and serves close to 1,000 hospitals and 3,000 physician practices, all making an impact on patients, providers and their communities.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Bricks and mortar do not make a hospital. People do.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
If you are looking for an opportunity that provides satisfaction and personal growth, we encourage you to apply for our Machine Learning Engineer WFH opening. We promptly review all applications. Highly qualified candidates will be contacted for interviews. Unlock the possibilities and apply today!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$88,427 /yr (est.)",1 to 50 Employees,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Capital Group Companies
4.1",4.1,"Irvine, CA",Data Engineer III,"“I can succeed as a Data Engineer III at Capital Group.”
As a Data Engineer III with an agile mindset, you will contribute to the design, implementation, and delivery of large-scale, critical, and complex data architecture, storage, and pipelines. You will build enterprise distributed data processing systems and data lakes, optimizing compute and storage on cloud platforms.
You will live by the motto: “you ship it, you own it,” by providing and receiving constructive code reviews and taking ownership of outcomes. Your data insights will drive business decisions that improve the lives of millions of people, every single day.
“I am the person Capital Group is looking for.”
You have a bachelor’s degree in computer science, Engineering or a related technical field.
You have 5+ years of experience with agile software development while ensuring disciplined engineering practices are followed with a focus on quality, test driven development, controlled and automated build and releases, code management etc.
You have experience working on a cloud platform like Microsoft Azure Cloud or AWS or GCS (AWS Preferred).
You are comfortable being hands-on and building & maintaining scalable data integration (ETL) pipelines using SQL, DBT, EMR (or Databricks), Python and Spark. You consistently automate testing for these pipelines.
You understand the big data ecosystem, Distributed data processing (Hadoop, Spark, Hive), data formats like parquet/delta/iceberg, orchestration tools like airflow. You can navigate open-source frameworks in search of innovating solutions.
You can write complex, SQL queries across large data sets and have experience working with columnar databases (e.g., Redshift, Snowflake).
You have experience with data modeling and can tailor models to business problems.
You have strong tech translation and enablement skills. You articulate clear connections between the customer and action.
You have a passion for achieving results, even under tough circumstances. You’re persistent in finding the best solutions in order to solve a problem.
You have experience working in a diversity of situations, and adapt to changes with a learning mindset.
Southern California Base Salary Range: $111,404-$178,246
In addition to a highly competitive base salary, per plan guidelines, restrictions and vesting requirements, you also will be eligible for an individual annual performance bonus, plus Capital’s annual profitability bonus plus a retirement plan where Capital contributes 15% of your eligible earnings.
You can learn more about our compensation and benefits
here
.

We are an equal opportunity employer, which means we comply with all federal, state and local laws that prohibit discrimination when making all decisions about employment. As equal opportunity employers, our policies prohibit unlawful discrimination on the basis of race, religion, color, national origin, ancestry, sex (including gender and gender identity), pregnancy, childbirth and related medical conditions, age, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, citizenship status, AIDS/HIV status, political activities or affiliations, military or veteran status, status as a victim of domestic violence, assault or stalking or any other characteristic protected by federal, state or local law.","$144,825 /yr (est.)",5001 to 10000 Employees,Company - Private,Financial Services,Investment & Asset Management,1931,$1 to $5 billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Plano, TX",Data Engineer III - AWS,"JOB DESCRIPTION

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.
Job Summary
As a Software Engineer III at JPMorgan Chase, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job Responsibilities
Acquire data from primary or secondary data sources
Identify, analyze, and interpret trends or patterns in complex data sets
Transform existing ETL logic into Hadoop/AWS Platform
Gathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems
Proactively identifies hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture
Contributes to software engineering communities of practice and events that explore new and emerging technologies
Adds to team culture of diversity, equity, inclusion, and respect
Required Qualifications, Capabilities, and Skills
Formal training or certification on software engineering concepts and 3+ years applied experience
Hands-on practical experience in system design, application development, testing, and operational stability
Proficient in coding in one or more languages
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Strong Experience with UNIX shell scripting to automate file preparation and database loads
Solid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Experience performing data analytics on AWS/Hadoop-based platforms is preferred
Preferred Qualifications, Capabilities, and Skills
Experience with data management process on AWS is a huge Plus
Financial Services and Commercial banking experience is a plus
Familiarity with NoSQL database platforms(DynamoDB, Cassandra) is a plus
Proficiency across the full range of database and business intelligence tools; publishing and presenting information in an engaging way is a plus
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Commercial Banking is focused on helping our clients succeed and making a positive difference in our communities. We provide credit and financing, treasury and payment services, international banking and real estate services to clients including corporations, municipalities, institutions, real estate investors and owners, and nonprofit organizations.","$99,421 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Aunalytics
4.2",4.2,"South Bend, IN",Data Engineer,"Position Overview
At the heart of our Daybreak teams are our super talented Data Engineers. Data Engineers are data experts who dive right into new client projects and make it their job to understand how a client’s data fits into our Industry Intelligent data models. Utilizing this knowledge and the industry’s newest technologie, they create high performance databases that become the very foundation of the work we do. Critical at all stages of the data science process, Data Engineers work cross-functionally with both external and internal teams – from business analysts to data scientists; web app developers to platform engineers; IT teams to high-level executives. Data Engineers also provide valuable feedback to our software team that helps to shape the development of Aunsight, our proprietary end-to-end cloud analytics platform; and the development of our proprietary web applications. The best Data Engineers are patient, persistent, focused, creative, and incredibly curious. They love to learn and seek out opportunities to identify unexpected solutions or develop alternate ways to solve challenging problems.

Essential Duties & Responsibilities:
Build and own “one source of truth” data sets to facilitate consistency and efficiency in extracting and analyzing data from disparate data sources
Ensure data integrity by developing and executing necessary processes and controls around the flow of data
Innovate and improve efficiency of managing data to allow for greater speed and accuracy of producing analyses, metrics, and insights
Collaborate with internal and external teams to understand business needs/issues, troubleshoot problems, conduct root cause analysis, and develop cost effective resolutions for data anomalies.
Provides input into data governance initiatives to enhance current systems, ensure development of efficient application systems, influence the development of data policy, and support overall corporate and business goals
Utilize technology to analyze data from applicable systems to review data processes, identify issues, and determine actions to resolve or escalate problems that require data, system, or process improvement
Verify accuracy of table changes and data transformation processes. Test changes prior to deployment as appropriate.
Recommend and implement enhancements that standardize and streamline processes, assure data quality and reliability, and reduce processing time to meet client expectations
Communicate progress and completion to project team. Escalate roadblocks that may impact delivery schedule
Stay up-to-date on data engineering and data science trends and developments
Follow company policy and procedures which protect sensitive data and maintain compliance with established security standards and best practices
Additional duties as assigned to ensure client and company success

Required Skills:
Bachelor’s degree in Information Science, Computer Science, Computer Engineering, Mathematics, or related field, or 3 plus years of relevant work experience
Experience working with relational database structures, SQL and/or flat files and performing table joins, web crawling, and web development
Proficiency in one or more of the following programming languages: Java, C#, C++, or Python and a familiarity with Node.js
Experience working with commercial relational database systems such as electronic medical records or other clinical systems, client relationship management software, or accounting systems a plus
Familiar with various data management methodologies, data exploration techniques, data quality assurance practices, and data discovery/ visualization tools
Natural curiosity about what’s hidden in the data through exploration, attention to detail, and ability to see the big picture – similar to putting together a 10,000-piece puzzle
Ability to communicate your ideas (verbal and written) so that team members and clients can understand them
Share our values: growth, relationships, integrity, and true grit

What's in it for You?
Opportunity to work with a rapidly expanding tech company in the booming field of data analytics alongside some of the brightest minds in the industry
Opportunity to work with cutting-edge technology in a casual, fun environment
Opportunity to be a part of a local company committed to making a difference in our community
Flexible schedule and paid time off
Social events such as happy hours, game nights, holiday parties, birthday celebrations, movie days, ice cream sundae bars, fancy coffee carts, company softball team, etc.
Competitive salary and benefits package including health, vision, dental and life insurance and 401(k) plan.
Aunalytics is a data platform company that delivers insights as a service to answer a company’s most important IT and business questions. Our cloud-native data platform is built for universal data access, advanced analytics, and AI; unifying disparate data silos into a single golden record of accurate, actionable business information. Through our side-by-side digital transformation model, we provide on-demand scalable access to technology, data science, and AI experts to seamlessly transform a client’s business.","$95,502 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Bayer
3.9",3.9,"Chesterfield, MO",Senior Data Engineer,"At Bayer we’re visionaries, driven to solve the world’s toughest challenges and striving for a world where 'Health for all Hunger for none’ is no longer a dream, but a real possibility. We’re doing it with energy, curiosity and sheer dedication, always learning from unique perspectives of those around us, expanding our thinking, growing our capabilities and redefining ‘impossible’. There are so many reasons to join us. If you’re hungry to build a varied and meaningful career in a community of brilliant and diverse minds to make a real difference, there’s only one choice.

Senior Data Engineer

OUR TASKS AND RESPONSIBILITIES

The primary responsibilities of this role, Senior Data Engineer, are to:

Develops strategies to identify, acquire and use appropriate data sets to develop practical solutions and support decision making;
Defines the strategy and engineering guidelines for major data platforms jointly with the data architect Governance;
Ensures to implement efficient data access control mechanisms to different raw data sources both on-premises and cloud environments;
Identifies, designs, and implements internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability;
Creates and maintains optimal data pipeline architecture;
Builds an infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using various state of the art and big data technologies;
Architects, builds and manages a robust, scalable, data pipeline in a hybrid-cloud environment that provides data processing capabilities to meet functional / non-functional business requirements;
Responsible for establishing and continuously improving sustainable, efficient, scalable, adaptable data processes and data processing applications;
Supports the development of continuous integration processes and infrastructure;
Analyzes large and complex data sets and models to gain insights and build suitable data models;
Assembles large, complex data sets (e.g. text, time series, imagery) into a useful format for analysis using fit-for-purpose database technologies;
Builds services and tools to make data more accessible to all data consumers (tools such as searchable metadata, API gateway);
Ensures end-to-end pipeline orchestration;
Supports the further development of existing enterprise data analytics solutions and be available as a contact person for data support;
Responsible for participating in the data warehouse by continuously improving ELT and ETL processes for the data lakes and data warehouses;
Supports software architecture decisions by writing, maintaining, and reviewing software code and ensures the code quality by automated testing;
Builds semantic data layers and knowledge graphs using fit-for-purpose methodology and technologies e.g. linked data concept, RDF, triple stores, graph databases to make core data structures that have already been discovered findable, accessible and reusable in an efficient way to for data knowledge workers;
Works with the platform development team to design & use tools for data logging and repeatable data tasks to accelerate and automate data scientist duties;
Responsible for processing, cleaning, structuring, and improving data model and building processes to support company-wide analytics;
Participate and propose systems design, architecture and deployment strategy to automate the data aggregation and decisions capturing for the lab systems;
Collaborating with business and technical stakeholders and application end users through various stages of design and development.

Relocation as well as visa sponsorship is available.

WHO YOU ARE

Your success will be driven by your demonstration of our LIFE values. More specifically related to this position, Bayer seeks an incumbent who possesses the following:

Required Qualifications:

Bachelor’s degree;
Experience in data architecture development, data asset management, data modelling, and linked data.

Preferred Qualifications:

Bachelor’s degree in computer science, management information systems, or a related discipline.

Employees can expect to be paid a salary between $108,678.00 to $163,000.00. Additional compensation may include a bonus or commission (if relevant). Additional benefits include health care, vision, dental, retirement, PTO, sick leave, etc.. This salary range is merely an estimate and may vary based on an applicant’s location, market data/ranges, an applicant’s skills and prior relevant experience, certain degrees and certifications, and other relevant factors.


YOUR APPLICATION



Bayer offers a wide variety of competitive compensation and benefits programs. If you meet the requirements of this unique opportunity, and want to impact our mission Science for a better life, we encourage you to apply now. Be part of something bigger. Be you. Be Bayer.
To all recruitment agencies: Bayer does not accept unsolicited third party resumes.

Bayer is an Equal Opportunity Employer/Disabled/Veterans

Bayer is committed to providing access and reasonable accommodations in its application process for individuals with disabilities and encourages applicants with disabilities to request any needed accommodation(s) using the contact information below.



Bayer is an E-Verify Employer.





Location:
United States : Missouri : Chesterfield || United States : Residence Based : Residence Based

Division:
Crop Science

Reference Code:
800274




Contact Us


Email:
hrop_usa@bayer.com","$135,839 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1863,$10+ billion (USD)
"Associated Bank
3.8",3.8,Wisconsin,"Data Engineer, Core Data - Remote within Footprint","Guided by our relentless focus on people and desire to actively listen, we strive to create an inclusive culture and uphold equitable practices for our colleagues and community members. We seek to hire people who share our winning spirit and recognize diverse backgrounds, perspectives, and representation as strengths critical to success. If you thrive in an environment where your growth and development are supported and achieving together is valued, then Associated Bank may be the right place for you.
This is a full time remote role and we can hire candidates located within the Associated Bank footprint. This includes the states of Arizona, Connecticut, Florida, Illinois, Indiana, Iowa, Maine, Massachusetts, Michigan, Minnesota, Missouri, Nebraska, Nevada, New Hampshire, New Jersey, New York, Ohio, Pennsylvania, South Carolina, Rhode Island, Texas, and Wisconsin.
We invite you to view the opportunity below:
This Data Engineer role with Associated Bank will focus on support delivery, system monitoring, and data quality for the core data of the enterprise. This role will also work with leaders to define support models that enable cross team collaborations and efficiencies, monitor data pipelines, analyze feedback and iterate on future sprints to improve data flow. This person will:
Manage the installation and configuration of solutions.
Complete code and script updates, as well as resolving product implementation errors.
Contribute expertise on information system options, risk, and operational impact.
Oversee routine maintenance procedures and performing diagnostic tests.
Collaborate with developers on software requirements, as well as interpreting test stage data.
Have experience programming in a high-level language such as Python, PowerShell scripting, SQL, or other language to script installation, configuration, and provisioning.
Requirements:
Bachelor’s degree or equivalent combination of education and experience in mathematics, computer science, MIS, data science, analytics or related program. Required
Required Experience:
2+ years of familiarity with a broad portfolio of AWS infrastructure tools (EBS, S3, EC2, Elastic IP, Route 53, VPC) and experience with cloud infrastructure management and automation technologies.
2+ years’ experience working with basic structured, semi-structured, and unstructured data.
Basic SQL knowledge proficiency and analytical skills.
Exposure to modern data/analytics architecture (Big Data, Cloud, etc.).
Experience with advanced analytics tools (Python, R, etc.).
Scripting (shell, python, ruby) skills for monitoring and automation.
Preferred Experience:
Experience working with ETL tools such as Informatica, SQL Loader, etc.
Experience working in databases/data warehouses such as Oracle PLSQL, MS SQL server, SSIS, SSRS, etc.
Note: this position can be hired as a Data Engineer or Senior Data Engineer. We will assess applicants based on their skills and years of relevant experience.
In addition to core traditional benefits, we take pride in offering benefits for every stage of life:
Retirement savings including both 401(k) and Pension plans.
Paid time off to volunteer in your community.
Opportunities to connect with others through our diversity-focused Colleague Resource Groups.
Competitive salaries with professional development and advancement opportunities.
Bonus benefits including well-being programs and incentives, parental leave, an employee stock purchase plan, military benefits and much more.
Personal banking, loan, investment and insurance benefits.
Associated Bank serves more than 120 communities throughout Wisconsin, Illinois and Minnesota and we consider our colleagues critical to our continued success. See why our colleagues continually vote us a best place to work in the Midwest. Join our community on Facebook , LinkedIn and Twitter .
Associated Bank is an equal opportunity employer committed to creating a diverse workforce. We support a work environment where colleagues are respected and given the opportunity to perform to their fullest potential. We consider all qualified applicants without regard to race, religion, color, sex, national origin, age, sexual orientation, gender identity, disability or veteran status, among other factors. Applicants with a disability who need assistance applying for a position with Associated Bank are asked to email: Careers@AssociatedBank.com.
Compliance Statement
Fully complies with all applicable enterprise policies and procedures. Acts in compliance with all applicable laws and regulations as outlined in training materials, including but not limited to Bank Secrecy Act. Responsible for reporting suspicious activity to Financial Intelligence. Responsible to report all customer complaints as prescribed and procedure violations to management or HR. Responsible to report ethical concerns as needed to Associated Bank’s anonymous Ethics Hotline.",#N/A,1001 to 5000 Employees,Company - Public,Financial Services,Banking & Lending,1870,$1 to $5 billion (USD)
"KYM Advisors, Inc
3.9",3.9,"Reston, VA",Data Engineer,"KYM Advisors focuses on innovative Solutions that support the ever-volving Mission and Technical environments. We are a team of talented 'Solutioneers' specializing in Information Management, Cybersecurity, DevOps and Program Manager.
KYM Advisors is seeking Junior to Subject Matter Expert Data Engineers to support a newly awarded contract. This client develops and conducts IC enterprise-level assessment, improvement, and oversight activities to further the their mission. This mission includes enterprise management of training across the IC and DoD to educate users on how the National Intelligence Priorities Framework (NIPF) influences the collection and analytic communities and how to leverage NIPF processes and products. The NIPF is the primary mechanism to establish, disestablish, manage, and communicate national intelligence priorities. The NIPF reflects customers' priorities for national intelligence support and ensures that enduring and emerging national intelligence issues are addressed (ICD 204). The NIPF Training Program mission requirement is for development and delivery of NIPF seminars and courses, including development of web-based training (WBT).
Primary responsibilities:
Designs, develops, builds, analyzes, evaluates, and installs database management systems to include database modeling and design, relational database architecture, metadata and repository creation and configuration management.
Defines and oversees database organizations, standards, controls, procedures, and documentation. Provides technical consulting in the definition, design, and creation of a data base environment.
Advises applications development staff and users on data-based solutions to business problems, data architectures, data base management system facilities and capabilities, and the operation and tuning of data bases.
Ensures economic and efficient availability of data within adequate safeguards.
Designs and implements databases with respect to access methods, access time, batch processes, device allocation, validation checks, organization, protection and security, documentation, and statistical methods.
Uses data mapping, data mining and data transformational analysis tools to design and develop databases.
Determines data storage and optimum storage requirements.
Prepares system requirements, source analysis and process analyses and design throughout the database implementation.
Requirements:
BA/BS and 1 to 18 years of experience or a Masters and 10 years of experience.
TS/SCI with Poly level clearance is required
Demonstrated successful development experience with full life cycle of government database management systems to include database modeling and design, relational database architecture, metadata and repository creation and configuration management.
Entry to Seasoned applications development experience with data-based solutions to business problems, data architectures, data base management system facilities and capabilities, and the operation and tuning of data bases.
Excellent communications skills (both oral and written) with process-oriented organizational skills to ensure project success.
Must be a U.S. Citizen and have an active Top Secret/SCI with Polygraph clearance.
Applicants have rights under Federal Employment Laws:
EEOC Know Your Rights: Workplace Discrimination is Illegal
EEO is the Law - Federal Contractors/Subcontractors
Employee Polygraph Protection Act
Pay Transparency Nondiscrimination Provision","$101,044 /yr (est.)",1 to 50 Employees,Company - Private,Management & Consulting,Business Consulting,2010,Unknown / Non-Applicable
"Planar Systems
3.4",3.4,"Hillsboro, OR",Associate Data Engineer,"The Associate Data Engineer will play a pivotal role in helping to build and operationalize the reporting data necessary for Enterprise Analytics initiatives while leveraging industry standard practices and tools. They will collaborate with the Enterprise Analytics Architect and Senior Data Engineers in building, managing, and optimizing data pipelines and deploying these data pipelines effectively across development and testing tiers and into production for consumers across the enterprise. The Data Engineer will also be tasked with developing, implementing, and maintaining ETL/ELT processes, data models, and reports/dashboards that meet the organization's data analysis and visualization needs. They will work closely with cross functional team members and subject matter experts to gather technical requirements, analyze business data, and create recommended reporting that provides actionable insights and informs critical decision-making.

What you'll do:

Closely collaborate with the Enterprise Analytics team to design, build, test, and implement data pipelines from key services, applications, and systems. Maintain and optimize the data analytics and reporting pipelines to ensure relevant information is highly available and accurate.
Work closely with business stakeholders to gather requirements and understand business needs.
Analyze and manipulate complex data resources to provide valuable insights and inform business decisions.
Implement best practices for data warehousing, data integration, and data quality to ensure data accuracy and consistency.
Troubleshoot and resolve data quality and pipeline issues, and work to proactively prevent recurrent future issues.
Help implement and curate end user analytics data models, reports, and dashboards using Power BI report development platforms and tools.
Help administer and manage the Power BI Report Server and Cloud Tenant platforms.
Utilize Azure cloud technologies and services such as Azure Data Factory, Synapse Analytics, Analysis Services, and DevOps to design, develop, and deploy scalable and reliable data solutions.
Utilize Microsoft cloud tools and services such as Power Platform (Power Automate, Power Apps, and Dataverse) to develop and administer data-driven solutions that integrate with Microsoft Dynamics 365, Salesforce and other core business and analytics services.
Maintain and enhance existing ETL/ELT processes using SSIS and SQL programming to load data from ERP/CRM systems into the data warehouse.
Help maintain and enhance existing multidimensional data models and analysis cubes using SSAS to provide fast and efficient end user data analysis. Assist in migration to newer tabular data models
Keep current with industry trends and best practices in BI and Analytics, data warehousing, data engineering, and data visualization.

What you'll bring:
Bachelor’s degree in computer science, Information Systems, related technical field, or equivalent experience in an enterprise organization.
3+ years of experience working in roles involving data engineering, data analytics, data warehousing, business intelligence or a related field.
Relevant Microsoft BI, Azure or other industry certifications and technical training is a plus.
Prior experience working with manufacturing data is desirable.
Prior dba or working knowledge of RDBMS systems such as SQL Server.

Benefits – All benefits start on first day of employment!
75% employer-paid medical for employee. Family coverage also included.
100% employer paid dental, and vision for employee and dependents
100% employer paid long-term, short-term disability, and life insurance policy
401k Match, if you’re contributing 5% we match 4%. 100% vested immediately.
10 paid holidays
Starting at 15 days paid PTO (inclusive of sick and vacation time) annually
Employee Assistance Program (EAP)
Flexible Spending Account (FSA)
EEOC Statement:
Planar is an equal opportunity employer, we believe in fostering a culture of equality, diversity, and inclusivity. Our commitment to this goal is clearly expressed in our zero-tolerance policy for discrimination and harassment of any kind, including on the basis of race, color, sex, age, religion, sexual orientation, national origin, disability, genetic information, pregnancy, protected veteran status or any other characteristic protected by applicable federal, state, or local laws. Our hiring practices ensure that decisions are based solely on qualifications, merit, and current business needs, while extending to all aspects of our operations - from recruitment and promotion, to layoff and recall, to leave of absence, compensation, benefits, and training. We are committed to remaining a drug free workplace","$93,896 /yr (est.)",501 to 1000 Employees,Subsidiary or Business Segment,Information Technology,Computer Hardware Development,1983,$100 to $500 million (USD)
"GM Financial
3.8",3.8,"Arlington, TX",Data Governance Engineer,"Overview:
Why GM Financial?

GM Financial is the wholly owned captive finance subsidiary of General Motors and is headquartered in Fort Worth, U.S. We are a global provider of auto finance solutions, with operations in North America, South America, and the Asia Pacific region. Through our long-standing relationships with auto dealers, we offer attractive retail financing and lease programs to meet the needs of each customer. We also offer commercial lending products to dealers to help them finance and grow their businesses.
At GM Financial, our team members define and shape our culture — an environment that welcomes new ideas, fosters integrity, and creates a sense of community and belonging. Here we do more than work — we thrive.

Our Purpose: We pioneer the innovations that move and connect people to what matters.

Responsibilities:
About the Role:

We are building an expanded Data Governance & Enablement practice focused on reducing risk, delivering trust, driving maturity, and enabling speed related to data operations. To support these priorities, we are rolling out technical solutions providing enhanced capabilities in the areas of metadata management, privacy compliance, data quality management, and master data management. This role is responsible for on-going collaboration with Product Owners and Analysts to deliver technical solutions and capabilities that support key data governance functions. In addition, this role is responsible for understanding the development and progression of the systems in use, new capabilities being delivered, and their potential value to the practice.

Qualifications:

What makes you a dream candidate?
Collaborate with product owners to define and deliver new technical solutions supporting the data governance practice
Manage and administer data governance systems and tools
Configure and execute connections and integrations to source systems
Develop new integrations and customizations supporting data governance services
Identify technical gaps and propose solutions
Gather and publish technical metrics related to data governance processes and systems
Provide technical support to users of data governance systems
Perform other duties as assigned
Conform with all company policies and procedures","$103,447 /yr (est.)",5001 to 10000 Employees,Company - Public,Financial Services,Banking & Lending,1992,$5 to $10 billion (USD)
"Applied Medical
3.4",3.4,"Rancho Santa Margarita, CA",Data Center Engineer,"Applied Medical is a new generation medical device company with a proven business model and commitment to innovation fueled by rapid business growth and expansion. Our company has been developing and manufacturing advanced surgical technologies for over 35 years and has earned a strong reputation for excellence in the healthcare field. Our unique business model, combined with our dedication to delivering the highest quality products, enables team members to contribute in a larger capacity than is possible in typical positions.
Position Description:As a Data Center Engineer, you will be responsible for working within the framework of a team and performing the following activities during specific timeframes:
First 30 days
Participate in department trainings and standard operating procedures (SOPs) to learn about company solutions and relevant specialties
Discuss your goals and expectations with your team leaders
Read and review all relevant team resources and materials
Immerse yourself in team meetings and discussions to understand the team structure and individuals that make it up
Discover the systems we use and the processes the team follows
Join project meetings and assist with any tasks, as needed
Within 60 days
Support team meetings and agendas
Review current learning materials and participate in feedback to identify possible learning gaps
Recommend and implement solutions through process improvements, growth and training opportunities, or software upgrades
Continue personal development and project management work
After 90 days to 1 year
Develop interpersonal connections and relationships to effectively accomplish project objectives and deliverables
Use the knowledge and experience gained in the first 60 days to help provide oversight across all Data Center Operations activities
Address design issues to deliver quality solutions to customers.
Complete for any additional tasks or duties, as needed
Position Requirements:
This position requires the following skills and attributes:
More than five years' experience or equivalent working in an information technology (IT) or IT-related field
Solid background in critical facilities design, architecture, engineering, and construction services
Proficiency in on-premise and cloud-connected enterprise infrastructure software, including operational systems (Microsoft Windows and Linux/UNIX), patch management, virus protection, Microsoft Office platforms (SharePoint and Teams), Active Directory and Azure Active Directory, Dynamic Host Configuration Protocol (DHCP), Domain Name System (DNS), Microsoft Exchange, Identity Management (ID) systems, and various database platforms (Microsoft SQL, Oracle, Postgres)
Knowledge of on-premise and cloud-connected enterprise storage systems, such as direct-attached storage, object-based, Network-Attached Storage (NAS), Storage Area Network (SAN), and cloud-based
Understanding of telecommunication infrastructure and essential communication systems, including digital microwave, radio, satellite, Wide Area Networks (WAN), Local Area Network (LAN), copper Ethernet, fiber-optic networks, and intra-building cabling
Familiarity with server and network security, including role- or rule-based Access Control Lists (ACLs), logical and physical level security, anti-virus end-point protection, and Secure Sockets Layer (SSL) encryption, and certificates
Ability to write scripts for automating data center processes
Expertise in monitoring energy usage for data center efficiency
Experience conducting environmental and air quality tests to ensure compliance with regulations
Quick learner with the ability to address issues in a 24x7 mission-critical environment
Effective project management skills, capable of handling multiple projects simultaneously
Proven capability in setting short-term and long-term objectives aligned with strategic goals
Demonstrated ability to build and maintain strong customer relationships
Excellent written and verbal communication skills
Confident, articulate, and professional presentation abilities
Strong time management, prioritization, and organizational skills
Hands-on experience in installing, troubleshooting, repairing, and replacing data center equipment
Diligent in maintaining comprehensive documentation of server and storage configurations and changes
Proficient in conducting capacity assessments for future growth planning
Familiarity with building management protocols like Modbus and BACnet
Basic understanding of 568A and 568B color codes and applications
Adherence to all escalation procedures for critical or emergency situations
Preferred:
The following skills and attributes are preferred:
Bachelor's degree in a related field
More than five years of Data Center experience
Relevant certifications
Benefits:
The base compensation range for this role is $65000 - $100000 / year for the position in California. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to skill set, depth of experience, certifications, and specific work location. The range displayed reflects the minimum and maximum target for new hire salaries in California based on the date of this job posting. Your recruiter can share more about the specific salary range compensation package during your hiring process.
Please understand that the compensation range may be modified in the future. Each amount of pay is considered to be wages or compensation once such amount is earned and determinable. The amount and availability of any bonus, commission, benefit or any other form of compensation may be modified at the Company’s sole discretion, consistent with the law.
The total compensation package for this position may also include [bonuses and/or other applicable incentive compensation plans].
Our total reward package also includes the following:
Training and mentorship with ongoing learning and development courses
On-campus wellness activities
Comprehensive medical and dental and vision coverage
Education reimbursement program
401(k) program with discretionary employer match
Generous vacation accrual and paid holiday schedule
All compensation and benefits are subject to the requirements and restrictions set forth in the applicable plan documents and any written agreements between the parties.
Equal Opportunity Employer
Applied Medical is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, disability (mental and physical), exercising the right to family care and medical leave, gender, gender expression, gender identity, genetic information, marital status, medical condition, military or veteran status, national origin, political affiliation, race, religious creed, sex (including pregnancy, childbirth, breastfeeding and related medical conditions), or sexual orientation, or any other status protected by federal, state or local laws in the locations where Applied Medical operates.
Location: 22872 Avenida Empresa, Rancho Santa Margarita, CA 92688
Location: 22872 Avenida Empresa, Rancho Santa Margarita, CA 92688
Job Type: Full-time
Pay: $65,000.00 - $100,000.00 per year","$82,500 /yr (est.)",1001 to 5000 Employees,Company - Private,Manufacturing,Health Care Products Manufacturing,1987,$500 million to $1 billion (USD)
"Endeavor Operating Company, LLC
3.6",3.6,Remote,Data Engineer,"Who We Are:
Who We Are:
IMG Academy is the world’s leading sports education brand, providing a holistic education model that empowers student-athletes to win their future, preparing them for college and for life. IMG Academy offers an innovative suite of on-campus and online experiences, providing growth opportunities for all student-athletes through:
Boarding school and camps, via a 600-acre state-of-the-art campus in Bradenton, Fla. (
IMGAcademy.com
)
Online coaching via the IMG Academy+ brand, with a focus on personal development through the lens of sport and performance (
IMGAcademy.com/Plus
)
Online college recruiting, via the NCSA brand, providing content, tools, coaching and access to a network of 40,000 college coaches (
ncsasports.org
)
Our team has a deep appreciation for the transformative power of sports and holistic personal development. Our leadership is actively investing in the growth of the organization. We continue to broaden and deepen our technology platform and team in pursuit of our vision for empowering youth sports and the path-to-college for student-athletes.
Position Summary:
The Data Engineer is responsible for implementing the technical direction of the Data Engineering team. This is a hands-on, individual contributor role operating on a cross-functional and skill-focused team. The Data Engineering team enables data- and insight-driven decision-making and planning by providing consistent, accurate and timely data to analysts, data scientists and business users. Working closely with platform development managers, Data Engineers design, implement and maintain data infrastructure used by Product and Platform Engineering teams in the form of data pipelines, data lakes and warehouses, business intelligence and visualization tools, and services for data quality and governance. Working with analysts and data scientists, they build custom data integrations, develop and deploy machine learning endpoints, and optimize the performance and scalability of customer-facing and internal data applications. The Data Engineer’s work provides teams with visibility into NCSA’s business performance, product delivery, and the outcomes student athletes, coaches and teams achieve to realize their goals. As one of the Data Engineers in the organization, you are empowered to make significant, impactful technical and cultural decisions, and help shape and guide the evolution of our data platform and company data strategy. Reporting to the Director, Data Engineering, the role requires deep expertise in the design, implementation, and continuous improvement of cloud-native data infrastructure and platforms.
Position Responsibilities:
You have experience (3-5 years) in data engineering, building capabilities with architecture, modeling (physical and logical), storage, resilience, and security.
You have experience in the mechanics of software engineering (preferably Python) practices to write Airflow DAGs and scripts.
You have deep expertise with cloud-based distributed data platforms, preferably in AWS.
You have experience developing data pipelines using Airflow, ELT design, optimization and maintaining data storage systems using S3 and Redshift or similar tools.
You have implemented batch and streaming data pipelines at scale and built platform components with automated testing suites using test-driven development principles for data.
You are familiar with relational databases (e.g. Postgres).
You have knowledge of SQL, Python and DBT.
You know how to create efficiency in data handling by tracking the lineage, maintaining the quality, and improving the discoverability of data.
Knowledge, Skills and Abilities:
Design, develop and maintain automated data pipelines to standardize and refine data collection for existing and new data sources used to power analytics and data science for business teams.
Develop extensive subject-matter expertise around individual and categories of data pipelines to establish operating standards and service-level agreements with analysts and data scientists.
Forecast data utilization and identify potential bottlenecks or optimization opportunities.
Apply test-driven development methods to data platform configuration and deployment.
Work with Software Engineering teams to adopt standard data platform components for their systems with the confidence that event data will be safely collected, stored, and transformed.
Lead technical conversations and decision-making around data architecture and implementation with Engineering teams, helping to identify opportunities and recommend technical solutions.
Partner with Analysts, Data Scientists and Data Program Managers to apply, implement and productionalize descriptive, predictive, and prescriptive statistical models on large datasets.
Define data operations approach and operating methodology for versioning, testing, security, test data management, data migrations, data quality, metadata, and documentation.
Dedicate meaningful time to research, evaluation and implementation of new tools and methods (Open Source and commercial) to meet changing organizational data needs and opportunities.
Serve as part of an on-call support rotation with other engineers to debug, troubleshoot and resolve data platform using the Incident Command System methodology.
Background Requirements:
Requires a background check upon offer.
Don’t meet every single requirement? We are dedicated to building a diverse, inclusive, authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfect with every qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.
Get to know us better:
www.imgacademy.com
IMG Academy provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",#N/A,Unknown,Company - Public,"Arts, Entertainment & Recreation",Culture & Entertainment,1898,Unknown / Non-Applicable
"Aevitas IT
3.5",3.5,"Spring, TX",Data Engineer,"To be successful in this role you will:
Write, analyze, review, and rewrite programs, using workflow charts and diagrams, and applying knowledge of computer capabilities, subject matter, and symbolic logic.
Perform revision, repair, or expansion of existing programs to increase operating efficiency or adapt to new requirements.
Analyze user needs and software requirements to determine feasibility of design within time and cost constraints.
Confer with systems analysts, engineers, programmers and others to design systems and to obtain information on project limitations and capabilities, performance requirements and interfaces.
Compile and write documentation of program development and subsequent revisions, inserting comments in the coded instructions so others can understand the program.
Develop and perform software system testing and validation procedures.
Store, retrieve, and manipulate data for analysis of system capabilities and requirements.
Analyze information to determine, recommend, and plan installation of a new system or modification of an existing system.
Coordinate software system installation and monitor equipment functioning to ensure specifications are met.
Consult with engineering staff to evaluate interface between hardware and software, develop specifications and performance requirements, or resolve customer problems.
Confer with data processing or project managers to obtain information on limitations or capabilities for data processing projects.
Participate in on-call and after-hours support, including weekends and holidays.
Lead medium projects as defined by scope
Technical Qualifications:
Bachelor of Science degree in computer science, engineering, or management of information systems is preferred.
Minimum of 5 years of software development experience
Experience creating dashboards and analysis using tools such as Microsoft PowerBI, TIBCO Spotfire, Tableau, etc. is required.
Experience querying and developing Oracle and Microsoft SQL Server databases is required.
Experience integrating data using ETL technologies such as Informatica, Dell Boomi, Microsoft SSIS/DTS, etc. is required.
Experience integrating applications using APIs and scripting languages. Python/R is a plus.
Knowledge of WellView, SiteView, Enertia, and other upstream oil and gas systems is a plus.
Ability to communicate ideas in both technical and user-friendly language
Strong customer focus mindset
Benefits:
An attractive 401(k) plan
Paid vacation, holidays and benefit hours
Family medical, dental and vision insurance
Educational assistance
Matching gift program
Job Type: Full-time
Pay: From $126,427.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Compensation package:
Yearly pay
Schedule:
Monday to Friday
Ability to commute/relocate:
Spring, TX 77389: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Hybrid remote in Spring, TX 77389","$126,427 /yr (est.)",51 to 200 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Retool
4.2",4.2,"San Francisco, CA",Data Engineer,"Team
Data Engineering
Location
San Francisco, CA

ABOUT RETOOL:
At Retool, we’re changing the way software is built. We’ve developed the fastest way to build internal tools, saving companies time, resources, and engineering bandwidth. Whether it’s refunding orders, underwriting loans, managing marketplaces, rolling out new features, analyzing transactions, or providing customer support, Retool makes it dramatically faster and easier to build internal tools that teams need. We believe that the future of software development lies in being a force multiplier for developers and technical builders, helping them move considerably faster building a lot more software. We’re looking for highly collaborative people as we build a world-class team to support this mission and we’d love for you to join us!
WHY WE'RE LOOKING FOR YOU:
Retool is a fast-growing company with quickly evolving business needs. We’re looking to hire engineers to help us build out our data ecosystem to serve the needs of our business today and for broader scale years from now. We're looking for someone who is ready to get their hands dirty, is motivated by having an impact on the business, and is constantly curious. This is the right role for someone who thrives while making sense of the blurry space that is data at a high growth startup.
WHAT YOU'LL DO:
You’ll design and build a foundation that strengthens Retool’s data culture at scale. You’ll take on projects that solidify Retool’s reporting capabilities and help the company remain data-driven. You'll develop and scale ingestion infrastructure, optimize our ETLs, and design our data architecture for scale, with a keen eye for data warehouse management and tooling. You'll also take on ownership of our data stack to ensure that your teammates are able to access the data they need to make decisions and technical teams are able to quickly implement events. We’ve already built out a solid stack on top of Segment, Databricks, DBT, and of course, Retool, but we need your help to ensure it scales with the company as our user base grows.
WHO YOU'LL WORK WITH:
You’ll work with stakeholders across the business, including data scientists, finance, marketing, engineering, product, operations, and support. You’ll be joining a broader team of Retools who are passionate about serving our customers, enjoy collaborating to build an incredibly innovative product, and enjoy swapping stories. If this sounds like you, we’d love to hear from you!
IN THIS ROLE, YOU'LL:
Architect and scale a modern data platform that will be used internally by all of Retool
Build and maintain scalable ETL pipelines to efficiently process and transform large volumes of data from source systems into our data warehouse
Work with our engineering teams to ensure robust instrumentation across areas of the product
Partner with business stakeholders to synthesize and develop requirements for core tables
Implement monitoring and observability to guarantee data quality and consistency
Articulate and implement best practices around ingestion frameworks and data pipeline development
THE SKILLSET YOU'll BRING:
Background in Data Engineering, 5+ years of experience building and maintaining scalable data infrastructure, including distributed processing solutions (e.g. Spark), cloud-based data lakes and warehouses (e.g. Databricks, Snowflake, BigQuery), workflow management (e.g. Airflow, Luigi), and data transformation tools (e.g. DBT)
Experience using Infrastructure as Code (IaC) to automate data infrastructure provisioning and management (i.e. Terraform)
Experience implementing and defining best data practices at scale
Experience proactively identifying opportunities to improve ETL & dashboard performance and cost
Excellent business acumen with the ability to translate stakeholder requirements into data models
Proficiency with common git workflows and at least one programming language (e.g. Python, Scala, Java)
A solution-oriented growth mindset. You’ll need to be a self-starter and thrive in a dynamic environment
A bias towards communication and collaboration with business and technical stakeholders
Quantitative rigor and systems thinking
Retool offers generous benefits to all employees. For more information, please visit the benefits and perks section of our careers page!
At this time, Retool is only set up to employ in the US and UK.","$116,314 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Computer Hardware Development,2017,Unknown / Non-Applicable
"Torch.AI
2.7",2.7,"Leawood, KS",Data Engineer,"Why this Role is Interesting?
There are very few companies in the world with the credentials we have. You’ll have an opportunity to support critically important customer missions and work with paradigm-changing technology.
You’ll be supporting one of the largest programs and customers in the company, offering significant visibility of your impact.
The role is critical in positioning Torch.AI as a leader in data infrastructure AI in the market and helps ensure the company is well-positioning for the next stages of growth.
You’ll have the opportunity to showcase your skills as a seasoned data engineer, while also learning from a team of extremely talented and credentialed indviduals.
Torch.AI is in the midst of a pivotal, high-growth period, with several initiatives and investments anticipated to fuel hyper-growth across a diverse customer base.
You’ll play a significant roe in strengthening Torch.AI’s reputation as one ofForbes Best Startup Employers.
A Game-Changing AI Company in the Heart of the Midwest
Torch.AI, the Data Infrastructure AI Pioneers™, are headquartered in Kansas City with offices in Washington, DC. We build AI that makes data easier to use by processing data in-flight and radically evolving analytic and operational capabilities in any IT environment. Our Torch Platform instantly unlocks value from data and provides information needed for humans and machines to be more productive. Partnering with U.S. military forces, our solutions and people support a growing array of national defense capabilities with advanced technology.
At Torch.AI, we’re passionate about building software that solves some of the world’s most challenging problems. We have helped our customers enhance top-secret clearances, stop fraud at massive scales, discover new trends and global events, gain an edge in financial markets, and beyond. We are driven by our mission to unlock human potential and serve our clients in valuable and meaningful ways.
The Role
The U.S. Department of Defense relies on complex data every day to drive decisions, support warfighters, mitigate risks to national security, and ensure our global leadership. Data is being generated at an exponential rate and existing solutions don’t address today’s needs.
This Data Engineer role will work in support of developing and implementing solutions for a major U.S. Department of Defense program. The role will engage with cross-functional teams to discover all existing data types and documentation that are currently in use in multiple data producer environments. The successful candidate will be a creative problem solver, diligent and detail oriented, and will have a sharp focus on value creation and mission importance. They will have a keen eye on understanding customer needs, how they currently leverage Torch.AI software, and will help in driving the future success of the customer program.
What Success Looks Like
Participates in design meetings and consults with other staff to evaluate interface between hardware and software, and operational and performance requirements of overall system.
Develop and perform automated builds, testing, and deployments in support of NiFi development.
Work with the development and services teams to support service artifacts, which could include bug fixes, security improvements, functional extension, performance improvement, refactoring, and/or rewriting.
Experience in building data ingestion workflows/pipeline flows using NiFi, NiFi registry, and other Nifi management tools.
Create Artifact that will primarily be Apache Nifi flows and/or custom processors used in Nifi flows.
Create tables in Trino to deliver data via APIs to package and disseminate data to mission partners.
Build data models and analytics to support mission needs.
Pull or receive command and control files.
Test services artifacts for correctness and/or performance.
What We Value
B.S. degree in related field or equivalent combination of training and experience.
5+ years of proven work experience as a data engineer.
Demonstrable experience with Java, Parquet, Nifi, Kafka.
Experience with ETLs and APIs.
Understanding and Experience with Apache Nifi tool.
Analysis of the product to determine the end points as per the requirements.
Well-versed with docker.
Hands on experience on GIT.
Understanding of security products focusing on IAM.
Knowledge on ETL focusing on mapping.
Good to have experience with NiFi-supported scripting languages (Python) and writing regular expressions.
Experience creating custom NiFi processors.
Full Software Development Life Cycle (SDLC) experience.
Work well within a formal team structure and with minimal supervision.
This position REQUIRES an active TS/SCI. TS/SCI with CI Poly is preferred.
Work Environment & Travel Requirements

This job operates in state-of-the-art, professional office environment.
You will be expected to work out of Torch.AI's Leawood, KS office; limited hybrid/remote days may occasionally be available.
Travel: You will be required to travel to Northern Virginia and/or St. Louis on a periodic basis (10-50%) to work in and attend client meetings in a SCIF environment.
Perks & Compensation

Competitive salary, performance bonus, and benefits package. The salary range for this role is commensurate with experience.
Opportunity to participate in Torch.AI’s employee equity grant program.
Unlimited PTO.
In-Office Catering for Lunch Every Monday.
Access to company suite at the T-Mobile Center, with tickets to all major events and concerts.
Amazing professional growth opportunity at a high growth start-up.
Passionate, smart, and fun people to work with.
Excellent medical, dental, and vision insurance.
Life and disability coverage.
Relocation assistance.
11 paid holidays each year.
Torch.AI is an Equal Opportunity /Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, protected veteran status or status as an individual with a disability.","$93,428 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,2018,Unknown / Non-Applicable
"Stuzo
4.4",4.4,Remote,Senior Data Engineer,"What You’ll Do:
We are seeking a Senior Data Engineer to join our team and help us build the next generation of data tools for our retail and commerce loyalty platform. The ideal candidate will have a passion for tackling complex challenges related to extracting insights from transactional data. In this role, you will work closely with our Application Development teams, Customer Support, Business SMEs, and stakeholders to design and implement data pipelines that transform our data into valuable insights. As we strive to scale and deploy new technologies that enhance the user experience and provide deeper insights, your expertise will be critical to our success.
Responsibilities + Activities:
Explores and documents new sources of data.
Implement schema parsers for standard event protocols.
Own Data Quality Management for specific data lake models.
Handle performance improvements and bottleneck removal.
Adds and maintains schemas for elements of the Open Commerce data lake.
Develops and tests data pipelines using PySpark.
Creates notebooks and configures jobs for running data pipelines on Databricks.
Collaborates with the team to ensure quality, consistency, and performance of all pipelines across the entire data platform.
Prepare and support internal documentation for the data lake.
Experience & Skills You’ll Need:
Excellent interpersonal, communication and organizational skills are essential.
Self motivated, ability to work as collaborative member of a team
5-8 years experience working with data in databases such as PostgreSQL, MySQL, etc.
Knowledge of ETL/ELT data pipelines and best practices
3-5 years experience coding and testing with Python
2-3 years experience working with Spark and Structured Streaming
2-3 years experience working with Spark orchestration platforms such as Databricks
Experience with project and bug-tracking systems like Jira
Experience with Scrum processes.

Reports To:

This position reports to the Principal Data Engineer.

We are looking to add amazing folks to our team who will bring diversity across many lines, including race, ethnicity, religion, sexual orientation, age, marital status, disability, gender identity, sex, and country of origin. And while we’re headquartered in Philadelphia, we have a “Remote First” approach to work and do not see being in the office or living in the Philadelphia area as a requirement. Several of Stuzo’s Senior Leaders (your future peers, we hope) are fully remote.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,#N/A,Less than $1 million (USD)
"Entergy
3.8",3.8,"New Orleans, LA",Data Engineer,"Posting End Date:
Work Place Flexibility: Hybrid
Legal Entity: Entergy Services, LLC
This posting will be used to fill multiple vacancies. These vacancies can be filled as a Data Engineer I – Data Engineer II depending on related experience.
These positions can be filled in New Orleans, LA or Little Rock, AR. Relocation is not offered for these roles.

Job Summary/Purpose:

The Data Engineer reports to the Manager, Business Services Operations – Meter to Cash, and often works closely with the VP Meter to Cash and VP Contact Center and their teams to help drive continual improvements across Entergy and within Entergy Customer Operations.
This position will: (1) develop, construct, test and maintain architectures, such as databases and large-scale processing systems; (2) analyze and optimize raw data that may contain human, system errors; (3) recommend ways to improve data reliability, efficiency, and quality by employing a variety of languages and tools to marry systems together or try to hunt down opportunities to acquire new data from other systems to support sound business decisions; (4) ensure that the architecture that is in place supports the requirements of the of Customer Operations stakeholders, and the business; (5) deliver data visualization and insights to Customer Operations stakeholders to drive sound business decision and optimization. (6) Develop data set processes for data modeling, mining, and production.

Job Duties/Responsibilities

Analytics
Support the multi-year analytics roadmap to transform how Customer Operations uses data for decision support and process improvement.
Architect, build and publish Customer Operations metrics, analytics, and reporting for inclusion in Customer Operations and business communications.
Extract and aggregate data sets from various sources, including both databases and flat files.
Apply data analytics practices and the right tools (e.g. Power BI, Python, SQL, Hadoop).
Gather requirements, formulate metrics and synthesize analytics into dashboard and reports.
Present data and information, in technical and business terms, with a compelling final product that tells a story to management.
Analyze data sources, taxonomies and methodologies regularly to ensure data integrity from all relevant data sources.
Identify statistically significant patterns, correlations, and compelling questions raised by such analysis.

Data
Develop, construct, test and maintain architectures across Customer Operations including databases, Customer Operations processing systems
Gather, collect, store, and process data the data, leveraging tools and technology including ETL, API, SQL.
Conduct or participate in management of analytical studies to address moderately difficult to complex business problems, identify deficiencies and improve solutions which impact Entergy Custom er Operations effectiveness and provide the basis for management decisions.
Develop, manage and deploy best in practice data collection, data governance, storage and manipulation techniques (extract, transform and load) that ultimately enable Customer Operations business units to unlock additional value from company-held data.
Focus on improving the data integration of current Customer Operations systems of record as well as ensuring the approach adopted is agile enough to ingest additional data streams as they become available.
Understand the strengths and limitations of various data storing, data transformation and data distribution mechanisms and help identify the appropriate data sources, manipulation tools and techniques (including data enrichment/automation) for a particular analytics use case as a function of data quality (including availability) and work collaboratively with other technology and data experts and Customer Operations SMEs to help solve their analytical needs.

Effectively manage relationships and can create rapport with others. Anticipate customer/stakeholder needs and accept ownership.
At all times put safety first, actively promote safety in both the office environment and on-site/off-site visits at Entergy or supplier sites.

Minimum Requirements

Minimum education required of the position
Bachelor’s degree in a data-centric field (Economics, Computer Science or other science field), Information Systems, Information Processing, Business, or Engineering.
Master’s in Analytics or related advanced degree preferred.

Minimum experience required of the position
Data Engineer I:
0-1 years of professional experience with a bachelor’s degree; in lieu of a degree 4 years of experience in data engineering/data modeling is required
At least 2 years in developing and utilizing tools that prepare, extract and manipulate (big) data to create connected datasets (data lake) that can be utilized for analytics purposes preferred.

Data Engineer II:
2-4 years of professional experience with a bachelor’s degree in lieu of a degree 6 years of experience in data engineering/data modeling is required
At least 4 years in developing and utilizing tools that prepare, extract and manipulate (big) data to create connected datasets (data lake) that can be utilized for analytics purposes preferred.

Minimum knowledge, skills, and abilities required of the position
Technical:
Understanding of gathering requirements, formulate metrics and convert data analysis into tangible reporting products.
Ability to execute in report design, data visualization and presentation techniques.
Solid application of data management, control and data mining applications and systems.
Proficient at providing data driven insights and key recommendations on findings.
Proficient at sharing key insights with department staff and analytics team to promote continuous learning.
Knowledge and understanding of existing and evolving Customer systems.
Works to identify the need for new systems and offers strategic input on the utilization of current systems.

Professional
Knowledge to advise on the application of project management principles to ensure systematic, thorough completion of assignments, identifying critical pathways and risks to delivery.
Ability to communicate with Customer Operations stakeholders, delivering key messages concisely, supported by relevant data; influencing skills to develop best outcomes.
Continually seeks sources of business intelligence on company imperatives, industry trends and emerging capabilities that will drive a world-class customer experience.
Proficient at building extensive relationships and effective networks with all stakeholders.

Leadership
Basic skills to influence others to action, and to successfully implement strategies and process improvements
Basic knowledge of change management and continuous improvement methods, and the application to daily activities to drive performance improvement.
Able to provide direction on appropriate change to enable business objectives and ensures consistent application across all initiatives and stakeholder interactions.
Ability to communicate complex scenarios and data, clearly articulate the organization’s strategy, and translate organizational strategy into departmental strategies and plans
Able to provide technical and professional coaching/mentoring on contract provisions, commercial analytics, etc., to project teams, other Customer Operations personnel and Entergy customers.
Ability to lead others through ambiguity and support functional leadership of small teams.
Capability to be the trusted advisor; leader/coach in identifying what is important to the customer base.

#LI-RM1
#LI-HYBRID

Primary Location: Louisiana-New Orleans Louisiana : New Orleans || Arkansas : Little Rock
Job Function: Engineering
FLSA Status: Professional
Relocation Option: No Relocation Offered
Union description/code: NON BARGAINING UNIT
Number of Openings: 1
Req ID: 112727
Travel Percentage:Up to 25%

An Equal Opportunity Employer, Minority/Female/Disability/Vets. Please click here to view the EEI page, or see statements below.
EEO Statement: The Entergy System of Companies provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, gender, sexual orientation, gender identity or expression, national origin, age, disability, genetic information, marital status, amnesty, or status as a protected veteran in accordance with applicable federal, state and local laws. The Entergy System of Companies complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment including, but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.

The Entergy System of Companies expressly prohibits any form of unlawful employee harassment based on race, color, religion, sex, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of the Entergy System of Company employees to perform their expected job duties is absolutely not tolerated.
Accessibility: Entergy provides reasonable accommodations for online applicants. Requests for a reasonable accommodation may be made orally or in writing by an applicant, employee, or third party on his or her behalf. If you are an individual with a disability and you are in need of an accommodation for the recruiting process please click here and provide your name, contact number, the accommodation requested and the requisition number that you are requesting the accommodation for. Employee Services will contact you regarding your request.
Additional Responsibilities: As a provider of essential services, Entergy expects its employees to be available to work additional hours, to work in alternate locations, and/or to perform additional duties in connection with storms, outages, emergencies, or other situations as deemed necessary by the company. Exempt employees may not be paid overtime associated with such duties.
Entergy Pay Transparency Policy Statement: The Entergy System of Companies (the Company) will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company’s legal duty to furnish information. 41 CFR 60-1.35(c). Equal Opportunity and Pay Transparency.
Pay Transparency Notice:
Pay Transparency Nondiscrimination Provision (dol.gov)
The non-confidential portions of the affirmative action program for individuals with disabilities and protected veterans shall be available for inspection upon request by any employee or applicant for employment. Please contact HRCompliance@entergy.com to schedule a time to review the affirmative action plan during regular office hours.
WORKING CONDITIONS:
As a provider of essential services, Entergy expects its employees to be available to work additional hours, to work in alternate locations, and/or to perform additional duties in connection with storms, outages, emergencies, or other situations as deemed necessary by the company. Exempt employees may not be paid overtime associated with such duties.

Please note: Authorization to work in the United States is a precondition to employment in this position. Entergy will not sponsor candidates for work visas for this position.","$82,563 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1992,$10+ billion (USD)
"FIS Global
3.7",3.7,"Baltimore, MD",Senior Data Engineer,"Position Type :
Full time
Type Of Hire :
Experienced (relevant combo of work and education)
Education Desired :
Bachelor of Computer Engineering
Travel Percentage :
0%
Job Description
We are FIS. Our technology powers the world’s economy and our teams bring innovation to life. We champion diversity to deliver the best products and solutions for our colleagues, clients and communities. If you’re ready to start learning, growing and making an impact with a career in fintech, we’d like to know: Are you FIS?

About the role:
As a Software Engineer you could work with bleeding edge technology as you build innovative fintech products that change the way the world pays, banks and invests. This will involve developing core versions of software applications, identifying client requirements and technical specifications, interacting with engineering groups and training clients on applications.

What you will be doing:
Designing, programming, debugging and modifying software enhancements.
Interacting with product managers and users to define requirements and modifications.
Participating in software design meetings to determine technical requirements.
Working with internal Client Training, Client Relationship and Sales teams.

What you will need:
Experience with end-to-end systems development life cycles and standards.
Knowledge of financial industry practices, regulations and operations.
Fluency in sequence diagrams, class models, etc.
Proficiency in solutions design and requirements definition disciplines.
A bachelor’s in computer engineering, computer science or other related discipline or equivalent experience.

What we offer you:
A career at FIS is more than just a job. It’s the change to shape the future of fintech. At FIS, we offer you:

A voice in the future of fintech
Always-on learning and development
Collaborative work environment
Opportunities to give back
Competitive salary and benefits
.
Privacy Statement
FIS is committed to protecting the privacy and security of all personal information that we process in order to provide services to our clients. For specific information on how FIS protects personal information online, please see the Online Privacy Notice.
EEOC Statement
FIS is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics. The EEO is the Law poster is available here supplement document available here

For positions located in the US, the following conditions apply. If you are made a conditional offer of employment, you will be required to undergo a drug test. ADA Disclaimer: In developing this job description care was taken to include all competencies needed to successfully perform in this position. However, for Americans with Disabilities Act (ADA) purposes, the essential functions of the job may or may not have been described for purposes of ADA reasonable accommodation. All reasonable accommodation requests will be reviewed and evaluated on a case-by-case basis.
Sourcing Model
Recruitment at FIS works primarily on a direct sourcing model; a relatively small portion of our hiring is through recruitment agencies. FIS does not accept resumes from recruitment agencies which are not on the preferred supplier list and is not responsible for any related fees for resumes submitted to job postings, our employees, or any other part of our company.
#pridepass","$116,119 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1968,$5 to $10 billion (USD)
XO Health,#N/A,Remote,Data Engineer,"About the Company:
Headquartered in Stamford, CT and founded in 2021, XO Health Inc. is the first health plan designed by and for self-insured employers that promises to create a more unified health experience for everyone – from those who receive care, to those who deliver it, and to those who pay for it.
XO Health is seeking dynamic, committed individuals who are ready to improve the healthcare experience, eliminate deeply entrenched system inefficiencies and improve equitable access to affordable healthcare. We are growing a multi-disciplinary team of diverse and digitally empowered employees ready to rebuild trust in healthcare through comprehensive and unified transformation.
Healthcare is fixable. Become part of the community changing the face of the industry.
About the Role:
The Data Engineer is a member of our Data Engineering team who will focus on data analytics, data engineering and report development to meet business requirements. A successful candidate has experience building healthcare measures, efficiently retrieving data from a data lake, build and troubleshooting data pipelines and developing automated data set processes. The candidate will act as a subject matter expert in implementing the best practices of coding in implementing the projects. In this role, you'll influence technology strategies, ensure that the technological solutions are aligned with the company's business needs and bring to life data and how it can impact positive healthcare outcomes.
The ideal candidate should have good understanding of healthcare data to design and build data solutions using data engineering techniques to provide unparalleled experience to our clients, members and providers. The candidate should be passionate about continuously collaborating with other teams to provide optimal analytical insights and reporting frameworks.
In This Role, You will:
Design & implement big data ingestion & transformation pipelines in order to publish data for consumption.
Develop & champion best practices for large scale information extraction from structured/semi-structured data sources.
Understand data sources in-depth; design & implement data extraction & processing pipelines that work around imperfections of data to improve data quality & coverage.
Deliver high-quality, scalable code with automated test coverage.
Drive data quality across the product vertical and related business areas.
Support the delivery of high impact dashboards and data visualizations.
Define and manage SLA’s for all data sets and processes running in production.
We’re Looking for People Who Have:
A Bachelor’s degree in a technical or business discipline, or equivalent experience.
4 years of related data engineering, software engineering and/or business intelligence experience.
Minimum of 4 years of experience in creating reports using SAS, SQL languages.
3 years of hands-on experience with big data technologies & event driven architecture.
Experience working in building NCQA/HEDIS quality measures to measure quality performance rates is preferred.
Ability to develop highly scalable cloud-based data platforms.
Hands on data modeling / data architecture experience
2+ years development experience in at least one object-oriented language (Python, R, Java, etc.).
Progressive experience with SQL and related data base technologies
Progressive experience with a variety of data management tools and technologies, and related tools, data visualization and data extraction and transformation tools.
Must have strong problem-solving, analytical and in-depth research skills.
Possess the ability to communicate effectively, with internal and external partners, both orally and written.
Job Type: Full-time
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
4 years
Schedule:
Monday to Friday
Experience:
SQL: 3 years (Preferred)
Healthcare IT: 4 years (Required)
Data analytics: 4 years (Required)
Management reporting: 4 years (Required)
Data engineering: 4 years (Required)
SAS: 3 years (Preferred)
Work Location: Remote",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"TTC, Inc.
4.6",4.6,"Nellis AFB, NV",Data Pipeline Engineer,"Position: Data Pipeline Engineer
Location: Nellis AFB, NV
Clearance: Secret security clearance with Top Secret eligibility
Travel: 5%
TTC is currently accepting applications for a Data Pipeline Engineer. Selected Candidates will work within dynamic leading-edge-technology environments enabling the 805th Combat Training Squadron/Shadow Operations Center – Nellis (ShOC-N) to conduct integration, experimentation, and assessments of emerging technologies and mission procedures to meet warfighter requirements in Joint All Domain Command and Control (JADC2) and the Advanced Battle Management System (ABMS), providing the USAF resilient and integrated joint C2 solutions sets. This is an on-site position located at Nellis Air Force Base in Las Vegas, NV.
This excellent opportunity requires that the ideal candidate to be customer focused, and willing to join a winning team.
Responsibilities:
Support the data instrumentation and analysis pipeline for the 805 CTS
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional organizational requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other ‘big data’ technologies
Work with stakeholders and design teams to assist with data-related technical issues and support their data infrastructure needs
Keep data separated and secure across multiple data centers
Work with data and analytics experts to strive for greater functionality in our data systems
Preferred Skills & Experience:
4+ years of experience in a Data Engineer role desired
Data engineering certification desired (e.g IBM Certified Data Engineer)
Experience with cloud services desired
Strong project management and organizational skills desired
Experience supporting and working with cross-functional teams in a dynamic environment desired
Required Skills, Abilities and Competencies:
Bachelor’s degree required in Computer Science, Statistics, Informatics, Information Systems or another quantitative field required
Must have advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Must have experience building and optimizing ‘big data’ data pipelines, architectures and data sets
Must have experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Must have strong analytic skills related to working with unstructured datasets
Contractor will build processes supporting data transformation, data structures, metadata, dependency and workload management
Must have working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc
Must maintain a Secret security clearance with Top Secret eligibility
At TTC, Inc., we value diversity and have worked diligently to create a workforce that reflects this. As an Equal Opportunity and Affirmative Action Employer, we are committed to providing an environment based on mutual respect which is free of discrimination and harassment. TTC's employment opportunities are available to all teammates and applicants, without regard to race, color, religion, sex, pregnancy, national origin, age, physical or mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information, military and veteran status, and any status protected by federal, state, and local laws. Diversity, inclusion and genuine respect for each other are key contributors to our success as an employer.

[Equal Opportunity/Affirmative Action Employer – minorities/females/veterans/individuals with disabilities/sexual orientation/gender identity]

Information Assurance and Information System Security are the responsibility of each and every TTC, Inc. employee. All TTC employees shall comply with TTC Information Assurance and Information Management System policies and procedures. Additionally, employees with access to Government systems and information will comply with all Government laws, regulation, instructions and rules. TTC employees will do everything within their abilities to safeguard information and systems, to include issued/authorized devices such as computers, cellular phones, notebooks, tablets, iPad, etc. In the event of an information systems security incident, TTC employees will immediately report the situation to one of the TTC corporate members.


Should you require assistance or an accommodation to complete your application, please contact our Human Resources Department at HR@ttcin.com or 1-571-319-7516.","$92,361 /yr (est.)",Unknown,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"SoundThinking, Inc.
3.5",3.5,"Tucson, AZ",Data Integration Engineer,"The Integration Engineer will design, build, test and deploy integration software to our clients. The Engineer will utilize in-house and industry-standard technologies to perform duties related to data analysis, conversion, consolidation and synchronization.

Essential Duties/Responsibilities


Analyze/reverse-engineer client database structures/schemas.


Document database structures, schemas.


Build ETL/ELT connectors from our clients’ data to our solution.


Build transformations around the data.


Verify quality of converted data using automated test suites and ad hoc testing.


Step through and debug ETL processes.


Conduct validation sessions with client agencies.


Establish ongoing synchronization between database

Learn new technologies as our company grows.


Minimum Qualification


Bachelor’s degree required.


Relational Database experience (Microsoft SQL Server preferred).


Minimum of 2 years of experience with languages used in Apache Spark (Python/Scala/SQL).


Exposure to data modelling notations such as ERD, Instance Diagramming, and/or UML.


Excellent documentation skill is a must.


Must be self-motivated, detail-oriented while multi-tasking and a team player.

The above salary range is based on a good faith estimate made at the time of publication and may be modified in the future. The pay offered to a candidate may vary within this range depending on factors such as education, experience, and geographic location

SoundThinking provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, SoundThinking complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

SoundThinking expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of SoundThinking’s employees to perform their job duties may result in discipline up to and including discharge. If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact SoundThinking at +1.510.794.3183 or careers@soundthinking.com for assistance.

Note: The Company reserves exclusive right in its sole discretion to modify, adjust, delete, add or otherwise change the above at any time.","$104,375 /yr (est.)",201 to 500 Employees,Company - Public,Information Technology,Software Development,1996,$25 to $100 million (USD)
"Vision Government Solutions Inc
3.6",3.6,Remote,Data Engineer,"About Vision
Vision Government Solutions is a leading government technology firm providing cutting-edge software to the public sector. We are at an incredible inflection point of growth and are looking for exceptional individuals to join our Software Implementation team to help us successfully welcome new communities to our Vision software.
Our software implementation philosophy emphasizes the importance of customer delight, speed, and long-term partnership. To that end, we are searching for ambitious, motivated, detail-oriented individuals looking to further a career in Implementation Engineering. The right candidate will be driven by customer happiness, be obsessed with continuous improvement, and have strong data engineering and ETL toolkit to master the vast landscape of unique implementation projects we encounter.
Summary of Role & Responsibilities
The Data Engineer (Software Implementation) will primarily be responsible for writing and deploying custom data conversions, working in concert with technical project managers and architects. Sample responsibilities include:
Data Engineering
Deliver custom database conversions during new customer implementation projects
Migrate data from competitor solutions to our in-house software
Upgrade existing customers from our previous Oracle/VB6 software version to our current SQL Server/C#/.Net product
Assist with the development of ad hoc T-SQL scripts for occasional data engineering needs
Collaborate with the Continuous Improvement team to streamline future processes, automate repeatable tasks, improve quality assurance, and minimize rework
Develop custom routines to convert graphical building drawings from various formats, including (but not limited to) Traverse, SVG, AutoCAD DXF, and binary, to our proprietary Sketch XML format
Create and alter client analytics dashboards using PowerBI
Embrace agile methodologies to achieve industry-leading project delivery schedules while maintaining ongoing customer engagement and excitement
Partner with project teams to provide a seamless customer transition experience

Role Evolution
This role will begin with a primary focus on municipal assessment software implementation projects (~90% of the time), with the remaining 10% focused on continuous improvement initiatives and team growth. In addition, role evolution may include calibration and modeling efforts, branching into our SaaS product world, advanced data engineering opportunities, and exciting continuous improvement projects.
Who We Are Looking For
The ideal person for this role will have demonstrated the following abilities and traits:
Skills and Ambitions:
Ability to thrive in a fast-paced, ever-changing landscape
5 + years of experience working in a SQL-focused conversion role
Solid knowledge of T-SQL and SQL Server Management Studio
Familiarity with Oracle SQL*Plus is desired but not required
Experience with ETL and Data Migration
Understanding of relational database concepts
Impressive oral and written communication skills
Exceptional time management capabilities; deadlines are not flexible
Ability to communicate and translate ideas between technical and non-technical parties
SQL Server 2012+/SSRS/SSIS/Jira/GitHub/Confluence
Skills using Apache NiFi, R, or Python are a plus but not required
BS/BA in Computer Science or related field preferred
Total Compensation Package: To be discussed
Benefits Package: Vision offers health, dental, and vision plans, as well as a 401(k)-matching program.
Work Location: Remote
Equal Employment Opportunity
Vision Government Solutions is an Equal Opportunity Employer and committed to a diverse and inclusive workplace. All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.
We're proud to be an equal opportunity employer and celebrate our employees' differences, including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability and Veteran status.
Vision Government Solutions maintains a drug-free workplace.
xWWunRlzxY",#N/A,51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,1975,$5 to $25 million (USD)
"REPS & Co.
4.5",4.5,"Houston, TX",Data Engineer,"Founded in 2017, REPS & Co. is a leader in the entertainment industry specializing in ticketing for live events. We provide tickets to many events and shows across the nation including music, sports and theatrical performances. We pride ourselves in offering the best experience for the best price to our customers. Our technology is what allows us to outperform our competitors and deliver an unforgettable experience to fans.
We are looking for an organized, experienced, and driven Data Engineer. The Data Engineer is responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
We are excited to add a Data Engineer to our growing team!
Responsibilities:
Work on data architecture and use a systematic approach to plan, create, and maintain data while also keeping it aligned with business requirements
Collect and obtain data from appropriate sources after formulating a set of dataset processes
Conduct research in the industry to address any issues that can arise while tackling a business problem
Create models and identify patterns
Dive into data and pinpoint tasks where manual participation can be eliminated with automation
Use programming languages and tools
Identify ways to improve data reliability, efficiency, and quality
Use large data sets to address business issues
Prepare data for predictive and prescriptive modeling
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems
Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases, including RDS, Postgres, MySQL, Mongo / DynamoDB, and Cassandra.
Experience in data pipeline and workflow tools: DBT, Lambda, AirByte, Airflow, etc.
Experience with BigData cloud services: BigQuery, EMR, RDS, Redshift, Glue, Athena
Experience with stream-processing systems: Druid, Storm, Spark-Streaming, etc.
Experience with object-oriented languages: Python, Java, Javascript, etc.
Benefits
Medical, Dental and Vision insurance
PTO
Sick Leave
Paid Holidays
Volunteer Time Off
401k with Match
ESOP
Parental Leave
100% Employer Paid Life Insurance & Long Term Disability
EAP Program
Bonus
Gym Membership Reimbursement
Ticket Benefit
#Li-Remote","$101,128 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,Unknown / Non-Applicable
"Quality Built
2.4",2.4,United States,Data and Reporting Engineer,"Primary Function
The Reporting and Data Engineer reports to the Head of Data and Analytics. This individual will work closely with various internal and external stakeholders to design and implement robust reporting solutions. They will contribute to enhancing the value of our data for our customers, and aid in the development of new tools/products that augment the QB Software / Foresite group’s value proposition.
Fair Labor Standards Act (FLSA) Status: Exempt
Specific Duties:
Collaborate with teams to gather requirements on business processes, current systems/reports, and areas of improvement.
Design and implement end-to-end data visualizations/reporting solutions, from data extraction to presentation, to meet client needs.
Maintain, enhance, and develop new reports, including SQL stored procedures and SSRS report developments.
Ensure the accuracy of reporting solutions by performing data validation/quality assurance to confirm they fulfill customer requirements.
Analyze business reports to provide insights and discern patterns.
Integrate embedded reports and white-labeled systems/tools for a seamless reporting experience.
Prioritize tasks and projects related to software-reporting integration.
Competencies: To perform the job successfully, an individual should demonstrate the following.
Achievement Focus
Demonstrates persistence and surpasses challenges.
Measures oneself against a standard of excellence.
Capitalizes on opportunities.
Sets and accomplishes ambitious objectives.
Communications
Practices attentive listening.
Articulates ideas clearly in both written and verbal forms.
Ensures stakeholders are well-informed.
Chooses the most effective modes of communication.
Planning and Organization
Seamlessly integrates changes.
Strategizes for necessary resources.
Prioritizes tasks effectively.
Sets clear objectives.
Manages time efficiently and maintains an organized workflow.
Problem Solving
Proposes alternative solutions.
Assesses information adeptly.
Identifies issues promptly.
Resolves challenges early on.
Thrives in collaborative problem-solving situations.
Education and Skills Requirements:
Bachelor’s Degree in a technical field (e.g., computer science, Information Systems, business, or related disciplines).
3-4 years’ experience with extensive datasets or database systems, particularly SQL Server.
3-4 years’ proficiency in writing SQL, with a focus on stored procedure development.
Strong familiarity with BI reporting tools (e.g., Power BI, Tableau).
Knowledge of embedded reports and white-labeled systems/tools.
Familiarity with Windward Studio is a strong plus.
2-4 years' role in data engineering, reporting analyst, or a related capacity with emphasis on developing data-driven reports. Lesser emphasis on AI/ML concepts, but a basic understanding is beneficial.
Standard Work Hours
Normal business hours (8:00am to 5:00pm). This position may require more than 40 hours per week including evenings and weekends. Work will be performed via telecommunications from home. Occasional travel may be required.","$90,000 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Building & Personnel Services,1994,Unknown / Non-Applicable
"Breezeline
3.6",3.6,"Quincy, MA",Data Engineer,"Our culture lifts you up—there is no ego in the way. Our common purpose? We all want to win for our customers. We aim to always be evolving, dynamic, and ambitious. We believe in the power of genuine connections. Each employee is a part of what makes us unique on the market: agile and dedicated.
Time Type:
Regular
Job Description :
Breezeline is a dynamic, innovative company providing the very best Internet, TV, and Voice service to the US markets we serve. We Are ‘Above And Beyonders’, who consistently strive to surprise and delight our customers by doing the unexpected. We continually look for new and better ways to enrich our customers’ lives through connected and memorable experiences.

As the eighth-largest cable operator in the United States, Breezeline reaches more than 1.7 million homes and businesses in 13 states with Internet, TV, Voice and fiber services. Headquartered in Quincy, MA, Breezeline is a subsidiary of Cogeco Communications Inc. (TSX:CCA).

Why Work At Breezeline?
As one of the country’s fast-growing Internet service providers, Breezeline offers our colleagues a vibrant workplace culture and excellent career opportunities. As a proudly diverse and inclusive organization, we believe that every person’s unique individuality should be welcomed and celebrated, and their abilities and potential should be honored and recognized. It is a key part of our culture to actively promote opportunities internally to ensure that you are never static in your career with us.

Internal Values – How we act
We’re proud that Breezeline is unlike any other employer in the industry. We work hard, but we never lose sight of the big picture. We understand that our colleagues are looking for more than just a great job – they want an extraordinary life – and at Breezeline, we want to make that a reality.
And here is how we do it.

Fun: We laugh a lot. It makes every day brighter, and if you don’t love what you do, you’re not doing it right.

Job flexibility: We think everything you do matters – at work and home.

Discounted services: We offer our customers some fantastic services, and we think you deserve to enjoy them in your home, too.

Total Rewards: Let’s be honest, everyone wants to make a good salary. We offer attractive total rewards and a great culture to go along with it. We’ve got you and your family covered with one of the best packages in the business.

Career evolution: At Breezeline, you get more than just a job. You get all the tools you need to learn, grow, and achieve your career goals!

Cutting-edge technology: Do you have a passion for technology? Great, we do, too. At Breezeline, you will get the opportunity to manage, influence, play, create, fix, and re-shape the industry.

About the Job

As a Data Engineer at Breezeline, you will participate in all steps of the data lifecycle, with the ultimate goal of adding value to the business. This role is responsible for a variety of tasks relating to data warehousing and business intelligence. For example, you may work one week on ingesting data from a new source, and work the next week on a visualization of this data for stakeholders to view. This position will be part of the Data & Analytics team. This is a remote position with the requirement of residing in the Breezeline services footprint (Ohio, Connecticut, Delaware, Florida, Pennsylvania, Maine, Maryland, Massachusetts, New Hampshire, South Carolina, Virginia, and West Virginia)

Responsibilities:
Building Cloud Composer/Airflow pipelines for optimal extraction, transformation and loading of data from various data sources including MySQL, Oracle, JSON, CSV into our Big Query EDH
Implementing tools and methodologies to improve data reliability and quality
Creating dashboards in Google Data Studio for stakeholders to visualize activity and gain actionable insights
Analyzing large, complex sets of data to deliver meaningful and accurate reporting
Identifying and developing internal process improvements optimizing data delivery, and automating manual processes

Skills:
Ability to build and support data pipelines and other scheduled processes
Ability to effectively communicate with business stakeholders
Ability to learn complex data schemas and new technologies
Experience with data visualization tools
Excellent analytic skills and attention to detail

Education & Knowledge:
Bachelor's degree in Information Technology, Computer Science or equivalent combination of training and/or experience.
Knowledge of relational databases and type 2 slowly changing dimensions
Strong initiative to find ways to improve solutions, systems, and processes.
Experience with UNIX/Linux environments
Familiarity of APIs including knowledge of XML, JSON, REST, SOAP, etc.
Scripting/programming: Python, SQL, Bash etc
Familiarity with cloud technologies
3-5 years of experience


Available Benefits:
Competitive salary
Medical coverage (including prescription and vision plans)
Dental coverage
Life Insurance (1x salary at no cost to employee)
Long and short-term disability insurance (no cost to employee)
Voluntary employee, spousal, and child life insurance
Company recognized Holidays with additional Floating Holidays
Paid Time Off (PTO) programs
Comprehensive Flex Work Policy
401(k) plan eligibility (company match 50% up to 5% of eligible contributions)
Participation in the Employee Bonus Plan
Participation in the Cogeco Stock Purchase Plan
Complimentary and discounted broadband services (for those in our service area)
Tuition Reimbursement
Opportunities for LinkedIn Learning subscriptions for select colleagues

#LI-REMOTE
#LI-JS1
Location :
Quincy, MA
Company :
Breezeline
At Cogeco, we know that different backgrounds, perspectives, and beliefs can bring critical value to our business. The strength of this diversity enhances our ability to imagine, innovate, and grow as a company. So, we are committed to doing everything in our power to create a more diverse and inclusive world of belonging.
By creating a culture where all our colleagues can bring their best selves to work, we’re doing our part to build a more equitable workplace and world. From professional development to personal safety, Cogeco constantly strives to create an environment that welcomes and nurtures all. We make the health and well-being of our colleagues one of our highest priorities, for we know engaged and appreciated employees equate to a better overall experience for our customers.

If you need any accommodations to apply or as part of the recruitment process, please contact us confidentially at
inclusion@cogeco.com","$96,856 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Telecommunications,Telecommunications Services,2012,Unknown / Non-Applicable
"Form Energy, Inc
4.9",4.9,"Pittsburgh, PA",Senior Process Data Engineer,"Are you ready to rise to the challenge of climate change with the team that will deliver? Form Energy is a U.S. technology and manufacturing company that is developing and commercializing pioneering energy storage technologies to enable the electric grid to run on 100% renewable energy, every day of the year.
Supported by leading investors such as Breakthrough Energy Ventures, ArcelorMittal, TPG Rise, MIT’s The Engine, and others, we share a common belief that low-cost, multi-day energy storage is the key to enable tomorrow’s zero carbon electric grid. Driven by our core values of humanity, excellence, and creativity, we are deeply motivated and inspired to create a better world. We need talented, hardworking individuals who share our goal of tackling the challenge of climate change. Do you want to work with us today to build a better tomorrow?
Role Description
This data engineer will be responsible for leading and supporting the initial operations production environment in all cell/battery assembly processes by providing data analytics and dashboards to streamline processes. Your work will impact all stages of the process, from raw materials/chemicals to final product, while ensuring quality, efficiency, and safety. You will use your strong background in data and process engineering within an industrial operation and process development/optimization to contribute to our first of a kind manufacturing facility. This is an exciting opportunity to help shape and be part of the growth of a fast-moving company with breakthrough technology and an incredible mission!

This opportunity is based out of Form Energy's Eighty Four, PA location (Greater Pittsburgh Area). Relocation assistance available.
What You'll Do:
Responsible for collecting, managing, and converting raw data into information that can be interpreted by data scientists and business analysts. Data accessibility is the ultimate goal, which will enable the utilization of data for process performance evaluation and optimization.
Collaborate with cross-functional teams to identify and solve production issues
Analyze data, develop and maintain data sets and improve data quality and efficiency
Be a key resource for root cause analysis data needs/correlations and statistical analysis resources to the production team.
Develop visualizations, monitor, and analyze key performance indicators (KPIs) to identify areas for improvement and ensure that targets are met or exceeded
Support the implementation and usage of PLM, MES, and ERP systems, as well as other tools related to manufacturing and sustainability
Support factory optimization efforts, capacity and yield tracking, etc.
What You'll Bring:
5+ years of experience in production engineering, ideally in a cell or battery module production environment
Minimum of Bachelor's degree in Chemical, Mechanical, Manufacturing Engineering, Computer science or related field
Proven experience managing projects, leading teams, and implementing data improvement activities
Hands-on experience with SQL database design and the ability to analyze complex data and develop effective, data driven solutions
Strong attention to detail and ability to work in a fast-paced, dynamic environment where changes in design and processes are expected
Experience with lean manufacturing principles and continuous improvement met
Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages (e.g. Java and Python)
Data engineering certification (e.g IBM Certified Data Engineer) and statistical analysis capabilities is a plus
#LI-LN1
#LI-Onsite

Besides joining a community of people working to make the world better, Form Energy commits to you equitable compensation, stock options, and offers a generous benefits package to make sure you have the support you need to thrive.
We cover 100% of employee premiums and 80% of dependent premiums for medical, dental, and vision insurance for full time employees. We offer a flexible Paid Time Off program and every employee, regardless of gender identity or expression, is eligible for 12 weeks of paid parental bonding leave. A full listing of our benefits is available on our careers page.
At Form Energy, we are working toward a 100% renewable energy future for everyone in the world. We are committed to creating an inclusive environment for all our employees and are seeking to build a team that reflects the diversity of the people we hope to serve with our revolutionary products. Form Energy is proud to be an equal opportunity employer.","$105,752 /yr (est.)",501 to 1000 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,2017,Unknown / Non-Applicable
"Noblis
4.5",4.5,"Reston, VA",Data Analytics Engineer,"Responsibilities:
Noblis is expanding its data development team to support a wide variety of client needs focused on electronic fraud. The successful candidate will work collaboratively with the Noblis Lead Data Analytics architects and data scientists to design and implement analytics, data ETL, data QA, and a variety of operational needs to support the mission.

The Data Analytics Engineer will also work closely with government personnel and other Noblis professionals in a team environment.

Responsibilities include:
Design, development, integration, and implementation of data processes
Identification of analytics approaches, and development of supporting analytical data sets.
Understand business processes and work collaboratively yet independently to support the operation of a large and complex data warehouse (MapR(Hadoop), Spark, ElasticSearch)
Interacting directly with client project team members and operational staff
Qualifications:
QUALIFICATIONS:
Bachelor’s degree in a technical or quantitative discipline required + 18 years of experience, or Masters degree + 10 years of experience.
Five or more years of progressive experience in data analytics
Experience in the design, development, integration, testing, and implementation of a large scale analytical data sets
Strong skills in either Python or Java are a required starting point.
Experience in Linux command line environment is required
Strong analytic and creative problem solving abilities are required
Highly inquisitive and ability to work both independently and in collaborative setting
Strong teamwork, communication and interpersonal skills
Strong communication, written, and organizational skills
Ability to work on multiple aspects of a large scale project which includes prioritizing, tracking, attention to detail, follow-up and follow-through to project completion
Prior experience with any of PySpark, Scala, ElasticSearch, Hadoop/MapR is a plus (eagerness to learn is required!)
Experience with D3 or Flask is a plus
Ability to obtain a public trust
Client Engagement: · Support and lead evolving business development efforts by applying technical and functional expertise to develop business solutions. · Lead proposal sections for small or limited competition proposals and actively participate in teaming strategy discussions Overview:
At Noblis we recognize and reward your contributions, provide you with growth opportunities, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, and work-life programs. Our award programs acknowledge employees for exceptional performance and superior demonstration of our service standards. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in our benefit programs. Other offerings may be provided for employees not within this category. We encourage you to learn more about our total benefits by visiting the Benefits page on our Careers site.

Salary at Noblis is determined by various factors, including but not limited to, the combination of education, certifications, knowledge, skills, competencies, and experience, internal and external equity, location, and clearance level, as well as contract-specific affordability and organizational requirements and applicable employment laws. The projected compensation range for this position is provided within the posting and are based on full time status. Part time staff receive a prorated salary based on regularly scheduled hours. The estimated minimum and maximum displayed represents the broadest range for this position (inclusive of high geographic and high clearance requirements), and is just one component of Noblis’ total compensation package for employees.

Noblis and our wholly owned subsidiaries, Noblis ESI, and Noblis MSD tackle the nation's toughest problems and apply advanced solutions to our clients' most critical missions. We bring the best of scientific thought, management, and engineering expertise together in an environment of independence and objectivity to deliver enduring impact on federal missions. Noblis works with a wide range of government clients in the defense, intelligence and federal civil sectors. Learn more at Noblis -About Us

Why work at a Noblis company?
Our employees find greater meaning in their work and balance the other things in life that matter to them. Our people are our greatest asset. They are exceptionally skilled, knowledgeable, team-oriented, and mission-driven individuals who want to do work that matters and benefits the public. Noblis has won numerous workplace awards. Noblis maintains a drug-free workplace.

Noblis is an Equal Opportunity Employer. Employment decisions are made without regard to race (as well as because of or on the basis of traits historically associated with race, including hair texture, hair type, and protective hairstyles such as braids, locks, and twists), color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, pregnancy, childbirth, lactation and related medical conditions, genetic factors, military/veteran status, or other characteristics protected by law.

Noblis is committed to the full inclusion of all qualified individuals. As part of this commitment, Noblis will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact employee-relations@noblis.org.","$112,296 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Management & Consulting,Business Consulting,1996,$100 to $500 million (USD)
"Steampunk
4.6",4.6,"McLean, VA",Data Engineer,"Overview:
At Steampunk, our goal is to build and execute a data strategy for our clients to coordinate data collection and generation, to align the organization and its data assets in support of the mission, and ultimately to realize mission goals with the strongest effectiveness possible.

For our clients, data is a strategic asset. They are looking to become a facts-based, data-driven, customer-focused organization. To help realize this goal, they are leveraging visual analytics platforms to analyze, visualize, and share information. At Steampunk you will design and develop solutions to high-impact, complex data problems, working with the best and data practitioners around. Our data exploitation approach is tightly integrated with Human-Centered Design and DevSecOps.
Contributions:
We are looking for seasoned Data Engineer to work with our team and our clients to develop enterprise grade data platforms, services, and pipelines.
Lead and architect migration of data environments with performance and reliability.
Assess and understand the ETL jobs, workflows, BI tools, and reports
Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
Experience in crafting database / data warehouse solutions in cloud (Preferably AWS. Alternatively Azure, GCP).
Key must have skill sets – Python, AWS
Support an Agile software development lifecycle
You will contribute to the growth of our Data Exploitation Practice!
Qualifications:
US Citizen Only
Ability to hold a position of public trust with the US government.
5+ years industry experience coding commercial software and a passion for solving complex problems.
5+ years direct experience in Data Engineering with experience in tools such as:
Relational SQL and NoSQL databases, Postgres and MongoDB.
Data pipeline and workflow management tools. Airflow highly preferred. Nifi/Zookeeper also preferred.
Object-oriented/object function scripting languages. Python highly preferred. R also preferred.
AWS cloud offerings such as S3, EC2, Data Pipelines, Glue, and EKS.
DevOps tools: Github, Jenkins, Vault
Working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.
Experience manipulating, processing, and extracting value from large, disconnected datasets.
Experience manipulating structured and unstructured data for analysis
Experience constructing complex queries to analyze results using databases or in a data processing development environment
Experience with data modeling tools and process
Experience aggregating results and/or compiling information for reporting from multiple datasets
Experience working in an Agile and DevOps environment
Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models
About steampunk:

Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.","$103,833 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2003,Unknown / Non-Applicable
"Metova
3.4",3.4,"Little Rock, AR",Data and Testing Engineer (Remote/Hydrid),"JOIN US IN DRIVING SUCCESS:
Everyone at Metova is given the tools and resources they need to succeed at their job. We offer a flexible and positive work environment so you have the autonomy to build amazing software for our customers and add to our team of industry leading visionaries. You will build a compelling and easy to use interface, ensure its maintainability and ease of use, and suggest ways to improve the look and feel of the application. We are lean, which means we reflect on what we learn and use that new knowledge to quickly make better products. Your job is to keep learning, contribute your knowledge back to the rest of the team, and apply what you learn to make Metova and our clients even greater.
YOUR OPPORTUNITY:
Metova's engineering team is looking for a Data and Test Engineer in collaboration with a Metova Partner in the healthcare industry. We are looking for individuals who are highly motivated, collaborative, and technical, with the passion to help shape the delivery of software products for customers.
This is a six month remote contract opportunity that may require on site work over time. Time Zone Preference: CST.
This role may be filled by applicants in the following states: Arkansas, Florida, Georgia, Illinois, Kansas, Louisiana, Minnesota, Mississippi, Oklahoma, South Carolina, Tennessee, Texas, Virginia and Wisconsin.
WHAT YOU WILL DO:
The Data & Testing Engineer conducts analyses to identify business trends, conducts root cause analysis of business problems and suggests areas for process improvement
The position also consults with users and decision makers to identify items required for data sources, required data elements, and/or data validation standards
Assists with integration of data from multiple data sources or functional areas, ensures data accuracy and integrity, and updates data as needed to develop data warehouse data tables
Leads the development and validation of new vendor integration and reports to leadership on open items. This position provides and maintains an efficient level of
documentation to be managed for the Enterprise metadata portals
YOUR QUALIFICATIONS:
Bachelor's degree in Health Services Administration, Business Administration, Public Health, Mathematics, Computer Programing or related field
Minimum three (3) years' related data engineering work related to Medicare Pharmacy claims. In case of related Masters' degree, minimum of one (1) year related experience
Data engineering work experience related to Medicare Pharmacy claims, includes PDE claims, Part D vs B claims and Rejection claims
Documentation substantiating incumbent's analysis experience may be required
Demonstrated experience in the application of data analysis or data management and analysis tools including but not limited to SAS, SQL and AQT
Demonstrated experience with other PC-based software products including Microsoft Office suite of products - Excel, Word, and PowerPoint
Prior experience with project leadership
Demonstrated ability to speak within small groups on project work (average 8 - 10 people)
WE CONSIDER IT A PLUS IF YOU HAVE EXPERIENCE WITH:
Medicare Claims experience
ABOUT US:
Founded in 2006, Metova has a long history of providing cutting edge technology solutions to clients across a variety of industries. Today, Metova specializes in software and application development for web based solutions, iOS, and Android. Working at Metova allows you to not only provide your strategic and technical expertise to others, but also continued personal development through internal career development curriculum, cross-training programs with fellow employees, and challenging projects solving real-world issues. We are a growing company looking for thought leaders who want to revolutionize industries to join our team.
We offer a work environment that also works for you through remote teams, flexible schedules, open PTO policy, and a flat organization that embraces the diverse backgrounds and skill sets across our teams to continue to drive Metova forward on our path to success. We offer a competitive salary, dental, vision, and health plans, and a matching 401(k) program.
Metova is interested in every qualified candidate who is eligible to work and reside in the United States. However, we will not consider applicants who are not U.S. citizens, U.S. nationals, lawful permanent residents, asylees, or refugees.
Metova, Inc. is an Affirmative Action and Equal Opportunity Employer.

Notice to Third Party Recruitment Agencies:
Please note that Metova does not accept unsolicited resumes from recruiters or employment agencies. In the absence of an executed Recruitment Services Agreement, there will be no obligation to any referral compensation or recruiter fee.
In the event a recruiter or agency submits a resume or candidate without an agreement, Metova shall explicitly reserve the right to pursue and hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited resumes, including those submitted to hiring managers, shall be deemed the property of Metova.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,2006,$5 to $25 million (USD)
"CACI
4.0",4.0,Virginia,Data Integration Engineer,"Data Integration Engineer
Job Category: Information Technology
Time Type: Full time
Minimum Clearance Required to Start: None
Employee Type: Regular
Percentage of Travel Required:
Type of Travel:
What You’ll Get to Do
CACI is seeking a Data Integration Engineer to support a complex data modeling position supporting cybersecurity data collection, analysis, and mitigation. This position will be responsible for researching industry trends related to enterprise data and incorporating best practices into the roadmap.
The engineer will be responsible for analysis of data derived from diverse cybersecurity tools and architecting and developing scalable and comprehensive enterprise solutions to extract data from source systems or models, transform data according to Business Rules and MDM, and load data into operational and presentation models. The engineer will also work with the Integration Layer Architecture Product Owner to develop an approach for expanding the scope of the existing data integration layer to accommodate data from an expanded set of data sources, as a part of a future solution deployment.
This position will support the Continuous Diagnostics and Mitigation (CDM) Program’s mission to safeguard and secure cyberspace in an environment where the threat of cyber-attack is continuously growing and evolving and is responsible for enhancing the security, resilience, and reliability of the Nation’s cyber and communications infrastructure. The CDM Program defends the United States (U.S.) Federal Information Technology (IT) networks from cybersecurity threats by providing continuous monitoring sensors (tools), diagnosis, mitigation tools, and associated services to strengthen the security posture of Government networks.
More About the Role
Design and build reusable data integration APIs for the data lake with optimal storage, compute scale, and observability.
Examine the criteria and develop data structures following client-established norms.
Build and accelerate low-code ETL/ELT system to process billions of records daily.
Develop rules and algorithms for using ML/AI in data processing, transformation, and correlation, whether the data is structured, unstructured, or semi-structured.
Use Python, BASH, PowerShell, or another scripting language to automate manual processes.
Load large volumes of data.
Developing, deploying, scheduling, and maintaining the data pipeline workflows to move data from multiple source systems to the Integration Layer and Elastic
Identify and define system data collection requirements.
Prepare and document standard operating procedures and protocols for all designed and developed solutions that ensure detailed project documentation.
You’ll Bring These Qualifications
US Citizenship required
There is no clearance requirement to begin employment. However, as a requirement of continued employment, you must meet eligibility requirements for access to classified information and be clearable to a Department of Homeland Security (DHS) Entrance on Duty (EOD) authorization.
Experience in building and maintaining data integration and processing systems that receive data feeds from multiple disparate data sources
Familiarity with web related technologies (Web applications, Web Services, Service Oriented Architectures) and of network/web related protocols
Possess strong problem-solving skills and can work effectively under high-pressure situations.
BS degree in Computer Science or a related field
Expert in programming languages like Python, R, Java, and Scala, and well-versed in libraries and frameworks for ML/AI such as TensorFlow+Keras, PyTorch, and scikit-learn – 4 or more years
Extensive experience in ML algorithms, statistical analysis, data mining, data visualization, data labeling – 4 or more years
Experience in Data Lakes such as Databricks Data Lake, Azure Data Factory, Azure Databricks, Snowflake, AWS Glue, AWS Stitch – 4 or more years
Practical knowledge in data cleaning, reporting, and visualization.
Experience with source control tools such as GitLab, Github or Azure DevOps and related CI/CD processes - 4 or more years
Experience with Data Modelling – 4 or more years
Data Management Concepts (Data Extraction, Cleansing, Transformation, loading, Validation, Migration, Modelling, RDBMS concepts) – 4 or more years
These Qualifications Would Be Nice to Have
Any other cybersecurity certification such as Security+, CEH, or CISSP
Any other relevant certification on tools used for large scale data integration and processing.
Knowledge / experience of Machine Learning
What We Can Offer You

We’ve been named a Best Place to Work by the Washington Post.

Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.

We offer competitive benefits and learning and development opportunities.

We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.

For over 60 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.

Company Overview: At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1962,$1 to $5 billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Software Engineer Graduate (Monetization Technology-Big Data) - 2024 Start (BS/MS),"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

Our ads data platform team work closely with our product managers and data analysts by building state of the art streaming and batch data processing solution. The entire data pipeline is supporting both the Tiktok ads platform and our internal business intelligence platform. In this role, you will see a direct link between your work, and the company's business success. You will have opportunities to deal with Petabyte-level data warehouse. Some of the world's most challenging technical and business problems are waiting for you to solve.

We are looking for talented individuals to join our team in 2024. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok.

Successful candidates must be able to commit to one of the following start dates below:
1. January 15, 2024
2. February 5, 2024
3. March 4, 2024
4. May 20, 2024
5. June 10, 2024
6. July 15, 2024
7. August 12, 2024
We will prioritize candidates who are able to commit to these start dates. Please state your availability and graduation date clearly in your resume.

Applications will be reviewed on a rolling basis. We encourage you to apply as early as possible.

Candidates can apply to a maximum of two positions and will be considered for jobs in the order you apply. The application limit is applicable to TikTok and its affiliates' jobs globally. Applications will be reviewed on a rolling basis - we encourage you to apply early.
Online Assessment
Candidates who pass resume evaluation will be invited to participate in TikTok's technical online assessment in HackerRank.

Responsibilities
Work with product managers and data analyst to make the data-related product design.
Interface with engineers, product managers and product analysts to understand data needs.
Build data expertise and own data quality for allocated areas of ownership.
Design, build and launch new data extraction, transformation and loading processes in production.
Support existing streaming and batch system in production, solve the on-call issues.
Define and manage SLA for all data sets in allocated areas of ownership.
Work with data infrastructure to triage infra issues and drive to resolution.
Qualifications
Graduate with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment.
Proficient in one of Programming languages (e.g., Python, Java)
Communication skills, including the ability to identify and communicate data driven insights.
Ability in managing and communicating data warehouse plans to internal cl
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at earlycareers.accommodations@tiktok.com.

By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy.
Job Information
The base salary range for this position in the selected city is $112065 - $172800 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$142,433 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Love's Travel Stops & Country Stores
4.0",4.0,"Oklahoma City, OK",Data Engineer II,"Req ID: 420925

BASIC PURPOSE : As a Data Engineer II for Loves, the successful candidate will play a pivotal role in building, managing, and optimizing data pipelines for the Enterprise Data & Analytics initiatives following industry standard practices and tools. This role will be the key interface in operationalizing data and analytics on behalf of the business unit(s) and organizational outcomes. The candidate will require both creative and collaborative skills working with IT and business, including data scientists, data analysts, and other data consumers, as well as 3rd party business partners and vendors. The candidate should have 3-5+ years of experience in the responsibilities listed below.

MAJOR RESPONSIBILITIES/SKILLS:
Collaborate with program leadership to architect, build, and maintain data pipelines through acquisition, ingestion, staging, and modeling

Moderate experience with various Data Management architectures like Data Warehouse, Data Lake, Data Hub, Data Vault and the supporting processes like Data Integration, Governance, and Metadata Management

Moderate experience working with large, heterogeneous datasets in building data pipelines and integrating datasets using traditional data integration technologies, including ETL/ELT, data replication/CDC, message-oriented data movement, and API-based data acquisition

Responsible for the identification and qualification of source data to satisfy master and transactional data requirements for the target warehouse

Perform data assessment and mapping activities, and develop the underlying migration framework to extract, transform, validate, enrich, and load the source data

Fundamental understanding of data warehousing principles

Ability to understand impacts of a solution architecture on corresponding design, build, and test efforts

Ship small features with minimal oversight

EDUCATION AND EXPERIENCE:
Required Experience:
Moderate experience with cloud data warehouses, such as Snowflake

Moderate experience working with complex SQL code

Moderate experience working with open-source or commercial message queuing technologies, such as Azure Service Bus, Apache Nifi, Apache Kafka, etc.

Moderate experience working with DevOps capabilities like version control, automated builds, testing and release management using tools like Git

Moderate experience working with replication software such as Fivetran or HVR

Moderate experience with ETL tools

Preferred Experience:
SQL Server 2008+ experience a plus

SAP Hana experience a plus

Tableau experience a plus

Power BI experience a plus

R/Python experience a plus

Dbt experience strongly preferred

Education:
HS Diploma or equivalent required

Bachelor’s degree in Business with MIS or technology related degree (C.S.) required

INTERPERSONAL SKILLS & CHARACTERISTICS

Capable of thinking big picture and sorting through an ambiguous environment

Ability to manage numerous competing demands in a fast-paced environment

Demonstrates good judgement, sense of urgency and commitment to high standards of ethics, regulatory compliance, customer service and business integrity

Required to be highly creative and collaborative

Excellent verbal and written communication skills

Ability to communicate clearly and concisely to various levels in the organization

PHYSICAL DEMANDS:
Requires prolonged sitting, some bending and stooping.

Occasional lifting up to 25 pounds.

Manual dexterity sufficient to operate a computer keyboard and calculator.

Requires normal range of hearing and vision

#LI-Hybrid

Job Function(s): Information Technology

Love’s Travel Stops & Country Stores is the industry-leading travel stop network in the United States. For more than 55 years, we’ve provided customers with highway hospitality and “Clean Places, Friendly Faces.” We’re passionate about serving drivers with clean, modern facilities stocked with fuel, food and supplies. We offer meals from popular restaurant chains, trucking supplies, showers and everything needed to get back on the road quickly. The Love’s Family of Companies includes:

Gemini Motor Transport, one of the industry’s safest trucking fleets

Speedco, the light mechanical and trucking service specialists

Musket, a rapidly growing, Houston-based commodities supplier and trader

Trillium, a Houston-based alternative fuels expert","$94,610 /yr (est.)",10000+ Employees,Company - Private,Retail & Wholesale,Convenience Stores,1964,$10+ billion (USD)
"NW Natural
3.8",3.8,"Portland, OR",Data Engineer/Data Lead and Developer,"Non-Union Position
Portland, Oregon (US-OR)
Regular FT
Posting # 4629

About Us:
At NW Natural, we offer more than rewarding career opportunities and a vibrant, inclusive work culture. We invite you to join us in providing safe and reliable utility services and renewable energy to better the lives of the communities we serve. Our vision is to be the leader in service excellence, innovation and environmental stewardship for our customers, while building on our strengths as a trusted energy provider and environmental leader for our industry.

In addition to environmental stewardship, We’re also deeply committed to Diversity, Equity and Inclusion at NW Natural. Our DEI Council started 21 years ago, and today we continue to foster a culture where all employees can experience a sense of belonging, shared purpose and possibility.
Northwest Natural Gas Company d/b/a NW Natural
Data Engineer/Data Lead and Developer in Portland, Oregon

Job Duties: Responsible for Cloud Data Integrations within Enterprise Data Platform (EDP). Translate complex enterprise logic into metadata and data quality rule sets. Design, develop, and test pipelines between source and target systems. Oversee technical administration of the Data Acquisition and Enterprise Data landscape and data migration into the Data Access layer. Design consistent and effective data models through utilization of appropriate BI tools and application of best practices and standards. Design, develop, and test ETL solutions for initial and CDC based on functional requirements. Create and maintain documentation of processes, pipelines, applications, and procedures as per department policy. Create and deliver training and documentation for solutions. Partner with business users across the company to understand business needs and gather business requirements. Partner with other team members to ensure that data warehouse models support analytic needs and reporting requirements of the business. Provide off hours support for the Enterprise Data Platform. Support Company’s commitment to a culture of safe work practices. Liaise between business users across the company and the IT&S BIDBA team.

Minimum Requirements: Bachelor’s degree in Computer Science, or related field or equivalent in education, training and experience, plus 3 years of experience as a Data Engineer, Delivery Lead, Lead Developer, Programmer/Analyst, or related position, including experience in the following:

3 years of experience working in Informatica Intelligent Cloud Services (IICS) with Informatica connectors for cloud-based and on-premises systems.
3 years of experience performing database modeling.
3 years of experience with data warehouse ETL tools, such as Informatica, Azure Data Factory, SSIS, stored procedures.
3 years of experience analyzing business objectives and requirements.
3 years of experience utilizing python, Azure Data Lake, Azure SQL DB, and JSON files,
2 years of experience with databases, Business Intelligence development and performing data transformations.

Must pass pre-employment drug test and background check.
All education, experience, and training may be gained concurrently. Applicants must be U.S. workers (includes U.S. citizens, permanent residents, foreign nationals granted temporary residence under one of the 1986 legalization programs, refugees, and asylees). To be considered for this position, submit a complete electronic application including cover letter and resume for Job# 4629via our website at . Resumes submitted via email, fax or mail will not be accepted in lieu of an electronic application.

What we offer:
Health & Wellness –
Rich health insurance benefits with competitive employer contribution
Free access to an online wellness resources platform

Work Life Balance -
Up to 23 Vacation Days
80 Hours of Sick Time
10 paid holidays and 3 floating holidays
Flexible work arrangements
3 weeks paid parental leave
Green Team / Diversity, Equity & Inclusion Council / Safety Team / Women’s Network and many other Employee Resource Groups
1500 sq foot exercise facility and secure bike room

Financial -
Meaningful annual incentive bonus opportunity in addition to base salary
Competitive 401K company contribution and match
15% discount on NW Natural stock through Employee Stock Purchase Program
Up to $5250 a year in tuition reimbursement
Wellness incentive program

Discounts -
20% off natural gas service
Up to 30% discount at NW Natural Appliance Center
TriMet Pass for all HQ employees
Generous discounts with Verizon & AT&T Wireless

Disclosure: We are a drug free workplace and we comply with Federal Drug Free Workplace Act and Department of Transportation regulations. Pre-employment drug tests are part of the hiring process and apply to all positions.

NW Natural is proud to be an equal opportunity employer. We welcome and embrace our candidates’ diversity and take affirmative action to employ and advance individuals without discrimination on the basis of race, color, sex, gender identity or expression, sexual orientation, religion, age, physical or mental disability, veteran status, pregnancy (including childbirth or related medical conditions), national origin, marital status, genetic information, and all other legally protected characteristics. We forbid discrimination and harassment in the workplace based on any protected status or characteristic. A criminal history is not an automatic bar to employment with NW Natural. Instead, we make individualized assessments regarding qualifications and backgrounds. NW Natural is also committed to providing reasonable accommodations for individuals with disabilities, individuals with sincerely held religious beliefs, and disabled veterans in our job application procedures. If you need assistance or an accommodation as part of the application process, please contact us at employment@nwnatural.com or (971) 979-6341.

NW Natural does not accept unsolicited submissions or assistance from search firms for posted positions. Resumes submitted by search firms working under a valid and current written contract with NW Natural valid written Statement of Work in place for this position from NW Natural HR/Employment will be deemed the sole property of NW Natural. No fee will be paid in the event the candidate is hired by NW Natural as a result of the referral or through other means.","$89,166 /yr (est.)",1001 to 5000 Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1859,Unknown / Non-Applicable
"Nike
4.2",4.2,"Beaverton, OR",Senior Data Engineer (Remote Option*),"Become a Part of the NIKE, Inc. Team

\r

\r

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

Open to remote work except in South Dakota, Vermont and West Virginia.

The annual base salary for this position ranges from $93,900.00 in our lowest geographic market to $209,700.00 in our highest geographic market. Actual salary will vary based on a candidate's location, qualifications, skills and experience.

Information about benefits can be found here .

WHO WE ARE LOOKING FOR

We are looking for a Senior Data Engineer to help drive the delivery of scalable data and analytics solutions, implement and integrate new technologies, and manage and evolve the data lake. The ideal candidate will have outstanding communication skills, proven data design and implementation capabilities, a strong eye for business, and a drive to deliver results. This person will be technically proficient and excel at collaborating with engineers, analysts, and business partners. Our ideal candidate is a self-starter who is comfortable with ambiguity and enjoys a fast-paced, dynamic environment.

WHAT YOU WILL WORK ON

In this role, you'll build and deliver scalable data and analytics solutions focused within our Nike Direct-to-Consumer, Supply Chain, and Commercial spaces. You will design, implement, and integrate new technologies and evolve data and analytics products. You will be contributing to all aspects of data engineering from ingestion, transformation, and consumption, in addition to, designing and building test-driven development, reusable frameworks, automated workflows, and libraries at scale to support analytics products. You will also participate in architecture and design discussions to process and store high-volume data sets.

WHO YOU WILL WORK WITH

Join the North America Data & Analytics Organization working with world-class talent in the field of Data Engineering. The impact is large with a goal of delivering better business insights and driving data-driven decisions across the organization. You'll be working closely with several hard-working teams including, internal partners, Product Owners, Engineering Leaders, Data Analysts, Big Data Leads, and Engineers. One of Nike's maxims (a.k.a. ""values"") is ""Win as a Team"" and you will be working in a very collaborative environment and will find success through teamwork, a positive attitude, and hard work.

WHAT YOU BRING

Bachelor's Degree in Computer Science or other related field of study OR any combination of relevant equivalent experience, education, and training

3-5+ years of relevant work experience in Data and/or Software Engineering

2+ years of experience working with Hadoop and/or Big Data processing frameworks (e.g. Spark, Hive, Nifi, Spark-Streaming, Flink, etc.)

2+ years experience with relational SQL and programming languages such as Python, Scala, or Java

Experience with source control tools such as GitHub and related CI/CD processes

Experience working in AWS environment primarily EMR, S3, Kinesis, Redshift, Athena, etc

Experience with data warehouses/RDBMS like Snowflake & Teradata and NoSQL data stores such as HBase, DynamoDB, etc.

Experience processing Big Data streams using services such as Spark, Flink, Kinesis, Kafka, etc.

Experience with workflow scheduling tools like Airflow

Experience implementing solutions using Databricks and/or Databricks Lake House

Strong knowledge of algorithms, data structures, data architecture, and software design patterns

#LI-CL6

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

How We Hire

At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.

This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.

Benefits

Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$93,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Plano, TX",Software Engineer III AWS Data Engineer,"JOB DESCRIPTION

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.
As a Software Engineer III at JPMorgan Chase within Enterprise Technology, Global Technology Infrastructure, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job responsibilities
Participate in efforts to design, build, and develop rapid Proof-of-Concept (POC) solutions and services;
Build applications using Python, SQL, Databricks and AWS;
Be a key team member in design and development dashboards;
Working understanding of Agile, Scrum and Design Thinking;
Apply knowledge of basic principles, methods and practices to simple and moderately complex assignments;
Proactively identify and implement opportunities to automate tasks and develop reusable frameworks;
Act as a run manager, provide Run/DevOps support;
Adhere to standard methodologies for coding, testing and designing reusable code/component;
Participate in sprint planning meetings and provide estimations on technical implementation;
Contributed to the exploration and understanding of new tools and techniques, and propose improvements to the data pipeline;
Work as a data engineer within the IAM team that uses several Data, Search and AWS technologies;
Implement standardized, automated operational and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs;
Collaborate with the other engineering team members to ensure all services are reliable, maintainable, and well-integrated into existing platforms;
Review functional and technical designs to identify areas of risk and/or missing requirements;
Provide technical write-ups and drawings to promote the proposed solutions.
Required qualifications, capabilities, and skills
Formal training or certification on software engineering concepts and 3+ years applied experience
Hands-on practical experience in system design, application development, testing, and operational stability
Proficient in coding in one or more languages
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages
Overall knowledge of the Software Development Life Cycle
Solid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security 5 years’ experience with automation of DevOps build using GitLab/Bitbucket/Jenkins;
Experience working directly with technical and business teams;
5 years’ experience AWS cloud and AWS services such as EC2, S3 Buckets, Lambda, API Gateway, SQS Queues, Glue, Redshift, Cloud Watch;
5 years’ experience with batch job scheduling and identifying data/job dependencies;
5 years’ experience with data engineering using AWS platform and Python/Java;
A Techno-functional role, with a Total experience of 5+ years;
Familiar with software DevOps CI/CD tools, such Git, Jenkins, Linux, and Shell Script;
Preferred qualifications, capabilities, and skills
Familiarity with modern front-end technologies
Exposure to cloud technologies
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.","$100,322 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Zillow
3.9",3.9,Remote,Senior Big Data Software Engineer,"About the team
Zillow is disrupting real estate by empowering people to unlock life's next chapter! The Zillow Data Engineering team supports multiple lines of business and is responsible for implementing, operating and improving data pipelines and creating data sets to empower Zillow Group brands and customers. We achieve this goal by building and deploying highly scalable data pipelines, adhering to software/data engineering best practices and ensuring the quality of our data to the delight of our consumers.
About the role
In this role, you will evangelize and build Data Products for customer, property and business-specific data to simplify critical ML and Analytics products, like the Zestimate and pricing of Zillow-owned homes, to enrich the customer experience, and simplify marketing operations. You will partner with other data engineering teams and platform teams within AI to lead the architecture, implementation, and operations of big data pipelines and tools for building high-quality data marts.
As a member of this team, you will:
Architect, design, build, implement and support data pipelines/products to serve ML and Analytical use cases
Collaborate with product managers, engineers, data scientists, and analysts on mission-critical property data needs to build world-class datasets
Identify opportunities to evangelize and support existing data processes
Contribute back to common tooling/infrastructure to enable self-service tooling to expedite customer onboarding
This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.
In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $157,100.00 - $250,900.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.
In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.
Who you are
5+ years software development experience using Python/Scala/Java and experience leading the design/implementation of config driven, scalable, reliable services and workflows/pipelines using Airflow, Hive, Spark, Kafka, EMR, or equivalents.
A degree in Computer Science or a related technical field; or equivalent work experience
Expert in establishing and promoting high standards in pipeline monitoring, data validation, testing, etc.
You have extensive experience in applying automation to data engineering (DataOps).
Passionate about data engineering/analytics and distributed systems.
Excellent interpersonal skills and passionate about collaborating across organizational boundaries.
Comfortable distilling informal customer requirements into problem definitions, resolving ambiguity and balancing challenging objectives.
Excited about mentorship and coaching/onboarding/leading teammates.
Here at Zillow - we value the experience and perspective of candidates with non-traditional backgrounds. We encourage you to apply if you have transferable skills or related experiences.
Get to know us
Zillow is reimagining real estate to make home a reality for more and more people.
As the most-visited real estate website in the United States, Zillow® and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people.
Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We’re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don’t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees’ Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.
Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.","$204,000 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Internet & Web Services,2005,$1 to $5 billion (USD)
"Shoe Carnival
3.3",3.3,"Evansville, IN",Sr. Data Engineer,"The Sr. Data Engineer evaluates, designs, builds, tests and deploys Analytic Dashboards, Reports, Data Pipelines, Data Structures and Infrastructure across the company.
Primary Duties & Responsibilities:
Builds Operational, Analytical and Ad-Hoc Dashboards-Reports to support decisions in the various company disciplines.
Leverages existing data infrastructure to fulfill all data-related requests, perform necessary data housekeeping, data cleansing, normalization, hashing, and implementation of required data model changes.
Builds, evolves and scales out infrastructure to ingest, process and extract meaning out of data.
Analyzes data to spot anomalies, trends and correlate similar data sets.
Designs, develops and implements statistical models to carry out various novel aspects of classification and information extraction from data.
Troubleshoots problems, identifies possible solutions, and resolves accordingly.
Requirements:
Bachelor's degree in Business Analytics, Mathematics, Computer Science, Statistics, Data Science or related analytical degree or experience required.
6+ years of experience, with 4 or more years in quantitative analytics/data mining and experience presenting those results to business partners required.
Experience with various Business Intelligence (BI) platforms (e.g., MicroStrategy, Tableau, Cognos, etc.).
Microstrategy Analyst and/or Architect Certification not required but would be beneficial.
Experience in data integration and database programming for relational and nonrelational databases.
Experience with advanced analytics tools using programming languages such as R, Python, Java and others.
Familiarity with a variety of statistical models including logistic/linear regression, cluster analysis, propensity models, and other modeling techniques required.
Excellent problem-solving skills with an aptitude for critical thinking.
Strong communication and technical writing skills.
Strong collaboration skills. Works well in a team environment and cross-functionally.
Total Rewards:
The Shoe Carnival, Inc. Total Rewards program offers eligible associates highly competitive benefits, including the following:
Competitive Pay
Paid Time Off (Vacation & Sick Time)
Comprehensive Medical, Dental, & Vision Benefits
Flexible Spending Accounts
Life, Disability, and Voluntary Benefits
Fitness Membership Discounts
Employee Assistance Program
401(k) Retirement Plan
Employee Stock Purchase Plan
Employee & Family Discounts
Relocation Opportunities
Shoe Carnival, Inc. is an Equal Opportunity Employer.
Requirements:
Ability to provide world class customer support by adopting and meeting Shoe Carnival's Corporate Core Customer Service Goals.","$90,927 /yr (est.)",5001 to 10000 Employees,Company - Public,Retail & Wholesale,"Department, Clothing & Shoe Stores",1978,$1 to $5 billion (USD)
"Collins Aerospace
3.5",3.5,Texas,Senior Data Engineer (Remote),"Date Posted:
2023-06-14
Country:
United States of America
Location:
HTX99: Field Office - TX Remote Location, Remote City, TX, 73301 USA
Position Role Type:
Remote
Aviation connects the world and Connected Aviation Solutions (CAS) connects Aviation. Sustainably. Seamlessly. Securely. The Data Management & Data Science (DM&DS) team is tasked with the end to end responsibility to ensure that CAS data assets are managed with integrity and quality prior to consumption by our critical customer facing applications - whether via API’s, analytics and/or data visualizations. As a senior data engineer on the DM&DS team, you will be responsible for the design, development and maintenance of data processes and pipelines supporting critical CAS Strategic Business Unit (SBU) Data initiatives in support of the Digital Transformation of CAS as well as for the cross-SBU Connected Ecosystem. In this endeavor, you will be working closely with data architecture, data analytics & visualization teams leaders across CAS, SBU and Digital Technology (DT) teams to ensure the technical solutions are efficient, scalable and meet long term Connected Ecosystem needs.
Primary Responsibilities:
Design, develop and support the processes and pipelines for moving data throughout the CAS and cross SBU environments.
Develop automation and monitoring processes that support the data pipelines
Work closely with the architecture team to implement modern data repositories that support the CAS use cases (Pipelines, API’s, Data Science, Applications and Visualizations)
Work with internal business customers and software development teams to gather and document requirements for data publishing and data consumption via data warehouse, data lake, and analytics solutions
Support the operation of the CAS and Digital Technology owned Data Platforms, Data Warehouse and Data Lakes with a view to leveraging capabilities and resources over-time
Work with the CAS and DT Enterprise Data Architects to automate cloud deployments, as well as build CI/CD pipeline to support Cloud-Based workloads. Develop views, materialized views, and SQL scripts
Work with the CAS and DT Enterprise Data Architects to recommend investments or changes in technology, resources, procedures, equipment, systems, or other assets to improve the quality of the organization’s projects.
May travel domestically and internationally up to 15%.
Qualifications / Required Skills:
Bachelor’s degree and 5 years of prior relevant experience OR Advanced Degree in a related technical field and minimum years 3 experience OR In absence of a degree, 10 years of relevant experience is required
3+ years of demonstrated engineering leadership in a relevant engineering function, such as software/service development and deployment, system design and integration, or data analytics.
Must be authorized to work in the U.S. without sponsorship now or in the future. RTX will not offer sponsorship for this position
Preferred Qualifications:
Aerospace knowledge and experience - specifically Airlines/Business Aviation or Airports. Knowledge of ADS-B data is a plus
Working knowledge of Collins Management System
Experience applying Agile methodology
Experience with ETL and Analytics tools
Experience with legacy migrations
Experience with database solutions including Postgres, JSON, NoSQL, Snowflake, Synapse, and Delta as well as AWS and Azure based database technologies
Experience with data quality or data preparation techniques
Experience in data normalization, data modeling and streaming technologies
Experience in the operationalization of data science models
Scripting/coding in C#
Experience with infrastructure as code scripting including CloudFormation, Terraform and ARM
Knowledge of IT audit, regulatory, and compliance in the Aerospace and Defense industry
Cloud-related certifications
Scripting/coding in Python, SQL, and Spark
Experience in cloud computing such as AWS and/or Azure
Experience with cloud-based data warehouse and data lake environments
Experience supporting Production applications or workloads in a cloud-based environment
Experience working with structured, unstructured, and semi-structured data
Experience building data pipelines, transformations, infrastructure, and monitoring solutions
In depth understanding of data warehouses, data lakes and lake houses
Experience with big data processing technologies such as Spark and Hadoop.
DevOps concepts including automated testing, build automation, automated deployments using CI/CD pipelines
Experience with Source Code Repository tools such as GitHub or Similar
Excellent interpersonal (verbal and written) communication skills
Collins Aerospace Diversity & Inclusion Statement:
Diversity drives innovation; inclusion drives success. We believe a multitude of approaches and ideas enable us to deliver the best results for our workforce, workplace, and customers. We are committed to fostering a culture where all employees can share their passions and ideas so we can tackle the toughest challenges in our industry and pave new paths to limitless possibility.
WE ARE REDEFINING AEROSPACE.
Remote: Employees who are working in Remote roles will work primarily offsite (from home). An employee may be expected to travel to the site location as needed.
Regardless of your role type, collaboration and innovation are critical to our business and all employees will have access to digital tools so they can work with colleagues around the world – and access to Collins sites when their work requires in-person meetings.
Some of our competitive benefits package includes:
Medical, dental, and vision insurance
Three weeks of vacation for newly hired employees
Generous 401(k) plan that includes employer matching funds and separate employer retirement contribution, including a Lifetime Income Strategy option
Tuition reimbursement program
Student Loan Repayment Program
Life insurance and disability coverage
Optional coverages you can buy: pet insurance, home and auto insurance, additional life and accident insurance, critical illness insurance, group legal, ID theft protection
Birth, adoption, parental leave benefits
Ovia Health, fertility, and family planning
Adoption Assistance
Autism Benefit
Employee Assistance Plan, including up to 10 free counseling sessions
Healthy You Incentives, wellness rewards program
Doctor on Demand, virtual doctor visits
Bright Horizons, child and elder care services
Teladoc Medical Experts, second opinion program
And more!
Nothing matters more to Collins Aerospace than our strong ethical and safety commitments. As such, all U.S. positions require a background check, which may include a drug screen.
Note:
Background check and drug screen required (every external new hire in the U.S.)
Drug Screen only performed on re-hires who have been gone for more than 1 year

At Collins, the paths we pave together lead to limitless possibility. And the bonds we form – with our customers and with each other - propel us all higher, again and again.

Apply now and be part of the team that’s redefining aerospace, every day.
#reempowerprogram

This role is also eligible for the Re-Empower Program. The Re-Empower Program helps support talented and committed professionals as they rebuild their capabilities, enhance leadership skills, and continue their professional journey. Over the course of the 14-week program, experienced professionals will gain paid, on-the-job experience, have an opportunity to participate in sessions with leadership, develop personalized plans for success and receive coaching to guide their return-to-work experience. Upon completion of the program, based on performance and contributions participants will be eligible for a career at RTX.
The salary range for this role is 75,000 USD - 161,000 USD; however, RTX considers several factors when extending an offer, including but not limited to, the role and associated responsibilities, a candidate’s work experience, location, education/training, and key skills. Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement. Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance.
RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.
Privacy Policy and Terms:
Click on this link to read the Policy and Terms",#N/A,1001 to 5000 Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1922,$10+ billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Salt Lake City, UT",Aumni - Sr. Associate Data Engineer,"JOB DESCRIPTION

The Aumni Software Engineering department is responsible for developing and maintaining custom software solutions. We work closely and in alignment with Product, InfoSec, and Data Science to deliver the best quality product to our customers. Our core values are:
No More Mysteries
Don't Name Two Different Things the Same Thing
Don't Name the Same Thing Two Different Things
Any Line of Code Might Be the One You're Judged By
We are currently seeking a skilled Senior Software Engineer in Data to join our team. The successful candidate will be responsible for designing, developing, and implementing high-quality software programs for both front-end and back-end applications.
Aumni is a Ruby on Rails backend with a React front end.
This position is for Salt Lake City (Cottonwood Heights), UT
Responsibilities:
Develop, test, and maintain web applications using modern web technologies
Design and develop scalable, reliable, and robust applications
Collaborate with cross-functional teams to identify and solve complex problems
Write clean, efficient, and maintainable code that adheres to best practices and industry standards
Create and maintain APIs and integration with third-party systems
Perform code reviews to ensure quality and scalability of the codebase
Participate in the full software development lifecycle including design, development, testing, deployment, and maintenance
Continuously improve development processes and stay up to date with emerging trends and best practices
We are seeking a candidate who is passionate about learning and eager to develop their skills across the entire technology stack. The ideal candidate will have a hunger for knowledge and a drive to continuously improve themselves, and will thrive in an environment that values innovation and growth.
Experience
4+ years of work as an engineer
Writing comprehensive unit tests for all production code
Object-oriented or functional programming paradigms
Some of our other tech:
Apache Airflow
Data modeling
Large dataset manipulation
Snowflake
Venture Capital/Private Equity
Docker/Kubernetes or containerization in general
Microservices architecture
Security testing best practices and tools
Stress testing and scaling services
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our Corporate & Investment Bank relies on innovators like you to build and maintain the technology that helps us safely service the world’s important corporations, governments and institutions. You'll develop solutions that help the bank provide strategic advice, raise capital, manage risk, and extend liquidity in markets spanning over 100 countries around the world.","$134,625 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"AE Business Solutions
4.2",4.2,Wisconsin,AWS Redshift Consultant (Cloud/Data Engineer),"AE Business Solutions is seeking an experienced AWS Redshift Consultant to take on a fully-remote contract role! This role is expected to last between 6 and 12 months with a focus on designing, developing, and maintaining data pipelines/ETL processes on AWS Redshift (including data lakes and data warehouses. Health insurance, PTO, and 401K match can be provided throughout the duration of the position!

Candidates MUST reside in WI to be considered for the opportunity
No C2C please

Top skills desired (aside from the above):
Hands-on experience with AWS services such as AWS DMS, Amazon S3, AWS Glue, Redshift, Airflow, and other pertinent data technologies
Strong understanding of ETL best practices, data integration, data modeling, and data transformation

Other nice-to-have skills include:
Proficiency in SQL programming and Redshift stored procedures for efficient data manipulation and transformation,
AWS certifications related to data engineering or databases are a plus.
Experience with complex ETL scenarios, such as CDC and SCD logics, and integrating data from multiple source systems,
Demonstrated expertise in AWS DMS for seamless ingestion from on-prem databases to AWS cloud

If this position sounds like a fit for you, please apply here or send a resume with your qualifications to alex.stormoen@aebs.com

TECHNOLOGY. INNOVATION. PEOPLE

AE Business Solutions does not sponsor applicants for employment visas.
AE Business Solutions is an Equal Opportunity Employer. EOE/AA",#N/A,51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,1949,$25 to $100 million (USD)
"Fleet Response
3.9",3.9,"Independence, OH",Software Development Engineer (Data),"Job Summary
Are you interested in joining a fast growing and customer focused company that is consistently rated as one of the Top Workplaces in Northeast Ohio? Do you feel that hard work should pay off, and you value things like workplace flexibility, career advancement opportunities, a positive culture, and a genuine feeling that you belong to a team? If so, you would be perfect for Fleet Response. Fleet Response specializes in providing services to corporations who self-insure physical damages to their fleets. Built from an insurance background with an eye for detail, Fleet Response prides itself on offering a variety of customized services to all our clients. Fleet Response is seeking qualified candidates for the position of Software Development Engineer.
Software Development Engineers are team members utilizing an agile development process. They are responsible for the creation, maintenance, and management of all tiers of the software stack from Database to Front-End. Other responsibilities include working with internal business partners to gather requirements, prototyping, implementing/updating solutions, building and executing unit tests.
Software Development Engineers must be able to adjust to constant business change; common types of changes include new requirements, evolving goals and strategies, and emerging technologies. Software Development Engineers require the ability to interact, develop, engineer, and communicate collaboratively at the highest technical levels with clients, vendors, partners, and all levels of Fleet Response staff.
Job Activities
Works on complex, major or highly visible tasks in support of multiple projects that require multiple areas of expertise.
Application design and development focused on all tiers of the software architecture.
Supporting application releases and development activities following a true Agile SDLC methodology, including TDD, and CI/CD.
Design and extend back-end web services using JSON, .NET web services and SQL.
Expertise in multiple technical environments and knowledge of one or more business areas.
Works closely with architects to assure all systems are in line with Fleet Response IT’s long-term strategy.
Solution scoping and development, including identifying and crafting solutions to identified client challenges.
Collaborate with Product, UX, and Engineering through requirements, design, testing, and implementation stages.
Technical Requirements
5+ years of experience
Expert with writing T-SQL and ADF, SQL Server.
Expert with C# in SSIS script tasks/components
Proficient in creating and consuming RESTful APIs
Experience in API and web development technologies.
Experience with Angular 9+, TypeScript, JavaScript, CSS, LESS, NodeJS, etc.
Experience with Docker and/or Kubernetes.
Experience with Azure DevOps, Git, or other code repository tools.
Comfortable with a predominantly .NET based code base.
Comfortable in a predominately Windows-based environment.
Knowledge with Microsoft Azure (preferred) or AWS.

Fleet Response is an Equal Employment Opportunity Employer.",#N/A,51 to 200 Employees,Company - Private,"Construction, Repair & Maintenance Services",Commercial Equipment Services,1986,Unknown / Non-Applicable
"Fidelity & Guaranty Life Insurance Company
4.0",4.0,"Des Moines, IA",Data Engineer,"Job Summary
The Data Engineer will support the sourcing, transformation, and analysis of data and develop ETL logic utilizing Informatica to support existing and future deployments. This position is responsible for development of data integrations for the delivery of platforms and applications for F&G Retail Markets' DTCC, middleware, and distributor integrations needs
Duties and Responsibilities
Support the sourcing, transformation, and analysis of data
Develop ETL logic utilizing Informatica to support existing and future deployments
Execute technical aspects of data management functions including creating, loading, transforming, cleansing, processing, analyzing, and visualizing data
Assist teammates and business partners with building technical solutions that solve problems, are reusable, scalable, fast, and maintainable through large datasets, both clean and un-clean
Work with multiple development technologies including SQL
Learn new and existing tools, resources, and processes
Develop operational and management/analytical reports and dashboards
Assist in the implementation of architecture and solutions
Develop and deliver code to support existing and future deployments
Support daily production cycles and work with all required parties to resolve issues if any and communicate regular status updates to IT and business partners.
Experience and Education Requirements
Associate's/Bachelor's Degree (preferred emphasis in technology, engineering or math related field) or equivalent combination of education and experience
0-3 years of experience in working with data structures
Familiarity with ETL tools such as Informatica
Experience with data structures
Experience with algorithm design
Exposure to SQL Server and/or Oracle
Basic understanding of object-oriented analysis and design
Preferred Requirements
Exposure developing in .Net/Java
Ability to write SQL queries and interpret data models
Experience with database modeling
Experience within a Financial Services/Insurer's IT Organization
Knowledge of Life and Annuity Order Entry, Integrations needs, and automation trends
Knowledge of integrations, development processes, and integration architectures
Experience with communication for technology enablement for DTCC, middleware, and distributor integrations
Skills and Abilities
Strong analytical, critical-thinking, and problem-solving skills
Fast, adaptive learner
Ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Ability to manage multiple tasks and deadlines simultaneously
Exhibits flexibility and tolerance for ambiguity with the ability to thrive in a rapidly changing business environment
Results-oriented
Dedicated work ethic
Strong interpersonal communication skills, written and verbal
#LI-MB1 #LI-Remote
Additional Information
Work Environments
F&G believes in an employee-centric flexible environment, which is why we offer the ability for in-office, hybrid and remote work arrangements. During the hiring process, you'll work with your leader to decide what works best for your role.
Join our employee-centric hybrid work environment: F&G Careers
About F&G
Since 1959, Fidelity & Guaranty Life Insurance Company (F&G) has offered annuity and life insurance products to those who are seeking security in retirement and protection during life's unexpected events.
As a national Top Workplace1, an Iowa Top Workplace2 and a proud equal opportunity employer, F&G team members are empowered, collaborative, dynamic and authentic. We believe that by embracing these values, we will continue to build and strengthen the company while continuing to be a great place to work.
1Top Workplaces USA 2022 – 2023
2Des Moines Register Top Workplaces 2018 – 2022

Notice for all Applicants who are California residents under the California Privacy Rights Act. Please click here to review the policy.","$67,766 /yr (est.)",501 to 1000 Employees,Subsidiary or Business Segment,Insurance,Insurance Carriers,1959,$100 to $500 million (USD)
"Nordic
3.1",3.1,"Madison, WI",Senior Data Engineer,"Make a difference. Be happy. Grow your career.
The Senior Data Engineer will manage a delivery team to analyze and implement enterprise business intelligence capabilities for Nordic. The individual will be responsible for defining the architectural platform(s), associated data models and ETL /ELT processes used to build out enterprise reporting and application functionality built off the enterprise data warehouse. In addition, the individual will help business draw key insights and findings based on intelligence findings. The individual will interact with internal stakeholders and communicate critical project requirements within Nordic. The individual will also manage ETL and BI Developers and direct their efforts to reach organizational goals in a timely manner.
The Senior Data Engineer will have the following responsibilities, including but not limited to:
Perform solution architecture capabilities, business architecture, data architecture and technical architecture skills and knowledge
Create and support business intelligence platforms such as Azure and DBT Cloud, as well as the 3rd normal form data models and/or dimensional models to support analytic and reporting insights
Lead and support the enterprise design, development, and analysis of the data architecture and warehousing approaches
Implement, integrate, and extract data from applications across the organization
Lead data Integration from source systems to target databases using SSIS, Microsoft Data Factory, Fivetran and DBT Cloud
Lead technical guidance for design and implementation of data storage and governance systems
Develop, maintain, support, and enhance the business intelligence data backend
Design, code, test, and aggregate results using Power BI and/or Tableau
Map configurations and complex data architectures, ensuring documentation meets current and forecasted reporting needs
Design, code, and manage developers’ projects to meet specifications for end user data, business systems, dashboards, and tools
Operate in an agile environment, following best practices for CI/CD as part of the software development life cycle (SDLC)
Collaborate and work with end users to ensure that data and reports meet their business needs
Design and monitor end-user reports to ensuring reports are accurate and up to date
Audit data and take steps to remedy data quality issues, including making source system recommendations to increase data quality for end user reporting
Create technical documents to document database or other system contents, concepts, and mapping between databases
Create and maintain physical and virtual data models and dimensions to support business
Design, code, test, and aggregate results from SQL queries to provide information to users
Collaborate with internal operations experts to understand their data needs, provide insights, and develop user-friendly reporting to support decision making and process improvement initiatives
Collaborate with members of the BI, IT, and operational teams to drive data governance
Skills and Experience
Must have 8+ years of professional work experience in data warehouse, business intelligence, analytic, reporting, data governance and metadata skills
7+ years experience in Healthcare IT; with direct involvement in Payer and/or Hospital/Health System/Practitioner deployment of business operations, processes, procedures, solutions, applications, data models and business intelligence
5+ years experience with Operations and Financial analytics, metrics and KPIs
3+ years experience with Power BI
Experience with NetSuite and WorkDay is preferred
Experience with SalesForce Health Cloud and/or SalesForce Marketing Clous is a plus
Must demonstrate and embody Nordic’s maxims
Post-secondary or equivalent experience in Business, IT, or related field required
Advanced SQL skills and experience with reporting and visualization tools required
Healthcare data experience is preferred
Must be proficient with system databases and developing business intelligence solutions
Experience with an object-oriented programming language like python is preferred
Strong communication skills and ability to build relationships with a variety of internal customers
Detail-oriented with ability to dig into the weeds while keeping the big picture reporting goals in mind
Demonstrated success establishing rapport quickly and collaborating within an organization
Ability to work and communicate effectively and efficiently across all levels of an organization, both written and verbal
Ability to work independently and within a team environment
Excellent interaction skills, collaborative work style, and interpersonal skills
Additional details
Working in Madison, WI, is not required. Travel to the Nordic offices, or client offices, may be required at times
Ability to travel up to 25% of the time","$118,943 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2010,$100 to $500 million (USD)
"Sumitomo Mitsui Banking Corporation
3.4",3.4,Arizona,Sr. Software Engineer - Data (Remote),"Join us on our mission to create a completely new, 100% digital bank that truly serves customers' best interests. We are a close-knit and fun-loving team of seasoned financial services professionals who came together for the challenge of building a bank from scratch - and we are committed to doing it all the right way (from technology infrastructure to modern marketing to customer experience).

The anticipated salary range for this role is between $75,000.00 and $150,000.00. The specific salary offered to an applicant will be based on their individual qualifications, experiences, and an analysis of the current compensation paid in their geography and the market for similar roles at the time of hire. The role may also be eligible for an annual discretionary incentive award. In addition to cash compensation, SMBC offers a competitive portfolio of benefits to its employees.

We work with the flexibility and speed of a start-up. But we also have significant stability and capital from being part of the SMBC Group (Sumitomo Mitsui Banking Corporation). SMBC is the second largest bank in Japan and the 12th largest bank in the world with operations in over forty countries. And SMBC is committed to disrupting the US marketplace with ground-breaking products.

It is the best of both worlds, and we are seeking proven marketing leaders to propel us towards a national launch. We have both the ambitious growth plans and the 'patient capital' necessary to execute a multi-year plan. Join us on the journey to deliver an exciting concept of evolved banking.
Principal Duties and Responsibilities:
A solid experience and understanding of considerations for large-scale solutioning and operationalization of data warehouses, data lakes and analytics platforms within Cloud environments.
Monitors the Data Lake constantly and ensures that the appropriate support teams are engaged at the right times.
Design, build and test scalable data ingestion pipelines, perform end to end automation of ETL process for various datasets that are being ingested.
Determine the best way to extract application telemetry data, structure it, send to proper tool for reporting (Kafka, Splunk).
Work with business and cross-functional teams to gather and document requirements to meet business needs.
Provide support as required to ensure the availability and performance of ETL/ELT jobs.
Provide technical assistance and cross training to business and internal team members.
Collaborate with business partners for continuous improvement opportunities.
Position Specifications:
Bachelor's degree in Computer Science, Computer Engineering, or Information Systems Technology
6+ years of experience in Data Engineering with an emphasis on Data Warehousing and Data Analytics.
4+ years of experience with one of the leading public clouds.
4+ years of experience in design and build of salable data pipelines that deal with extraction, transformation, and loading.
4+ years of experience with Java, Python or Scala.
Ability to work independently, solve problems, update the stake holders.
Analyze, design, develop and deploy solutions as per business requirements.
Strong understanding of relational and dimensional data modeling.
Experience in CI/CD related technologies. You will be responsible for creating CI/CD pipelines.
Excellent written, verbal communication skills, including experience in technical documentation and ability to communicate with senior business managers and executives.
Knowledge of GCP Cloud data implementation projects (Dataflow, DataProc, Cloud Composer, Big Query, Cloud Storage, GKE, Airflow, etc.) is preferred.
EOE STATEMENT
We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.

CCPA DISCLOSURE
Personal Information Collection Notice: This notice contains information under the California Consumer Privacy Act (CCPA) about the categories of personal information (PI) of California residents that Manufacturers Bank collects and the business or commercial purpose(s) for which the PI may be used. We do not sell PI. More information about our collection and use of PI may be found in our CCPA Privacy Policy at https://www.manufacturersbank.com/CCPA-Privacy. Persons with disabilities may contact our Customer Contact Center toll-free at (877) 560-9812 to request the information in this Notice in an alternative format.","$112,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1996,$10+ billion (USD)
"DMI
4.0",4.0,"Linthicum Heights, MD",Data Engineer,"About DMI:
DMI is a leading global provider of digital services working at the intersection of public and private sectors. With broad capabilities across IT managed services, cybersecurity, cloud migration and application development, DMI provides on-site and remote support to clients within governments, healthcare, financial services, transportation, manufacturing, and other critical infrastructure sectors. DMI has grown to over 2,100+ employees globally and has been continually recognized as a Top Workplace in both regional and national categories.
About the Opportunity:
DMI, LLC is seeking a Data Engineer to oversee our Managed Mobility Services team.

Duties and Responsibilities:
Designing, implementing, and maintaining batch and streaming data pipelines between
various SQL sources, including Aurora and SQL Server, and a target data lake in S3,
as well as enterprise data stored in Redshift/Snowflake.
Expertise in AWS cloud services, such as Kinesis, S3, Lake Formation, Glue, and Step
Functions, to build scalable, reliable, and high-performance data pipelines that
enable seamless data integration and empower data-driven insights.
Data Pipeline Design: Design end-to-end data pipelines that efficiently extract,
transform, and load data from SQL sources (Aurora, SQL Server) to the target data
lake in S3 and the enterprise data in Redshift/Snowflake.
Batch and Streaming Integration: Implement both batch and real-time streaming data
integration solutions using AWS Kinesis and other relevant technologies.
Data Transformation: Develop data transformation processes using AWS Glue or other
ETL tools to harmonize, cleanse, and enrich data for analytical use.
Data Lake Management: Oversee the setup and configuration of the data lake in S3,
applying AWS Lake Formation best practices for data organization, cataloging, and
access control.
Data Governance: Ensure adherence to data governance and security standards across
the data pipelines, guaranteeing data privacy and compliance.
Performance Optimization: Continuously monitor and optimize the performance of the
data pipelines, addressing bottlenecks and ensuring efficient data processing and
delivery.
Error Handling and Monitoring: Implement error handling mechanisms and robust
data monitoring to identify and resolve data pipeline issues proactively.
Data Cataloging and Lineage: Establish and maintain data cataloging and lineage
information using AWS Glue Data Catalog to enable data discoverability and
traceability.
Documentation: Create comprehensive technical documentation, including design
specifications, data flow diagrams, and operational guides.
Collaboration: Collaborate with data analysts, data scientists, and other stakeholders to
understand data requirements and deliver reliable data solutions.
Data Governance: Ensure data governance principles are implemented throughout the
data pipelines to maintain data quality and integrity.
Qualifications:
Education Qualification:
A Bachelor's Degree from an accredited college or university with a major in
Computer Science, Information Systems, Engineering, Business, or other related
scientific or technical discipline is required.
General Experience:
At least six (6) years of experience working on AWS cloud-based batch and streaming
data pipelines.
Strong proficiency in AWS cloud services, including Kinesis, S3, Lake Formation,
Glue, and Step Functions.
In-depth knowledge of SQL databases, such as Aurora and SQL Server, and data lakes
in S3, as well as enterprise data in Redshift/Snowflake.
Hands-on experience with ETL tools, data transformation, and data integration
techniques.
Familiarity with data governance, data privacy, and security best practices in AWS
environments.
Strong problem-solving skills and the ability to troubleshoot complex data pipeline
issues.
Excellent communication and teamwork skills to collaborate effectively with crossfunctional teams.
AWS certifications, such as AWS Certified Data Analytics - Specialty or AWS
Certified Big Data - Specialty, are advantageous.
Working at DMI
DMI is a diverse, prosperous, and rewarding place to work. Being part of the DMI family means we care about your wellbeing. We offer a variety of perks and benefits that help meet various interests and needs, while still having the opportunity to work directly with a number of our award-winning, Fortune 1000 clients. The following categories make up your DMI wellbeing:

Convenience/Concierge - Virtual visits through health insurance, pet insurance, commuter benefits, discount tickets for movies, travel, and many other items to provide convenie
Development – Annual performance management, continuing education, and tuition assistance, internal job opportunities along with career enrichment and advancement to help each employee with their professional and personal develo
Financial – Generous 401k matches both pre-tax and post-tax (ROTH) contributions along with financial wellness education, EAP, Life Insurance and Disability help provide financial stability for each DMI employe
Recognition – Great achievements do not go unnoticed by DMI through Annual Awards ceremony, service anniversaries, peer-to-peer acknowledgment, employee referral
Wellness – Healthcare benefits, Wellness programs, Flu Shots, Biometric screenings, and several other wellness optio

Employees are valued for their talents and contributions. We all take pride in helping our customers achieve their goals, which in turn contributes to the overall success of the company. The company does and will take affirmative action to employ and advance in employment individuals with disabilities and protected veterans, and to treat qualified individuals without discrimination based on their physical or mental disability or veteran status. DMI is an Equal Opportunity Employer Minority/Female/Veterans/Disability. DMI maintains a drug-free workplace.

***************** No Agencies Please *****************

Applicants selected may be subject to a government security investigation and must meet eligibility requirements for access to classified information. US citizenship may be required for some positions.","$92,990 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,2002,$100 to $500 million (USD)
"TikTok
3.5",3.5,"San Jose, CA",Senior Software Development Engineer - Data,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

Team Introduction
The Data Platform team works on building data infrastructures and data products to support business engineering teams at TikTok.

As a Software Development Engineer in the data platform team, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.

Responsibilities - What You'll Do

Design and build data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)
Design and implement reliable, scalable, robust and extensible big data systems that support core products and business
Establish solid design and best engineering practice for engineers as well as non-technical people.
Qualifications
Qualification

BS/MS from a quantitative field of study (CS, STEM, etc)
Experience in API, backend, and data services development
Experience in Big Data stack(Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc.)
Experience with ETL (Extraction, Transformation & Loading) or ELT, and architecting data systems
Ability to ship code in Java, Python and SQL
Solid communication and collaboration skills
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at dataecommerce.accommodation@tiktok.com
Job Information
The base salary range for this position in the selected city is $187040 - $280000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$233,520 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"F2Onsite
3.9",3.9,"Princeton, NJ",Remote Senior Data Center Engineer/Consultant - part-time,"Sr. Data Center Engineer/Consultant
Remote-PT-20 hours per week - East Coast time zone
6 month assignment

Requirements
Our client is looking for a Sr. Engineer with recent experience deploying the HPE Simplivity data center platform.
Our client is looking for an engineer who can provide insight and direction on best practices utilizing HPE Simplivyt and VMware.
Large implementations with Simplivity Gen 10 nodes.

Additional Information
All candidates are encouraged to apply, but many positions require a strict drug and background check by our customers.
F2OnSite supports and adheres to all state laws regarding background checks.
“Except where prohibited by law, many employees and contractors of F2OnSite are required to obtain a Covid-19 vaccine, and new hires will be required to provide proof they have done so, or obtain an exemption or deferral based on a valid religious or medical reason, prior to beginning employment.”",$65.00 /hr (est.),201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2007,$5 to $25 million (USD)
"INTEL
4.1",4.1,"Santa Clara, CA",Software Engineer / Data Analyst - Graphics and AI,"Job Description

The Graphics and AI Engineering Evangelism and Enablement team is looking for a software engineer who can help set our client products for success by looking at strategic opportunities between GPU IPs, API features and workloads. This person will work in an ever-changing fast paced environment and will integrate deeply with the engineering teams to build a strong understanding of key technologies, software APIs and workloads related to graphics and AI.
You will be responsible for, but not limited to:
Build data-based analysis and recommendations to help drive cross-organizations alignment on roadmap strategy and next-gen workloads.
Understand the key APIs, tools and frameworks used for graphics and AI development.
Run graphics and AI workloads analysis with internal and third party tools.
Identify opportunities to better align IPs and software stack improvements with developers’ needs.
Create content, including slides and visual presentations of data to illustrate and contextualize recommendations to the broader team.
Contribute to building a culture oriented toward serving the changing client computing well in a competitive environment.

Qualifications

You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates.
Minimum Qualifications:
Bachelor’s degree in computer science, electrical engineering, computer engineering or any STEM related field with:
3+ years of experience real-time graphics workloads and APIs (1-2 years)

Preferred Qualifications:
Master’s degree in computer science, electrical engineering, computer engineering or related field
1+ years of experience running workloads analysis with Intel GPA or similar third-party tools.
1+ years of experience with AI accelerated workloads is desirable.
Proven experience articulating technical concepts.

Inside this Business Group

The Client Computing Group (CCG) is responsible for driving business strategy and product development for Intel's PC products and platforms, spanning form factors such as notebooks, desktops, 2 in 1s, all in ones. Working with our partners across the industry, we intend to continue to advance PC experiences to deliver the real-world performance people demand. As the largest business unit at Intel, CCG is investing more heavily in the PC, ramping its capabilities even more aggressively, and designing the PC experience even more deliberately, including delivering a predictable cadence of leadership products. As a result, we are able to fuel innovation across Intel, providing an important source of IP and scale, as well as help the company deliver on its purpose of enriching the lives of every person on earth.
Other Locations

US, OR, Hillsboro; US, CA, Santa Clara
Covid Statement

Intel strongly encourages employees to be vaccinated against COVID-19. Intel aligns to federal, state, and local laws and as a contractor to the U.S. Government is subject to government mandates that may be issued. Intel policies for COVID-19 including guidance about testing and vaccination are subject to change over time.
Posting Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.
Benefits

We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html

Annual Salary Range for jobs which could be performed in US, California: $102,540.00-$153,580.00
Salary range dependent on a number of factors including location and experience

Working Model

This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs.

JobType
Hybrid","$128,060 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1968,$10+ billion (USD)
"Relevance Lab
4.1",4.1,Remote,Senior Data Engineer,"Work Location: Remote/ Hybrid
Experience: 5 – 8 years
Required Skills: AWS Data services, Redshift, Lambda, Glue, S3, Athena, Kinesis, ETL, SQL, No SQL, Python/Scala/java, Agile, CICD.
Job Description:
The Senior Data Engineer is responsible for data processing in the company Data Cloud . The candidate will demonstrate a successful track record of thought leadership and management skills coupled with deep experience engineering and managing cloud-based data platforms. The ideal candidate will be distinguished not only by their experience working in a cloud-based, multi-tenant environment, but also by high levels of creativity, passion and thought leadership.
Responsibilities:
Lead the company Data Cloud development effort focusing on scalability, quality and performance.
Perform code reviews.
Ensure adherence to Scholastic’s enterprise best practices.
Design efficient, scalable processes to acquire, manipulate and project data.
Participate actively in all facets of the Agile process.
Contribute to the SDC codebase directly by taking on development tasks.
Requirements:
Bachelor’s degree in computer science, Math, Statistics or other quantitative disciplines
5+ years’ experience implementing enterprise data solutions.
Extensive experience with AWS data services: Redshift, RDS, DynamoDB, Data Pipeline, EMR, Athena, Spectrum, GLUE, Lambda, Airflow
Extensive experience writing and tuning SQL queries.
5+ years using ETL / data movement tools (dbt, talend, Pentaho, Glue, SSIS, Sqoop, Matillion, Informatica).
3+ years programming in one or more languages (Python, Java, Scala, C/C++)
2+ years’ experience with NoSQL data platforms.
Experience implementing a data lake architecture in AWS mainly for S3, and Lambda implementation.
Experience with Agile process methodology, CI/CD automation, Test Driven Development.
Experience with AWS Kinesis, Kafka, Storm, Spark, SonarQube highly desired Certifications.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2011,$25 to $100 million (USD)
"CACI
4.0",4.0,"Fort Bragg, NC",Data Engineer,"Data Engineer
Job Category: Engineering
Time Type: Full time
Minimum Clearance Required to Start: None
Employee Type: Regular
Percentage of Travel Required: None
Type of Travel: Local
What You’ll Get to Do:
As a CACI-Wexford Data Engineer, you will support United States Army Special Operations Command's (USASOC) core responsibility to provide trained and ready forces that are prepared to meet Geographic Combatant Command (GCC) and Theater Special Operations Command (TSOC) requirements around the world. Considering the breadth of hybrid and dynamic threat groups associated with each GCC's respective Area of Responsibility, providing tailored Special Operations force packages with the proper mix of skills and equipment in time to prevent or address conflict is a difficult task using conventional force generation and deployment processes. USASOCs transition to a truly data-driven organization to best posture for both the current operational environment and the next operational environment.
More About the Role:
The project is rooted in Agile best practices, executing the tenants of DevOps and implement continuous process improvement in process and tools/technology to facilitate USASOC’s transition to a data-driven organization, support ongoing AI/ML across the enterprise, and enable modernization efforts that support the ARSOF mission. The Project Actively supports the Artificial Intelligence Division (AI DIV).
**This position is a blend of on-site and telework with weekly presence required on Fort Bragg, NC
You’ll Bring These Qualifications:
Ability to obtain a DoD Secret security clearance is required
Must meet DoD 8140 IAT Level II or IAM Level I
Must have a Bachelor's Degree and 3 years' experience, Associate Degree and 4 years' experience or Highschool Diploma and 6 years' experience
Ability to assemble large, complex sets of data that meet non-functional and functional business requirements.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity
Works with stakeholders including data, design, product, and executive teams to assist them with data-related technical issues
Able to migrate workloads to, from, and among the different cloud computing service models.
Able to Identify data consolidation opportunities across database systems, including data sharing and access between business lines.
Provide recommendations on new database technologies and architectures.
Monitor and maintain databases to ensure optimal performance.
Implement data mining and data warehousing applications.
Writes unit/integration tests, contributes to engineering wiki, and documents work
Designs data integrations and data quality framework
Designs and evaluates open source and vendor tools for data lineage
High-level of proficiency in SQL, data modeling, and ETL/ELT processes and implementation
Technical Documentation Skills; familiar with multiple databases
Knowledge of programming languages (e.g. Java and Python)
These Qualifications Would be Nice to Have:
Experience with AWS and open-source data engineering solutions for big data
Familiar with data engineer tools like Apache Airflow/NiFi
Experience with non-SQL database and data engineering problem sets ie. noSQL, vector, graph
Can effectively communicate with Data Science Teams and Software Development Teams
What We Can Offer You:
CACI-Wexford manages the Special Operations and Asymmetric Solutions Operating Group within CACI’s Operations Support and Services Sector.
As the premier provider of Special Operations capabilities; Tactical Advisory and Embedded Support; intelligence Applications to Law Enforcement; security cooperation and OCONUS Training Support Delivery for the company, CACI-Wexford has a reputation for uncompromising standards of quality in its people and its performance.
Joining the CACI-Wexford team is a mark of excellence for those employees who complete our rigorous Mission-Focused Staffing process.
CACI-Wexford ’s mission places its personnel against the government’s most critical emerging challenges. Work with us, and you’ll be working with a team making a difference across the globe.
CACI-Wexford offers competitive benefits as well as numerous learning and development opportunities.
As the Prime Contractor for this effort, CACI-Wexford offers unmatched stability and growth potential within the program.
Company Overview: At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic.",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1962,$1 to $5 billion (USD)
"Spartan Technologies
3.4",3.4,"Atlanta, GA",Senior Data Engineer (ETL SSIS Snowflake) | Atlanta | Hybrid,"Spartan Technologies, Inc. - Atlanta, GA
We are seeking an experienced Data Engineer for a global client's ETL team. The role is Contract to Hire and requires 2 days in office at the client's North Atlanta office.
The Data Engineer will be responsible for ETL projects and developing ETL processes into enterprise data solutions. The Data Engineer will also work closely with business analysts and stakeholders in other departments to identify, recommend, develop, implement, and support data solutions.
The Job
Deliver high quality, transactional consistent and efficient enterprise ETL / ELT solutions
Provide support, and documentation of new and existing ETL / ELT processes and solutions
Present the solution to business user and communicate with end user solution details
Work with Enterprise, ETL and Data Architect to define, develop and deliver Data Engineering Roadmap
Develop, test & implement ETL / ELT solutions using an agile methodology
Ability to handle multiple projects at once
Collaborate with other ETL and / or application developers and business users
Ability to work with on/off shore extended teams
Be a proactive member of the data services team
Maintain professional demeanor at all times while representing the company
Regular and predictable attendance at assigned times is required
Qualifications
Bachelor’s Degree in Engineering/Computer related discipline or equivalent experience
5+ years of ETL / ELT Design, development and implementation experience using standard ETL tools
5+ years of SQL Development Experience
5+ years of experience defining and managing ETL / ELT using tools and industry standard practices
3+ years of Cloud (Azure) experience
3+ years of Snowflake experience
3+ years of SQL Server Reporting Services
Knowledge Base
Advanced knowledge of SQL databases and queries
Advanced knowledge of CDC (Change Data Capture) & CT (Change Tracking) inner workings
Experience in implementing and supporting several different ETL / ELT solutions
Experience in working with many different data sets, large and small
Experience working with data in multiple ERP and data movement technologies
Experience with normalizing and de-normalizing data
Knowledge of ETL best practices and standards
Ability to quickly resolve issues
Experience with Cloud (Azure), Snowflake, SQL Server 2014 – SQL Server 2019 , SQL Server Reporting Services , SQL Server Integration Services
Ability to present ideas in concise, business-friendly and user-friendly language
Excellent written, interpersonal and verbal communication skills
Experience with managing and collaborating with multidisciplinary teams
Experience with design and development of EDW (Enterprise Data warehouse) is preferred
Experience with Data Lakehouse, Data Fabric architecture framework is preferred","$85,165 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,2007,$5 to $25 million (USD)
"Berkley
4.1",4.1,"Urbandale, IA",Data Engineer,"Company Details:

Berkley Technology Services (BTS) is the dynamic technology solution for W. R. Berkley Corporation, a Fortune 500 Commercial Lines Insurance Company. With key locations in Urbandale, IA and Wilmington, DE, BTS provides innovative and customer-focused IT solutions to the majority of WRBC’s 60+ operating units across the globe. BTS’s wide reach ensures that ideas and opinions are considered at every level of the organization to guarantee we find the best solutions possible.

Driven by a commitment to collaboration, BTS acts as consultants to our customers and Operating Units by providing comprehensive solutions that not only address the challenge at hand, but proactively plan for the “What’s Next” in our industry and beyond.

With a culture centered on innovation and entrepreneurial spirit, BTS stands as a community of technology leaders with eyes toward the future - leaders who truly care about growing not only their team members, but themselves, and take pride in their employees who shine. BTS offers endless ways to get involved and have the chance to grow your career into a wide range of roles you'd never known existed. Come join us as we push forward into the future of industry leading technological solutions.

Berkley Technology Services: Right Team, Right Technology, Simple and Secure.
Responsibilities:
Conduct code reviews, and unit testing to ensure optimal performance of Guidewire ClaimCenter system, and maintain documentation of the same;
Identify potential corrective measures to resolve system issues, and implement such corrective actions within the Guidewire ClaimCenter system or process;
Devise modifications for existing system functionalities and develop routine improvements to such systems to improve functionality;
Coordinate with multiple Operating Unit Claim’s teams and with Berkley Technology Services IT teams in order to gather information and analyze system functionality;
Collaborate with other engineers and developers in developing, maintaining and overseeing performance of databases, software and IT tools within the Guidewire ClaimCenter platform;
Provide technical support for claims analyses by adjusting and fine-tuning the data set up, interrogation, and observations in order to accommodate such analyses, per specifications and requirements;
Collaborate with stakeholders including Executive, Product, Data and Design teams to assist with data-related technical issues and support data infrastructure needs; and
Remain abreast of advancements in technologies that can be integrated with Guideware, specifically as such relates to data processes and/or structures of the Guidewire ClaimCenter platform, ODS, and data processes through integrations with Guideware.
Qualifications:
Must have a Bachelor’s Degree in Computer Science, Engineering or related field plus 5 years of progressive experience in any occupation which includes the required experience and skills.
5 years of experience with relational SQL databases such as Microsoft SQL Server;
5 years of experience in data analysis, data engineering, and ETL processes: SSIS, WinScp, SoapUI, Putty and MS Visual Studio;
5 years of experience with Guidewire ClaimCenter and Contact Manager data model;
3 years of experience with object-oriented/object function scripting languages: Python, Java, SQL and Stored Procedures; and
1 year of experience creating business intelligence reports.
10% domestic travel required to unanticipated client locations.","$82,914 /yr (est.)",1 to 50 Employees,Company - Private,Manufacturing,Commercial Printing,2012,$25 to $100 million (USD)
"Sodexo
3.3",3.3,"Irvine, CA",Senior Data Engineer,"Unit Description:
Sodexo is accelerating its’ data journey to boost sustainable business growth and enhance service offerings to consumers, clients and employees. In collaboration with a cross-functional feature team (AI Product Manager, Data Engineer, DevOps, etc.), we are setting up a North America Data Factory that designs and builds scalable and reliable ML/AI solutions integrating and optimizing algorithms at every stage of the Product life cycle (e.g. MVM, MVP, Industrialization, etc).

We are searching for a Senior Data Engineer who will design and build scalable and reliable ML/AI solutions integrating and optimizing algorithms at every stage of the Product life cycle

This is a hybrid position, we are seeking candidates located in the Irvine, CA region.

The successful candidate will:
Provide support during the scoping and minimum viable model phases
Design and co-implement functional blocks to ensure a scalable and reliable ML/AI solution all along the product life cycle
Drive innovation within Sodexo recommending & testing new AI/ML technologies
Is this the right opportunity for you? We are looking for candidates that have/are:
Excellent knowledge of Python and experience in Scala.
Good understanding of both OOP and functional programming.
Experience with Java and C# are a plus but Python is mandatory.
Experience with R is a plus
Experience with Spark is a must with knowledge of message based systems (service bus, Kafka, Stream).
Experience in Azure Databricks is a plus.
Knowledge of Container based technologies: Docker and Kubernetes
Architecture and cloud patterns: Microservices (Azure Functions) architectures, SOA architectures, API design practices (HATEOAS, GraphQL, etc)
Databases: SQL (Azure SQL Server) and NoSQL (ElasticSearch, CosmosDB, MongoDB).
Proven experience of Snowflake is a plus.
Excellent knowledge of data structures
Excellent knowledge of big data oriented file formats (Parquet/Delta, ORC, AVRO)
Experience in dashboarding and visualization tools is a plus (PowerBI in particular).
Experience in Azure Machine Learning Services is a plus
Sodexo offers a full array of benefits including paid time off, holidays, medical, dental, vision, 401K and access to ongoing training and development programs, tuition reimbursement, plus health and wellness programs.

Not the job for you?
At Sodexo, we have numerous IS&T positions that support this and other initiatives with similar goals. Continue your search for IS&T jobs.

Working for Sodexo:
Sodexo fosters a culture committed to the growth of individuals through continuous learning, mentoring and career growth opportunities. Our IS&T team supports 13,000 locations across North America and collaborates with the entire Sodexo Group, spanning 72 countries. Sodexo empowers its employees who have developed a thorough understanding of the organization to create their own career path

#LI-Hybrid
What We Offer:
Sodexo offers fair and equitable compensation, partially determined by a candidate's education level or years of relevant experience. While the budgeted range for the position is posted, Sodexo salary offers are based on a candidate's specific criteria, like experience, skills, education and training.
Position Summary:
In collaboration with a cross-functional feature team (AI Product Manager, Data Engineer, DevOps, etc), the Data Engineer Data Lab objective is to design and build scalable and reliable ML/AI solutions integrating and optimizing algorithms at every stage of the Product life cycle (e.g. MVM, MVP, Industrialization, etc).

40%
Provide support during the scoping and Minimum Viable Model phases
Co-realize the data and tech due diligence and SoTA* analysis
Guarantee correct exploratory environment setup
Provide workload estimation on the product backlog to the AI Product Manager

40%
Design and co-implement functional blocks to ensure a scalable and reliable ML/AI solution all along the product life cycle
Design and build pipelines on an ad hoc basis
Measure cost effectiveness of the different transformation pipelines scenario
Embed monitoring metrics into products-Design MVP target architectures-Package, document code and infrastructure
Optimize ML/AI algorithm performances in distributed systems (e.g. model response time, optimization of the parallelism, etc)

20%
Drive innovation within Sodexo recommending & testing new AI/ML technologies
Conduct technological watch
Test new technologies in the context of use cases MVMs & MVPs
Communicate on new market technologies which could bring value to Sodexo
Participate to selecting new service providers (e.g. RFP)
Qualifications & Requirements:
Basic Education Requirement: Bachelor’s Degree or equivalent experience
Basic Management Experience: 0–7 years
Basic Functional Experience: 7 years

Sodexo is an EEO/AA/Minority/Female/Disability/Veteran employer.","$119,127 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Catering & Food Service Contractors,1966,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA",Software Development Engineer - Applications [Dept: IS Data Services],"Summary
Posted: Aug 2, 2023
Weekly Hours: 40
Role Number:200494226
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
5 years of experience in the job offered or related occupation.
1 year of experience with each of the following skills is required 1. Database fundamentals 2. Managing critical implementations of Oracle and Mongo 3. Automating day to day tasks using Python, Shell or Java 4. Managing database replication using Oracle Golden Gate 5. Performance tuning of queries, databases 6. Implementing and managing database instances on cloud services like AWS 7. Defining and adopting database security best practices 8. Designing and architecting cross-region database instances both on cloud and on-premise as a part of Disaster Recovery
Description
Multiple positions available in Cupertino, California and various unanticipated locations throughout the USA. Develop database automation scripts and reports. Integrate and collaborate with application development and support teams on new projects. Utilize expertise in HA options, TAF, RAG, ASM, Flex Clusters, and GDS. Continue to improve and create DBA policies, procedures, and standards. Provide technical guidance for integration and testing. Design, develop, and plan new production systems and databases. Engineer and tune databases. Responsible for configuration management, performance tuning, and administration. 40 hours/week. At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700- $256,500/yr and your base pay will depend on your skills, qualifications, experience, and location. PAY & BENEFITS: Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits: https://www.apple.com/careers/us/benefits.html. Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program. Apple is an Equal Employment Opportunity Employer that is committed to inclusion and diversity. We also take affirmative action to offer employment and advancement opportunities to all applicants, including minorities, women, protected veterans, and individuals with disabilities.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Atlassian
4.4",4.4,"San Francisco, CA","Senior Software Engineer, Learning Data and Integrations","Working at Atlassian

Atlassians can choose where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.

You are the accountable technical service owner of Atlassian University data and integrations to support our learning experience. You are an enterprise architect, development, operations, compliance/security engineer that lives and breathes customer learning experiences. You will team with your colleagues to define the end-to-end learning experience and how the data flows between systems. You will execute, operate, and improve said vision. You will report to the leader of Delivery Technologies.

Enterprise Architect
You are our technical visionary of how our systems and products work with each other to support our learner experience. (Our learner experience refers to how our customers interact with our different Atlassian platforms to access and engage in our learning solutions.) Systems include a mixture of homegrown, commercial-off-the-shelf and SaaS vendors that provide the essential capabilities, such as:
Learning Management Systems (Intellum/Homegrown)
Community Management Systems (Khoros)
Identity systems (Homegrown)
Gamification (Bunchball)
Lab environments (Homegrown/CloudShare)
Certification systems (Homegrown/Certmetrics)
Commerce/Financial (Homegrown/Oracle)
Marketing/Web properties
Analytics/Reporting (Amplitude, Databricks, Tableau)
Stay up to date on all the latest technology trends in this area.
This is 30% of the job.

Software Developer
You are a Software Developer for Atlassian University. You will develop and team with other software developers at Atlassian to build microservices, and integrate with other microservices/SaaS systems focused on learner data. Key technologies include:
Java
Node.js
DynamoDB
Postgres
Amplitude
Databricks
Tableau
Data lakes
This is 25% of the job.

Operations Engineer
In addition to being a Developer, you are also an Operations Engineer…A DevOps Engineer if you will. Responsibilities include:
Monitor and resolve high-priority incidents and outages
Monitor SLAs/SLOs
Prioritize tech debt in upcoming sprints
Produce and review operations reports with management
This is 25% of the job.
Compliance and Security Engineer
Trust and security are core to our value proposition and this role. Responsibilities include:
Monitor and resolve high-priority security incidents
Monitor and resolve vulnerabilities identified by our larger Atlassian trust/security capability
Create and operate internal controls
Ensure our Trust Scorecard is >= 90%
This is 10% of the job.

Vendor Manager
As mentioned above, our learner experience consists of a mix of homegrown, commercial software, and SaaS vendors. Our vendors are key partners in providing a fabulous end-user experience. You will team with them so we can extract the best from them. You will partner with your Business Operations peers for:
Operational reviews
Product roadmap reviews
Joint strategy sessions
This is 5% of the job.

Accountant
Channel your inner Ben Wyatt and work with our Business Operations peers to make sure the budget is balanced and always optimized for effectiveness. Avoid “Ice Town.”
This is 5% of the job.
More about you:
8+ years in software engineering following Agile development processes using microservices architecture
REST API Development: Exposure to software ecosystems, API technology such as REST or GraphQL, and experience building tools or platforms for other developers is also desirable
Programming: Expert-level proficiency in one or more prominent languages such as Java, Python
Exposure to building high-scale reliable systems in the cloud
Experience in AWS technologies like CloudFormation, EC2, ELB, DynamoDB, Glue ETL, Postgres, S3, and more. AWS experience can be substituted with experience in similar public clouds (i.e Azure)
Technical architecture experience and familiarity with enterprise architecture
Business acumen and a passion for understanding customers and their needs
Knowledge of data engineering
BS (or higher) in CS or a related field
And ideally, we'd hope you'd have:
Strong programming experience in Java or similar languages, and foundation in data structures, algorithms, and distributed system
Prior operations experience with 24x7 SLAs
Knowledge of learning management systems
Knowledge of community management systems
Knowledge of website and content management systems
Knowledge of e-commerce and finance systems
More about our team
You will join our Atlassian University team at a really exciting time! Atlassian is growing rapidly year over year, and we want to scale intelligently while helping our customers unlock value from our products faster. This is an opportunity to play a major role in achieving that goal. We are a small but mighty team of top-tier professionals with diverse skills and work backgrounds. Our team is open, encouraging, focused, located around the globe, and is all about providing outstanding training solutions to our customers!
Read about engineering at Atlassian:
Atlassian Engineering

Compensation
At Atlassian, we strive to design equitable and explainable compensation programs. To support this goal, the baseline of our range is higher than that of the typical market range, but in turn we expect to hire most candidates near this baseline. Base pay within the range is ultimately determined by a candidate's skills, expertise, or experience.
In the United States, we have three geographic pay zones. For this role, our current base pay ranges for new hires in each zone are:

Zone A: $135,400 - $162,400

Zone B: $121,800 - $146,200

Zone C: $112,400 - $134,800

This role may also be eligible for benefits, bonuses, commissions, and equity.
Please visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.
#LI-Remote

Our perks & benefits

Atlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.

About Atlassian

At Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.

We believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.

To provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

To learn more about our culture and hiring process, visit go.atlassian.com/crh.","$149,287 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Software Development,2002,Unknown / Non-Applicable
"Duke University
4.1",4.1,"Durham, NC","Data Analytics Engineer (Analyst, IT)","If you are passionate about addressing challenging issues in higher education through the use of data engineering practices and tools, we would like to talk to you about an engineering role on the Data Analytics team within Duke University’s Office of Information Technology.

POSITION SUMMARY:
The Office of Information Technology (OIT) is responsible for the overall coordination, implementation and management of enterprise IT services for Duke University. In partnership with Duke Health Technology Services (DHTS), OIT manages a shared log analysis service supporting the intake and management of IT logs from a variety of sources in enterprise tools (Splunk and Apache Spark).

The incumbent will be embedded in the OIT Data Analytics team and work with collective OIT and DHTS team to manage the log analysis infrastructure. The position will be responsible for working with OIT and DHTS teams to support this shared environment and work with OIT and DHTS teams to ensure the performance and maintenance of the systems. In addition, the successful candidate will work with the support teams to establish or support performance reporting via dashboards within the enterprise tools.

Duties include:
Manage the log analysis platforms, including but not limited to performance tuning and application maintenance.
Work hands-on with data to collect, summarize and visualize operational metrics based on detailed log data in support of IT activities
Build, maintain, and improve dashboards to describe past, present, and future trends
Work with OIT and DHTS teams to establish processes for adding resources and groups to the shared log analysis environment.
Identify opportunities to improve institutional systems, process, and data
Support log ingestion from a variety of sources into the enterprise log analysis infrastructure.
Design and implement local and cloud batch and streaming data pipelines
Gather data requirements from stakeholder analysts and data scientists and deliver prepared data for analytics and modeling
Integrate data derived from a variety of data sources including logs, external APIs, and internal databases
Utilize python to analyze and build complex datasets

Skills/Qualifications

Deep experience with log aggregation and analytics platforms such as Splunk, Apache Spark or ELK required.
Demonstrated technical expertise with application performance tuning, log ingestion, and general administration with the aforementioned applications.
Demonstrated experience with Kafka or other pub/sub technologies.
Knowledge of or experience with creation of dashboards or other data visualizations within analytics platforms.
Experience in maintaining log analytics platforms on virtual infrastructures.
Hands-on experience with RDBMS and with advanced SQL
Demonstrated experience with one or more scripting languages, especially Python
Demonstrated experience writing maintainable, production-ready software
Experience working within one or more cloud providers (Azure, AWS, GCP)
Experience with Spark or the Hadoop ecosystem
Experience with GIT workflow and version control systems
Ability to understand new technology concepts quickly and apply them accurately through an evolving, dynamic environment
Ability to take ownership of activities and work independently
Excellent verbal and written skills.
Experience with Data Modeling (Normalization, star schema) a plus
Experience with CI/CD flows a plus

EDUCATION:
Required: B.S. in Computer Science, Engineering or related field

QUALIFICATIONS:
3 years of experience in security, log analytics, systems administration, etc; or 5 or more years of related experience.
Certifications inclusive of log analysis products or approaches, etc. are optional, but will be considered favorably

Duke is an Affirmative Action/Equal Opportunity Employer committed to providing employment opportunity without regard to an individual's age, color, disability, gender, gender expression, gender identity, genetic information, national origin, race, religion, sex, sexual orientation, or veteran status.

Duke aspires to create a community built on collaboration, innovation, creativity, and belonging. Our collective success depends on the robust exchange of ideas—an exchange that is best when the rich diversity of our perspectives, backgrounds, and experiences flourishes. To achieve this exchange, it is essential that all members of the community feel secure and welcome, that the contributions of all individuals are respected, and that all voices are heard. All members of our community have a responsibility to uphold these values.

Essential Physical Job Functions: Certain jobs at Duke University and Duke University Health System may include essentialjob functions that require specific physical and/or mental abilities. Additional information and provision for requests for reasonable accommodation will be provided by each hiring department.","$85,606 /yr (est.)",10000+ Employees,College / University,Education,Colleges & Universities,1838,$1 to $5 billion (USD)
"Dominion Energy
3.9",3.9,"Glen Allen, VA",Engineer I/II/III - Engineering Analytics & Modeling: Data Analysis & Data Visualization,"At Dominion Energy we love our jobs. That’s right. Love. Every day we go to work filled with passion to be excellent, to creatively problem solve and to innovate. These are exciting days for energy companies, and Dominion Energy aims to shape the future of energy in America. We are looking at all of our work with fresh eyes, retooling everything we do, in every part of the company, to operate more sustainably and to deliver energy more reliably than ever. We are looking for interesting, independent thinkers and doers who can help shape the culture of a forward-looking company that’s proud of its rich legacy. Are you a change agent? Do you think differently? Do you want to fall in love with your job? If you answered “yes,” then read on!

To learn more about Dominion Energy’s workplace culture, sustainability efforts, and commitment to DE&I, please see our Sustainability & Corporate Responsibility Report and Diversity, Equity & Inclusion Report.

Groups using the 3-2 schedule:

We offer a hybrid 3-2 work schedule (three days in the office, two days of teleworking) to accommodate the need for flexibility.

Job Summary
We Strive to Drive Power Innovation Through Data


The nature of the grid is in flux – we on the Engineering Analytics & Modeling team see this challenge and aim to rise to the occasion. Our team mandate is simple: we aim to bridge the gap between real-world system data and provide consumable business intelligence to help steer the future of how we monitor and manage the grid. Our fast-growing team is responsible for the capture, utilization, and application of time-series data, including Synchrophasors and SCADA. Our work is to steward this data and ensure its analysis and outputs influence our business and the industry to adapt and meet the demands of shifting energy landscape. We seek the curious, the self-motivated, and those driven by the pursuit of driving change.

Job Summary: We Seek Joint Expertise in Power Systems & Data Storytelling
Our Engineering Analytics & Modeling team is seeking a Data Analysis & Data Visualization expert with Engineering background to support our growing and developing electric transmission analytics capabilities. An ideal candidate is driven by the pursuit of excellence – this is not a job for wrench-turning, but rather for those compelled to identify problems and solve them with critical thinking abilities and working with a multi-faceted team. Candidates must bring an ability to identify gaps in knowledge and organizational capability and pinpoint uses for data and storytelling techniques to ensure we serve the business with improved data-decision making technology. A successful candidate will focus on:
Forging new relationships across the organization in search for applicable use cases and opportunities to use time series data as a backbone for analysis and decision-making.
Ongoing account management – tending to existing relationships to meet established project requirements and ensure any analytic/application outputs meet the stated objective from our captured requirements.
Trial and error through agile methods with the established stakeholder group; in the pursuit of lightweight applications and capabilities, we operate through constant contact and focus on results and proving value, not through over-engineered top-down solutioning.:
Continuous learning: whether it’s new technologies or more about our company vertical, our most successful team members are those who have an insatiable desire to learn.
Exploring new visualization tools and modeling for time-series analysis in power systems
- whether from industry or parallel industries – we aim to stay plugged into the latest offered through technology and professional practice.



This position will be filled at the level commensurate with the selected candidates’ skills and abilities.

Must be able to meet NERC qualifications.
Relocation assistance may be offered to the successful candidate.
Sponsorship assistance may be offered to the successful candidate.
Required Knowledge, Skills, Abilities & Experience
The knowledge, skills, abilities and experience required for entry into this job include the following:


Engineer I: 0-2+ years of engineering experience
Engineer II: 3+ years of engineering experience
Engineer III: 5+ years of engineering experience
Engineering principles: We prefer candidates bring a power systems background to this role, but it is not required. Alternative engineering skills and a desire to learn about our operating vertical will also be accepted provided a candidate shows strong data analysis and storytelling skills and demonstrates an affinity for learning and growth.
Data Analysis: Interrogating data and carefully posing the right questions to produce insightful and high impact outputs and outcomes. Candidates should possess strong analytic skills and have a history of using programmatic languages to create data analyses and visualizations that answer specific and properly posed questions. Candidates must demonstrate a high degree of proficiency in developing tools and performing analysis using Python, R Studio, or an equivalent data analysis language. Advanced Excel, Visual Basic, and SQL skills are not mandatory, but strongly preferred.
Data Visualization: More accurately, data storytelling. Graphing data has become a low-code/no-code capability – telling the right story with data to ensure end users feel empowered and assured of how they approach their work is the elevated and specialized skill we’re after. We encourage candidates with background in Power BI, Tableau, Google Data Studio, or SAS to apply for the role.
Signal processing (not required but nice to have): This includes the application of signal processing techniques to power system analysis (Fourier transform, SVD, time-frequency analysis).
Autonomy and self-starting: We are spearheading a brand-new industry capability; we are seeking candidates with the ability to operate independently while aligning to the joint mission of our team.
Strong Communication Skills: Our work will support customers across the organization, strong oral and written communication skills will be a key part of our ability to succeed and penetrate the organization.

Education Requirements
Required degree (equivalency not accepted in lieu of required degree): Bachelor
Required discipline(s): Electrical Engineering
Preferred but not required: Master's in Electrical Engineering

This position will consider recent and upcoming graduates up until August 31, 2023

REQUIRED ENGINEERING CRITERIA:

For placement of a candidate in the Engineer job series, the following criteria must be met:
Possess a 4-year Engineering degree from an ABET accredited Engineering program based on the year that the Engineering program was accredited by ABET, or
Possess a 4-year Engineering degree from an institution outside of the U.S. which is accredited through the country's own Engineering accrediting body under the Washington Accord as a full signatory, and is a degree that was recognized by the country's accrediting body on or after the date that full signatory status was achieved, or
Possess a 4-year degree in Engineering (non-ABET accredited), Physics, Chemistry, Math or Engineering Technology and a post-graduate Engineering degree from an institution where the undergraduate degree in the same Engineering discipline is ABET-accredited based on the year the Engineering program was accredited by ABET, or
Holds or has previously held a valid U.S. Professional Engineer license.
Licenses, Certifications, or Quals Description
Working Conditions
Office Work Environment 76 -100%
Travel Up to 25%
Other Working Conditions
Test Description
No Testing Required

Export Control


Certain positions at Dominion Energy may involve access to information and technology subject to export controls under U.S. law. Compliance with these export controls may result in Dominion Energy limiting its consideration of certain applicants.

Other Information


We offer excellent plans and programs for employees. Employees are rewarded with a competitive salary and comprehensive benefits package which may include: health benefits with coverage for families and domestic partners, vacation, retirement plans, paid holidays, tuition reimbursement, and much more. To learn more about our benefits, click here dombenefits.com.
Dominion Energy is an equal opportunity employer and is committed to a diverse workforce. Qualified applicants will receive consideration for employment without regard to their protected veteran or disabled status.
You can experience the excitement of our company – it's the difference between taking a job and starting a career.","$83,567 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1909,$10+ billion (USD)
"AMS.NET
3.6",3.6,"Livermore, CA",Systems Engineer (Data Center),"Job Summary

The position is part of the engineering team and requires strong communication skills to coordinate with technical subject matter experts, network architects, and subcontractors. A strong understanding of Data Center Infrastructure, manufacturer best practices and documentation skills are required.
This is a hands-on trouble-shooting opportunity for a versatile candidate to develop and work on small to large scale data center system infrastructures. Some travel to customer sites required.
Duties/Responsibilities
1. Quick learner and ability to adjust to different customers’ environments.
2. Acts as a mentor and provides guidance and support to engineers and technicians.
3. Maintains open and professional communication with customers and AMS.NET employees at all times.
4. Maintains accurate time tracking in accordance with AMS.NET procedures
5. Generates and accurately maintains Data Center and system documentation.
6. Supports technology for networks, data centers and communication systems
7. Supports customer systems that are under contract with AMS.NET
8. Troubleshoots and supports technology for networks, data centers and communication systems
9. Conducts trainings on various applications
Job requirements
Skills/Qualifications
1. Hands-On Data Center troubleshooting skills including:
VMware vSphere and vCenter applications
Server Hardware Support (Cisco UCS, HPE ProLiant, Dell PowerEdge)
Microsoft Server 2016/2019/2022
FCoE/iSCSI protocol knowledge
Vmware (vSphere/ESXi)
Backups (VEEAM/ Rubrik/Cohesity)
SAN Technologies (Pure Storage, IBM, HPE Nimble)
Cloud technologies (Wasabi, Azure)
2. Professional communication skills – both written and verbal
3. Ability to meet deadlines, work under pressure and multi-tasking
4. Ability to read and understand technical documents (safety rules, maintenance instructions and procedure manuals) and pass related examinations
5. Working knowledge of Microsoft Office Suite programs (Word, Excel, Outlook, PowerPoint)
6. Ability to quickly learn and apply evolving technologies
7. Troubleshoot, identify, correct and provide root cause analysis of technical issues
8. Ability to identify and resolve customer service problems including the ability to escalate the issue to a higher level when necessary
9. Strong analytical and problem-solving skills
10. Strong time management skills including ability to prioritize activities effectively
11. Strong organizational skills

Education and Experience
High school diploma or equivalency
Degree in telecommunications, science or engineering preferred
5 years’ experience in technical engineering environment and/or design preferred
Job preferences
Certifications
VMware VCP (Recommended not required)
Microsoft Certifications is a plus
Additional information
Special Physical Demands
Ability to lift 50 lbs
Ability to climb a ladder
Ability to work in tight or confining workspaces
Ability to work in dusty and/or hot environmental conditions

Job Requirements
Pre-employment background check required
Valid California driver’s license
Good driving record
A well-maintained automobile in good operating condition
Auto insurance
Occasional travel required","$114,011 /yr (est.)",51 to 200 Employees,Company - Private,Manufacturing,Electronics Manufacturing,#N/A,$25 to $100 million (USD)
"KPMG
3.8",3.8,"Austin, TX","Associate, Data Engineer","Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today’s most important industries. Our growth is driven by delivering real results for our clients. It’s also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it’s no wonder we’re consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you’re as passionate about your future as we are, join our team.
KPMG is currently seeking an Associate, Data Engineering to join our Audit Technology organization.
Responsibilities:
Create artificial intelligence or generative artificial intelligence applications to support the execution of a high-quality audit and/or audit support activity
Define insights in large datasets by identifying trends and patterns and create data visualizations and dashboards to communicate insights to key stakeholders
Assist cross-functional teams with data-driven solutions
Support the execution of a high-quality audit and/or audit support through the diligent performance of assigned tasks and professional client and engagement team interactions
Qualifications:
Minimum one year of recent experience developing integrations using Jira, Python, REST API framework and SQL Alchemy
Bachelor’s degree from an accredited college or university
Strong technical aptitude and critical thinking and research skills
Ability to navigate various computer applications and technologies, including MS Office, ERP systems and data analysis tools
Excellent communication, time management and relationship-building skills
Able to employ sound professional judgment and professional skepticism; flexible and adaptable team player; leadership experience and resourceful in delivering high quality work
KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the salary range(s) are displayed via the URL below. The range is specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, performance, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your emotion and mental health. KPMG provides personal days off per fiscal year depending on job classification, standard work hours and years of service. Additionally, each year the firm publishes a calendar of holidays to be observed during the year. Available benefits are based on eligibility.
Colorado Salary Range: Low: $71300 - High: $122500
Albany Salary Range: Low: $67900 - High: $116700
Seattle Salary Range: Low: $74700 - High: $128400

Follow this link to obtain salary ranges by city:

https://www.kpmg.us/work-for-kpmg/pay-transparency.html/?id=6727-9
KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.
KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).","$71,300 /yr (est.)",10000+ Employees,Company - Private,Management & Consulting,Business Consulting,1987,$1 to $5 billion (USD)
UPPER LLC,#N/A,"Charlotte, NC",Data center Engineer (contractor),"As a data center engineer you perform work on server and network equipment in data centers in your region. UPPER is a nationwide provider of remote-hands services and as such, our clients hit us up to get work done by us on their behalf.
UPPER holds a database of qualifying engineers. Whenever work is ordered through UPPER, a suitable Engineer is selected to get the job done. Whether it’s a short and sweet order to push a button, rack/stack, etcetera or a larger project, UPPER selects the Engineers based on criteria like quality, accuracy availability and location.
Note carefully, as a qualifying Engineer, you are offering your services to UPPER as an independent contractor. That means that you have a lot of freedom. It also means that you have a lot of responsibility. Because when you accept an order, we expect you to execute the order in accordance with our guidelines. In short, these guidelines describe how important a professional demeanor is.
We are always looking to add smart and hard-working Engineers to our team. Because thanks to our Engineers we form a nationwide, 24×7 workforce of professionals. The word ‘professional’ is key and paramount with everything that our Engineers do.
If this is for you, we welcome you to go ahead and apply.
Job Types: Part-time, Temporary
Pay: $35.00 - $45.00 per hour
Schedule:
On call
Application Question(s):
This job is subject to a thorough background check.
Experience:
data center: 1 year (Required)
Work Location: On the road",$40.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Schlitterbahn Waterparks and Resorts
3.8",3.8,"Charlotte, NC",Data Engineer,"Charlotte, North Carolina
Job Category: Information Technology
Req ID19054
Overview:
Cedar Fair is seeking a Data Engineer at our corporate Charlotte office. The Data Engineer develops and supports centralized corporate data repository, to include large data sets from enterprise applications across the Cedar Fair domain. Deliver easy to consume data sets to the business analyst and aid in dashboard and reporting creation and delivery.
Responsibilities:
Develop data transformation processes.
Work with data and business analyst building consumable data sets.
Data governance and validation between source application and centralized data store.
Document and diagram all corporate data flow, ETL, and ELT processes.
Administrative i.e.. email, meetings.
Qualifications:
Bachelor's degree required in Information Technology.
Master's degree preferred in Data Engineering.
2-4 years work-related experience required.
3 or more years of data architecting (ETL & ELT) . 3+ years of SQL Server or other relational data application. Experience with cloud data lake and data delivery models. Expert in TSQL & ansi SQL. Experience in calling API’s via postman.
AWS, Qlik, and Visual Cron experience a plus. Working knowledge of dbt Cloud and python a plus.
Ability to pass a background check, if 18 years of age or older, which may include, but is not limited to, credit, criminal, DMV, previous employment, education and personal references, per Company policy, unless prohibited by federal, state, or provincial law.
Ability to work nights, weekends, and holiday periods to meet business needs.
Must possess a valid Driver's License.
#LI-CM1","$89,824 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,"Arts, Entertainment & Recreation",Culture & Entertainment,1979,Unknown / Non-Applicable
"HCA Healthcare
3.3",3.3,"Nashville, TN",Data Engineer,"Introduction
Do you want to join an organization that invests in you as a Data Engineer? At HCA Healthcare, you come first. HCA Healthcare has committed up to $300 million in programs to support our incredible team members over the course of three years.
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

You contribute to our success. Every role has an impact on our patients’ lives and you have the opportunity to make a difference. We are looking for a dedicated Data Engineer like you to be a part of our team.
Job Summary and Qualifications
Data Engineers within HCA’s Information and Analytics organization are responsible for defining and implementing data management practices across the enterprise. This position will focus primarily on enterprise data management and migrating of data to the cloud. This role requires working closely with the different data teams and requires ‘self-starters’ who are proficient in problem solving and capable of bringing clarity to complex situations.
Data Engineers are expected to source and incorporate new data sources into the Enterprise Data Ecosystem. The responsibilities will include writing, testing, and reviewing ETL pipelines for defining and implementing data management practices across the enterprise
This candidate will have a history of increasing responsibility in a small multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement solutions with minimal supervision. This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team environment.
Major Responsibilities:
Responsible for building and supporting a Cloud based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data. Direct the transformation from HCA Healthcare’s current on premise Teradata platform to Google Cloud Platform to enable analytics and machine learning at scale.
Implement enterprise data management practices, standards, and frameworks for Data Integration
Develop, manage, and own full data lifecycle from raw data acquisition through transformation to end user consumption.
Analyze requirements, design data pipelines and integrate those solutions for customer environments
Translate business requirements into technical design specifications
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Maintains a holistic view of information assets by creating and maintaining artifacts that illustrate how information is stored, processed, and accessed
Provide guidance on technology choices and design considerations for migrating data to the Cloud
Experience with building consumable data lakes, analytics applications and tools
Designing the cloud environment from a comprehensive perspective, ensuring that it satisfies all of the company’s needs.
Performs activities such as deployment, maintenance, monitoring, and management inside the cloud framework that has been created
Work closely with individuals across the technology organizations to help promote awareness of the data architecture and ensure that enterprise assets of competence are leveraged
Education & Experience:
Bachelor's degree required
Master's degree preferred
7+ years of experience in Information Technology required
3+ years of experience in Cloud Technologies required
Knowledge, Skills, Abilities, Behaviors:
Teradata ETL experience using BTEQ and SQL scripts.
Extensive experience with relational database management systems; Teradata, Oracle or SQL Server preferred.
Ability to troubleshoot, maintain, reverse engineer, and optimize existing ETL pipelines
Advanced SQL skills, including the ability to write, tune, and interpret SQL queries
Experience developing and supporting data pipelines from various source types (on-prem RDBMS, AWS, GCS bucket, flat file) to Big Query utilizing Google Cloud Platform native technologies
Scripting experience with Python/Unix/Linux.
Experience with Git and GitHub version control.
Experience with relational databases such as Teradata and public cloud technologies such as, GCP Big Query, GCP Data Catalog and Azure Data Bricks preferred
Experience with Cloud Data Flow, Airflow, Cloud Composer, Streamsets or managing streaming data is strongly preferred
Ability to troubleshoot, maintain, reverse engineer and optimize existing ETL pipelines.
Experience with Cloud Data Flow, Airflow, Cloud Composer, Cloud Data Fusion, Data Catalog, gsutil, GCS, Pub/Sub, Kafka, DataProc, github
Experience with handling streaming data is strongly preferred
NoSQL, Hbase, Cassandra, MongoDB, In-memory, Columnar, other emerging technologies
Ability to analyze and interpret complex data, and offer solutions to complex clinical problems.
Ability to work independently on assigned tasks.
Strong written and verbal communication skills including the ability to explain complex technical issues in a way that non-technical people may understand.
Excellent problem-solving and critical thinking skills.
Knowledge of IT governance and operations.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Good people beget good people.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
We are a family 270,000 dedicated professionals! Our Talent Acquisition team is reviewing applications for our Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your resume today to join our community of caring!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$91,163 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
"Mastech Digital
4.2",4.2,Remote,Data Solution Engineer - W2/Full Time,"Job Title: Data Solution Engineer
Duration - 6 months
Work Location: 100% remote
Job Description:
Implement data pipelines, infrastructure components, framework - Audit, Balance, Control; Security; Exception Handling etc. using Databricks
Collaborate with Data Solution Designer to ensure cohesive integration between systems and data models.
Analyze Business requirements, existing systems and provide a design guidelines that meet the business needs & Architecture principles.
Implement a metadata driven framework for processing data.
Implement Databricks optimization techniques.
Implement batch and real time data pipelines.
Build a scalable ingestion framework.
Implement a common Error/Exception handling framework.
Configure and Implement Control M, Astronomer or Airflow for scheduling and monitoring data pipelines.
Configure and integrate with REST API gateway like APIGEE.
Familiarity with Informatica (IICS), Network Data Mover (NDM), Axway Managed File transfer (MFT)
Flexible in work schedule to collaborate and guide the offshore development team
Job Type: Contract
Schedule:
8 hour shift
Experience:
Databricks deployment in Azure: 2 years (Preferred)
integrating Databricks into the Azure ecosystem: 2 years (Preferred)
Work Location: Remote",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Information Technology Support Services,1986,$100 to $500 million (USD)
"HCSC
3.9",3.9,"Richardson, TX",Test Data Management Engineer,"At HCSC, we consider our employees the cornerstone of our business and the foundation to our success. We enable employees to craft their career with curated development plans that set their learning path to a rewarding and fulfilling career.
Come join us and be part of a purpose driven company who is invested in your future!
Job Summary
This position is responsible for demonstrating a capable understanding of Test Data Management related to data security, data masking, synthetic data creation and test data strategy planning; working with teams to provide test data; creating synthetic data, perform data conditioning, macro creations for data generation, data masking, provisioning for data and mask data as needed; multi-tasking in an environment of changing priorities.
Required Job Qualifications:
Bachelor's degree required or combination of education and 2 years’ experience OR 4 years Information Technology experience
Preferred Job Qualifications:
Data Engineering Certification
Experience with Selenium Automation - novice
Python experience - capable
Experience with SQL database queries and programming - capable
Understanding of data masking concepts, with proven implementation experience. Familiarity with data quality, cleaning and masking techniques -novice
Ability to diagnose diverse technical issues in a complex enterprise environment - capable
Organizational and time management skills, with the ability to manage workload and projects in order to navigate peaks, prioritize competing commitments, and complete assignments in accordance with established deadlines - capable
Attention to detail, follow-through and customer focused orientation - capable
Analytical, decision making and problem-solving abilities, with demonstrated troubleshooting and debugging skills - capable
Ability to work independently, as well as collaboratively in a team environment - capable
Verbal and written communication, presentation and interpersonal skills – capable
TDM functions including Data provisioning, sub setting, profiling, Data mining
Abilities with TDM masking tools
Macro generation for synthetic data creation
Scripting experience with Shell, Perl, .bat, VB Script or any other scripting language experience
Are you being referred to one of our roles? If so, ask your connection at HCSC about our Employee Referral process!
HCSC Employment Statement:
HCSC is committed to diversity in the workplace and to providing equal opportunity and affirmative action to employees and applicants. We are an Equal Opportunity Employment / Affirmative Action employer dedicated to workforce diversity and a drug-free and smoke-free workplace. Drug screening and background investigation are required, as allowed by law. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.","$85,704 /yr (est.)",10000+ Employees,Company - Private,Insurance,Insurance Carriers,1936,Unknown / Non-Applicable
Eevabits,#N/A,Remote,Data Security Engineer,"Eevabits is seeking a fully remote team member to enhance our agile unit dedicated to our clients' data security goals.
Description
Eevabits is looking to add a fully remote team member to join our growing team. We are a small but agile team working together to support our customers’ data security objectives. We use a range of tools to support our customers with a focus on the Netwrix product suite. Netwrix experience is not required. Our team is continually training and up to date on the latest Netwrix products. Our team typically supports medium to enterprise customers. We work on Active Directory and data remediation, migration, and assessments projects. A typical day for the team member will be monitoring and optimizing customer environment(s), engaging vendor support as needed, and providing a high level of customer service.

Our view of an ideal team member is one who works well with the other team members, excited to learn new technologies while continuing to use existing skillsets, does not shy away from diving into a problem and obsessed with resolution.
Below experience is used as a guideline and not necessarily a requirement to perform the duties in this position. If you do not meet all these experience guidelines, we still encourage you to apply.

Desired experience:
1-3 years Windows System Administration Experience (Windows Server 2016+)
Active Directory basics (e.g., understanding user, group, and computer object management, OU management, critical roles like Domain Admins and Account Operators, and AD architecture, etc.)
Windows Operating System basics (e.g., understanding managing local users and groups, joining computers to domains, ipconfig, disk management, etc.)
Windows Operating System permissions basics (e.g., understanding NTFS and share permissions)
3rd party software deployment and troubleshooting
1 year Azure Active Directory (aka, Entra)
Exposure to Azure AD Portal administration (e.g., managing users, groups, devices, applications, etc.)
1-3 years basic network/firewall knowledge

Bonus experience:
MS SQL development
PowerShell development
Traditional/Cloud NAS administration
Data Security and Governance solutions
Privilege Access Management solutions
Interest in AI/ML technology to better serve our customer needs
Project Management suites like Asana
Password Management solutions
Security Configuration Management solutions

Team member benefits:
Medical and Dental Insurance
95% paid for by company for employee.
50% paid for by company for dependents.
Life Insurance
100% paid for by company for employee.
Flexible time off policy, empowering you to make the most of your time, so you can thrive both inside and outside the workplace.
Extended holiday periods, including the entire week of Christmas, to give you ample opportunity to unwind and connect with your family.
Internet and Cell Phone reimbursement
Salary
$50,000 - $75,000 per year","$62,500 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Blueprint Technologies
3.5",3.5,"Bellevue, WA",Senior Data Engineer,"Senior Data Engineer Spark/C#
Remote
Who is Blueprint?
We are a technology solutions firm headquartered in Bellevue, Washington, with a strong presence across the United States and in Europe. Unified by a shared passion for solving complicated problems, our people are our greatest asset. We use technology as a tool to bridge the gap between strategy and execution, powered by the knowledge, skills, and the expertise of our teams, who all have unique perspectives and years of experience across multiple industries. We're bold, smart, agile and fun.
What does Blueprint do?
Blueprint helps organizations unlock value from existing assets by leveraging cutting-edge technology to create additional revenue streams and new lines of business. We connect strategy, business solutions, products, and services to transform and grow companies.
Why Blueprint?
At Blueprint, we believe in the power of possibility and are passionate about bringing it to life. Whether you join our bustling product division, our multifaceted services team or you want to grow your career in human resources, your ability to make an impact is amplified when you join one of our teams. You'll focus on solving unique business problems while gaining hands-on experience with the world's best technology. We believe in unique perspectives and build teams of people with diverse skillsets and backgrounds. At Blueprint, you'll have the opportunity to work with multiple clients and teams, such as data science and product development, all while learning, growing, and developing new solutions. We guarantee you won't find a better place to work and thrive than at Blueprint.
What will I be doing?
Blueprint is looking for a Senior Data Engineer Spark/C# to join us as we build cutting-edge technology solutions!
As a Senior Data Engineer Spark/C#, you will lead the plan and execution of complex, mission-critical software development projects and program initiatives. You will work with a cross-functional team including engineering, product, design, operations, marketing, finance, legal, business development, and executive teams to bring ideas to market. A successful candidate will be strong in team collaboration and customer obsession, have a solution-oriented mindset, seek data-driven decisions, and will be able to dive deep.
Responsibilities Include:
Advanced Experience with Software development (5+ years)
Hands on experience of implementing utility handling frameworks with C#, Azure DataFactory and/or Synapse and Databricks
Experience with Spark (3+ years)
Working knowledge of large data platforms and Lakehouse architecture
Optimize and tune data pipelines for performance and scalability
Monitor and troubleshoot data pipelines to ensure data availability and reliability
Implement best practices for data governance, data security, and data quality to ensure data integrity across all data sources
Excellent critical thinking and problem-solving skills.
Ability to develop simple, elegant solutions to complex problems.
Ability to handle multiple competing priorities in a fast-paced environment
Being able to work as an individual contributor, as well as potentially managing other team members depending on project.
Experienced in design or support of enterprise level applications
Bachelor's or Master's degree in Computer Science, Computer Engineering, or related discipline
Preferred Qualifications:
Excellent coding skills in Python and/or C#
Experience implementing utility handling frameworks with C#, Azure DataFactory and/or Synapse and Databricks
Experience with distributed cloud (preferably Azure)
Experience with Spark (2-3 years minimum)
Experience with Azure Synapse
Appreciation for the Lakehouse medallion data architecture – bronze, silver, gold – and how those data stages are used
Strong understanding of ETL and ELT data ingestion, acquisition, and data processing patterns
Hands on experience with Relational Database (SQL or similar)
Experience with agile software development methodology and continuous delivery models
Strong written and oral communication skills.
Salary Range
Pay ranges vary based on multiple factors including, without limitation, skill sets, education, responsibilities, experience, and geographical market. The pay range for this position reflects geographic based ranges for Washington state: $142,100 to $173,000 USD/annually. The salary/wage and job title for this opening will be based on the selected candidate's qualifications and experience and may be outside this range.
Equal Opportunity Employer
Blueprint Technologies, LLC is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, age, disability, sex, gender identity or expression, orientation, veteran/military status, religion, national origin, ancestry, marital, or familial status, genetic information, citizenship, or any other status protected by law.
If you need assistance or a reasonable accommodation to complete the application process, please reach out to: recruiting@bpcs.com
Blueprint believe in the importance of a healthy and happy team, which is why our comprehensive benefits package includes:
Medical, dental, and vision coverage
Flexible Spending Account
401k program
Competitive PTO offerings
Parental Leave
Personal paid Volunteer time to support our community
Opportunities for professional growth and development
FLSA - Job Classification: Exempt, Full Time Position.","$157,550 /yr (est.)",501 to 1000 Employees,Company - Private,Management & Consulting,Business Consulting,2013,Unknown / Non-Applicable
"Connvertex Technologies Inc.
4.1",4.1,"Austin, TX",Big Data Engineer,"Big Data Engineer
Location: Cupertino, CA | Seattle, WA | Nashville, TN | Richmond, VA | Boston, MA | Austin, TX (Hybrid)
Salary Depend on Experience:
Junior level: 3-5 years
Mid level: 6-9 years
Senior level: 10-15 years
Job Description:
Requirements:
AWS
Python
Spark
Job Type: Full-time
Salary: $100,000.00 - $140,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Austin, TX 78701: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 3 years (Required)
Spark: 3 years (Required)
AWS: 3 years (Required)
Hadoop: 2 years (Required)
Work Location: Hybrid remote in Austin, TX 78701","$120,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2008,Unknown / Non-Applicable
"Radiant Digital
3.5",3.5,"Vienna, VA",Data Engineer,"Position: Data Engineer
Location: Remote
Visa: Only US Citizens
Experience and Qualifications:
Demonstrate background experience and knowledge base in Data Engineering and functional responsibilities described.
Bachelor's degree in computer science, engineering, or related field.
5+ years of experience as a Data Engineer.
Strong SQL skills.
Strong Python skills and experience with Python data libraries, e.g., Pandas, PySpark.
Experience working with Azure Synapse Analytics.
(Desired) Experience with ETL tools such as Azure Data Factory or Apache NiFi.
(Desired) Experience with big data technologies such as Parquet, Hadoop, or Spark.
Functional Responsibilities:
Designing and implementing data pipelines using Azure Synapse Analytics.
Experience profiling data sets and developing scripts to improve data quality.
Collaborating with cross-functional teams to identify and solve complex data problems.
Developing and maintaining ETL processes.
Monitoring and optimizing data pipelines for performance and reliability.
Ensuring data quality and integrity.
Working with large datasets and designing scalable data solutions.


This is a remote position.","$112,056 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2000,Unknown / Non-Applicable
"Continental Resources, Inc.
3.7",3.7,"Oklahoma City, OK",Senior IT Data Engineer,"Job Summary
The Senior Data Engineer develops and maintains robust datasets, dashboards and reports across the enterprise. The ideal candidate is passionate about solving business problems and improving processes using data from every possible source. This position works closely with asset team data analysts, engineers, geologists, data scientists and other stakeholders to design and create “decision-ready” datasets for use in technical workflows and advanced analytics.
Recognized as an expert within the organization; contributes to the development of functional strategy. Leads functional teams or projects with broad visibility to achieve milestones and objectives. Recognized expert within functional area. Solves unique and complex problems that have a broad impact on the business. Operates with broad latitude in a complex environment.
Duties and Responsibilities
Design, build, and support scalable data pipelines that combine data from multiple sources, transform it into usable formats, and deliver it to business users to consume within BI tools, industry software or on an ad-hoc basis.
Monitor, troubleshoot and optimize data pipeline tasks to maximize performance.
Collaborate with varying levels of engineers, geologists and management to effectively gather data/reporting requirements and build analytical datasets, visualizations and tools
Lead efforts to reduce duplicative datasets and tools across the value chain and drive the adoption of curated solutions
Conduct technical training on reporting and analytics best practices for new and current technical staff to increase data literacy across the company
Work with business stakeholders and IT counterparts to identify, acquire and integrate new sources of data for analytics
Stay updated on industry trends, emerging technologies, and best practices in data engineering and analytics. Apply new knowledge to enhance the creation of standardized datasets and reports.
Advise on and recommend data & analytics software improvements; perform testing and sign off for enhancement projects.
Rapid, hands-on development of new datasets & analytical solutions using SQL, Spotfire and Power BI
Personal commitment to inclusion and diversity
Other duties as assigned
Skills and Competencies
Self-starter, with ability to build and maintain cross-functional relationships
Advanced written and verbal communication skills; high degree of organizational awareness and attention to detail
Understands data modeling and data integration principles and techniques
Use SQL to retrieve data from systems, create integrated datasets using CTEs and/or subqueries, update data within systems and create data tables and views within CLR’s data warehouse
Use Spotfire to enhance existing projects and create new projects from scratch using data from a variety of sources across the enterprise
Create and support Spotfire Information Links to deliver datasets created on CLR’s Data Platform
Understand and navigate the data models of Continental’s primary data sources including Aries, WellView, ProCount, SAP, Planning Analytics, eGIS, WLM, IHS and Enverus.
Use UiPath, Grooper or Alteryx to implement automated solutions for manual workflows
Meticulous approach to data accuracy, ensuring precision in data extraction, transformation, and loading processes.
Understands E&P operations, drilling, completions, production, reservoir and geoscience data types
Willingness to learn and adapt to new technologies, tools, and business processes in a dynamic industry environment.
Ability to quickly break down business problems and requests into solvable components to delivery results efficiently
Ability to lead initiatives related to standardized reporting, coordinating teams and resources toward successful outcomes.
Ability to troubleshoot and optimize queries and datasets created by others
A mindset focused on using data to drive decision-making, improve operational efficiency, and support strategic initiatives.
Ability to quickly adapt and exemplify flexibility around process changes and shifting priorities
Action oriented - Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasm
Instills trust - Gaining the confidence and trust of others through honesty, integrity, and authenticity
Drives results - Consistently achieving results, even under tough circumstances.
Required Qualifications
High School Diploma or GED
Minimum of eight (8) years’ experience within the Oil and Gas industry working as a Data Engineer, Data Analyst, Engineering Tech, Engineering Specialist, Business Analyst, Systems Analyst, IT Analyst or related role
Intermediate to advanced skills within SQL with the ability to retrieve data from systems, create integrated datasets using CTEs and/or subqueries, update data within systems and create and manage data tables and views within CLR’s data warehouse
Intermediate to advanced skills within Spotfire and/or Power BI with the ability to use existing projects, inherit and enhance existing projects and create new projects from scratch leveraging multiple data sources.
An acceptable pre-employment background and drug test.
Preferred Qualifications
Bachelor’s Degree from an accredited college or university in Management Information Systems, Data Analytics, Information Science/Management, Economics, Finance, Accounting or related degree
Intermediate to advanced skills creating data pipelines in Databricks, FME or Alteryx
Intermediate to advanced skills developing automated workflows in Grooper or UiPath
Basic to intermediate coding skills in R or Python
Physical Requirements and Working Conditions
Requires prolonged sitting, some bending and stooping.
Occasional lifting up to 25 pounds
Manual dexterity sufficient to operate a computer keyboard and calculator.
Continental Resources, Inc. provides equal employment and affirmative action opportunities to applicants and employees without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, protected veteran status, or disability.","$101,050 /yr (est.)",1001 to 5000 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1967,Unknown / Non-Applicable
"MyFitnessPal
4.2",4.2,"Austin, TX",Data Engineer 2 - Data Platform,"At MyFitnessPal, our vision is to be the global catalyst for every ""body"" to achieve their healthy. We believe good health starts with what you eat. We provide the tools and resources to reach your fitness goals.
We are looking for a Data Engineer to join the MyFitnessPal Data Engineering team. Our users rely on MyFitnessPal to power their health and fitness journeys every day. As a member of our MyFitnessPal Engineering team, you'll have the opportunity to positively impact those users with your expertise in the backend systems that drive the MyFitnessPal ecosystem. In addition to technical expertise, you'll find that your teammates value collaboration, mentorship, and inclusive environments.
What you'll be doing:
Build and maintain pipelines that provide data critical to operational reporting and data-driven initiatives
Integrate with services and systems across the MyFitnessPal engineering teams
Evaluate and improve existing pipelines, data models, and processes to provide more robust solutions that allow others to move quickly and efficiently
Support resolution of production issues across the Data Platform stack
Engage in code-reviews, working with teammates to learn and grow
Live our core values in all you do:
Be Kind and Care
Live Good Health
Be Data-Inspired
Champion Change
Leave it Better than You Found It
Make It Happen
Qualifications to be successful in this role:
2-4 years of data engineering experience working with large datasets and complex data environments, processes, and associated solutions
Experience with a variety of data stores (e.g. Snowflake, MySQL, MongoDB, DynamoDB, etc.)
Experience with data orchestration tooling (e.g. Airflow, Data Factory, etc.)
Experience with development languages (e.g. Python, SQL, Scala, etc.)
Understanding of data modeling for analysis by business intelligence or data science teams
Experience with a variety of API design patterns, such as REST
Experience developing validation and data integrity frameworks
Triaging and debugging production data issues
Experience building high volume data pipelines for downstream analysis supporting operational indicators
Experience with data at scale
Worked alongside client teams to support integration efforts
Familiarity with AWS and/or other cloud computing platforms

Please consider applying even if you don't meet 100% of the qualifications. Research shows you can still be considered for a position if you meet some of the requirements. At MyFitnessPal, we're building a fitness product for everyone and believe our team should reflect that. We encourage people of different backgrounds, experiences, abilities, and perspectives to apply.
Exciting Full-Time Employee Benefits, Perks and Culture
Embrace the Freedom: Be a digital nomad, work from anywhere we have operations within the continental U.S.
Office Vibes: If you prefer working in an office, we've got you covered, our HQ is in vibrant Austin, TX.
Face-to-Face Connections: We value personal connections. Enjoy opportunities to meet and connect with your team members in person to help forge meaningful relationships that extend beyond the virtual realm. Teams meet as often as needed and all of MyFitnessPal gathers annually.
Flexibility At Its Best: Achieve the work-life balance you deserve. Enjoy a flexible time-off policy and work on your own terms with our Responsible Time Off benefit.
Give Back: Use your volunteer days off to support what matters most to you. Each full time teammate receives 2 days per calendar year to give back to their community through service.
Mentorship Program: Take control of your career through our mentorship program where, if you'd like, you will be matched with a teammate who can help you scale your skills and propel your growth.
Family-Friendly Support: Embrace the journey with confidence and care. Enjoy our paid maternity and paternity leave, to provide time to balance family responsibilities with your career and take the time needed to strengthen family relationships. We understand the complexities of starting or expanding a family, which is why we provide best-in-class comprehensive assistance for fertility-related matters.
Wellness Comes First: Live Good Health is one of our core values. Receive a monthly Wellness Allowance, empowering you to focus on your physical and mental well-being by choosing from a range of wellness initiatives, including dedicated mental health days.
Celebrate Greatness: Your hard work deserves recognition! Our reward and recognition platform empowers peers to acknowledge and reward each other for the exceptional contributions they make.
Elevate Your Health & Fitness: Get access to MyFitnessPal Premium, allowing you to take your fitness, health and wellness journey to new heights.
Unlock Your Potential: Access our virtual learning and development library, and participate in training opportunities to continuously grow and enhance your skills.
Championing Inclusion: Our dedicated DEI Committee actively fosters a diverse and inclusive workplace by setting actionable goals and evaluating progress across the organization.
Healthcare Matters: Your well-being is our priority. Take advantage of our competitive medical, dental, and vision benefits that cater to your holistic healthcare needs. Feel secure and supported on your wellness journey.
Secure Your Future: Benefit from our retirement savings program, giving you peace of mind for your financial goals. Reach them sooner with MyFitnessPal's competitive employer match.

At MyFitnessPal, our mission is to enable people to make healthy choices. And it wouldn't be possible without our team. We celebrate the unique POV that each person brings to the table and believe in a collaborative and inclusive environment. As an equal opportunity employer, we prohibit any unlawful discrimination on the basis of race, religion, military or veteran status, sex, gender, marital status, gender identity or expression, sexual orientation, national origin, age, or disability. These are our guiding ideologies and apply across all aspects of employment.

MyFitnessPal participates in E-Verify.","$105,164 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Internet & Web Services,2005,$100 to $500 million (USD)
"Gravie
3.5",3.5,"Minneapolis, MN",Senior Data Engineer,"Hi, we’re Gravie. Our mission is to improve the way people purchase and access healthcare through innovative, consumer-centric health benefit solutions that people can actually use. Our industry-changing products and services are developed and delivered by a diverse group of unique people. We encourage you to be your authentic self - we like you that way.
If you’re dreaming about how you can use an awesome tech stack to disrupt an industry... Gravie could be the place for you. AWS native since we started, we use functional programming with autonomous, cross-functional teams to build fast and deliver impact. Gravie is at that sweet spot, checking the boxes for both excellent technology and making a huge splash in the insurance industry.
What does it take to thrive as a Senior Data Engineer at Gravie? You need both deep technical data engineering skills, broad cross-functional skills to innovate and own creative data solution development. You should be curious, and eager to move quickly to deliver results for our customers. As part of Gravie’s engineering organization, our data team uses engineering delivery standards and practices to build and operate our core data infrastructure to support the reporting, analytics, and data science needs of our business users.
You are likely to be self-driven, enjoy working in a fast-paced entrepreneurial environment, and want to use a modern data engineering stack to solve challenging problems—with a long-term vision to create a data driven organization.
You will:
Create data pipelines and operate data infrastructure to ingest data from various sources into Gravie’s data estate.
Lead the creation of data models, architecture, and be hands-on with development and release of efficient & reliable pipelines that balance performance, cost, fit to business requirements, and security.
Operate and enhance Gravie’s AWS CDK-provisioned data infrastructure, to enable data ingestion from a variety of sources using SQL, Python, and core AWS data technologies (Redshift, Glue, EMR, Lambda).
Act as a data architect to understand various source applications, data standards, and how to integrate them with other source applications.
Identify opportunities for internal process improvement such as automating manual processes or optimizing data delivery and infrastructure for greater scalability. Design a POC and implement a solution.
Passionate about data, data quality, access, and governance to create accurate high-performance performance data assets that are easy to consume.
Mentor junior team members, regularly lead code reviews and solution design workshops.
Excel at collaborating with data vendors and design creative solutions to potentially rigid constraints on source data.
Demonstrate commitment to our core competencies of being authentic, curious, creative, empathetic and outcome oriented.
You bring:
4+ years of experience building, optimizing, testing, and orchestrating data integrations, pipelines, and cloud architectures using modern technologies such as AWS Redshift, dbt, Glue, Airflow.
3+ years of hands-on experience building or enhancing data warehouses with a Kimbell methodology.
4+ years of overall experience in a Data Engineer role, with an undergraduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Experience with data transformation, governance, data structures, metadata, dependency and workflow management.
Interest in emerging tech within the field of data tooling and practices, and willingness to make recommendations on opportunities to advance our capabilities.
Comfortable using the command line, a Unix-based OS (we are 100% Mac+Linux at Gravie) and extensive experience with software engineering best practices, like version control using Git and IaaC (AWS CDK, Terraform).
History of managing complex dependencies, processes, multi-layered projects, and estimations of scope and timeline.
Excellent communication skills and demonstrated success at driving results through influence and collaboration.
Extra credit:
Knowledge of Health Insurance Industry, ideally working with HIPAA Protected Health Information (PHI) and EDI-transmitted data.
Familiarity with data-adjacent AWS Infrastructure and services like EC2, IAM, ECS, Sagemaker.
Experience using and administering data visualization or BI tools (Looker, Tableau, Power BI).
Working knowledge of message queuing, stream processing, and data lake architectures.
Previous venture-backed start-up company experience.
Competitive pay is standard. Our unique benefits program is the gravy, i.e., the special sauce that sets our compensation package apart. In addition to standard benefits, Gravie’s package includes alternative medicine coverage, flexible PTO, 16 weeks paid parental leave, paid holidays, cell phone reimbursement, education reimbursement, and 1 week of paid paw-ternity leave just to name a few.","$108,387 /yr (est.)",201 to 500 Employees,Company - Private,Insurance,Insurance Carriers,2013,Unknown / Non-Applicable
"Allstate Identity Protection
3.6",3.6,Remote,Senior Data Engineer,"We are Allstate Identity Protection (formerly, InfoArmor), a wholly-owned subsidiary of Allstate since 2019. We are a technology and services company that has led the Identity Protection and Advanced Threat Intelligence pack for 10 years. We combine our advanced investigative systems with our expertise in working with businesses to ensure our customers remain protected from ever-evolving online threats.

Our product is a proactive identity monitoring service that alerts you at the first sign of fraud and fully restores your identity. Our new Allstate Digital Footprint™ feature offers a simple way for customers to see and secure their data and is our next step in reinventing digital and identity protection.

4,500 employers have AIP as their sole identity-protection provider including 30% of Fortune 500. Our end-user subscriber base is nearly 5 million people covered by our comprehensive protection products.

WHAT WE OFFER:
Base Pay + Corporate Bonus Plan
$100 monthly connectivity stipend
15 days of Paid Time Off
13 Paid Holidays
Career Growth Opportunities
Access to LinkedIn Learning or Pluralsight
Tuition Reimbursement
401k contribution (matching available)
100% Employer-paid medical premiums (after six months)
Free Identity Protection enrollment (employee + immediate family members)

The Enterprise Data Services Team overview and overall scope of this role

Enterprise Data Services, part of the Corporate Systems Org, provides integrated solutions leveraging Enterprise data within the organization. This encompasses blending data from internal systems of record via operational automated processes that deliver certified datasets to Business Units for consumption
The lean, productive and agile results-driven team currently consists of 1 Manager, 3 mid to senior Data Engineers, and 1 Visualization Engineer
Technical Partnerships with Data Governance, Enterprise Solutions and Financial Systems and Business Partnerships with Operations, Digital Marketing and Finance
As part of the Data Services team, reporting to the Manager, Data Engineering, you are enabling business decisions and driving growth for Allstate Identity Protection by developing effective data solutions to power operational excellence and business insight.

Current Technology Stack:
Mostly SQL and some no-SQL (mongo DB)
Data warehouse data pipelines coded in MS Stacks (MS SQL Server BI Stack, including SSIS, SSAS, and T-SQL)
Operational data pipelines are coded in LINUX Python stacks
Dashboard and Reporting solutions are coded in Power BI applications
Automated data orchestrations are conducted in SQL Server, Power BI, Cron
In your day to day
All members are fully remote; connect with team members as needed for questions, troubleshooting.
80% of your time will be dedicated to solutioning and development.
On-call support is required; the teams rotates 1-week of coverage per team member.
Meetings:
Bi-weekly Staff meetings; Distribution of top-down company and department information.
Weekly Agile meetings; Stand-ups, Planning, Estimating
Weekly Water coolers; Non-work team connections
Bi-weekly 1 on1 meetings; You and your manager discuss company/individual goals, training, roadblocks etc.

Essential Functions
Develop and maintain data pipelines leveraging the existing technical stack.
Work with business units and stakeholders to understand data needs and requirements.
Create ELT and ETL solutions targeting data assets such as data lakes (different transformational layers), data warehouses (dimensions and facts), and other database artifacts; build the infrastructure required for extraction, transformation, and loading of data from different data sources using SQL and no-SQL
Participate in maintaining documentation and standards in design, security, and data governance.
Investigate and resolve issues related to data accuracy and consistency.
Troubleshoot and remediate process failures within database and reporting platforms.
Participate in technical meetings related to enterprise architecture and data processes with the intent to plan for impacts to existing data platforms.
Develop, construct, test and maintain data architectures

Required Education, Skills, and Experiences:

Overall:
High School Diploma/ GED mandatory with 6 to 10 years’ of Progressive Experiences as a data engineer developing data pipelines
Experience in mentoring other data engineers, understanding colleague problems and questions, and working side-by-side.
Experience in leading and delivering DE projects (with Business); ability to self-manage and also review product quality of other team mates

Soft Skills:
Confident in your ability to work and communicate with data consumers to help them understand what the data means and its lineage.
Critical Thinking Skills: Can valuate issues and then develop solutions that are both creative and effective. Critical thinking also applies in the design and troubleshooting of data collection and management systems to find effective solutions to problems.

Technical Requirements:
Proficiency in programming language in Python, Java and expertise in data processing frameworks and libraries
Data Warehousing: Experience in building and working with a data warehouse. Data warehousing assists data engineers to aggregate unstructured data, collected from multiple sources (Kimball and Inman Methodologies). Experience with data design and development like data modeling.
Intermediate to expert query knowledge and experience in optimization. Strong skills in writing T-SQL code, creating and tuning views, stored procedures, and functions, verifying data integrity and accuracy.
Experience with mapping data elements from various data sources.
Demonstrable experience utilizing tools and systems on the MS SQL Server BI Stack, including SSIS, SSAS, and T-SQL, with the ability to move, audit and evaluate data.
Data Analysis Skills: Experience and understanding of one or more, Observation and research of data, types of Machine learning, and Probability and statistics concepts
Well-versed in different operating systems, primarily Linux
Good understanding of containerization and orchestration tools and CI/CD
Deep understanding of database fundamentals, including relational database design, multidimensional database design, and Online Transaction Processing (OLTP).
Experience interacting with API data sources

Preferred Education, Skills, and Experiences:
Bachelors Degree in IT, Computer Applications or Business Intelligence
API Integration (MuleSoft) experience
MuleSoft Certified Integration Associate and/or MuleSoft Certified Developer - Level 1
Cloud concepts knowledge (Azure, AWS)

The salary range information provided, reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual salary will be commensurate with skills, experience, certifications or licenses and other relevant factors. In addition, this role will be eligible to participate in the annual performance bonus of up to 20% of base salary
Employment Criteria

The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen

Work Environment & Physical Demands
AIP is a remote-first company, however our US based roles are open to in-office or flex work if you live in a city with a physical office location. This role has the opportunity to operate 100% virtually from your US based home office. We primarily collaborate with our US colleagues through virtual meetings (Zoom), email, and Slack. In this role, you will have to operate a laptop computer (PC or Mac available), computer software platforms, and other office productivity machinery, as necessary. Due to the nature of this role, you must be able to remain stationary for extended periods and must be able to observe and interpret written and/or verbal communication.

Additional Information

AIP provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

We are committed to the full inclusion of all qualified individuals. As part of this commitment, AIP will provide reasonable accommodations to all qualified individuals with disabilities to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment.

Please let us know if you need a reasonable accommodation.

Employee Privacy Statement:

Your privacy is very important to us. Allstate Identity Protection is a wholly owned subsidiary of the Allstate Corporation. To find information on our privacy practices as it relates to the collection, use and sharing of personal information relating to prospective, current, and former employees in the United States, see the Allstate US Employee Privacy Statement. Please click CA Notice of Collection to learn more on the information we collect and how we collect it

AIP uses the E-Verify employment verification program.

By submitting this application, I confirm that I have submitted the correct and accurate information that AIP can verify from their background check provider.","$130,000 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Security & Protective,2007,$100 to $500 million (USD)
"Tesla
3.6",3.6,"Fremont, CA","Data Engineer, Quality Data Engineering","What to Expect
The manufacturing quality data engineering team is a high impact, high priority and high visibility team that is laser focus on safety critical issues and expanding critical services to Gigafactories worldwide. Within Tesla's Vehicle Engineering organization, you will have the data gold mines across design, manufacturing and vehicle data sources, enabling you to design, create and deploy innovative new data services, automation and machine learning tools into production use. In this role, you will focus on building state of the art data pipelines and applying machine learning techniques to take high impact actions automatically.
What You’ll Do
Contribute to the development of our data systems by building software for retrieving, processing, analyzing, and visualizing data.
Create ETL pipelines using Python, Airflow and Kubernetes.
Analyze manufacturing, equipment and vehicle data and extract useful statistics and insights about failures in order to drive meaningful improvements to production quality and customer experience.
Work effectively with engineering to turn analysis results into meaningful actions in the production and in the manufacturing process.
Identify data sources where the potential value is not fully realized and invent new means with which to interact and gather insights from them.
Develop and deploy predictive models for anomaly detection based on time-series data, images, text and numeric data.
What You’ll Bring
[Friday 10:26 AM] Jimmy Yu
Data EngineerRole
The manufacturing quality data engineering team is a high impact, high priority and high visibility team that is laser focus on safety critical issues and expanding critical services to Gigafactories worldwide. Within Tesla's Vehicle Engineering organization, you will have the data gold mines across design, manufacturing and vehicle data sources, enabling you to design, create and deploy innovative new data services, automation and machine learning tools into production use. In this role, you will focus on building state of the art data pipelines and applying machine learning techniques to take high impact actions automatically.
Responsibilities
Contribute to the development of our data systems by building software for retrieving, processing, analyzing, and visualizing data.
Create ETL pipelines using Python, Airflow and Kubernetes.
Analyze manufacturing, equipment and vehicle data and extract useful statistics and insights about failures in order to drive meaningful improvements to production quality and customer experience.
Work effectively with engineering to turn analysis results into meaningful actions in the production and in the manufacturing process.
Identify data sources where the potential value is not fully realized and invent new means with which to interact and gather insights from them.
Develop and deploy predictive models for anomaly detection based on time-series data, images, text and numeric data.
Requirements
Bachelor’s degree or higher in quantitative discipline (e.g. Statistics, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or the equivalent in experience and evidence of exceptional ability
2+ years of work experience in data engineering or analytics related field
Extensive experience writing software with Python (e.g. Pandas, Numpy)
Experience with multiple data architecture paradigms (e.g. MySQL, MicrosoftSQL, Oracle, Hadoop, Hbase, Kafka, Spark)
Experience with open source machine learning libraries and frameworks (e.g. Scikit-Learn, Tensorflow, Keras) and introduce accurate models to a production environment
Experience with data visualization techniques and tools (e.g. Matplotlib, Plotly, Superset, Tableau), quick web application experience preferred (e.g. Flask, JQuery, Angular)
Knowledge of various data communication protocols (e.g. REST API, Websockets)
Able to work under pressure while collaborating and managing competing demands with tight deadlines
A passion and curiosity for data, data-driven decision making and machine learning
Working knowledge with continuous integration pipelines and infrastructure (e.g. Docker, Jenkins, Kubernetes)","$147,932 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Alliance Health
3.7",3.7,"Morrisville, NC","Data Operations Engineer (Full-time Remote, North Carolina)","The Data Operations Engineer is responsible of the deployment, administration and support of advanced healthcare data interoperability solutions using multiple tools and programming languages. The Data Ops Engineer uses industry standards and best practices to ensure that data integration solutions are operational and working efficiently with a focus on automation, continuous integration and continuous delivery.
This position is full-time remote; however, travel to the home will be required as needed. The selected candidate must reside in North Carolina. Candidates located in the Rock Hill, South Carolina Region will also be given consideration.
Responsibilities & Duties
Develop, deploy and support SQL and SSIS processes to support data integration projects
Develop, deploy and support APIs to consume and distribute healthcare data
Design, develop and execute unit testing plans
Develop technical and business process documentation for data integration projects
Design, develop and/or manage monitoring solutions for data integration projects
Maintain and continually improve data integration projects
Conduct ETL and data pipelines capacity planning, optimization, troubleshooting and support
Assist in establishing standards for the design, development, implementation and support of data integration projects
Provide data integration support to internal and external stakeholders
Any other tasks as reasonably required
Education & Experience
Required: Graduation from a Community College or Technical School with a major in Information Technology or related field and seven (7) years of experience in a computer science related field including experience in a data integration or ETL development position. Military experience and education in the field of work related to the position's role may be substituted on a year-for-year basis.
Knowledge, Skills, & Abilities-
Expert programming in SQL
Proficient developing, testing, deploying and maintaining ETL processes, preferably using SSIS and JAMS
Proficient developing, testing, deploying and maintaining APIs, preferably using .NET Framework
Experience with healthcare interoperability tools and protocols, including FHIR, HL7, CDA and EDI
Experience working with API management and data integration platforms such as Apigee or MuleSoft
Experience working with HIEs and/or HISPs
Strong communication and organizational skills
Ability to work independently and in a team setting
Preferred
Bachelor’s degree plus five (5) years of experience in a computer science related field including experience in a data integration or ETL development position or an equivalent combination of education and experience that includes developing complex data integration software applications.
Microsoft Certified Solutions Expert, MuleSoft Certified Developer and/or HL7 Certifications.
Salary Range
$87,454.04 to $150,549.87/Annually
Exact compensation will be determined based on the candidate's education, experience, external market data and consideration of internal equity. An excellent fringe benefit package accompanies the salary, which includes:

Medical, Dental, Vision, Life, Long Term Disability
Generous retirement savings plan
Flexible work schedules including hybrid/remote options
Paid time off including vacation, sick leave, holiday, management leave
Dress flexibility
Education
Preferred
Associates or better in Computer Information Systems
Skills
Preferred
APIs
Database Design
SQL","$119,002 /yr (est.)",201 to 500 Employees,Government,Healthcare,Health Care Services & Hospitals,2012,Unknown / Non-Applicable
"Mastercard
4.3",4.3,"O Fallon, MO",Lead Cloud Data Engineer,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Lead Cloud Data Engineer
Overview:
We are looking for a self-motivated and enthusiastic Lead Cloud Data Engineer to join the Data Platforms and Engineering Services team. This individual will be responsible to work with our Cloud Architects, Cloud infrastructure, Information Security, Technical Product Managers and Senior Stakeholders to ensure we are delivering the right solutions for our customers.
Data Platform provides real time streaming, batch data processing, pipeline orchestration, data lake management, data cataloging capabilities and deliver data on time with quality, supported by metrics. As a key player of our data platform team, you will have opportunity to use your expertise to work in solving big data problems, design, coding and analytical skills to build core capabilities, frameworks and data pipelines.

Role:
Design, develop and implement large scale, high-volume, high-performance, highly available, scalable data infrastructure and pipelines for the Lake house data platforms in AWS cloud.
Work closely with senior data engineers and data architects using Agile methodology, take ownership of the delegated tasks and deliver the results in timely manner.
Assist in troubleshooting and resolving issues with data pipelines, ensuring they are running smoothly and efficiently.
Stay up to date with emerging technologies and trends in the data engineering and cloud space and willingness to learn and use new tools and platforms that can improve efficiency.

All About You:
Experience with Software engineering or DevOps, Cloud computing - AWS and Distributed database systems (Hadoop, Oracle, Netezza etc.)
Experience in data processing platforms on cloud such as Data bricks, Apache Spark, and Snowflake to handle large-scale data processing and distributed computing across massive datasets.
Experience in programming with Python, Scala, R, Java.
Experience and knowledge of Bit Bucket, Rally, and Jenkins a plus
Experience in delivering end-to-end automation of deployment, monitoring and infrastructure management in a cloud environment.
Building and configuring environments supporting CI/CD tools using an Agile delivery methodology
Strong experience using infrastructure as Code (IaC) with tools such as Cloud Formation, Terraform to buildout AWS environments.
Supporting all tiers of applications deployed in the cloud, configuring network, cloud native services, infrastructure, and privileges for development teams (AWS Accounts, IAM Users and Roles, VPCs, S3 buckets, cloud native services) and Knowledge of cloud networking concepts, subnets, routing, load balancing, firewalls, and cloud security.
Experience in ETL orchestration and workflow management tools using open-source tools like Apache NIFI.
Knowledge with Hadoop (CDP), relational databases and SQL, ETL development, data validation and testing, Data Analysis, and experience with Hadoop technologies such as Hive, Impala, Sqoop, Hue, Spark, Python of Hadoop Platform is a plus.
BS or higher degree in Computer Science, Information Technology or relevant fields.
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Pay Ranges
O'Fallon, Missouri: $137,000 - $213,000 USD","$120,464 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Partners Health Management
3.8",3.8,"Gastonia, NC",Data Integration Engineer (Remote Option Available),"Competitive Compensation & Benefits Package!
Position eligible for –
Annual incentive bonus plan
Medical, dental, and vision insurance with low deductible/low cost health plan
Generous vacation and sick time accrual
12 paid holidays
State Retirement (pension plan)
401(k) Plan with employer match
Company paid life and disability insurance
Wellness Programs
See attachment for additional details.

Location: Remote option available for any of our locations
Projected Hiring Range: Depending on Experience
Closing Date: Open Until Filled

Primary Purpose of Position:
The Data Integration Engineer will install back-end, automated data integrations to state systems and providers’ electronic medical records, billing, data warehouses or other applicable state and providers’ systems in order to ingest customer healthcare data into applicable environments. Will also help create, manage, and optimize ETL from multiple internal data systems to provide a foundation for internal analytic dashboards. Will lead data discovery and validation projects to ensure accurate data is delivered in a timely manner for business users and state reporting requirements.

Role and Responsibilities:
Coordinate integration systems installation and monitor equipment functioning to ensure specifications are met.
Determine and recommend integration performance standards.
Analyze user needs and software requirements to determine feasibility of design within time and cost constraints.
Develop and direct software system testing and validation procedures, programming, and documentation related to integrations and interfaces.
Train users to use new or modified processes and solutions.
Store, retrieve, and manipulate data for analysis of system capabilities and requirements.
Confer with systems analysts, engineers, developers, and others to design integrations and to obtain information on project limitations and capabilities, performance requirements and interfaces.
Modify existing integrations to correct errors, allow it to adapt to new modifications, or to improve its performance.
Analyze information to determine, recommend, and plan modifications and adjustments as needed for optimum performance and transfer of information / data with internal and external partners.
Design, build, document, and troubleshoot interfaces that facilitate data exchange between Partners and third-party systems including the State, providers, etc.
Ownership of data integrity checks across interfaces
Tests and validates implemented interfaces based on requirements.
Perform internal training as well as customer training as needed.
Analyze rejected and queued transactions and perform root cause analysis.
Routinely review interface transaction statistics by vendor, client and transaction type.
Provide ad hoc written or verbal status of critical issues to management.
Coordinate update to technical documentation. Document processes and procedures.
Plan, coordinate and facilitate with clients, vendors, development, and implementation teams.

Perform other related duties as assigned.

Knowledge, Skills and Abilities:
Knowledge and familiarity working in healthcare software integration; using HL7, FHIR, Json, XML, or other related integration protocols or interoperability toolsets.
Experience with Mirth Connect/Nextgen Connect, Rhapsody or other healthcare interface engines.
Experience working in software development using Java, JavaScript, or other similar languages.
Experience working with relational databases writing SQL, Stored Procedure, and reports.
Experience analyzing specifications, software design, documentation, and testing.
Team-oriented, ability to handle multiple tasks at once, and meet deadlines.
Ability to effectively communicate with providers, external partners, management and end users both within and external to the organization.
Excellent time management skills.
Excellent verbal and written communication skills.
Attention to detail and accuracy of facts and documentation.
Knowledge of Microsoft Windows 10, Microsoft 365, Server 2019,
Knowledge of Microsoft Remote Desktop, Computer Management, and Event Viewer.
Proficient in MS Office
Experience with Azure integrations and Azure DevOps processes.

Education/Experience Required:
Bachelor’s degree in Computer Science or related field required.
3+ years of experience in extract, transform, and load (ETL) programming.
3+ years of experience working with relational databases.
Experience with Health Level Seven (HL7).
Ability to work independently solving application software problems.
Experience with establishing external access and extract, transform, and load (ETL) strategies with multiple types of data sources, particularly a variety of electronic medical record systems.
Ability to assemble and query complex data from databases, perform in depth analysis and decipher computational data.
Working experience with relational databases including Microsoft SQL, and/or MySQL
Proficient in Microsoft Office 365 Suite, specifically Word, Excel, Outlook, and general working knowledge of Internet for business use.
Conditions of Employment: Individuals must successfully complete pre-employment process, which includes criminal background check, drug screening, and reference verification.

Education/Experience Preferred:
Candidates must have a strong background, advanced knowledge and working experience in IT technologies, security architecture and system life-cycle phases are recommended.
3+ years of experience of ETL programming in an analytic/dashboard building environment, preferably with healthcare related data.
Programming and scripting skills with Java Script.
Familiarity and past work experience deploying ETL solutions using Mirth Connect, CloverETL, and/or other ETL tools.
Drive for Results (Service, Quality, and Continuous Improvement) – Ensure procedures and processes are in place that leads to delivery of quality results and continually reassess their effectiveness to achieve continuous improvement.
Communication – Proficient verbal and written communication skills. Willingness to share and receive information and ideas from all levels of the organization to achieve the desired results.
Teamwork – Commitment to the successful achievement of team and organizational goals through a desire to participate with and help other members of the team.
Customer Service Focus – Demonstrate a focus on listening to and understanding client/customer needs and then delighting the client/customer by exceeding service and quality expectations.","$48,094 /yr (est.)",Unknown,Company - Private,Healthcare,Hospitals & Health Clinics,#N/A,Unknown / Non-Applicable
The Data Sherpas,#N/A,Remote,Google Cloud Data Engineer,"Who We Are:
The Data Sherpas are a team of highly skilled and motivated engineers that help our clients at every phase of their cloud journey. If it touches the cloud, involves data, or lives as an application, we have either worked on it or have the skills and expertise to accomplish it.
What We Are Looking For:
We are looking for a detail-oriented and innovative Data Engineer with substantial experience in Google Cloud, BigQuery, SQL, and DBT. Your expertise in data pipeline construction and transformation processes and your ability to write and optimize SQL queries allow you to manage and analyze vast amounts of data effectively. Additionally, your Python skills enable you to automate and streamline data processes. Your in-depth understanding of Google Cloud data services and SQL optimization techniques contributes to your proficiency in enhancing data-driven decision-making processes.
What You'll Do:
Design, develop, and optimize data pipelines, architectures, and data sets in Google Cloud using tools such as BigQuery and DBT.
Use SQL and DBT for data transformation and manipulation, developing complex SQL queries and implementing optimization techniques for improved performance.
Utilize your expertise in Python to automate data pipeline processes, ensuring accuracy and efficiency.
Collaborate with our team of data analysts and data scientists, providing them with clean, reliable data for their analytical work.
Ensure data governance and security practices are applied across all data initiatives.
Conduct regular reviews and tests of our data systems to ensure data integrity and quality.
Stay up-to-date with industry trends and innovations, continuously improving and expanding your knowledge and skills.
What You Have:
Deep expertise in DBT (Data Build Tool) for defining, testing, and documenting data transformations in BigQuery.
Proficiency in creating and maintaining DBT models, understanding the use of macros, sources, and snapshots.
Understanding of advanced DBT concepts like incremental models, custom schemas, and the use of variables.
Experience with DBT Cloud, including setting up deployments, automated tests, and version control.
Outstanding proficiency in SQL, with the ability to write complex, efficient queries for data extraction and transformation.
Extensive experience with SQL optimization techniques, aiming to improve query performance and database scalability.
Knowledge of advanced SQL concepts like window functions, common table expressions (CTEs), and stored procedures.
Extensive experience in Google Cloud, including hands-on experience with Google Cloud data services such as BigQuery, Pub/Sub, Dataflow, and Dataproc.
Proven ability to design and implement Google Cloud-based data architectures, adhering to best practices for security, performance, and reliability.
Solid understanding of data warehousing concepts and data modeling principles.
Proficient in Python for data automation tasks.
Understanding of data governance and security practices.
Google Cloud Certification - Professional Data Engineer
Strong communication skills, with the ability to explain complex concepts to non-technical stakeholders.
Excellent problem-solving skills and attention to detail.
This contract is until the end of 2023, with a high likelihood of an extension
We cannot work with third-party agencies at this time. Resumes submitted via unapproved agencies will be automatically rejected.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Quevera LLC
4.4",4.4,"Hanover, MD",TTO 5 Software Engineer - Data Management,"Job Description:

Quevera is seeking a Software Engineer to join an exciting, collaborative and innovative team. A place where you are positioned for More than Just a Job. Where leadership partners with you, seek to cultivate and support career development, encouraging growth from within while striving to foster a diverse and inclusive environment that improves individual and organizational performance.

Duties and Responsibilities:
The analytics team is focused on delivering reliable, accurate data to our end users.
Primary Skills:
PIG
Py-Spark
Secondary Skills:
NiFi
PressureWave

Quevera is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age or any other characteristic protected by law.","$104,617 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2013,Unknown / Non-Applicable
"UrVenue
5.0",5.0,"Las Vegas, NV",Data Engineer,"Data Engineer
at UrVenue
Las Vegas Nevada (non-remote in-office position)
ABOUT THE ROLE
We are seeking an experienced Data Engineer for a full-time career as a key contributor to the creation and enhancement of the next generation data ecosystem of our groundbreaking hospitality software applications.
Your goal will be to translate internal and external data consumers’ requirements to practical and efficient code, pipelines and data structures that will maximize the value of all data assets. This will entail planning, designing, and building the processes to deliver information needed to derive key insights and value for some of the world's largest hospitality companies and resorts that is trusted, secure, compliant, and easy to use.
You will also be a key contributor along with the Data Architecture, IT, Compliance, and Security teams to ensure that data assets and data processes comply with data governance policies, including all data security, data quality and data privacy policies, automating data quality processes to ensure accurate, complete, consistent, timely, unique, and valid data assets.
Additionally, as the resident data expert at UrVenue, you will also work closely with Sales, Marketing, and IT to develop an understanding of UrVenue’s data and provide data research, analytics, and reporting solutions as needed.
This is a full-time in-office position in Las Vegas, NV.
WHAT YOU'LL DO
Develop, enhance and maintain scalable data pipelines, CDC/ETL/ELT processes and data integrations for analytics, data warehousing and data operations.
Collaborate with Data Architecture and other business teams to build out a secure, scalable high quality data ecosystem.
Collaborate with analytics and business teams to improve data movement and data models that foster data-driven decision making for both internal and external customers across the organization.
Devise and implement processes and systems to monitor all facets of data quality, ensuring production data is always accurate and available for key stakeholders and downstream business processes.
Ensure compliance with data governance, data privacy and data security policies.
Collaborating closely with Sales, Marketing, and IT teams to develop a comprehensive understanding of UrVenue's data ecosystem.
Providing data research and analysis to support decision-making processes across various departments.
Creating and delivering insightful reports and presentations based on data findings to aid strategic planning and business growth.
Developing and maintaining data analytics tools, dashboards, and visualizations to enable data-driven insights for the organization.
Ensuring data quality and accuracy through regular audits and validation processes.
Working on special projects and ad hoc analysis to address specific business challenges.
Collaborating with internal stakeholders to define data requirements for various initiatives.
Providing training and support to team members on data-related tools and practices.
Contributing to the continuous improvement of data processes and workflows.
WHO YOU ARE
2+ years of experience using Snowflake Data Warehouse, or other cloud data warehouse services.
5+ years of experience using SQL to perform complex transformations and queries.
3+ years of experience with scripting languages such as Python, PHP, Java, .net.
BS/MS degree in Computer Science, Engineering or a related subject, or equivalent educational certification or extensive real-world experience is required
Familiarity with ETL/ELT/CDC and Data Pipeline tools, such as Fivetran, Airflow, SSIS, DataStage, Stitch, Talend, etc.
You must have a passion for data, along with an appreciation of the value and beauty of well prepared and curated data assets.
Solid understanding of how data pipelines, ETL/ ELT, data integration and ingestion work, including security, scalability, data governance & compliance and data quality management.
Substantial experience developing and maintaining scalable data pipelines, ETL/ELT processes and data integrations for analytics, data warehousing and data operations.
Solid understanding of Data Warehousing, Data Lake, Operational Data Store and Data Science Data Preparation concepts.
Experience with cloud and Linux environments.
Experience with a wide variety of source data and systems, including databases, flat files, json objects, along with various APIs.
Ability to write well designed, testable, efficient, and organized code, and to follow development best practices.
Experience with optimization and parallelization of integration pipelines and databases.
Experience using Postman for API discovery and testing.
Ability to aggressively diagnose problem areas with creative problem-solving skills.
Maintain strong organizational skills to juggle multiple tasks within the constraints of timelines and budgets with business acumen.
Ability to stay up to date with industry trends, competitor products, and share this knowledge with team members
Comfort with working with stakeholders including the Executive, Product, Data and Design teams to support their data integration needs while assisting with data-related technical issues
Familiarity with GitHub version control and DataOps SDLC concepts.
Familiarity with data privacy, data governance and data quality concepts.
WHAT WE OFFER
Competitive salaries and flexible work life balance
Benefit coverage including medical and dental
Paid Vacation
A fun, vibrant office environment in Las Vegas with a smart and passionate team doing incredible things to disrupt the hospitality tech space
ABOUT US
UrVenue is the leading hospitality technology platform that powers commerce, enhances the guest experience, and monetizes resort real estate by leveraging non-room inventory across all customer touchpoints in the booking and in-stay journey. UrVenue maximizes revenue-per available-customer (RevPAC) with its advanced booking, ticketing and presale platform built for hospitality venues: nightclubs and day clubs, restaurants and lounges, resort pools and beaches, sportsbooks, spas, special events, small group meeting rooms, recreation services, bundled experiences and more. Since 2011, UrVenue’s scalable enterprise technology has been the trusted industry standard for clients ranging from independent venue operators to global hospitality, entertainment and gaming organizations including Wynn Resorts, MGM Resorts International, Caesars Entertainment, Circa Resort & Casino, Tao Group, Bagatelle, and Okada.","$81,269 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Nitor Infotech
4.1",4.1,Remote,Data Engineer/Experienced BA,"Position : Data Engineer/Experienced Business Analyst (Please note we are in the process of refining the job description for this role)
Location: USA (Remote)
Total experience : 7+yrs
Work authorization – Must have valid USA work visa
The candidate should have minimum 7 years of total experience working in a provider / Healthcare IT / consultancy setting.
The candidate must have hands-on experience implementing or supporting technology solutions in healthcare, with critical thinking and problem-solving skills.
Responsibilities:
Translate business requirements into technical requirements and solutions
Collaborate with resources to ensure all system design requirements adequately reflect the defined business processes and fully support all components of the functional business requirements
Research complex issues and collaborate with engineering teams to determine effective resolutions
Perform updates and ongoing maintenance to client workflow configurations based on client needs and requirements
Participate in identifying, designing, and implementing internal process improvements, such as automating manual processes that minimize errors and promote scalability
Experience working in different ticketing systems like JIRA, Azure DevOps etc. (Creating backlogs, creating EPIC/User stories, maintaining the board etc.)
Knowledge, Experience & Qualifications
US Healthcare Experience (Mandatory)
Pre-Post Intervention Analysis experience
Expertise in US Health Insurance Claims Processing (Mandatory)
Sound domain knowledge on healthcare practice management, electronic health records, RCM/claim processing, HL7, ICD-10, NDC Codes, HIPAA 5010 compliance and healthcare insurance payer processes
Knowledge of Payer/Provider Enrolment process
Knowledge of Provider Workflows for billing
Experience writing and reviewing business, technical, and user non-functional/system level requirements
Good communication skill for client interaction (preferred)
Good basic mathematics, reasoning, and interpretation skills (preferred)
Working knowledge of MS Excel/Access/PowerPoint for project delivery (Mandatory)
Experience in reporting and data analysis (preferred)
Must have valid US visa.
Soft skills:
Excellent communication skills (verbal as well as written)
Ability to plan activities for self as well as others, and then follow them through
Ability to communicate well with all the team members
High energy levels and a strong work ethic
Desire to learn new things and then apply the learning to make meaningful contribution towards the team / organization goals
Flexibility to adapt to changes in work and work environment
Job Type: Full-time
Pay: $111,969.57 - $134,845.06 per year
Benefits:
401(k)
Dental insurance
Health insurance
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote","$123,407 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,2006,Unknown / Non-Applicable
"CHS Inc
3.9",3.9,"Inver Grove Heights, MN",Big Data Engineer,"CHS Inc. is a leading global agribusiness owned by farmers, ranchers and cooperatives across the United States that provides grain, food and energy resources to businesses and consumers around the world. We serve agriculture customers and consumers across the United States and around the world. Most of our 10,000 employees are in the United States, but today we have employees in 19 countries. At CHS, we are creating connections to empower agriculture.
Summary
CHS has an exciting opportunity in our Information Technology division. We are seeking an experienced level Big Data Engineer to join a talented, energetic application development team, making a measurable impact with the work you do every day. You must have excellent communication skills, both verbal and written, exceptional analytical problem-solving skills and be able to work independently as well as in a team environment.
Responsibilities
Develop solutions related to Big Data, and Data Sciences from end-to-end (data ingestion to consumption).
Develop and maintain scalable data pipelines that will ingest, transform, and distribute data streams and/or batches within the AWS, Snowflake and Microsoft Platforms.
Identify, design, and implement process improvements for automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Self-motivated, self-directed with strong problem-solving skills.
Support and decommission legacy platforms.
Enable business strategy, lean processes, increased data velocity, and insights.
Embody a culture of continuous innovation and learning.
Adhere to programming/development standards and governance framework.
Collaborate with business, analytical teams, and data scientist to improve efficiency, increase the applicability of predictive models, and help translate ad-hoc analyses into scalable data delivery solutions.
Consulting on data ingestion, data modeling, security, and capabilities.
Manage the innovation cycle of conducting analyses, generating insights.
Assist with the selection and management of consultants and vendors.
Assist with the recruitment and development of talent.
Collaborate with DevOps team to integrate innovations and algorithms into a production system.
Support business decisions with ad hoc analysis as needed.
Work with the DevOps team to create and manage deployment workflows for all scripts and code using Microsoft Azure.
Minimum Qualifications (required)
Bachelor or Graduate degree in Computer Science Management Information Systems (MIS), Business Intelligence, other STEM degree program (or equivalent years of training, work experience and education)
2+ years of experience in Big Data Engineering or Business Intelligence to include:
Data Integration
Data Modeling
ETL/ELT and SQL Development
1+ years of experience to include:
Software Engineering
Software Development Lifecycle (SDLC)
Test-Driven Development
Programming Languages
Java
C++ or C#
Object Oriented Design o Scripting Languages
Python 2.7 and/or 3
1+ years of experience with Cloud Big Data Technologies to include:
CDC Tools (HRV, Qlik Replicate)
AWS Native Tools (Glue, DMS, S3, Athena), Snowflake, Cloudera CDP or Databricks
NoSQL Databases (Hive, Spark)
Additional Qualifications
Master’s Degree in Information Systems, Computer Science or related field
In-depth experience with cloud data movement techniques
Experience with Snowflake data platform
NoSQL background such as MongoDB, HBase
Experience with Search Engine tools such as Lucene and Elastic Search
Experience with IDEs such as Microsoft Visual Code, Eclipse and/or PyCharm
Experience with version control using Git
Experience with Agile Methodology using Scrum
Knowledge of Data Science using Python and R
Pre-employment screening is based on the job requirements and industry guidelines and may or may not be required for the position. If required, selected candidates must pass pre-employment screenings to include all or a combination of drug, criminal, motor vehicle check, physical requirements and FMSCA Clearinghouse.
CHS offers a competitive total compensation package. Benefits include Health, Dental, Vision, Hearing, Life Insurance, Health and Day Care Savings Accounts, Paid Vacation, 401K, Company Funded Pension, Profit Sharing, Long and Short Term Disability, Tuition reimbursement, and Adoption assistance.
CHS is an Equal Opportunity Employer.","$92,145 /yr (est.)",10000+ Employees,Company - Public,Agriculture,Farm Support,1929,$10+ billion (USD)
"Mashvisor Inc.
3.7",3.7,Remote,Data Science Engineer,"Build the solution that transforms the real estate industry!
We are looking for a Data Science Engineer superhero with a sixth sense for data who can ignite our day-to-day activities with their creativity.
Want to infuse a $30B+ sector of the insurance and real estate industry with predictive analytics and a tech-forward customer experience? Looking for a fully remote startup culture supported by a profitable business model? Join Mashvisor and help us build an entirely new type of real estate model.

Our Values

Customer Obsessed – We always put our customers first.
Solution Driven – We solve problems that other people are afraid to.
Product led: We are always one step ahead of our customer's needs and create / add features they love every time
One Team – We believe inclusion and teamwork produce the best results.
Open and Direct – We communicate with honesty and respect to our colleagues, customers, and partners.

What You’ll Do
Designing, developing, and researching Machine Learning systems, models, and schemes
Studying, transforming, and converting data science prototypes
Searching and selecting appropriate data sets
Performing statistical analysis and using results to improve models
Training and retraining ML systems and models as needed
Identifying differences in data distribution that could affect model performance in real-world situations
Visualizing data for deeper insights
Analyzing the use cases of ML algorithms and ranking them by their success probability
Understanding when your findings can be applied to business decisions
Enriching existing ML frameworks and libraries
Verifying data quality and/or ensuring it via data cleaning

What You’ll Need
BS or Masters degree in Mathematics, Statistics, Economics, Data Science or another quantitative field
3+ years of hands-on experience utilizing data science to manage, enhance and develop models and deploy solutions to solve complex business problems
Expertise in SQL and programming in SQL, R, Python, C++, Java, and beneficial to know Lisp and Prolog
Strong organizational, interpersonal, and communication skills (both written and verbal)
A bias towards solving problems from a customer-centric lens and an intuitive sense for how the work aligns closely with business objectives
Solid experience with managing databases and datasets and structuring and optimizing the framework
A thorough understanding of SQL databases
Bonus: background in US real estate data, insurance or financial markets analysis
The ideal candidate will be a creative problem solver with an excellent work history on data analytics projects.

We want the work you do here to be the best work of your life.
Compensation: We offer a great salary with a yearly bonus based on performance.
Attitude: Work with a Can-Do team across the world.
Freedom: Work anywhere, anytime.
Time Off: Yearly vacations and sick leaves.
Responsibility: Ability to excel in a fully remote work environment.
Are you the one?",#N/A,1 to 50 Employees,Company - Private,Real Estate,Real Estate,2015,$1 to $5 million (USD)
"Nisum Latam
3.9",3.9,Remote,Data Engineer (Latam),"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development.
Founded in 2000 with the customer-centric motto “Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels.
Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.
What challenges will you face as a Data Engineer?
You will be responsible for the acquisition, modeling, transformation, and delivery of the organization’s data in support of reporting and analytics while also keeping an eye out for trends or inconsistencies that will impact business goals for one of our important clients located in US.
You will be working closely with Data Analysts and Business Intelligence Developers, ensuring that the data pipeline from source to presentation layer is available and robust.
Responsibilities include but are not limited to:
Ingest data from a variety of internal and third-party sources
Connect to data sources including open API, databases
Define and implement a robust automated data pipeline using modern techniques
Model data supporting a variety of uses such as reporting, analysis, and internal and external data delivery
Ensure and improve data reliability, linage, efficiency, and quality
Develop data set processes and best practices
Identify, design and implement internal process improvements
Provide accurate project effort estimates
To be successful in this role, we expect you to have the following skills and experience:
You must reside in Latam
Advanced working SQL knowledge and experience with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
At least 5 years of relevant experience related to data acquisition, ingestion, warehousing and modeling
Advanced english communication skills
Experience with APIs, Python
Understanding of ETL/ELT tools and processes
Experience building processes supporting data transformation, data structures, metadata, dependency, and workload management
Demonstrated analytical, technical, and problem-solving skills
Detail-oriented, and organized with strong verbal and written communication skills
Skills and experience that would be nice for you to have:
AWS
Redshift data warehousing
Repositories within AWS
Snowflake type technologies that are part of AWS
What do we offer?
You will belong to an international and multicultural company that supports diversity.
Be part of international projects with a presence in North America, Pakistan, India and Latam.
Work environment with extensive experience in remote and distributed work, using agile methodologies.
Culture of constant learning and development in current technologies.
Pleasant and collaborative environment, with a focus on teamwork.
Access to learning platforms, Google Cloud certifications, Databricks, Tech Talks, etc. You will be part of various initiatives and continuous participation in internal and external activities of innovation, hackathon, technology, agility, talks, webinars, well-being and culture with the possibility not only to participate but also to be an exhibitor.
If you’re from Chile you will also have access to: Sodexo Card, Sala Cuna benefit, Agreement with the SmartFit gym, Access to Complementary Health Insurance, Mutual Security, among others!
Fully remote You can work from anywhere in the world.
Remote work policy
Fully remote
Candidates can reside anywhere in the world.",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,2000,Unknown / Non-Applicable
"Ancestry
3.5",3.5,"Lehi, UT",Staff Data Engineer,"About Ancestry:
When you join Ancestry, you join a human-centered company where every person’s story is important. Ancestry®, the global leader in family history, empowers journeys of personal discovery to enrich lives. With our unparalleled collection of more than 40 billion records, over 3 million subscribers and over 23 million people in our growing DNA network, customers can discover their family story and gain a new level of understanding about their lives. Over the past 40 years, we’ve built trusted relationships with millions of people who have chosen us as the platform for discovering, preserving and sharing the most important information about themselves and their families.

We are committed to our location flexible work approach, allowing you to choose to work in the nearest office, from your home, or a hybrid of both (subject to location restrictions and roles that are required to be in the office- see the full list of eligible US locations HERE). We will continue to hire and promote beyond the boundaries of our office locations, to enable broadened possibilities for employee diversity.

Together, we work every day to foster a work environment that's inclusive as well as diverse, and where our people can be themselves. Every idea and perspective is valued so that our products and services reflect the global and diverse clients we serve.

Ancestry encourages applications from minorities, women, the disabled, protected veterans and all other qualified applicants. Passionate about dedicating your work to enriching people’s lives? Join the curious.
We are seeking a Staff Data Engineer to join our Enterprise Data Management (EDM) organization. The EDM team is the hub of data within Ancestry, ingesting data across the organization to process, transform, and deliver to our internal and external stakeholders.
What you will do…
Develop extract-transform-load (ETL) pipelines
Practice good coding techniques including writing unit and integration tests, doing commits and pull requests (Git), etc.
Mentor, train, and collaborate with other engineers to develop scalable, resilient, and maintainable ETL pipelines
Participate in an on-call rotation to ensure pipelines are successful and data meets quality requirements
Provide technical leadership to team and across the EDM organization
Ensure ETL pipelines meet quality standards and data quality requirements
Work with internal and external stakeholders to identify and define data requirements, design solutions, and ensure timely delivery
Manage individual data projects, ensuring appropriate designs and stakeholder involvement
Who you are…
10+ years of experience as a data engineer, with specific experience in developing ETL pipelines
10+ years of industry experience programming in Python and SQL (or related languages) with significant experience in data warehouses, Spark, and other related technologies (experience with Airflow a plus)
Experience training and mentoring other engineers, leading teams, and coordinating with stakeholders
Excellent written and verbal communication skills
Familiarity with agile software development
Familiarity with AWS technologies (specifically, EMR)
Bachelors or 4-year degree in Computer Science or equivalent industry experience
Helping people discover their story is at the heart of ours. Ancestry is the largest provider of family history and personal DNA testing, harnessing a powerful combination of information, science and technology to help people discover their family history and stories that were never possible before. Ancestry’s suite of products includes: AncestryDNA, AncestryProGenealogists, Fold3, Newspapers.com, Find a Grave, Archives.com, and Rootsweb. We offer excellent benefits and a competitive compensation package. For additional information, regarding our benefits and career information, please visit our website at http://ancestry.com/careers
As a signatory of the ParityPledge in Support of Women and the ParityPledge in Support of People of Color, Ancestry values pay transparency and pay equity. We are pleased to share the base salary range for this position: $133,200 - $200,550 with eligibility for bonus, equity and comprehensive benefits including health, dental and vision. The actual salary will vary by geographic region and job experience. We will share detailed compensation data for a specific location during the recruiting process. Read more about our benefits HERE.

Note: Disclosure as required by sb19-085(8-5-20) and sb1162(1-1-23)
#GDSponsored
#IND2
#LI-MK1

Additional Information:
Ancestry is an Equal Opportunity Employer that makes employment decisions without regard to race, color, religious creed, national origin, ancestry, sex, pregnancy, sexual orientation, gender, gender identity, gender expression, age, mental or physical disability, medical condition, military or veteran status, citizenship, marital status, genetic information, or any other characteristic protected by applicable law. In addition, Ancestry will provide reasonable accommodations for qualified individuals with disabilities.
All job offers are contingent on a background check screen that complies with applicable law. For San Francisco office candidates, pursuant to the San Francisco Fair Chance Ordinance, Ancestry will consider for employment qualified applicants with arrest and conviction records.
Ancestry is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Ancestry via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Ancestry. No fee will be paid in the event the candidate is hired by Ancestry as a result of the referral or through other means.","$166,875 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,1983,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Sr Machine Learning Data Infrastructure Engineer, Data & Machine Learning Innovation","Summary
Posted: Aug 3, 2023
Weekly Hours: 40
Role Number:200493624
As part of Apple's AI and Machine Learning org, we encourage and create groundbreaking technology for large-scale ML systems, computer vision, natural language processing, and multi-modal understanding. The Data and Machine Learning Innovation (DMLI) team is looking for a passionate Machine Learning Engineer to explore new methods, challenge existing metrics or protocols, and develop new insightful practices that will change how we understand data and overcome real-world ML challenges. Are you excited to work on some of the most ambitious technical challenges in the field? Your role will involve collaborating closely with machine learning researchers, engineers, and data scientists. Together, we will spearhead groundbreaking research initiatives and develop transformative products designed to build a significant impact for billions of users worldwide.
Key Qualifications
Demonstrated expertise in machine learning with a passion for data-centric machine learning.
Experience with natural language processing (NLP), and large language models, such as BERT, GPT, or Transformers.
Staying on top of emerging trends in LLMs.
Strong programming skills and hands-on experience using the following languages or deep learning frameworks: Python, PyTorch, or Jax.
Strong problem-solving and communication skills.
5+ years of experience with developing and evaluating ML applications, and demonstrated experience in understanding and improving data quality.
3+ years of experience with managing engineering teams, including defining plans, coaching technical leaders and engineers, and collaborating with other teams.
Demonstrated publication record in relevant conferences (e.g. ACL, EMNLP, NeurIPS, ICML, ICLR, , etc) is a plus.
Description
As a Machine Learning (ML) Engineer, you will be entrusted with the critical role of innovating and applying innovative research in ML to tackle complex data problems. The solutions you develop will significantly impact future Apple products and the broader ML development ecosystem. You will work with a multidisciplinary team to actively participate in the data-model co-design and co-development practice. Your responsibilities will extend to the design and development of a comprehensive data curation framework. You will also build robust model evaluation pipelines, integral to the continuous improvement and assessment of ML models. Additionally, your role will entail an in-depth analysis of collected data to underscore its influence on model performance. Furthermore, you will have the opportunity to showcase your groundbreaking research work by publishing and presenting at premier academic venues. Your work may span a variety of topics, including but not limited to: Designing and implementing semi-supervised, self-supervised representation learning techniques for growing the power of both limited labeled data and large-scale unlabeled data. Developing evaluation protocols centered on the end-to-end user experience, with a focus on anticipating potential failure modes, edge cases, and anomalies. Employing data selection techniques such as novelty detection, active learning, and core-set selection for diverse data types like images, 3D models, natural language, and audio. Uncovering patterns in data, setting performance targets, and using modern statistical and ML-based methods to model data distributions. This will aid in reducing redundancy and addressing out-of-distribution samples.
Education & Experience
Ph.D/MS degree in Machine Learning, Natural Language Processing, Computer Vision, Data Science, Statistics or related areas.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $199,800 and $364,100, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"ZoomInfo Technologies LLC
3.8",3.8,"Bethesda, MD",Senior Data Engineer,"At ZoomInfo, we encourage creativity, value innovation, demand teamwork, expect accountability and cherish results. We value your take charge, take initiative, get stuff done attitude and will help you unlock your growth potential. One great choice can change everything. Thrive with us at ZoomInfo.
At ZoomInfo we encourage creativity, value innovation, demand teamwork, expect accountability and cherish results. If you are a take charge, take initiative, get stuff done individual we want to talk to you! We have high aspirations for the company and are looking for the right people to help fulfill the dream. We strive to continually improve every aspect of the company and use cutting edge technologies and processes to delight our customers and rapidly increase revenues.
As a Senior Data Engineer, you'll have a key role in building and designing the strategy of our finance analytics engineering team under the Enterprise Data Engineering group.
Our Technological Stack includes: Airflow, DBT, Python, Snowflake, AWS, GCP, Amplitude, Fivetran, and more.

What will you actually be doing?
Building, and continuously improving our data gathering, modeling, reporting capabilities and self-service data platforms.
Working closely with Data Engineers, Data Analysts, Data Scientists, Product Owners, and Domain Experts to identify data needs.
Required Experience:
Relevant Bachelor degree – preferably CS, Engineering/ Information Systems or other equivalent Software Engineering background.
8+ years of experience as a Data/BI engineer.
Strong SQL abilities and hands-on experience with SQL and no-SQL DBs, performing analysis and performance optimizations.
Hands-on experience in Python or equivalent programming language
Experience with data warehouse solutions (like BigQuery/ Redshift/ Snowflake)
Experience with data modeling, data catalog concepts, data formats, data pipelines/ETL design, implementation and maintenance.
Experience with AWS/GCP cloud services such as GCS/S3, Lambda/Cloud Function, EMR/Dataproc, Glue/Dataflow, Athena.
Experience with Airflow and DBT - Advantage.
Experience with data visualization tools and infrastructures (like Tableau/SiSense/Looker/other) - Advantage.
Experience with development practices – Agile, CI/CD, TDD - Advantage.
Experience with Infrastructure as Code practices - Terraform - Advantage
About us:
For over a decade, ZoomInfo has helped companies achieve their most important objective: profitable growth. Backed by the world's most comprehensive B2B database, our platform puts sales and marketing professionals in position to identify, connect, and engage with qualified prospects.
Our mission is to provide every company with a 360-degree view of their ideal customer, empowering each phase of their go-to-market strategy and driving their ability to hit their number.

The US base salary range for this position is $133,600.00 to $183,700.00 variable compensation + benefits.
Actual compensation offered will be based on factors such as the candidate's work location, qualifications, skills, experience and/or training. Your recruiter can share more information about the specific salary range for your desired work location during the hiring process.
We want our employees and their families to thrive. In addition to comprehensive benefits we offer holistic mind, body and lifestyle programs designed for overall well-being. Learn more about ZoomInfo benefits here.

About us:
ZoomInfo (NASDAQ: ZI) is the trusted go-to-market platform for businesses to find, acquire, and grow their customers. It delivers accurate, real-time data, insights, and technology to more than 35,000 companies worldwide. Businesses use ZoomInfo to increase efficiency, consolidate technology stacks, and align their sales and marketing teams — all in one platform.
ZoomInfo may use a software-based assessment as part of the recruitment process. More information about this tool, including the results of the most recent bias audit, is available here.
ZoomInfo is proud to be an Equal Opportunity employer. We are committed to equal employment opportunities for applicants and employees regardless of sex, race, age, color, national origin, sexual orientation, gender identity, marital status, disability status, religion, protected military or veteran status, medical condition, or any other characteristic or status protected by applicable law. At ZoomInfo, we also consider qualified candidates with criminal histories, consistent with legal requirements.","$158,650 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Software Development,2007,$1 to $5 billion (USD)
"Medical Mutual of Ohio
3.9",3.9,"Brooklyn, OH",Data Engineer I-V,"Data Engineer I-V
- (2300469)

Founded in 1934, Medical Mutual is the oldest and one of the largest health insurance companies based in Ohio. We provide peace of mind to more than 1.6 million Ohioans through our high-quality health, life, disability, dental, vision and indemnity plans. We offer fully insured and self-funded group coverage, including stop loss, as well as Medicare Advantage, Medicare Supplement, and individual plans.
Medical Mutual’ s status as a mutual company means we are owned by our policyholders, not stockholders, so we don’t answer to Wall Street analysts or pay dividends to investors. Instead, we focus on developing products and services that allow us to better serve our customers and the communities around us and help our members achieve their best possible health and quality of life.
Data Engineer I
Software developer for the design and development of the company’s data lake, data warehouse, and data marts, and development of related business intelligence dashboards and visualizations. Job duties involve profiling data, developing data transformation jobs and processes, measuring data quality, and designing data warehouse data models, evaluating usability and testing data models, and developing business intelligence visualizations.
Data Engineer II
Software developer for the design and development of the company’s data lake, data warehouse, and data marts, and support for applied use of data for business insights. Job duties involve profiling data, developing data transformation jobs and processes, measuring data quality, and designing data warehouse data models, evaluating usability and testing data models, and developing processes for applied use of enterprise data (data analysis, business intelligence, reporting).
Data Engineer III
Data engineer responsible for the design and development of data integration pipelines. Build data solutions for business problems and support the applied use of data to enable business insights and action. Job duties involve profiling data, developing data transformation pipelines, measuring data quality, designing data models, and supporting applied use of data to solve problems (exploratory analysis, business intelligence/dashboards, reporting, alerts).
Data Engineer IV
Data engineer responsible for the design and development of data integration pipelines. Build data solutions for business problems and support the applied use of data to enable business insights and action. Job duties involve profiling data, developing data transformation pipelines, measuring data quality, designing data models, and supporting applied use of data to solve problems (exploratory analysis, business intelligence/dashboards, reporting, alerts).
Data Engineer V
Data engineer responsible for the design and development of data integration pipelines. Build data solutions for business problems and support the applied use of data to enable business insights and action. Job duties involve profiling data, developing data transformation pipelines, measuring data quality, designing data models, and supporting applied use of data to solve problems (exploratory analysis, business intelligence/dashboards, reporting, alerts).
Responsibilities
Data Engineer I
Develop data pipelines to integrate and transform data for analysis
Support other data users and enable applied use of data to solve business problems
Business meetings to understand data and business needs, socialize knowledge of data products and insights, and generate consensus
Data profiling, data documentation, measuring and enforcing data quality
Developing data models to represent information
Performs other duties as assigned.
Learns new technical concepts and software languages as needed.
Data Engineer II
Developing and sequencing jobs and processes to transform data into data lake and data warehouse
Support analytic projects, data extracts, and other work to apply data in the warehouse, test and prove capabilities, evaluate usability, and perform demonstrations to other analysts for how to use data to meet objectives
Business meetings to understand data, capture agreement on business rules, understand analyst and stakeholder objectives, and support usage of data to solve business problems
Data profiling, data documentation, and measuring data quality with manual verification and
development of automated data quality tests
Developing data models to represent data
Data Engineer III
Develop data pipelines to integrate and transform data for analysis
Support other data users and enable applied use of data to solve business problems
Business meetings to understand data and business needs, socialize knowledge of data products and insights, and generate consensus
Data profiling, data documentation, measuring and enforcing data quality
Developing data models to represent information
Performs other duties as assigned.
Learns new technical concepts and software languages as needed
Data Engineer IV
Develop data pipelines to integrate and transform data for analysis
Support other data users and enable applied use of data to solve business problems
Business meetings to understand data and business needs, socialize knowledge of data products and insights, and generate consensus
Data profiling, data documentation, measuring and enforcing data quality
Developing data models to represent information
Performs other duties as assigned.
Learns new technical concepts and software languages as needed.
Data Engineer V
Develop data pipelines to integrate and transform data for analysis
Support other data users and enable applied use of data to solve business problems
Business meetings to understand data and business needs, socialize knowledge of data products and insights, and generate consensus
Data profiling, data documentation, measuring and enforcing data quality
Developing data models to represent information
Performs other duties as assigned.
Learns new technical concepts and software languages as needed.

Qualifications
Data Engineer I
Education and Experience:
Bachelors degree in Computer Science, Computer Information Systems, business degree with focus on data transformation or analysis, or equivalent work experience
Technical Skills and Knowledge:
Basic understanding of programming design and coding techniques
Familiarity with systems development life cycle
Understanding of database technologies and query semantics
Experience with public cloud database technology (e.g. RedShift, SnowFlake, DataBricks, Azure Synapse, BigQuery)
Experience programming in ETL or ELT technology
Understanding of data warehouse data model theory and techniques
Experience with Python programming language
Data Engineer II
Education and Experience:
Bachelors degree in Computer Science, Computer Information Systems, business degree with focus on data transformation or analysis, or equivalent work experience
Technical Skills and Knowledge:
Two or more years professional experience developing software to solve business problems
Experience with data engineering system design and software implementation
Experience with all parts of the systems development life cycle
Experience with database technologies and query semantics
Experience with public cloud database technology (e.g. RedShift, SnowFlake, DataBricks, Azure Synapse, BigQuery)
Experience programming in ETL or ELT technology
Understanding of data warehouse data model theory and techniques
Experience with Python programming language
Data Engineer III
Education and Experience:
Bachelors degree in Computer Science, Computer Information Systems, business degree with focus on data transformation or analysis, or equivalent work experience
Technical Skills and Knowledge:
Four or more years professional experience developing software to solve business problems
Three or more years experience with data engineering system design and software implementation
Experience with all parts of the systems development life cycle
Experience with database technologies and query semantics
Experience with public cloud database technology (e.g. RedShift, SnowFlake, DataBricks, Azure Synapse, BigQuery)
Experience programming in ETL or ELT technology
Understanding of data warehouse data model theory and techniques
Experience with Python programming language
Data Engineer IV
Education and Experience:
Bachelors degree in Computer Science, Computer Information Systems, business degree with focus on data transformation or analysis, or equivalent work experience
Technical Skills and Knowledge:
Seven or more years professional experience developing software to solve business problems
Five or more years experience with data engineering system design and software implementation
Proficient with all parts of the systems development life cycle
Experience with database technologies and query semantics
Experience leading and coordinating technical initiatives
Experience with public cloud database technology (e.g. RedShift, SnowFlake, DataBricks, Azure Synapse, BigQuery)
Experience programming in ETL or ELT technology
Understanding of data warehouse data model theory and techniques
Experience with Python programming language
Data Engineer V
Education and Experience:
Bachelors degree in Computer Science, Computer Information Systems, business degree with focus on data transformation or analysis, or equivalent work experience
Technical Skills and Knowledge:
Seven or more years professional experience developing software to solve business problems
Five or more years experience and demonstrated excellence with data engineering system design and software implementation
Demonstrated excellence with all parts of the systems development life cycle
Expert in database technologies and query semantics
Demonstrated excellence leading and coordinating technical initiatives
Experience with public cloud database technology (e.g. RedShift, SnowFlake, DataBricks, Azure Synapse, BigQuery)
Experience programming in ETL or ELT technology
Expert understanding of data warehouse data model theory and techniques
Experience with Python programming language
Medical Mutual is looking to grow our team! We truly value and respect the talents and abilities of all of our employees. That's why we offer an exceptional package that includes:
A Great Place to Work:
Top Workplace in Northeast Ohio. Year after year we've received this recognition!
On-site wellness center at most locations. Enjoy personal trainers, towel service, locker room, weight room, elliptical machines, and a variety of classes!
On-site cafeteria serving hot breakfast and lunch, at most locations. Choices ranging from salad bar, made to order, hot and cold sandwiches, or a variety of entrees cooked fresh daily. Convenience store at most locations
Employee discount program. Discounts at many places in and around town, just for being a Medical Mutual team member
Business Casual attire
Excellent Benefits and Compensation:
Competitive compensation plans
Employee bonus program
401(k) with company match and an additional company contribution
Excellent medical, dental, vision, and disability insurance
An Investment in You:
Career development programs and classes
Mentoring and coaching to help you advance
Education reimbursement up to $5K per year
About Medical Mutual:
We strive to create peace of mind. Our customers can trust us to do things right and to help them get value from their health plan. We're the largest health insurer in Ohio and for over 85 years, we've been serving our members and the Ohio communities where they live and work. Medical Mutual is a Top Place to Work in Northeast Ohio with exceptional career opportunities that offer challenge, growth and a great work/life balance. We want talented, innovative, and driven people to help us continue to be the best health insurance choice of Ohioans and help make Ohio the best it can be! Our headquarter building is located in the heart of downtown Cleveland and we have multiple offices throughout the state. Join us at one near you!

At Medical Mutual and its family of companies we celebrate differences and are mutually invested in our employees and our community. We are proud to be an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment regardless of race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, veteran status, or disability status.
We maintain a drug-free workplace and perform pre-employment substance abuse and nicotine testing.
Primary Location US-OH-Brooklyn
Work Locations Brooklyn 100 American Road Brooklyn 44144
Job 7 - General Staff
Organization IT Infrastructure
Schedule Regular
Shift Standard
Employee Status Individual Contributor
Job Type Full-time
Job Level Day Job
Travel No
Job Posting Aug 31, 2023, 11:20:56 AM","$90,305 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Insurance,Insurance Carriers,1934,Unknown / Non-Applicable
"Hawaii Foodservice Alliance
5.0",5.0,"Honolulu, HI",Data Engineer (Oahu),"We are looking for a Data Engineer passionate about data to join our growing team. You will be directly responsible in shaping our data infrastructure. You should be committed to harnessing the power of data to drive innovation and make informed business decisions and be dedicated growing your skills. The Engineer will have an opportunity to be a key player in shaping our data infrastructure and contribute to data-driven decision making.
Do you have a passion for guiding people to be a better version of themselves and fostering a culture of continuous learning and professional development? The primary responsibilities include collaborating, developing and implementing a variety of training programs at department and enterprise levels within HFA. The ideal candidate will bring their applied knowledge of learning technologies and talent management to support the ongoing growth and development of our diverse team of over 500+ team members.
We offer individual, small group, and enterprise-wide programs that reach our employees' minds and hearts. HFA understands what it means to be a first-generation leader. For this reason, we hire for talent, character and potential. We stand behind and invest in our people and this is a key position to foster this culture.
Hawaii Foodservice Alliance is a locally owned food distributor in business for 20 years specializing in highly perishable foods sourced locally and from the West Coast United States. We provide staples (e.g., baked goods, fresh milk & eggs) and a variety of quality products to our customers (leading clubs, grocers, retailers) throughout Hawaii.
We invite you to visit us at: https://www.hfahawaii.com
WHAT YOU’LL DO
Use tools such as SQL, Python, Tableau, etc. to design, develop, and maintain end-to-end data pipelines to support the collection, processing, and analysis of large datasets.
Partner and collaborate with various parts of the organization to build a working knowledge of the organization, business, processes, and its customers.
Leverage data mining tools and techniques to analyze large amounts of data identifying relationships and patterns within the data.
Integrate data from diverse sources, both batch and real-time, ensuring smooth data flow and consistency.
Build and optimize data storage solutions, including data warehouses and data lakes.
Perform data transformations, data cleansing, and enrichment to ensure data accuracy and usability.
Implement data quality checks and validation mechanisms to uphold data integrity.
Monitor and troubleshoot data pipelines and infrastructure, addressing issues promptly to ensure uninterrupted data availability.
Ensure data security and compliance with relevant data privacy regulations.
Document data engineering processes, pipelines, and best practices for knowledge sharing and future reference.
Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives.
WHAT WE’LL LOVE ABOUT YOU
Bachelor’s or master’s degree in Computer Science, Information Technology, Data Analytics, Applied Mathematics, related field, or equivalent work experience.
Experience in data engineering, with expertise in Python and SQL.
Strong knowledge of data storage technologies, including relational databases and distributed storage solutions.
Proficiency in cloud platforms such as Microsoft Azure or AWS.
Solid understanding of data modeling concepts and practices.
Excellent problem-solving skills and ability to optimize data pipelines for performance and scalability.
Must be able to work independently end-to-end on projects.
Food distribution or similar industry experience a plus.
Currently reside on Oahu.
WHAT YOU'LL LOVE ABOUT US
Competitive Pay
Free Healthcare (for Team Members & partial subsidy for family members)
401(k) Plan with % matching
Paid Weekly
Paid Time Off
Paid Volunteer Time
Financial Education Programs
On the Job Training
Employee Assistance Program
Employee Discounts (e.g., Gym membership, Cellular service, Legal Assistance plan)
We kindly request all applicants to submit a tailored cover letter outlining their relevant experience, skills, and interest in the position.
HFA is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age citizenship, marital status, disability, gender identity or Veteran status.
Job Type: Full-time
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Life insurance
Paid time off
Referral program
Retirement plan
Vision insurance
Ability to commute/relocate:
Honolulu, HI 96819: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
What is your desired salary?
Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)
Work Location: Hybrid remote in Honolulu, HI 96819","$80,014 /yr (est.)",Unknown,Company - Private,Retail & Wholesale,Vehicle Dealers,#N/A,$25 to $100 million (USD)
"JLL
3.9",3.9,"Lewisville, TX",Data Center Operations Engineer,"JLL supports the Whole You, personally and professionally.

Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you’ve got deep experience in commercial real estate, skilled trades, and technology, or you’re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally.

The Data Center Operations Engineer is responsible for delivery of best practice systems and problem resolution on all data center electrical and mechanical infrastructure (UPS, MV electrical systems, generators, cooling systems etc.)

Location: Allen Texas

Principal Duties and Responsibilities

Task will include but not be limited to:
Responsible for maintaining, monitoring, and performing preventive maintenance and continuous operation of all building systems to maintain 100% Up-time including: fire/life safety, mechanical systems such as (HVAC, chillers, crac, crah, plumbing, controls), electrical including emergency backup systems such as (lighting, UPS, ATS, STS, PDU, generators, primary switchgear, power distribution, transformers), and hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and water heaters; pumps, valves, piping, and filters; other mechanical and electrical equipment. Must record readings and make and adjust where necessary to ensure proper operation of equipment.
Requires the ability to analyze the operation of various systems, determine the cause of any problems/malfunctions and take corrective action as required.
Comply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintains a clean and safe workplace.
Learn and understand the data center site in-order to manage incidents and events that put the critical systems at risk.
Work order management, including CMMS, Vendor Management, and Customer Facing Tickets.
Understanding and complying with emergency escalation procedures.
Perform additional job duties as required.

Minimum Requirements:
Preferred to have hands-on experience working in a data center/critical facility, including UPS.
Systems, emergency generators, and switchgears.
High School diploma or GED equivalent
2+ years related work experience.
Working knowledge of computer applications including Word and Excel.
Demonstrated verbal/written communication skills.

Preferred Requirements:
Corrigo Experience.
MCIM / Salesforce Experience.
Zendesk Experience.
Service Now Experience.
Received EPA 608.
Trained in NFPA70E.

PHYSICAL WORK ABILITIES AND REQUIREMENTS:
This position requires frequent walking, climbing, bending, kneeling, lifting, stooping, and working/extending overhead, including:
Walking large, campus-like settings.
Lifting a minimum of 50 lbs.
Climbing stairs and navigating rooftops to access equipment.
Using ladders up to 30 ft. and working from heights.
Ability to Climb a ladder with a 300-lb weight limit.
Must be able to work different schedules.
Must be able to work Holidays.
Must be able to respond to site emergencies.

Personalized benefits that support personal well-being and growth:
JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health. Some of these benefits, include:
401(k) plan with matching company contributions
Comprehensive Medical, Dental & Vision Care
FMLA at 100% of salary after 1 year of employment.
Paid Time Off and Company Holidays.
Compensated for Holidays Worked.
15% Pay differential for Night Shift Employment.

If this job description resonates with you, we encourage you to apply, even if you don’t meet all the requirements. We’re interested in getting to know you and what you bring to the table!

Proposed compensation is $35-$38 per hour depending on experience.
If this job description resonates with you, we encourage you to apply even if you don’t meet all of the requirements below. We’re interested in getting to know you and what you bring to the table!

Personalized benefits that support personal well-being and growth:

JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health.

About JLL –

We’re JLL—a leading professional services and investment management firm specializing in real estate. We have operations in over 80 countries and a workforce of over 102,000 individuals around the world who help real estate owners, occupiers and investors achieve their business ambitions. As a global Fortune 500 company, we also have an inherent responsibility to drive sustainability and corporate social responsibility. That’s why we’re committed to our purpose to shape the future of real estate for a better world. We’re using the most advanced technology to create rewarding opportunities, amazing spaces and sustainable real estate solutions for our clients, our people, and our communities.

Our core values of teamwork, ethics and excellence are also fundamental to everything we do and we’re honored to be recognized with awards for our success by organizations both globally and locally.

Creating a diverse and inclusive culture where we all feel welcomed, valued and empowered to achieve our full potential is important to who we are today and where we’re headed in the future. And we know that unique backgrounds, experiences and perspectives help us think bigger, spark innovation and succeed together.",$36.50 /hr (est.),10000+ Employees,Company - Public,Real Estate,Real Estate,#N/A,$5 to $10 billion (USD)
Coupang Internal,#N/A,"Seattle, WA",Staff Data Infrastructure Engineer,"We exist to wow our customers. We know we're doing the right thing when we hear our customers say, ""How did we ever live without Coupang?"" Born out of an obsession to make shopping, eating, and living more effortless than ever, we are collectively disrupting the multi-billion-dollar e-commerce industry from the ground up. We're one of the fastest-growing e-commerce companies with an unparalleled reputation for being a dominant and reliable force in South Korean commerce.
We are proud to have the best of both worlds — a startup culture with the resources of a significant global public company. This fuels us to continue our growth and launch new services at the speed we have been at since our inception. We are all entrepreneurs surrounded by opportunities to drive new initiatives and innovations. At our core, we are bold and ambitious people that like to get our hands dirty and make a hands-on impact. At Coupang, you will see yourself, your colleagues, your team, and the company grow every day.
Our mission to build the future of commerce is real. We push the boundaries of what's possible to solve problems and break traditional tradeoffs. Join Coupang to create an epic experience in this always-on, high-tech, hyper-connected world.
Role Overview
The Data Infrastructure team in the Data Platform organization serves Hadoop clusters, DW, and Orchestration platforms across the entire business domain. The infrastructure managed by the Data Infrastructure team provides various data processing related to Coupang services, including log analysis, recommendation, price comparison, AB testing, search indexing, advertising, and rocket delivery. We are confident that we are playing a pivotal role in experiencing the best e-commerce for Coupang's customers.
The Data Infrastructure team simultaneously serves hundreds of Hadoop clusters in cloud environments and has the infrastructure and know-how to reliably scale to thousands of nodes. To this end, open sources such as Hadoop, Spark, Hive, Presto, Airflow, Oozie, Docker, Kubernetes, Ansible, Terraform, Packer, and Java and Python are used as development languages.
Our vision is to provide modern self-service tools to enhance engineering productivity, making it easy for anyone to utilize our data, and build a platform that is consistently scalable and reliable. We are looking for a software engineer who will create the most robust platform services at a global level beyond Korea!
Responsibilities:
With a solid understanding of big data technology and skilled development capabilities, the Staff Data Infra Engineer will be responsible for performing the following tasks:
Provide a roadmap and vision for scalable and robust growth for your data infrastructure team
Collaborate with stakeholders and lead engineers on key mission-critical projects
Leading the design and deployment of big data infrastructure architectures
Hadoop/Data Warehouse infrastructure Maintanence
Establish Data Warehouse governance and improve cluster operation efficiency
Self-service development to improve cluster operational efficiency and user experience
As a Backend Engineer, participate in business/technical improvement projects from a data platform perspective
Modern data engineering technology research and product development
Requirements:
Bachelor's degree or/and master's degree in computer science and equivalent majors
Proficient in at least one or more Java, Scala, Python
More than 10 years of experience in designing, developing, and maintaining large software infrastructures
Have expertise in distributed systems such as Hadoop and Spark
More than 3 years of experience in developing and operating enterprise DW platform (RedShift, Netezza, Greenplum, Exadata, Teradata)
Great communication skills and someone who likes to share your experiences and learnings with your colleagues
People who try to automate without maintaining manual or repetitive tasks
Preferred:
Experience in designing and developing data pipelines in cloud environments such as AWS and GCP
Experience in leading projects and initiatives with complex scope
High competency in SQL writing and OLTP / Batch SQL Tuning
Strong experiences with RedShift
Experience with Snowflake and Databricks
Pay & Benefits
Our compensation reflects the cost of labor across several US geographic markets. At Coupang, your base pay is one part of your total compensation.
The base pay for this position ranges from $151,090/year in our lowest geographic market to $300,105/year in our highest geographic market. Pay is based on several factors, including market location, and may vary depending on job-related knowledge, skills, and experience.
General Description of All Benefits
Medical/Dental/Vision/Life, AD&D insurance
Flexible Spending Accounts (FSA) & Health Savings Accounts (HSA)
Long-term/Short-term Disability
Employee Assistance Program (EAP) program
401K Plan with Company Match
18-21 days of Paid Time Off (PTO) a year based on tenure
12 Public Holidays
Paid Parental leave
Pre-tax commuter benefits
MTV - [Free] Electric Car Charging Station
General Description of Other Compensation
""Other Compensation"" includes, but is not limited to, bonuses, equity, or other forms of compensation offered to the hired applicant in addition to their established salary range or wage scale.

Coupang is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race (including traits historically associated with race, including but not limited to hair texture and protective hair styles), color, religion, religious creed (including religious dress and grooming practices), sex or gender (including pregnancy, childbirth, breastfeeding, and medical conditions related to pregnancy, childbirth or breastfeeding), gender identity, gender expression, sexual orientation, ,ancestry, national origin (including language use restrictions), age (40 and over), physical or mental disability, medical condition, genetic information, HIV/AIDS or Hepatitis C status, family status (including but not limited to marital or domestic partnership status), military or veteran status, use of a trained dog guide or service animal, political activities or affiliations, ancestry, citizenship, family and medical leave status, status as a victim of any violent crime, or any other characteristic or class protected by the laws or regulations in the locations where we operate. Coupang is also committed to providing a safe work environment for its employees and its consumers. As a condition of employment, Coupang requires employees to be fully vaccinated against Covid-19, subject to legally required accommodations. If you need assistance and/or a reasonable accommodation in the application of recruiting process due to a disability, please contact us at usrecruiting@coupang.com

Equal Opportunities for All
Coupang is an equal opportunity employer. Our unprecedented success could not be possible without the valuable inputs of our globally diverse team.","$151,090 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"JPMorgan Chase & Co
4.0",4.0,"Plano, TX",Lead Software Engineer - Data Platform Engineering,"JOB DESCRIPTION

We have an opportunity to impact your career and provide an adventure where you can push the limits of what's possible.
As a Lead Software Engineer at JPMorgan Chase within the GTI - IAM domain, you are an integral part of an agile team that works to enhance, build, and deliver trusted market-leading technology products in a secure, stable, and scalable way. As a core technical contributor, you are responsible for conducting critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job responsibilities:
Executes creative software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Develops secure high-quality production code, and reviews and debugs code written by others
Identifies opportunities to eliminate or automate remediation of recurring issues to improve overall operational stability of software applications and systems
Leads evaluation sessions with external vendors, startups, and internal teams to drive outcomes-oriented probing of architectural designs, technical credentials, and applicability for use within existing systems and information architecture
Leads communities of practice across Software Engineering to drive awareness and use of new and leading-edge technologies
Adds to team culture of diversity, equity, inclusion, and respect
Required qualifications, capabilities, and skills :
Bachelors Degree in Computer Science (preferably), Software or Computer Engineering, and 5+ years of applied experience
Hands-on practical experience delivering system design, application development, testing, and operational stability
Advanced in Java and similar programming languages
Proficiency in automation and continuous delivery methods
Proficient in all aspects of the Software Development Life Cycle
Advanced understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Passionate about full-stack development and learning new concepts of software engineering
Knowledge of systems analysis and designing platform capabilities, data formats and data flows
Knowledge of purpose built databases and polyglot storage and operating systems
Knowledge of Micro services architecture and Restful API development
Practical cloud native experience
Preferred qualifications, capabilities, and skills :
In-depth knowledge of the financial services industry and their IT systems
AWS Cloud experience is plus
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.","$124,105 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Booz Allen Hamilton
4.2",4.2,"Washington, DC","Health Data Management Engineer, Lead","Job Description
Location:
Washington,DC,US
Remote Work:
Yes
Job Number:
R0179111

Health Data Management Engineer, Lead
Key Role:
Support the Department of Veterans Affairs (VA) Office as a Senior Health Data Migration Engineer. Assess the current VA's data migration requirements, and maintain and update the strategy to meet the requirements. Review error and trace logs. Track messages by domain and reconcile table counts with Cerner. Review secure data message transmission logs. Track the number of records sent per message by domain. Monitor queue depth by service, process, and operation. Track retry attempts and suspended messages. Validate and update data integration reports in support of VX130 data domains. Review, update, and maintain Cerner to CDW, VistA, Millennium or Cloud database data mappings for potential data migrations. Evaluate and integrate data from multiple sources, which requires data mapping from one data source to another minimizing any data loss. Document VistA extraction and monitoring process and update existing documentation quarterly. Interpret Cerner’s data model to be used for the construction of APIs, queries, and reports that will be consumed by internal or external applications. Review domain adds to Ensemble production. Validate Ensemble data flows built using VX130 ClassBuilder.
Basic Qualifications:
15+ years of experience with InterSystems IRIS in a healthcare environment
Experience with VA and DoD legacy health data or private sector health data
Experience with extraction, transformation, and loading of data between system
Experience introducing new hardware or software into a new or existing environment while minimizing disruption and mitigating risks
Experience with Cache
Experience with VistA, IRIS, or Ensemble
Ability to coordinate with development and user teams to assess risks, goals, and needs and ensure that all are adequately addressed
Bachelor's degree in CS, Engineering, Math, Information Systems, Data Science, Data Analytics, or Statistics or 23+ years of experience working in a professional environment in lieu of a degree
Additional Qualifications:
Experience in the VA
Experience with implementing EHRs
Experience with scalability analysis and modeling
Experience with end-to-end system performance assessment and optimization
Compensation
At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $93,300.00 to $212,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
Work Model
Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.
EEO Commitment
We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.
#LI-AH1, #LI-Remote, DH1, ID13-C","$152,650 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1914,$5 to $10 billion (USD)
"The CORE Institute | HOPCo
3.1",3.1,"Phoenix, AZ",Senior Engineer Data Management- Remote,"ESSENTIAL FUNCTIONS
Develop and execute on a support model for current AWS and Snowflake Data Warehouse solutions.
Interface with business stakeholders regarding data warehouse, Snowflake, and dependent application performance and capacity issues.
Interface with business stakeholders regarding additional data warehousing and analytics capabilities and features needed.
Inventory, map, and understand all data sources within HOPCo Digital and related entities.
Document and maintain data standards related to data storage and retention, processing and normalization, ingestion formats, utilization.
Design and manage programs to ensure appropriate monitoring of data quality, including audit methodology and frequency.
Monitor utilization and billing of AWS and Snowflake, driving efforts to effectively manage spending.
Develop roadmap for data and analytics maturity, including the move to more robust uses of Machine Learning.
Remain aware of best practices within the industry on utilization of data to drive healthcare outcomes.
Partner with HOPCo leaders and analytical teams to make recommendations on approaches to maximize data sets to derive and drive greater value.
Partner with HOPCo and HOPCo Digital IT leadership to ensure data is protected and that HOPCo remains compliant with all HITRUST, regulatory, and contractual obligations.
Function as accountable owner for Snowflake vendor relationship.
Lead external and internal technical resources to accomplish support goals.
Perform technical work, as needed, to query data, move data, or complete other essential work that is part of running the business and maintaining data assets.

EDUCATION
Bachelor’s Degree required. Study in computer science, data analytics, or related field preferred.
Snowflake and AWS certification preferred.
EXPERIENCE
5 years in various roles related to the management of healthcare data.
5 years of technology and data-related experience in a healthcare environment.
Project management experience, including determining scope, hosting meetings, documenting action items, and driving to project deadlines.
Exceptional written and verbal communication skills. Ability to communicate complex technical topics effectively to executive audiences.
Experience within a HITRUST certified organization and involvement in ongoing adherence
Experience supporting a data warehouse within a complex environment.
Experience directly managing third parties to deliver data management solutions.
Demonstrated experience as successful influential leader across matrixed teams.
Experience with Snowflake and AWS.
Exposure to Machine Learning methodologies and models.

REQUIREMENTS
None

KNOWLEDGE
Expert knowledge of data modeling and understanding of different data structures and data management packages
Capability to architect highly scalable data management systems that interconnect open source and packaged solutions.
Experience with leading data warehouse and Business Intelligence tools like Snowflake, R, Python, Power BI, and other visualization packages
Expert knowledge of AWS
Expert knowledge of Snowflake

SKILLS
Strong negotiation skills for keeping organizational focus on needed investments, while keeping the bigger HOPCo business picture in mind
Expert knowledge and insight into effective uses of data, data management tools, and business intelligence
Familiarity with the uses of Machine Learning and other advanced techniques for extracting value from large data sets
Current and thorough knowledge regarding data privacy and protection regulations (HIPAA, GDPR, etc.)
Expertise in technical infrastructure, network architecture, and data movement
Expertise in data storage, cloud technologies, database configuration, data protection techniques
Excellent listening, analytical, and communication skills
Analytical thinking and problem-solving skills, with acute attention to detail, accuracy and accountability balanced with sound business judgment.
Exceptional interpersonal skills","$81,470 /yr (est.)",Unknown,Company - Public,Healthcare,Health Care Services & Hospitals,#N/A,Unknown / Non-Applicable
"Apple
4.2",4.2,"Seattle, WA","AIML - Senior Data Infrastructure Software Engineer, Machine Learning Platform and Technology","Summary
Posted: Jul 31, 2023
Weekly Hours: 40
Role Number:200493570
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure. Are you a passionate about building scalable, reliable, maintainable infrastructure and solving data problems at scale? Come join us and be part of the Data Infrastructure journey.
Key Qualifications
12+ years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Preferred:
Familiarity with distributed databases, such as DynamoDB, MongoDB, or Cassandra.
Experience with containerization and orchestration technologies, such as Docker and Kubernetes.
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $161,700 and $284,900, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Jump Trading
4.5",4.5,"Carlstadt, NJ",Data Center Systems Engineer,"Jump Trading Group is committed to world class research. We empower exceptional talents in Mathematics, Physics, and Computer Science to seek scientific boundaries, push through them, and apply cutting edge research to global financial markets. Our culture is unique. Constant innovation requires fearlessness, creativity, intellectual honesty, and a relentless competitive streak. We believe in winning together and unlocking unique individual talent by incenting collaboration and mutual respect. At Jump, research outcomes drive more than superior risk adjusted returns. We design, develop, and deploy technologies that change our world, fund start-ups across industries, and partner with leading global research organizations and universities to solve problems.
Trading Infrastructure is a global organization of Engineers who architect, build and maintain our world-class infrastructure. From colo design/implementation to optimizing our exchange connectivity, we leverage research and automation to consistently adapt and innovate our infrastructure to scale and drive our trading and evolving business.
Our Data Center team is responsible for the strategy, implementation and maintenance of our data centers and colocations on a global scale. From deploying, automating and monitoring our infrastructure, to physically implementing and supporting our high-performance networks, we tackle a range of interesting challenges that help drive our business.
What You'll Do:
Racking and cabling of hardware in a professional manner (i.e. servers, switches, routers, storage, etc.)
Hardware break-fix and preventive maintenance
Management of third-party contractors
General datacenter operations (i.e. shipping/receiving, maintain inventory of frequently used parts, documentation, etc.)
Lead, plan and deploy datacenter infrastructure for a variety of projects (i.e. cabinets, power, servers, network, storage, cabling, etc)
Monitor datacenter hardware, power and thermals
Perform datacenter capacity planning (i.e. space, cooling, power, cabling plant)
Support high-performance networks
Leverage automation and dev-ops skills to automate tasks and troubleshoot issues
Skills You'll Need:
At least 3+ years experience working in a highly available data center environment
Working knowledge of:
Data center best practices
Common cabling, media types and optics
Structured cabling (i.e. trunks, panels, cassettes, etc.)
Server and switch hardware
Data center power and cooling
Networking (switching and routing concepts, configuration, troubleshooting, CCNA a plus) and Linux (experience using CLI and execution of scripts)
Experience managing full lifecycle projects
Ability to work well as team player in a global, fast-paced environment
Excellent written and verbal communication skills with ability to communicate with people of varying technical abilities
Availability to work during nightly maintenance window (typically 4-8pm ET) and on weekends as needed
Able to meet physical requirements of the position (i.e. racking heavy devices, climbing and working on ladders, running cables, etc.)
Able to operate vehicle and self-transport to data centers across NJ region
Benefits
- Discretionary bonus eligibility
Medical, dental, and vision insurance
HSA, FSA, and Dependent Care options
Employer Paid Group Term Life and AD&D Insurance
Voluntary Life & AD&D insurance
Paid vacation plus paid holidays
Retirement plan with employer match
Paid parental leave
Wellness Programs

Annual Base Salary Range
$75,000—$175,000 USD","$125,000 /yr (est.)",501 to 1000 Employees,Company - Private,Financial Services,Investment & Asset Management,1999,Unknown / Non-Applicable
"Netflix
4.2",4.2,Remote,Software Engineer 5 - Operational Data Infrastructure,"Remote, United States
Core Engineering
Content Infrastructure & Solutions (CIS) empowers engineers working on content and studio applications to be innovative and agile in supporting our massive global content production needs. Infrastructure pieces like very large-scale media processing platforms (1, 2), workflows (conductor), media asset management, collaboration, reporting, data movement and data processing are some of the key services we build. All this is custom-built on top of Amazon Web Services (AWS) infrastructure.

The Operational Data Infrastructure (ODI) is a part of the CIS organization–which provides infrastructure services that simplify discovering and accessing data produced across the Studio & Content applications, catering to both technical and non-technical end-users, and making operational reporting easier and more efficient. Currently, the core service to enable a highly leverageable reporting infrastructure is in a proof of concept phase. This presents a great opportunity to be a part of building and shaping such novel and high-impact foundational services at Netflix. The ODI team also owns other mature applications which serve specific reporting needs and their usage help inform the design and implementation of new services.

About the role
We are looking for a Backend Software Engineer 5 to help shape and build next-generation reporting infrastructure services and tools. In this role, you will have the opportunity to drive technical strategy and direction, own development end-to-end, manage stakeholder relationships, provide actionable feedback and insights to colleagues, and create technical solutions at scale. We are looking for a problem-solver who delivers well-tested, maintainable, performant, and predictable implementations.

You’ll be successful in this role if you:
Enjoy collaborating with teammates and technical cross-functional partner teams and have excellent communication skills
Take end-to-end ownership of major features and components from design to deployment to continuous improvements and maintenance.
Have a strong demonstrable knowledge in backend programming languages (eg. Java, Go, Python, Node.js)
Build testable, highly-available applications and services with monitoring and alerting
Have a good understanding of concepts like concurrency, parallelism, and event-driven architecture.
Demonstrates proactiveness in learning new technology and building new partnerships to identify opportunities for the team.
Comfortable with navigating ambiguity and able to form strategy/direction and plan for greenfield an/or complex problem space.
Passionate about improving data discovery and accessibility.
Nice to have:
Experience with technologies such as Spring, GraphQL, and RDF
Experience with automatic SQL query generation and relational algebra
At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for roles in this area of Netflix is typically $100,000 - $700,000

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.",#N/A,5001 to 10000 Employees,Company - Public,Information Technology,Internet & Web Services,1997,$5 to $10 billion (USD)
"Cystic Fibrosis Foundation
3.8",3.8,Remote,Data Engineer V,"The Cystic Fibrosis Foundation is a leading healthcare nonprofit organization like no other. For decades, we have been taking major steps and pioneering new ways to advance the mission to find a cure for cystic fibrosis and to provide all people with CF the opportunity to lead long, fulfilling lives by funding research and drug development, partnering with the CF community, and advancing high-quality, specialized care.
We are the global leader in the search for a cure for cystic fibrosis and nearly every CF drug and therapy available today was made possible because of CF Foundation support. We did this not only for the close to 40,000 people living in the U.S. with CF – and the estimated 105,000 people worldwide – but for the people with CF and families who have worked tirelessly to support the mission.
These achievements have required dedication and unwavering commitment from a talented team of CF Foundation employees. We promote an environment that attracts - and retains - a diverse group of talented people who are passionate about eradicating this disease . Join us and you will join an amazing team, devoted to our community, and our mission.
Position Description
The Cystic Fibrosis Foundation (CF Foundation) and its employees embrace their commitment to its core values. These core values are the pillars on which the CF Foundation stand and will continue to sustain us as we move forward.
Keep sight of what really matters: Our decisions are based on what is best for people with cystic fibrosis and their families.
Aspire for excellence in all we do: We take pride in our work. We are committed to continuous learning and improvement.
Stronger together: We collaborate and work together so that we can learn more and achieve more.
Innovate with courage: We embrace challenges. We reach beyond boundaries in pursuit of our vision.
Care about our people: We deeply care about each other and all who support our shared mission. We listen with respect. We support one another.
We are a nonprofit, donor-supported organization that has raised and invested billions of dollars to help develop cystic fibrosis therapies that have changed the lives of people with this disease. Nearly every CF medicine available today was made possible because of Foundation support.
POSITION SUMMARY:
The CF Foundation is preparing for the next leap in how we serve the CF community of patients, caregivers, care providers, and researchers with our Patient Registry. We have an ambitious vision for this next generation health data ecosystem: linking the existing records to many sources of additional data (e.g., electronic medical records, patient-reported outcomes, wearables, clinical trials, pharmacy, genetics, and claims) while providing patients with the power to control what is shared and with whom; welcoming flexibility and building a new architecture that will leverage the opportunities the next decade will bring in healthcare and technology solutions.
The Data Engineer V will be an essential member of the new health data ecosystem team overseeing the development and modification of database programs and data modeling. The individual is the lead data architect responsible for designing and implementing the technical data architecture, security and access management, data models, APIs, ETL, and DevOps. The Data Engineer V will be responsible for the underlying architecture for all database/data warehousing work, as well as for overseeing the technical work being done by other Data Engineers. The Data Engineer V will lead the development of strategies for data acquisition, archive recovery, and database implementation as well as the management of data migrations/conversions and troubleshooting data processing issues. They will be part of an interdisciplinary technology team and will work closely with developers and clinical data specialists. Within the team, the Data Engineer V is also expected to serve as a technical adviser to solve uniquely complex problems. This role will report to the Application Development Manager and work closely with the Head of Data Science.
ESSENTIAL DUTIES & RESPONSIBILITIES:
Designs/builds/tests/deploys in-house database applications, custom integration across various platforms that meet customer requirements.
Documents work/code including and not limited to process workflows and architecture diagrams.
Provides guidance regarding data integration and database development, best practices, and standards as needed.
Ensures the security and confidentiality of data.
Is responsible for the availability, reliability, and integrity of business data stored in production databases.
Designs, develops, and implements database applications and solutions for managing and integrating data between operational systems, data repositories, and reporting and analytical applications.
Builds the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources on-premises and cloud-based technologies.
Leads the design, development, and maintenance of data models to support business requirements.
Establishes and maintains the foundational architecture for databases and data warehousing projects.
Provides technical leadership to a team of Data Engineers, mentoring them and ensuring high-quality output.
Devises comprehensive strategies for data acquisition, archival recovery, and seamless database implementation.
Manages and executes data migrations and conversions while effectively troubleshooting data processing challenges.
Collaborates with cross-functional teams to identify and implement data solutions that align with business objectives.
Designs, implements, and thoroughly tests database schemas to guarantee optimal performance and data integrity.
Applies advanced principles, theories, and concepts to solve complex data engineering challenges.
Innovates and contributes to the development of cutting-edge ideas, principles, and methodologies within the field.
Acts as a technical advisor, offering expertise in resolving complex and unique problems.
Additional Responsibilities:
Understanding of health care, and health coverage issues.
Understanding HIPAA and relevant FDA regulations.
KNOWLEDGE, SKILLS AND ABILITIES:
Bachelor’s in Computer Science, Information Systems, Software Engineering, Information Technology, Applied Mathematics, or related fields. Master's in Computer Science or Information Systems preferred.
Minimum of ten years of experience with database development and DevOps. Equivalent experience will be accepted in lieu of a degree.
Industry-relevant professional certifications are required.
Demonstrated experience in data modeling for enterprise data.
Advanced knowledge of data integration tools and techniques.
Experience with Agile project methodology.
Expert knowledge of logical/physical data models for database /data warehouses.
Demonstrated ability to perform problem identification, analysis, and resolution on various DBMS on-premises or on the cloud.
Expert knowledge to integrate data within internal and external services from various formats such as APIs, Files, SFTP, Office 365, etc.
Strong expertise in SQL and other relevant programming languages (Python, Java, etc.).
Hands-on experience with database technologies such as SQL Server, Data Bricks, Snowflakes, and NoSQL databases.
Has a working experience in data warehousing and data lake house solutions and cloud platforms (AWS, Azure, Google Cloud).
Superb analytical, problem-solving skills and the ability to address complex and unique challenges.
Strong leadership skills with a track record of guiding and mentoring junior team members.
Effective communication skills, both verbal and written, including the ability to communicate technical concepts to a non-technical audience.
Superb experience with DevOps and IT Controls.
Superb ability to implement solutions using effective and innovative methodologies and perform peer code reviews.
Superb ability to estimate the level of effort for their and other work.
Superb time management skills, including the ability to work on multiple concurrent projects.
Proven ability to learn new skills and technologies as needed.
Proven ability to work with and support other departments in the development and support of enterprise applications.
Advanced attention to detail and ability to provide feedback for processes and improvement.
Excellent written and verbal skills in English.
Professional, polite, and courteous.
REPORTING RELATIONSHIPS:
Reports to Application Development Manager. No direct reports.
WORKING CONDITIONS:
Basic office environment, primary functions are computer-based.
Ability to work as part of a team committed to delivering exceptional customer service.
The above is intended to describe the general content of and requirements for the performance of this job. It is not to be construed as an exhaustive statement of essential functions, responsibilities, or requirements.
The salary range is $120,000 to $162,500. Specific salary varies based on geographic location and is commensurate with experience.
#LI-Remote
Total Rewards: The CF Foundation is committed to offering competitive compensation (base pay and incentive), benefits, and professional development opportunities that maximize our ability to recruit, retain, reward, and motivate a highly-qualified and diverse workforce. Our comprehensive benefits package includes medical, dental, and vision coverage; generous time-off and leave policies; a holistic well-being program; health savings and flexible spending accounts; employer-provided life and disability insurance; retirement savings benefits; and a variety of work-life benefits to support employees and their family members.
The CF Foundation is an equal opportunity employer that is committed to being an employer of choice, not just a good place to work, but a great and inclusive place to work. We strive to recruit and maintain a diverse workforce. Qualified applicants will receive consideration for employment without regard to race, physical or mental disability, color, religious creed, ancestry, national origin, religion, age, sex, marital status, genetic information or testing, gender identity and expression, sexual orientation or status as a Vietnam-era or special disabled veteran or any characteristic protected by law.
Reasonable Accommodations: The CF Foundation is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application procedures. If you need assistance or would like to request an accommodation due to a disability, please contact us at HROps@cff.org.","$141,250 /yr (est.)",501 to 1000 Employees,Nonprofit Organization,Nonprofit & NGO,Grantmaking & Charitable Foundations,1955,$100 to $500 million (USD)
"Affinity.co
4.1",4.1,Remote,Staff Data Engineer,"USA (Remote)
Affinity stitches together billions of data points from massive datasets to create a powerful, accurate representation of the world's professional relationship graph. Based on this data, we offer our users the insights and visibility they need to nurture and tap into their team's network of opportunities.
Reporting to the Director of Engineering, you'll support creating the magic that underlies Affinity's industry-leading relationship intelligence model as the key technical leader of Affinity’s Data Enrichment team.
In this role, you’ll leverage your past experiences and deep understanding of back-end technologies to help shape and execute Affinity's roadmap for dataflow and system architecture, champion engineering best practices, delivery velocity, and act as a technical mentor for other engineers on the team. You’ll play a significant role in defining the future of how businesses around the world use their relationships.
What you’ll be doing:
Drive complex technical, architecture, design, and product discussions
Lead data domain, technical and business discussions in relation to future architecture direction
Design, implement, and build data solutions that deliver data with measurable quality using Spark, Python, Databricks, and the AWS ecosystem (S3, Redshift, EMR, Athena, Glue)
Help define our data roadmap. You'll collaborate with our fast-growing team of data engineering, machine learning engineering, product, and business leaders to help to answer these questions and more
Mentoring, coaching, and inspiring the engineers on the team
Identify and fill gaps in the team, and create the processes necessary for the teams’ success

Qualifications
Don’t meet every single requirement? Studies have shown that women and people of color are less likely to apply to jobs unless they meet every qualification. At Affinity, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role, but your past experience doesn’t perfectly align with the qualifications above, we encourage you to apply anyways. You may be just the right candidate for this or other roles.
Required:
You have 10+ years of experience working in data engineering, with at least 3+ years of acting as a senior team lead or staff engineer, leading complex, sometimes ambiguous engineering projects across team boundaries
You have extensive hands-on experience in building scalable data platforms and reliable data pipelines using technologies such as Spark, Hadoop, DataBricks, AWS SQS, AWS Kinesis, and/or Kafka
You have experience working with large, multi-terabyte datasets and are comfortable with high-scale data ingestion, transformation, and distributed processing tools such as Apache Spark (Scala or Python)
Experience with AWS, DBX or related cloud technologies
You're comfortable with the building blocks of modern back-end systems, such as horizontally scalable data infrastructure, event-driven architecture, and beyond and can clearly articulate the pros/cons of different approaches, while also providing a recommended solution based on the current context
You have familiarity with databases and analytics technologies in the industry, including Data Warehousing, Data Lakes, ETL and Relational Databases
You have experience mentoring and helping the engineers around you grow
You have experience partnering with product and machine learning teams on large, strategic data projects and routine partner work
You take pride in delivering exceptionally high quality work in terms of data accuracy, performance, and reliability
You’re eager to contribute your ideas and experiences to help Affinity continuously improve as a product and company
Nice to have:
Experience leveraging machine learning to improve the quality of ingested data.
You have worked with multiple third party data vendors and have experience in conflict resolution approaches.
How we work:
Our culture is a key part of how we operate as well as our hiring process:
We iterate quickly. As such, you must be comfortable embracing ambiguity, be able to cut through it, and deliver incremental value to our customers each sprint
We are candid, transparent, and speak our minds while simultaneously caring personally with each person we interact with
We make data driven decisions and make the best decision for the moment based on the information available
Join us in enabling every professional on the planet to succeed by harnessing the power of their relationships.

What you'll enjoy at Affinity:
We live our values as playmakers, obsessed with learning, caring personally about our colleagues and clients, are radically open-minded, and take pride in everything we do.
We pay your medical, dental, and vision insurance with comprehensive PPO and HMO plans. And provide flexible personal & sick days. We want our team to be happy and healthy :)
We offer a 401k plan to help you plan for retirement.
We provide an annual budget for you to spend on education and offer a comprehensive L&D program – after all, one of our core values is that we're #obsessedwithlearning!
We support our employee's overall health and well-being and reimburse monthly for things such as; transportation, Home Internet, Meals, and Wellness memberships/equipment.
Virtual team building and socials. Keeping people connected is essential.
Please note that the role compensation details below reflect the base salary only and do not include any variable pay, equity, or benefits. This represents the salary range that Affinity believes, in good faith, at the time of this posting, that it will pay for the posted job.
A reasonable estimate of the current range is $165,000 to $278,000 USD. Within the range, individual pay is determined by factors such as job-related skills, experience, and relevant education or training.
About Affinity
We have raised over $120M and are backed by some of Silicon Valley’s best firms, with over 2,700 customers worldwide on our platform. We are proud to have a 4.5 Star Glassdoor rating and recently ranked; Inc.’s Best Workplaces of 2022 and Great Places to Work 2022. Passionate about helping dealmakers in the world’s biggest relationship-driven industries to find, manage, and close the most important deals; our Relationship Intelligence platform uses the data exhaust of trillions of interactions between Investment Bankers, Venture Capitalists, Consultants, and other strategic dealmakers with their networks to deliver automated relationship insights that drive over 450,000 deals every month.","$221,500 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2015,Unknown / Non-Applicable
"Walmart
3.3",3.3,"Dallas, TX",Staff Data Engineer,"Position Summary...

What you'll do...

As a ""Staff Data Engineer"", you should be able to technically help and assist team to steer through correct technical directions following the best practices. You will have deeper understanding of Data Engineering approaches along with hands on experience in building highly scalable solutions.

About Team: Data Ventures
Our team creates reusable technologies to help with customer acquisition, onboarding, and empowering merchants, while ensuring a seamless experience for both stakeholders. We also optimize tariffs and assortment in accordance with Walmart's Everyday Low-Cost philosophy. We not only create affordability, but we also deliver customized experiences for customers across all channels - in-store, mobile app, and websites. Our team is responsible for providing support to US Marketplace sellers. We focus on providing immediate solutions to the cases/tickets created by sellers. We interact with multiple teams across the company to provide excellent seller experience.

What you'll do:
You will lead the work of other small groups of ten to twelve engineers, including offshore associates, for assigned Engineering projects by providing pertinent.
documents, direction, and examples; identifying short- and long- term solutions and timeline; reviewing and approving proposed solutions.
You will drive the execution of multiple business plans and projects by identifying customer and operational needs, developing, and communicating business.
Leads and participates in medium- to large-scale, complex, cross-functional projects by reviewing project requirements, translating requirements into
technical solutions; gathering requested information (for example, design documents, product requirements, wire frames); writing and developing.
code; conducting unit testing; communicating status and issues to team members and stakeholders; collaborating with project team and cross.
functional teams; troubleshooting open issues and bug-fixes; enhancing design to prevent re-occurrences of defects; ensuring on-time delivery and
hand-offs: interacting with project manager to provide input on project plan; and providing leadership to the project team.
plans and priorities; removing barriers and obstacles that impact performance; providing resources; identifying performance standards; measuring.
progress and adjusting performance; accordingly, developing contingency plans; and demonstrating adaptability and supporting continuous learning.
Implementing new architectural patterns; and performing design and code reviews of changes.
Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to
others in their use and application; ensuring compliance with them; and utilizing and supporting the Open Door Policy.
Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives, consulting with business.
partners, managers, co-workers, or other key stakeholders; soliciting, evaluating, and applying suggestions for improving efficiency and cost effectiveness.
and participating in and supporting community outreach events.

What you'll bring:
Knowledge of Databricks, Snowflake is an added advantage.
Experience with ThoughtSpot, Druid, Big Query and ClickHouse is added advantage.
Hands on knowledge in NoSQL like Cosmos DB along with RDBMS like MySQL, Postgres is plus.
Hands on working experience in any messaging platform like Kafka is preferred.
Increase the efficiency of the team by setting right Processes of Software Development, Requirement Intake, Effort Estimation
Demonstrating creative, critical thinking & troubleshooting skills.

About Walmart Global Tech
Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.

Flexible, hybrid work: We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.

#GraceHopper23

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.

At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .

Additional compensation includes annual or quarterly performance incentives.

Additional compensation for certain positions may also include:

Regional Pay Zone (RPZ) (based on location)

Stock equity incentives

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field.
3 years' experience in data engineering, database engineering, business intelligence, or business analytics.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master's degree in Computer Science or related field and 4 years' experience in software engineering or related field

Primary Location...
603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America","$133,857 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,General Merchandise & Superstores,1962,$10+ billion (USD)
"Netflix
4.2",4.2,Remote,"Security Risk Engineer (L4), Data Analyst","Remote, United States
Corporate Real Estate, Employee Health, Workplace, and Security
Taking risks, making bets!

At Netflix, we continue to challenge the traditional risk assessment and modeling approach. Our strategic bet around risk quantification shapes our decision-making and guides us in prioritizing risk responses and control design. Our risk program is looking for a new team member as we continue helping the business increase their confidence and ability to:

use data analysis to improve decision making
provide data visualization to decision-makers to reduce uncertainty,
and understand optimal techniques to respond to technology risk

To support our investment in this space, we need to take smart risks, and you will enable Netflix to lean into those smart risks by expanding a program that promotes risk quantification, statistical models, and impact analysis to increase our confidence in risk response activities. We are looking for thoughtful data-oriented professionals to enable our mission and support our inclusive culture. In this role, you will help establish and execute a broad strategic vision for the risk program at Netflix. You will not only work within the team but also cross-functionally with various teams across the organization.
You are excited about this opportunity because…
You are enthusiastic about analyzing and visualizing how data analysis can help inform risk-based decision making
You understand and advocate for risk management and understand how data supports analytical models and influence decision making
Our company culture encourages independent decision-making by employees
You have a passion for risk management, information security, metrics, efficient security operations, and effective control designs
Visualizing risk data for people to consume and use effectively is something you are good at doing
To be successful in this role, we are looking for individuals that…
Participate in developing key risk indicators, provide inputs to the development of key control indicators, and key performance indicators for various programs
Excited to learn and apply statistical models to risk frameworks (FAIR, Monte-Carlo with PERT distributions, sensitivity analysis, and others)
Familiarity with R, Python, SQL, etc
Familiarity with Tableau or other statistical and visualization tools
Understand relevant data collection, data cleaning, and data analysis techniques
Can participate in risk management, decision-making, and collaborative discussions
Can participate and support quantified risk assessments and understand the value of qualitative data for improvements to quality and engineering processes
Utilize information security risk expertise to develop loss event scenarios across operating companies, business units, projects, and products
Interpret internal or external cyber security risk analyses in business terms and recommend a responsible course of action
Develop templates and instructional materials to help with self-service risk management actions based on defined risk tolerances
Monitor and identify opportunities to improve the effectiveness of risk management processes
Core value skills - must-have
Attention to detail
Inclusivity
Broad knowledge of how to operationalize the management of risk as a part of regular workflow
Autonomously drives work delivery (bias to action)
Strong communication (technical, status/blockers, cross-functional)
Cross-functional Collaboration
Our security approach is influenced by our “Freedom and Responsibility” and “Context not Control” principles. As a result, employees have tremendous freedom in their work and the corresponding responsibility and accountability to do the right thing for Netflix. Read more about the Netflix culture here.

The overall market range for roles in this area of Netflix is typically $100,000 - $700,000.
This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.",#N/A,5001 to 10000 Employees,Company - Public,Information Technology,Internet & Web Services,1997,$5 to $10 billion (USD)
"VMware
4.3",4.3,"Palo Alto, CA","Senior Data Engineer - Opportunity for Working Remotely Palo Alto, CA","Duties: Develop data solutions and models in Tableau to meet customers needs by collecting user needs and queries. Extract data from company's data lake to the local data model, initiate and guide report in Report Builders utilizing complicated data models. Maintain the data lake by reviewing the extract data, transform and load (ETL) job status, disk space usage, report extraction status, and source connections. Plan, design, develop and test software products and features for enhancements and new cloud-based tools and solutions. Work autonomously in an area of specialization to analyze information and user needs to determine and develop software solutions working on moderately complex problems of diverse scope. Modify existing software to correct errors, adapt to new hardware, and improve performance. Develop and direct software systems testing and validation procedures, programming, and documentation. Apply company policies and procedures to resolve a wide range of technical and programming issues in creative ways. Design, develop, and modify software systems to meet customer needs and company goals. Work with cross-functional teams including engineers, programmers, analysts and others to interface between hardware and software, develop specifications and performance requirements, and resolve customer problems. Customize software solutions to optimize operational efficiency in cloud-based environments and exercise discretion within defined practices and procedures in selecting methods and techniques for obtaining solutions. Utilize knowledge of data base management system software, development environment software, object-oriented development software, program testing software, operating system software, and various programming languages. Utilize knowledge of computer hardware and software, including applications and programming, and of systems architecture and components, including networking and storage. Apply knowledge of engineering principles, best practices, and technologies to the design, development, testing, and production of various company proprietary products and services.
Requirements: Master’s degree (U.S. or foreign equivalent) in Computer Science, Computer Engineering, Software Engineering, Electrical Engineering, Computer Information Systems, Information Technology or a related technical/quantitative field and two (2) years of experience in job offered or related position. In the alternative, employer will accept Bachelor’s degree (U.S. or foreign equivalent) in Computer Science, Computer Engineering, Software Engineering, Electrical Engineering, Computer Information Systems, Information Technology or a related technical/quantitative field and five (5) years of experience in job offered or related position.
Employer requires at least four (4) out of the following skills gained through industry experience:
ETL tool such as Spark;
Data Analysis and data modelling;
Data Visualization such as Tableau;
Operating system such as Linux;
Data algorithms;
Java or C++.
Telecommuting role to be performed anywhere in the U.S. Multiple openings. Ref # R2307105.
For US based candidates, the annual pay range (OTE for commissioned roles; Salary for other roles) for this position is: $192,941- $227,000. The actual offer will be based on the role, location, and individual candidate experience. Bonus, commission, and/or equity may be eligible for this position. VMware offers comprehensive benefits including, but not limited to: medical, dental, and vision plans, company paid holidays, paid sick leave, and vacation time. Additional benefits for this position can be found at https://benefits.vmware.com/. Your talent advisor can share more about the specific salary range for your preferred location during the hiring process.
Qualified Applicants: Applicants must contact VMware, Inc. via email at resumeshr@vmware.com. Please include reference # R2307105.

This job may require the candidate to travel and/or work from a facility that requires full vaccination prior to entry.

Category : Engineering and Technology
Subcategory: Software Engineering
Experience: Manager and Professional
Full Time/ Part Time: Full Time
Posted Date: 2023-08-31

VMware Company Overview: At VMware, we believe that software has the power to unlock new opportunities for people and our planet. We look beyond the barriers of compromise to engineer new ways to make technologies work together seamlessly. Our cloud, mobility, and security software form a flexible, consistent digital foundation for securely delivering the apps, services and experiences that are transforming business innovation around the globe. At the core of what we do are our people who deeply value execution, passion, integrity, customers, and community. Shape what’s possible today at http://careers.vmware.com.

Equal Employment Opportunity Statement: VMware is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: VMware is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at VMware are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. VMware will not tolerate discrimination or harassment based on any of these characteristics. VMware encourages applicants of all ages. Vmware will provide reasonable accommodation to employees who have protected disabilities consistent with local law.","$156,475 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1998,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Nashville, TN","Senior Data Engineer , People Data and Analytics Systems","5+ years of data engineering experience
Experience with data modeling, warehousing and building ETL pipelines
Experience with SQL
Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
Experience mentoring team members on best practices
As a Senior Data Engineer, you will analyze large amounts of business data, solve real world problems, and develop metrics and business cases that will enable us to continually deliver on people metrics. You will also work with a team of Business Intelligence Engineers and help automate and scale the analysis, and to make the data more actionable to manage business at scale. You will own many large datasets, production pipelines, automate anomaly detection model, data models, implement new data pipelines that feed into or from critical data systems at Amazon

This role will support the field operations and specifically improving data analytics capabilities for core and common PXT metrics directly impacting delivery associates across middle and last mile. This role will maintain database and reporting infrastructure for field people metrics such as employee time and attendance, attrition, associate schedule flexibility employee voice and staffing metrics, in addition to various exempt metrics such as attrition. The focal point of this role would be to support field PXT reporting and data insights enabling operators and capacity planning teams to make real time productivity and employee experience decisions based on Daily, Weekly or Monthly reporting cadences.

Key job responsibilities
Work closely with senior engineers to model, implement data pipelines that feed into or from people data across middle and last mile.
Own the delivery of data modelling and data pipelines.
Management and execution against project plans and delivery commitments
Assist directly and indirectly in the continual hiring and development of technical talent.
Create and execute appropriate quality plans, project plans, test strategies and processes for development activities in concert with business and project management efforts.
Maintain in-house cluster and continuously work on improving cluster health with enabling alerts and key functions
We are open to hiring candidates to work out of one of the following locations:

Arlington, VA, USA | Atlanta, GA, USA | Austin, TX, USA | Bellevue, WA, USA | Boston, MA, USA | Nashville, TN, USA | Phoenix, AZ, USA | Quincy, MA, USA | Seattle, WA, USA | Washington, DC, USA

Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
Experience operating large data warehouses
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $123,700/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$123,700 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Microchip Technology
4.0",4.0,"Chandler, AZ",Principal Engineer - IT Systems (Enterprise Storage & Data Center),"Are you looking for a unique opportunity to be a part of something great? Want to join a 20,000-member team that works on the technology that powers the world around us? Looking for an atmosphere of trust, empowerment, respect, diversity, and communication? How about an opportunity to own a piece of a multi-billion dollar (with a B!) global organization? We offer all that and more at Microchip Technology, Inc.
People come to work at Microchip because we help design the technology that runs the world. They stay because our culture supports their growth and stability. They are challenged and driven by an incredible array of products and solutions with unlimited career potential. Microchip’s nationally-recognized Leadership Passage Programs support career growth where we proudly enroll over a thousand people annually. We take pride in our commitment to employee development, values-based decision making, and strong sense of community, driven by our
Vision, Mission, and 11 Guiding Values
; we affectionately refer to it as the Aggregate System and it’s won us countless awards for diversity and workplace excellence.
Our company is built by dedicated team players who love to challenge the status quo; we did not achieve record revenue and over
30 years of quarterly profitability
without a great team dedicated to empowering innovation. People like you.
Visit our
careers
page to see what exciting opportunities and company
perks
await!
Job Description:
The Principal Engineer - IT Systems must be a seasoned Enterprise Data Storage & Backup Architect/Engineer with in depth knowledge and hands-on experience with a wide range of enterprise storage technologies, specifically NetApp. Responsible for Global IT Enterprise Data Storage & Backup Solutions including Infrastructure Design, Architecture & Strategy, Data Center support and projects in a 7/24 multi-site environment.
This role requires a previous storage technical background, coupled with extensive experience of working with the demands of a large enterprise. Also, assist with storage systems management, upgrades and migrations utilizing SAN & NAS technologies with NetApp,PureStorage, Veeam, NetBackup & Brocade switches. Capable of working with minimal supervision & applies the necessary technical expertise for efficient storage and backup system management while communicating with peers, customers and leadership.
Key Responsibilities:
Lead/Assist with the Architecture, Design, Implementation, Migration and day-to-day support of all Storage & Backup technologies.
Extensive technical expertise with enterprise level NetApp Storage environment, monitoring, networking, configuration, capacity management & performance optimization.
Support Business & Database applications and Server Infrastructure including HP ServiceGuard Linux HA & disaster recovery.
Assist with the Architecture of all Storage Systems in the upgrade and transformation of current legacy Storage Systems.
Must have an in-depth understanding of storage & backup technologies with a strong focus on NetApp Storage Solutions as well as working knowledge of Backup, Virtualization, Networking, and Server Solutions.
Responsibility encompasses the technical streams of Archive solutions, Data Protection & Disaster Recovery Solutions with disk, tape, and associated systems management technologies. This also includes the restoration of service and identification of the root cause of any problems within the environment.
Maximizes storage systems utilization & performance with storage efficiency technologies, provisioning/re-claiming, deploying new storage systems, adding/removing disk shelves, schedule & perform CDOT/ONTAP/firmware upgrades, troubleshooting SAN/NAS/performance issues/outages, connectivity problems, and assessing storage needs.
Configuration, administration of data backup, disaster recovery and replication technologies.
Provide day-to-day operational/technical support, research new technologies, develop/guide insightful strategies, performs necessary storage infrastructure maintenance & responsible for ongoing recommendations and best practices.
Provide pro-active day-to-day operational support to ensure issues are prevented where possible and resolved according to business impact and established service level agreements.
Work with the incident and problem management on root causes and proactive avoidance of future incidents.
Work with vendors where necessary to maintain software and hardware to keep within supported versions. Physical ability to rack/stack hardware.
Directs & coordinates the work assigned with global teams & possess excellent communication & problem-solving skills with minimal supervision.
Requirements/Qualifications:
Bachelor’s degree in Computer Science, Information Systems, or equivalent education.
Minimum 8.5+ years enterprise storage and backup experience (required).
Strong understanding of storage and backup systems architecture and design, including administration of enterprise SAN/NAS and storage switches, NetBackup and tape library management, disaster recovery & business continuity solutions.
Strong experience with NetApp CDOT, 7-MODE, Snap management suite, backup, recovery, DR & replication technologies is a must.
Experience with Virtualization, VMWare, Windows Server, Networking & Linux is an asset.
Strong attention to detail, excellent organizational and time management skills.
Able to manage own workload and balance conflicting priorities.
On-call rotation & travel if required based on business requirements.
Must be able to work & communicate with internal teams, clients & remote site resources by following best practices.
Travel Time:
0% - 25%
Physical Attributes:
Hearing, Seeing, Talking, Wet and/or Humid, Works Alone
Physical Requirements:
95% Sitting, 5% Standing/Walking
Microchip Technology Inc is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.

For more information on applicable equal employment regulations, please refer to the
EEO is the Law Poster
and the
EEO is the Law Poster Supplement
. Please also refer to the
Pay Transparency Policy Statement
.","$115,087 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Electronics Manufacturing,1989,$5 to $10 billion (USD)
"Cushman & Wakefield
3.7",3.7,"Hillsboro, OR",Data Center Operating Engineer,"Job Title
Data Center Operating Engineer
Job Description Summary
We are seeking a Data Center Engineering Operations Technician (EOT) to join our team. The ideal candidate will be responsible for operating and maintaining mechanical and electrical equipment in the data center, troubleshooting facility and rack-level events, performing limited maintenance tasks, and providing support to Data Center Operations. Additionally, the EOT will take daily operational readings, utilize internal CMMS, supervise contractors, and ensure compliance with safety procedures.
Job Description
We are currently seeking a skilled and experienced Data Center Facility Engineer to join our team. The successful candidate will be responsible for the efficient operation and maintenance of the mechanical, electrical, and plumbing equipment and systems for our data center facility.
Responsibilities:
Perform all plumbing, electrical, or HVAC requirements of the building(s).
Maintain heating equipment, chillers (air and/or water-cooled), DX units, pumps, cooling towers, fan coil units, VAV, and air distribution systems, etc.
Monitor and adjust all mechanical/pneumatic equipment, steam stations, control gauges, distributor panels, valves, thermostats, diffusers, and other equipment necessary to provide a comfortable environment for the data center facility.
Verify field conditions and perform any necessary repairs or adjustments.
Monitor Energy Management and perform any necessary repairs or adjustments.
Perform repairs to plumbing fixtures (water closets, urinals, flush valve assemblies, lavatories, etc.).
Perform preventive maintenance duties in accordance with industry best practices and standards, including changing filters, cleaning coils, flushing condensers, punching tubes, greasing fan, pump and motor bearings as required, inspecting and adjusting belts, replacing motor bearings, aligning pulleys and shafts, monitor condenser, chilled, heating and secondary water chemical treatment and its associated feed equipment, clean and maintain cooling towers, and perform annual inspections and other scheduled routines as directed.
Inspect engine room equipment, fan room equipment, cooling tower, all motors, house pumps, electric rooms, back-up generator, fire pump(s), sump pump(s), and ejector pumps. Replace lamps, light fixtures, reinstall or replace signage, verify rooms are clean and clear of obstructions and debris.
Check for properly operating emergency exit signs and lights and ensure free and clear access to emergency stairs and exits. Perform additional fire and life safety inspections as per NFPA and local jurisdiction, industry standards, building protocol and as directed by superiors and property management.
• Document and report activities to supervisor. • Respond immediately to emergency situations (fire, evacuation, equipment failure, etc.) and customer concerns.
Comply with all applicable codes, regulations, governmental agency, and company directives as relates to building operations and practice safe work habits.
Complete all required safety training as scheduled annually.
Comply with Uniform Dress Code while working and maintain a neat and clean appearance while on the property at times other than working hours.
Requirements:
High School Diploma or GED Equivalent.
Graduate of apprentice program or trade school preferred.
5+ years of related work experience in operating mechanical, electrical, and plumbing systems in a commercial property setting.
Technical proficiency.
Initiative.
Flexibility.
Multi-tasking.
Sense of urgency.
Ability to work extended periods of time without relief when responding to priority/emergency situations (including overtime type assignments).
May require shift work and/or on-call duties.
If you meet the above qualifications and are passionate about delivering top-notch service to our customers, we would like to hear from you. We thank all applicants for their interest.
#INDSkilledtrades

Cushman & Wakefield provides equal employment opportunity. Discrimination of any type will not be tolerated. Cushman & Wakefield is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other characteristic protected by state, federal, or local law.
In compliance with the Americans with Disabilities Act Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position at Cushman & Wakefield, please call the ADA line at 1-888-365-5406 or email HRServices@cushwake.com. Please refer to the job title and job location when you contact us.","$83,743 /yr (est.)",10000+ Employees,Company - Public,Real Estate,Real Estate,1917,$5 to $10 billion (USD)
"Infoblox
4.5",4.5,"Dallas, TX",Staff Data Engineer,"Infoblox Inc. seeks Staff Data Engr. in Dallas, TX. Build and support data lake to enable access to data for internal and external customers.

BS degree in IT related fields& 6 yrs exp req. Send res. To M. Edwards, Infoblox, 2106 Pacific Ave., Suite 600, Tacoma, WA 98402, w/ref to VCPA.

EOE.","$151,040 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,1999,$500 million to $1 billion (USD)
"Lockheed Martin
4.1",4.1,"Fort Worth, TX",Quality Engineer - Data Analyst - Early Career,"Job ID: 644991BR
Date posted: Aug. 30, 2023

Description:By bringing together people that use their passion for purposeful innovation, at Lockheed Martin we keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work. With our employees as our priority, we provide diverse career opportunities designed to propel development and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. At Lockheed Martin, we place an emphasis on empowering our employees by fostering innovation, integrity, and exemplifying the epitome of corporate responsibility. Your Mission is Ours.

Lockheed Martin Aeronautics in Fort Worth, Texas is seeking a fulltime Early Career Quality Engineer (Data Analysts). In this role, you will you will assist in the development of actionable metrics and models to make data-based decisions while analyzing trends across Lockheed Martin. This role will have a particular focus on business operations analytics, whereby the candidate will need to take questions from stakeholders, collect and analyze the needed information for project requirement design, and prepare written or interactive reports presenting the conclusions and reasoning following from the analysis and modeling. The successful candidate will have experience and/or knowledge of Python, Tableau, SQL, HTML, Anaconda, Java, APIs, and various forms of machine learning. The candidate will be expected to apply languages and tools listed above to inference techniques to business problems throughout the corporation.
Basic Qualifications:
Bachelor's Degree in Engineering, Computer Science from an accredited college in a related discipline
Experience with machine learning
Experience with SQL and Programming languages, preferably Python and C#
Experience with Java, HTML, and JavaScript.
Desired Skills:
Familiar with open-source intelligence projects
Familiar with consulting
Excellent written and verbal communication skills
Ability to work in a collaborative and team-based environment
Proficient with Microsoft Office
Experience with analytical tools such as Tableau as well as other data analytics and visualization tools.
Knowledge of aerospace and defense market, corporate finance and microeconomic factors associated with manufacturing, weapons systems sustainment
Ability to understand the data lifecycle and be able to interpret and communicate data
Clearance Level: None
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: 4x10 hour day, 3 days off per week
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.

With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.

If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications.
Experience Level: 4 yr and up College
Business Unit: AERONAUTICS COMPANY
Relocation Available: Yes
Career Area: QA/Test and Inspection
Type: Full-Time
Shift: First",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1995,$10+ billion (USD)
"Peraton
3.6",3.6,"Fort Gordon, GA",Sr-level Data Analyst/Engineer,"Responsibilities:
Peraton seeks a Sr. Level Data Analyst / Engineer to support assembly of data and infrastructure in a cloud environment in Fort Gordon, GA.

Tasks include:
Leverage built-in security services across multiple network infrastructures
Ensure that the right users have access to the right services
Use various cloud service providers – Amazon Web Services (AWS), Google
Cloud, and Microsoft Azure.
Develop a solid data foundation to process modeling data and perform robust
analytics
Conduct network analysis to characterize the threat of social media narratives and messaging
Analyze various ingested and stored large data sets and facilitate cohernet visualization of results in the Army’s Big Data Platform (BDP)
Qualifications:
Required Qualifications:
BS 10-12, MS 8-10, Phd 5-7 Will consider: Edu/Exp: HS +14 years experience
Experience managing and supporting system requirements analysis, design, and development activities.
Significant expertise performing engineering analysis and issue resolution.
Analyzes and develops CONOPs, system architectures, and requirements.
Has developed specifications, drawings, and other engineering artifacts.
Experience supporting process engineering and optimization activities.
Mentors mid-level and junior staff.
Must be familiar with basic data analysis and visualization techniques in Python.
Must have experience using basic Python data analysis packages (pandas, matplotlib, etc.).
Must have experience using a notebook analytic environment like Jupyter Notebooks.
Requires DoD 8570/8140 IAT Level II. Must hold the appropriate DoD 8570.01 baseline certification applicable to their work role prior to beginning work.
Active TS/SCI clearance with ability to obtain and maintain a CI Poly and MEAD clearance.

Preferred Qualifications:
IAT DoD 8570/8140 IAT Level III or comparable certifications
Benefits:

At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We’re fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.

#LI-ET1
Peraton Overview:
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers.
Target Salary Range: $112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors. EEO: An Equal Opportunity Employer including Disability/Veteran.","$145,500 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $10 billion (USD)
"Salesforce
4.1",4.1,"Washington, DC","Staff Data Engineer, Enterprise Insights - Slack","To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
About the team
Slack is looking for data engineers to join our Insights team! We build data products that are used across our large enterprise customers to access metrics that are critical to their workflow.
In this role, you will partner cross-functionally with business domain partners, analytics, and engineering to craft and implement our data model. You will design, build and scale data pipelines that transform billions of records into measurable data that enable insights.
You will work on initiatives that directly key decision makers within our Enterprise customer base by building and scaling our data models that provide key adoption and engagement metrics.
We are looking for passionate individuals with deep technical skills that are comfortable contributing to an up-and-coming data ecosystem, and can build a strong data foundation for the company. We are also in search of a self-starter, detail and quality oriented, and hardworking individual that's interested in making a huge impact at Slack!
What you will be doing:
Translate business requirements into data models that are easy to understand and used by different subject areas
Design, implement and build data models and pipelines that deliver data with measurable quality under the SLA
Partner with product teams, data analysts and engineering teams to build foundational data sets that are trusted, well understood, and aligned with business strategy
Be a champion of the overall strategy for data across multiple teams and different use cases
Increase access to foundational company metrics through process and technical foundations
Identify, document and promote data engineering standard methodologies throughout Slack
What you should have:
7+ years of experience working in data architecture, data modeling, master data management, metadata management
Recent accomplishments working with relational methods and approaches (logging, columnar, star and snowflake, dimensional modeling)
A consistent track record in scaling and optimizing schemas, performance tuning SQL and ETL pipelines in OLAP and Data Warehouse environments
Airflow or any workflow management platform for data engineering pipelines orchestration.
Proficiency in coding through the use of with Python and SQL
Familiar with data governance frameworks, SDLC, and Agile methodology
Excellent written and verbal communication and interpersonal skills, and ability to efficiently collaborate with technical and business partners
Bachelor's degree in Computer Science, Engineering or a related field, equivalent training, fellowship, or work experience
Bonus Points:
Hands-on experience with Spark SQL, AWS (S3, EMR), Apache Pinot, Big Data & Hadoop.
Proficient in coding through the use of Scala
Experience working with cloud technologies such as AWS, GCP or Azure.
Understanding of NoSQL Data Stores
Experience around Batch & Real-time processing
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce .
Salesforce welcomes all.
For Colorado-based roles, the base salary hiring range for this position is $175,600 to $254,700.
For Washington-based roles, the base salary hiring range for this position is $175,600 to $254,700.
Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.","$215,150 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1999,$10+ billion (USD)
"Lumen
3.5",3.5,Remote,Lead Data Engineer (Azure),"About Lumen

Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology
The Role
Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen’s reputation as a technology leader?

In this role, you will be taking the lead in partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence.
The Main Responsibilities
You are a great fit for this position if you:
Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions.
Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments.
Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in.
Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations.
What We Look For in a Candidate
Qualifications:
Experience building data models and performing complex queries using SQL
Experience performance tuning large datasets
Experience building large data pipelines and/or web services
Strong programming skills with Python and other scripting languages
8+ years of Business Intelligence or software development experience using industry technologies
4+ years of experience in building integration with upstream and downstream systems with REST APIs
Excellent problem solving, critical thinking, and communication skills
Ability to communicate effectively with technical and business teams, drive issues to closure
Strong understanding of data engineering and data stewardship roles in an organization
Ability to foster an innovative and inclusive team-oriented work environment. You’ll play an active role in counselling and mentoring junior team members across the organization by providing structured and on-the-job feedback.
Ability to work on multiple priorities that span different areas of focus. You should feel comfortable talking to business stakeholders, analysts, data scientists and developers.
An entrepreneurial spirit who is excited by ambiguity, operates autonomously and can make informed decisions on the fly, grounded in a digital transformation point of view for marketing/sales initiatives.
BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science

Nice to Haves:
Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable
Azure experience
Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable
Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies
Experience with cloud data platforms is helpful
Combined IT and Marketing background
Machine Learning, Data Science, and statistical modeling experience are highly valued

Requisition #: 329669
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
This position is part of a bargaining unit and represented by a union. Depending upon the applicable collective bargaining agreement under which you may be hired, you may be: (a) required to join the union and pay union dues as a condition of employment; or, (b) required to pay union dues, but not join the union as a condition of employment; or (c) free to chose whether or not to join the union, but if you do join the union you would be obligated to pay union dues.
EEO Statement

We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, creed, veteran status, disability, medical condition, genetic characteristic or information, age, sex, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, ""protected statuses""). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE:
Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer

The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
85230
Salary Max :
189360
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information . We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.","$137,295 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1968,$10+ billion (USD)
"GEICO
2.9",2.9,"Chevy Chase, MD",Sr Engineer - Data (Support),"Position Summary
GEICO is seeking an experienced Senior Engineer with a passion for building high performance, low-latency platforms, and applications. You will help drive our insurance business transformation as we redefine experiences for our customers.
Position Description
Our Senior Engineer is a key member of the engineering staff working across the organization to provide a friction-less experience to our customers and maintain the highest standards of protection and availability. Our team thrives and succeeds in delivering high quality technology products and services in a hyper-growth environment where priorities shift quickly. The ideal candidate has broad and deep technical knowledge, typically ranging from front-end UIs through back-end systems and all points in between.
Position Responsibilities
As a Senior Engineer, you will:
Troubleshoot and resolve data-related Production incidents, including logging details and providing updates at regular intervals to stakeholders
Track and drive the resolution of data-pipeline related issues within agreed upon SLAs
Escalate production issues to appropriate management levels, proportionate to the severity and complexity of the issue
Provide updates to customers during ongoing incidents; provide accurate, timely and frequent communication
Assist users with troubleshooting issues via multiple channels (chat, email, text, phone call etc.)
Maintain high quality and relevant technical documentation for data product and pipelines
Create incident summary reports, release notes, troubleshooting guides and runbooks
Develop tools and features that automate key support tasks and reduce manual effort
Continuously look for ways to reduce production support ticket volume; deliver enhancements to pipelines and suggest improvements to other engineers
Work with development and different teams to improve performance & configuration
Implement monitoring & alerting for critical components of platform
Migrate code from dev to production
Apply hot fixes, maintenance packages, & perform upgrades
Support the delivery of high quality and reliable data infrastructure
Support the design, build, and testing of new data product and data pipeline features
Maintain strong relationships with partners and stakeholders
Explore ways to enhance data quality and reliability, and provide recommendations
Collaborate with product managers, team members, customers, and other engineering teams to pilot innovative solutions and help solve our toughest problems
Consistently share best practices and improve processes within and across teams
Mentor more junior team members on the team to help them realize their full potential
This role will require 24x7 shift support, i.e., working day or night-time hours on a pre-defined schedule; this will also include holidays and weekends
Qualifications
Experience working with data technologies such as SQL, Python, PySpark, Spark, Scala, JSON, Kafka, DBT (Data Build Tool), Snowflake, Airflow and Azure Data Factory (ADF) are preferred
Experience with container orchestration services including Docker and Kubernetes, and a variety of Azure tools and services
Experience with CI/CD pipeline setup with best practices. Azure DevOps (ADO) is preferred
Knowledge of Cloud Data Ecosystems. Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure Storage are preferred
Experience designing, building, implementing, and supporting monitoring tool solutions, telemetry, alerts & monitoring using tools like AppInsights, Dynatrace, Splunk, Azure Monitor
Experience working with data technologies equivalent to SQL, Python, PySpark, Spark, Scala, JSON, Kafka, DBT, Snowflake, etc.

Experience
4+ years of professional software development or production support experience, preferably with data pipelines and data platforms
3+ years of experience with architecture and design
3+ years of experience with AWS, GCP, Azure, or another cloud service
2+ years of experience in open-source frameworks

Education
Bachelor’s degree in Computer Science, Information Systems, or equivalent education or work experience
Benefits:
At GEICO, we make sure you have the support and resources to leverage and develop your skills, secure your financial future, and take care of your health and well-being. GEICO continually seeks to provide a workplace where everyone can be their authentic self. To help achieve this goal, we support associate-led Employee Resource Groups that foster a true sense of community. Through GEICO’s competitive benefits offerings and various training and development opportunities, we have you covered with our
Total Rewards Program
that includes:
Premier Medical, Dental and Vision Insurance with no waiting period**
Paid Vacation, Sick and Parental Leave
401(k) Plan
Tuition Assistance including Direct Billing and Reimbursement payment plan options
Paid Training, Licensures, and Certificates
Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.
**Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.
GEICO is proud to be an equal opportunity employer. We are committed to cultivating an environment where equal employment opportunities are available to all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO celebrates diversity and believes it is critical to our success. As such, we are committed to recruit, develop and retain the most talented individuals to join our team
#LI-PK1 #DICE

GEICO will consider sponsoring a new qualified applicant for employment authorization for this position.

Annual Salary
$82,000.00 - $185,000.00
The above annual salary range is a general guideline. Multiple factors are taken into consideration to arrive at the final hourly rate/ annual salary to be offered to the selected candidate. Factors include, but are not limited to, the scope and responsibilities of the role, the selected candidate’s work experience, education and training, the work location as well as market and business considerations.","$133,500 /yr (est.)",10000+ Employees,Subsidiary or Business Segment,Insurance,Insurance Carriers,1936,$10+ billion (USD)
"HX5, LLC
4.5",4.5,"Niceville, FL",Data Engineer Journeyman,"Data Engineer Journeyman
Scientist and Engineer III
Eglin AFB, Florida
Niceville, Florida
HX5 is an award-winning provider of engineering, research and development, and technical services to clients such as NASA and the Department of Defense. Founded in 2004, HX5 is a fast-growing veteran- and woman-owned company with locations nationwide.
HX5 is currently seeking a Data Engineer to join the 417 FLTS team at Eglin AFB, Florida.
Essential Duties and Responsibilities:
Develop, maintain, and manage data tools as an integral part of multiple C-130 test teams.
Support testing as a Data Engineer; involved in the development of test objectives, test methods, identification of instrumentation, and test support equipment requirements.
Use statistical methods and tools to plan for and report on test activities.
Develop data collection logs, coordinate with test support agencies and ranges, and perform other planning tasks to support the full-spectrum developmental test and evaluation
Perform analysis of technical specifications data and system design documents.
Participate in test execution by performing data collection and reduction, data analysis, assessing systems effectiveness, and test reporting (results and findings).
Education and/or Experience:
A bachelor's degree and three (3) years of experience;
OR an Associate’s degree may be acceptable with combined additional years of experience
Ability to work as part of a test team
Proficiency in the use of Microsoft Office applications including Excel
Proficiency in one or more programming languages used in data science (for example: SQL, Python, Java, MATLAB)
Preferences:
Knowledge of business intelligence tools (e.g., Tableau, Power BI)
Knowledge and experience in statistical, data mining, and machine learning techniques: GLM/Regression, Random Forest, Boosting, Trees, simulation, clustering, neural networks, etc.
Prior experience using distributed data/computing tools: Hadoop, Hive, Spark, MySQL, etc.
Position Type/Expected Hours of Work:
This is a full-time position requiring 40 hours per week and offers a flexible work schedule Monday through Friday during core business hours.
Other Position Requirements:
Proof of U.S. Citizenship is a requirement for this position.
Must be able to complete a U.S. government background investigation.
Must be able to obtain and maintain a Secret clearance.
Must be able to travel as necessary.
HX5 offers a competitive salary and benefits package to include:
Relocation Assistance
Medical/Dental/Vision Insurance
401(k) plan with Company Match
Paid Holidays
Accrued Paid Time Off
Life Insurance
Tuition Reimbursement
Identity Protection
Medical and Dependent Care Flexible Spending Accounts
Commuter/Transit Spending Accounts
Group Legal Coverage Options
Pet Insurance
HX5, LLC is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.
HX5, LLC is a Drug Free Workplace Employer.
ACCESSIBILITY NOTICE:
If you need a reasonable accommodation for any part of the employment process due to a physical or mental disability, please call (850) 362-6551.
CJ","$74,202 /yr (est.)",1001 to 5000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2004,$100 to $500 million (USD)
"INTEL
4.1",4.1,"Hillsboro, OR",Software Engineer / Data Analyst - Graphics and AI,"Job Description

The Graphics and AI Engineering Evangelism and Enablement team is looking for a software engineer who can help set our client products for success by looking at strategic opportunities between GPU IPs, API features and workloads. This person will work in an ever-changing fast paced environment and will integrate deeply with the engineering teams to build a strong understanding of key technologies, software APIs and workloads related to graphics and AI.
You will be responsible for, but not limited to:
Build data-based analysis and recommendations to help drive cross-organizations alignment on roadmap strategy and next-gen workloads.
Understand the key APIs, tools and frameworks used for graphics and AI development.
Run graphics and AI workloads analysis with internal and third party tools.
Identify opportunities to better align IPs and software stack improvements with developers’ needs.
Create content, including slides and visual presentations of data to illustrate and contextualize recommendations to the broader team.
Contribute to building a culture oriented toward serving the changing client computing well in a competitive environment.

Qualifications

You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates.
Minimum Qualifications:
Bachelor’s degree in computer science, electrical engineering, computer engineering or any STEM related field with:
3+ years of experience real-time graphics workloads and APIs (1-2 years)

Preferred Qualifications:
Master’s degree in computer science, electrical engineering, computer engineering or related field
1+ years of experience running workloads analysis with Intel GPA or similar third-party tools.
1+ years of experience with AI accelerated workloads is desirable.
Proven experience articulating technical concepts.

Inside this Business Group

The Client Computing Group (CCG) is responsible for driving business strategy and product development for Intel's PC products and platforms, spanning form factors such as notebooks, desktops, 2 in 1s, all in ones. Working with our partners across the industry, we intend to continue to advance PC experiences to deliver the real-world performance people demand. As the largest business unit at Intel, CCG is investing more heavily in the PC, ramping its capabilities even more aggressively, and designing the PC experience even more deliberately, including delivering a predictable cadence of leadership products. As a result, we are able to fuel innovation across Intel, providing an important source of IP and scale, as well as help the company deliver on its purpose of enriching the lives of every person on earth.
Other Locations

US, OR, Hillsboro; US, CA, Santa Clara
Covid Statement

Intel strongly encourages employees to be vaccinated against COVID-19. Intel aligns to federal, state, and local laws and as a contractor to the U.S. Government is subject to government mandates that may be issued. Intel policies for COVID-19 including guidance about testing and vaccination are subject to change over time.
Posting Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.
Benefits

We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html

Annual Salary Range for jobs which could be performed in US, California: $102,540.00-$153,580.00
Salary range dependent on a number of factors including location and experience

Working Model

This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs.

JobType
Hybrid","$128,060 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1968,$10+ billion (USD)
"Microsoft
4.3",4.3,"Houston, TX","Senior Software Engineer (Data), Industry Solutions Engineering","Do you enjoy solving problems, writing software, and working with customers? Do you wake up hoping to find time to learn a bit more about how to containerize compute workloads? Work with high scale data? Or build end to end engineering deployment systems? Do you want to join a team where learning about new technology is part of our work every day?

The Industry Solutions Engineering (ISE) team is a global engineering organization that works directly with customers looking to leverage the latest technologies to address their toughest challenges. We work closely with our customers’ engineers to jointly develop code for cloud-based solutions that can accelerate their organization. We work in collaboration with Microsoft product teams, partners, and open-source communities to empower our customers to do more with the cloud. We pride ourselves in making contributions to open source and making our platforms easier to use.

We develop solutions side-by-side with our customers through collaborative innovation to solve their challenges. This work involves the development of broadly applicable, high-impact solution patterns and open-source software assets that contribute to the Microsoft platform. In this role, you will be working with engineers from your team and our customers’ teams to apply your skills, perspectives, and creativity to grow as engineers and help solve our customers’ toughest challenges.

ISE is part of the Microsoft Industry Solutions organization and is a global organization of over 16,000 strategic sellers, industry experts, elite engineers, and world-class architects, consultants, and delivery experts who work together to bring Microsoft’s mission of empowerment – and cutting-edge technology - to life for the world’s most influential customers. We are on the front lines of innovation, working side-by-side with customers to drive value across the entirety of their digital transformation journey.

Our team prides itself on embracing a growth mindset, inspiring excellence, and encouraging everyone to share their unique viewpoints and be their authentic selves. Join us and help create life-changing innovations that impact billions around the world!

As a Senior Software Engineer (Data), you will team up with other Industry Solutions engineers on customer engagements involving Microsoft’s Data offerings. We understand that most technologies are evolving very quickly, so broad experience in the Data space and the ability to quickly upskill and unblock others is the key to success. By interacting with our customers’ engineering teams and Microsoft’s product engineering teams, you will develop real-world technical experience that helps customers grow their business and Microsoft to improve our products and services.

At Microsoft, we are seeking people who have a passion for the positive impact technology can have on communities and for making a difference in the world. Within ISE, you will find a wide range of backgrounds, perspectives, personal and cultural experiences which are vital to our success with our customers. It’s an informal and flexible work environment and you’ll be welcome to work in the way that best enables you to get your job done.

We invest in your health, wellness, and financial future by offering a competitive package including a wide range of benefits built around your personal needs and those close to you.

Responsibilities
Understand User Requirements
Identify deep insights from customer engagements and partner with the product group on using customer needs and insights to guide future product roadmap
Design
Participate in architecture design sessions and coding sprints working alongside Industry Solutions Engineering engineers and customer engineers to help them make good design decisions specifically around building solid Data solutions.
Coding
Be a hands-on software engineer where needed, with ability to write quality code.
Bring Data & AI capability to the existing Industry Solutions Engineering crew that has end-to-end ownership of the customer engagement, not adding extra capacity to work on any technology.
Collaboration
Collaborate with other members of the team and the broader organization to strategically invest in building reusable assets and playbooks, leveraging the experience of delivering quality solutions to customers
Qualifications
Required/Minimum Qualifications
Bachelor's Degree in Computer Science, or related technical discipline AND 4+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR equivalent experience.
3+ years experience with Spark (Databricks or Synapse) or Modern Data Architectures such as Modern Data Warehouse and Data Mesh.
Preferred Qualifications:
Familiarity with the Microsoft Azure cloud or similar experience with another cloud platform
Working with Transactional Systems (either NoSQL or traditional RDBMS)
Flexibility to travel when it would be more efficient and effective to collocate with the customer or ISE engineering crew, and for occasional ISE-wide events but also a willingness to work with a geographically-dispersed virtual team
Hands-on experience from design through implementation of large-scale distributed data systems, setting examples for good data engineering practices, CI/CD and coding along the way
Proven experience providing technical leadership, drawing insights and communicating (both written and verbal) effectively with stakeholders
Software Engineering IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

#ISEngineering
#ARTFY24H1

Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.","$165,200 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1975,$10+ billion (USD)
"Google
4.4",4.4,"Seattle, WA","Senior Software Engineer, Google Cloud Data Management","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Sunnyvale, CA, USA; Kirkland, WA, USA; Seattle, WA, USA.
Minimum qualifications:
Bachelor’s degree or equivalent practical experience.
5 years of experience with software development in one or more programming languages, and with data structures/algorithms.
3 years of experience testing, maintaining, or launching software products, and 1 year of experience with software design and architecture.


Preferred qualifications:
Master's degree or PhD in Computer Science or related technical field.
1 year of experience in a technical leadership role.
Experience developing accessible technologies.
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.
With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.
Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
The US base salary range for this full-time position is $157,000-$235,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Write and test product or system development code.
Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies.
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"California Air Resources Board
4.1",4.1,"Sacramento, CA",Carbon Market Data Program Engineer,"This is a repost. If you have previously applied for this position, there is no need to reapply.
Do you have an engineering background and experience with either designing programs to evaluate financial transactions or overseeing and implementing environmental programs using emissions data and forecasts? Are you interested in working at the forefront of global climate policy and helping to monitor and evaluate carbon market trading data and related greenhouse gas program activities?
The Market Monitoring Section of the Climate Change Program Evaluation Branch in the Industrial Strategies Division has an opening for an Air Resources Engineer (ARE) to serve in a critical role in the operation and oversight of the California Cap-and-Trade Program (Program), and to assist in the continued implementation and development of the Cap-and-Trade Regulation. The individual selected for this position should have an engineering background, programming expertise, and demonstrated abilities to perform market trade data analyses and to evaluate emissions data sets for compliance with the Program. The candidate will serve as the section’s market data engineer to help update existing monitoring programs and analyses used for surveilling transactions of carbon allowances and offset credits to ensure these transactions conform to Program market rules. The ARE will also draft market data reports, and develop automated market tools, such as data dashboards and data inventory checks, using R, SAS, or Python to develop written assessments and forecasts of the carbon market.
The Market Monitoring Section is responsible for overseeing the carbon market and tracking activities that occur in secondary markets, including derivatives and futures trading that can impact the behavior of entities registered to the Program. This position plays an integral role in the planning, evaluation, development, and implementation of market monitoring and market surveillance strategies. Under the direction of an Air Resources Supervisor I, the successful candidate will work as a member of a team to prepare carbon allowance supply and demand forecasts, investigate market transaction data, review business disclosures and filings, and surveil corporate structure and business relationships to protect the integrity of the carbon market as the market operator and State regulator.
The ARE will become a subject matter expert in the Cap-and-Trade Regulation and in evaluating entities registered in the carbon market for conformance with the Regulation and market rules and in developing the tools needed to perform such evaluations. The ARE will analyze an array of market data, including market transaction information, entity registration disclosures, and corporate associations and structures, and periodically update market analysis tools as necessary to respond to new market information that accounts for changing state, federal, and other jurisdiction program authority and requirements. The incumbent will work with a diverse group of authorities, including other California state agencies and federal agencies, to ensure robust oversight of the markets for compliance instruments. The ARE will assess entity behavior, auction participation information, and data on transfers and holdings of compliance instruments. This position will work with a diverse and highly skilled team to prepare internal briefing memos and market data reports, and, when necessary, work with CARB's Legal Office on investigations of potential market rule violations. The ARE may work with staff and stakeholders to develop regulatory amendments, conduct public consultations and workshops, and produce regulatory documents and guidance materials.
NOTE: IF SELECTED FOR THE POSITION, YOUR SALARY OFFER IS DETERMINED BY WHAT YOU INCLUDE ON YOUR STANDARD STATE APPLICATION (STD. 678). PLEASE INCLUDE A DETAILED DESCRIPTION OF ALL RELEVANT EXPERIENCE AND EDUCATION IN YOUR STATE APPLICATION (STD.678) WHEN APPLYING.
You will find additional information about the job in the Duty Statement.
Working Conditions
The positions at the CARB may be eligible for telework with in-person attendance based on the operational needs of the position under Government Code 14200 for eligible applicants residing in California, subject to the candidate meeting telework eligibility criteria set forth in the CalEPA telework policy and/or future program need. Employees not residing in California are not eligible for telework. Regardless of hybrid telework eligibility, all employees may be required to report to the position’s designated headquarters location at their own expense, as indicated on their duty statement.
Position located in a high-rise building.
Requires being stationary, consistent with office work, for extended periods.
Standard office environment (artificial lighting, controlled temperature, etc.).
Daily use of a personal computer, office equipment, and/or telephone.
Remote work is offered based on a telework agreement. This position requires some in-person office headquarters work.
Job Type: Full-time
Pay: $6,175.00 - $11,567.00 per month
Benefits:
Dental insurance
Health insurance
Paid time off
Retirement plan
Vision insurance
Schedule:
8 hour shift
Work Location: In person","$8,871 /mo (est.)",1001 to 5000 Employees,Government,Government & Public Administration,State & Regional Agencies,1968,$100 to $500 million (USD)
"California ISO
4.5",4.5,"Folsom, CA",Sr Data Center Infrastructure Engineer (On-site),"Company Description

The California Independent System Operator (ISO) manages the flow of electricity across the high-voltage, long-distance power lines that make up 80 percent of California's power grid. We safeguard the economy and well-being of 30 million Californians by operating the grid reliably 24/7.
As the impartial grid operator, the California ISO opens access to the wholesale power market that is designed to diversify resources and lower prices. It also grants equal access to 25,865 circuit-miles of power lines and reduces barriers to diverse resources competing to bring power to customers.
The California ISO's function is often compared to that of air traffic controllers. It would be grossly unfair for air traffic controllers to represent one airline and profit from allowing that company's planes to go through before others. In the same way, the California ISO operates independently—managing the electron traffic on a power grid we do not own—making sure electricity is safely delivered to utilities and consumers on time and reliably.
Relocation assistance is available.

Job Description

Under the general direction of the Manager, responsible for designing, implementing, and maintaining the physical infrastructure and systems that support data center operations. Performs regular installations and onsite support for equipment located in the data center, including servers, storage systems, network devices, and power distribution units (PDUs). Identifies and resolves issues promptly to minimize downtime and optimize performance. Performs troubleshooting and resolution of layer 1 (physical) issues related to all equipment, including cables, connectors, and interfaces.
What You Will Be Doing:
Maintenance and Troubleshooting: Performs regular installations and onsite support for equipment located in the data center. Responds to requests for installation and troubleshooting of both network and storage cabling. Coordinates the organization of asset storage areas and data centers, including power and cooling needs of assets within the data centers.
Documentation and Reporting: Maintains accurate and up-to-date documentation of data center infrastructure, including equipment inventory, network diagrams, cable management, and maintenance logs. Generates regular reports to track key performance metrics, identify trends, and propose improvement initiatives.
Capacity Planning: Monitors and analyzes data center capacity, including power usage, space utilization, and cooling efficiency. Develops and implements capacity planning strategies to ensure the availability and scalability of infrastructure resources.
Design and Implementation: Collaborates with cross-functional teams to design and implement data center infrastructure solutions, including power distribution, cooling systems, cabling infrastructure, rack layouts, and network connectivity. Ensures compliance with industry standards and best practices.

Qualifications

Level of Education and Discipline:
A Bachelor's degree (BA, BS) or equivalent education, training or experience in Information Technology, Business Administration, or related technical field. Master’s degree preferred.
Amount of Experience:
Equivalent years of education and training, plus five (5) or more years related experience.
Certifications:
BICSI Certification (preferred)
ITAM Accreditation
Type of Experience:
Experience in data center operations, including installation and troubleshooting of network and storage cabling, capacity planning, and designing infrastructure solutions.
Additional Skills and Abilities:
Must be able to work effectively in a team environment as facilitator and team member. Excellent analytical, verbal and written communication and documentation skills required, with a demonstrated attention to detail. Ability to use deductive reasoning and analytical thinking with sound judgment and decision-making skills. Excellent interpersonal and conflict resolution skills are also essential. Must be self-starting and willing and able to work independently in a dynamic corporate organization under pressure of tight deadlines and aggressive expectations. Self-motivated, problem solving skills and the ability to influence others without direct authority.

Additional Information

The pay range for the Sr Data Center Infrastructure Engineer is $46.52 - $77.53 per hour.",$62.03 /hr (est.),501 to 1000 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1997,$25 to $100 million (USD)
"Quest Global
3.8",3.8,"Phoenix, AZ",Data and Automation Engineer,"Quest Global is an organization at the forefront of innovation and one of the world’s fastest growing engineering services firms with deep domain knowledge and recognized expertise in the top OEMs across seven industries. We are a twenty-five-year-old company on a journey to becoming a centenary one, driven by aspiration, hunger and humility.
We are looking for humble geniuses, who believe that engineering has the potential to make the impossible, possible; innovators, who are not only inspired by technology and innovation, but also perpetually driven to design, develop, and test as a trusted partner for Fortune 500 customers.
As a team of remarkably diverse engineers, we recognize that what we are really engineering is a brighter future for us all. If you want to contribute to meaningful work and be part of an organization that truly believes when you win, we all win, and when you fail, we all learn, then we’re eager to hear from you.
The achievers and courageous challenge-crushers we seek, have the following characteristics and skills:

Roles & Responsibilities:
Work with product owner to identify the data requirements and design data pipeline
Develop data pipelines for test engineering products
Design and develop data models for machine data originated from test cells
Support the development of real time data pipeline for test engineering IoT
Report project status during regular internal and external meetings. Typical reports would include updates on project status, assumptions, information needed, and overall program health
Required Skills (Technical Competency):
Ability to Read & Understand engineering drawings
Significant experience with data systems for Aerospace test engineering applications
Experience with Facility Controls in Aerospace test engineering applications
Experience with Engine Control Systems within engine test cells
Experience with both SQL and NoSQL-based systems
Experience with: Data Pipeline, Data Warehouse, Data Analytics, Data Modeling, building data engineering pipelines for performance and scalability, automation of data flow, building multiple unique but similar data pipelines to support specific test requirements
Excellent communication and coordination capabilities

Desired Skills:
Experience working in an Aerospace engines test engineering environment
Experience with both local and cloud-based environments
Ability to express technical information in a clear and simple way
Work as a team member in a technical project environment. Must be self-motivated and able to think 'outside the box'

Physical Requirements & Work Environment:
Primarily Office Environment
Substantial amounts of telephone and computer work
Heavily Regulated Industries with strict adherence to procedures
Flexibility to meet business deadlines by staying late or arriving early
Typical 8 hour days plus lunch / 40 hour weeks / core (required) hours are 9AM to 4PM
Ability to use personal transportation to visit customer locations
Due to the nature of the work, all candidates must be a US Citizen
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Job Type
Full Time-Regular
Experience Level
Mid Level
Total Years of Exp
3 - 6","$85,941 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,1997,$500 million to $1 billion (USD)
"Meta
3.9",3.9,"Menlo Park, CA",Data Center Network Engineer,"The scale of the network and its continuous expansion presents an opportunity to work on and solve interesting engineering challenges in the datacenter network domain. We constantly push the boundaries of what is possible. We create new and innovative ways of designing and operating our global datacenter networks and do it at scale with efficiency. We imagine what our tomorrow is going to be and make it a reality.Data Center Network Engineers at Meta are hybrid software and network engineers who design, build, and operate our worldwide Data Center network. This team owns the complete lifecycle of the Data Center network, which includes areas of planning, design, product definition, QA, deployment, and monitoring. Simple, elegant, and scalable network design, automation, and data analytics are the keys to meeting our demands. In this role, you will be part of a team that is responsible for conceiving design solutions, developing and deploying network software, systems, and tools that keep the Data Center network operating at maximum reliability, scalability, and efficiency.


Data Center Network Engineer Responsibilities:
Design network topologies and configuration for the DC Fabric networks
Develop IP addressing and routing policy intent in the DC
Create deployment packages and maintain as-built documentation for installed network gear
Establish and implement global best practices and contribute to the design of new scalable network solutions
Define and partner with network hardware, software, and vendor teams on the development of network platforms (switch and optics)
Partner with the in-house SWE, Tooling, Planning, Simulation, and Delivery teams to codify the network designs
Participate in an on-call rotation to support the global datacenter network infrastructure 24x7
10% of travel required



Minimum Qualifications:
5+ years of work experience responsible for designing, deploying and operating large-scale networks
Experience configuring and troubleshooting routing and switching protocols (BGP, IS-IS, OSPF, MPLS, RSVP-TE)
Working knowledge of network protocols (TCP/UDP, DHCP, DNS) and experience with IPv4 and IPv6
Experience working in a multi-vendor environment with hands-on experience with networking hardware
Experience in at least one programming language like Python, Go, C/C++ for developing automation software or tooling
Working knowledge of physical infrastructure design including structured cabling and fiber-optic cabling
Experience managing multiple projects simultaneously and deliver against deadlines
Experience working in global team environments and solve problems
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.



Preferred Qualifications:
Working knowledge of 40/100/400G Ethernet and CWDM, DWDM and optical transport network technologies
Understanding of different Optics and internals of a switch ASIC
Familiarity with the Linux based systems
Technical leadership experience





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$173,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Global Atlantic Financial Group Opportunities
4.1",4.1,"Boston, MA",Senior Azure Data Engineer,"All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com.
COMPANY OVERVIEW
Global Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.

Global Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us.
We use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling.
SUMMARY
The Finance Platform Developer role partners with the Actuary team, IT data team and primary vendor to provide data development, support, and administration for the Actuarial Modeling/Data Management Platform. This position will be accountable for managing the data lifecycle and development throughout the Actuarial Modeling process.
This position can sit in our Boston or Des Moines offices.
Key responsibilities will include the following:
New Requests/Builds
Collaborate with Actuary Model Development to support any data needs for models
Collaborate with Actuary Valuation to support model analytics and approval workflow
Define backlog items and requirements for IT Data team and other supporting IT areas
Participate in testing and verification of technical solutions
General Support
Become a subject matter expert in Actuarial Modeling Platform Data Management capabilities
Is primary administrator of Actuarial Modeling Platform and appropriately manages required administrative tasks if needed
Responsible for the regular maintenance, updates, fixes and upgrades. This could include testing after upgrade or facilitating UAT
Ensures platform is running at optimal performance and levels
Maintain application run books to ensure appropriate documentation exists
Provide training to new and existing users on current and future functionality
Production Process
Manage and facilitate all incidents from Priority 1 to Priority 4, which includes, but not limited to, providing support to users of applications, responding to user-based questions, tickets and assists with troubleshooting issues within platform.
Manage day-to-day operational and tactical aspects of multiple projects or requests
Provides on-call assistance as requested, for after-hours issues and support needs
Resolve incidents if able to, otherwise escalate as needed (provide tier-2 incident response)
SKILLS
General development skills with proven experience across 2+ programming languages
Understanding of Life and Annuity insurance a plus
Experience working with technology vendors & Actuaries
Demonstrates excellent interpersonal communication skills and documentation skills
Proven Data management skills with understanding of Data flows across different platforms
Able to manage work across a development team
Work cross-functionally within IT, with an emphasis working with a data team
Self-disciplined, able to work independently, but also able to take direction when necessary
Self-motivated to identity and resolve issues and in advancing personal knowledge
Hands on experience with GITLAB
QUALIFICATIONS
An undergraduate degree in an IT related field or similar combination or education and experience
Experience working on Life and Annuity products
2+ years' experience in Data Integration and Data Management
Experience working in cloud environments
Hands on experience with SAS programming
Must have
Experience in the following technologies –Azure Data Factory and PowerBI
Experience in Data Integration and Data Management
Experience working with and actuarial or finance

Global Atlantic's base salary range is determined through an analysis of similar positions in the external labor market. The annual base salary range provided in this posting for this position is a nationwide market range and represents a broad range of salaries for this role across the country. Base pay is just one component of Global Atlantic's total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k), as well as a company match on your contributions), and sales incentives. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives. The base salary range for this role is $84,800 to $155,000.

#LI-AO1
#LI-Hybrid
TOTAL REWARDS STATEMENT
Global Atlantic's total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.
We are active in our communities-
New York: Red Hook Conservancy, Girls Who Invest and The Bowery Mission
Boston: Cradles to Crayons, Project Bread, Let's Get Ready, Rise Against Hunger, Salvation Army and many other local volunteer organizations in around the Boston area
Hartford: Habitat for Humanity, Foodshare, Humane Society, Hands on Hartford, Mercy Shelter and Dog Star Rescue
Indianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation
Batesville: American Cancer Society Relay for Life, Angels of Giving, Margaret Mary Health Foundation, Ripley County Community Foundation, Safe Passage, Batesville High School Sponsorships, local area youth sports and food pantries, as well as many others
Des Moines: United Way, Central Iowa Shelter & Services, Junior Achievement of Central Iowa and Make a Wish Foundation
Berwyn: Food drive and will be planning an event to help a local family over the holidays
Atlanta: Packaged Good Organization, which helps the most vulnerable community members with providing personalized care packages for people in need including the elderly, our armed forces, the homeless and hospitalized kids
Bermuda: Sponsor of a weekly feeding program operated by The Hamilton Seventh-Day Adventist Church
Social platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.
Global Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws. More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.
Employees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com.
Please click on the below links to learn more about Global Atlantic.
Global Atlantic Privacy Statement","$119,900 /yr (est.)",1001 to 5000 Employees,Company - Private,Insurance,Insurance Carriers,2004,Unknown / Non-Applicable
"Danfoss
4.0",4.0,"Van Wert, OH",Senior Data Engineer (On-Site),"Requisition ID:
35156

Job Location(s):
Van Wert, OH, US

Job Description
The Danfoss Van Wert, Ohio plant is looking for a Senior Data Engineer to develop our digital manufacturing initiatives across the site in support of our world-class manufacturing program. As a Senior Data Engineer, you will be leading projects to facilitate data collection while building innovative visualizations and dashboards, with the objective to further improve Safety, Quality, Delivery, and Cost.
Job Responsibilities
Analyze and interpret manufacturing data from multiple sources to extract useful information about the operations
Support in data-driven analysis to identify production related inconsistencies and opportunities for continuous improvement activities
Create and maintain existing dashboards used for real time data visualizations
Lead Industry 4.0 projects to automate data collection and increase machine uptime
Develop digital factory management boards to provide daily results of our KPI’s
Provide training for end users of dashboards and reporting tools
Collaborate across functions to define, develop, and improve data collection and reporting tool s to support long term business objectives
Background & Skills
At Danfoss, we believe that a diverse and inclusive workplace fosters creativity, innovation, and a broader perspective in decision-making. When you consider this job posting, do you feel like your profile is not a perfect match? Numerous studies have found that women and people of color are more likely to apply only when they meet all requirements listed in the job posting. Even if you do not check all the boxes, we encourage you to apply anyway. We are curious to find out how you can bring new insights to the role or to Danfoss as an organization.

The ideal candidate possesses these skills.

Required (basic) qualifications

Bachelor’s Degree in Computer Science, Statistics, Industrial Engineering or Mathematics preferred or equivalent experience in this type of role
Five (5) years manufacturing experience
Preferred qualifications

Project Management experience
Lean Six Sigma training and/or experience applying tools
Job Criteria

Experience working with large data sets and determining best ways to analyze and measure KPI’s
Excellent written and verbal skills, including proficiency with Microsoft Office Suite (Advanced Excel, Access, Outlook, PowerPoint, etc.)
Experience with advanced analytics platforms such as Power BI, Tableau, or others
Strong communication skills with the ability to communicate up and down the organization
Strong problem-solving skills
Employee Benefits
We are excited to offer you the following benefits with your employment:

Bonus system

Paid vacation

Flexible working hours

Pension plan

Personal insurance

Communication package

Opportunity to join Employee Resource Groups

Employee Referral Program

This list does not promise or guarantee any particular benefit or specific action. They may depend on country or contract specifics and are subject to change at any time without prior notice.
Danfoss – Engineering Tomorrow
At Danfoss, we are engineering solutions that allow the world to use resources in smarter ways - driving the sustainable transformation of tomorrow. No transformation has ever been started without a group of passionate, dedicated and empowered people. We believe that innovation and great results are driven by the right mix of people with diverse backgrounds, personalities, skills, and perspectives, reflecting the world in which we do business. To make sure the mix of people works, we strive to create an inclusive work environment where people of all backgrounds are treated equally, respected, and valued for who they are. It is a strong priority within Danfoss to improve the health, working environment and safety of our employees.
Following our founder’s mindset “action speaks louder than words”, we set ourselves ambitious targets to protect the environment by embarking on a plan to become CO2 neutral latest by 2030.
Danfoss is an EO employer and VEVRAA Federal Contractor. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, veteran status, or other protected category.
Danfoss engineers solutions that increase machine productivity, reduce emissions, lower energy consumption, and enable electrification.

Our solutions are used in such areas as refrigeration, air conditioning, heating, power conversion, motor control, industrial machinery, automotive, marine, and off- and on-highway equipment. We also provide solutions for renewable energy, such as solar and wind power, as well as district-energy infrastructure for cities.

Our innovative engineering dates back to 1933. Danfoss is family-owned, employing more than 42.000 people, serving customers in more than 100 countries through a global footprint of 95 factories.

Danfoss engineers solutions that increase machine productivity, reduce emissions, lower energy consumption, and enable electrification.

Our solutions are used in such areas as refrigeration, air conditioning, heating, power conversion, motor control, industrial machinery, automotive, marine, and off- and on-highway equipment. We also provide solutions for renewable energy, such as solar and wind power, as well as district-energy infrastructure for cities.

Our innovative engineering dates back to 1933. Danfoss is family-owned, employing more than 42.000 people, serving customers in more than 100 countries through a global footprint of 95 factories.","$83,616 /yr (est.)",10000+ Employees,Company - Private,Manufacturing,Machinery Manufacturing,1933,$10+ billion (USD)
"Parts Town
3.8",3.8,"Plattsburgh, NY",Data Engineer (On-site),"See What We’re All About
As the fastest growing distributor of foodservice equipment parts, we like to do things a little differently. We believe our team should be like family. Not like a second cousin, twice removed, but more like the family you choose to be with every day. First, you have to demonstrate our core values and keep safety as your #1 priority, that’s key. But we’re also looking for unique enthusiasm, high integrity, courage to embrace change…and if you know a few jokes, that puts you on the top of our list.

Do you have a genius-level knowledge of foodservice equipment parts? If not, no problem! We’re more interested in passionate people with fresh ideas from different backgrounds. That’s what keeps us at the top of our game. We’re proud that our workplace has been recognized for its growth and innovation on the Inc. 5000 list, fifteen years in a row, and the Crain’s Fast 50 list ten times. We are honored to be voted by our Chicagoland team as a Chicago Tribune Top Workplace for three consecutive years in 2020, 2021, and 2022.

If you’re ready to roll up your sleeves, go above and beyond and put your ambition to work, all while having some fun, let’s chat – Apply Today!

Perks
Parts Town Pride – check out our virtual tour and culture!
Quarterly profit-sharing bonus
Hybrid Work schedule
Team member appreciation events and recognition programs
Volunteer opportunities
Monthly IT stipend
Casual dress code
On-demand pay options: Access your pay as you earn it, to cover unexpected or even everyday expenses
All the traditional benefits like health insurance, 401k/401k match, employee assistance programs and time away – don’t worry, we’ve got you covered.

The Job at a Glance
At Parts Town, we proudly put the PART in partnership. Do you thrive on leading the way into uncharted territory? Ok, maybe it’s not uncharted, but it’s newer for Parts Town. The Data Engineer will develop, implement, and maintain systems and processes to transform our upstream raw data into high-quality, consistent information and insights. Downstream use cases include analytics, reporting and ML/AI for the sales funnel, ecommerce metrics and customer intent, measure ROI of online and offline advertising campaigns, digital KPIs like leads, conversion rates, website traffic, email, events, and social media engagement. Whew-that’s a lot! Troubleshoot the data pipeline, document your process and workflows and work with others to provide feedback on data processes and code.

A Typical Day
Develop, monitor and maintain ETL processes from various internal and external sources into BigQuery, ensuring data quality, integrity, and consistency
Collaborate with data scientists, analysts and business partners to understand their data, business and product requirements. Provide the necessary infrastructure and tools to access and analyze the data
Optimize data pipelines and ETL processes for performance, fault-tolerance, scalability, and cost-effectiveness
Monitor, diagnose and troubleshoot data pipeline issues, ensuring data availability and reliability
Implement data security to protect sensitive information
Continuously learn about industry best practices and emerging trends in data engineering, and GCP
Collaborate with cross-functional teams (technical and non-technical) to understand business and product requirements
Document data engineering processes, best practices, procedures, and workflows
Contribute to peer-review of code and documentation and share knowledge and best practices

To Land This Opportunity
You have 3+ years of programming experience and proficient in Python and SQL
You have experience building data pipelines from scratch in traditional data warehouse environment (ETL pipelines) and cloud-based systems (ideally GCP)
You are familiar with any of the following tools: BigQuery, Airflow, Dataflow, DBT, PubSub
You obtain a strong technical background and product/business sense.
You are passionate about building version-controlled and data-intensive applications
You are flexible and adaptable to change. In fact, you thrive in change.
You speak your mind and happily provide input to drive to the right outcome.
You are detail oriented, efficient, organized, self-starter, highly productive and collaborative approach to work
Extra Awesome
You love to blaze a trail and do things that no one has ever done before.
Willing to go above and beyond, suggest new ideas and identify opportunities

About Your Future Team
You’re really in for a treat. Bring your knowledge of comics, superheroes, pop culture and music from the 80’s and 90’s and you’ll fit right in. If you like either Star Wars or Star Trek over the other, we won’t judge you…much. We like to laugh, so bring your best jokes – you will be tested.
Parts Town welcomes diversity and as an equal opportunity employer all qualified applicants will be considered regardless of race, religion, color, national origin, sex, age, sexual orientation, gender identity, disability or protected veteran status.","$79,504 /yr (est.)",501 to 1000 Employees,Company - Private,Retail & Wholesale,Wholesale,1987,$1 to $5 billion (USD)
"University of Texas at Austin
4.3",4.3,"Austin, TX","Principal Data Engineer, AWS Cloud","Job Posting Title:
Principal Data Engineer, AWS Cloud
-
Hiring Department:
University Development Office
-
Position Open To:
All Applicants
-
Weekly Scheduled Hours:
40
-
FLSA Status:
Exempt
-
Earliest Start Date:
Sep 05, 2023
-
Position Duration:
Expected to Continue
-
Location:
UT MAIN CAMPUS
-
Job Details:
Purpose
Reporting to the Director of Data Management, Advancement Data Operations (ADO) and residing on the Data Engineering and Infrastructure support team, the Principal Data Engineer will serve as a technical team lead for ADO’s modernization efforts by architecting, modeling, and building data pipelines for their nascent AWS cloud-based analytics platform.
Responsibilities
R&D for cloud computing technologies and proving applicability to projects.
Work closely with Reporting and Analytics team to build data models, schemas, complex stored procedures, and optimized queries to support high-performing reporting and advanced analytics.
Work closely with the Applications Development, Records Management, and Reporting and Analytics teams to ensure that data assets relating to both applications and business intelligence systems (warehouse, reporting systems, etc.) are accurate, consistent, and reliable.
Develop automated ETL/ELT data ingestion pipelines processing data from multiple sources and formats (ex. Oracle, Salesforce, CSV files, API endpoints, etc.). Build resilient and robust processes that can handle exceptions and failures with grace.
Work closely with Data Ops Engineer to implement testing strategies and monitoring to ensure data consistency between data sources, reports, and interfaces
Work closely with Project Coordinator and Business Analyst to ensure project stay on track and to create supplemental documentation
Required Qualifications
Bachelor’s degree with five years of relevant experience
Hands on production experience using various AWS services and technologies
Knowledge and experience of delivering CI/CD and DevOps capabilities in a data environment
A strong understanding of data modelling, data structures, databases, and ETL processes
2+ years of experience of implementing and delivering data solutions and pipelines on AWS Cloud Platform
3+ years of experience with building integrations/ETL pipelines
3+ years of experience with SQL development including writing complex queries and working with large amounts of data
2+ year of experience with database management
Stakeholder management and communication skills, including prioritizing, problem solving and interpersonal relationship building
Preferred Qualifications
Associates level or higher certification in AWS and/or AWS Data Analytics Specialty certification
Familiarity with Lakehouse architecture (including hands on experience with Delta Lake)
Familiarity with Kimball dimensional modeling concepts
Handon experience with Salesforce CRM and Salesforce data objects
Experience working with campus’s Data to Insights (D2I) UT Data Hub and UT Integrations Hub
Salary Range
$125,000 + depending on qualifications
Working Conditions
Hybrid/Flexible Work Environment
Required Materials
Resume/CV
3 work references with their contact information; at least one reference should be from a supervisor
Letter of interest
Important for applicants who are NOT current university employees or contingent workers: You will be prompted to submit your resume the first time you apply, then you will be provided an option to upload a new Resume for subsequent applications. Any additional Required Materials (letter of interest, references, etc.) will be uploaded in the Application Questions section; you will be able to multi-select additional files. Before submitting your online job application, ensure that ALL Required Materials have been uploaded. Once your job application has been submitted, you cannot make changes.
Important for Current university employees and contingent workers: As a current university employee or contingent worker, you MUST apply within Workday by searching for Find UT Jobs. If you are a current University employee, log-in to Workday, navigate to your Worker Profile, click the Career link in the left hand navigation menu and then update the sections in your Professional Profile before you apply. This information will be pulled in to your application. The application is one page and you will be prompted to upload your resume. In addition, you must respond to the application questions presented to upload any additional Required Materials (letter of interest, references, etc.) that were noted above.
-
Employment Eligibility:
Regular staff who have been employed in their current position for the last six continuous months are eligible for openings being recruited for through University-Wide or Open Recruiting, to include both promotional opportunities and lateral transfers. Staff who are promotion/transfer eligible may apply for positions without supervisor approval.
-
Retirement Plan Eligibility:
The retirement plan for this position is Teacher Retirement System of Texas (TRS), subject to the position being at least 20 hours per week and at least 135 days in length.
-
Background Checks:
A criminal history background check will be required for finalist(s) under consideration for this position.
-
Equal Opportunity Employer:
The University of Texas at Austin, as an
equal opportunity/affirmative action employer
, complies with all applicable federal and state laws regarding nondiscrimination and affirmative action. The University is committed to a policy of equal opportunity for all persons and does not discriminate on the basis of race, color, national origin, age, marital status, sex, sexual orientation, gender identity, gender expression, disability, religion, or veteran status in employment, educational programs and activities, and admissions.
-
Pay Transparency:
The University of Texas at Austin will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information.
-
Employment Eligibility Verification:
If hired, you will be required to complete the federal Employment Eligibility Verification I-9 form. You will be required to present acceptable and original
documents
to prove your identity and authorization to work in the United States. Documents need to be presented no later than the third day of employment. Failure to do so will result in loss of employment at the university.
-
E-Verify:
The University of Texas at Austin use E-Verify to check the work authorization of all new hires effective May 2015. The university’s company ID number for purposes of E-Verify is 854197. For more information about E-Verify, please see the following:
E-Verify Poster (English)
[PDF]
E-Verify Poster (Spanish)
[PDF]
Right To Work Poster (English)
[PDF]
Right To Work Poster (Spanish)
[PDF]
-
Compliance:
Employees may be required to report violations of law under Title IX and the Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act (Clery Act). If this position is identified a Campus Security Authority (Clery Act), you will be notified and provided resources for reporting. Responsible employees under Title IX are defined and outlined in
HOP-3031
.
The Clery Act requires all prospective employees be notified of the availability of the Annual Security and Fire Safety report. You may
access the most recent report here
or obtain a copy at University Compliance Services, 1616 Guadalupe Street, UTA 2.206, Austin, Texas 78701.","$125,000 /yr (est.)",10000+ Employees,College / University,Education,Colleges & Universities,1883,$1 to $5 billion (USD)
"Brightly Software Inc.
3.6",3.6,United States,Principal Data Engineer,"Description:

Who we are
Brightly, a Siemens company, is the global leader in intelligent asset management solutions. Brightly enables organizations to transform the performance of their assets with a sophisticated cloud-based platform that leverages more than 20 years of data to deliver predictive insights that help users through the key phases of the entire asset lifecycle. More than 12,000 clients of every size worldwide depend on Brightly’s complete suite of intuitive software – including CMMS, EAM, Strategic Asset Management, IoT Remote Monitoring, Sustainability and Community Engagement. Paired with award-winning training, support and consulting services, Brightly helps light the way to a bright future with smarter assets and sustainable.
About the job
We are seeking experienced data engineers to help us with rapid expansion our Data Cloud, constructing new data pipelines and buildout of the Snowflake cloud data warehouse structures for various stakeholders and analytics applications, using most modern techniques and technologies. Our modern solution features standardized data ingestion pipelines that support low latency of data updates from the sources and enable variety of analytics applications, automation and instrumentation for production support as well as agile yet robust DataOps/DevOps development lifecycle processes. This is an excellent opportunity for a data engineer that is passionate about designing, implementing and operating scalable, and efficient solutions to flow data from production systems into a data lake and data warehouse, building data structures for information delivery to consumers. These may range across new predictive models, advanced analytics, operations monitoring and automation, as well as more traditional operational reporting.
Requirements:

What you need
BS in an Engineering or Science discipline, or equivalent experience
5+ years of software/data engineering experience using Java, Scala, and/or Python, with at least 3 years experience in a data focused role
Experience in data integration (ETL/ELT) development using multiple languages (e.g., Java, Scala, Python, PySpark, SparkSQL)
Experience building and maintaining data pipelines supporting a variety of integration patterns (batch, replication/CDC, event streaming) and data lake/warehouse in production environments
Experience with AWS-based data services technologies (e.g., Kinesis, Glue, RDS, Athena, Snowflake, etc.)
Experience of working in the larger initiatives building and rationalizing large scale data environments with a large variety of data pipelines, possibly with internal and external partner integrations, would be a plus
Willingness to experiment and learn new approaches and technology applications
Knowledge and experience with various relational databases and SQL
Knowledge of software engineering and agile development best practices
Excellent written and verbal communication skills
The Brightly culture
Service. Ingenuity. Integrity. Together. These values are core to who we are and help us make the best decisions, manage change, and provide the foundations for our future. These guiding principles help us innovate, flourish and make a real impact in the businesses and communities we help to thrive. We are committed to the great experiences that nurture our employees and the people we serve while protecting the environments in which we live.
Together we are Brightly",#N/A,501 to 1000 Employees,Company - Private,Information Technology,Software Development,1999,$25 to $100 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Principal Engineer - Data, PubTech Data, Insights & Analytics","10+ years of software engineering with a proven track record of leading large-scale data projects
Knowledge of object-oriented design, data structures, and algorithms
Deep technical expertise in big data engineering and/or machine learning systems
Amazon is continuing to invest in its Advertising business to tap into the growing online advertising market. Amazon’s Publisher Technology team is looking for an Principal Engineer with experience in Big Data Engineering.

Publisher Technology Data, Insights, and Analytics team enables faster data-driven decision making for Publishers and Monetization teams by providing them with near real time data, data management tools, actionable insights, and an easy-to-use reporting experience. Our data products provide Publishers and Monetization teams with the capabilities necessary to better understand the performance of their Advertising products along with supporting machine learning at scale.

In this role, you will lead the architecture and development of data infrastructure and services. Our data products and services empower hundreds of teams across Amazon with near real time data to support big data analytics, insights, and machine learning at scale. Our structured datasets enable Scientist to train and deploy Machine learning models, provide Publishers with near real time reporting and insights of their Advertising products, and enable Engineers, Product Managers with access to structured and unstructured data. You will build scalable data-intensive infrastructure that processes petabyte size logs, catalogs, transactional data, and telemetry signals.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

Demonstrated leadership abilities in an engineering environment in driving operational excellence and best practices and mentoring other team members
You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning models
You have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modeling
Familiarity with legal compliance and changing landscape of ads and data regulations around the world
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $147,200/year in our lowest geographic market up to $286,200/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$147,200 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Conductor, Inc.
4.3",4.3,"New York, NY","Principal Engineer, Data Platform","Conductor is the world’s leading SEO platform, helping businesses accelerate organic traffic and revenue growth. Conductor’s technology helps marketers create powerful marketing content to drive high-quality traffic to their site and measure their organic performance.
Conductor is a mission-driven company with a commitment to innovation, customer success, and culture. For Conductor, success is improving the lives of all the people in our orbit—our customers, our customers' customers, our employee-owners, and our communities.
Conductor is also proud to have been recognized externally: the company was named the leader in 2020 Forrester Wave: SEO Platforms Research Report and have been top rated on G2 and TrustRadius by customers.
What are we looking for?
Conductor is seeking a seasoned product-minded engineer with extensive data architecture and data platform design experience to power massive scale SaaS applications. This leader brings deep technical data and infrastructure expertise, and partners with Product Management, Engineering, and Cloud teams to drive architecture and define, design, create, manage, and deploy highly scalable and available data systems and applications.
Reporting to the Vice President of Engineering, this leader -
Designs, develops, implements, and translates business requirements and the overall organizational data strategy, including standards, principles, data sources, storage, pipelines, data flow, data processing, and data security/ governance policies
Collaborates with data engineers, data scientists, application developers and other stakeholders to define and execute the enterprise data strategy
Communicates and defines data architecture patterns in the organization that guide the data framework
Provides technical leadership to data teams to implement secure, scalable, high-performance, and reliable data platform for AI/ML powered analytics applications and services
Embraces a strong centralized data platform to unlock insights, innovation, and intelligence in the application, and to support rapid development and iteration of capabilities for our users
Appreciates working across stacks in an organization without silos
Is motivated to understand the challenges in the SEO space, and has a passion for solving problems and not just delivering features
Influences strategic thinking across the team. Advocates for best practices, investigates new technologies and mentors other engineers.
The successful candidate must thrive in ambiguity with a strong decision-making capability along with a sense of accountability, leveraging a collaborative leadership style with a bias-to-action. The candidate must have a passion to solve hard problems with technical expertise and a growth-mindset, using strong engineering rigor and data-driven operational skills to drive the desired outcomes across global teams. Conductor is poised for significant growth and this leader is a very important stakeholder in the next phase of our company’s journey.
Who you are
A hands-on software engineer with 10+ years in systems software development including 6+ years as a data engineering technical leader building scalable and secure data platforms and systems powering intelligent applications.
An expert in concepts, principles, and implementation of data models, design, integration, transformation, and data management.
Deep knowledge of various relational (row-oriented and columnar) and non-relational (key value, document, graph, etc.) database technologies including database and storage services in open source and those provided by public cloud vendors such as AWS (preferred) and GCP.
Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, and performance.
Understands processes, roles, policies, standards, and metrics that ensure the effective and efficient use of data/information, data privacy and confidentiality, and risks and mitigations.
Extensive experience using cloud technologies, Snowflake/ Redshift/ Bigquery, Spark, Kafka, event queues, containers and orchestration (Docker, Kubernetes), storage, networking, and operating systems
A thought leader with comprehensive understanding of the data sources, data formats, and data processing challenges at scale in application verticals such as (preferably) organic marketing/ SEO, retail, content, etc.
An expert in Java and SQL programming languages
Proficiency with solution discovery and delivery using rapid prototyping, experimentation and iterative development.
Have a minimum of bachelor’s degree in Computer Science, Mathematics, or a related field. Master’s or PHD preferred.
Have excellent verbal and written communication skills – can communicate clear technical solutions to complex data problems to both technical and non-technical audiences.
Why You Should Join
Conductor is a People-First and Customer-First company. We are looking for engaged and passionate technology leaders that can raise the bar. We have built a highly collaborative culture of technical excellence with tremendous opportunity to have an immediate impact in the day-to-day life of our employees and customers and drive the company's success and growth. We all share the same values, innovate, and motivate each other to attain ambitious goals, and celebrate each other’s success.
We are made up of a diverse group of people from all backgrounds. Wherever you are from, you will find a common ground here to accelerate your career and make a difference in the organic marketing industry.
Conductor, Inc. is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Our Core Values
Design for the Future, Build for Today: Don’t be limited by the present. Anticipate, architect, and design for the long-term so that we don’t have to rework our software as we grow. But build for today in terms of quality and time to delivery.
Be Product-Minded: By knowing our customers, we can build better products that empower them and help their customers. To be a great Organic MarTech engineer one must understand the organic marketing landscape.
Innovate: Step up the game. Find new ways to solve problems. Influence the entire product. Deliver better value for our customers. Create moats for our competition. Enhance our company’s brand, and enhance your own personal brand image.
Optimize for Value: Great products focus on building value rather than chasing an artificial deadline. Embrace continuous planning that believes in delivering products when they are ready.
Value Your Time: Think harder. Don’t settle. Strive for better outcomes than the last time in the same amount of time. Automate away toil and spend your energy solving newer, bigger, more interesting problems.
Be Biased to Build Right: How you create value is very important. Prefer open source over commercial products to invent/create value and accelerate delivery. Dependency on external products for value creation increases cost and risk, impedes innovation, and discounts value.
Seek Challenges: Good engineers just solve problems. Great engineers also seek and define new challenges. Invention and value creation happens when engineers show curiosity and initiative, and participate in defining “what’s next”.
Embrace Change: When we maintain the status quo, we hold ourselves back. Have an open mind. Don’t cling to existing processes, technical biases, etc. Try something new. We all learn and grow together.
About Conductor
Conductor’s search and content intelligence platform helps marketers create and optimize content to improve visibility online.
The technology generates customer intent insights that lead to compelling content, increased traffic, and higher organic marketing ROI. Customizable dashboards and workflows guide marketers through the content creation process, empowering them to measure, refine, and demonstrate the effectiveness of their SEO and content marketing efforts.
In addition to its SaaS platform, Conductor offers a suite of services and support including site audits, site migrations, and managed services that empower in-house marketing teams and digital marketing agencies to drive results and put their customers' needs first.
Conductor's forward-thinking customers include leading global and emerging enterprise brands.
-
Compensation: Conductor maintains competitive, performance-based compensation programs.
The base salary for this role is currently up to $250,000. The actual base salary offered may vary within this range based on education, knowledge, skills, abilities, relevant experience, internal equity, and geographic location, among other factors. The actual compensation, if offered a position, will be based on these factors.
Variable compensation: In addition to base salary, this role is also eligible for a discretionary annual bonus based on attainment of corporate revenue performance targets.
Benefits: Conductor offers the following attractive benefits and perks including: 100% covered employee medical plan, a dental & vision plans, 401(k) with employer contribution, an unlimited vacation policy, 10 sick days, short-term disability, long-term disability, generous paid parental leave, Employee assistance program, flexible savings accounts, paid holidays, life and accidental death insurance, and a host of perks (YOLO Months, internet/cell phone allowance, fully stacked kitchens, etc.).
In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.
-
Conductor LLC is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Bringing in diverse perspectives and challenging our assumptions is the clear key to growth; it drives innovation, creativity, faster problem-solving, and stronger decision making. All aspects of employment including the decision to hire, promote, train, discipline, or discharge, will be based on merit, competence, performance, and business needs.
Conductor does not discriminate against any employee or applicant on the basis of race, color, ancestry, national origin, religion or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, or other characteristics protected by state or federal law or local ordinance. In addition, it is the policy of Conductor to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations and ordinances where a particular employee works.
***********************************************************************
Disclosure: Conductor cares about your privacy. We are committed to maintaining your trust by protecting and processing your Personal Information that you provide to us in accordance with Greenhouse's Privacy Policy. Please take a moment to review before submitting your application.","$143,787 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2010,$25 to $100 million (USD)
"Hopper
3.3",3.3,Remote,Senior Data Engineer - Fintech Foundation (100% remote),"Hopper is continually redefining how people travel, combining a best-in-class travel agency with a portfolio of proprietary fintech offerings that give our customers peace of mind when booking travel. More than 100M monthly active users are exposed to our products through our mobile app and a growing list of partners such as CapitalOne, Air Canada, and Spirit Airlines. With a real-time feed of 50B+ priced itineraries daily along with more than ten years of history and multiple external data sources, we have unparalleled insight about pricing and demand trends.

This is a unique opportunity to join our growing Fintech Foundation team and help millions of people travel better, for less. Our team enables our product teams to deliver new products to market faster; produce better quality pricing and provisioning models faster; and be more responsive to changing market conditions, product construction and service outages. As a Senior Data Engineer, you will be directly responsible for developing the services and tooling on our golden path for model development and delivery in collaboration with our product engineers, data scientists and product managers. This will include developing and maintaining our ETL pipelines, and ownership of several tier-one production services.
IN THIS ROLE, YOU WILL:
Specify data schemas and maintain pipelines for delivering huge volumes of real-time streaming data to our data users working in many fields
Assist with building the next generation of our predictive modeling infrastructure
Work in a complex dynamic environment with a rich API tier
Collaborate with a diverse group of people, giving and receiving feedback for growth
Execute on big opportunities, helping Hopper’s continued rise to the top of the travel industry
A PERFECT CANDIDATE HAS:
Extensive experience designing streaming data systems with tools such as GCP Dataflow, GCP PubSub, Kafka, Flink, or Akka/Pekko Streams.
Expertise with various data stores (transactional and warehouse) such as Spanner and BigQuery.
Experience with traditional batch ETL tools like Airflow is also an asset.
Familiarity with Scala (or other functional, statically typed languages) for backend development and Python for ML automation
Familiarity with machine learning techniques and technology for model development and deployment is an asset but not required
Comfortable mentoring and leading people at different stages in their career
Excel in cross-functional teams, working with Product Managers, Data Scientists, full stack Engineers, and other highly skilled specialists
Passion for quality; writing robust, performant, and testable code for our customers
Comfortable being on-call for critical production services relied upon by all of Hopper
MORE ABOUT HOPPER

At Hopper, we are on a mission to become the world’s best — and most fun — place to book travel. By leveraging massive amounts of data, advanced machine learning algorithms, Hopper combines its world-class travel agency offering with proprietary fintech products to help customers spend less and travel better. Ranked the third largest online travel agency in North America, the app has been downloaded nearly 80 million times and continues to gain market share globally.

Here are just a few stats that demonstrate the company’s recent growth:

Hopper sold around $4 billion in travel and travel fintech in 2022, up nearly 3X over 2021. In 2022, Hopper increased its revenue 2.5X year-over year.

The company’s bespoke fintech products, such as Flight Disruption Guarantee and Price Freeze, now represent 30-40% of Hopper’s total app revenue.

Given the success of its fintech products, Hopper launched a B2B initiative called Hopper Cloud in late 2021. Through this partnership program, any travel provider (airlines, hotels, banks, travel agencies, etc.) can integrate and seamlessly distribute Hopper’s fintech or travel inventory. As its first Hopper Cloud partnership,

Hopper partnered with Capital One to co-develop Capital One Travel, a new travel portal designed specifically for cardholders.

Recognized as one of the world’s most innovative companies by Fast Company four years in a row, Hopper has been downloaded over 80 million times and continues to have millions of new installs each month.

Hopper has raised over $700 million USD of private capital and is backed by some of the largest institutional investors and banks in the world. Hopper is primed to continue its acceleration as the world’s fastest-growing mobile-first travel marketplace.

Come take off with us!",#N/A,1001 to 5000 Employees,Company - Private,Hotels & Travel Accommodation,Travel Agencies,2007,Unknown / Non-Applicable
"Inteliquet, Inc",#N/A,"Washington, DC",Data Integration Engineer - Remote,"Are you passionate about driving successful implementations and data integration and to help Cancer Centers adopt a self-service data access and integrated patient matching solution? Then we want you to join our team!

At Inteliquet, we believe every patient is valuable and worthy of our very best efforts.
Our mission is to be a key connector at the intersections of clinical decision support, patient therapy, and therapeutic research and development. Envisioning a world where everyone has timely access to the best and longest-lasting therapies possible, we strive to remove barriers so that clinical trials and research work better for all stakeholders—especially the patient. Through insights, technology, and expertise we help solve one of the most difficult problems in healthcare—harnessing the data needed to quickly and accurately match patients to clinical trials and bring more trials to those patients. We focus on improving the way clinical trials work, so that trial access is available to every patient.
Job Title
Data Integration Engineer
Reports to:
Manager/Director Engineering-Integration
Functional Group:
Engineering
Location:
Remote - Company is 100% remote - always has been
Engagement:
Full-Time Position
Summary:
The Data Integration Engineer plays a vital role in ensuring outstanding project execution, delivery, and support in the implementation of Inteliquet’s software and data integration with Cancer Center oncology data sources. The Data Integration Engineer is responsible for executing project tasks, data management, data discovery, code implementations, data conversion, and on-going support of data ingestion.
Duties and Responsibilities:
This list is not comprehensive but meant to represent the most common or important duties of the position. Other duties are required and/or assigned.
Liaise with Deployment Project Management Lead on client related issues, opportunities and challenges
Participate in new system release testing and evaluation for impact to data integration efforts
Act as technical point of contact for customer integration/data product issues and involve the QA/Engineering team to debug, analyze, and fix software bugs.
Participate in data integration projects:
Develop knowledgebases, templates, and standards to ensure repeatability and quality.
Developing process workflows to increase automation and scalability.
Maintain and enforce best practices to facilitate optimized software implementation and ETL transfer of data.
Works closely with data QA and architects to ensure good data quality and sound data security.
Performing initial data validation before and after implementation.
Implement code necessary to develop data extraction, transformation and loading in SQL, SSIS, C# and other tools as necessary.
Converting and loading client data into the Inteliquet conformed data structures.
Initial integration and configuration of our software from a technical perspective.
Experience with MongoDB and/or Neo4J an advantage.
Serve as company representative to external clients. Inspire confidence in our organization and deliver results.
Contribute to the development of plans, the engagement of and integration of addition data sources with clients
Support transition efforts for clients migrating to a new EMR or other source system
Support Client Daily Needs:
Investigate and resolve data related issues.
Triage and resolve technical issues.
Minimum Requirements:
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
4 or more years related application and systems development experience
Knowledge of data processing system, design methods, techniques and standards.
Detail-oriented and proficient in data analysis, with a keen interest in data manipulation and ability to see beyond the data and draw conclusions.
Candidates with experience in medical records, bioinformatics or analytic software will be advantaged. An in-depth knowledge of oncology will be a plus, but we don't expect you to cover all areas of expertise.
Ensure compliance with company policies
Review, understanding, and compliance with HIPAA Security policies and procedures.
Safeguarding the privacy and security of protected health information
Technical Proficiencies:
Fundamental understanding and knowledge of software development environments such as, but not limited to:
MS SQL Server: TSQL, SSIS, SSRS
Languages: PowerShell, C# (optional)
MongoDB (optional)
Neo4j (optional)
Source Code Control: TFS, DevOps
Agile experienced
MS Office: used for documentation
MS Teams
Essential Job Functions:
Critical features of this job are described below. They may be subject to change at any time due to reasonable accommodation or other reasons.
Soft-skills: Must be able to effectively communicate with others; complete and understand complex analysis of numbers; read, analyze and interpret written materials; develop team to meet company standards; ensure compliance with company policies; respond appropriately to feedback to make improvements; maintain positive working relationships; troubleshoot and solve problems.
Physical: Must be able to hear and verbally communicate for hours at a time, use computer equipment. Moderate noise level and limited exposure to physical risk.
Knowledge, Skills, and Abilities Required:
Knowledge of modern business communication, office procedures and methods. Skill to use a personal computer and various software packages such as Microsoft Office Suite. Ability to establish priorities, work independently with minimal supervision, and facilitate teamwork.
Equipment Used:
Headsets, telephones, computer, other office equipment as needed.","$101,498 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Abercrombie and Fitch Co.
3.6",3.6,"Columbus, OH","Senior Engineer, Data Insights (Remote)","Company Description

Job Description
The primary responsibility of the Senior Engineer, Global Data & Insights - Data Management is to build data pipelines, model and prepare data, perform complex data analysis to answer Business questions, build and automate data pipeline and quality framework to enable and promote self service data pipelines, assist in operationalizing the AI / ML Engineering solutions. This role is expected to lead and guide other team members and evangelize the design patterns as well as coding standards.
This role plays an active part in our Data Modernization project to migrate the from on-prem platforms such as IBM Netezza to cloud project
What Will You Be Doing?
Team up with the engineering teams and enterprise architecture (EA) to define standards, design patterns, accelerators, development practices, DevOps and CI/CD automation
Create and maintain the data ingestion, quality testing and audit framework
Conduct complex data analysis to answer the queries from Business Users or Technology team partners either directly from Analysts or stemmed from one of the Reporting tools suchs PowerBI, Tableau, OBIEE.
Build and automate the data ingestion, transformation and aggregation pipelines using Azure Data Factory, Databricks / Spark, Snowflake, Kafka as well as Enterprise Scheduler tools such as CA Workload automation or Control M
Setup and evangelize the metadata driven approach to data pipelines to promote self service
Setup and continuously improve the data quality and audit monitoring as well as alerting
Constantly evaluate the process automation options and collaborate with engineering as well as architecture to review the proposed design.
Demonstrate mastery of build and release engineering principles and methodologies including source control, branch management, build and smoke testing, archiving and retention practices
Adhere to and enhance and document the design principles, best practices by collaborating with Solution and in some cases Enterprise Architects
Participate in and support the Data Academy and Data Literacy program to train the Business Users and Technology teams on Data
Respond SLA driven production data quality or pipeline issues
Work in a fast-paced Agile/Scrum environment
Identify and assist with implementation of DevOps practices in support of fully automated deployments
Document the Data Flow Diagrams, Data Models, Technical Data Mapping and Production Support Information for Data Pipelines
Follow the Industry standard data security practices and evangelize the same across the team.
What Do You Need To Bring?
Bachelor’s degree in Computer Science or Engineering or Mathematics or related field and 5+ years of experience in various cloud technologies within a large-scale organization
Personal Attributes: Self-starter, Collaborative, Curious, Strong work ethic, highly motivated, Team oriented
Experience designing and building complex data pipelines in an agile environment
Expertise on data analysis and wrangling using sql, python, databricks
Experience with modern cloud development and design concepts; software development lifecycle; multi-developer code versioning and conflict resolution; planning, design, and problem resolution enterprise data applications / solutions
Demonstrated ability in developing a culture that embraces innovation, and challenges existing paradigms
5+ years of experience in an Enterprise Data Management or Data Engineering role
3+ of hands on experience in building metadata driven data pipelines using Azure Data Factory, Databricks / Spark for Cloud Datalake
5+ years hands on experience with using one or more of the following for data analysis and wrangling Databricks, Python / PySpark, Jupyter Notebooks
Expert level SQL knowledge on databases such as but not limited to Snowflake, Netezza, Oracle, Sql Server, MySQL, Teradata
3+ years of hands on experience on one or more of big data technologies such as Cloudera Hadoop, Pivotal, Vertica, MapR is a plus
Experience working in a multi developer environment and hands on experience in using either azure devops or gitlab
Preferably experienced in SLA driven Production Data Pipeline or Quality support
Experience or strong understanding of the traditional enterprise ETL platforms such as IBM Datastage, Informatica, Pentaho, Ab Initio etc.
Functional knowledge of some of the following technologies - Terraform, Azure CLI, PowerShell, Containerization (Kubernetes, Docker)
Functional knowledge of one or more Reporting tools such as PowerBI, Tableau, OBIEE
Team player with excellent communication skills, ability to communicate with the customer directly and able to explain the status of the deliverables in scrum calls
Ability to implement Agile methodologies and work in an Agile DevOps environment
Our Company
Abercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we’re here for our associates, customers and communities on the journey to being and becoming who they are – and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas.
Our Values
We lead with purpose and always put our people first, which is evidenced by our Great Place to Work™ Certification, as well as being a 2021 recipient of Fortune’s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We’re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities.
What You'll Get
As an Abercrombie & Fitch Co. (A&F Co.) associate, you’ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company’s culture and values, but most importantly – with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward:
Incentive Bonus Program
Paid Time Off and Work From Anywhere Flexibility
Paid Volunteer Day per Year, allowing you to give back to your community
Merchandise Discount
Medical, Dental and Vision Insurance Available
Life and Disability Insurance
Associate Assistance Program
Paid Parental and Adoption Leave
Access to Carrot to support your unique parenthood journey
Access to Headspace dedicated to creating healthier, happier lives from the inside out
401(K) Savings Plan with Company Match
Opportunities for Career Advancement, we believe in promoting from within
A Global Team of People Who'll Celebrate you for Being YOU

Additional Information

ABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER
Notice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $110,000 - $136,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future.","$123,000 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,"Department, Clothing & Shoe Stores",1892,$1 to $5 billion (USD)
"City of Burbank, CA
3.8",3.8,"Burbank, CA",PRINCIPAL DATA ENGINEER,"Definition
Nestled between the Hollywood Hills and the Verdugo Mountains in the heart of Los Angeles County lies the City of Burbank, the “Media Capital of the World”. Burbank’s entertainment base is anchored by some of the biggest names in the business, including, among others, Walt Disney Studios, Warner Bros., ABC, iHeart Radio, Nickelodeon Animation, and Netflix Animation.
Burbank is well-known for its strong sense of community and its superior City services. The City of Burbank workforce is powered by incredible people and teams who are committed to ensuring that the level of service Burbank is known for, remains unparalleled.
The City of Burbank IT Department is seeking a Principal Data Engineer who will lead the data and analytics practice for the City, including planning, designing, creating and managing the organization’s data architecture, data pipeline strategy, and other data related programs. The Principal Data Engineer will perform a key role in helping the City to realize greater value from the data they possess, close gaps to create efficient digitized services, and leverage data and data driven insights to improve City services.
OPEN COMPETITIVE RECRUITMENT
Open to all qualified candidates.
Tentative examination dates for this recruitment:
Week of 10/06/23- Blind application and supplemental scoring
Week of 10/25/23 - Oral interview
Dates may change due to unforeseen circumstances. Candidates who pass each phase of the recruitment process will be notified of the official examination dates.
Under general direction, to act as a subject matter expert in a self-directed position; lead data and analytics initiatives for the City's digital business mission to include planning, designing, creating, deploying, and managing the organization's data architecture, data pipeline strategy and data related programs; and perform related work as required.
Essential Functions
Designs, creates, implements, and manages the City's enterprise data architecture by using relevant tools; integrates data architecture with business processes amongst cross functional business areas aligning with overall data architecture; builds, optimizes, and manages reusable data pipelines and data analytics solutions through successful production deployment; maintains complex databases; controls access methods, access time, device allocation, validation checks, organization, protection and security, and documentation and statistical methods; analyzes database needs of the organization; evaluates, designs, and implements database systems; formulates database strategies, policies, and procedures; ensures accuracy and completeness data in master files and various support tools; monitors and resolves database problems; performs validation checks; optimizes database performance; evaluates and promotes new technologies in database management; advises management on database concepts and functional capabilities; serves as key business liaison in operationalizing data and analytics on behalf of business stakeholders to plan and deliver optimal analytics and data science solutions for the City; automates and optimizes data pipelines, data flows, and data consumption with structured and unstructured data from different sources; builds processes supporting data transformation, data structures, metadata, and data stores; integrates data managed by heterogeneous systems, as well as any applications using or processing that data; supports data scientists, developers, business analysts, and database administrators in providing optimal data technology solutions; organizes data at a macro and micro level; addresses data infrastructure issues relating to velocity, variety, and volume of data; develops a logical data model as a standard for consuming applications; maps systems and interfaces used to manage data; sets standards for data management; analyzes current state and conceives desired future state, and conceives projects needed to address deficiencies between current state and future goals; participates in working groups and advisory committees related to data and database administration for innovative and proof of concept solutions; collaborates organization-wide to build and deliver analytic tools for users, stakeholders, and staff to provide actionable insight into the use of data, business performance metrics, and other relevant business objectives; manages department/Citywide data projects; recommends or defines the physical structure and functional capabilities of databases; ensures reliable interaction and interdependency of multiple database systems; administers databases for multi-system and highly complex commercial off-the-shelf (COTS) applications; sets data quality assurance policies and practices; ensures compliance and governance in data use; participates in working groups, and advisory committees related to data administration; performs related duties as required; supervises, trains, and evaluates employees; makes effective recommendations regarding hiring, promotions, transfers, and disciplinary action as needed up to and including termination; drives on City business.
Minimum Qualifications
Employment Standards:
Knowledge of principles, practices, and techniques of computer programming, systems design, computer operating systems, and procedures; any combination of programming languages such as Python, Java, C Sharp (C#), R, Structured Query Language (SQL), and Procedural Language extensions to SQL (PL/SQL); various database management systems, data modeling techniques, data warehousing techniques, concepts, practices, and procedures of data collection, modifications, and analytical practices of performing various complex data interpretation and integration using application programming interfaces; applications programming database technologies; comprehensive knowledge of data structures and current data analytical technologies; principles and practices of sound personnel management and supervision; spelling, grammar, and punctuation.
Skill in installing, maintaining, designing, developing, scripting, extracting, transforming, and modeling data: working with structured and unstructured data, to include utilizing large data sets; statistics, predictive modeling, and optimization; operating modern computers and related software; creating scalable systems.
Ability to lead, initiate, evaluate, and manage projects aligning the enterprise architecture to project specific objectives; apply data management concepts and techniques and design and implement solutions to meet future requirements; astutely operate in a large organization emphasizing design, methodology, modeling, and governance; articulate and persuade; effectively work with cross-functional teams; be highly creative and collaborative; direct, manage, mentor, and supervise staff activities and operations; work with staff to resolve technical and operational problems and implement solutions; communicate effectively, both orally and in writing; perform assigned tasks quickly and accurately; follow oral and written directions; write clear and accurate data and system documentation; establish and maintain effective working relationships with supervisors, fellow employees, and the public.
Education/Training: Any combination of education and/or experience that has provided the knowledge, skills, and abilities necessary for acceptable job performance as determined by the City. Example combination includes, but is not limited to graduation from an accredited college or university with a bachelor’s degree in computer science or closely related field and seven years of hands-on experience in software engineering, database administration, data warehousing, data science, or application programming, including two years of supervisory experience.
License & Certificates: A valid California Class “C” driver’s license or equivalent at time of appointment; a current industry recognized professional certification in data science or data analytics (to be determined at the time of recruitment) may be required at the time of appointment. All required licenses and certificates must be maintained throughout employment in this classification.
Supplemental Information
None.

This job title is represented by the Burbank Management Association (BMA)

The City of Burbank offers excellent employee benefits, please click on the following link for additional information regarding employee benefits: https://www.burbankca.gov/web/management-services/employee-benefits

Additionally, there are Benefit Summary Sheets for each represented and unrepresented employee group that provide a more detailed summary of benefits. There are also some Benefit Summary Sheets for specific job titles. To access the Benefit Summary Sheets, please click here: https://www.burbankca.gov/web/management-services/benefits-summary-sheets

Please note, employee benefits vary based on employment status - full-time or part-time; regular or temporary, and many benefits are not applicable to temporary employees.",#N/A,1001 to 5000 Employees,Government,Government & Public Administration,Municipal Agencies,1911,$100 to $500 million (USD)
"Workday
4.2",4.2,"Boulder, CO",Software Development Engineer in Test - Data Collaboration,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
Do you like solving hard and sophisticated at-scale problems? Love working with spreadsheets? Help support and enhance Workday's very own spreadsheet product!

The Workday Data Collaboration team is dedicated to building an extensible platform and a consumer based interface to enable our customers to work securely with their Workday data in a familiar UX.

Enhance your career with an opportunity that connects you to a strong network, enables you to do your best work, and places an emphasis on fun. Workday’s office in Boulder, Colorado is home to Productivity Technology, the team that is delivering our next generation of collaborative tools and features, focused on enabling customers to get the most out of their Workday data.

Some reasons why our engineers love working on our team:

No tech ruts: Expand your role. We work on Data Collaboration tools integrated across all areas of the Workday user experience to improve the product as a whole and share the knowledge we have acquired across the team.

Collaboration: Our agile team works closely together, enabling us to rapidly learn from each other.

A Learning Culture: We encourage creativity and experimentation in development practices, which allows us to constantly evolve our methodology and tools.

Influence: Every developer is encouraged and empowered to make things better – product, technology, processes, and culture.

Location: With a growing tech scene, 300 days of sunshine, 300 miles of dedicated bikeways, and an almost embarrassing abundance of outdoor adventure opportunities, Boulder is an amazing place to live.

Work/life balance: We love where we live, and we want to enjoy it. Balancing life and Work is a Workday value and a team value.
About the Role
The Data Collaboration team is looking for an exceptional SDET to help build out the next generation of Workday functionality. You will join our team in Boulder to help iterate and enhance the Worksheets, Slides, and Drive applications to expand their value and usage across the Workday product. You'd be involved in bringing new features from idea to delivery and beyond.
About You
You have talent and passion for testing usable, scalable software! You enjoy exploring the nooks and crannies of sophisticated products, and bring a power user perspective to assessing the impact of software changes. You want to work in a highly collaborative, agile environment. You love learning new technologies, languages, tools, and frameworks – and thinking carefully about which ones will be of real benefit in your projects.
Basic Qualifications
Software Development Engineer in Test
3+ years of proven experience planning, writing, and maintaining manual and automated tests, ideally using TypeScript, Cypress, and Jest
Senior Software Development Engineer in Test
4+ years of proven experience planning, writing, and maintaining manual and automated tests, ideally using TypeScript, Cypress, and Jest
Bachelor's degree in Computer Science or a related field or 5+ years equivalent experience
Other Qualifications
Strong working knowledge of spreadsheet software like Microsoft Excel
Genuine interest and ability to perform significant manual testing while growing into more automation
Professional experience using NPM, webpack, dependency management, Jenkins, Docker, GitHub, Java, and/or JUnit
Strong problem-solving and analytical skills
You are looking to grow and have mentorship opportunities
Strong communicator, who takes the initiative to get stuff done
You are ready to partner with Product Managers to define acceptance criteria, and with Engineers to ensure appropriate test coverage

Workday Pay Transparency Statement - United States
The annualized base salary ranges for the primary location and any additional locations in the United States (US) are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please
click here
.

Primary Location: USA.CO.Boulder
Primary Location Base Pay Range: $110,100 - $165,100
Additional US Location(s) Base Pay Range: $104,600 - $188,800

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.
Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!","$137,600 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
"Nuro
4.0",4.0,"Mountain View, CA","Senior Software Engineer, Data Platform","Who We Are
Nuro exists to better everyday life through robotics. The company's custom electric autonomous vehicles are designed to bring the things you need—from produce to prescriptions—right to your home. Nuro's autonomous, goods-focused solution can give you valuable time back and more freedom to do what you love. This convenient, eco-friendly alternative to driving has the potential to make streets safer and cities more livable.
About the Role

The Data platform provides end-to-end data management at Nuro, from data acquisition to data consumption and visualization. We build software and tools to offload large amounts of raw autonomy data in batches, transform data for different use cases, and visualize key company metrics; we build a centralized metadata store to facilitate autonomy development and validation, providing important datasets that are critical to downstream applications; we develop interactive dashboards for users to consume our core autonomy data and make rapid progress to put the vehicles on public road.
About the Work

Design, develop, and scale batch log offloading for R&D and production fleet operations
Provide centralized robotics data management, services, tools, and APIs for data-intensive autonomy and product applications
Manage end-to-end data generation & consumption from onboard bots to offboard applications, and define best practices and metrics for data ingestion, ETL, and processing
Design and develop unified, introspectable, large-scale batch and streaming data processing systems that can ingest and process data across a wide range of use cases relevant to AV development
Develop continuous testing and validation systems to ensure the robustness of our data and data architectures
About You

Domain experience: Experience working with large scale data and building scalable & reliable systems / data pipelines; ability to understand and design complex systems
Engineering leadership: Experience setting team or project product and technical vision, timelines and prioritization; formally or informally being a Tech Lead, mentoring and support junior engineers
Technical excellence: Ability and willingness to deep dive into implementation, driving technical standards and best practices across broader software organization
A bachelor's degree in Computer Science, Electrical Engineering, or a closely related field
Strong proficiency in Python, C++, or similar languages
Bonus Points

Knowledge of data engineering, and its tooling and best practices
Knowledge of batch and streaming data processing, warehousing, and analytics solutions
Experience working with large scale distributed data systems
Experience with system & framework design
Experience with data workflow orchestration platforms

At Nuro, your base pay is one part of your total compensation package. For this position, the reasonably expected pay range is between $167,200 and $250,800/year for the level at which this job has been scoped. Your base pay will depend on several factors, including your experience, qualifications, education, location, and skills. In the event that you are considered for a different level, a higher or lower pay range would apply. This position is also eligible for an annual performance bonus, equity, and a competitive benefits package.
At Nuro, we celebrate differences and are committed to a diverse workplace that fosters inclusion and psychological safety for all employees. Nuro is proud to be an equal opportunity employer and expressly prohibits any form of workplace discrimination based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, veteran status, or any other legally protected characteristics.
You must be fully vaccinated against COVID-19 by your hire date to be eligible to start the role. Proof of vaccination will be required by your start date. Nuro will consider and review accommodation requests based on medical, religious, or other grounds as required by applicable law for qualified candidates.","$209,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Computer Hardware Development,2016,Unknown / Non-Applicable
"JPMorgan Chase & Co
4.0",4.0,"Atlanta, GA",Lead Software Engineer (Big Data/AWS),"JOB DESCRIPTION

In this role you will serve as a site lead for our newly established Sao Paulo location, managing local team members and partnering with stakeholders on regional support strategy. As the site lead you’ll have additional responsibilities to ensure people agenda commitments are met through support beyond regional responsibilities.
Job Responsibilities
Provide oversight of local resources that perform service and operational activities, ensuring allocated work is completed and managed appropriately, meeting and exceeding Key Performance Indicators (KPIs).
Own team readiness, ensuring departmental policies, procedures, and other reference resources are well maintained and up to date.
Guide service improvements and lead projects that enhance the client experience, reducing friction while promoting digital tools;
Serve as an escalation point of contact and incident manager for critical client issues or platform outages, interfacing directly with clients as needed.
Promote J.P. Morgan as employer of choice in local markets and influence the recruitment process to ensure appropriate sensitivity to and awareness of emerging market hiring trends
Share information and raise awareness of global, regional and local initiatives through updates from senior leadership
Understand and actively manage location-level financial performance, cost effectiveness and efficiency
Required Qualifications, Skills and Capabilities
Fluency in English (oral and written)
5 or more years of people management, and relevant work experience in client support.
Strong oral and written communication skills, with a proven ability to communicate and interact with senior level management.
Proven organizational skills, deadline-oriented, and ability to successfully multi-task and prioritize across tactical and strategic initiatives
Able to analyze, interpret, and create visualizations in order to report data in various formats to meet client and stakeholder needs.
Ability to lead and influence as part of a global team, cultivating relationships with business partners in order to achieve business goals.
Demonstrating strong leadership and interpersonal skills, with proven ability to mentor and coach team members to further development.
Preferred Qualifications, Skills and Capabilities
Local and regional regulatory environment familiarity
Strong Risk and Controls acumen
Cash Management and Treasury Services experience
Fluency in Spanish is a plus
ABOUT US

J.P. Morgan is a global leader in financial services, providing strategic advice and products to the world’s most prominent corporations, governments, wealthy individuals and institutional investors. Our first-class business in a first-class way approach to serving clients drives everything we do. We strive to build trusted, long-term partnerships to help our clients achieve their business objectives.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.

ABOUT THE TEAM
The Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world’s most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.


Operations teams develop and manage innovative, secure service solutions to meet clients’ needs globally. Developing and using the latest technology, teams work to deliver industry-leading capabilities to our clients and customers, making it easy and convenient to do business with the firm. Teams also drive growth by refining technology-driven customer and client experiences that put users first, providing an unparalleled experience.
JOB DESCRIPTION

We have an opportunity to impact your career and provide an adventure where you can push the limits of what's possible.
As a Lead Software Engineer at JPMorgan Chase, you are an integral part of an agile team that works to enhance, build, and deliver trusted market-leading technology products in a secure, stable, and scalable way. As a core technical contributor, you are responsible for conducting critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job responsibilities
Lead the technical design for the platform.
Define coding standards / best practices within the team.
Provide technical leadership to a global team of ~30 engineers.
Ensure solutions are scalable, resilient & perform consistently.
Incorporate security requirements into design.
Establish strong working relationships with team members and all stake holders, including GTI support and business sponsors.
Executes creative software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Develops secure and high-quality production code, and reviews and debugs code written by others
Identifies opportunities to eliminate or automate remediation of recurring issues to improve overall operational stability of software applications and systems
Leads evaluation sessions with external vendors, startups, and internal teams to drive outcomes-oriented probing of architectural designs, technical credentials, and applicability for use within existing systems and information architecture
Leads communities of practice across Software Engineering to drive awareness and use of new and leading-edge technologies
Adds to team culture of diversity, equity, inclusion, and respect
Required qualifications, capabilities, and skills
10+ years of relevant experience working in data centric applications (Big Data or very large RDB).
Highly proficient in Java & Scala.
Very experienced in Big Data components ( HDFS, Kafka ).
Excellent analytic and problem solving skills.
Good communication skills; written and oral.
Bachelor’s Degree in a related subject ( Computer Science or Engineering ).
Proficient in all aspects of the Software Development Life Cycle
Advanced understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Demonstrated proficiency in software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)
In-depth knowledge of the financial services industry and their IT systems
Practical cloud native experience
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

J.P. Morgan Asset & Wealth Management delivers industry-leading investment management and private banking solutions. Asset Management provides individuals, advisors and institutions with strategies and expertise that span the full spectrum of asset classes through our global network of investment professionals. Wealth Management helps individuals, families and foundations take a more intentional approach to their wealth or finances to better define, focus and realize their goals.","$123,383 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Novo Nordisk
4.3",4.3,"West Lebanon, NH",Information Technology Data Engineer III,"About the Department
Site New Hampshire, located in West Lebanon, is where Novo Nordisk’s life-saving treatments are brought to life. Our manufacturing facility produces a global supply of our hemophilia and growth hormone product lines, as well as our next generation of cutting-edge medications. It’s not your average production site – it’s a tight-knit, supportive community working together to contribute to a better tomorrow for our patients. Ethics and quality are held in the highest regard, and a patient-focused mindset guides everything we do. We’re looking for individuals who are self-starters with a strong work ethic to join our team. At Novo Nordisk, you will find opportunities, resources and mentorship to grow and build your career. Are you ready to realize your potential?

The Position
The IT Data Engineer III is responsible for acting as a lead and trusted advisor to provide technical expertise supporting Novo Nordisk Site New Hampshire data and digitalization efforts. The role is responsible for improving data availability and validation and be a liaison between Manufacturing Science and IT / OT teams. It includes take a leading role to rollout, maintain, and support Novo Nordisk Data Management solutions used at Site in an agile product teamwork mindset, focusing on using AWS tools, Azure DevOps and custom tools to deliver data into our data lake, data mesh and data science platforms. Moreover, identify and sharing better practice, increase awareness of data management standards and validation and create improvements in methods, techniques, approaches etc., for optimizing the way we work and striving for simplicity.

What we offer you:
Leading pay and annual performance bonus for all positions
34 Paid days off including vacation, sick days & company holidays
Health Insurance, Dental Insurance, Vision Insurance
Guaranteed 8% 401K contribution plus individual company match option
12 weeks Paid Parental Leave
Free access to Novo Nordisk-marketed pharmaceutical products

Essential Functions
Interact with LoB, Data Scientist, and SMEs to understand and document business and data requirements. Collaborating with cross-function teams to design and build data pipelines for cleaning, transforming and combining datasets from wide variety of data sources
Document data from a-z (sources, interfaces, transformation). Further the role is responsible for data wrangling – Data ingestion, integration and curation from various sources, incl. internal and external sources in a highly-regulated environment
Analyse and assemble data from different data sources i.e. IoT telemetry, historian databases in real-time or batch manner and build the data-driven solutions
Stay current with industry trends, identifying opportunities, developing roadmaps and participating/conducting Proof of Concepts
Contributes to development of standards, frameworks, and operating model of assigned applications or solutions
Communicate, facilitate, and coordinate with relevant stakeholders’ activities related to planned and unplanned maintenance events impacting site users and processes
Other duties as assigned
Performs all job duties and responsibilities in a compliant and ethical manner and in accordance with all applicable healthcare laws, regulations, and industry codes
Incorporates the Novo Nordisk Way and 10 Essentials in all activities and interactions with others

Physical Requirements
Domestic and international travel will vary based on business need and travel restrictions. This position may lift up to 33lbs/15kg occasionally, and/or up to 10 pounds frequently or constantly to lift, carry, push, pull or otherwise move objects. Repetition including substantial movement of wrists, hands, and or fingers. The ability to speak, listen, and understand verbal and written communication. The ability to stoop, kneel, crouch, reach, stand, and walk. The ability to push, pull, lift, finger, and grasp. Visual acuity to perform close activities such as: reading, writing, and analyzing; operating a motor vehicle or heavy equipment, and to determine the accuracy, neatness, and thoroughness of work assigned or to make general observations. The working environment includes a variety of physical conditions including noise, inside and outside conditions including temperature changes; atmospheric conditions including odors, fumes, and dust.

Qualifications
A Bachelor’s degree preferably in Computer Science, Information Systems, Business Administration or other related field required
A minimum of 6 years of progressively responsible experience in Computer Science, programming/systems analysis or other related experience required
6+ years of data warehousing and relational database experience (Snowflake , MS SQL, or PostgreSQL)
Experience with NoSQL e.g. HBase, MongoDB, Cassandra, or similar
Experience in AWS and Cloud Technologies in General with Knowledge of data warehousing concepts
Experience in assembling large, complex structured/unstructured data sets that meet functional / non-functional business requirements
Experience in identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Experience with streaming technologies e.g. Kafka, AWS Kinesis etc.
Experience developing solutions on cloud platforms e.g. AWS, Azure, or similar
Working experience with industrial application, SCADA, IIOT, MES
Experience with programming language i.e. Python, Java
Excellent skills on interpersonal commutations and relationship management to collaborate in a team environment
Inclusive and sees the value of diversity
Strong IT Knowledge, demonstrating ability to handle most situations independently and with minimal guidance; able to identify better practice and create improvements in methods, techniques, approaches, etc.
Demonstrated problem solver with the ability to provide technical solutions to a wide range of complex data-related problems
Expert knowledge of systems analysis and design techniques
Demonstrated problem solver with the ability to provide technical solutions to a wide range of complex data-related problems
Expert knowledge of systems analysis and design techniques
Knowledge of project and system development methodologies, especially Agile
Knowledge of operating systems, relational database architectures, query languages and interface, standard programming environments, data integration tools, application integration solutions, and web-based information solutions
Knowledge of testing techniques that ensure that all business or technical requirements are appropriately met
Ability to manage and prioritize multiple projects simultaneously
Experience in applying systematic and rigorous analytics methods to improve data-related business processes

We commit to an inclusive recruitment process and equality of opportunity for all our job applicants.

At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.

Novo Nordisk is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, gender identity, sexual orientation, national origin, disability, protected veteran status or any other characteristic protected by local, state or federal laws, rules or regulations.

If you are interested in applying to Novo Nordisk and need special assistance or an accommodation to apply, please call us at 1-855-411-5290. This contact is for accommodation requests only and cannot be used to inquire about the status of applications.","$97,521 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1923,$10+ billion (USD)
"LiveRamp
3.6",3.6,Remote,"Senior Software Engineer, Big Data Activation","LiveRamp is the data collaboration platform of choice for the world’s most innovative companies. A groundbreaking leader in consumer privacy, data ethics, and foundational identity, LiveRamp is setting the new standard for building a connected customer view with unmatched clarity and context while protecting precious brand and consumer trust. LiveRamp offers complete flexibility to collaborate wherever data lives to support the widest range of data collaboration use cases—within organizations, between brands, and across its premier global network of top-quality partners.
Hundreds of global innovators, from iconic consumer brands and tech giants to banks, retailers, and healthcare leaders turn to LiveRamp to build enduring brand and business value by deepening customer engagement and loyalty, activating new partnerships, and maximizing the value of their first-party data while staying on the forefront of rapidly evolving compliance and privacy requirements.

LiveRamp is the leading data connectivity platform. We believe connected data has the power to change the world. Our platform powers insights and experiences centered around the needs of real people, and in ways that keep the Internet open for all. LiveRampers thrive on building together with curiosity and humility—and have a good bit of fun along the way. We’re always looking for smart, kind, and creative people to grow our team and impact.

Mission: LiveRamp makes it safe and easy for businesses to use data effectively.

The Activations Back End team is responsible for the bulk of big data processing that powers LiveRamp’s primary product (a product that delivers several hundred million in annual recurring revenue). Our systems process tens of thousands of batch requests per day, ranging in size from GBs to tens of TBs, and provide detailed monitoring, statistics, error recovery, and resiliency to power this core product.

At LiveRamp big data processing is not just for analytics to uncover business insights. Our product fundamentally is a big data product, as we transform, make useful, and transport massive datasets to hundreds of integrations. In doing so, we enable many of the most successful companies on the planet.

You will:
Work collaboratively with a small team of engineers to reinvent a system already processing petabytes of data every day.
Play a key role in transforming Activations Back End systems to being cloud-agnostic, multi-regional, and fundamentally more extensible
Building new pipelines and products with SQL on cloud data warehouses
Help shape the future of our big data technology platform.
Infuse industry best practices into our team processes and development practices.
Assist in architectural design and implementation of our systems and interfaces.
Develop our data processing pipelines using technology such as Spark, Dataproc, and Kubernetes.
Research and experiment strategies to optimize the performance and efficiency of petabytes of data processing.
Foster a positive environment of integrity, empowerment, initiative, and teamwork.
Provide operational support for our team’s production systems.
Share the remarkable work of our Activations team with the world through tech talks, blog posts, whitepapers, and conference participation.
Learn and grow in your role and career.

Your team will:
Rearchitect its platform to power our products in multiple clouds and regions, as well as to take advantage of cutting-edge cloud data warehouses, like Snowflake and SingleStore, which unlocks many new exciting possibilities.
Deliver 1-> N Global deployments, Novel Uses of Cloud Data Warehouses, 100x Processing Speedups, and other Paradigm shifts.
Play an important role in improving LiveRamp’s foundational products

About you: :
3+ years of experience writing and deploying high-quality production code.
Have made significant and meaningful development contributions to team projects involving distributed systems operating at scale.
Excitement to learn and improve, comfort with ambiguity
Communication skills to share highly technical information with technical and non-technical teammates.
Deeply inquisitive. Always asking why we do things and how we can do them better.
Thrive in a collaborative environment.
Demonstrated ability to build sustainable technical solutions that verifiably meet specific, well-defined business requirements.
Are you the type of person that likes running 200TB spark shuffles, 100x-ing job times, and or having an insight that saves $1 million in recurring cloud infrastructure cost? Call us
Experience architecting and improving system performance on cloud data warehouses
Experience writing and managing complex SQL queries
Benefits:
People: Work with talented, collaborative, and friendly people who love what they do.
Fun: We host in-person and virtual events such as game nights, happy hours, camping trips, and sports leagues.
Work/Life Harmony: Flexible paid time off, paid holidays, options for working from home, and paid parental leave.
Comprehensive Benefits Package: Medical, dental, vision, life, and disability. Plus, mental health support (via Talkspace), flexible time off, parental leave, family forming benefits, and a flexible lifestyle and wellbeing reimbursement program (up to $375 per quarter, U.S. LiveRampers)
Savings: Our 401K matching plan—1:1 match up to 6% of salary—helps you plan ahead. Also Employee Stock Purchase Plan - 15% discount off purchase price of LiveRamp stock (U.S. LiveRampers)
The approximate annual base compensation range is $130,000 to $190,000 The actual offer, reflecting the total compensation package and benefits, will be determined by a number of factors including the applicant's experience, knowledge, skills, and abilities, geography, as well as internal equity among our team.

More about us:
LiveRamp’s mission is to connect data in ways that matter, and doing so starts with our people. We know that inspired teams enlist people from a blend of backgrounds and experiences. And we know that individuals do their best when they not only bring their full selves to work but feel like they truly belong. Connecting LiveRampers to new ideas and one another is one of our guiding principles—one that informs how we hire, train, and grow our global team across nine countries and four continents. Click
here
to learn more about Diversity, Inclusion, & Belonging (DIB) at LiveRamp.","$160,000 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Software Development,2005,$100 to $500 million (USD)
"Axon
3.8",3.8,"Scottsdale, AZ",Data Solutions Engineer II - Dispatch,"Join Axon and be a Force for Good.
At Axon, we're on a mission to Protect Life. We're explorers, pursuing society's most critical safety and justice issues with our ecosystem of devices and cloud software. Like our products, we work better together. We connect with candor and care, seeking out diverse perspectives from our customers, communities and each other.

Life at Axon is fast-paced, challenging and meaningful. Here, you'll take ownership and drive real change. Constantly grow as you work hard for a mission that matters at a company where you matter.
Your Impact
Axon's Data and Integrations Team is looking for a Data Solutions Engineer II to create and maintain pipelines on the data integration, management, and analytics platform alongside Axon's newest public safety technology products. This platform will automate officer's workflows and offer law enforcement administrators and crime analysts flexible access to key crime data, decision support, state and federal crime reports, and criminal investigation insights.

Axon has lead the global effort to protect life and through electric weapons, body cameras, a number of real-time sensors, public safety software products and AI tools. Axon is uniquely positioned to tie together every aspect of an incident in order to help law enforcement agencies better prepare for what might happen, respond efficiently and effectively, deliver justice, ensure the well being of their officers, and increase the safety of communities. Working together with our customers and product teams, you will build the foundation for Axon's outcome-oriented data efforts.

What You'll Do
Location: Remotely from the United States
Reports to: Data Solutions Engineering Manager
Direct Reports: 0

Develop and maintain pipelines on Axon's system integration, data integration, management, and analytics solutions.
Develop and maintain automated processes that support Axon's product deployment and evolution at scale.
Possible projects could include DataStore Deployment, Integration Configuration/Testing, and Data Conversion.
Partner with internal teams and agencies to make public safety data accessible and actionable.
Influence peers, advise leaders, coach and mentor junior team members.
Facilitate cross-team collaboration among engineers, customer solution architects, and business analysts.
What You Bring
Prior experience working with Public Safety software including a solid understanding of Computer Aided Dispatch
Bachelor's Degree in a technical or quantitative field, OR graduate of coding boot camp OR 3+ years of technical experience in related field
Experience developing and maintaining customer production systems
Experience working with and writing T-SQL Queries
Proficiency in at least one scripting language, Python, Bash, or similar
Experience working with and interpreting JSON and XML
Familiarity using API REST clients to perform tests (Postman, Insomnia, etc.)
Familiarity working with YAML for purposes of configuring builds and releases
Experience and understanding of deploying hardware agnostic software to cloud hosts
Experience with container-based platforms such as Docker and Kubernetes
Backend engineering experience (Java, Scala, C++, or similar) is a plus
Must pass a Criminal Justice Information Services (CJIS) background check and maintain confidential and highly sensitive information
Benefits that Benefit You
Competitive salary and 401k with employer match
Discretionary time off
Paid parental leave for all
Medical, Dental, Vision plans
Fitness Programs
Emotional & Development Programs
And yes, we have snacks in our offices
Benefits listed herein may vary depending on the nature of your employment and the location where you work.

The Pay: Axon is a total compensation company, meaning compensation is made up of base pay, bonus, and stock awards. The starting base pay for this role is between USD 90,000 in the lowest geographic market and USD 140,000 in the highest geographic market. The on target earnings range for this role is between USD 110,000 in the lowest geographic market and USD 160,000 in the highest geographic market. The actual base pay is dependent upon many factors, such as: level, function, training, transferable skills, work experience, business needs, geographic market, and often a combination of all these factors. Our benefits offer an array of options to help support you physically, financially and emotionally through the big milestones and in your everyday life. To see more details on our benefits offerings please visit www.axon.com/careers/benefits (http://www.axon.com/careers/benefits).

#LI-Remote
Don't meet every single requirement? That's ok. At Axon, we Aim Far. We think big with a long-term view because we want to reinvent the world to be a safer, better place. We are also committed to building diverse teams that reflect the communities we serve.
Studies have shown that women and people of color are less likely to apply to jobs unless they check every box in the job description. If you're excited about this role and our mission to Protect Life but your experience doesn't align perfectly with every qualification listed here, we encourage you to apply anyways. You may be just the right candidate for this or other roles.

Important Notes
The above job description is not intended as, nor should it be construed as, exhaustive of all duties, responsibilities, skills, efforts, or working conditions associated with this job. The job description may change or be supplemented at any time in accordance with business needs and conditions.
Some roles may also require legal eligibility to work in a firearms environment.
Axon's mission is to Protect Life and is committed to the well-being and safety of its employees as well as Axon's impact on the environment. All Axon employees must be aware of and committed to the appropriate environmental, health, and safety regulations, policies, and procedures. Axon employees are empowered to report safety concerns as they arise and activities potentially impacting the environment.
We are an equal opportunity employer that promotes justice, advances equity, values diversity and fosters inclusion. We're committed to hiring the best talent — regardless of race, creed, color, ancestry, religion, sex (including pregnancy), national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations and ordinances — and empowering all of our employees so they can do their best work. If you have a disability or special need that requires assistance or accommodation during the application or the recruiting process, please email recruitingops@axon.com. Please note that this email address is for accommodation purposes only. Axon will not respond to inquiries for other purposes.","$110,000 /yr (est.)",501 to 1000 Employees,Company - Public,Information Technology,Computer Hardware Development,1993,$100 to $500 million (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Privacy,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

Team:
The Data Privacy team is responsible for providing capabilities for our customers to protect their sensitive data. We develop algorithms, APIs and user experiences to govern how sensitive data is discovered, protected, used and shared. Gartner predicts the global data privacy software market is projected to grow from $1.57b in 2021 to over $17b in 2028.
What you get to do in this role:
Build high-quality, clean, scalable, and reusable code by enforcing best practices around software engineering architecture and processes (Code Reviews, Unit testing, etc.)
Partner closely with senior to staff engineers to understand detailed requirements and own your code from design, implementation, test automation and delivery of high-quality product to our users.
Design software that is simple to use to allow customers to extend and customize the functionality to meet their specific needs.
Help design and implement new products and features while also enhancing the existing product suite.
To be successful in the role:
Passion for JavaScript and the Web as a platform, reusability, and componentization
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Analytical and design skills
Working knowledge and ability to use tools to assist with daily tasks (IDE, debugger, build tools, source control, ServiceNow instances, profilers, system administration/Unix tools)
Nice to have:
Experience and background in security a plus

Qualifications
4+ years of experience with Java or a similar OO language
Experience and/or knowledge with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Experience and/or knowledge of analytical and design skills

RM23
FD21
For positions in California (outside of the Bay Area), we offer a base pay of $119,970 - $204,030, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. For individuals who will be working in the Bay Area, there is a pay enhancement for positions located in that geographical area; please contact your recruiter for additional information.

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$162,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Google
4.4",4.4,"Austin, TX","Customer Engineer, Data and Analytics, Public Sector","Minimum qualifications:
Bachelor's degree in Computer Science, a related technical field, or equivalent practical experience.
6 years of experience in virtualization or cloud native architectures in a customer-facing or support role.
Experience in cloud computing (e.g., cloud market) and delivering technical presentations.
Experience in analytic warehouse solutions, Big Data technologies, real-time streaming, performance, and scalability optimizations.

Preferred qualifications:
Master's degree in Computer Science or a related technical field.
Experience with Public Sector client groups including state and local government.
Experience in developing data warehousing, data lakes, batch, or real-time event processing and Exact Transform and Load (ETL) workflows solutions (e.g., Informatica, Talend, Alooma, SAP, Data Services).
Experience in technical sales in the field of cloud computing, data, information lifecycle management, and Big Data.
Knowledge of Linux.
Ability to address domain name systems, transmission control protocol, firewalls, proxy servers, load balancing, virtual private networks, and virtual private cloud.

About the job
The Google Cloud Platform team helps customers transform and build what's next for their business — all with technology built in the cloud. Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping our customers — developers, small and large businesses, educational institutions and government agencies — see the benefits of our technology come to life. As part of an entrepreneurial team in this rapidly growing business, you will play a key role in understanding the needs of our customers and help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.
As a Customer Engineer, you will work with the Sales team to introduce Google Cloud to our customers. You will help prospective and existing customers and partners understand Google Cloud, develop creative cloud solutions and architectures to solve their business issues and problem-solve any potential roadblocks.

Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
The US base salary range for this full-time position is $139,000-$213,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Work with the team to identify and qualify business opportunities, identify key customer technical objections, and develop a strategy to resolve technical blockers.
Manage the technical relationship with Google customers (e.g., managing product and solution briefings, proof-of-concept work, and the coordination of additional technical resources).
Work with customers to demonstrate and prototype Google Cloud product integrations in customer and partner environments.
Prepare and deliver product messaging in an effort to highlight the Google Cloud Platform value proposition, using techniques that include presentations, product demonstrations, white papers, and request for information response documents.
Travel to customer sites, conferences, and other events as needed.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"BAE Systems
4.0",4.0,"Washington, DC",Data Engineer,"Job Description

BAE Systems is seeking a Data Engineers to support our government customer. The selected applicants will join the team as we seek to deliver world-class capabilities for our client and their associated contractors, driving productivity and innovation. This team works with real-time data and create tools using cutting-edge visualization, development, and analytic technologies.

Our staff provides full product lifecycle support for a large suite of multiplatform tools, environments, and microservices. These services support every aspect of the intelligence lifecycle including collection management, data aggregation, transformation, and enrichment, knowledge management, object-based production, and production creation and dissemination.

We utilize best practices in data science, artificial intelligence, machine learning, software engineering, data analytics, systems administration, and cybersecurity. Our team will lead in providing the next generation of capabilities planning and continuous integration of new and emerging technologies.

This position will include the following duties and responsibilities:
What you will do (day in the life):
Interacts with customers, Program Managers and other development teams to gather, analyze and define requirements to determine the most effective software and web technologies to satisfy the client needs
Develops, maintains, supports and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of extremely large data sets, real-time systems, and business management information systems) based upon documented requirements
Reviews and tests software components for adherence to the design requirements and documents test results
Designs, creates, tests, and maintains software and web-based applications and content solutions to satisfy customer requirements
Follows a formal design process using formal specifications, data flow diagrams, and adheres to laws, standards, and established guidelines for development and delivery of software and web applications
Designs and develops visually-pleasing, content rich, user-friendly interfaces with intuitive navigation
Develops and maintains software and web development technical documentation to assist with software and web application maintenance and upgrades
Provides software process management and configuration management throughout the software / web development life cycle.
Recommends new technologies and processes for complex software projects.
Ensures quality control of all developed and modified software.
Analyzes and troubleshoots extremely complex software problems and provides solutions using the latest technologies.
Integrates new software and web products with existing software and web applications in order to improve the functionality or design of the system.

Required Education, Experience, & Skills

Required Education:
Bachelors Degree with at least 12 years of relevant experience (or Masters Degree with at least 10 years of relevant experience).
Required Credentials:
Active TS/SCI clearance with CI polygraph
Active Security+ Certification or DoD 8140/8570 compliant IAT Level II certification
Required Experience:
Experience in troubleshooting complex data analytic systems.
Should have thorough experience working with Python and associated libraries
Experience in creating and using Docker Images and Kubernetes
Experience in Jira/Confluence using Agile/SCRUM methodologies and Kanban
Should have thorough understanding of the server/client model. (i.e., RESTful APIs, microservices, etc.)
Should have a working knowledge of data loading and ingestion.
Should have experience in extract, transform, and load (ETL) of legacy data source to current standards (i.e., be able to migrate from relational data base to NoSQL database)
Data standardization and normalization of legacy data source
Should have a working knowledge of Linux (i.e., should be able to edit/debug programs on Linux).
Familiarity with extracting implementation measurements and interaction requirements from designs
Technical understanding of big data concepts, cloud technologies such as AWS and Oracle.
Experience creating and troubleshooting APIs for migrating data from a relational data base to a NoSQL database (PostgreSQL)
Strong trouble shooting and problem-solving skills.
Must be able to work in a collaborative work environment.
Enthusiastic about teamwork, comprehensive automated tests, and collective code ownership.

Preferred Education, Experience, & Skills
Experience with APIs
Experience with AWS and/or Azure
Experience interfacing and briefing government customers at all levels
3+ years agile development and use of tools such as JIRA/Confluence
2+ years data standardization and ETL of legacy date to current standards.

Pay Information
Full-Time Salary Range: $122870 - $208890

Please note: This range is based on our market pay structures. However, individual salaries are determined by a variety of factors including, but not limited to: business considerations, local market conditions, and internal equity, as well as candidate qualifications, such as skills, education, and experience.

Employee Benefits: At BAE Systems, we support our employees in all aspects of their life, including their health and financial well-being. Regular employees scheduled to work 20+ hours per week are offered: health, dental, and vision insurance; health savings accounts; a 401(k) savings plan; disability coverage; and life and accident insurance. We also have an employee assistance program, a legal plan, and other perks including discounts on things like home, auto, and pet insurance. Our leave programs include paid time off, paid holidays, as well as other types of leave, including paid parental, military, bereavement, and any applicable federal and state sick leave. Employees may participate in the company recognition program to receive monetary or non-monetary recognition awards. Other incentives may be available based on position level and/or job specifics.

About BAE Systems Intelligence & Security
BAE Systems, Inc. is the U.S. subsidiary of BAE Systems plc, an international defense, aerospace and security company which delivers a full range of products and services for air, land and naval forces, as well as advanced electronics, security, information technology solutions and customer support services. Improving the future and protecting lives is an ambitious mission, but it’s what we do at BAE Systems. Working here means using your passion and ingenuity where it counts – defending national security with breakthrough technology, superior products, and intelligence solutions. As you develop the latest technology and defend national security, you will continually hone your skills on a team—making a big impact on a global scale. At BAE Systems, you’ll find a rewarding career that truly makes a difference.

Intelligence & Security (I&S), based in McLean, Virginia, designs and delivers advanced defense, intelligence, and security solutions that support the important missions of our customers. Our pride and dedication shows in everything we do—from intelligence analysis, cyber operations and IT expertise to systems development, systems integration, and operations and maintenance services. Knowing that our work enables the U.S. military and government to recognize, manage and defeat threats inspires us to push ourselves and our technologies to new levels.

Our Commitment to Diversity, Equity, and Inclusion:
At BAE Systems, we work hard every day to nurture an inclusive culture where employees are valued and feel like they belong. We are conscious of the need for all employees to see themselves reflected at every level of the company and know that in order to unlock the full potential of our workforce, everyone must feel confident being their best, most sincere self and be equipped to thrive. We provide impactful professional development experiences to our employees and invest in social impact partnerships to uplift communities and drive purposeful change. Here you will find significant opportunities to do meaningful work in an environment intentionally designed to be one where you will learn, grow and belong.","$165,880 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1999,$10+ billion (USD)
"Modern Technology Solutions, Inc.
4.8",4.8,"Beavercreek, OH",Data Engineer,"Own Your Future.

Modern Technology Solutions, Inc. (MTSI), is seeking an experienced Data Engineer to support our AFRL customer in Dayton, OH.

Why is MTSI known as a Great Place to Work?
Interesting Work: Our co-workers support some of the most important and critical programs to our national defense and security.
Values: Our first core value is that employees come first. We challenge our co-workers to provide the highest level of support and service, and reward them with some of the best benefits in the industry.
100% Employee Ownership: we have a stake in each other's success, and the success of our customers. It's also nice to know what's going on across the company; we have company wide town-hall meetings three times a year.
Great Benefits - Most Full-Time Staff Are Eligible for:
Starting PTO accrual of 20 days PTO/year + 10 holidays/year
Flexible schedules
6% 401k match with immediate vesting
Semi-annual bonus eligibility (July and December)
Company funded Employee Stock Ownership Plan (ESOP) - a separate qualified retirement account
Up to $10,000 in annual tuition reimbursement
Other company funded benefits, like life and disability insurance
Optional zero deductible Blue Cross/Blue Shield health insurance plan
Track Record of Success: We have grown every year since our founding in 1993
Modern Technology Solutions, Inc. (MTSI) is a 100% employee-owned engineering services and solutions company that provides high-demand technical expertise in Digital Transformation, Modeling and Simulation, Rapid Capability Development, Test and Evaluation, Artificial Intelligence, Autonomy, Cybersecurity and Mission Assurance.

MTSI delivers capabilities to solve problems of global importance. Founded in 1993, MTSI today has employees at over 20 offices and field sites worldwide.

For more information about MTSI, please visit www.mtsi-va.com.
Responsibilities:
MTSI is seeking an experienced Data Engineer to work in a growing data environment in support of digital transformations efforts for our AFRL customer in Dayton OH. You will have the opportunity to influence, design and implement data pipelines to collect, tag, curate and manage data from a variety of sources in support of research efforts. Additionally, you will assist in the identification and assessment of systems and software necessary to support the governance and management of data in on-premise and cloud environments. As the Data Engineer you will work with data owners and stewards to understand the data architecture needed to support evolving digital engineering and transformation requirements. This position is well suited to those who enjoy problem solving in evolving environments.

Duties include but not limited to:
Requirements analysis for data solutions and architecture
Data engineering for data transport, ETL, wrangling and storage
Data pipelines and automation in support of data management activities
Assist team in the identification of architecture components
Support data integration and interoperability efforts between teams
Work with stakeholders, users and data stewards to understand document and understand data requirements.
Ability to communicate complex solutions to technical and non-technical employees
Qualifications:
Qualifications:
Minimum 5 years of experience required
Experience working with multiple stakeholders and data stewards to understand the enterprise’s data landscape and future needs.
Experience working with teams for metadata identification
Experience with on-premise and cloud services
Experience with common data wrangling and manipulation languages such as Python and SQL
Experience with data lakes/stores and data pipelines
Experience with relational and NoSQL data stores
Experience with data pipeline and transformation tools such as Informatica, Apache Airflow and NiFi
Education Requirements:
Bachelor's degree in related field
Clearance Requirements:
Must have at least an active Secret clearance and be eligible for a Top-Secret clearance
#LI-CW1
#MTSI","$88,228 /yr (est.)",1001 to 5000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1993,$100 to $500 million (USD)
"Coupang
3.6",3.6,"Seattle, WA",Staff Data Infrastructure Engineer,"We exist to wow our customers. We know we're doing the right thing when we hear our customers say, ""How did we ever live without Coupang?"" Born out of an obsession to make shopping, eating, and living more effortless than ever, we are collectively disrupting the multi-billion-dollar e-commerce industry from the ground up. We're one of the fastest-growing e-commerce companies with an unparalleled reputation for being a dominant and reliable force in South Korean commerce.
We are proud to have the best of both worlds — a startup culture with the resources of a significant global public company. This fuels us to continue our growth and launch new services at the speed we have been at since our inception. We are all entrepreneurs surrounded by opportunities to drive new initiatives and innovations. At our core, we are bold and ambitious people that like to get our hands dirty and make a hands-on impact. At Coupang, you will see yourself, your colleagues, your team, and the company grow every day.
Our mission to build the future of commerce is real. We push the boundaries of what's possible to solve problems and break traditional tradeoffs. Join Coupang to create an epic experience in this always-on, high-tech, hyper-connected world.
Role Overview
The Data Infrastructure team in the Data Platform organization serves Hadoop clusters, DW, and Orchestration platforms across the entire business domain. The infrastructure managed by the Data Infrastructure team provides various data processing related to Coupang services, including log analysis, recommendation, price comparison, AB testing, search indexing, advertising, and rocket delivery. We are confident that we are playing a pivotal role in experiencing the best e-commerce for Coupang's customers.
The Data Infrastructure team simultaneously serves hundreds of Hadoop clusters in cloud environments and has the infrastructure and know-how to reliably scale to thousands of nodes. To this end, open sources such as Hadoop, Spark, Hive, Presto, Airflow, Oozie, Docker, Kubernetes, Ansible, Terraform, Packer, and Java and Python are used as development languages.
Our vision is to provide modern self-service tools to enhance engineering productivity, making it easy for anyone to utilize our data, and build a platform that is consistently scalable and reliable. We are looking for a software engineer who will create the most robust platform services at a global level beyond Korea!
Responsibilities:
With a solid understanding of big data technology and skilled development capabilities, the Staff Data Infra Engineer will be responsible for performing the following tasks:
Provide a roadmap and vision for scalable and robust growth for your data infrastructure team
Collaborate with stakeholders and lead engineers on key mission-critical projects
Leading the design and deployment of big data infrastructure architectures
Hadoop/Data Warehouse infrastructure Maintanence
Establish Data Warehouse governance and improve cluster operation efficiency
Self-service development to improve cluster operational efficiency and user experience
As a Backend Engineer, participate in business/technical improvement projects from a data platform perspective
Modern data engineering technology research and product development
Requirements:
Bachelor's degree or/and master's degree in computer science and equivalent majors
Proficient in at least one or more Java, Scala, Python
More than 10 years of experience in designing, developing, and maintaining large software infrastructures
Have expertise in distributed systems such as Hadoop and Spark
More than 3 years of experience in developing and operating enterprise DW platform (RedShift, Netezza, Greenplum, Exadata, Teradata)
Great communication skills and someone who likes to share your experiences and learnings with your colleagues
People who try to automate without maintaining manual or repetitive tasks
Preferred:
Experience in designing and developing data pipelines in cloud environments such as AWS and GCP
Experience in leading projects and initiatives with complex scope
High competency in SQL writing and OLTP / Batch SQL Tuning
Strong experiences with RedShift
Experience with Snowflake and Databricks
Pay & Benefits
Our compensation reflects the cost of labor across several US geographic markets. At Coupang, your base pay is one part of your total compensation.
The base pay for this position ranges from $151,090/year in our lowest geographic market to $300,105/year in our highest geographic market. Pay is based on several factors, including market location, and may vary depending on job-related knowledge, skills, and experience.
General Description of All Benefits
Medical/Dental/Vision/Life, AD&D insurance
Flexible Spending Accounts (FSA) & Health Savings Accounts (HSA)
Long-term/Short-term Disability
Employee Assistance Program (EAP) program
401K Plan with Company Match
18-21 days of Paid Time Off (PTO) a year based on tenure
12 Public Holidays
Paid Parental leave
Pre-tax commuter benefits
MTV - [Free] Electric Car Charging Station
General Description of Other Compensation
""Other Compensation"" includes, but is not limited to, bonuses, equity, or other forms of compensation offered to the hired applicant in addition to their established salary range or wage scale.

Coupang is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to actual or perceived race (including traits historically associated with race, including but not limited to hair texture and protective hair styles), color, religion, religious creed (including religious dress and grooming practices), sex or gender (including pregnancy, childbirth, breastfeeding, and medical conditions related to pregnancy, childbirth or breastfeeding), gender identity, gender expression, sexual orientation, ,ancestry, national origin (including language use restrictions), age (40 and over), physical or mental disability, medical condition, genetic information, HIV/AIDS or Hepatitis C status, family status (including but not limited to marital or domestic partnership status), military or veteran status, use of a trained dog guide or service animal, political activities or affiliations, ancestry, citizenship, family and medical leave status, status as a victim of any violent crime, or any other characteristic or class protected by the laws or regulations in the locations where we operate. Coupang is also committed to providing a safe work environment for its employees and its consumers. As a condition of employment, Coupang requires employees to be fully vaccinated against Covid-19, subject to legally required accommodations. If you need assistance and/or a reasonable accommodation in the application of recruiting process due to a disability, please contact us at usrecruiting@coupang.com

Equal Opportunities for All
Coupang is an equal opportunity employer. Our unprecedented success could not be possible without the valuable inputs of our globally diverse team.","$151,090 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Internet & Web Services,2010,Unknown / Non-Applicable
"GEI Consultants Inc
4.2",4.2,"Woburn, MA",Data Engineer,"Your role at GEI.
GEI Consultants has an opening in our Operational Development Team for a qualified Data Engineer to support a variety of systems and data engineering tasks focused on data flow activities. The majority of our systems are based in MS SQL Server, Tableau Server, Azure, and FastField Forms. This person will primarily work closely with members of the Operational Development Team and with members of our IT staff. The ideal candidate will be focused, detail-oriented, and driven to attain and maintain very high standards for efficiency and accuracy in data acquisition and integration into our systems. The ideal candidate will have more than 3 years of data engineering experience in the AEC industry or in similar science and/or engineering environments. GEI seeks a committed, self-motivated, organized and detail-oriented individual who anticipates issues and thrives on creative, independent problem solving within a rapid, deadline-driven environment.
Essential Responsibilities & Duties
ETL of data from a wide variety of sources
Database and Data Warehouse design/expansion/backup & recovery
Index management and optimization
Support data sources for Tableau Server, Power BI, and ArcGIS
Stored procedure development and maintenance
Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis
Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases
Troubleshoot SSIS package permission issues related to execute-as/data source read/write access
SQL Agent Job development and monitoring
Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc
Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS
Develop test plans, implementation plans, and project timelines for various data engineering projects
Define, prioritize, communicate, and foster shared understanding of project objectives and scope
Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product
Team with all staff necessary to complete assignments
Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements
Other duties as assigned
Minimum Qualifications
3+ years of experience in a position performing similar data engineering tasks
Proven record of ability to design, manage, and support MS SQL Server and Azure databases
Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R
Bachelor's Degree, from an accredited college or university
MS SQL Server/Azure certification preferred
Ability to develop project plans and meet deadlines
Self-starter with attention to detail and stakeholder needs
Able to critically analyze and solve problems of a complex nature
Excellent Communication skills
Able to work on multiple projects of moderate complexity simultaneously and independently
Proficient in organization and time management skills
Familiarity with engineering, environmental science, and/or chemistry subject matter preferred.
Able to work effectively in GEI s partnership model, including a team environment, building rapport and relationships.
We are GEI.
Some of the world s most pressing problems – from climate change to sustainable development, to critical infrastructure and the future of our energy supply – need our brightest and diverse minds working together to create safer, more resilient communities for tomorrow.
We are technical experts, collaborators, and entrepreneurs who draw from diverse backgrounds to solve our clients most complex challenges.
With more than 40 offices across North America, we offer a range of engineering, science, and technical consulting services. Our range of expertise, project types, and culture make us the choice for top talent in the AEC industry.
Employee-owned. Employee-focused.
As a 100% employee-owned company, our employees support our flat leadership structure, have a say in how our business operates and benefit from our financial success. We are committed to employee growth with career development opportunities, competitive total rewards, a well-being program, flexible work arrangements and more. Our company culture is driven by our 4 Cs – we are Client-Centered, Curious, Collaborative, and Community Minded – which support our focus on sustainability, safety, diversity, equity and inclusion. Get to know us better by visiting GEI s career site here.
GEI s Total Rewards Package
Market-Competitive Compensation, including Eligibility for an Annual Performance Bonus
Pay Range For This Position: $33.65-72.11/hour
Comprehensive Benefits Program, including Medical, Dental, Vision, Life, Disability and More
Well-Being Program and Paid Parental Leave
Commuter Benefits
Hybrid Work Schedules and Home Office and Cell Phone Stipends
GEI University (GEIU) with Continuing Education Assistance and Tuition Reimbursement
Connecting Conversation Program with a Focus on Professional Development and Opportunities for Advancement
Support and Financial Rewards for Publication Awards, Professional Dues, and Professional Licenses
Paid Holidays and Generous Paid Time Off Program
Rewards and Recognition
GEI-Funded Profit Sharing and 401(k)
Opportunity to be an Owner and Shareholder (Learn more here)
A Vibrant Culture that is Focused on Partnership, Sustainability, Giving Back to Our Communities and Diversity, Equity and Inclusion
And More…
Physical Job Requirements

Sedentary

X

Light

Medium

Other


Activity Level Throughout Workday

Physical Activity Requirements

Occasional
(0-35% of day)

Frequent
(33-66% of day)

Continuous
(67-100% of day)

Not Applicable

Sitting

X

Standing

X


Walking

X


Climbing

X

Lifting (floor to waist level) (in pounds)

X


Lifting (waist level and above) (in pounds)

X


Carrying objects

X


Push/pull

X


Twisting

X


Bending

X


Reaching forward

X


Reaching overhead

X


Squat/kneel/crawl

X


Wrist position deviation

X


Pinching/fine motor skills

X


Keyboard use/repetitive motion

X


Taste or smell (taste=never)

X

Talk or hear

X


Accurate 20/40

Very Accurate 20/20

Not Applicable


Near Vision

X


Far Vision

X



Yes

No

Not Applicable


Color Vision (ability to identify and distinguish colors)

X


Sensory Requirements

Minimal

Moderate

Accurate

Not Applicable

Depth perception

X

Hearing

X



Environmental Requirements

Occupational Exposure Risk Potential

Reasonably Anticipated

Not Anticipated

Blood borne pathogens

X

Chemical

X

Airborne communicable diseases

X

Extreme temperatures

X

Radiation

X

Uneven surfaces or elevations

X

Extreme noise levels

X

Dust/particular matter

X

Other (exposure risks):


Usual workday hours:

X
8

10

12

Other work hours


GEI is an AA/equal opportunity employer, including disabled and veterans.",$52.88 /hr (est.),1001 to 5000 Employees,Company - Private,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1970,$100 to $500 million (USD)
"Core BTS
3.5",3.5,Remote,Sr. Azure Data Engineer w/ Snowflake,"Overview:
Through Core BTS Resource Management Services (RMS), we offer custom talent solutions to help our clients meet their evolving technology and business needs. We help effectively match the right technology professional to their organization, recruiting for contract, contract-to-hire, and direct roles.
Our client in New York, has an immediate need for a Data/Azure Engineer. Please note that this is a 6-month contract to hire with our client and NOT with Core BTS.
Position Summary: Responsible for designing, configuring, managing, and maintaining data systems and infrastructure on Microsoft Azure and Snowflake platforms.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned.
Design, build, and manage data pipelines in Azure and Snowflake, ensuring they meet the company's technical and business requirements.
Manage and optimize the performance of Azure and Snowflake data solutions to ensure maximum availability, scalability, and security.
Implement data migration and transformation processes between Azure and Snowflake environments.
Work closely with other team members to ensure seamless integration between third-party and organizational systems.
Develop and implement monitoring, logging, and reporting processes for data platforms.
· Provide technical guidance and support to the development team, ensuring adherence to best practices in Azure and Snowflake technologies.
Collaborate with cross-functional teams to ensure the smooth operation of cloud-based data services and applications.
Continuously research and evaluate new features and technologies in Azure and Snowflake to recommend improvements and enhancements.
Maintain up-to-date knowledge of Azure and Snowflake architecture, security, and compliance best practices.
Competencies: To perform the job successfully, an individual should demonstrate the following:
In-depth knowledge of Azure and Snowflake architecture, services, and features.
Experience with Azure Data Factory, Databricks, SQL Services, Storage and Snowflake Data Warehousing.
Hands-on experience with Azure DevOps, CI/CD pipelines, and Snowflake data transformation tools.
Knowledge of security and compliance best practices in Azure and Snowflake environments.
Relevant certifications such as Azure Data Engineer or Snowflake SnowPro Core Certification are preferred.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education / Experience:
Bachelor's degree in computer science, Information Technology, or related field.
Minimum of 3 to 5 years of experience in Azure data technologies and Snowflake.
In lieu of a Bachelor’s degree, candidates must have a minimum of 5 to 7 years related experience in Azure and Snowflake technologies.
3-5 years of experience in financial services. Experience with Fiserv and Temenos platforms a major plus.
Language Ability: Read, analyze and interpret complex documents. Respond effectively to sensitive inquiries. Make persuasive presentations on complex topics to management, public groups and/or boards of directors.
Reasoning Ability: Apply logical thinking to a wide range of intellectual and practical problems.
Additional Required Computer Skills:
MS Office Productivity Suite
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job.
This is a remote position.
Working hours for this position are 9 AM to 5 PM Eastern US.
Job Type: Contract
Pay: $70.00 - $75.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Compensation package:
Overtime pay
Weekly pay
Experience level:
6 years
Schedule:
8 hour shift
Work Location: Remote",$72.50 /hr (est.),501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,2004,$100 to $500 million (USD)
"Conductor LLC
4.3",4.3,"New York, NY","Principal Engineer, Data Platform","Conductor is the world's leading SEO platform, helping businesses accelerate organic traffic and revenue growth. Conductor's technology helps marketers create powerful marketing content to drive high-quality traffic to their site and measure their organic performance.
Conductor is a mission-driven company with a commitment to innovation, customer success, and culture. For Conductor, success is improving the lives of all the people in our orbit—our customers, our customers' customers, our employee-owners, and our communities.
Conductor is also proud to have been recognized externally: the company was named the leader in 2020 Forrester Wave: SEO Platforms Research Report and have been top rated on G2 and TrustRadius by customers.
What are we looking for?
Conductor is seeking a seasoned product-minded engineer with extensive data architecture and data platform design experience to power massive scale SaaS applications. This leader brings deep technical data and infrastructure expertise, and partners with Product Management, Engineering, and Cloud teams to drive architecture and define, design, create, manage, and deploy highly scalable and available data systems and applications.
Reporting to the Vice President of Engineering, this leader -
Designs, develops, implements, and translates business requirements and the overall organizational data strategy, including standards, principles, data sources, storage, pipelines, data flow, data processing, and data security/ governance policies
Collaborates with data engineers, data scientists, application developers and other stakeholders to define and execute the enterprise data strategy
Communicates and defines data architecture patterns in the organization that guide the data framework
Provides technical leadership to data teams to implement secure, scalable, high-performance, and reliable data platform for AI/ML powered analytics applications and services
Embraces a strong centralized data platform to unlock insights, innovation, and intelligence in the application, and to support rapid development and iteration of capabilities for our users
Appreciates working across stacks in an organization without silos
Is motivated to understand the challenges in the SEO space, and has a passion for solving problems and not just delivering features
Influences strategic thinking across the team. Advocates for best practices, investigates new technologies and mentors other engineers.
The successful candidate must thrive in ambiguity with a strong decision-making capability along with a sense of accountability, leveraging a collaborative leadership style with a bias-to-action. The candidate must have a passion to solve hard problems with technical expertise and a growth-mindset, using strong engineering rigor and data-driven operational skills to drive the desired outcomes across global teams. Conductor is poised for significant growth and this leader is a very important stakeholder in the next phase of our company's journey.
Who you are
A hands-on software engineer with 10+ years in systems software development including 6+ years as a data engineering technical leader building scalable and secure data platforms and systems powering intelligent applications.
An expert in concepts, principles, and implementation of data models, design, integration, transformation, and data management.
Deep knowledge of various relational (row-oriented and columnar) and non-relational (key value, document, graph, etc.) database technologies including database and storage services in open source and those provided by public cloud vendors such as AWS (preferred) and GCP.
Deep knowledge and experience with architectures for modern data infrastructure including data lakes, data warehouses, ETL pipelines, physical and logical data formats, data processing systems, data reliability, security, and performance.
Understands processes, roles, policies, standards, and metrics that ensure the effective and efficient use of data/information, data privacy and confidentiality, and risks and mitigations.
Extensive experience using cloud technologies, Snowflake/ Redshift/ Bigquery, Spark, Kafka, event queues, containers and orchestration (Docker, Kubernetes), storage, networking, and operating systems
A thought leader with comprehensive understanding of the data sources, data formats, and data processing challenges at scale in application verticals such as (preferably) organic marketing/ SEO, retail, content, etc.
An expert in Java and SQL programming languages
Proficiency with solution discovery and delivery using rapid prototyping, experimentation and iterative development.
Have a minimum of bachelor's degree in Computer Science, Mathematics, or a related field. Master's or PHD preferred.
Have excellent verbal and written communication skills – can communicate clear technical solutions to complex data problems to both technical and non-technical audiences.
Why You Should Join
Conductor is a People-First and Customer-First company. We are looking for engaged and passionate technology leaders that can raise the bar. We have built a highly collaborative culture of technical excellence with tremendous opportunity to have an immediate impact in the day-to-day life of our employees and customers and drive the company's success and growth. We all share the same values, innovate, and motivate each other to attain ambitious goals, and celebrate each other's success.
We are made up of a diverse group of people from all backgrounds. Wherever you are from, you will find a common ground here to accelerate your career and make a difference in the organic marketing industry.
Conductor, Inc. is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Our Core Values
Design for the Future, Build for Today: Don't be limited by the present. Anticipate, architect, and design for the long-term so that we don't have to rework our software as we grow. But build for today in terms of quality and time to delivery.
Be Product-Minded: By knowing our customers, we can build better products that empower them and help their customers. To be a great Organic MarTech engineer one must understand the organic marketing landscape.
Innovate: Step up the game. Find new ways to solve problems. Influence the entire product. Deliver better value for our customers. Create moats for our competition. Enhance our company's brand, and enhance your own personal brand image.
Optimize for Value: Great products focus on building value rather than chasing an artificial deadline. Embrace continuous planning that believes in delivering products when they are ready.
Value Your Time: Think harder. Don't settle. Strive for better outcomes than the last time in the same amount of time. Automate away toil and spend your energy solving newer, bigger, more interesting problems.
Be Biased to Build Right: How you create value is very important. Prefer open source over commercial products to invent/create value and accelerate delivery. Dependency on external products for value creation increases cost and risk, impedes innovation, and discounts value.
Seek Challenges: Good engineers just solve problems. Great engineers also seek and define new challenges. Invention and value creation happens when engineers show curiosity and initiative, and participate in defining ""what's next"".
Embrace Change: When we maintain the status quo, we hold ourselves back. Have an open mind. Don't cling to existing processes, technical biases, etc. Try something new. We all learn and grow together.
About Conductor
Conductor's search and content intelligence platform helps marketers create and optimize content to improve visibility online.
The technology generates customer intent insights that lead to compelling content, increased traffic, and higher organic marketing ROI. Customizable dashboards and workflows guide marketers through the content creation process, empowering them to measure, refine, and demonstrate the effectiveness of their SEO and content marketing efforts.
In addition to its SaaS platform, Conductor offers a suite of services and support including site audits, site migrations, and managed services that empower in-house marketing teams and digital marketing agencies to drive results and put their customers' needs first.
Conductor's forward-thinking customers include leading global and emerging enterprise brands.
-
Compensation: Conductor maintains competitive, performance-based compensation programs.
The base salary for this role is currently up to $250,000. The actual base salary offered may vary within this range based on education, knowledge, skills, abilities, relevant experience, internal equity, and geographic location, among other factors. The actual compensation, if offered a position, will be based on these factors.
Variable compensation: In addition to base salary, this role is also eligible for a discretionary annual bonus based on attainment of corporate revenue performance targets.
Benefits: Conductor offers the following attractive benefits and perks including: 100% covered employee medical plan, a dental & vision plans, 401(k) with employer contribution, an unlimited vacation policy, 10 sick days, short-term disability, long-term disability, generous paid parental leave, Employee assistance program, flexible savings accounts, paid holidays, life and accidental death insurance, and a host of perks (YOLO Months, internet/cell phone allowance, fully stacked kitchens, etc.).
In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.
-
Conductor LLC is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. Bringing in diverse perspectives and challenging our assumptions is the clear key to growth; it drives innovation, creativity, faster problem-solving, and stronger decision making. All aspects of employment including the decision to hire, promote, train, discipline, or discharge, will be based on merit, competence, performance, and business needs.
Conductor does not discriminate against any employee or applicant on the basis of race, color, ancestry, national origin, religion or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, or other characteristics protected by state or federal law or local ordinance. In addition, it is the policy of Conductor to provide reasonable accommodation to qualified employees who have protected disabilities to the extent required by applicable laws, regulations and ordinances where a particular employee works.
***********************************************************************
Disclosure: Conductor cares about your privacy. We are committed to maintaining your trust by protecting and processing your Personal Information that you provide to us in accordance with Greenhouse's Privacy Policy. Please take a moment to review before submitting your application.","$143,787 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2010,$25 to $100 million (USD)
"UniGroup
3.2",3.2,Remote,"STAFF SOFTWARE ENGINEER, DATA","Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology.

The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE.

Essential Duties and Responsibilities:
Technical Skills:
Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code.
Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy.
Proficient at using systematic debugging to diagnose all issues within a set of related domains.
Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains.
Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems.
Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes.
Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example.
Delivery:
Reviews cross-team work critically and ensures it’s appropriately broken down and prioritized, and well understood by all involved teams.
Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy.
Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations.
Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved.
When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions.
Feedback, Communication, Collaboration:
Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors.
Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors.
Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication.
Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors.
Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due.
Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams.
Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans.
Leadership:
Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves.
Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals.
Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes.
Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in.
Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors.
Strategic Impact:
Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals.
Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints.
Technical expertise with data modelling and data mining techniques:
Experience with programming languages (e.g. Python and JavaScript/Typescript)
Experience with relational SQL and NoSQL databases, including Postgres and MongoDB.
Experience with cloud environments (Microservices / AWS / Docker / Kubernetes)
Experience of using Git / GitLab /GitHub
Hands-on experience with SQL database design
Experience with big data tools such as Kafka, etc.
Experience with data pipeline and workflow management tools
Great numerical and analytical skills
Education, License or Certification:
Bachelor’s degree in Information Systems or equivalent experience.
Experience:
6-8 years of experience in IS Development
We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law.

We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country’s heroes. We hope you consider joining the UniGroup family.

UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com",#N/A,1001 to 5000 Employees,Company - Private,Transportation & Logistics,Taxi & Car Services,1920,$1 to $5 billion (USD)
"Leidos
3.8",3.8,Remote,Sr Data Engineer,"Description
The Leidos Public Health Operation is seeking a Sr Data Engineer, Contingent upon contract award, to support a Modernization effort for the CDC.
Role is expected to be fully remote
Must currently reside in the United States for the last three consecutive years
Duties:
Assists in the implementation of data governance processes and systems. Develops and maps vocabularies to support data that flows through CDC’s North Star Architecture. Supports data exchange processes and data sharing within the organization. Coordinates with data governance support to facilitate streamlining of data access request processes. Builds and maintains data warehouses that store and organize large data sets for analysis. Optimizes data storage and retrieval by designing and implementing efficient storage systems, such as NoSQL or Hadoop, and using indexing and partitioning techniques. Applies data validation, data profiling, and data cleansing to ensure data quality and integrity. Collaborates with data analysts and data scientists to understand data requirements and develop solutions.
Required Qualifications:
Bachelor's Degree or equivalent and 12 years of progressive related experience
Experience with conceptual, logical, and physical data modeling
Experience with exchanging health data in various standards and formats such as XML, CSV, JSON, EDI X12, HL7, and FHIR.
Possess data science expertise to prepare and analyze unstructured data.
Experience with Machine Learning and Natural Language Processing for data analysis, manipulation, mining, and pattern recognition.
Strong software scripting skills in Python and other scripting languages (Bash, Perl, etc.)
Experience with statistical programming using R, Python, Scala, or Metlab.
Experience with creating objects, querying, and improving performance of RDBMS databases (PostgreSQL, Oracle, MySql, etc.)
Experience with Azure Boards, Jira or VersionOne (Agility).
Prior experience working with the Git version-control system
Familiarity with Cloud platforms such as Azure or AWS
Knowledge of Scrum and Kanban Agile development process and ceremonies including scrums, planning events, backlog grooming, retrospectives, and demonstrations.
Experience with Continuous Delivery/Integration tools such as Azure DevOps, Azure Data Factory and Jenkins
Experience with building data warehouses, data marts, and data lakehouses using Azure Databricks, Data Warehouse, Data Factory, and Hadoop
Familiarity with monitoring tools such as Grafana and Splunk
Familiarity with event streaming platforms such as Kafka and Spark
Strong communication and collaborative skills in providing technical direction and hands-on software development to include design, development, and testing.
Demonstrate ability to navigate projects through established processes and continuous improvement.
Preferred Qualifications:
Experience with implementing IT and data Policy as Code frameworks
Knowledge of Master Data Management approaches, tools, and implantation.
Knowledge of FAIR principles for data stewardship.
Experience gathering and analyzing system requirements for data science and analytics products and performing gap analysis.
Experience with data visualization tools such as Tableau, Excel, Power BI, Azure Data Explorer
Familiar with SAFe Agile development methodology
Experience with CDC/Public Health
Knowledge of NIH EPLC and Stage Gate reviews
Requires ability to obtain Public Trust level 5 clearance
hhscdc
Pay Range:
Pay Range $118,300.00 - $213,850.00
The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.
#Remote","$166,075 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1969,$10+ billion (USD)
"US John F. Kennedy Space Center
3.9",3.9,"Kennedy Space Center, FL","Electronics Engineer - AST, Data Hardware Systems (Direct Hire)","Duties
Perform Avionics/Electronics research, analysis, design, development, integration, testing, evaluation, modification, and implementation for RandT payloads, flight experiments, and technology developments for space and surface applications.
Provide engineering technical expertise to Avionics systems' hardware and software elements, such as command and control, instrumentation, data acquisition, processing, and handling, communication, telemetry, power distribution.
Resolve technical difficulties of Avionics/Electronics systems as well provide technical expertise on hardware and software elements such as system/embedded software, electrical and electronics.
Review, analyze and evaluate test data, including engineering analysis, troubleshooting, problem resolution and corrective actions in support of new developments or modifications of existing avionics systems.
Develop and review technical goals, requirements, drawings and schematics, procedures and other documentation required during formulation, design and development, fabrication and testing, and implementation of avionics/electronics.
Perform required analysis, test, verification, and validation activities to ensure Avionics/Electronics systems meets project objectives and are compatible with flight and data acquisition and processing capabilities.
Support project in requirements' formulation, technical meetings, technical boards, projects? design and acceptance reviews, and other design and implementation processes.
Requirements
Conditions of Employment
This position is open to U.S. citizens, nationals or those who owe allegiance to the U.S
Position subject to pre-employment background investigation
You must meet qualifications requirements by the closing date of this announcement
A one year probationary may be required
Qualifications
In addition to the Basic Education Requirement (in the Education section below), to qualify for this position you must meet the requirements below. Specialized experience is experience that has equipped you with the particular ability, skill, and knowledge to successfully perform the duties of this position and is typically in or related to this line of work.

NASA utilizes OPM-approved qualification and rating requirements specific for Aerospace Technology (AST) positions which recognizes NASA's unique aerospace work. The specific qualifications and minimum education requirements are further described below and within the education section of the job announcement.

To qualify for GS-13, you must have one year of directly related specialized experience equivalent to the GS-12 level in the federal sector:
Applying electronics/electrical engineering practices to support implementation of technology;
Designing and testing avionics hardware or software for aerospace applications;
Applying electronics/electrical engineering practices to resolve technical problems.
Your resume must include a clear and detailed narrative description, in your own words, of how you meet the required specialized experience. Experience statements copied from a position description, vacancy announcement or other reference material constitutes plagiarism and may result in disqualification and losing consideration for the job.
Education
Basic Education Requirement: You must have successfully completed a bachelor's degree with a major in one of the following:
a) Engineering from a college or university that has ABET accredited engineering programs
b) Physical Science, Mathematics, Life Science or other field of Science
c) Computer Science that included 30 semester hours or 45 quarter hours of course work in any combination of mathematics, statistics and computer science with at least half of those hours in mathematics and statistics courses that included differential and integral calculus.

If you did not complete a qualifying bachelor's degree, you may be eligible if you have obtained a graduate degree in an AST qualifying field, as listed above.

Degrees in engineering technology ARE NOT considered qualifying for this position.

Engineering degrees earned within the United States: Engineering degrees earned within the United States must be from a college or university that has at least one ABET accredited engineering program. To find out if a school has at least one ABET accredited program, please visit http://www.abet.org.

Engineering degrees earned outside the United States: Engineering degrees earned outside the United States must be recognized by a Mutual Recognition Agreement (MRA), often known as accords. These are non-governmental agreements among organizations that accredit academic degree programs. MRAs recognize the substantial equivalence of mature accreditation systems and programs accredited by signatory organizations within their jurisdictions. For a listing of Signatories, please visit, https://www.abet.org/global-presence/mutual-recognition-agreements/is-your-program-recognized/.

Science and other related degrees earned within the United States: Science and other related degrees must have been awarded from colleges or universities that are accredited by recognized accrediting organizations. For a list of schools that meet this criteria, go to http://ope.ed.gov/accreditation/.

Science and other related degrees earned outside the United States: If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show that the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs. These education credentials must be deemed equivalent to that gained in an accredited U.S. education program; or full credit has been given for the courses at a U.S. accredited college or university. For further information, visit: https://www2.ed.gov/about/offices/list/ous/international/usnei/us/edlite-visitus-forrecog.html.

All degrees must have been received in the year of, or any year subsequent to the original date of accreditation.
Additional information
Additional selections may be made for similar positions across NASA within the local commuting area(s) of the location(s) identified in this announcement. By applying, you agree to have your application shared with interested selecting official(s) within NASA. CTAP/ICTAP will be cleared for any additional selection from this announcement.

If you have special priority selection rights under the Agency Career Transition Assistance Program (CTAP) or the Interagency Career Transition Assistance Program (ICTAP), you must:

Indicate your eligibility when applying for a position. The questionnaire asks you to identify your ICTAP/CTAP eligibility.
Meet the minimum qualifications requirements for the position
Submit proof that you meet the requirements for CTAP/ICTAP as indicated in 'Required Documents'

For additional information about CTAP/ICTAP eligibility, click here - https://www.opm.gov/policy-data-oversight/workforce-restructuring/employee-guide-to-career-transition/#ictap.
Benefits
A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.
Review our benefits
Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.
How You Will Be Evaluated
You will be evaluated for this job based on how well you meet the qualifications above.
Direct Hire Authority: These positions will be filled through the Office of Personnel Management's Direct Hire Authority. Category rating and veterans' preference will not be considered in evaluating applicants. For more information on Direct Hire Authority, please see: OPM Direct Hire Fact Sheet.

Veterans: Under the provisions of Direct Hire Authority, veterans' preference does not apply. However, applicants who are eligible for veterans' preference are encouraged to include that information in their application and submit supporting documentation (i.e. DD-214, or other substantiating documents). For more information please see: Veterans' Preference information on the FedsHireVets website.

You will be evaluated for this position based on how well you meet the qualifications and eligibility requirements listed in this vacancy announcement. To determine your qualifications and referral status, we may review your resume and supporting documentation and compare it against your responses to the vacancy questionnaire. Overstating your qualifications and/or experience in your application materials or application questionnaire may result in your removal from consideration.

You will be assessed on the following competencies:
Problem Solving
Avionics
Design and Development Engineering
Electrical and Electronic Systems
NASA considers paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional; philanthropic; religious; spiritual; community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.
Benefits
A career with the U.S. government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Opens in a new windowLearn more about federal benefits.
Review our benefits
Eligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time or intermittent. Contact the hiring agency for more information on the specific benefits offered.
Required Documents
As a new or existing federal employee, you and your family may have access to a range of benefits. Your benefits depend on the type of position you have - whether you're a permanent, part-time, temporary or an intermittent employee. You may be eligible for the following benefits, however, check with your agency to make sure you're eligible under their policies.
A complete application package includes a resume, required documents and completion of the vacancy announcement questionnaire. Please see this guidance: What to include in your resume. Your resume should describe your specialized experience and support your answers to the vacancy announcement questionnaire. If you are using a Curriculum Vitae (CV) as a resume, it must meet all requirements listed above for a complete resume package. Please note: if any of the following types of information are included on your resume, your application package will be disqualified:
Classified or government sensitive information.
Social Security Number (SSN)
Photos of yourself
Personal information, such as age, gender, religious affiliation, etc.
Encrypted and digitally signed documents.
If your resume contains any of the above information, you must redact that information prior to the submission of your application.

The following documents are required:
Resume
Transcript


For transcripts the following documents are acceptable:
An unofficial transcript
A copy of an official transcript
You will lose consideration if you do not submit proof of your education. Documents must fully support the education requirements listed above. Incomplete documents or documents that do not show completion of required degree program or coursework may result in disqualification.

There may be other supporting documents (licenses, certification, veterans preference, etc.), depending on your answers to the questionnaire and job announcement description, that you may need to submit.

If you are a surplus or displaced employee (CTAP and ICTAP), submit proof that you meet the requirements for CTAP/ICTAP. This includes copies of your agency notice, most recent Performance Rating and most recent Notification of Personnel Action (SF-50) noting current position, grade level, and duty location.

Official documents are required at the time of appointment for verification of eligibility and qualifications.
How to Apply
Please read the entire announcement and all the instructions before you begin an application and have all required information available. We encourage you to provide a complete description of your educational achievements and include both paid and non-paid work in the experience portion of your resume. If you submit a resume that does not contain the required information, you may lose consideration.

To apply for this position, you must complete the initial online application, to include the initial online assessment and submission of the required documentation specified in the Required Documents section below.

The complete application package must be submitted by 11:59 PM (ET) on the closing date of the announcement to receive consideration. The application process is as follows:

1. To begin the application process, you will need to be logged into your USAJOBS account. If you do not have a USAJOBS account, you will need to create one before beginning the application process. Once logged in to your account, click on the ""Apply"" link.
2. Follow the prompts to select your resume and/or other supporting documents to be included with your application package. We strongly encourage you to utilize the USAJOBS resume builder when creating your resume. Using the resume builder will help you ensure your resume includes important information related to your qualifications and eligibility for this position. Answer the questions presented in the application and attach all necessary supporting documentation. During the application process you can review, edit, delete and update your information. We'll automatically save your progress as you go, so you won't lose any changes. Your uploaded documents may take several hours to clear the virus scan process.
3. After acknowledging you have reviewed your application package, complete the 'Include Personal Information' section as you deem appropriate and click to continue with the application process. You will be taken to the vacancy questionnaire which you must complete in order to apply for the position. Complete the online application, verify all required documentation is included with your application package, and submit the application.
4. Click the Submit Application button prior to 11:59PM (ET) on the announcement closing date.
If you are unable to apply online or need to fax a document you do not have in electronic form, view the following link for information regarding an Alternate Application.

If you have questions about this announcement, you may contact the agency toll free at the phone number located below. Be advised - application materials faxed, emailed, and/or mailed to Kennedy Space Center will not be accepted for this announcement.

NASA provides reasonable accommodations to applicants with disabilities. If you are an applicant with a disability and need a reasonable accommodation for any part of the application and hiring process, please notify the agency contact center listed on the job vacancy announcement. The decision on granting reasonable accommodations will be on a case-by-case basis.
Agency contact information
NASA Shared Services Contact Center
Phone
1-877-677-2123
Fax
1-866-779-6772
Email
nssc-contactcenter@mail.nasa.gov
Address
Kennedy Space Center
Space Commerce Way
Titusville, FL 32899
US
Next steps
Once you submit your application package, you will receive an acknowledgement email. Throughout the process you will receive regular status updates through USAJOBS. To verify the status of your application, log into your USAJOBS account (https://my.usajobs.gov/Account/Login), all of your applications will appear on the Welcome screen. The Application Status will appear along with the date your application was last updated. For information on what each Application Status means, visit: https://www.usajobs.gov/Help/how-to/application/status/.

Whether or not you are contacted for an interview depends upon the location of the position and the judgment of the hiring manager.

If you are selected, you will be notified by phone or email with a tentative job offer. If you fail to meet the conditions of employment or any other pre-employment requirements, such as missing a scheduled appointment, we may rescind a tentative job offer.

An official, written job offer will be issued once all requirements have been verified.
Fair and Transparent
The Federal hiring process is set up to be fair and transparent. Please read the following guidance.
Equal Employment Opportunity (EEO) Policy
Reasonable accommodation policy
Financial suitability
Selective Service
New employee probationary period
Signature and false statements
Privacy Act
Social security number request
Required Documents
A complete application package includes a resume, required documents and completion of the vacancy announcement questionnaire. Please see this guidance: What to include in your resume. Your resume should describe your specialized experience and support your answers to the vacancy announcement questionnaire. If you are using a Curriculum Vitae (CV) as a resume, it must meet all requirements listed above for a complete resume package. Please note: if any of the following types of information are included on your resume, your application package will be disqualified:
Classified or government sensitive information.
Social Security Number (SSN)
Photos of yourself
Personal information, such as age, gender, religious affiliation, etc.
Encrypted and digitally signed documents.
If your resume contains any of the above information, you must redact that information prior to the submission of your application.

The following documents are required:
Resume
Transcript


For transcripts the following documents are acceptable:
An unofficial transcript
A copy of an official transcript
You will lose consideration if you do not submit proof of your education. Documents must fully support the education requirements listed above. Incomplete documents or documents that do not show completion of required degree program or coursework may result in disqualification.

There may be other supporting documents (licenses, certification, veterans preference, etc.), depending on your answers to the questionnaire and job announcement description, that you may need to submit.

If you are a surplus or displaced employee (CTAP and ICTAP), submit proof that you meet the requirements for CTAP/ICTAP. This includes copies of your agency notice, most recent Performance Rating and most recent Notification of Personnel Action (SF-50) noting current position, grade level, and duty location.

Official documents are required at the time of appointment for verification of eligibility and qualifications.

Help
This job is open to
The public
U.S. Citizens, Nationals or those who owe allegiance to the U.S.","$114,047 /yr (est.)",10000+ Employees,College / University,Education,Colleges & Universities,1907,$500 million to $1 billion (USD)
"Peraton
3.6",3.6,"Belcamp, MD",Integration Systems Engineer III (Data & Analytics),"Responsibilities:
What you'll do:
Provides feedback to design engineers and evaluates end-to-end systems and systems-oriented products through their entire life cycle.
Working as expert, conducts research and evaluates technical performance of software products and overall segments and systems.
Ensures products and systems comply with requirements and government information assurance and cyber security standards and practices through formal verification methods.
Verifies/validates systems with specific emphasis on network operations and cyber warfare tactics, techniques, and procedures focused on the threat to information networks.
Assesses performance using evaluation criteria and technical performance measures.
Prepares assessments and cyber threat profiles of current and planned products based on sophisticated testing, research, and analysis.
Participates in design reviews of components (hardware and software) to ensure applicability to the current system and traceability of requirements.
Reviews test plans/procedures and ensures they verify/validate the requirements.
Develops and maintains analytical procedures to meet changing requirements.
Produces high-quality papers, presentations, recommendations, and findings for senior US government intelligence and operations officials.

Systems Engineer with a focus on DOD5000.02 artifacts and documentation. Tasks include:
Applies systems engineering principles throughout the systems life cycle phases: Concept, Development, Production, Utilization, Support and Retirement.
Interacts with the Government regarding Systems Engineering technical considerations and for associated problems, issues or conflicts.
Communicates with other program personnel, government overseers, and senior executives.
Responsibility for the technical integrity, quality, and completeness of work performed and deliverables associated with one or more of the 25 process areas defined by ISO/IEC15288 to include: Technical Process Area, Enterprise Process Area, and Agreement Process Area.
Will be expected to contribute to the development of sections of systems engineering documentation such as System Engineering plans, Initial Capability documents, Requirements specifications, and Interface Control Documents.
May be responsible for supervision and mentoring of subordinate staff
Qualifications:
BS 5-7 Years, MS 3-5, PhD 0-2

Minimum Qualifications:
Active TS/SCI Security Clearance
Bachelor's degree in STEM field
DoD 8570.01-m IAT Level II
Preferred Experience:
7 years of experience in DoD systems development
Experience with use case development
Experience with requirements derivation
Experience with developing technical project artifacts
Familiarity with Agile software development process
Experience with Software Engineering processes
Experience with C, C#, C++, SQL, or Java.
Experience with Jira, Confluence, and GIT.
At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We’re fully committed to the growth of our employees. From fully comprehensive medical plans to professional development resources, we are there to support you all the way.
Peraton Overview:
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers.
Target Salary Range: $86,000 - $138,000. This represents the typical salary range for this position based on experience and other factors. EEO: An Equal Opportunity Employer including Disability/Veteran.","$112,000 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $10 billion (USD)
"TikTok
3.5",3.5,"Seattle, WA","Backend Software Engineer, Global E-Commerce Data Intelligence","Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Mountain View, Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
Join us.

The e-commerce industry has seen tremendous growth in recent years and has become a hotly contested space amongst leading Internet companies, and its future growth cannot be underestimated. With millions of loyal users globally, we believe TikTok is an ideal platform to deliver a brand new and better e-commerce experience to our users. Our product engineering team is responsible for building an e-commerce ecosystem that is innovative, secure and intuitive for our users. We are looking for passionate and talented people to join us as we drive the future of e-commerce here at TikTok.

Responsibilities:
Develop data insights capabilities for the global e-commerce platform, enabling users to extract actionable insights and intelligence from data to maximize their revenue potential and decision-making efficacy.
Collaborate closely with product and data teams to evolve data-empowered capabilities in data visualization, operational analysis, intelligent diagnosis, product/strategy optimization, market intelligence, etc verticals.
Drive continuous improvements to engineering excellence and efficiency, lead research & development into key areas of optimizations for backend systems and services, including data security, systems architecture, and computational efficiency & scalability.
Drive and shape the growth of a highly effective product engineering team, provide professional and technical leadership to support the professional growth of individual team members
Qualifications
Bachelor or higher degree in Computer Science or related fields from accredited and reputable institutions.
2+ years experience developing highly scalable backend services and systems using at least one of Java/Golang/Python/Scala/C++
Strong software programming capabilities, exhibits good code design and coding style.
Deep understanding of data structure, algorithm design and analysis, networking, data security and highly scalable systems design.
In-depth knowledge of common databases and messaging frameworks like MySQL/Redis/Kafka etc.
Exhibits strong product/business understanding, able to align product engineering directions to support current and future product and business evolutions.
Even Better if:
Agile, quick self-learner, highly self-motivated with a strong sense of product ownership, and creative problem solver.
Deeply passionate about software coding/development and building great mobile/web applications.
Ability to lead independent research to solve complex technical problems.
Good collaborator and team player, comfortable working in a fast-moving, culturally diverse, and globally distributed team environment.
Professional level proficiency in written and spoken English, clear communicator, and open to receiving from and giving constructive feedback to the team.
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at pdi.accommodations@tiktok.com
Job Information
The base salary range for this position in the selected city is $129960 - $194750 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$162,355 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"KPMG
3.8",3.8,"Austin, TX","Associate, Data Engineer","Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today’s most important industries. Our growth is driven by delivering real results for our clients. It’s also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it’s no wonder we’re consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you’re as passionate about your future as we are, join our team.
KPMG is currently seeking an Associate, Data Engineering to join our Audit Technology organization.
Responsibilities:
Create artificial intelligence or generative artificial intelligence applications to support the execution of a high-quality audit and/or audit support activity
Define insights in large datasets by identifying trends and patterns and create data visualizations and dashboards to communicate insights to key stakeholders
Assist cross-functional teams with data-driven solutions
Support the execution of a high-quality audit and/or audit support through the diligent performance of assigned tasks and professional client and engagement team interactions
Qualifications:
Minimum one year of recent experience developing integrations using Jira, Python, REST API framework and SQL Alchemy
Bachelor’s degree from an accredited college or university
Strong technical aptitude and critical thinking and research skills
Ability to navigate various computer applications and technologies, including MS Office, ERP systems and data analysis tools
Excellent communication, time management and relationship-building skills
Able to employ sound professional judgment and professional skepticism; flexible and adaptable team player; leadership experience and resourceful in delivering high quality work
KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the salary range(s) are displayed via the URL below. The range is specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, performance, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your emotion and mental health. KPMG provides personal days off per fiscal year depending on job classification, standard work hours and years of service. Additionally, each year the firm publishes a calendar of holidays to be observed during the year. Available benefits are based on eligibility.
Albany Salary Range: Low: $67900 - High: $116700
Colorado Salary Range: Low: $71300 - High: $122500
New York City Salary Range: Low: $78100 - High: $134200
Rochester Salary Range: Low: $6900 - High: $119000

Follow this link to obtain salary ranges by city:

https://www.kpmg.us/work-for-kpmg/pay-transparency.html/?id=6727-9
KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.
KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).","$67,900 /yr (est.)",10000+ Employees,Company - Private,Management & Consulting,Business Consulting,1987,$1 to $5 billion (USD)
"Ascendion
4.3",4.3,"Dallas, TX",Data Engineer/Data Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:
Job Title: Big Data Spark Developer/Engineer
Must Haves:
Candidate should have 4-12 years of experience and ready to work from client office from Day 1
Advanced knowledge of application, data, and infrastructure architecture disciplines
Experience with security, isolation, and multi-tenant design of distributed cloud services
Hadoop ecosystem technology stacks as HDFS, HBase, Hive, Pig, Spark, MapReduce, Cloudera etc
Eclipse/IntelliJ, Maven, Jenkins, GIT, JIRA, Control M or equivalent tools
Casandra, Kafka preferred
ETL based High volume Real Time & Batch application processing
Experienced in developing large scale enterprise applications using Big Data open-source solutions such as Hadoop, Spark, Kafka, and Elastic Search
Experience with Scala, Java and/or Python
Hands-on experience with RDBMS (Oracle, MySQL) and NoSQL (Cassandra)
Experience with Change Management and Incident Management process
Location: Plano, TX or Wilmington, DE or Columbus, OH
Salary Range: The pay for this position is between $100,000- $130,000 per year. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.
Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [Ascendion Learning Management System]
Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
If interested do share me your resume on rakhi.kumari@ascendion.com
Preferred Skills:
Big Data
Spark
Python
Job details
Job ID
328380
Job Requirements
Data Engineer/Data Engineer
Location
Dallas, Texas, US
Recruiter
Rakhi
Email
rakhi.kumari@ascendion.com","$115,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
DataDelivers LLC,#N/A,"Schaumburg, IL",Big Data Engineer I,"The Big Data Engineer's primary responsibilities are to build, integrate data from various resources, and support DataDelivers big data ecosystem. The Engineer will work closely with other teammates to design optimum solutions using best practices. The Engineer is responsible to ensure the data ecosystem is built to be highly scalable and responsive through writing queries and ensuring optimal performance and availability.

The Big Data Engineer also creates ETL, batch, and automated processes on top of big datasets and creates big data warehouses to be used for reporting and analysis by DataDelivers data scientists. This role will provide build and support ingestion and connection solutions for the businesses' data science teams as well as outside partners and clients.

Responsibilities:
Work closely with SMEs and implement agreed upon solutions using best practices
Select and integrate any Big Data tools and frameworks required to provide requested capabilities
Implement ETL processes
Monitor performance and advising any necessary infrastructure changes
Monitor AWS landscape of EC2 clusters, Glue Jobs, Athena Tables, S3 data lakes and related services.
Design, implement, and tune tables, queries, stored procedures, indexes, etc.
Provide technical support to members of TS and SA team, as well as project support across client engagements
Work with geographically dispersed teams, embracing Agile and DevOps strategies for themselves and others while driving adoption to enable greater technology and business value
Stays current with relevant technology in order to maintain and/or improve functionality for authored applications.
Assume other responsibilities as requested/required

Qualifications:
Bachelor's or advanced degree in Computer Science/IT or related field
3 years of relevant experience) or (1 years of relevant experience and an advanced degree in Computer Science/IT or related field)
Proficient understanding of distributed computing principles
Ability to solve any ongoing issues with operating the cluster
Proficiency with Big Data frameworks such as Hadoop, Spark, MapReduce.
Experience building stream-processing systems, using solutions such as Storm or Spark-Streaming
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Some experience with integration of data from multiple data sources such as REST API, SFTP flat files, Streaming data etc.
Experience with NoSQL databases, such as DynamoDB, Redshift, Databricks, etc.
Experience with various ETL techniques and frameworks, such as Glue Jobs, Step Functions, etc.
Good understanding of Lambda Architecture, along with its advantages and drawbacks
Proven experience with AWS Lambda and leveraging it in various solutions such as Glue, Step Functions, CloudWatch, S3 Events, etc.
Extensive experience with Python scripts & libraries
Experience desired with Database Warehousing Design Concepts; Dimensional Modeling, Star/Snowflake Schemas, ETL/ELT, Data Marts, Analytic Playgrounds, Reporting techniques
Experience working with Agile software development methodologies, namely Scrum
Proven experience with team collaboration, release management, system, and performance monitoring
Ability to work well with people from many different disciplines and varying degrees of technical experience
Strong organizational, presentation and customer service skills. Excellent problem-solving skills to assist in detecting potential issues and issue resolution
Excellent analytical, problem resolution, organization, and time management skills.
Ability to handle multiple tasks at a time",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Data Engineer, Amazon Prime","1+ years of data engineering experience
Experience with data modeling, warehousing and building ETL pipelines
Experience with SQL
Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)
Experience with one or more scripting language (e.g., Python, KornShell)
Amazon Prime’s Science organization leads the Research & Development towards innovation for Amazon Prime. Amazon Prime is the backbone of Amazon’s consumer business and aspires to be the world’s most engaging, satisfying, and loved membership program, driving growth and profitability by spinning Amazon’s flywheel. The program serves over 200 million members across 25 countries and is key to Amazon’s customer growth and engagement. Prime Science innovates in Artificial Intelligence and Economics, to develop algorithms and systems for automated marketing, personalization, targeting, and decisioning. Within the engineering group in Prime Science, we develop world class solutions to complex scientific and engineering problems at Amazon scale. You will work alongside world class scientists to build a suite of fully automated, scalable and robust products driven by the data systems you develop.

Do you want to work with the worlds best engineers at massive scale on hard problems? Do you want to be impact over 200 million Prime members WW? Do you want to learn the latest AWS and big data technologies to build cutting-edge science products? Are you someone who likes using big data to drive high-impact business decisions? If the answer is yes, come join our team!

Key job responsibilities
Build big data pipelines for machine learning applications at Amazon scale
Advance the state of data engineering infrastructure on the latest tools (AWS Glue, Spark, AWS EMR, EMR Serverless, Ray etc...)
Improve and raise the bar on proactive data quality monitoring and alarming (e.g., anamoly detection) across big data pipelines
Work alongside science to enrichen data pipelines that feed models improving the customer experience of over 250MM customers world wide.
A day in the life
As a data engineer on this team, you will collaborate closely with Prime business leaders, scientists (economists, research scientists, applied scientists) and engineering leaders to build data solutions. You will leverage AWS technologies (EMR, EC2, S3, GLUE, KMS, Lambda, DynamoDB, etc.) to build novel systems and tackle challenges at scale. You will manipulate and process TB-sized data, supporting real-time access and orchestration across multiple systems. Your work will enhance our scientific models and data applications. As a consequence, you will have global impact, improving customer experiences for Prime members worldwide. As a successful candidate, you will successfully interact with both technical and business stakeholders.

About the team
Our team has a vision to enable Prime Science to be adopted WW across Amazon so as to drive the best possible customer experience. We set and raise engineering excellence standards in Amazon for science-based products. We are a unique team as we sit at the intersection of building engineering systems at Amazon scale and availability, incorporating the latest science (econometrics, ML, AI etc...), and delivering cross-cutting applications to delight over 200 million customers. Building and our science products at-scale and in real-time, creates interesting new data engineering challenges. These give a person in this role a head start in solving artificial intelligence challenges that will be ubiquitous 3-5 years from now.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.
Experience as a data engineer or related specialty (e.g., software engineer, business intelligence engineer, data scientist) with a track record of manipulating, processing, and extracting value from large datasets
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$81,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
Next Generation Inc. (NGI),#N/A,United States,Snowflake Developer/Data Engineer,"Job Summary:
Next Generation, Inc., an Equal Opportunity Employer, is seeking a Snowflake developer with considerable experience for a remote full time position starting immediately.
Job Description

The Snowflake Developer/Data Engineer will be responsible for creating very large-scale data analytics solutions based on the Snowflake Data Warehouse.
Design, implement, and optimize large-scale data and analytics solutions on Snowflake Cloud Data Warehouse is essential.
Develop Integration with other third party tools and snowflake
Create standardized procedures for data flows
Perform Tuning, testing and problem analysis
Automate manual processes and optimize data flows
Resolve production issues to ensure seamless data processing
Implementing ETL pipelines within and outside of a data warehouse using Python and Snowflakes SQL
Querying Snowflake using SQL.
Development of scripts using Unix, Python, etc. for loading, extracting, and transforming data.
Troubleshooting production issues in Data Warehouses like reloading data, transformations, and translations
Develop a Database Design and Reporting Design based on Business Intelligence and Reporting requirements
3rd party API calling and integration experience
Semantic Layer design and development to support Tableau reporting layer

Job requirements:
Enterprise-level technical exposure to Snowflake applications (3+ years)
Knowledge of Amazon Web Services
Preferred: Snowflake Certification
Preferred: Public health experience
Experience with Snowflake warehousing, architecture, processing
Experience with Data ingestion into Snowflake
Experience with Snowflake configuration and customization based on client user stories and underlying acceptance criteria.",#N/A,1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
Hull Tactical Asset Allocation,#N/A,"Chicago, IL",Financial Data Engineer,"Hull Tactical is seeking a data manager to join our growing equity options team to build and manage daily data processes. The mission is to curate and analyze fundamental and sentiment data (news, social, Reddit, etc.) to anticipate market movements in US listed companies including “meme” stocks.
Practical experience managing a “fundamental data” store is necessary for a candidate to be successful.
“Fundamental data” means information about individual US stocks and options that is updated at most daily. Examples are:
Corporate actions, such as dividends and splits
Symbol name changes
Industry sector mapping and changes
Earnings dates
Fundamental data is mostly sourced from vendors such as FactSet, Bloomberg, Thomson Reuters or EOD Historical Data
Some of the fundamental data is derived in-house from intraday data including trading volume, open interest, and aggregated tick data

Position Location: Chicago, IL
Required Skills
Experience with fundamental data from vendors such as FactSet, Bloomberg, Thomson Reuters, EOD Historical Data
Experience with basic relational modeling and SQL
Practical experience working with MySQL, PostgreSQL or similar databases
Experience working in a Linux environment
Basic Linux command line skills and familiarity with simple Bash scripts
Python scripting to build and maintain data ingestion pipelines
Experience with Pandas and with Python database scripting
Managing daily recurring data processing jobs with tools such as cron, rundeck, etc.
Desired Skills
Python programming
Experience using git, feature branches and automated testing
Experience with generating data for reporting tools using Python
Prior experience working on a fundamental data team
Ability to identify and correct performance bottlenecks
Bachelor’s or advanced degree in computer science, information technology or related field
WHAT WE OFFER
Competitive financial rewards with further upside tied individual, team, and firm performance
Employee benefits that include exceptional insurance and 401K matching program
Friendly and collegial work environment
Opportunity to learn from successful industry experts

Please send your CV or Resume to resume@hulltactical.com in PDF format only. Non-PDF files will be rejected!","$95,704 /yr (est.)",1 to 50 Employees,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Q1 Technologies
3.4",3.4,"Tampa, FL",Test Data Management Engineer,"Expert in Test Data Management with 3+ - 8 years of experience working on TDM tools
CA TDM, Deplhix and Data Modelling experience is must have.
Strong knowledge in implementing TDM capabilities across testing life cycles
Experience working with data sources across On Prem & Cloud
Experience working on TDM tools such as Broadcom TDM, Informatica TDM, Delphix, Javelin, GenRocket etc.
Integrate data provisioning solutions with Automation, CI/CD, Data Pipelines.
Ability to understand data landscape and draw architectures.
Ensure solutions are secured, scalable, resilient and bring agility into product development
Ability to measure and monitor data coverage using KPIs/OKRs
Operationalizing data pipelines – from requests intake, processing, reserving, delivery and restoration of data
Processing scaled real time data
Producing intelligent data sets in lower level environments – synthetic/manufactured data
Server and Docker experience.
Desensitize confidential information with masking/obfuscation techniques
Structured data sources – Oracle, MySQL, Terradata, MongoDB, , DB2, cloud storage, etc.
Unstructured data sources - app server logs, monitoring tools, etc.
Working knowledge in Retail industry with focus on Agile and DevOps environments; knowledge of DevOps operations and test integration into the DevOps process and tools
Job Type: Contract
Salary: $45.00 - $55.00 per hour
Experience level:
7 years
8 years
Schedule:
8 hour shift
Ability to commute/relocate:
Tampa, FL 33602: Reliably commute or planning to relocate before starting work (Required)
Experience:
TDM: 7 years (Required)
Data Modelling: 5 years (Required)
Prem & Cloud: 5 years (Required)
Work Location: In person",$50.00 /hr (est.),201 to 500 Employees,Private Practice / Firm,Information Technology,Information Technology Support Services,2002,$25 to $100 million (USD)
"Enterra Solutions
4.5",4.5,Remote,Senior Data Engineer,"LOCATION: U.S. Eastern Time Zone
Must reside in the US – preferably in the Eastern Time Zone. Remote working permitted. Must be eligible to work in the US without sponsorship now or in the future. This is a full-time position with benefits. Contractors will not be considered for this position.

Who we are:
Enterra provides solutions that leverage sophisticated machine learning, artificial intelligence (ontologies, inference engines and rules) and natural language processing to provide highly actionable insights and recommendations to business users. Today, our solutions impact just about every aspect of the products you buy at your local store – from what is available to how it is priced and even where it is placed on the shelf. Our SolaaS (Solution as a Service) solutions are deployed within private clouds – principally on Azure. We help transform market-leading companies into true data-driven digital enterprises.

What you will do:
The ideal candidate must be collaborative, and deadline driven. Because of the nature of our work and our technology, successful candidates must take a growth mindset and be comfortable with ambiguity, with the ability to take a proactive, structured approach to achieve results. Results-orientation and deadline driven are critical in our fast-paced environment.
The successful candidate will join a diverse team to:
Build unique high-impact business solutions utilizing advanced technologies for use by world class clients.
Create and maintain the underlying data pipeline architecture for the solution offerings from raw client data to final solution output.
Create, populate, and maintain data structures for machine learning and other analytics.
Use quantitative and statistical methods to derive insights from data.
Guide the data technology stack used to build Enterra's solution offerings.
Combine machine learning, artificial intelligence (ontologies, inference engines and rules) and natural language processing under a holistic vision to scale and transform businesses — across multiple functions and processes.
Responsibilities Include:
Work with other Enterra personnel to develop and enhance commercial quality solution offerings
Design, create and maintain optimal data pipeline architecture, incorporating data wrangling and Extract-Transform-Load (ETL) flows.
Assemble large, complex data sets to meet analytical requirements – analytics tables, feature-engineering etc.
Design and build the infrastructure required for optimal, automated extraction, transformation, and loading of data from a wide variety of data sources using SQL and other 'big data' technologies such as Databricks.
Design and build automated analytics tools that utilize the data pipeline to derive actionable insights.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Design and develop data integrations and data quality framework
Develop appropriate testing strategies and reports for the solution as well as data from external sources.
Evaluate new technology for use within Enterra.
Work with other Enterra and client personnel to administer and operate client-specific instances of the Enterra solution offerings
Configure the data pipelines to accommodate client-specific requirements to onboard new clients.
Perform regular operations tasks to ingest new and changing data – implement automation where possible.
Implement processes and tools to monitor data quality - investigate and remedy any data-related issues in daily solution operations.
May provide guidance and oversight to fellow data engineers
Requirements:
Bachelor's degree in Computer Science or a STEM (Science, Technology, Engineering or Math) field required
Minimum of 7 years hands on experience as a data engineer or similar position.
Minimum of 7 years commercial experience with Python or Scala Programming Language
Minimum of 7 years SQL and experience working with relational databases (Postgres preferred).
Experience with at least one of the following – Databricks, Spark, Hadoop or Kafka
Demonstratable knowledge and experience developing data pipelines to automate data processing workflows
Demonstratable experience in data modeling
Demonstratable knowledge of data warehousing, business intelligence, and application data integration solutions
Demonstratable experience in developing applications and services that run on a cloud infrastructure Azure preferred
Excellent problem-solving and communication skills
Ability to thrive in a fast-paced, remote environment.
Comfortable with ambiguity with the ability to build structure and take a proactive approach to drive results.
Attention to detail – quality and accuracy in work is essential.

The following additional skills would be beneficial:
Knowledge of one or more of the following technologies: Data Science, Machine Learning, Natural Language Processing, Business Intelligence, and Data Visualization.
Knowledge of statistics and experience using statistical or BI packages for analyzing large datasets (Excel, R, Python, Power BI, Tableau etc.).
Experience with container management and deployment, e.g., Docker and Kubernetes",#N/A,1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,2001,Unknown / Non-Applicable
"LPL Financial
3.9",3.9,United States,Sr. Data Engineer,"Are you a team player? Are you curious to learn? Are you interested in working in meaningful projects? Do you want to work with cutting-edge technology? Are you interested in being part of a team that is working to transform and do things differently? If so, LPL Financial is the place for you!
LPL Financial (Nasdaq: LPLA) was founded on the principle that the firm should work for the advisor, and not the other way around. Today, LPL is a leader* in the markets we serve, supporting more than 18,000 financial advisors, 800 institution-based investment programs and 450 independent RIA firms nationwide. We are steadfast in our commitment to the advisor-centered model and the belief that Americans deserve access to personalized guidance from a financial advisor. At LPL, independence means that advisors have the freedom they deserve to choose the business model, services, and technology resources that allow them to run their perfect practice. And they have the freedom to manage their client relationships, because they know their clients best. Simply put, we take care of our advisors, so they can take care of their clients.
Job Overview:
As a Sr. Data Engineer, you will collaborate with our users and other data product teams to understand their needs and build impactful data/analytics solutions. You will design and build data pipelines to support applications and data science projects following software engineering best practices.
Responsibilities:
Work with development teams and other project leaders/stakeholders to provide technical
solutions that enable business capabilities
Design and develop data applications using big data technologies (AWS, Spark) to ingest, process,
and analyze large disparate datasets
Build robust data pipelines on the Cloud using AWS Glue, Aurora Postgres, EKS, Redshift, PySpark, Lambda, and Snowflake
Build Rest API using Python / C#, EKS, Lambda
Build the infrastructure required for optimal extraction, transformation, and loading of data from various data sources using SQL and AWS ‘big data’ technologies
Work with data and analytics experts to strive for greater functionality in our data systems
Implement architectures to handle large-scale data and its organization
Execute strategies that inform data design and architecture partnering with enterprise standard
Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement
What are we looking for?
We want strong collaborators who can deliver a world-class client experience. We are looking for people who thrive in a fast-paced environment, are client-focused, team oriented, and are able to execute in a way that encourages creativity and continuous improvement.
Requirements:
BS in Computer Science, Applied Mathematics, Physics, Statistics or area of study related to data sciences and data mining or relevant experience
5+ years of solid development in big data stack and programming experience in Python/C#, and Spark/Scala
3+ years’ experience using AWS services like Glue, RDS, Redshift, Aurora Postgres, EKS, Lambda, and Snowflake
3+ years of experience in a data-engineering role to build highly scalable large data pipelines & API.
Preferences:
Experience in CI/CD tools like TeamCity, Octopus, GitHub Actions
Nice to have experience with microservice development, Docker, Kubernetes
Hands-on experience in BI Tools like Tableau, Power BI
DynamoDB, Microsoft SQL Server, Oracle, Fivetran

Pay Range:
$97,200-$145,800/year
Actual base salary varies based on factors, including but not limited to, relevant skill, prior experience, education, base salary of internal peers, demonstrated performance, and geographic location. Additionally, LPL Total Rewards package is highly competitive, designed to support your success at work, at home, and at play – such as 401K matching, health benefits, employee stock options, paid time off, volunteer time off, and more. Your recruiter will be happy to discuss all that LPL has to offer!

Why LPL?
At LPL, we believe that objective financial guidance is a fundamental need for everyone. As the nation’s leading independent broker-dealer, we offer an integrated platform of proprietary technology, brokerage, and investment advisor services. We provide you with a work environment that encourages your creativity and growth, a leadership team that is supportive and responsive, and the opportunity to create a career that has no limits, only amazing potential.
We are one team on one mission. We take care of our advisors, so they can take care of their clients.
Because our company is not too big and not too small, you can seize the opportunity to make a real impact. We are committed to supporting workplace equality, and we embrace the different perspectives and backgrounds of our employees. We also care for our communities, and we encourage our employees to do the same. This creates an environment in which you can do your best work.
Want to hear from our employees on what it’s like to work at LPL? Watch this!
We take social responsibility seriously. Learn more here
Want to see info on our benefits? Learn more here
Join the LPL team and help us make a difference by turning life’s aspirations into financial realities. Please log in or create an account to apply to this position. Principals only. EOE.
Information on Interviews:
LPL will only communicate with a job applicant directly from an @lplfinancial.com email address and will never conduct an interview online or in a chatroom forum. During an interview, LPL will not request any form of payment from the applicant, or information regarding an applicant’s bank or credit card. Should you have any questions regarding the application process, please contact LPL’s Human Resources Solutions Center at (800) 877-7210.","$121,500 /yr (est.)",5001 to 10000 Employees,Company - Public,Financial Services,Investment & Asset Management,1968,$1 to $5 billion (USD)
"Cox Automotive
4.0",4.0,"Atlanta, GA",Senior Data Engineer,"Cox Automotive is seeking a Senior Data Engineer to join our Manheim team! This is a full-time position based in our Atlanta, GA office. We work a hybrid schedule, with the expectation that team members to report into our Atlanta office 1-2 times per week.

We are migrating data from Oracle to Snowflake and seeking a Senior Data Engineer with extensive hands on experience with Oracle database, Snowflake cloud platforms, building data pipelines, and a very strong SQL knowledge.

Responsibilities :

Applies advanced knowledge of Data Engineering principles, methodologies and techniques to design and implement data loading and aggregation frameworks.

Gathers and processes raw, structured, semi-structured and unstructured data using batch and real-time data processing frameworks.

Strong hands-on knowledge of Snowflake.

Creates and maintains optimal data pipeline architectures.

Ensures that required data is available, can be trusted and is readily accessible by those who need it.

Influences the data infrastructure roadmap.

Identifies, designs and implements internal data management process improvements.

Drives the implementation of tools and frameworks for automating the identification of data quality issues.

Plays a key role in application development projects to evolve the company's database architecture and design.

Automates manual processes, transforming them into repeatable capabilities.

Designs, develops and implements dashboards and reports to facilitate data review and analysis.

Data Model Design and Integration to support various Manheim Product lines related to operational functions for physical and digital auctions.

Query optimization and performance tune ups.

Backfilling / fixing large volume data.

Detect and fix data discrepancies/ mismatch from the source systems.

Minimum Requirements :
Bachelor's degree in Computer Science or related field plus at least 4 years of relevant work experience
In lieu of a degree, qualified candidates would require 8+ years of relevant professional experience
Substantial experience with Snowflake Cloud Data Platform, Oracle Database, SQL and building data pipelines



Preferred Qualifications:


Use of Data Analysis/Exploration/Intelligence tools like Power BI, BOBJ or Tableau
Alert creation based on Data quality/discrepancies
Design and maintenance of data pipelines using DBT
Full lifecycle application development related to middleware and enterprise data movement
Ability to develop scalable production-ready data integration and processing solutions


About Cox Automotive

At Cox Automotive, people of every background are driven by their passion for mobility, innovation and community. We transform the way the world buys, sells, owns and uses cars, accelerating the industry with global powerhouse brands like Autotrader, Kelley Blue Book, Manheim and more. What's more, we do it all with an emphasis on employee growth and happiness. Drive your future forward and join Cox Automotive today!

About Cox

Cox empowers employees to build a better future and has been doing so for over 120 years. With exciting investments and innovations across transportation, communications, cleantech and healthcare, our family of businesses - which includes Cox Automotive and Cox Communications - is forging a better future for us all. Ready to make your mark? Join us today!

Benefits of working at Cox may include health care insurance (medical, dental, vision), retirement planning (401(k)), and paid days off (sick leave, parental leave, flexible vacation/wellness days, and/or PTO). For more details on what benefits you may be offered, visit our benefits page .

Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law. Cox provides reasonable accommodations when requested by a qualified applicant or employee with disability, unless such accommodations would cause an undue hardship.

Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.","$127,979 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2014,Unknown / Non-Applicable
"CBRE
4.0",4.0,"Sterling, VA",Chief Engineer - Data Center Manager,"Posted
30-Aug-2023
Service line
GWS Segment
Role type
Full-time
Areas of Interest
Data Centers, Engineering/Maintenance, Facilities Management
Location(s)
Ashburn - Virginia - United States of America, Sterling - Virginia - United States of America
JOB SUMMARY
This role oversees the operations and development of a team of Critical Environment engineers onsite, ensuring they provide both Preventative Maintenance (PM) and Repair Services to the Client & their customers onsite (within agreed Service Level Agreement.) Also, assists the client's Data Center Manager, providing support for Data Center operations. Provide on-site support for the provision and maintenance of Critical Environment services.

ESSENTIAL DUTIES AND RESPONSIBILITIES
Manage unforeseen circumstances that occur and provide relevant feedback to Client / CBRE management where necessary.
Mentor & motivate the Critical Environment team, providing them with regular feedback to ensure they continually improve. Identify areas for training where necessary.
Overall responsibility for Configuration Management (CM)MS Work Orders, Preventative Maintenance (PM), Configuration Management (CM), or Repairs within the agreed SLA timeframe, or escalate if issues cannot be resolved promptly.
Overall responsibility to ensure the completion of:
Facility infrastructure equipment installations within the agreed SLA timeframe and to applicable internal, manufacture and industry standards.
Information Technology equipment power installations, relocation and decommission requests within the agreed SLA timeframes and to applicable internal, manufacture and industry standards.
Daily routine checks and cleanup of the data halls and record their findings.
Mechanical and Electrical troubleshooting support (chiller, Computer Room Air Conditioning (CRAC), Computer Room Air Handler (CRAH), Uninterruptible Power Supply (UPS), Power Distribution Unit (PDU), Static Transfer Switches (STS), etc.)
Ensure all deployments are installed to applicable internal, manufacture and industry standards.
Ensure that all records are updated following any changes made and that documentation is also kept up to date for all applicable processes.
Ensure that Method Statements and Risk Assessments are prepared and used for all tasks, providing safe working practices at all times.

SUPERVISORY RESPONSIBILITIES
Provides formal supervision to individual employees within single functional or operational area. Recommends staff recruitment, selection, promotion, advancement, corrective action and termination. Plans and monitors appropriate staffing levels and utilization of labor, including overtime. Prepares and delivers performance appraisal for staff. Mentors and coaches team members to further develop competencies. Leads by example and models behaviors that are consistent with the company's values.
QUALIFICATIONS
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

EDUCATION and EXPERIENCE
High School Diploma/GED required, Bachelors Degree preferred. 6-8 years of experience in mechanical or electrical engineering, preferred.
Experience of leading and motivating a Critical Environment Team. Accredited training in the installation of DC Facilities Infrastructure and Building Management System (BMS), preferred. Experience of leading and motivating a Critical Environment Team. A proven knowledge of Critical Facility or DC equipment and their components including UPS, PDU, STS, EG, CRAC, CRAH , etc. A strong understanding of the Data Center environment, and the working restrictions applicable to such environments.

CERTIFICATES and/or LICENSES
None

COMMUNICATION SKILLS
Excellent written and verbal communication skills. Strong organizational and analytical skills. Ability to provide efficient, timely, reliable and courteous service to customers. Ability to effectively present information.
Ability to respond effectively to sensitive issues.

FINANCIAL KNOWLEDGE
Requires advanced knowledge of financial terms and principles. Ability to calculate intermediate figures such as percentages, discounts, and commissions. Conducts advanced financial analysis.

REASONING ABILITY
Ability to comprehend, analyze, and interpret complex documents. Ability to solve problems involving several options in situations. Requires advanced analytical and quantitative skills.

OTHER SKILLS and/or ABILITIES
Experience in a financial setting working with billing and payables; prior experience using a
financial system; and, the ability to use Microsoft Excel.
Ability to comprehend and interpret instructions, short correspondence, and memos and ask clarifying questions to ensure understanding.
Ability to write routine reports and correspondence.
Ability to respond to common inquiries or complaints from clients, co-workers, and/or supervisor.
Ability to effectively present information to an internal department and/or large groups of employees.

SCOPE OF RESPONSIBILITY
Decisions made with thorough understanding of procedures, company policies, and business practices to achieve general results and deadlines. Responsible for setting work unit and/or project deadlines. Errors in judgment may cause short-term impact to department.
CBRE is an equal opportunity employer that values diversity. We have a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law. We also provide reasonable accommodations, as needed, throughout the job application process. If you have a disability that inhibits your ability to apply for a position through our online application process, you may contact us via email at recruitingaccommodations@cbre.com or via telephone at +1 866 225 3099 (U.S.) and +1 866 388 4346 (Canada).
NOTE: Some, but not all, of our positions may have an additional requirement to comply with COVID-19 health and safety protocols, including COVID-19 vaccination proof and/or rigorous testing. If you have questions about the requirement(s) for this position, please inform your Recruiter.","$147,320 /yr (est.)",10000+ Employees,Company - Public,Real Estate,Real Estate,1906,Unknown / Non-Applicable
"Density
3.0",3.0,Remote,Senior Data Engineer,"About Density
Density’s mission is to measure and improve our footprint on the world.
We help companies understand how their workplaces are used. At Density, we build one of the most advanced people sensing systems in the world. Density can tell you how many people are in any room in near real-time, with very high degrees of accuracy and without invading privacy.
We translate that data into actionable, opinionated insights that help companies increase the financial and experiential performance of any workplace. Today, we work with companies ranging from Fortune 1000 to high growth such as Uber, Pinterest, Shopify and Okta, occupying more than a billion square feet worldwide.
The result: lower emissions, less waste, better access, safer buildings and better designed cities. It is a long term pursuit and one we could use your help achieving. That’s where you come in.
The Opportunity:
We are seeking a highly skilled and experienced Senior Data Pipeline Engineer to join our platform software team. The team's mission revolves around processing, storing, and presenting real-time analytics derived from thousands of sensors, offering insights into workplace utilization. As a Senior Data Pipeline Engineer at Density, you will be instrumental in designing, implementing, and optimizing our data pipelines. Your expertise will be crucial in transforming raw sensor data into actionable insights that drive informed decision-making across the workplace organization.
In this role you will:
Design, develop, and maintain scalable and robust data pipelines, ensuring efficient data extraction, transformation, and loading (ETL) processes.
Optimize and fine-tune existing data pipelines for performance, reliability, and scalability.
Work with large data-streams to extract meaningful analytics and insights.
Implement best practices for data governance, data security, and data quality assurance.
Collaborate with data scientists and analysts to provide them with clean, structured data for analysis and reporting.
Articulate your contributions with local French and US overseas platform team members
Find satisfaction in working remotely from your home.
The ideal candidate will have:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
5+ years of experience as a Data Engineer, with a proven track record of designing and implementing complex data solutions.
Proficiency in Python.
In-depth knowledge of SQL relational language
Excellent problem-solving skills and the ability to troubleshoot complex data issues.
Strong communication skills and the ability to work effectively in a collaborative team environment.
Nice-To-Have:
Knowledge of Rust and Go is a plus.
Strong experience with ETL processes, data modeling, and data integration techniques.
Hands-on experience with big data technologies such as Spark, and Kafka.
Familiarity with AWS cloud platform and their data services.
Experience with data warehousing solutions (e.g Clickhouse, BigQuery) is a plus.
We offer:
A company full of fun, smart, talented and legitimately kind teammates. Our culture powers everything we do and we work hard to nurture it by bringing on the right humans.
A team hailing from innovators like Apple, LinkedIn, Stripe, Meraki, Flexport, WeWork, NASA & beyond.
$227M raised from investors including Kleiner Perkins, Founders Fund and Upfront Ventures.
The chance to change the built world as we know it.

Density provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
Job Compensation Range:
Salary Range: €60,000.00 - €90,000.00
Preferred Primary Location: Paris, France

An important note on salary:
The annual pay range for this position is based on the preferred primary location of the role which is listed above. If you are applying to this role at a location that is not the preferred primary location, please keep in mind the salary range will vary and may fall outside of what is listed. Only in truly rare and exceptional circumstances, where an external candidate has experience, credentials or expertise that far exceed those required or expected for the position, would the Density consider paying a salary or rate near the higher end of the range. Equity may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, depending on the position offered.",#N/A,1 to 50 Employees,Company - Private,Information Technology,Internet & Web Services,2014,Unknown / Non-Applicable
"Parrish Medical Center
2.7",2.7,"Titusville, FL",Data Center Network Engineer,"Department:
Information Systems/IT

Schedule/Status:
Varies; 8:00am-4:30pm

Standard Hours/Week:
40

Location:
Titusville

General Description:
The Network Engineer – Data Center is responsible for demonstrating Parrish Healthcare’s Culture of Choice®, designing, implementing, and managing the network infrastructure of the data centers. The Network Engineer – Data Center will ensure the data center's design structure and network is secure, reliable, and efficient, and they work closely with other IT professionals to meet the organization's networking needs. The position shall exemplify the desired Culture of Choice® and philosophies of Parrish Healthcare.

Key Responsibilities:
Specify, configure, maintain, monitor, and troubleshoot local area network hardware and software, such as routers, switches, cabling, firewalls, security appliances, wireless access points, circuits, and Internet service.
Maintain excellent network performance by performing regular network monitoring and performance tuning; escalate problems to vendors as needed.
Provide proactive network support, including daily review of device and security logs, assisting with traffic monitoring, intrusion protection systems, and support for data center environment monitoring.
Establish and maintain network user accounts, user environments, directories, security, and connectivity.
Maintain a secure network by developing access standards, structure and develop processes to monitor usage.
Investigate, test, and perform software upgrades, install patches, hot-fixes, versioning, and virus definitions updates.
Prepare staff for network related changes using a variety of tools including references, training programs, and in-person support.
Provide technical support and advice as necessary for all departments and outside agencies, including researching, evaluating, and recommending new technologies.
Provide project management support for network/infrastructure projects.
Create documentation of procedures in a format that will assist other staff in carrying out those procedures.
Communicate with vendors and external support resources to research products, new technologies, and deployment of new technologies.
Maintain up-to-date skills and awareness of new and emerging network-based technologies and how they may apply to our infrastructure to support our long-term goals.
Knows fire, disaster and safety procedures and regulations as it pertains to the work area.
Performs similar or related duties as assigned.
Requirements:

Formal Education:
Bachelor’s degree in computer science, information technology, computer engineering or a related field is required (A combination of experience and certifications may be considered).
Work Experience:
5 to 7 years of systems or network engineering experience
Required Licenses, Certifications, Registrations:
Cisco Certified Network Professional - Collaboration (CCNP – Datacenter) certification required.
Cisco Certified Internetwork Expert – Data Center (CCIE – Data Center),
Training or Certification in Dell, EMC, Fortinet highly preferred.","$71,254 /yr (est.)",1001 to 5000 Employees,Hospital,Healthcare,Health Care Services & Hospitals,1958,Less than $1 million (USD)
"ENGIE INSIGHT SERVICES INC.
3.9",3.9,"Boston, MA",Principal Data Engineer,"Requisition ID: 13676
Location: Boston, MA, US, 2111
SUMMARY: Principal Data Engineer

Leads a scrum team designing, creating, and operating new interactive big data solutions centered on database and data lake technologies in support of Energy services and associated web based applications. Significant big data expertise using Microsoft, AWS, and Snowflake technologies plus familiarity with client facing, critical SaaS applications.

PRIMARY FUNCTIONS AND ESSENTIAL RESPONSIBILITIES:

Lead technical scrum teams constructing OLAP, OLTP, and AI driven cloud software in a cloud environment.
Responsibilities include one or more of the following:
Design, develop, configure and enhance big data systems centered on AWS, PostgresSQL, Redshift, S3, Lamdba, Python, and PowerBI hosted at Azure.
Construct datalake solutions based on AWS or Azure datalake architectures
Create highly scalable and available data software with a focus on data throughput and quality in all software processes
Build data integration capabilities loading large volumes of data reliably enforcing data quality standards and implementing enrichment approaches
Translate Agile software development stories into data software capabilities supporting the needed functionality and performance, estimate level of effort, and track progress on a daily basis
Translate data science deliverables into production software
Document and educate technology partners and peers regarding capabilities of constructed solutions
Partner with DevOps teams to size and design the infrastructure necessary to support our big data computing needs
Support client engagement success driven by data software driving quality answers for platform clients


LOCATION: Boston


QUALIFICATIONS


Education/Certification/
Knowledge

Computer Science BS/MS degree
Non-CS BS/MS degree with other software related training
Big data skill and technology certifications required


Experience:

7+ years of big data engineering experience
5+ years cloud engineering experience with an emphasis on AWS and Azure technologies
Hands on experience with PostgresSQL
Experience creating data repositories support web applications and REST APIs.
Experience with high throughput, big volume, fast response time, scalable systems
Expertise with advanced caching strategies leveraging technologies such as Redis, Memcache, and ElasticSearch.
Energy or financial services experience a plus


Skills/Abilities:

Redshift, Snowflake, Azure Synapse SQL, and/or Redshift
PostgresSQL design and development experience
Strong Python skills in a Lambda environment
Data modelling skills for OLTP and OLAP systems
Data lake construction with parquet
Experience with Python, Hadoop, and Spark helpful
Strong familiarity with AWS and/or Azure cloud environments

The ability to mentor and lead team members focused on technical topics

Good written and verbal English communication skills, client relation skills, and ability to work effectively as a contributor in a technical team environment.

Ability to speak French and/or Spanish a plus

At ENGIE, our goal is to support, promote, and thrive on diversity, equity, and inclusion. We do so for the benefit of our employees, customers, products and services, and community. ENGIE is proud to be an equal opportunity workplace, and we are firmly committed to creating an equitable and inclusive environment for all employees.
We are committed to providing employees with a work environment free of discrimination and harassment. All employment decisions at ENGIE are based on business needs, job requirements, and individual qualifications. ENGIE is committed to providing equal employment opportunities regardless of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship, age, sex or gender (including pregnancy, childbirth, and related medical conditions), gender identity, or gender expression (including transgender status), sexual orientation, marital status, civil union, or domestic partnership status, military service or veteran status, physical or mental disability, protected medical condition, genetic information, or any other legally protected category (referred to as “protected characteristics”) as defined by applicable federal, state or local law in the locations where we operate.
The pay range for this role is: $ 120,000-180,000
Pay range is based on several factors and may vary in addition to a full range of medical, financial, and/or other benefits. Final salary and offer will be determined by the applicant’s background, experience, skills, internal equity, and alignment with geographical market data. This position is eligible for our comprehensive and competitive benefits package including medical, dental, vision, and basic life insurance. Additional ENGIE benefits include a 401k plan, paid time off and annual bonus. ENGIE complies with all federal, state, and local minimum wage laws.


WORK ENVIRONMENT


Hybrid work environment on site in Boston 2-3 days per week




Business Unit: GBU Energy Solutions
Division: ES ENGIE Impact - Americas
Legal Entity: ENGIE INSIGHT SERVICES INC.
Contract Type: Permanent
Job Type: Full - Time
Professional Experience: Skilled ( >3 experience <15 years)
Education Level: Bachelor's Degree","$150,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,2008,$25 to $100 million (USD)
"Veracity Consulting Group
4.8",4.8,Remote,Cloud Data Engineer,"Veracity is a digital consulting company headquartered in Richmond, Virginia. What started in 2015 as a small group of consultant trailblazers has quickly transformed into a fast-growing firm innovating fortune 500s that you see today.
Our team is made up of technologists, strategists, and creative problem solvers who have one goal in common: creating fluid solutions that support business growth. With substantial experience in more than 10 industries, we come together as one team to deliver transformative results. While we take our work seriously, we never lose our playful spirit and we pride ourselves on our fun and energetic culture.
Today we are ready to add a Cloud Data Engineer/Analyst to the team. As Data Engineer you will be responsible for using you knowledge of data processing software and business application development to support analytical needs of the Business. Duties include collaborating with business customers, stakeholders and other development team members to define, design and implement analytical products like automated reports (including visual), statistical models, data analytics processes and etc.
Responsibilities
Collaborate with development team members to finalize system design and to identify incremental features delivery
Build POC/Prototypes and present to team/business customers
Use application development tools and resources to independently build data application components including triggers, validation, monitoring and logging.
Working with data, looking for anomalies, identifying issues and unwinding root cause of any issues and/or determining if an anomaly is not an issue
Define options for automating manual solutions
Create analytical presentations and reports based on recommendations and findings
Required skills and qualifications
7-10 years of experience and a Bachelor’s Degree
Excellent Analytical and problem-solving skills and self-sufficient in investigating data discrepancies – proficient at data analysis and mining
Technical communication skills – writing and editing, as well as speaking
Knowledge of logical/physical data model and data relationships
Excellent attention to detail
Experience in cloud engineering (preferably Azure)
Experience writing complex queries in SQL and understanding large scale data warehouse environments
Proven Expertise in Data Application Coding languages such as SQL, Scala, Python and Spark used in production applications and unit testing.
Experience with development and implementation of Databricks Notebooks and Azure Machine Learning (AML) projects
Experience with end-to-end development and deployment of analytics products and end user analytical tools/data visualization skills
Experience testing and debugging complex data transformations as well as standard code packages.

rn3bSDHwHK",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2015,Unknown / Non-Applicable
"Cross River
4.0",4.0,"Fort Lee, NJ",Senior Data Engineer,"Who We Are
Cross River is a highly profitable, fast-growing financial technology company powering the future of financial services. Our comprehensive suite of innovative and scalable embedded payments, cards, and lending products deliver financial services for millions of businesses and consumers around the globe. Cross River is backed by leading investors and serves the world's most essential fintech and technology companies. Together with its partners, Cross River is reshaping global finance and financial inclusion.
We are on a mission to build the infrastructure that propels access, inclusion, and the democratization of financial services. While our company has tripled in size over the last three years, our strong sense of purpose led Cross River to be named to American Banker's list of Best Places to Work in Fintech for the last 6 years. The reason for this success is simple – our nimble and collaborative family culture lives in every member of our growing team. Together we are at the forefront of technology and innovation, and we invite passionate, collaborative, and motivated high performers to join our expanding team.
About Our Team
Cross River's Data Platform team is made up of problem solvers hungry to build and perfect new products and systems. We have team members both on-site and remotely across multiple US time zones, and we understand the flexibility today's engineers need. We collaborate, help and mentor each other, and check in on our progress and blockers frequently. We work together primarily within Teams, Git, and JIRA. Although we are in separate places, we still make space to know one another and have fun!
What We're Looking For
We are hiring a Senior Data Engineer that will report to the Director leading the creation of a new Data Platform. The ideal candidate has a Software and Data Engineering background focused on executing and enhancing modern data platforms. You will be responsible for building batch/distributed and real-time, highly-available pipelines while ensuring data quality is constantly maintained via DataOps best practices. You will participate as a key contributor on implementation of our enterprise data model.
Responsibilities:
Build fault tolerant, self-healing, adaptive and highly accurate data pipelines
Demonstrate deep knowledge of data engineering to build and support non-interactive (batch, distributed) & real-time, highly available data, data pipeline and technology capabilities
Institute data quality checks and implement monitoring in the pipelines to ensure confidence in the data
Be a key contributor to the data modeling of the data warehouse
Champion the automation of all data, tool, and cloud infrastructure processes
Display strong thought leadership in pursuit of modern architecture principles and technology modernization
Partner with business, and other engineering teams to design and build data pipelines
Develop and maintain data platform documentation
Perform root cause analysis to identify permanent resolutions to software or business process issues
Leverage source code management best practices including git, pull requests, code reviews
Perform SQL tuning as necessary
Qualifications:
Bachelor's degree in Computer Science, or equivalent experience
10+ years of experience as a Software engineer with a strong Data focus or similar role
5+ years writing SQL with a strong understanding of 3NF, dimensional and denormalized data modeling (experience with DBT is a plus)
5+ years using Python, Pandas and Pyspark
5+ years maintaining enterprise data platforms on a major cloud provider (AWS preferred)
2+ years working with an orchestration tool like Airflow
2+ years architecting container-based application/task execution with Docker
2+ years working with cloud data warehouses (Snowflake, Redshift, etc.)
Experience with practices for data and table schema change migration
Knowledge of high-availability, data replication and failover configurations across pipelines, infrastructure, and regions
Experience with data privacy, security and regulatory concerns related to data management in Financial Services industries
Working experience with Terraform scripts for Infrastructure as Code scripting is preferred

#LI-AP1
#LI-HYBRID
Salary Range: $140,000.00 - $160,000.00
Cross River is an Equal Opportunity Employer. Cross River does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.
By submitting your application, you give Cross River permission to email, call, or text you using the contact details provided. We will only contact you with job related information.","$150,000 /yr (est.)",501 to 1000 Employees,Company - Private,Financial Services,Banking & Lending,2008,$500 million to $1 billion (USD)
"Moen
4.0",4.0,"North Olmsted, OH",Data Operations Engineer,"Company Description

Fortune Brands Innovations is a global Fortune 500 company specializing in home, outdoors, plumbing, and security products. Our portfolio includes famous brands such as Moen, Master Lock, Fiberon, and Therma-Tru.

Job Description

Data Operations Engineer, full-time from North Olmsted, Cleveland, Toledo, and Columbus.

As a DataOps Engineer in our Data & Analytics team, you'll build a state-of-the-art data, ML, and analytical platform using Cloud and DevOps tech. Collaborate with experts, work on hybrid infrastructure (on-premise and Azure), integrate ERP systems like SAP, Oracle, and Snowflake. Utilize tools like Azure Pipelines, GitHub, Kubernetes, dbt, Talend, and Python.

Enjoy flexible remote work with the option to engage at our North Olmsted office. This role offers career growth and leadership opportunities in this exciting new initiative.

The ideal candidate will have a bachelor’s degree in computer science, information systems, or engineering. You will have a data engineering background with experience with DevOps tools, cloud environments, and all stack tools associated including but not limited to:
Infrastructure: Hybrid - a mix of on-premise infrastructure and public Cloud, primarily Azure.
Data systems: ERP systems, including SAP and Oracle. Snowflake as Enterprise Datawarehouse.
Platform infrastructure and DevOps: Azure Pipelines, GitHub, Kubernetes, IaC.
Data tools: dbt, Talend, and python.

What you will be doing:


Own, develop, manage, and optimize the orchestration of data pipelines and source code version control that adhere to our data governance principles.
Own, develop, manage, and enhance the tools for the data engineers.
Work closely with stakeholders in Business Intelligence, Data Governance, Infrastructure, and business units to gather functional and non-functional requirements, and deliver the appropriate tooling and systems to produce high-quality data and analytics in a timely manner.
Build systems and automation to overcome the limitations of existing systems and integrate new modern-day tech stack into the company’s IT infrastructure.
Establish system monitoring, cost monitoring/mitigation, and alerting.
Define and enforce best practices and standards for the Data & Analytics team.

Qualifications

Bachelor’s degree in computer science, information systems, science, or engineering; or equivalent years of experience in IT, software engineering, or a relevant field.

4+ years of experience in Python or/and an equivalent language, such as bash or PowerShell.

4+ years of experience in Linux system administration, network administration, or working at a data center.

2+ years of experience in working with a Cloud provider, including AWS, GCP, or Azure.

2+ years in developing and managing SDLC workflow, DevOps tools, and CI/CD.

Basic understanding of data architecture, data warehousing, and Gitflow.

Experience in observability, including cost monitoring, log management, alerting, monitoring, and tuning.

Self-driven with the ability to work in a multi-stakeholder environment and deal with ambiguity.

Good analytical & problem-solving skills and the ability to incorporate multiple perspectives.

Good written and verbal communication skills.

Preferred Qualifications

Big plus if you have these skills.
Big Plus: Snowflake or a Cloud Warehouse product like Google BigQuery or AWS RedShift.
Big Plus: Experience in data orchestration.
Experience in infrastructure as code, including Terraform, Pulumi, Chef, or Puppet.
Experience in SQL querying language.
Quick learner.
Great sense of humor.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.","$71,021 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"Criterion Systems, Inc.
4.2",4.2,"Washington, DC",Voice/Data Communications Engineer,"Overview:
At Criterion Systems, we developed a different kind of business—a company whose real value is a reputation for excellence built upon the collective skills, talents, perspectives, and backgrounds of its people. By accepting a position with Criterion Systems, you will join a group of professionals with a collaborative mindset where we share ideas and foster professional development to accomplish our goals. In addition to our great culture, we also offer competitive compensation and benefit packages, company-sponsored team building events, and advancement opportunities. To find out more about how Criterion can help you take your career to the next level please visit our website: www.criterion-sys.com. Criterion Systems is a Military/Veteran Friendly Company therefore we encourage Veterans to apply.
Responsibilities:
We are is seeking a Voice/Data Communications Engineer to support a contract in Washington, DC.

Background: within the Department of Commerce (DOC), Office of IT Services (OCIO) operates the computer and telecommunications network and security infrastructure at the Herbert C. Hoover building (HCHB). The HCHB network infrastructure (HCHBNet) provides data, voice, Wi-Fi/wireless, and emergency broadcast services to several Operating Units that reside within DOC headquarters. The primary purpose of this task order is to provide ongoing operation and maintenance (O&M) of HCHBNet and to enhance the overall service delivery model for the infrastructure.

The selected candidate's primary responsibilities will be to provide Voice over Internet Protocol (VoIP) network design, installation, documentation, operations, maintenance, system engineering, sustainment engineering, management and oversight for Department of Commerce agency's IP telecommunications network. Will provide administrative telephone support for conferencing, alert and notification systems, networked voice, video and data VOIP infrastructure. Provide voice mail services, including recorded announcements, audio and visual indicators of messages, forwarding capability, broadcast (voice-mail lists), standard and enhanced message storage, auto dial voice mail caller, auto reply, create, delete, and retrieval of messages from any Dual Tone Multi-Frequency phone. Monitor statuses and alert systems necessary to provide real time network availability to include remote applications and hardware necessary to monitor and communicate with remote sites as required.

Will also provide end-to-end support of equipment and services, infrastructure and other required services to provide telecommunications related connectivity. Apply knowledge of policies and procedures regarding the installation, configuration, and management of Cisco IP Systems to perform real time conference scheduling, bridge management, and connectivity support for a global IP and ISDN teleconferencing network.

Perform architecture and design support for current and future large–scale enterprise VoIP solutions. Provide Tier III troubleshooting for Cisco UCM, Unity Connection, Instant Messaging and Presence (IM&P), Unified Border Element (CUBE), and Unified Contact Center Express. Provide engineering and design support for local area networks, including layer 2 and 3 switches, routers, and firewalls. Work with vendors to determine how their latest technologies can be incorporated into future designs. Conduct test and evaluation activities within a lab environment for future upgrades to an enterprise UC solution.

Duties, Tasks & Responsibilities
Develops, operates, and maintains voice, wireless, video, and data communications systems.
Knowledge and experience in networking principles and administration.
Knowledge and experience with telecommunications and principles related to Cisco Unified Communications services.
Expert with Cisco Unified Communications Manager, Cisco Unity Connection, Cisco Unified Presence, and Cisco Unified Contact Center Express applications.
Ability to perform upgrades/patching of multiple platforms including, but not limited to CUCM, Unity, CUPS, UCCX, Windows Server, and SingleWire InformaCast.
Ability to configure UC services, applications, end point devices and other aspects of the UC system.
Experience with UCCX script design, buildout, and implementation.
Experience with Cisco Unified Intelligence Center (CUIC) reporting tool.
Practical experience with Cisco Unified Border Element (CUBE) deployment and operational maintenance.
Extensive knowledge with dial-plan and digit manipulation
Ability to produce detailed design, operational and end user training documents.
Experience with Active Directory
Experience with Unified Computing Systems and VMware ESXi/vCenter 6.0 or higher.
Possess extensive troubleshooting capabilities across the enterprise platform. Must be familiar with debugs, call traces, and monitoring tools.
Able to provide detailed reports and communications to the management team regarding the operational status of the Unified Communications deployment and system status.
Proficient with H323, MGCP, and Session Initiated Protocol (SIP) implementation and maintenance.
Skilled with call setup and signaling, quality of service, design and support of unified communications networks, configuring, installing, and upgrading Cisco ISR voice gateways.
Knowledge and experience working with InformaCast Advanced Notification system.
Must be able to work as part of a team, or independently with little direction.
Must have good communications skills and experience working with teams, and directly with the customer.
Capability to perform essential technical maintenance activities without direct supervision
Experience working within an electronic ticketing system - ServiceNow experience a plus.
Excellent verbal and written communication skills
Positive service-oriented attitude
Experience with larger enterprise IP networks and related networking equipment and management of Cisco IP Systems
Provides technical direction and engineering knowledge for communications activities including planning, designing, developing, testing, installing and maintaining large communications networks.
Qualifications:
Required Experience, Education, Skills & Technologies
Minimum of an undergraduate (Bachelors) degree in Information Technology, Information Systems Management, Computer Science, or a related field from an accredited University. Degree requirements may be substituted with an equivalent combination of education, training, and experience.
6+ years of related experience with telecommunications, integration design, installation and support
4+ years deploying or integrating Cisco Communications Manager and Cisco Collaboration Product Suite
US Citizenship
Ability to obtain a Top Secret clearance
Preferred Experience, Education, Skills & Technologies
Security +
Work Schedule
Full-time on-site (3 days work on the customer site each week, 2 days can work remote)

Benefits Offered
Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Tuition/Training Assistance, Parental Leave, Paid Time Off, and Holidays.
Criterion Systems, LLC and its subsidiaries are committed to equal employment opportunity and non-discrimination at all levels of our organization. We believe in treating all applicants and employees fairly and make employment decisions without regard to any individual’s protected status: race, ethnicity, color, national origin, ancestry, religion, creed, sex/gender, gender identity/gender expression, sexual orientation, physical and mental disability, marital/parental status, pregnancy (including childbirth, lactation, and related medical conditions), age, genetic information (including characteristics and testing), military and veteran status, or any other characteristic protected by law. For our complete EEO/AA and Pay Transparency statement, please visit https://careers-criterion-sys.icims.com/.","$88,482 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,$25 to $100 million (USD)
"Aerojet Rocketdyne
3.7",3.7,"Canoga Park, CA","Specialist, Data Acquisition & Control System Engineer","Job Overview:
Aerojet Rocketdyne, an L3Harris Technologies Company is seeking an experienced Data Acquisition and Control System Engineer to join our Avionics Engineering Test Equipment Design organization. This position will be located at our facility in Canoga Park, California (Los Angeles area) and will report to the Avionics Special Test Equipment (STE) Design Manager.
In this role, you will support both Space and Defense programs. In addition, you will perform an array of technical and project engineering related duties in support of a variety of Avionics STE design projects.
The candidate will perform an array of technical and project engineering related duties in support of a variety of Avionics Special Test Equipment (STE) design projects to ensure cost, performance and schedule objectives and constraints of STE development and their use for characterization of the products under test are met.

This position may be filled at this level posted or one level higher.
About Us:
L3Harris Technologies is the Trusted Disruptor for the global aerospace and defense industry. With customers’ mission-critical needs always in mind, our more than 50,000 employees deliver end-to-end technology solutions connecting the space, air, land, sea and cyber domains.

Enjoy work/life balance at our Canoga Park, CA (Los Angeles area) site. At this facility, we design & manufacture rocket engines and unique power systems that support space exploration & the defense of our nation such as NASA’s SLS, Lockheed Martin’s THAAD, Sierra Nevada’s Dream Chaser, and the Mars Perseverance Rover.

You're not just ""doing a job"" at Aerojet Rocketdyne, an L3Harris Technologies Company. The work you perform makes significant contributions to national security and space exploration.
Inspiring Company Culture - Our people support each other and work together to leave an indelible impact on our nation’s aerospace and defense legacy. Read more about our culture: Careers | L3Harris
Rest and Relaxation- Accrue 3 weeks of vacation to start plus separate sick allowance. 9/80 schedule providing longer weekends. Plus 90 hours of paid holidays on average throughout the year.
Comprehensive Health Benefits - Medical, Dental, Vision, Health Savings Accounts, and Wellness programs. Want to know more? Check out: Benefits | L3Harris
Prepare for the Future - 401(k) with company match
Professional Development - Tuition assistance, free professional development training through Rocket University, employee recognition, and leadership development programs
Employee Resource Groups – Local and Enterprise employee-led volunteer groups to create community, awareness, impact, and to support a culture where everyone belongs
Essential Functions:
65% Hands on design work including design of test equipment, review of design elements performed by engineering team members, review of customer requirements, generation of derived requirements, generation and/or review of test plans, test and calibration procedures, STE user manuals, participate in and direct test campaigns as the lead engineer, lead test team in test failure root cause investigation, generate and/or review test reports. Serve as technical lead to Avionics Directorate for design of advanced STE concepts and training of test personnel in new concepts and applications. Lead and participate in product and STE Design reviews. Generate and review budgetary basis of estimate in support of new proposals. Work with customer and test centers engineering teams to ensure STE meets stakeholder expectations.

20% Perform system requirements evaluation and trade studies as required for providing new or optimizing system solutions to reduce test cost. Define product breakdown structure and establish requirements process flow for the system under development. Participate and direct hardware development at all stages of STE development lifecycle to include requirements capture/flow-down, capability assessment and equipment validation and verification testing, system integration, qualification and certification. Plan, conduct and technically direct the efforts of STE Engineering Team. Strengthen the technical capacity of the company and facilitate transfer of knowledge and technology by mentoring less experience engineers and team members.

15% Travel to customer and test sites to review, discuss test plans and conduct test campaigns.

Requirements:
Bachelor of Science degree in Electrical Engineering or Computer Engineering and nine (9) or more years of experience (or an equivalent combination of education and experience).
Required Capabilities
Have at least nine years of diversified experience in electromechanical product development, test equipment design and the product testing for use in aerospace environments.
The applicant should be familiar with standard test equipment (analog and digital stimulus and measurement devices).
Capable of designing custom interface circuits where COTS equipment does not satisfy test requirements.
Thorough familiarity with design, assembly, operation and maintenance of instrumentation testing and hardware setup and assembly of test instrumentation panels and consoles.
Strong background in project planning, system testing, test fixture design, troubleshooting, staff training, mentoring and supervision.
Function as the project’s lead Instrumentation and Controls engineer on assigned projects
Evaluate customer requirements and related government and regulatory processes and procedures to correctly drive-out test equipment requirements.
Oversee and provide hands-on approach to integration and checkout and test of the high speed, deterministic, real-time DAQ and Control systems.
Strong back ground in FPGA application using Xilinx an other FPGAs and experience with RTL, Verilog and VHDL coding / (creation of test benches, functional code).
Attend and actively participate in test operations meetings as requested.
Train test team personnel in the operation of DAQ systems.
Conduct data reduction, data download and publication of test data.
Compile and prepare test data for test report development. Support review of the final test report for technical thoroughness.
The candidate must have strong oral and written communication skills to coordinate tasks across various engineering disciplines and centers of excellence in geographically separate regions.
Differentiating Capabilities
Familiarity with Programmable Logic Controllers (PLCs) and Distributed Control Systems (DCS) and their programming.
Familiarity with servo control and tuning PID controllers.
Familiarity with instrumentation (Pressure, Temperature, Force, Strain, Acceleration, Speed, etc) and the associated signal conditioning.
Familiarity with setting up Graphical User Interfaces.
Familiarity with test equipment: DMM, Oscilloscope, Logic Analyzer, etc.
Working experience with.
LabView
Simulink
C, C++ for reviewing codes produced the software team to verify compliance with requirements and to perform diagnostic troubleshooting.
Familiarity and working knowledge of Dynamic Object-Oriented Requirements System (DOORS™).

Will be required to obtain and maintain a U.S. Security Clearance at the appropriate level. Requires U.S Citizenship. Must be able to satisfy federal government requirements for access to government information, and having dual citizenship may preclude you from being able to meet this requirement.

Work Environment and Physical Requirements:
Employees in these positions must possess mobility to work in a standard office setting and to use standard office equipment, including a computer; stamina to sit or stand and maintain attention to detail despite interruptions; may occasionally lift/carry/push/pull up to 25 pounds; may require occasional walking, climbing, stooping, crouching, and/or bending; and vision to read printed materials and a computer screen, and hearing and speech to communicate in person and over the telephone. May require the ability to travel by air or auto. May require the use of personal protective equipment such as safety glasses, safety shoes, and shop coat. These positions may be expected to work varying shifts and hours to ensure successful operation of activities in the organization.

Pay range for this position:: 120,500 - 177,166 per year Note about pay range:: Pay range for this job level is a general guideline only for California and/or Washington State and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.","$148,833 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,2019,$10+ billion (USD)
"Mitsubishi HC Capital America Inc
3.1",3.1,"Itasca, IL",Principal Data Engineer,"For this role, we will consider remote candidates as well as candidates located near our Norwalk, CT office or Itasca office.
Position Overview:
The Principal Data Engineer holds the primary responsibility for skillfully designing, developing, implementing, and supporting Mitsubishi HC Capital America, Inc. (MHCCNA)'s enterprise Microsoft Azure Data Warehouse. This role assumes accountability for ensuring the dependable, efficient, and secure operation and advancement of MHCCNA's On-Premise and Cloud Data Warehouses to effectively meet crucial business needs. As a lead figure in the organization, the incumbent will manage intricate projects and offer technical leadership and guidance in all data-related matters for the Company.

Commitment to Internal Control:
The Principal Data Engineer is required to possess a comprehensive understanding of and adhere to the system of internal controls associated with the fundamental duties and responsibilities of the role. This includes compliance with SOX and all other pertinent regulatory and compliance policies and requirements.

Essential Duties and Responsibilities:
The responsibility of Principal Data Engineer encompasses the entire lifecycle of the Data Warehouse environments that underpin the vital business requirements of MHCCNA. This includes the design, development, implementation, operation, and ongoing support of these critical systems.

The individual in this position is tasked with developing a flexible, enterprise-level environment that integrates multiple warehouses to guarantee precise, comprehensive, consistent, and timely data. Their primary goal is to create a cohesive system that fulfills these demands while catering to diverse business requirements.

The role necessitates the capacity to explore and grasp emerging technologies while collaborating closely with peer teams to establish strategic roadmaps and priorities. The ability to swiftly acquire and proficiently apply hands-on administration skills is essential. As a Subject Matter Expert in technical requirements, this position will play a crucial role in supporting and implementing data projects, as well as engaging effectively with users and other IT staff.

The Principal Data Engineer responsibilities include:
Provide support in designing and overseeing enterprise-grade data pipelines and data stores, essential for the development of advanced analytics programs, machine learning models, and statistical methods.
Implement automation and streamline processes to optimize the entire data and analytics platform, ensuring efficient throughput and high-performance outcomes.
Recognize, devise, and execute internal process enhancements, including automation of manual tasks, optimizing data delivery, and redesigning architecture or infrastructure to enhance scalability.
Collate large, intricate datasets that align with functional and non-functional business demands.
Develop processes that facilitate data transformation, manage data structures, metadata, dependencies, and workload management.
Collaborate with business users to understand functional and data requirements, contributing to the enhancement of data models and pipelines.
Apply expert-level analytical and problem-solving skills to diagnose and resolve intricate technical issues.
Create, maintain, and continuously enhance scalable data pipelines, while also developing new data source integrations to accommodate the growing volume and complexity of data.
Designing, implementing, and managing data extraction, transformation, and loading (ETL) processes.
Creating comprehensive technical specification documents and application interface designs.
Creating data processing and integration solutions for both batch and real-time scenarios, proficiently handling structured and unstructured data.
Leading and participating in design discussions, code reviews, and project-related team meetings.
Providing mentoring and guidance to junior team members, promoting a culture of knowledge sharing and collaborative problem-solving.
Ensuring data security and compliance with relevant regulations and best practices in all data operations.
Provide assistance in troubleshooting and resolving data and system issues, stepping in when necessary to address outages and challenges.
Other duties and responsibilities as assigned or needed.

KPI’s (Key Performance Indicators):
Deliver Business Intelligence solutions that are 95% defect-free providing that adequate written business requirements, development time, and business test review were afforded during the project. This standard does not apply to legacy remediation efforts or ready to serve emergency production response activities.
Effectively utilize consulting resources on all significant projects (over 40 hours) to allow for development power of scale. Consultants should do lower value work that is considered heavy lift, freeing up programmer analysts to spend more time in analysis and design while maintaining tight control over quality, code, and company intellectual property.
These are overarching KPI metrics that are applicable to all goals that are defined over the course of the business year.

Responsibility and Decision-Making Authority:
Exercise independent judgment and decision-making while adhering to Company Policy.

Management/Supervisory Responsibilities:
Offers technical leadership to fellow IT staff members and actively engages with less experienced team members, providing valuable mentoring and guidance.
Demonstrates capability in assuming a leadership role for managing projects.

Qualifications/Competencies:
Key Technical Knowledge, Skills, and Abilities:
Exhibit a thorough understanding of Data Lake architectures, including raw, enriched, and curated layer concepts, and ETL/ELT operations.
Exhibit a solid understanding of database design, data warehousing concepts, big data platforms, and ETL operations.
Experience working with data integration techniques & self-service data preparation.
Experience in requirements analysis, design, and prototyping.
Experience deploying modern data solutions leveraging components like Azure functions, Azure Data Factory, Data Flows, Azure Data Lake, Azure SQL, Azure Synapse, Streaming Analytics or equivalent on another cloud provider such as AWS or Google Cloud.
Experience with DevOps tools like Azure DevOps, Jenkins, Maven etc.
Experience in building/operating/maintaining fault tolerant and scalable data processing integrations.
Demonstrated experience of turning business use cases and requirements into technical solutions.
Strong level of understanding on Azure Data Factory, SQL/Synapse, ADLS, and Azure DevOps.
Ability to conduct data profiling, cataloging, and mappings for technical design and construction of data flows.
Strong collaboration and experience working with remote teams.
Strong problem-solving skills with emphasis on optimization data pipelines.
Showcase excellent communication and presentation skills for effective collaboration with technical and non-technical stakeholders.
Strong analytical skills and a drive to learn and master new technologies and techniques.
Experienced using Azure Synapse Analytics.
Experience working with third party providers and vendors for critical support requirements.

Competencies:
Workload organization and prioritization
Customer service - attitude and responsiveness
Professional communications
Strong project management skills as both a project leader and participant
Good judgement, analytical capabilities and decision making.
Able to work independently and as part of a small, tightly integrated team.
Good documentation skills and attention to detail

Education and Experience:
Bachelor’s degree with a minimum of 10 years of related experience.
10+ years of hands-on Data Warehouse architecture and development experience
Demonstrated expertise in Microsoft SQL Server and/or Azure development.

Working Hours / Travel Requirements:
Hours may vary and will require periodic overtime, including occasional evening and weekends, depending on business needs.
On call 24x7 for emergency support
Occasional travel for business meetings, seminars or training may be required.

Physical Demands:
Digital dexterity and hand/eye coordination in operation of office equipment.
Light lifting and carrying of supplies, files, etc.
Ability to speak to and hear customers and/or other employees via phone, person or virtually.
Body motor skills sufficient to enable incumbent to move from one office location to another.

The job description does not constitute an employment contract, implied or otherwise, other than an “at will” relationship and is subject to change by the employer as the needs of the employer and requirements of the job change.

Salary Range: ($176,600 to $195,100) per year, plus a discretionary bonus.

The salary range is determined and based on internal equity, market data/ranges, applicant's skills, prior relevant experience, and education.

Additional Benefits:
Medical, Dental and Vision Plans
401(k) and matching
Generous Paid Time Off
Company paid Life Insurance
Employee assistance program
Training and Development Opportunities
Employee discounts","$185,850 /yr (est.)",51 to 200 Employees,Company - Private,Financial Services,Banking & Lending,1952,Unknown / Non-Applicable
"CLEAR - Corporate
3.1",3.1,"New York, NY","Principal Software Engineer, Data Platform","As a Principal Engineer for our Data Platform team, you will be responsible for modernizing our data platform and practice. You will play a critical role in selecting and implementing technology, which we will use across CLEAR to make data-driven decisions, build a best-in-class product, and enable future ML/AI use cases. You will work cross-functionally with multiple engineering teams, providing leadership and advice and helping teams integrate with the data platform. Additionally, you will be a crucial partner to various teams across CLEAR, including Business Intelligence, Product Management, Security, and more.
What you'll do:
Build partnerships with teams across CLEAR to ensure data solutions solve current and future use cases
Drive the migration to a modern data stack in which Analysts and Engineers can self-service changes in an automated, tested, and high-quality manner
Build data governance solutions into every part of the platform
Evangelize data and its use across CLEAR to make our decisions and products smarter
What you're great at:
10+ years of professional experience as a Data Engineer, focusing on building scalable data solutions
Experience with a modern programming language, such as Python
Building a modern datastack, using tools such as dbt, Dagster, Airflow, Snowflake, et cetera
Experienced with RDBMS, NoSQL, and real-time streaming systems like Kafka or Pulsar
Excellent communication skills, able to explain technical topics to non-technical audiences, manage up, down, and across
Have worked with or built a data governance program
How You'll be Rewarded:
At CLEAR we help YOU move forward - because when you're at your best, we're at our best. You'll work with talented team members who are motivated by our mission of making experiences safer and easier. Our hybrid work environment provides flexibility. In our offices, you'll enjoy benefits like meals and snacks. We invest in your well-being and learning & development with our stipend and reimbursement programs.
We offer holistic total rewards, including comprehensive healthcare plans, family building benefits (fertility and adoption/surrogacy support), flexible time off, free OneMedical memberships for you and your dependents, and a 401(k) retirement plan with employer match. The base salary range for this role is $225,000 - $260,000, depending on levels of skills and experience.
The base salary range represents the low and high end of CLEAR's salary range for this position. Salaries will vary depending on various factors which include, but are not limited to location, education, skills, experience and performance. The range listed is just one component of CLEAR's total compensation package for employees and other rewards may include annual bonuses, commission, Restricted Stock Units
About CLEAR
Have you ever had that green-light feeling? When you hit every green light and the day just feels like magic. CLEAR's mission is to create frictionless experiences where every day has that feeling. With more than 15+ million passionate members and hundreds of partners around the world, CLEAR's identity platform is transforming the way people live, work, and travel. Whether it's at the airport, stadium, or right on your phone, CLEAR connects you to the things that make you, you - unlocking easier, more secure, and more seamless experiences - making them all feel like magic.","$242,500 /yr (est.)",1001 to 5000 Employees,Company - Public,Management & Consulting,Security & Protective,2010,Unknown / Non-Applicable
"IBSS Corporation
4.2",4.2,"Washington, DC",Data Management / Data Services Engineer,"Job Title: Data Management / Data Services Engineer
Location: Washington DC
Clearance Required: Public Trust Eligible



Description (scope of work)
IBSS is seeking a Data Engineer to provide expertise for the development of a data repository, especially in database design, data formats and tagging, metadata management, and access, ingest, storage, and retrieval protocols that are cost effective for the National Oceanic and Atmospheric Administration Office of Space Commerce (OSC).


Key Responsibilities:
Work with OSC staff and System Integrator contractor staff in the development of data architecture and infrastructure.
Provide technical program support to include, but not limited to, stakeholder engagement, data management, and reporting.
Excellent written and verbal communication skills, both technical and nontechnical.
Major team player, collaborator, role model, and mentor.
Passion to exceed expectations and constantly push the envelope.
Demonstrated skills of technical rigor and data driven decision making.
Provide technical program support to include, but not limited to, stakeholder engagement, data management, and reporting.



Required Skills /Education/ Certifications & Qualifications:
Bachelor's degree in space science, engineering, or related scientific discipline
Experience in data formats and tagging, metadata management, and access, ingest, storage, and retrieval protocols.
Solid working knowledge of Data Modeling, Database design, Object-Oriented Analysis and Design Techniques. System Architecture, including Database and System performance tuning, as well as hardware and network workload balancing.
Understanding of the following languages and software: C++ Java CAD Software Solidworks Software Microsoft product suite
Organizational experience with one or more of the following: DOD FAA NASA Air Force Space Force Navy
General understanding of systems engineering, structural analysis, mechanical systems, and preparing technical reports, and other Aerospace engineering skill sets



Desired Skills:
Ability to work independently and with a team
Master's degree in space science, engineering, or related scientific discipline
TraCSS (previously OADR) experience
Prior NOAA, NASA, or DOC experience a plus

About IBSS Corp.
Since 1992, IBSS, a woman-owned small business, has provided transformational consulting services to the Federal defense, civilian, and commercial sectors. Our services include cybersecurity and enterprise information technology, environmental science and engineering (including oceans, coasts, climate, and weather), and professional management services.
Our approach is to serve our employees by investing in their growth and development. As a result, our employees bring greater capabilities and provide an exceptional level of service to our clients. In addition to creating career development opportunities for our employees, IBSS is passionate about giving back to the community and serving the environment. We strive to leave something better behind for the next generation.
We measure our success by the positive impact we have on our employees, clients, partners, and the communities we serve. Our tagline, Powered by Excellence, is a recognition of the employees that make up IBSS and ensures we deliver results with quality, applying industry best practices and certifications.
IBSS offers a competitive benefits package including medical, dental, vision and prescription drug coverage with company-paid deductible, paid time off, federal holidays, matching 401K plan, tuition/professional development reimbursement, and Flex-Spending (FSA)/Dependent Care Account (DCA) options.
IBSS is an affirmative action and equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, disability, age, sexual orientation, gender identity, national origin, veteran status, or genetic information. Click https://www.eeoc.gov/poster to see, The EEO is the law.
If you require reasonable accommodation in completing this application, interviewing, completing any pre-employment testing, or otherwise participating in the employee selection process, please direct your inquiries to the HR Department, Francesca Urrutia at (703) 826-4302, or email at HR@ibsscorp.com","$86,302 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Business Consulting,#N/A,$5 to $25 million (USD)
"Centene
3.8",3.8,"Clayton, MO",Senior Data Engineers,"You could be the one who changes everything for our 28 million members by using technology to improve health outcomes around the world. As a diversified, national organization, Centene's technology professionals have access to competitive benefits including a fresh perspective on workplace flexibility.
CENTENE MANAGEMENT COMPANY LLC ONLINE AD

EMPLOYER: Centene Management Company, LLC
POSITION: Senior Data Engineers
JOB ID No.: 1437811

DUTIES:

Develop and support the software, related dashboards, and other applications that the team owns or will own in the future.
Develop new software dashboards in Microstrategy or Power-BI.
Support existing dashboards (Ambetter, CARE Satisfaction, Provider Network and My Health Pays) and enhance them as the team receives requests for new requirement and the business prepares for future years of Open Enrollment.
Utilize experience with SQL Stored procedures in Teradata for existing tools to create and modify Control-M jobs and Informatica jobs.
Work with customers to understand the software solution requirements and design the appropriate solutions to meet their technical needs.
Ensure that customer needs can be satisfied in accordance with the limitations of our software systems and modify requirements as needed to ensure that they are consistent with software system design.
Document the requirements and obtain customer sign-in.
Design software solutions and get buy in from customers and the team.
Troubleshoot issues quickly and provide on call support, determining the appropriate courses of action.
Ensure jobs run successfully and on time, interjecting as needed if issues arise.
Escalate to upstream systems or Database Administrators to get jobs running or to fix them.
Document technical designs and ensure that all designs and technical solutions have been properly documented.
Create Visio diagrams of the process/data flow and solution.
Mentor junior developers and provide them with support and guidance to ensure that they quickly learn the business solutions and processes and become self-reliant.
Learn new technologies (e.g., ETL tools, packed tools, programming languages or new BI tools etc.) quickly and apply them.
Approximately 5% domestic overnight travel required.
Position reports to Centene headquarters at 7700 Forsyth Boulevard, St. Louis, MO 63105 and various unanticipated worksites throughout the U.S. Telecommuting permitted 100% of the time.
MINIMUM REQUIREMENTS:

PRIMARY REQUIREMENTS: Bachelor’s degree in Computer Science, Information Technology, Statistics, Mathematics, Engineering, or a related field, and 4 years of relevant work experience.
ALTERNATE REQUIREMENTS: Master’s degree in Computer Science, Information Technology, Statistics, Mathematics, Engineering, or a related field, and 2 years of relevant work experience.
In addition, experience with the following skills is required: (1) Utilizing SQL, including developing stored procedures, performance tuning the queries, and writing large complex queries with complex join conditions; (2) Working with Teradata and other relational databases like SQL Server; (3) Utilizing Informatica ETL tool to move data from one system to another; and (4) Utilizing Python to develop data science models and create utilities for data movement.

JOB SITE: 7700 Forsyth Boulevard, St. Louis, MO 63105
WORK HOURS: Monday-Friday, 40 hours/week [8:00 am to 5:00 pm]

To apply, please visit Centene’s web page at http://jobs.centene.com/#careers. Create a candidate profile and apply to requisition 1437811.

Centene is an equal opportunity employer that is committed to diversity and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.
Our Comprehensive Benefits Package: Flexible work solutions including remote options, hybrid work schedules and dress flexibility, Competitive pay, Paid time off including holidays, Health insurance coverage for you and your dependents, 401(k) and stock purchase plans, Tuition reimbursement and best-in-class training and development.
Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.","$91,399 /yr (est.)",10000+ Employees,Company - Public,Insurance,Insurance Carriers,1984,$10+ billion (USD)
"Cobenn Inc.
4.7",4.7,"New York, NY",DATA ENGINEER (AWS + SNOWFLAKE),"Role: DATA ENGINEER (AWS + SNOWFLAKE)
Type: Full Time
SKILLS AND CERTIFICATIONS [note: bold skills and certification are required]
AWS
Snowflake
ETL
Python
Job Description
With a startup spirit and 115,000+ curious and courageous minds, we have the expertise to go deep with the world’s biggest brands—and we have fun doing it. Now, we’re calling all who see the world differently and are bold enough to reinvent it. Come, transform with us.
Responsibilities:
Design and build reusable components, frameworks and libraries at scale to support analytics products.
Design and implement product features in collaboration with business and Technology stakeholders.
Identify and solve issues concerning data management to improve data quality.
Clean, prepare and optimize data for ingestion and consumption.
Collaborate on the implementation of new data management projects and re-structure of the current data architecture.
Implement automated workflows and routines using workflow scheduling tools.
Build continuous integration, test-driven development and production deployment frameworks.
Analyze and profile data for designing scalable solutions.
Troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues.
Requirements:
Strong understanding of data structures and algorithms
Strong understanding of solution and technical design
Has a strong problem solving and analytical mindset?
Able to influence and communicate effectively, both verbally and written, with team members and business stakeholders
Able to quickly pick up new programming languages, technologies, and frameworks.
Experience building cloud scalable, real time and high-performance data lake solutions.
Fair understanding of developing complex data solutions
Experience working on end-to-end solution design.
Willing to learn new skills and technologies.
Has a passion for data solutions.
Required and Preferred Skill Sets:
Hands on experience in AWS - EMR [Hive, Pyspark], S3, Athena or any other equivalent cloud
Familiarity with Spark Structured Streaming
Minimum experience working experience with Hadoop stack dealing huge volumes of data in a scalable fashion
Hands-on experience with SQL, ETL, data transformation and analytics functions
Hands-on Python experience including Batch scripting, data manipulation, distributable packages.
Experience working with batch orchestration tools such as Apache Airflow or equivalent, preferable Airflow.
Working with code versioning tools such as GitHub or BitBucket; expert level understanding of repo design and best practices
Familiarity with deployment automation tools such as Jenkins
Hands-on experience designing and building ETL pipelines; expert with data ingest, change data capture, data quality; hand on experience with API development.
Designing and developing relational database objects; knowledgeable on logical and physical data modelling concepts; some experience with Snowflake
Familiarity with Tableau or Cognos use cases
Familiarity with Agile; working experience preferred.
Job Type: Full-time
Salary: $80,000.00 - $100,000.00 per year
Experience level:
7 years
Schedule:
Monday to Friday
Ability to commute/relocate:
New York, NY: Reliably commute or planning to relocate before starting work (Required)
Experience:
AWS: 10 years (Preferred)
SNOWFLAKE: 10 years (Preferred)
ETL: 10 years (Preferred)
Python: 5 years (Preferred)
Apache Hive: 5 years (Preferred)
Pyspark: 10 years (Preferred)
Spark: 10 years (Preferred)
Tableau: 10 years (Preferred)
Work Location: Remote","$90,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Iron EagleX
4.9",4.9,"Tampa, FL",Lead Data Engineer,"Overview:
Iron EagleX is a veteran owned defense contracting company based in Tampa, FL.

It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.
Responsibilities:
Job Description:

The Lead Data Engineer builds and maintains data systems and constructs datasets that are easy to analyze and support customer requirements. Implement methods to improve data reliability and quality. Combine raw information from different sources to create consistent and machine-readable formats. Develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. Develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise.

Responsibilities:

Job Duties Include (but not limited to):
Acquire and assemble large, complex datasets that align with USSOCOM enterprise
Building, testing, and maintaining data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using modern data
Develop analytics tools and transformative algorithms for data to provide actionable insights into customer processes, operational efficiency, and other key business performance metrics.
Create new data validation methods for analytics and data scientist team members that assist them in building and optimizing products to fulfill customer objectives.
Work with IDST stakeholders including USSOCOM leadership, customers, and design teams to assist with data-related technical issues and support their data infrastructure needs.
Analyze procedures for USSOCOM data separation, access, and security across users and the enterprise data architecture.
Work with IDST data and analytics experts to strive for greater functionality in our data systems and capability integration.
Create and maintain optimal data pipeline architecture and support associated process improvements for automating manual processes, data delivery, and infrastructure re-design for scalability.
Qualifications:
Required Skills & Experience
8 years’ experience as a data engineer or in a similar
Demonstrated experience employing data models, data mining, and segmentation techniques.
Demonstrated experience developing, deploying and/or maintaining enterprise level data solutions.
Experience with SQL database design
Python, SQL, NoSQL, Cypher, POSTGRES
Can write in modern coding languages; Python & JavaScript required; Experience with Flask and React preferred.
Can read and understand other coding languages; HTML/CSS, R, Java, C, C++, C#
Create respective process documentation using a web-based version control
Experience with Gitlab and Jira
Provide written and verbal communication and respective business process
Work independently and on teams and have excellent time management and work prioritization skills
Execute complex projects within government defined timelines across a geographically dispersed workforce and user base
Desired Skills
SQL Alchemy, Flask, Swagger, JavaScript, Spark, Hadoop, Kafka, Hive, R, storm, MATLAB, Neo4J, MongoDB
Data engineering certification is a plus
Education & Certifications:
Possess a minimum of a bachelor's degree in computer science, IT, or similar field.
Security Clearance:
Active TS Clearance and eligible for SCI required while TS/SCI is preferred.
Benefits:
National health, vision, and dental plans
20 days of PTO and 11 paid holidays
Life Insurance
Short- and long-term disability plans
401(K) retirement plan
Incentive and recognition programs
Relocation opportunities

Iron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.","$117,493 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,#N/A,Unknown / Non-Applicable
"InfoQuest Consulting Group Inc.
4.5",4.5,"Philadelphia, PA",Data Engineer,"Duration & Type: 12 months Contract with a media & communications industry client
Location: Philadelphia, PA
No. of Positions: Multiple
Responsibilities:
Develop solutions to big data problems utilizing common tools found in the ecosystem.
Develop solutions to real-time and offline event collecting from various systems.
Develop, maintain, and perform analysis within a real-time architecture supporting large amounts of data from various sources.
Analyze massive amounts of data and help drive prototype ideas for new tools and products.
Design, build and support APIs and services that are exposed to other internal teams
Employ rigorous continuous delivery practices managed under an agile software development approach
Ensure a quality transition to production and solid production operation of the software
Required:
5+ years programming experience
Bachelors or Masters in Computer Science, Statistics or related discipline
Experience in one or more languages: Python, Scala/Java, Spark, Batch, Streaming, ML
Experience with Python unit testing and code coverage frameworks
Experienced in NoSQL / SQL, Microservice, RESTful API development
Strong Experience with AWS Core such as Kinesis, Lambda, API Gateway, CloudFormation, CloudWatch
Experienced with one of the Analytics tools – Presto / Athena, QuickSight, Tableau
Strong Experience with Container technologies and Real-time Streaming (such as Kafka, Kinesis)
Preferred:
Test-driven development/test automation, continuous integration, and deployment automation experience
Experience with Performance tuning at scale
Experience working on big data platforms in the cloud or on traditional Hadoop platforms
Experience working in agile/iterative development and delivery environments
Enjoy working with data – data analysis, data quality, reporting, and visualization
Great design and problem solving skills, with a strong bias for architecting at scale
Excellent communication skills
Experience in software development of large-scale distributed systems
For consideration, please send resume to career@infoquestgroup.com","$104,919 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,#N/A,Less than $1 million (USD)
"Thermo Fisher Scientific
3.7",3.7,"Waltham, MA",Senior Data Engineer,"Job Description
DUTIES:
Design, develop, test, deploy, support, enhance data integration solutions seamlessly to connect and integrate Thermo Fisher enterprise systems in our Data Science and Enterprise Data Platform.
Innovate for data integration in Apache Spark-based Platform to ensure the technology solutions leverage cutting-edge integration capabilities.
Facilitate requirements gathering and process mapping workshops, review business/functional requirement documents, author technical design documents, testing plans and scripts. Assist with implementing standard operating procedures, facilitate review sessions with functional owners and end-user representatives, and leverage technical knowledge and expertise to drive improvements.
Define, design and document reference architecture and lead the implementation of BI and analytical solutions.
Follow Agile development methodologies to deliver solutions and product features by following DevOps practices.
Collect business requirements from Thermo Fisher’s Digital Marketing team, and validate business rules and testing data solutions and quality to enable marketing team’ Algorithmic Targeting, Automation and Digital Sales Enablement.
REQUIREMENTS: Bachelor’s degree in Computer Science, Data Science, Engineering, or closely related field of study plus 9 years of experience in data analysis, data engineering, or related occupations/experience. Employer also accepts a Master’s degree plus 7 years of experience as an equivalent alternative.
Must have experience or knowledge of:
SQL data analytics;
Python;
Time series and regression modeling;
Machine Learning, including classification model;
Prediction models;
Databricks, including ETL and job creation/scheduling;
AWS or Azure;
Apache Spark;
PySpark;
DevOps.
TRAVEL: Up to 25% domestic and international travel required. Telecommuting Employee: Reports to company headquarters in Waltham, MA. Can work remotely or telecommute.","$136,065 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1902,$10+ billion (USD)
"Treliant LLC
3.7",3.7,"New York, NY",Senior Integration Engineer - Python - SSIS - Data Bricks,"Overview:
We are currently looking for a Collateral/Clearing Business Analyst in New York.

Who are we?
Treliant is a global consulting firm serving banks, mortgage originators and servicers, FinTechs, and other companies providing financial services. We are led by practitioners from the industry and the regulatory community who bring deep domain knowledge to help our clients drive business change and address the most pressing compliance, regulatory, and operational challenges.
We provide data-driven, technology-enabled advisory, implementation, and staffing solutions to the regulatory compliance, risk, financial crimes, and capital markets functions of our clients.
Founded in 2005, Treliant is headquartered in Washington, DC, with offices in New York, London, Belfast, Northern Ireland and Łódź, Poland. For more information visit www.treliant.com.
Responsibilities:
About the role
Responsibilities for the role may include, but are not limited to:
Design, develop and implement scalable data pipelines and ETL processes using Java, Python and Spark
Collaborate with data scientists, analysts and other stakeholders to understand data requirements and design efficient solutions
Manage and optimize Spark clusters to ensure high performance
Management of technical deliverables, project plans and open issues decks for assigned systems to support on time delivery to the programme

Who are we looking for?
Qualifications & Experience

Strong educational background – Degree (Masters would be an advantage)
Highly experience and skilled in Data Engineering
Experience designing, implementing, and maintaining data pipelines and infrastructure for big data projects
Your expertise in Java, Python, Spark cluster management, data science, big data, REST API development
Detail oriented, producing quality work accurately and efficiently
Knowledge of Databricks and Delta Lake will be essential in driving the success of our data initiatives
Good written and verbal communication skills

Professional Skills
Communication – advanced interpersonal & communication skills. Able to liaise confidently with senior stakeholders, either over the phone or via email
Team Player – able to work well within dynamic and goal-focused teams
Process Driven – able to become quickly proficient in new processes and systems
Detail-focused – very strong attention to detail
Multi-tasking – highly organized and able to balance various responsibilities simultaneously
Professionally Skeptical – able to identify and flag anomalies for review
Decision-making – ability to make decisions in a fast-paced and pressurized environment.
Commitment – strong work ethic and delivery focused
-
Primary Location: New York City
Primary Location Salary Range: $75,000 - $150,000
-

Why Treliant?
Career Development - We put an emphasis on personal and professional growth by providing all the training you’ll need to become a highly skilled Treliant consultant. Programs cover Finance, Regulatory, Technology, and Operational aspects of investment banking. On top of that, we also provide support in obtaining highly sought-after industry-recognized qualifications.
Clients – As a Treliant consultant, you will be working with some of the top clients in the financial services marketplace, such as top tier Investment Banks. Our roles place you at the cutting edge of the projects on which you’ll be working, and give you the opportunity to learn from, work with and build relationships with the very best within those companies.
Rewards – Treliant offers our permanent staff an excellent compensation package. View our full list of benefits here.
Core Values – Whether you are a client or an employee, Treliant wants the best for you. All our relationships are based on our Core Values: Deliver Excellence, Constantly Innovate, Treasure Diversity, Be Nimble, Listen First, and Develop our People.
Diversity & Inclusion – Treliant is an Equal Opportunity Employer. Treliant, LLC is committed to equal employment opportunity and providing reasonable accommodation to applicants with physical and/or mental disabilities. We value and encourage diversity and solicit applications from all qualified applicants without regard to race, color, religion, creed, national origin or ancestry, ethnicity, sex, pregnancy, sexual orientation, gender (including gender nonconformity and status as a transgender individual), age, physical or mental disability, citizenship, past, current, or prospective service in the uniformed services, genetic information, or any other characteristic protected under applicable federal, state, or local law.
Right to Work
Treliant is not in the position to provide sponsorship for this current position and so applicants must be able to work in the United States without requiring sponsorship

Please note, Treliant receives a high volume of applications for all roles. While we will endeavor to respond to all applicants, this is not always possible. Should you not receive a response to your application within 2 weeks, it is likely that you will have been unsuccessful on this occasion. However, we would like to retain your details on our systems for 6 months and may contact you should another potentially suitable vacancy arises.","$112,500 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Business Consulting,2005,$25 to $100 million (USD)
Authentica Solutions,#N/A,Remote,Senior Data Engineer,"Senior Data Engineer
About Authentica Solutions
Company Overview:
Authentica Solutions is a leading EdTech organization that aims to revolutionize the education sector by providing innovative solutions that empower educators, students, and institutions. We are dedicated to creating a holistic and data-driven educational ecosystem, and we are seeking a skilled Senior Data Engineer to play a pivotal role in building our Education Intelligence Platform. This platform will leverage IPaaS (Integration Platform as a Service), complex data transformation, data cleansing, standards alignment, intricate privacy requirements, and Data Lake technologies to solve complex problems in the EdTech landscape, enhancing our partnerships and driving data-informed decision-making.
Our Customers:
Architecting a platform that delivers capabilities as self-service and driven for needs known and unknown provide this role an opportunity to reimagine middleware making it miracle-ware that services EdTech Software Providers (ISVs), System Integrators, Resellers, Consulting Services Partners, Strategic Partners (Microsoft, Google, AWS, +), Departments/Ministries of Education, K12 School Districts, and Higher Education organizations, globally. With a priority on third party purchase and use, our platform must solve the most complex data challenges in Education empowering partners to serve their customer's needs fast, simple, and with consistency.
Responsibilities
As a Sr. Data Engineer, you will be an integral part of our engineering team, responsible for designing, developing, and maintaining the Education Intelligence Platform. Your expertise will be crucial in ensuring the scalability, reliability, and performance of the platform, enabling us to drive true impact for our partners and stakeholders.
You will play a key role in constructing, managing, and enhancing fault-tolerant data infrastructure while upholding the highest standards of data quality and integrity.
Collaborating with the engineering and product teams to execute on product goals.
Developing and managing fault-tolerant, scalable data pipelines capable of handling terabytes of data using distributed cloud technologies.
Develop data ingestion, processing, and transformation techniques to ensure data integrity and quality.
Assisting in the construction of control plane infrastructure using event-driven services for testing, code promotion, and job execution.
Conducting POCs to validate new tools and services that enhance our data engineering solutions and products.
Troubleshooting production data quality issues and ensuring data integrity.
Staying abreast of industry standards and technological advancements to continually improve our engineering output.
About You (or Here's What We're Looking For)
Growth mindset, insatiably curious, always learning, and welcoming challenges for the opportunity to grow.
You believe that you can only be successful when the whole team is successful, and you put your efforts towards it.
Has a keen interest in the educational sector and the impact technology can have on it.
Ability to bring innovative technical solutions ideas to solve real problems.
Strong verbal and written communication skills.
Required Skills and Experience
Must Have
Minimum of 4 years hands-on experience with Python and related data libraries (e.g. Pandas, Data Frames) Practical expertise in ETL/ELT technologies and methodologies.
Proven experience in data wrangling and cleaning across structured, semi-structured, and unstructured data formats.
Solid design and development background in modern technologies such as API management, REST/API integration, Containers, and Micro services.
Experience in designing or working with data warehouses, including an understanding of associated data flows.
Exceptional communication skills, both written and verbal.
English fluency is required to effectively communicate with our clients and other key stakeholders both internal and external.
Nice to Have
Familiarity or experience with orchestration tools.
Knowledge or hands-on experience with streaming platforms and real-time data pipeline systems such as Apache Kafka, Azure Event Hubs, and similar platforms.
Experience working with big data storage technologies like Azure Data Lake, Hadoop, BigQuery, and similar tools.
Join Authentica Solutions and be part of a dynamic team that's shaping the future of education through data-driven insights. If you are passionate about solving complex problems, building scalable data platforms, and making a positive impact on education, we encourage you to apply!
Authentica Solutions is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetics, disability, age, or veteran status. We provide a workplace free from discrimination and harassment, and where employees are treated with respect and dignity. Our employment decisions are based on business needs, job requirements, and individual qualifications.
We encourage candidates from all backgrounds to apply, as we believe a diverse workforce brings a variety of ideas, perspectives, and experiences that enhance our ability to meet the needs of our customers and drive innovation.
Applicants must be authorized to work for any employer in the United States. We are unable to provide sponsorship or assume responsibility for employment Visa sponsorship.",#N/A,1 to 50 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2013,Unknown / Non-Applicable
"Novo Nordisk
4.3",4.3,"Lexington, MA",Data and Solution Engineer - Molecular Design,"About the Department
Novo Nordisk Data Management and Informatics (DMI) within the Digital Science and Innovation Organization provides informatics solutions, data products and analysis support to the research organization in Novo Nordisk. DMI is establishing a data products organization across our research sites. Staff will be co-located to one of our global sites in Seattle, WA, Fremont, CA, Lexington, MA, Oxford, UK and Måløv, DK.

You will be part of the Data Management & Informatics (DMI) department and the Data Products Organization, where we are responsible for providing scientific data and software products to support the global research and early development organization at Novo Nordisk. Our work spans driving digitalization of laboratories, enabling scientific data capture, creating harmonized data for analytics, and providing informatics tools. We enable disruptive innovation and data driven decision making across areas that include disease understanding, molecular design, portfolio management and external scouting. We have a strong focus on employee engagement, and on developing and retaining talent.
Working at Novo Nordisk
At Novo Nordisk, we don't wait for change. We drive it. We're a dynamic company in an even more dynamic industry, and we know that what got us to where we are today is not necessarily what will make us successful in the future. We embrace the spirit of experimentation, striving for excellence without fixating on perfection. We never shy away from opportunities to develop, we seize them. From research and development, through to manufacturing, marketing and sales - we're all working to improve patient care.

The Position
This Data and Solution Engineer position is responsible for developing data products for pharmacology and therapeutic molecule development organizations. You will partner with stakeholders to contribute to the design of the data product roadmap and implement key features to deliver consistent access to existing and new data. Pharmacology and related modalities require architecting data pipelines to solve complex scientific problems. You will contribute directly to building the data pipelines leveraging artificial intelligence (AI) methods to discover new therapeutics. You will contribute to the full lifecycle spectrum of data products through technical guidance and implementations. Starting with data from internal and external sources, you will identify and describe requirements to find, access, consume, protect, and reuse molecular data across research and early development phases and therapeutic areas. Data may include multiple types, such as cheminformatics databases, custom file types, processing pipelines, Python code, compound catalogs, dynamics, docking, molecular structure, and more. Machine learning models and pipelines will play an increasing role in data products and will be part of the product roadmap. You will work with scientific architecture leads, data scientists, and computational chemists to understand, capture, and implement functionality that deliver a data product. It is important to utilize existing tools to handle software versions, model performance metrics, data provenance, and restrictions on sensitive data used in training and testing. We welcome and value your input how our tools and processes can be improved; always improve and share new ideas. Understanding how to create robust and extensible products which are flexible for complex and often ambiguous requirements will be essential.

You will collaborate and partner with various stakeholders such as computational scientists, data scientists, automation platform specialists, experimental scientists, and external partners. Your experience in computational molecular modeling and data workflows will be essential to shape data products. The development of a roadmap will evolve over time to develop new features and rigor of service levels. Key stakeholders will include data scientists, experimental scientists, and scientific project leaders. You will partner with data products engineering teammates to identify existing technical platforms or otherwise highlight technology or process gaps essential to the roadmap.
You will build based on requirements, created under an agile framework. It is important to ensure not only implementation of tooling and pipelines but equally necessarily to document and design testing and validation methods to define readiness; whether a software method or manual process. This will allow data engineers and data architects to successfully use continuous integration and continuous delivery.
You will be a key contributor who can influence process and understand requirements of chemists, computational modeling scientists, and biophysical experimentalists, with the goal of changing how data is captured and championing requests from data generation stakeholders. This requires aligning with other product owners and specialists across DMI and Global IT to address larger needs.
Do you believe that the digitalization transformation in Research and Early Development (R&ED) is crucial for the success of pharmaceutical companies in the future? Then apply to become part of the next wave of scientific discovery by joining Digital Science & Innovation (DSI).

Relationships
The Data and Solutions Engineer reports to the Sr. Director, Data and Solutions Engineering, Modalities and Pharmacology. Internal partners include therapeutic area scientists, computational biologists, data and software engineers, software developers, platform and compute engineers in Research and Development and Information Technology. External relationships include commercial and academic collaboration partners.

Essential Functions
The Data and Solution Engineer role will implement the molecular design data product to enable Global Research Technology to accelerate using our data for therapeutics discovery and early development.
You will:
Create data pipelines from raw sources to cloud services. This involves understanding the data to improve future data generation methods. Implementing ETL methods that can accommodate very large hierarchical data as well as streaming data, in addition to traditional data types like tabular stores.
Implement pipelines that use cheminformatics and molecular modelling tools in conjunction with AI methods to transform and analyse datasets in preparation for the data product platform. This is important to create robust and adaptable systems to address automation needs for data curation backlogs.
Gather, organize, and transform large, complex datasets while developing processing pipelines, and additionally, you'll establish automated monitoring to ensure pipeline and database compliance and integrity.
Being a key contributor to agile product delivery teams, concentrating on publishing data products to the data catalog, platform engineering, and providing clinical research data, while prioritizing tasks based on business needs and ensuring accessible and well-utilized imaging data for scientists and data scientists.
Proficiency in DevOps concepts such as continuous integration and delivery, along with expertise in facilitating efficient data sharing via cloud, accelerated computing, and AI/ML strategies, while also assisting in provisioning compute and data pipelines to ensure high-performing delivery of diverse data products within the research and enterprise data ecosystem.
Optimize workflows for research imaging data, facilitate global data exchange, ensure researchers' proficiency in preferred applications, and collaborate to develop or acquire new systems and software with both internal and external partners.
Advocate for data and data science utilization, including computational and machine learning methods, within research projects, while also contributing to the maintenance and support of various tools and applications like Python, R, Jupyter Hub, Domino, and DataLab.
Collaborate and be transparent

Physical Requirements
Up to 10% overnight travel required.

Qualifications
Master’s degree, or PhD in Life Sciences, Biomedical Engineering, Physics, Statistics, or Computer Engineering is preferred. Bachelor’s degree with 8+ years’ relevant experience may also be considered;
Master’s degree with 5+ years’ relevant experience, or PhD with 4+ years’ relevant experience can be considered
Relevant experience includes:
Experience in the life sciences, chemistry, biotechnology, medical device, or pharmaceutical industry.
Demonstrated experience in constructing and operationalizing ETL data pipelines, combined with proficiency in databases (SQL, Oracle, NoSQL) and cloud technologies such as AWS S3, DynamoDB, and Lambda. Be knowledgeable in working with structured and unstructured datasets.
Working experience in cheminformatics, quantum mechanics, or similar atomic / molecule pipelines. It is especially important to have experience working with AI workflows. Any working knowledge of large language models (e.g. ChatGPT) for scientific applications is a significant advantage. This includes accounting for molecular properties used in machine learning workflows.
Have proficiency is a variety of data types associated with molecular modelling or complex chemistry compute workflows. Need to understand how to represent modified peptides or RNA molecules using formats like SMILES, PDB, etc.
Ability to work independently while being open to occasional guidance from managers or senior colleagues, with a preference for automated testing skills; additionally, excellent communication skills are required, both in interactions with bench scientists and end-users, as well as with middle management.

The role calls for a genuine passion to comprehend scientists' use cases, coupled with a broad expertise encompassing data and digital realms, including hands-on technical proficiency. Strong analytical skills, meticulous planning, and the capacity to design robust, scalable solutions in a structured and detail-oriented manner are essential.

We commit to an inclusive recruitment process and equality of opportunity for all our job applicants.

At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.

Novo Nordisk is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, gender identity, sexual orientation, national origin, disability, protected veteran status or any other characteristic protected by local, state or federal laws, rules or regulations.

If you are interested in applying to Novo Nordisk and need special assistance or an accommodation to apply, please call us at 1-855-411-5290. This contact is for accommodation requests only and cannot be used to inquire about the status of applications.","$107,470 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1923,$10+ billion (USD)
"McDonald's Corporation
3.5",3.5,"Chicago, IL",Manager - Data Engineer - Data & Analytics,"Company Description

McDonald’s evolving Accelerating the Arches growth strategy puts our customers and people first, and uses our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.
Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)
Our growth pillars emphasize the meaningful role technology plays as the leading, global omni-channel restaurant brand. Technology enables the organization through digital technology, and improving the customer, crew and employee experience each and every day.
Global Technology forging the way
Leading the digitization of our business is the Technology organization made up of intrapreneurs who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of cutting-edge opportunities for the business. At McDonald’s you get to solve technology innovation challenges at an incredible scale, and work across global teams who are always eager for a challenge. This provides access to exciting career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.

Job Description

McDonald’s Global Technology – Data & Analytics team is looking to hire a Data Engineer who has a deep understanding of data product lifecycle, standards and practices. You will be responsible for building scalable and efficient data solutions to support the company's data products and analytics initiatives. As a Data Engineer, you will collaborate with data scientists, analysts, and other cross-functional teams to ensure the availability, reliability, and performance of data systems. Your expertise in cloud computing platforms, technologies and data engineering best practices will play a crucial role in delivering high-quality data products and enabling data-driven decision-making.
Responsibilities:
Builds and maintains relevant and reliable data products that support the business needs. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.
Participates in new software development engineering. Helps to define business rules that determines the quality of data, assists the product owner in writing test scripts that validates business rules, and performs detailed and rigorous testing to ensure data quality
Develops a solid understanding of the technical details of data domains, and clearly understands what business problems are being solved
Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).
Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.
Collaborating with data scientists and analysts to understand data requirements and ensure data accuracy, integrity, and availability.
Building and optimizing data integration workflows to connect data from different systems and platforms.
Monitoring and troubleshooting data pipelines, identifying and resolving performance issues and bottlenecks.
Ensuring data security and compliance with data governance policies and regulations.
Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.
Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to improve data systems and processes.
Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference.
Ability and flexibility to coordinate and work with teams distributed across time zones, as needed. For instance, early morning/late evening hours to coordinate with teams in India

Qualifications

Requirements:
Bachelor's or Master's degree in Computer Science or related engineering field and deep experience with AWS infrastructure
5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.
7+ years of proficiency in programming languages commonly used in data engineering, such as Python.
3+ years of hands-on experience with big data processing frameworks, such as Apache Spark.
5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.
Working knowledge of relational and dimensional data design and modeling in a large multi-platform data environment
Solid understanding of SQL and database concepts.
Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.
Expert Knowledge of data, master data and metadata related standards, processes and technology
Ability to drive continuous data management quality (i.e. timeliness, completeness, accuracy) through defined and governed principles
Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools
Demonstrated experience in data management & data governance capabilities
Familiarity with data warehousing principles and best practices.
Excellent problem solver - use of data and technology to solve problems or answer complex data related questions
Excellent communication and collaboration skills to work effectively in cross-functional teams.
Preferred Requirements:
Experience with JIRA and Confluence as part of project workflow and documentation tools is a plus
Experience with Agile project management methods and terminology a plus
Experience with Prometheus, Grafana

Additional Information

McDonald’s is committed to providing qualified individuals with reasonable accommodations to perform the essential functions of their jobs. Additionally, if you (or another applicant of whom you are aware) require assistance accessing or reading this job posting or otherwise seek assistance in the application process, please contact recruiting.supportteam@us.mcd.com
McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
Nothing in this job posting or description should be construed as an offer or guarantee of employment.","$103,480 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1955,$10+ billion (USD)
"EVRY India
4.0",4.0,"Jersey City, NJ",Onsite Lead Data Engineer(SSIS),"Onsite Lead Data Engineer(SSIS)
Location NJ-New Jersey Jersey City
Experience Range 8 - 10 Years
Open

Skills MSSQL & SSIS

Job Description
About Us
EVRY India and EVRY USA are wholly owned subsidiaries of TietoEVRY, a leading digital services and software company headquartered in Finland with annual revenues of around USD 3.3 billion. TietoEVRY employs around 24,000 experts globally and is recognized as the #1 IT services and #1 financial services company in the Nordics. TietoEVRY serves thousands of enterprises and public sector customers in more than 90 countries. We foster a culture of continuous learning and focus on helping our customers in accelerating their digital journey to scale business advantage. Be it talent, speed to market, innovation, or cross-pollination of ideas across markets, TietoEVRY leverages USA and India operations to compete locally as well as globally.
About EVRY USA
EVRY USA delivers IT services to a wide range of customers in the USA through its global delivery centers and India offices (EVRY India) in Bangalore & Chandigarh, India. We offer a comprehensive IT services portfolio and drive digital transformation across Banking & Financial Services, Insurance, Healthcare, Retail & Logistics, and Energy, Utilities & Manufacturing sectors. EVRY India's process and project maturity is very high — the two offshore development centers in India are appraised at CMMI DEV Maturity Level 5 & CMMI SVC Maturity Level 5 and certified under ISO 9001:2015 & ISO/IEC 27001:2013
Roles and Responsibility
Position - Lead Data Engineer (SSIS/ MSSQL / ETL/ TSQL)

Location - Warren, NJ (Onsite for 4 days / week)

Rate - Competitive

Visa Preference - USC, GC, H4's, L2 EAD.

Job Description:
8-10 years of experience in MSSQL & SSIS
Development of high-quality database solutions
Develop, implement and optimize stored procedures and functions using MSSQL, T-SQL
Strong knowledge on SQL and procedural languages such as T-SQL, PL/SQL etc
Experience with building ETL solution using SSIS.
Analyze existing SQL queries for performance improvements and suggest new queries.
Hands on with Performance optimizations
Develop procedures and scripts for data migration.
Provide timely scheduled management reporting.

Recruiter Name Nawaz
Recruiter Email Id usa-recruitment@tietoevry.com","$104,361 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Information Technology,Information Technology Support Services,1994,Unknown / Non-Applicable
"WSP
3.7",3.7,"Troy, NY",Associate Electrical Engineer (Mission Critical/Data Center),"Associate Electrical Engineer (Mission Critical/Data Center)

Who We Are
At WSP, we are driven by inspiring future-ready pioneers to innovate. We’re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!
Keep the internet running and the world working! At kW Mission Critical Engineering, a part of WSP USA, that’s exactly what we do. Simply, data centers are buildings that store information technology. These mission critical facilities must remain operational 24 hours a day, 365 days a year. Your role is to design the building infrastructure—power and cooling systems—to make sure that happens.
Be a part of an engineering team where from day one, you will collaborate and add value to every project. Gain invaluable experience early in your career. Not only will you be designing building systems, you’ll interact with all internal mechanical, electrical, plumbing, fire protection, and telecommunication engineers, external design partners like architects and structural engineers, and equipment vendors for the development of drawings and specifications. Then, travel to project locations during construction and watch your designs being built for some of the largest companies in the world.
Do you want to work on innovative, award-winning projects, travel and see your designs being built, and enjoy an occasional game of ping-pong, lunch and learn, or after-hours’ camaraderie? Are you looking for career growth? Join our great people at our great places designing great projects.
This Opportunity
kW Mission Critical Engineering, a WSP company, is looking for an Electrical Engineer for our offices in Troy, NY. As an Electrical Engineer with us, you will analyze complex power and other building systems including generator plants, medium voltage distribution, uninterruptible power systems, lighting, fire alarm, and grounding.
Your Impact
Perform a variety of assignments requiring the application of standard engineering and design techniques under the direction and guidance of senior engineers
Work with multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners.
Attend client meetings
Collaborate and coordinate with internal project discipline team members and equipment vendors and manufacturers
Design electrical systems for buildings including lighting, receptable, general, essential and critical electrical infrastructure
Select and schedule equipment
Prepare calculations and specifications
Understand short circuit, coordination, and arc flash calculations
Perform construction administration tasks with assistance from senior staff
Work alongside senior engineers to survey and evaluate existing worksite conditions
Who You Are
The ideal candidate is motivated, proactive, and excited to learn. Candidate shows a strong interest in a fast-paced and dynamic environment, communicating and collaborating with internal and external design, client and construction team members, and a desire to travel.
Required Qualifications:
1 to 3 years of relevant post education experience in an electrical engineering capacity.
Bachelor’s degree in Electrical Engineering or Architectural Engineering with electrical building systems emphasis
Excellent interpersonal skills, teamwork, and communication skills, both written and verbal
Ability to travel to project sites
Interest in innovative design, specifically in renewable energies and sustainable, high performing, commercial, industrial or mission critical/data center buildings.
Preferred Qualifications:
EIT License, or ability to obtain EIT
Knowledge of AutoCAD and Revit
Knowledge of building, electrical and energy codes
Knowledge of SKM, eTap or Cyme software
Previous building design or construction internship experience

Compensation and Benefits:
WSP provides a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on a providing health and financial stability throughout the employee’s career.
Expected Salary: $61,700 - $108,200
WSP USA is providing the compensation range and general description of other compensation and benefits that the company in good faith believes it might pay and/or offer for this position based on the successful applicant’s education, experience, knowledge, skills, and abilities in addition to internal equity and geographic location. WSP USA reserves the right to ultimately pay more or less than the posted range and offer additional benefits and other compensation, depending on circumstances not related to an applicant’s sex or other status protected by local, state, or federal law.

#LI-AB1
Additional Requirements
To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.
Additional Details
Travel Required: 20%
Job Status: Regular
Employee Type: Full
Primary Location: TROY - RIVER ST
All locations: US-NY-Troy
About WSP
WSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com
WSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee’s career.
At WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?
WSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race/Age/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability or Protected Veteran Status.
The selected candidate must be authorized to work in the United States.
NOTICE TO THIRD PARTY AGENCIES:
WSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation – no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service.","$84,950 /yr (est.)",10000+ Employees,Company - Private,#N/A,#N/A,#N/A,$5 to $25 million (USD)
"Bio-techne
3.7",3.7,"Centennial, CO",Senior Data Engineer,"By joining Bio-Techne, you’ll join a company with a powerful and positive purpose of enabling cutting-edge research in Life Sciences and Clinical Diagnostics. Bio-Techne, and all of its brands, provides tools for researchers to further treat and prevent disease worldwide.
Position Summary:
We are looking for a Senior Data Engineer to join our growing team. This individual will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The core function will be driving the creation of master data repositories for critical business data. The ideal candidate is an experienced data pipeline builder who enjoys optimizing data systems and building them from the ground up. The Senior Data Engineer will support our software developers, database architects and data analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.
Key Responsibilities:
Create and maintain master data solutions for critical business data
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure or similar cloud ‘big data’ technologies.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Education and Experience:
Bachelor’s Degree in Computer Science and 5-8 years of relevant experience, or a High School Diploma, certificate, or equivalent with 8-10 years relevant experience.
Experience with relational SQL databases required
Experience with data warehousing methodologies required
5+ years working with SQL and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
5+ years of experience in a Data Engineer or Database Developer role
Master Data Management knowledge and experience preferred
Knowledge, Skills and Abilities:
Experience with data pipeline and workflow management tools: Azure Service Bus, Azure Data Factory, Dell Boomi or similar ETL/ELT technologies a plus
Experience with Azure cloud services a plus
Experience with object-oriented/object function scripting languages: Python,C#, C++, JavaScript, etc. a plus
Experience building and optimizing data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets a plus
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Microsoft Master Data Services and/or Data Vault 2.0 would be a plus
Why Join Bio-Techne:
We offer competitive salaries along with extensive medical, vision, and dental plans for you and your family starting on day one!
We invest in our employees’ financial futures through 401k matching and an employee stock purchase plan.
We help our employees develop their careers through mentorship, promotional opportunities, training and development, internship programs, and more.
We offer employee resource groups, volunteer paid time off, employee events, and charity drives to build a culture of caring and belonging.
We foster a culture of empowerment and innovation, where employees feel valued and encouraged to bring their new ideas to the table.
Where permitted by applicable law, candidate must have received or be willing to receive an FDA authorized COVID-19 vaccine by date of hire to be considered for this position.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Bio-Techne is an E-Verify Employer in the United States.","$132,500 /yr (est.)",1001 to 5000 Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1976,$500 million to $1 billion (USD)
"Publicis Sapient
3.8",3.8,"Arlington, TX",Senior Manager Data Engineer (Public Sector),"Senior Manager Data Engineer (Public Sector)
Full-time
Company Description
As a Digital Business Transformation partner of choice at Publicis Sapient, we’ve spent nearly three decades utilizing the disruptive power of technology and ingenuity to help digitally enable our client's businesses in their pursuit of the next. Our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting, and customer obsession to accelerate our clients’ businesses by designing the products and services their customers truly value. In the space between next and now is how. And we believe that how you seize that space is everything.
Great Place to Work® Certified in the US: https://www.greatplacetowork.com/certified-company/1000228
Job Description
Publicis Sapient | Public Sector is looking for a Senior Manager, Data Engineer to be part of our team of top-notch technologists. You will lead and deliver technical solutions for large-scale digital transformation projects. Working with the latest data technologies in the industry, you will be instrumental in helping our clients evolve for a more digital future.
Qualifications
Primary Skill: 13 yrs of Data Engineering Exp; Azure migration, Cloud, Create road maps, Oversee Migration project, Data Warehouse and ETL
Must-Haves:
***Application open to ONLY U.S. Citizens and Permanent Residents***
***Must be eligible to obtain U.S. Government Clearance (Public Trust)***
13 yrs of demonstrable experience in data platforms involving the implementation of end-to-end data pipelines
Hands-on exp with at least one of the leading public cloud data platforms (Amazon Web Services, Azure, or Google Cloud)
Exp in implementing data pipelines for both streaming and batch integrations using tools; Google Cloud Dataflow, Azure Data Factory, ksqlDB
Exp working with code repositories and continuous integration
Exp in data modeling, warehouse design, and fact/dimension implementations
Strong SQL knowledge to develop efficient and complex queries
Exp working with Microsoft SQL Server
Exp in data processing, transformation, and manipulation using Python (3+ yr exp)
Develop, maintain, and troubleshoot complex ETL processes using Microsoft SSIS
Data ingest, validation, and enrichment pipeline design and implementation
Bachelor's degree in Computer Science, Engineering, or a related field
Nice to have:
Exp in Data bricks, Snowflakes
Exp in Tableau/ Power BI, familiarity with ArcGIS would be an asset
Certifications for any of the cloud services like AWS, Google Cloud, Azure
Logical programming in Spark/ PySpark / Scala
Additional Information
Annual Pay Range: 170,000 - 190,000 USD
The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. The actual range for this position may differ, depending on location and the specific skillset required for the work.
Benefits of Working Here:
Flexible vacation policy
Unlimited PTO's
15 company paid holidays annually
Work Your World program
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program","$180,000 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1990,Unknown / Non-Applicable
Aalpha Prime Tech Global,#N/A,"Jersey City, NJ",Data Engineer on W2,"Mandatory Skills: Apache Flink
Responsibilities include:
Engage in Event streaming design development using, Apache Flink, AWS KDA, Kafka
Develop technical specification documents and generic/reusable frameworks Public cloud-AWS.
Design and Develop stateless and stateful transformations using Apache Flink
Design and Develop the streaming pipelines with a various sink point like MSK, S3, Rest API.
Metric collection and Dashboard integration with ,Prometheus, CloudWatch, data dog.
Design and develop reconciliation and reprocessing the data and ensure zero data loss.
Mentor the JPMC team on Flink development practices and support the first implementation.
Identify/troubleshoot application code-related issues and review and provide feedback to the final user.
.Ensure that JPMC risk / controls, security, and data management policies are followed.
BS/BA degree or equivalent experience. Expertise in application, data, and infrastructure architecture disciplines
Advanced knowledge of architecture and design across all systems. Proficiency in multiple modern programming languages
12+ years of professional experience as Software Engineer, Applications Developer, Data Engineer or similar experience
Job Type: Contract
Salary: $75.00 - $80.00 per hour
Experience level:
10 years
Schedule:
8 hour shift
Monday to Friday
Application Question(s):
Are you USC or GC
Experience of Apache Flink
Local to New Jersey
Work Location: In person",$77.50 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$1 to $5 million (USD)
"INTEL
4.1",4.1,"Hillsboro, OR",DigiT Data Software Engineer,"Job Description

Join our Intel Fab Construction Enterprise (FCE) in building the world's largest semiconductor manufacturing factories across the globe. The future is what we build. Our enterprise manages a portfolio of capital projects on-site with a large contractor workforce that encompasses outsourced general contractors, A/E Architecture and Engineering firms, and key trade companies in the Semiconductor Construction Industry. The scope of our work includes but is not limited to Progressive Build, Tool Install, new factories, and site infrastructure. We are looking for world-class technical talent to join our team. If you enjoy working with the latest technology in a rewarding, fast-paced environment, this is the right place for you. Everywhere you go, you'll find an opportunity to make a difference. In any given workday, you will be given the responsibility to innovate and create an impact on our business. As part of FCE's Digital Transformation initiative, the organization is transitioning to cloud-based systems and technologies which require a completely different set of skills for a wide array of datasets to enable end-to-end analytics for delivering fab construction cost, schedule, and predictability improvements. The information systems and analytics team require qualified individual(s) with deep web application, data, business intelligence, and analytics experience in the Microsoft stack to implement solutions for construction-related projects, including developing new capabilities using Azure services. This is an Intel Contract Employee (ICE) position and relocation assistance will be provided. As a DigiT Data Software Engineer - ICE your responsibilities will include but are not limited to: Have technical leadership for end-to-end systems, data and/or analytics projects within FCE. Influence technical direction for solutions related to our Digital Transformation strategy. Set and refine objectives for developing capabilities to rapidly implement against digital transformation needs. Assign and oversee overall project tasks implementing systems, data and analytics in support of program goals. Ensure appropriate progress against plans and schedules. Develops and implements software and data quality standards as part of FCE's systems and data pipeline architecture. Build the infrastructure required for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources using SQL and Azure Cloud (Azure) technologies. Build data tools for analytics and data scientist team members that utilize the data pipeline for building and optimizing our solutions to deliver construction analytics. Work with the business stakeholders to identify data and visualization needs to model, frame business scenarios, and implement solutions that are meaningful and which impact critical business processes and/or decisions. Identify, design, and implement internal process improvements: CI/CD, automating processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build and drive safety culture of caring in every business environment, office to the construction sites, and from front-end planning to construction execution. The successful candidate should exhibit the following behavioral traits: Customer obsession, communication and analytic skills. Technical project management and execution skills. Operating in virtual, cross-organizational teams using Agile methodologies. Champion and value the safety culture of caring throughout the project lifecycle.
Qualifications

You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates. Position not eligible for Intel immigration sponsorship.

Minimum Qualifications:
5+ years of experience in: Microsoft software development stack (MVC.NET, C#, SQL, etc.), SQL Server in lieu of a degree.
Bachelor's or Master's degree in Computer Science, Data Science, Information Systems or closely related field and 4+ years of experience in: Microsoft software development stack (MVC.NET, C#, SQL, etc.), SQL Server OR
5+ years of experience in: Microsoft software development stack (MVC.NET, C#, SQL, etc.), SQL Server will be considered in lieu of a degree.

Preferred Qualifications:
Knowledge in Blazor technologies.
Technical Certificates/Certifications (e.g. online data engineering).
Experience in:Developing ETL processes.
Construction, tool install, or design engineering fields.
Manufacturing, supply chain, or related business acumen.

Inside this Business Group

As the world's largest chip manufacturer, Intel strives to make every facet of semiconductor manufacturing state-of-the-art - from semiconductor process development and manufacturing, through yield improvement to packaging, final test and optimization, and world class Supply Chain and facilities support. Employees in the Technology Development and Manufacturing Group are part of a worldwide network of design, development, manufacturing, and assembly/test facilities, all focused on utilizing the power of Moore’s Law to bring smart, connected devices to every person on Earth.
Other Locations

US, OR, Hillsboro; US, CA, Santa Clara
Covid Statement

Intel strongly encourages employees to be vaccinated against COVID-19. Intel aligns to federal, state, and local laws and as a contractor to the U.S. Government is subject to government mandates that may be issued. Intel policies for COVID-19 including guidance about testing and vaccination are subject to change over time.
Posting Statement

All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.
Benefits

We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here: https://www.intel.com/content/www/us/en/jobs/benefits.html

Annual Salary Range for jobs which could be performed in US, California: $52,000.00-$200,000.00
Salary range dependent on a number of factors including location and experience

Working Model

This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs.

JobType
Hybrid","$126,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1968,$10+ billion (USD)
"TekSynap
4.3",4.3,"Andrews AFB, MD",Voice Data Engineer,"Responsibilities & Qualifications:
RESPONSIBILITIES
Responsible for circuit restoration, fault isolation, quality control testing, trend analysis, performance monitoring, and status reporting.
Performs operational technical control functions on critical circuits using digital and analog test equipment.
Prepare operational reports as necessary.
Plans and implements physical connections on frames, patch panels, cabling, and equipment by making cross connects and building connectors.
Maintains associated labeling and circuit records.
Responsible for developing and implementing standard operating procedures for station operation.
Ensure that staff members are trained to provide full service in accordance with standard DISA tech control procedures.
Develops and maintains contingency/restoral plans.
Ensures proper operation of equipment and associated cryptographic systems. Ensures communications security (COMSEC) processes are followed in accordance with current regulations.
Coordinates circuit actions with circuit management office.
Prepares Authorized Service Interruption requests. (Selected applicant will be subject to a government security investigation and must meet eligibility requirements for access to classified information).
REQUIRED QUALIFICATIONS
Bachelors degree and 4+ years of prior relevant experience or a Masters degree with 2+ years of prior relevant experience, additional years of experience will be accepted in lieu of a degree.
Possess an active Secret security clearance with ability to obtain TS/SCI.
Current DoD 8570 baseline certification for IAT II (one of the following: GSEC, Security+, SCNP and SSCP certifications)
Must be familiar with DISA operations circulars, DOD circuit actions, and TSO/TSR processing requirements.
Must be familiar with NSA approved encryption devices and communications security processes and procedures.
Experience with circuit history folders, master station logs, trouble tickets, FACIT software.
Experience in writing standard operating procedures for tech control facilities.
Must possess excellent communication skills, written and verbal.
DESIRED QUALIFICATIONS
Successful completion of technical training associated with operations and maintenance of a Tech Control Facility equivalent to that required for US military (e.g., AFSC 3C2X1, MOS 31P, or NEC2318), or equivalent civilian training and work experience in the same or similar civilian environment.
Experience in managing tech control operations.
Familiarity with maintenance of circuit, equipment and systems records files and diagrams.
Implementation of Telecommunications Service Orders.
Overview:
We are seeking a Voice Data Engineer to join our team supporting AFNCR at Joint Base Andrews, MD(JBA)/Joint Base Anacostia Bolling, VA (JBAB).
The AFNCR IT Services program provides support services for information systems for Headquarters Air Force (HAF), Air Force District of Washington (AFDW), Office of the Secretary of Defense (OSD), Joint Chiefs of Staff, and other Air Force activities within the AFNCR missions to include the Pentagon, Joint Base Andrews (JBA), Joint Base Anacostia-Bolling (JBAB), and other locations, leased spaces, and alternate sites.
TekSynap is a fast growing high-tech company that understands both the pace of technology today and the need to have a comprehensive well planned information management environment. “Technology moving at the speed of thought” embodies these principles – the need to nimbly utilize the best that information technology offers to meet the business needs of our Federal Government customers.

We offer our full-time employees a competitive benefits package to include health, dental, vision, 401K, life insurance, short-term and long-term disability plans, vacation time and holidays.
Visit us at www.TekSynap.com.
Apply now to explore jobs with us!
The safety and health of our employees is of the utmost importance. Employees are required to comply with any contractually mandated Federal COVID-19 requirements. More information can be found here.
By applying to a role at TekSynap you are providing consent to receive text messages regarding your interview and employment status. If at any time you would like to opt out of text messaging, respond ""STOP"".
Additional Job Information:
COMPETENCIES
Establish Focus
Change Management
Develop Others
Oral Communication
Written Communication
Interpersonal Awareness
Build Relationships
Analytical Thinking
Conceptual Thinking
Strategic Thinking
Technical Expertise
Initiative
Foster Innovation
Results Oriented
Teamwork
Customer Service
WORK ENVIRONMENT AND PHYSICAL DEMANDS
The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of the job. Reasonable accommodation may be made to enable individuals with disabilities to perform the essential functions.
Location: Joint Base Andrews, MD (JBA), Joint Base Anacostia Bolling, VA (JBAB)
Type of environment: Office
Noise level: (Low, Medium, High)
Work schedule: Dayshift; core support hours are 0600 -1800
Amount of Travel: up to 10%
PHYSICAL DEMANDS
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is regularly required to use hands to handle, feel, touch; reach with hands and arms; talk and hear. The employee is regularly required to stand; walk; sit; climb or balance; and stoop, kneel, crouch, or crawl. The employee is regularly required to lift up to 10 pounds. The employee is frequently required to lift up to 25 pounds; and up to 50 pounds. The vision requirements include close vision, distance vision, peripheral vision, depth perception, and ability to adjust focus.

WORK AUTHORIZATION/SECURITY CLEARANCE
U.S.Citizenship
Clearance requirement: Active Secret clearance with ability to obtain TS/SCI

OTHER DUTIES
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.

EQUAL EMPLOYMENT OPPORTUNITY
In order to provide equal employment and advancement opportunities to all individuals, employment decisions will be based on merit, qualifications, and abilities. TekSynap does not discriminate against any person because of race, color, creed, religion, sex, sexual orientation, gender identity, protected veteran status, national origin, disability, age, genetic information or any other characteristic protected by law (referred to as “protected status”). This nondiscrimination policy extends to all terms, conditions, and privileges of employment as well as the use of all company facilities, participation in all company-sponsored activities, and all employment actions such as promotions, compensation, benefits, and termination of employment.

TekSynap is committed to ensuring that our online application process provides an equal employment opportunity to all job seekers, including individuals with disabilities. If you believe you need a reasonable accommodation in order to search for a job opening or to submit an application, please contact hr@teksynap.com for assistance.","$89,368 /yr (est.)",501 to 1000 Employees,Company - Private,Government & Public Administration,National Agencies,2008,$100 to $500 million (USD)
"Lockheed Martin
4.1",4.1,"Moorestown, NJ","Data Engineer, Staff - Data Warehouse / SAP / RDBMS - REMOTE","Job ID: 647148BR
Date posted: Aug. 02, 2023
Program: CDAO

Description:Data and Analytics is central to Lockheed Martin's digital transformation journey. Come join the team that develops the Data and Analytics solutions for Lockheed Martin's Rotary and Mission Systems (RMS) business area, including the strategy, platforms, and tools.

Lockheed Martin's RMS Chief Data and Analytics Office (CDAO) is seeking a Staff Data Engineer who can lead a team of data engineers and contractors to manage support operations and improve overall performance and reliability of our Data Warehouse Platform.

Our Data Warehouse Platform is a complex data system that takes data from Enterprise source systems including SAP, Solumina, and other transactional systems; processes and transforms the data through multiple ETL tools; and makes the data available in HANA, SQL Server, and Oracle data warehouses for our customers' reporting and analytics needs.

The team lead will work closely with the technical lead and architects to ensure ongoing stability of the platforms and to identify and coordinate architectural and data flow improvements. They will direct all team activities, including management of service desk tickets and implementation of improvements.

The team lead will also meet regularly with stakeholders and internal Lockheed Martin customers as the prime contact and the face of the Data Warehouse Platform team, to understand and address issues and concerns, and to provide regular status. In addition, the team lead may administer managed services support, and will build relationships with managed services team providers.

The successful candidate will must have strong communication and customer engagement skills, as well as organizational and team-leadership skills. In addition, the candidate must have strong data engineering skills and experience with complex data systems.

The work location for this position is virtual.

Duties and responsibilities include, but are not limited to:
Manage service desk tickets to ensure resolutions within established SLAs
Liaise with stakeholders and internal customers to understand and address their issues and concerns, and to provide regular status updates
Lead and motivate the team; Coach and develop team members
Partner with the Technical Lead, and collaborate with data architects, data engineers, data analysts to develop solutions across the entire data processing pipeline
Work along with the Technical Lead to lead the team's implementation of solutions to improve new and existing data pipelines and data storage systems
Oversee migration of data from legacy systems to modern solutions
Basic Qualifications:
9+ years' experience in Data Engineering, Data Analysis, or related disciplines
Strong understanding of data lifecycles. Able to interpret and communicate the state of data throughout the processing pipeline
Strong customer engagement experience
Team leadership experience
Strong analytical skills and understanding of data warehouses, data elements and application software solutions to optimize data gathering and analysis
Experience with SQL Server, Oracle, HANA, or other relational databases
Experience working with virtual teams
Experience with SAP tools and systems
Bachelor's Degree in Computer Science, Data Science, Computer Information Systems, or related discipline
US Citizenship
Desired Skills:
Experience with managed services support
Experience in Agile methodologies
Prior Aerospace & Defense industry experience
Experience troubleshooting and performance tuning views, models, or stored procedures in HANA, SQL Server, Oracle, or other relational databases
Experience with data analytics and/or visualization tools, such as Tableau, Alteryx, BusinessObjects
Clearance Level: None
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Full-time Remote Telework: The employee selected for this position will work remotely full time at a location other than a Lockheed Martin designated office/job site. Employees may travel to a Lockheed Martin office for periodic meetings.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: 4x10 hour day, 3 days off per week
Pay Rate:
The annual base salary range for this position in Colorado or Washington is $106,400 - $203,900 . Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.

Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.
(Washington state applicants only) Non-represented full time employees: accrue 10 hours per month of Paid Time Off (PTO); receive 40 hours of Granted PTO annually for incidental absences; receive at least 90 hours for holidays. Represented full time employees accrue 6.67 hours of PTO per month; accrue up to 52 hours of sick leave annually; receive at least 96 hours for holidays. PTO is prorated based on hours worked and start date during the calendar year.

This position is incentive plan eligible.
Pay Rate:
The annual base salary range for this position in California or New York City is $122,300 - $230,500 . Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.

Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.

This position is incentive plan eligible.
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.

With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.

If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications.
Experience Level: Experienced Professional
Business Unit: ENTERPRISE BUSINESS SERVICES
Relocation Available: No
Career Area: Information Technology
Type: Full-Time
Shift: First",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1995,$10+ billion (USD)
"Lockheed Martin
4.1",4.1,"Littleton, CO","Electronics Engineer, Command and Data Handling, Early-to-Mid Career","Job ID: 647263BR
Date posted: Aug. 02, 2023
Program: Remote Sensing

Description:Take your career to a new level and work at an extraordinary company in Sunnyvale CA or Littleton CO!

The coolest jobs on this planet... or any other... are with Lockheed Martin Space!

Lockheed Martin. You know about us already. We've been around for over 100 years and plan to be here for at least 100 more! We solve complex challenges, advance scientific discovery and deliver innovative solutions that help our customers keep people safe. We employ 116,000 employees worldwide, 20% of whom are veterans!

We know that our strong company culture and core values help us perform better in the long run. We believe in work-life balance which results in increased productivity and a happier, less-stressed workforce.

Our 3 core values are the foundation of our culture:
1. Do the right thing
2. Perform with excellence
3. Treat others with respect

What does this role look like?

Join us as an Electronics Engineer working on command and data handling (C&DH) hardware for the Remote Sensing Electronics team, supporting some of the most important missions for our country!

You will have technical ownership of command and data handling electronics, working closely with our design, manufacturing, and systems partners to deliver critical hardware

Key activities you will accomplish in this role:
Full product life cycle. Knowledge of the definition, interpretation, and implementation of design requirements, coordination and execution of hardware designs, development and integration of hardware in accordance with all Lockheed Martin Space engineering process specifications.
Interfacing with organizations across the enterprise including planning, manufacturing, and engineering to ensure the delivery of products.
Failure investigation processes, including discrepancy documentation and resolution.

Typical mins for this role:
5 - 9 years of professional experience for this role.
Willing and able to obtain and maintain a TS/SCI clearance, thus you are a US Citizen.

BENEFITS OF EMPLOYMENT:
Learn more about Lockheed Martin's comprehensive benefits package.

We are an equal opportunity employer and value diversity at Lockheed Martin. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Basic Qualifications:
Bachelor of Science or higher from an accredited college in Electrical Engineering or related discipline, or equivalent experience/combined education.
Ability to interpret and create electrical schematics.
Basic understanding of analog and digital circuit design.
Willing and able to obtain and maintain a TS/SCI clearance, thus you are a US Citizen.
Desired Skills:
Demonstrated useage of Zuken, Mentor Graphics or other schematic capture tool.
Performed Worst Case Analysis (WCA) on Circuit Card Assembly (CCA) designs.
Knowledge of card test requirements and process.
Ability to understand electrical circuits, interfaces, and interconnect diagrams.
Technical experience in full life cycle development of hardware including design, integration, and test.
Excellent presentation, oral and written skills.
Demonstrated strong problem solving and conflict resolution skills.
Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.
Clearance Level: TS/SCI
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Part-time Remote Telework: The employee selected for this position will work part of their work schedule remotely and part of their work schedule at a designated Lockheed Martin facility. The specific weekly schedule will be discussed during the hiring process.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: 9x80 every other Friday off
Pay Rate:
The annual base salary range for this position in Colorado or Washington is $82,200 - $157,500. Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.

Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.
(Washington state applicants only) Non-represented full time employees: accrue 10 hours per month of Paid Time Off (PTO); receive 40 hours of Granted PTO annually for incidental absences; receive at least 90 hours for holidays. Represented full time employees accrue 6.67 hours of PTO per month; accrue up to 52 hours of sick leave annually; receive at least 96 hours for holidays. PTO is prorated based on hours worked and start date during the calendar year.

This position is incentive plan eligible.
Pay Rate:
The annual base salary range for this position in California or New York City is $94,500 - $178,000. Please note that the salary information is a general guideline only. Lockheed Martin considers factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience, education/ training, key skills as well as market and business considerations when extending an offer.

Benefits offered: Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Flexible Spending Accounts, EAP, Education Assistance, Parental Leave, Paid time off, and Holidays.

This position is incentive plan eligible.
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.

With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.

If this sounds like a culture you connect with, you're invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications.
Experience Level: Experienced Professional
Business Unit: SPACE
Relocation Available: Possible
Career Area: Electronics Engineering
Type: Full-Time
Shift: First",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1995,$10+ billion (USD)
Easyhiring for Easyhiring,#N/A,"Denver, CO",Staff Data Center Network Engineer,"We are a recruiting company EasyHiring looking for candidates for the position of Staff Data Center Network Engineer for our partners.
We are seeking a Staff Network Engineer to design and engineer effective and scalable network systems that ultimately contribute to the success of our 5G network. The successful candidate will participate in the design, engineering, and deployment of network routing devices for a nationwide 5G network buildout. He or she will provide advanced technical leadership for complex project work, including functional subsystem upgrades for mission-critical network devices and services and strategic upgrades to the network. In this role, you will:
Review architectural requirements and provide analysis for network and services specifications, network design in a multi-VRF environment;
Design, plan, and implement complex LAN/WAN/RAN configurations at nationwide scale in a service provider network;
Effectively communicate engineering solutions through detailed high- and low-level diagrams;
Provide advanced expertise in the planning and development of network test, validation and integration plans on projects and assurance of network integrity;
Provide hands-on implementation and support for 24x7 production network operations.
Skills, Experience and Requirements
Ideal Staff Network Engineer candidates have:
Bachelor’s degree in electrical/computer Engineering preferred;
8 or more years of professional experience in large enterprise or carrier space;
Professional networking certifications a plus – CCNA/CCNP/CCIE or equivalent;
Public cloud certifications a plus – advanced networking, cloud network engineer or equivalent.
Successful Staff Network Engineer candidates will have an update-to-date working knowledge with recent hands-on activity in:
Service provider networking;ISIS, MPLS
BGP routing and route reflectors
Multi-VRF environments with traffic shaping and QoS
High availability, failover and redundant configurations
Network security design considerations and firewalls
Other services such as DNS, DHCP, TACACS, ISE, VPN
Network automation with Python, Bash, Ansible, and Zero Touch Provisioning
Data center fabric design and deployment
Job Type: Full-time
Salary: $87,500.00 - $144,000.00 per year
Ability to commute/relocate:
Denver, CO: Reliably commute or planning to relocate before starting work (Required)
Education:
Bachelor's (Required)
Experience:
Computer Engineering: 8 years (Required)
Service provider networking;ISIS, MPLS: 1 year (Required)
License/Certification:
CCNA/CCNP/CCIE or equivalent (Required)
advanced networking, cloud network engineer or equivalent. (Required)
Work Location: In person","$115,750 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Wolters Kluwer
3.7",3.7,"Coppell, TX",Associate Product Software Engineer - Data Engineer,"Job Description Summary: Associate Product Software Engineer - Data Engineer
The digital future has arrived, and the tax and accounting professions are changing rapidly. Professionals today have different needs, expectations and capabilities. In addition to accuracy, they need greater mobility, simplicity and speed. These needs place a premium on access to active intelligence, agile systems, and integrated workflow solutions — in short “Best in Process” solutions. This is precisely the value that Wolters Kluwer, Tax & Accounting US delivers to professionals.
Do you enjoy tackling problems that are often elusive and working with engineers to ensure the highest level of quality? Are you not content to know “what”, you need to know “why”, and are meticulous in your attention to detail? Do you take your commitments seriously? Do you have passions equally for technical excellence and seeing your work have an impact? If so, we have a career-changing opportunity to be a key player on a team in our Dallas office. If you wish to join the “best of the best,” read on….
Wolters Kluwer Tax & Accounting is looking for a Data Engineer to work in our Coppell, TX office. As a Data Engineer, this position will support the building of data pipelines for the Azure cloud data platform. The data engineer will review the existing solution and design a unified solution to transfer the data to our new data lake platform.
ESSENTIAL DUTIES AND RESPONSIBILITIES
Implement data lake pipelines that meet business use cases, are highly optimized for near real-time processing and reliable, and meet coding standards and best practices.
Work with Data architects and Data scientists to define & build data architecture, configure services for data science, using python or other ML languages.
Analyze and profile data from structured, semi-structured and unstructured sources, design the data model for various analytics use cases, and ability to build analytical reports and dashboards using modern data visualization tools
Identify newer and better technologies and solutions in data analytics and data architecture areas.
Build, enhance and maintain CI/CD DevOps pipelines for both infrastructure and code deployment.
MINIMUM QUALIFICATIONS
Bachelors or master's degree in information systems, Data Science, computer science or similar
Internship/co-op experience with a data science cloud project or a cloud project using data engineering related services like Kafka, data bricks, AWS glue, Azure data factory or similar
Strong communication and collaboration skills with creative problem-solving skills.
Wolters Kluwer Tax & Accounting US (CCHGroup.com) is a leading provider of tax, accounting and audit information, software and services, and is a division of Wolters Kluwer, a market-leading global information services company. It has served tax, accounting and business professionals since 1913. Among its market-leading solutions are The CCH® ProSystem fx® Suite, CCH Axcess™, CCH® IntelliConnect®, CCH® IntelliConnect Direct, CCH® Accounting Research Manager® and the U.S. Master Tax Guide®. Wolters Kluwer Tax & Accounting US is based in Riverwoods, IL, with key office locations in Dallas, Wichita, New York, Washington, D.C., Chicago and Torrance.","$99,865 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1836,$1 to $5 billion (USD)
"BDO
3.8",3.8,"Grand Rapids, MI",IT Data Engineer III,"Job Summary:
The Data Engineer III is expected to use their strong business acumen skills to effectively work with business partners to understand their data needs and develop technical designs and requirements to meet those needs. This role works to help extract, transform, and store the Firm’s valuable data assets to achieve better operational efficiencies and provide better services to its clients through modern data movement pipelines. This role, in collaboration with other data engineers, data architects, data engineers, and other IT teams, will operationalize and document data extraction and ingestion platforms. This role is responsible for supporting technologies for the benefit of the Firm. Finally, this role assists in developing strategies, policies, and governance models to ensure the Firm’s data remains accurate, timely and relevant to the Firm’s goals.
Job Duties:
Works closely with stakeholders and other data engineering team members to define, design, and implement data solutions to support the Firm’s data initiatives
Designs and builds pipelines using no-code/low-code cloud technology for extracting, transforming, loading data from a wide range of source systems and file types into various data stores
Uses PowerBI to create 'source of truth' datasets used across operational dashboards, enabling end-users without direct access to source systems to consume and build reports for their areas of expertise
Prepares mock-up solution designs, visualizations, and reports to effectively demonstrate proposed solutions and deliverables
Acts as a subject matter expert, evangelist, and catalyst to educate on the Firm’s data platforms and best practices as they relate to the usage and hygiene of the Firm’s data assets
Works with data scientists and developers to use emerging and advanced technologies such as artificial intelligence and machine learning to identify and extrapolate hidden patterns and trends, increasing the value of the Firm’s data
Builds and maintains constructive working relationships with project team members, vendors, and other departments involved with projects, systems, and IT strategies
Documents metadata and maintains the Firm’s metadata catalog and data dictionaries
Ensures master data management principles are followed through the course of day-to-day data usage and solution design
Identifies and executes continuous improvement efforts to ensure the Firm’s data remains accurate and timely
Works closely with the Information Security and Compliance teams to ensure the firm’s data strategy and technologies meet or exceed both internal policies and external regulatory requirements
Collaborates with BDO Global and other BDO member firms to ensure standards between organizations are followed in support of reusable models and rapid deployment of shared technology
Understands and follows Project Management basics and Project Management Office policies and procedures
Other duties as required
Supervisory Responsibilities:
N/A
Qualifications, Knowledge, Skills and Abilities:
Education
High School Diploma or GED , required
Bachelor’s Degree in Computer Science, Information Management, Mathematics, or Statistics, preferred
Experience
Three (3) or more years working as a data engineer, data analyst, or in similar analyst roles, required
Three (3) or more years working with PowerBI, Tableau, or similar data visualization products, required
Demonstrable proficiency in developing and understanding custom and ad-hoc SQL queries, required
Two (2) or more years working within commercial cloud platforms such as Microsoft Azure, AWS or GCP, preferred
Experience working within a large, complex enterprise with significant regulatory and compliance requirements, preferred
Experience using version control tools (Azure DevOps, GitHub), preferred
Experience using a modern scripting language such as Python, Scala, R, or Java, preferred
Professional service firm experience, preferred
License(s)/Certification(s)
N/A
Software
Strong proficiency in the use of Microsoft Office suite, specifically Excel, required
Strong proficiency in the use of SQL Server Management Studio (SSMS), or similar, required
Strong proficiency in the use of PowerBI, Tableau, Looker, Qlik, or similar, required
Language(s)
NA
Other Knowledge, Skills & Abilities
Strong analytical, organizational, and problem-solving skills
Excellent written communication skills, maintaining accurate documentation and technical authorship of complex documents
Ability to facilitate meetings efficiently and effectively
Ability to follow an issue through to its logical conclusion, and escalate as necessary
Ability to work independently as well as part of a team, including providing technical leadership to less experienced colleagues
Excellent interpersonal and customer relationship skills
Ability to work in a deadline-driven environment, while handling multiple complex projects/tasks simultaneously with a focus on details
Ability to work well under pressure while dealing with unexpected issues in a professional manner
Ability to work after hours and weekends as needed
Ability to travel as needed

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
Unparalleled partner-involvement
Deep industry knowledge and participation
Geographic coverage across the U.S.
Cohesive global network
Focused capabilities across disciplines
BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.
Some examples of our Total Rewards offerings include:
Competitive pay and eligibility for an annual performance bonus.
A 401k plan plus an employer match
Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
Paid Parental Leave
Adoption Assistance
Firm paid life insurance
Wellness programs
Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance
Above offerings may be subject to eligibility requirements.
Click here to find out more!","$99,147 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,2007,$10+ billion (USD)
"Equinix
4.1",4.1,"Englewood, CO",Data Center Critical Facilities Engineer,"Data Center Critical Facilities Engineer
Equinix is the world’s digital infrastructure company, operating 240+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, complex infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.
We are a fast-growing global company with 20 years of continuous growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of 10,000+ companies, including 2,100 networks and 3,000+ cloud and IT service providers in 32 countries spanning six continents.
Joining our operations team means that you will be at the forefront of all we do, maintaining critical facilities infrastructure as part of a close-knit team delivering best-in-class service to our data center customers. We embrace diversity in thought and contribution and are committed to providing an equitable work environment. that is foundational to our core values as a company and is vital to our success.
Job Summary
Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, public safety centers. Simply put - We cannot go dark. In this crucial role, you will complete repairs, corrective maintenance, and routine installations of Critical Facility infrastructure.

Responsibilities
Perform site inspections and supervise the building and Data Center alarm
Perform preventative maintenance of on-site infrastructure (e.g. maintenance of primary infrastructures), and lead vendors in maintenance activitie
Undertake repairs and corrective maintenance of critical infrastructure i.e. UPS, generator, BMS, chillers, life safety systems
Complete site logs and data gathering issuing for basic permits, such as MOPs and scripts
Respond to all on-site incidents and act as the need arises
Completes routine work requests and circuit installations
Provide assistance during critical maintenance activities
Collaborate within the department and provide recommendations to peers for general maintenance activities
Carry out basic infrastructure projects

Qualifications
4 or more years’ experience with facilities electrical, HVAC and/or mechanical
Experience working in a Data Center or other critical facility preferred
Strong system level mechanical or electrical proficiency
You are capable of lifting up to 50 lbs. and are agile in manual dexterity (climb, stoop, et.) with or without an accommodation
Able to work any assigned shift, off-schedule, fill in for workmate, respond to emergencies, etc.
The targeted pay range for this position in the following location is:
Colorado, Nevada, Rhode Island: $57,000 to $89,000
Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training.
This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process.
The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position.
More details about our company benefits can be found at the following link:
https://equinixbenefits.us.newsweaver.com/icfiles/201/1002910/1057118/1171391/921bc962bf0e0352cb2d6c93/equinix%202023%20oe%20ebook_rev122022%20-%20final.pdf
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.
Equinix is an Equal Employment Opportunity and, in the U.S., an Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy / childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political / organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law.
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $69,000 to $107,000 • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $63,000 to $98,000 • Colorado, Nevada, Rhode Island: $57,000 to $89,000 Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $69,000 to $107,000 • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $63,000 to $98,000 • Colorado, Nevada, Rhode Island: $57,000 to $89,000 Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook",#N/A,10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1998,$1 to $5 billion (USD)
"MFS Investment Management
4.0",4.0,"Boston, MA",IDMO Lead Data Engineer,"At MFS, you will find a culture that supports you in doing what you do best. Our employees work together to reach better outcomes, favoring the strongest idea over the strongest individual. We put people first and demonstrate care and compassion for our community and each other. Because what we do matters – to us as valued professionals and to the millions of people and institutions who rely on us to help them build more secure and prosperous futures.

THE ROLE
In conjunction with the Investment Data Management Office, the Lead Data Engineer contributes to a long-term strategic initiative to unify and harmonize our investment data. This initiative enables enhanced investment decision making, risk management and client reporting for our multi-asset platform by delivering consistent, timely, accurate and user-friendly data to investors, risk teams and clients.
Are you a hands-on and detailed-oriented individual working on the cutting edge of financial instruments, investment data, and analytics? Are you interested in investment data strategies across a wide variety of traditional and alternative asset classes? Are you a thinker who enjoys devising innovative and flexible business solutions to meet emerging business needs?
The MFS Investment Data Management Office is actively searching for a Lead Data Engineer to implement data engineering and analytics solutions . Primary responsibilities include full implementation and maintenance of data ingestion, data maintenance, data validation and data delivery of investment data. We are looking for someone who thrives in an agile, collaborative, team-based environment, working closely with technology peers across MFS, investment professionals and key vendor partners. This position offers the opportunity to shape the future of investment data at MFS.
WHAT YOU WILL DO
Design, develop, and implement data pipelines to maintain unified data platform for the Investment Data Management Office(IDMO)
Lead and participate in all development activities, develop and implement solutions to meet business requirements that align with program strategic objectives
Responsible for new and on-going development of data pipelines sourcing from internal and external sources
Drive continuous improvement of data quality, resiliency, control, efficiency, and monitoring
Troubleshooting complex system interactions to find the root cause to problems
Partner with platform lead to design, develop, implement and deploy new software components to investment data platform
Partner with data architect to evaluate and finalize the unified data model
Partner with integration architect to upgrade and integrate data ingestion and data delivery tools with the unified data platform
Upgrade and integrate transformation tool, data validation tool and orchestration tools with the unified data platform to implement data engineering, analytical engineering and data maintenance capabilities.
Provide support during unexpected outages

WHAT WE ARE LOOKING FOR
Bachelor’s degree in Computer Science or related disciplines.
Minimum of 5 years of experience in design, development and building data oriented complex applications.
Deep understanding of Agile SDLC, DevOps and Cloud technologies required, in addition to exposure to multiple, diverse technologies, platforms, and processing environments.
Experience in data integration, data warehouse, data modeling and data analytics architecture and design principles. Knowledge of and experience with Snowflake and other cloud native databases is highly preferred.
Knowledge about various architectures, patterns such as unified data management architecture (UDM), data mesh architecture, event-driven architecture, real-time data flows, non-relational repositories, data virtualization, tc.
Experience with building solutions in the financial services domain with an understanding of financial instruments, transactions, and positions, is desired.
Good interpersonal and communication skills with the ability to lead cross-team collaboration and partnerships across a variety of internal and external constituencies.
#MBLI
#LI-HYBRID
At MFS, we are dedicated to building a diverse, inclusive and authentic workplace. If you are excited about this role but your past experience doesn't align perfectly, we encourage you to apply - you might be just the right candidate for this role or others.
What we offer:
Generous time-off provided: including ""Responsible time off"" for many roles, paid company holidays when the US Stock Exchange is closed, plus paid volunteer time
Family Focus: Up to 20 weeks of paid leave for new parents, back-up care program, dependent care flexible spending account, adoption assistance, generous caregiver leave
Health and Welfare: Competitive medical, vision and dental plans, plus tax-free health savings accounts with company contributions
Wellness Programs: Robust wellness webinars, employee assistance program, gym reimbursement through our medical plans, fitness center discounts and more
Life & Disability Benefits: Company-paid basic life insurance and short-term disability
Financial Benefits: 401(k) savings plan, Defined Contribution plan- 15% of base salary invested into the Plan, competitive total compensation programs
MFS is a hybrid work environment (remote/onsite) unless otherwise stated in the job posting.
If any applicant is unable to complete an application or respond to a job opening because of a disability, please contact MFS at 617-954-5000 or email
talent_acquisition@mfs.com
for assistance.
MFS is an Affirmative Action and Equal Opportunity Employer and it is our policy to not discriminate against any employee or applicant for employment because of race, color, religion, sex, national origin, age, marital status, sexual orientation, gender identity, genetic information, disability, veteran status, or any other status protected by federal, state or local laws. Employees and applicants of MFS will not be subject to harassment on the basis of their status. Additionally, retaliation, including intimidation, threats, or coercion, because an employee or applicant has objected to discrimination, engaged or may engage in filing a complaint, assisted in a review, investigation, or hearing or have otherwise sought to obtain their legal rights under any Federal, State, or local EEO law is prohibited. Please see the
Know Your Rights: Workplace Discrimination is Illegal
document and
Pay Transparency Nondiscrimination Provision
, linked for your reference.","$116,521 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Financial Services,Investment & Asset Management,1982,$100 to $500 million (USD)
"NECI
4.6",4.6,"Mansfield, MA","Senior Digital, Data & Analytics Engineer","About NECI
NECI, an Emerson Impact Partner, is the leading Digital Automation solutions provider transforming manufacturing, lab operations, process development and process control within a range of process industries in New England. NECI relentlessly seeks to drive the outcomes that ‘change the game’ for our clients and is seeking team members to join in our mission.
SUMMARY - The Role
The Senior Digital, Data & Analytics Engineer will be part of the Digital, Data & Analytics group whose primary mission is to empower our clients with a gateway for continuous process improvement by transforming raw data into actionable data insights. We strive to achieve measurable business results for our clients’ overall data strategy by providing solutions that are: platform agnostic, highly accessible, easily leveraged via connected systems and scalable across corporate enterprise.
As a Senior Digital, Data & Analytics Engineer you will be customer facing individual capable of executing projects in the Digital, Data & Analytics space in a technical lead capacity. You will coordinate with customer site contacts and implement Digital, Data & Analytics solutions in a challenging real-time process environment.
What You’ll Do:
Design, consult and execute NECI – Digital products/platforms such as Aspen Inmation, Cloud (AWS, Azure) & IIoT Data Platforms, Business Intelligence Tools (Power BI, Spotfire, Tableau etc.), Data Historian Platforms (AVEVA PI, Aspentech IP21, etc) and Advanced Analytics Platforms
Provide technical leadership, requirements gathering, participate in workshops and feed, design and implement configurations for manufacturing intelligence tools, process control system historians, process analytics tools, enterprise data platforms and interfaces between these systems
Participate and/or lead in the roll-up of deliverables and project estimations with Project Managers, to ensure the appropriate expectations are set while executing projects
Maintain key relationships with clients and principals to support business unit.
Responsible for providing uncompromising quality to all work processes in designated area of responsibility. Has the authority to stop those work processes at any time it is believed that quality is being compromised
Collaborate between cross-functional teams in a dynamic, fast-moving, and outcome-based environment and execute a multi-discipline scope from concept through delivery.
Proactively identify and manage risks, resolve issues, and escalate where appropriate to drive successful customer and business outcomes
Provide support as needed to sales, solution architects, business development, operations, and project management functions in the sale of NECI’s products and services
Mentor, develop and train project staff during development and implementation of project deliverables as well as through the peer review process
Qualifications:
Bachelor of Science in Computer Engineering, Computer Science, or Equivalent Technical background
5+ years’ experience delivering data & analytics solutions with a combination of below
Process Control, Process Data Historians, or Industrial Automation
Industrial Acquisition Protocols (Modbus, OPC-UA, etc)
Knowledge with Messaging protocols (MQTT, AMQP, etc) or IIoT/Edge platforms
Experience with Data Lake, Big Data/MongoDB, and AWS Data Platforms
Business Intelligence tools (Power BI, Spotfire, Tableau etc.)
Knowledge of Microservices and Docker containers
Experience in programming with Python, C# or JavaScript
Experience with life sciences industries is an added advantage
Experience as the client-facing of successful services operations for a fast-growing data analytics practice or related technology
Self-Starter, must be comfortable in an environment where limited support or information may be available, along with the ability to navigate seamlessly between setting a strategy and executing/implementing
Excellent written and oral communication skills
Excellent interpersonal skills within and across work functions as well as with superiors
Ability to work independently. Organized and able to multi-task
Ability to get along well with others, and support cross-functional teams
Preferred location for this role will be in and around the New England region.
Travel Requirements: Up to 25% local New England travel, depending on the needs of the organization","$123,192 /yr (est.)",201 to 500 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotechnology,1966,$100 to $500 million (USD)
Set of X,#N/A,"Annapolis Junction, MD",Software Engineer - Data Analytics,"WE ARE HIRING OWNERS:
Set of X is led by industry veterans who see government contracting as a good community with plenty of opportunity to go around. With a shared desire to give back, grow the community, and do great work, the Set of X team is building an elite group of engineers with a strong sense of shared responsibility and ownership.
Because who you work with matters.:
____________________________________________________________________________________________
You will be a member of the Mission Intelligence (MI) team supporting a variety of data engineering, analysis, and automation efforts. The MI team maintains a business intelligence platform supporting data-driven decisions in the enterprise. Your primary responsibility will be to ensure the availability of this mission-essential platform. You will also contribute to the MI team as a software engineer and analytic developer where you will design, develop, and integrate solutions involving the analysis of large data sets to establish mission cognizance and deliver mission-centric insights.

Responsibilities::
Maintain and advance a mission-essential business intelligence platform.
Elicit requirements from stakeholders, gather and analyze available data, and develop solutions for delivering key metrics.
Develop analytics to combine, normalize, and enrich large data sets.
Design and implement ETL workflows to convert and normalize data.
Augment the platform with new tools or technologies.
Provide guidance to more junior software engineers and data scientists.Requirements: :
Production-grade software development experience in Java and Python.
Experience deploying and maintaining Elastic Stack components (Elasticsearch, Kibana).
Familiarity with customer authentication and authorization platforms and standards.
Experience with one or more ETL or data engineering platforms (e.g. Apache NiFi, AirFlow).
Experience with service containerization and deployment with Docker/Kubernetes.
Familiarity with Git for software version control.
Experience with Atlassian Tools (Jira, Confluence).

Desired:
Knowledge of map-reduce analytic environments (e.g. Hadoop).
Experience with cloud-based deployment environments (e.g. AWS).
Experience prototyping web applications (JavaScript).
Knowledge of end-to-end SIGINT collection and analysis systems.
Experience with production CNO capabilities and operations.

Experience/Education:
Level 3: 12 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S.
Level 2: :8 yrs., B.S. in a technical discipline or 4 additional yrs. in place of B.S.
All qualified applicants receive genuine consideration for employment without regard to race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, state or local protected class.
Set of X Technology Partners is committed to creating a diverse and inclusive workforce and is proud to be an equal opportunity employer. We hire great people from a wide variety of backgrounds, not just because it is the right thing to do, but because it makes our company stronger. The collective sum of the individual differences, experiences, self-expression, skills, knowledge, talent and innovation that our employees express in their work drives our culture and our reputation.","$105,977 /yr (est.)",1 to 50 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2020,Unknown / Non-Applicable
SBASE TECHNOLOGIES,#N/A,"Minneapolis, MN",Sr. Data Engineer,"Role – Sr. Data Engineer - Apache Spark
Location – Minneapolis, MN (Day 1 onsite)
Mode of employment – Full-Time
Top Skills:
Good Apache Spark Scala skills
Good Big Data Skills
Good Unix Skills
Job Description:
Strong in Spark Scala development (Minimum 5 years of experience).
Especially Persons should have good experience on building ETL pipeline using Scala.
Strong in SQL Concepts and Development
Must have worked on any ETL tool like Data stage, Spark /Scala etc... Preferred Data Stage.
Unix / Python Shell Scripting (Minimum 3 to 4 years)
Strong understanding of Hadoop eco system
Very well versed with Agile Methodology - Scrum boards.
Capable of handling scrum ceremonies in absence of scrum master.
Other tools – Jenkin, Autosys, GitHub, etc..
Any Cloud experience is plus. Preferred Azure
Job Type: Full-time
Pay: Up to $115,000.00 per year
Benefits:
Health insurance
Paid time off
Schedule:
Monday to Friday
Ability to commute/relocate:
Minneapolis, MN 55401: Reliably commute or planning to relocate before starting work (Required)
Experience:
Apache: 5 years (Preferred)
Big data: 8 years (Preferred)
Data warehouse: 5 years (Preferred)
Work Location: In person","$115,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Nexstar Broadcasting
2.8",2.8,"Irving, TX",Senior Data Engineer,"We are seeking a highly skilled Senior Data Engineer to join our team. The Senior Data Engineer will be responsible for designing, building, and maintaining the data architecture of our organization. The successful candidate will have a deep understanding of data structures, data modeling, data processing, and data storage technologies. They will work closely with the data analytics teams to ensure that data is accurate, reliable, and accessible to support business decision making.
Responsibilities
Collaborate with data engineers, analysts, and stakeholders to identify opportunities for data-driven insights and decision-making
Construct data pipelines between our partners and our data warehouse, leveraging a thorough knowledge of cloud platform tools to find accurate, efficient and maintainable solutions
Transform data within our data warehouse to prepare it for use by our stakeholders
Ensure data quality, accuracy, and completeness by implementing data validation, monitoring, and error handling methods
Find ways to reduce data processing and storage costs
Be a voice on the data team for improving process and capabilities by presenting alternative solutions

Qualifications
Strong problem-solving skills and attention to detail
5+ years working with Sql Server, Azure and related Microsoft data products
Familiarity with other cloud data products, including BigQuery, Redshift, Snowflake
Advanced SQL knowledge and abilities
Experience building data pipelines
Writing cloud functions in Python, R and Apache Spark
Extracting data from APIs
Transforming data between different formats.
Excellent communication skills

Preferred Experience
Familiarity with the digital media publishing space.
Experience with business intelligence and digital marketing tools:
Analytics: Adobe Analytics
Revenue: Google Ad Manager, Freewheel
Visualization: Power BI","$109,281 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Broadcast Media,1996,$500 million to $1 billion (USD)
"Sterling St James LLC
4.0",4.0,"Beaverton, OR",AWS Data Engineer,"We been engaged to find an AWS Data Engineer you will be part of a fast-paced team designing, developing, testing, integrating and supporting technically innovative solutions for our Fortune 500 customers.

AWS and Snowflake Data Engineer overview :
Design and build reusable components, frameworks and libraries at scale to support analytics products.
Design and implement product features in collaboration with business and Technology stakeholders.
Identify and solve issues concerning data management to improve data quality.
Clean, prepare and optimize data for ingestion and consumption.
Collaborate on the implementation of new data management projects and re-structure of the current data architecture.
Implement automated workflows and routines using workflow scheduling tools.
Build continuous integration, test-driven development and production deployment frameworks.
Analyze and profile data for designing scalable solutions.
Troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues.

AWS and Snowflake Data Engineer requirements :
Hands on experience in AWS - EMR [Hive, Pyspark], S3, Athena or any other equivalent cloud
Familiarity with Spark Structured Streaming
Minimum experience working experience with Hadoop
Hands-on experience with SQL, ETL, data transformation and analytics functions
Hands-on Python experience including Batch scripting, data manipulation, distributable packages.
Experience working with batch orchestration tools such as Apache Airflow or equivalent, preferable Airflow.
Working with code versioning tools such as GitHub or BitBucket; expert level understanding of repo design and best practices
Familiarity with deployment automation tools such as Jenkins
Hands-on experience designing and building ETL pipelines; expert with data ingest, change data capture, data quality; hand on experience with API development.
Designing and developing relational database objects; knowledgeable on logical and physical data modeling concepts; some experience with Snowflake
Familiarity with Tableau or Cognos
Familiarity with Agile; working experience preferred

AWS and Snowflake Data Engineer certifications :
AWS
ETL
Python

Industry: Data Engineer, AWS, Beaverton

Job Code: j-2047","$101,619 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Kingfisher Systems, Inc.
4.7",4.7,"Washington, DC",Data Engineer,"Kingfisher Systems, Inc. specializes in providing a full range of Information Technology, Cybersecurity, Intelligence, and support services to the U.S. Government. Kingfisher Systems’ core competency is technology-enabled services, with a specific focus on national security. Since 2005, Kingfisher has established itself as a recognized and trusted mission partner whose mission is safeguarding sensitive information, operations, and programs for our Federal customers and warfighters.
Kingfisher is seeking an experienced Data Engineer
Responsibilities:
Interacts with customers, Program Managers and other development teams to gather, analyze and define requirements to determine the most effective software and web technologies to satisfy the client needs
Develops, maintains, supports and enhances complex and diverse software systems (e.g., processing-intensive analytics, novel algorithm development, manipulation of extremely large data sets, real-time systems, and business management information systems) based upon documented requirements
Reviews and tests software components for adherence to the design requirements and documents test results
Designs, creates, tests, and maintains software and web-based applications and content solutions to satisfy customer requirements
Follows a formal design process using formal specifications, data flow diagrams, and adheres to laws, standards, and established guidelines for development and delivery of software and web applications
Designs and develops visually-pleasing, content rich, user-friendly interfaces with intuitive navigation
Develops and maintains software and web development technical documentation to assist with software and web application maintenance and upgrades
Provides software process management and configuration management throughout the software / web development life cycle.
Recommends new technologies and processes for complex software projects.
Ensures quality control of all developed and modified software.
Analyzes and troubleshoots extremely complex software problems and provides solutions using the latest technologies.
Integrates new software and web products with existing software and web applications in order to improve the functionality or design of the system.
Required Experience:
Experience in troubleshooting complex data analytic systems.
Should have thorough experience working with Python and associated libraries
Experience in creating and using Docker Images and Kubernetes
Experience in Jira/Confluence using Agile/SCRUM methodologies and Kanban
Should have thorough understanding of the server/client model. (i.e., RESTful APIs, microservices, etc.)
Should have a working knowledge of data loading and ingestion.
Should have experience in extract, transform, and load (ETL) of legacy data source to current standards (i.e., be able to migrate from relational data base to NoSQL database)
Data standardization and normalization of legacy data source
Should have a working knowledge of Linux (i.e., should be able to edit/debug programs on Linux).
Familiarity with extracting implementation measurements and interaction requirements from designs
Technical understanding of big data concepts, cloud technologies such as AWS and Oracle.
Experience creating and troubleshooting APIs for migrating data from a relational data base to a NoSQL database (PostgreSQL)
Strong trouble shooting and problem-solving skills.
Must be able to work in a collaborative work environment.
Enthusiastic about teamwork, comprehensive automated tests, and collective code ownership.
Clearance:
Active TS/SCI clearance with polygraph
Required Education:
Bachelors Degree with at least 12 years of relevant experience (or Masters Degree with at least 10 years of relevant experience).
Required Certification:
CompTIA Security+ (SEC+) CE
Work Location:
DMV (Washington DC Metropolitan area) may include telework availability: Hybrid, Remote and onsite
Kingfisher Systems, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender identity, national origin, age, protected veteran status, among other things, or status as a qualified individual with a disability.","$114,725 /yr (est.)",51 to 200 Employees,Company - Private,Government & Public Administration,National Agencies,2005,Unknown / Non-Applicable
"WIT Inc
4.6",4.6,"Troy, MI",QLIK Data Integration Engineer,"QLIK Data Integration Engineer
WIT is an analytics and automation consulting firm in Troy, Michigan, since 1996. WIT has partnerships with key software companies, including Microsoft, Qlik, Alteryx, UiPath, and Snowflake, among others. For more information, go to www.witinc.com
WIT has an immediate opening for a QLIK Data Integration Administrator with strong acumen in working with and administration of the QDI platform. We are seeking a blend of technical, systems administration, and advanced customer interaction skills, with a solid track record of delighting customers with the delivery of successful projects on the QLIK DATA INTEGRATION PLATFORM. Candidates should have hands-on development and administration experience in QDI platform, with excellent data administration skills.
Responsibilities
Responsible for administration of the QDI Platform.
Responsible for installing/configuring/maintaining the Attunity/QDI software and developing data replication jobs.
Responsible for replicating data to cloud platforms (Azure, AWS, GCP, Snowflake, Databricks)
Assemble design and development estimates for both waterfall and agile development projects.
Establish trust advisor status for data and analytics customers.
Lead by example through a culture of accountability and process
Qualifications
Minimum of 5 years of customer-facing project delivery experience.
Minimum of 5 years of Qilk Data Integration projects.
Experience as an QDI platform Systems Administrator.
Proven experience in replicating data from different cloud platforms.
5 Years of customer-facing project delivery experience required.
Active knowledge/experience with the QDI product, cloud platforms (Azure, AWS, GCP, Snowflake, Databricks)
Excellent facilitation, verbal, and written communication skills
Not willing to sponsor
Local candidates preferred, either remote/hybrid local
WIT offers attractive compensation, excellent benefits, a friendly work environment and great future potential for the right candidate.
Job Type: Full-time
Work location: Remote or Hybrid (Troy MI)
Benefits:
401(k) matching
Dental insurance
Health insurance
Health savings account
Life insurance
Paid time off
Professional development assistance
Vision insurance
Job Type: Full-time
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Professional development assistance
Vision insurance
Experience level:
5 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Troy, MI 48098: Reliably commute or planning to relocate before starting work (Required)
Work Location: Hybrid remote in Troy, MI 48098","$98,606 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,1996,$5 to $25 million (USD)
"Hawaiian Airlines, Inc.
4.0",4.0,"Tempe, AZ","Associate Software Developer Engineer, IT - Data and Common Services (Tempe)","At Hawaiian Airlines, we are all about welcoming our guests with Hawaiian hospitality and aloha, and taking care of our people, our home, and the communities we serve. Join our ‘ohana and be a part of an exciting team of professionals dedicated to serving our kama‘āina and introducing our islands to the world!
Position Summary
The IT - Data & Common Services, Analytics Platform & Architecture group is responsible for providing high-availability of access & performance to our organization’s analytical data, and modeling & enriching it for effortless consumption by our edge systems and end users. We partner with stakeholders to continuously assess data processes and tools, evaluate their usage and impact, and provide data governance and quality. We strive to transform Hawaiian Airlines to a data-focused, self-service business intelligence model with governed data management, built atop a modern analytics platform comprised of centralized cloud-based data and a powerful ecosystem of cloud-based tools.
Software Developer Engineers write and configure code. They generally come from Computer Science or Information Systems backgrounds.
The Software Developer Engineer family contains a wide array of individuals and skills so that the breadth of coding languages is encompassed (e.g. C, C#, C++, JAVA, Ruby, Python, etc.). This group creates the software and technical solutions that run the company. They are responsible to understand business requirements, comprehend the technical design for the solution, conceive and write detailed software implementations/code, as well as ensure their solutions adhere to the security, logging, error handling, and performance specifications.
Key Responsibilities
Write, configure and develop software and code-driven solutions for low-to-medium complexity business problems according to user specifications
Decompose business requirements and translate them into detailed design specifications and code
Analyze and resolve operational and production problems of low-to-medium complexity, including researching and recommending alternative actions for problem resolution and taking timely action
Develop understanding of business processes being supported by assigned system(s)
Participate in system and acceptance testing
Test and implement system components using techniques that preserve system integrity
Provide timely and accurate progress information to project status reports
Support the organization’s project management policy, practice and methodology
Maintain focus on internal and external customer requirements
Other duties as assigned

Minimum Requirements
Bachelor’s Degree (in lieu of degree – 4 years of experience working in an IT environment)
Ability to write/configure/develop software code
Ability to independently research, practice, and learn programming languages, tips, techniques required for software construction, testing, deployment
Basic knowledge of software development, practice, concepts, and technology obtained through formal training and/or work experience
Basic knowledge of at least one required programming language
Basic knowledge of the technical and business environments
Capable of learning core business processes
Ability to adhere to the corporate programming standards
Ability to adhere to the Enterprise Architecture Standards
Demonstrated programming aptitude and ability for logical and abstract thinking
Ability to analyze and resolve problems of simple to medium complexity that carry small risk to the organization
Ability to receive instruction from more senior members of the team
Ability to complete tasks under direction
Ability to work effectively in a strong customer service/team-oriented environment

**Hawaiian Airlines is regulated by the Department of Transportation (DOT - regulation, 49 CFR part 40) and all applicants are advised that post-offer and/or pre-employment drug testing will be conducted to determine the presence of Marijuana, Cocaine, Opioids, PCP (Phencyclidine), and Amphetamine prior to any offer of employment or transfer into a safety-sensitive position. Failure to submit to testing or positive indications of drug use will render the applicant ineligible for employment with Hawaiian Airlines and any employment offer will be withdrawn.
*** In addition to routine employment eligibility verification, U.S.-based airlines must gather information to validate country of citizenship and country of birth. Upon hire, you must provide documentation proving your current country of citizenship and birthplace.
Preferred Qualifications
B.S./B.A., Computer Science, Engineering, Information Systems
Excellent partnering, communication, and negotiation skills so as to interact effectively with business customers and technology development and support groups
Ability, within a specific technology area and under direction, complete root-cause analysis, design solutions, write code, perform testing, provide documentation, and implement small development projects or components of large projects
Industry experience
Understanding of the following:
different data categories (i.e. master, reference data, operational data, analytical, raw, domain, enterprise) and how they relate to each other
components of a modern data engineering comprised of centralized cloud-based data and cloud-based tools, data processing, data visualization tools, business intelligence and data governance
Experience with: Big Data, Snowflake, designing and building data pipelines in airflow, DAGs, DBT, AWS, Python, SQL, database design ·
Using SDLC protocols requiring specific branching, merging and code review policies ·
Experience working with CI/CD

About Hawaiian Airlines
Now in its 94th year of continuous service, Hawaiian is Hawaiʻi's biggest and longest-serving airline. Hawaiian offers approximately 150 daily flights within the Hawaiian Islands, and nonstop flights between Hawaiʻi and 15 U.S. gateway cities – more than any other airline – as well as service connecting Honolulu and American Samoa, Australia, Cook Islands, Japan, New Zealand, South Korea and Tahiti.

Consumer surveys by Condé Nast Traveler and TripAdvisor have placed Hawaiian among the top of all domestic airlines serving Hawaiʻi. The carrier was named Hawaiʻi's best employer by Forbes in 2022 and has topped Travel + Leisure’s World’s Best list as the No. 1 U.S. airline for the past two years. Hawaiian has also led all U.S. carriers in on-time performance for 18 consecutive years (2004-2021) as reported by the U.S. Department of Transportation.
The airline is committed to connecting people with aloha by offering complimentary meals for all guests on transpacific routes and the convenience of no change fees on Main Cabin and Premium Cabin seats. HawaiianMiles members also enjoy flexibility with miles that never expire. As Hawai‘i’s hometown airline, Hawaiian encourages guests to Travel Pono and experience the islands safely and respectfully.
Hawaiian Airlines, Inc. is a subsidiary of Hawaiian Holdings, Inc. (NASDAQ: HA). Additional information is available at HawaiianAirlines.com. Follow Hawaiian’s Twitter updates (@HawaiianAir), become a fan on Facebook (Hawaiian Airlines), and follow us on Instagram (hawaiianairlines). For career postings and updates, follow Hawaiian’s LinkedIn page.
For media inquiries, please visit Hawaiian Airlines’ online newsroom.
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$99,361 /yr (est.)",5001 to 10000 Employees,Company - Public,Transportation & Logistics,"Airlines, Airports & Air Transportation",1929,$1 to $5 billion (USD)
"Cognizant Technology Solutions
3.8",3.8,"Charlotte, NC",Jr. AWS Data Engineer (Onsite),"We are Cognizant Artificial Intelligence
Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. However, clients need new business models built from analyzing customers and business operations at every angle to really understand them.
With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks.

*You must be legally authorized to work in United States/Canada without the need of employer sponsorship, now or at any time in the future *

Job Title: Jr. AWS Data Engineer (Onsite)
Job summary
Looking for an experienced AWS Cloud Data Engineer. Experience building end-to-end systems as a Data Engineer with AWS Cloud Platform. Should have 4-5 years of experience working as an AWS Cloud Data Engineer. Strong AWS Dynamo DB, Lambda, Cloud watch skills Fluency in Python, PySpark skills. Strong DB skills in NoSQL, SQL. Experience working in ETL programming. Experience in JIRA, Service now. Ability to translate business needs to technical requirements Strong understanding. Experience 7 to10 yrs. Required Technical Skills- AWS Big Data Domain Skills- Nice to have skills Technical Skills- Python, PySpark, AWS Cloud, AWS Services Domain Skills-Technology Data Management.

Roles & Responsibilities:
Experience building end-to-end systems as a Data Engineer with AWS Cloud Platform Should have 4-5 years of experience working as an AWS Cloud Data Engineer. Strong AWS Dynamo DB Lambda, Cloud watch skills. Fluency in Python, PySpark skills Strong DB skills in NoSQL, SQL Experience working in ETL programming. Experience in JIRA, Service now. Ability to translate business needs to technical requirements. Strong understanding of software testing, benchmarking, and continuous integration? Exposure to machine learning methodology and best practices Project Planning and Set-up-Understand the project scope, identify activities/ tasks, task level estimates, schedule, dependencies, risks and provide inputs to Module Lead for review Provide inputs to testing strategy, configuration, deployment, hardware/software requirement etc. Review plan and provide feedback on gaps, timeline and execution feasibility etc. as required in the project Participate in KT sessions conducted by customer/ other business teams and provide feedback on requirements Requirement Understanding and Analysis-Analyze functional/nonfunctional requirements and seek clarifications for better understanding of requirements Based on understanding of system - upstream & downstream, provide feedback and inputs on gaps in requirements and technical feasibility of requirements Design-Prepare the LLD/ detailed design documents based on HLD and briefing from Module Lead Seek inputs from the developers on specific modules as applicable Consolidate all modules and provide to Module Lead/ Architects/ Designers for review Suggest changes in design on technical grounds Develop components inventory for the code to be developed tying it to the non-functional requirements Perform sampling of data to understand the character/ quality of the data (project dependent- in the absence of data analyst or designer.

Salary and Other Compensation:
The annual salary for this position is between $110.000 - $120.000 depending on experience and other qualifications of the successful candidate.
This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.

Benefits: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:
Medical/Dental/Vision/Life Insurance
Paid holidays plus Paid Time Off
401(k) plan and contributions
Long-term/Short-term Disability
Paid Parental Leave
Employee Stock Purchase Plan
Disclaimer: The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.
#LI-AR1 #Ind123
Employee Status : Full Time Employee
Shift : Day Job
Travel : No
Job Posting : Aug 31 2023
About Cognizant
Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 185 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.
Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.
Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.
If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information.","$75,388 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1994,$10+ billion (USD)
"BDO
3.8",3.8,"Austin, TX",Alliance Azure Data Engineer,"Job Summary:
The BDO Alliance Azure Data Engineer is responsible for the technology and data environment used to support the BDO Alliance Team and all 400+ Alliance Firms. Being at the leading edge of up-to-date Azure infrastructure knowledge, the Azure Data Engineer is a key member of the core BDO Alliance IT Digital Assets Team. The individual in the role will be working with our customers and other stakeholders to ensure exceptional oversight of projects and operations. A successful candidate will thrive in a dynamic environment at the direction of the Alliance Director in-charge of the BDO Alliance Digital Assets team.
Job Duties:
Leadership and Task Responsibilities
Leads the design, development, and implementation of the Alliance program’s new Data Lake which supports over 25,000 users
Works collectively with the other members of the Alliance team and our customer and stakeholders to identify and implement value added digital solutions for the Alliance Program
Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS
Listens to client needs to align solution with business requirements and delivery schedule
Creates written functional and technical designs
Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers
Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions
Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles
Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency)
Assists with implementation of data governance programs and best practices
Performs the cleaning and transforming of data from source systems into analytics models
Implements models to support data visualizations and integrations
Assists with implementing DevOps and DataOps on all projects
Writes custom integration logic in applicable programming languages
Provides clear, frequent, and transparent reporting to management on a timely basis
Assists leadership with project planning and project management as needed
Participates in special projects to enhance the overall value of Alliance Program.
Attends Alliance team meetings as requested by Alliance Team Executive Director or Operations Managing Director
Attends and supports the annual Alliance Conference
Works closely with the Alliance Team, BDO IT, and BDO Digital
Supervisory Responsibilities:
N/A
Qualifications, Knowledge, Skills and Abilities:
Education:
High School Diploma or GED, required
Bachelor’s degree with a focus in Information Systems, Data Science or Computer Science, preferred
Experience:
Prior experience working on Azure infrastructure, required
Five (5) or more years of experience with Data Infrastructure and Application, required
Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema construction, required
Hands-on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, required
Experience with one (1) or more of the following computer languages: Python, R, C#, required
Experience with GIT or DevOps deployment technologies, preferred
Experience with Linux, preferred
License/Certifications:
N/A
Software:
Proficient in the use of Microsoft Office Suite, required
Language:
N/A
Other Knowledge, Skills & Abilities:
Strong verbal and written communication skills
Solid judgment and reasoning skills with an analytical mindset with a passion for problem-solving
Good customer service skills, a result-orientated mindset and excellent attention to detail
Ability to work in a deadline-driven environment and handle multiple projects/tasks
Strong collaboration skills and team spirit with a team-first attitude
Minimal travel required

BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.
Unparalleled partner-involvement
Deep industry knowledge and participation
Geographic coverage across the U.S.
Cohesive global network
Focused capabilities across disciplines
BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.

BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best & Brightest Companies to Work For and more.
Some examples of our Total Rewards offerings include:
Competitive pay and eligibility for an annual performance bonus.
A 401k plan plus an employer match
Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one
Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays
Paid Parental Leave
Adoption Assistance
Firm paid life insurance
Wellness programs
Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance
Above offerings may be subject to eligibility requirements.
Click here to find out more!","$111,040 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,2007,$10+ billion (USD)
"Sbg Technology Solutions Inc
4.0",4.0,"Washington, DC","Senior Health Data Migration Engineer - 359.b, SBG","SBG Technology Solutions, Inc. (SBG), a DSS, Inc. company, offers IT Governance, Systems Engineering, Enterprise Modernization, Artificial Intelligence, and Cyber Security innovation to federal and commercial clients nationwide. We are looking for a Senior Health Data Migration Engineer to join our team. We are seeking highly motivated individuals looking to join our rapidly growing company. The ideal candidate for these positions are experienced individuals who are hard-working, with the ability to excel in a fast-paced government contractor environment, and who have positive energetic attitudes. The position location is 100% remote.

OVERVIEW
Support the Department of Veterans Affairs (VA) Electronic Health Record Modernization Integration Office (EHRM-IO) as a Senior Health Data Migration Engineer.
An Expert Integration Engineer must create strategies and plans for integration of multiple IT systems/subsystems into an operational unit, ensuring full functional and performance capabilities are retained. Coordinate with development and user teams to assess risks, goals and needs and ensure that all are adequately addressed. The expert integration engineer must be experienced in introducing new hardware or software into a new or existing environment while minimizing disruption and mitigating risks. The expert integration engineer must be cost conscience as well addressing goals.

Responsibilities:
Assess the current EHRM data migration requirements; maintain and update the strategy to meet the requirements.R
Review error and trace logs.
Track messages by domain and reconcile table counts with Cerner.
Review secure data message transmission logs.
Track the number of records sent per message by domain.
Monitor Queue Depth by service/process/operation.
Track retry attempts and suspended messages.
Validate and update data integration reports in support of VX130 data domains.
Review, update, and maintain Cerner to CDW, VistA, Millennium or Cloud Database data mappings for potential data migrations.
Evaluate and integrate data from multiple sources, which requires data mapping from one data source to another minimizing any data loss.
Document VistA Extraction and monitoring process and update existing documentation quarterly. Interpret Cerner’s Data model to be used for the construction of API’s, queries, and reports that will be consumed by internal or external applications.
Review Domain adds to Ensemble Production. Validate edits made to Domain record type, schema version, status, and payload size via the GUI Interface and Rule Builder.
Validate Ensemble data flows built using VX130 ClassBuilder.
Validate the load of Cache/IRIS Objects, SQL Tables or other storage structures (Historical Pulls) in all regions/districts for classes in all environments with VistA or Data Syndication data.
15+ years of professional work experience, to include experience with InterSystems IRIS in a healthcare environment
Be able to create strategies and plans for integration of multiple IT systems/subsystems into an operational unit, ensuring full functional and performance capabilities are retained.
Able to coordinate with development and user teams to assess risks, goals and needs and ensure that all are adequately addressed.
Experienced in introducing new hardware or software into a new or existing environment while minimizing disruption and mitigating risks.
Able to be cost conscience as well addressing goals.
Bachelor's degree in Computer Science, Engineering, Math, or equivalent, or an additional 8 years of relevant experience may be substituted for degree requirements
Preferred qualifications:
Experience in the VA.
Experience implementing Electronic Health Records (E H R).
Experience with VA and DoD legacy health data, and private sector health data.
Experience with Extraction, Transformation, and Loading of data between systems.
Knowledge and experience handling VistA data","$108,169 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,1991,Unknown / Non-Applicable
"Tesla
3.6",3.6,"Austin, TX","Sr. Distributed Systems Engineer, Formation Data","What to Expect
Tesla is looking for a Sr. Distributed Systems Engineer to help build the backend microservices which interface formation software services to the broader cell manufacturing execution system (MES). Formation is a highly automated, high-volume manufacturing process and in this role, you will part of the data team responsible for managing the state of cells in the current process, gathering and processing data from thousands of fixtures, and interfacing to upstream and downstream processes via the global cell MES. In particular, you will work closely with the team to design and implement improvements to the set of microservices which manage formation in order to improve scalability, data integrity, and maintainability across multiple factories.
What You’ll Do
Develop the critical backend service that manages formation process state and serves as the interface between the manufacturing line and the global cell manufacturing execution system
Work closely with data/software teams to design the integration with the global cell manufacturing execution system with a focus on data consistency, data integrity, and scalability
Work closely with process development and production teams to translate manufacturing asks into software requirements to design a system that is flexible enough for process changes (trials and ongoing improvements) yet robust enough for high-volume manufacturing
Provide technical guidance to junior engineers to build scalable streaming data pipelines and data warehouses to process and store terabytes of manufacturing data across multiple factories
Contribute through demonstrated leadership best-practices in code quality, software testing, and continuous deployment processes
What You’ll Bring
B.S. degree or higher in CS/CE/EE or similar engineering discipline with 3+ years of experience with backend development, streaming and/or batch data pipelines, or the equivalent.
Demonstrated proficiency in Golang, Python, and SQL
Experience building distributed backend systems and APIs (e.g. REST, gRPC), streaming data (e.g. Kafka), and working with distributed task queues (e.g. Celery).
Experience deploying, monitoring, and maintaining production-grade distributed systems via CI/CD pipelines, Kubernetes, Docker, git, OpenTelemetry, etc.
Strong communication and organizational skills to translate manufacturing questions into data/software requirements
Experience with electrochemistry or high-volume manufacturing preferred","$112,510 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Pinnacle Technical Resources
3.7",3.7,"Fort Worth, TX",Data Governance Engineer,"Data Governance Engineer in Fort Worth Texas 76155

Minimum Qualifications:
Bachelor’s degree in computer science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training
3 years software solution development using agile, DevOps, operating in a product model that includes designing, developing, and implementing large-scale applications or data engineering solutions
3 years data analytics experience using SQL.
2 years of cloud development and data lake experience (prefer Microsoft Azure) including Azure EventHub, Azure Data Factory, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Power BI.
Combination of Development, Administration & Support experience in several of the following tools/platforms required:
Scripting: Python, Spark, Unix, SQL
Data Platforms: Teradata, Cassandra, MongoDB, Oracle, SQL Server, ADLS, Snowflake
Azure Data Explorer. Administration skills a plus
Azure Cloud Technologies: Azure Data Factory, Azure Databricks, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Azure Functions
CI/CD: GitHub, Jenkins, Azure DevOps, Terraform
BI Analytics Tool Stack - Cognos, Tableau, Power BI, Alteryx, Denodo, and Grafana
Data Warehousing: DataStage, Informatica
Data Governance and Privacy: Informatica Axon and EDC, BigID, Anomalo or Montecarlo or other Data Quality tools

Pay Range: $70-75

The specific compensation for this position will be determined by a number of factors, including the scope, complexity and location of the role as well as the cost of labor in the market; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. Our full-time consultants have access to benefits including medical, dental, vision as well as 401K contributions.

#LI-JM1

#LI-HYBRID???????",$72.50 /hr (est.),1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,$1 to $5 million (USD)
"Harvard Partners, LLP, Trusted Advisors to IT
2.0",2.0,Remote,Data Platform Engineer - Python,"As the Data Platform Engineer, you will use your significant experience in Microsoft Azure to design and set up projects that combine information from various sources to enable analysis and decision-making as well as play a key role in implementing scalable and secure solutions that meet specific business requirements. Candidates must be able to work EST and travel to the DC area monthly to bimonthly.
Skills:
Develop Python code to ingest and transform Excel data, perform calculations, and check data quality
Troubleshoot and resolve issues related to ingesting and preparing data for visualization
Develop, test, and maintain production-level data pipelines running on a laptop and in the cloud
Support code refactoring to improve pipeline efficiency
Maintain data analytics (NLP, text classification, time series & forecast models)
Plan and deliver data warehouse and storage.
Design and run data services for individual projects.
Design, develop, adapt, and maintain data warehouse architecture and relational databases to support data mining.
Customize storage and extraction, meta-data, and information repositories.
Create and use effective metrics and monitoring processes.
Monitor key performance indicators to determine where current data operations can be improved.
Create the building blocks for transforming enterprise data solutions
Design and build modern data pipelines, data streams, and data service APIs
Create/maintain report forms and formats, information dashboards, data generators, scanned reports, and other information portals and resources
Excellent written and verbal communication skills in English.
Qualifications:
Minimum 5 years of work experience.
BS in Computer Science, Applied Mathematics, Statistics, or Machine Learning (or +3 years)
3 years of experience as an Azure or AWS Data Engineer in technology consulting
3 years of experience performing data engineering, warehousing, publishing and visualization throughout the full data lifecycle
1 year of experience defining ETA architecture and ETL process design
2 years of experience performing end-to-end implementation of data warehousing analytics solutions built on MS or Azure platforms
2 years of experience with Python, Databricks, Azure Synapse, SQL Server, Azure Data Lake, and/or Azure Data Factory (ADF).


About Harvard Partners, LLP, Trusted Advisors to IT:

Harvard Partners is a management consulting firm focused on helping companies more effectively leverage their IT investment. We engage with the C-Suite and Technology Team to help them better understand their IT infrastructure and process in order to align the technology strategy and organization to reach the firm’s strategic business goals.Some of our practices include:• Program/Project Management and ""PMO as a Service""• IT Assessments• Business Continuity/Disaster Recovery• Optimized Infrastructure• Concierge Managed Services• Data Center Strategy, Transformation, and Migration• Cloud Management Programs• Security Assessments and Remediation• Staffing, technical & tacticalWorking with the client’s staff, vendors, and consultants, we deliver supportive and collaborative engagements where direct dialog, simplified reporting, productive meetings, and clear responsibility and accountability encourage active participation resulting in consensus-based business outcomes.",#N/A,Unknown,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"Quevera LLC
4.4",4.4,"Hanover, MD",TTO 5/6 Database Engineer III - Data Mgmt,"Job Description:

Quevera is seeking a Database Engineer III to join an exciting, collaborative and innovative team. A place where you are positioned for More than Just a Job. Where leadership partners with you, seek to cultivate and support career development, encouraging growth from within while striving to foster a diverse and inclusive environment that improves individual and organizational performance.

Duties and Responsibilities:
The Database Engineer will direct the development of complex systems using queries, tables, and database storage and retrieval using Cloud methodologies for the design, development, implementation, information storage and retrieval, data flow and analysis. Direct the overall database structure to fit into the overall architecture of the system. Create new workflows to take over existing processes as needed as well as provide break/fix requests or updates. Lead development of database structures, database parser software, and database loading software. Direct fulfillment of requirements from a project inception to conclusion.

Required Experience:
Python, Django or Flask, Database experience using MongoDB or MariaDB, ReST endpoint development, Micro service model

Desired Experience:
Swagger, AWS, C2S or other cloud experience, Docker, Visual Studio Code or similar IDEs, JSON and/or XML serialization, Jira, Confluence, Git version control, Experience working in Agile environment

Quevera is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age or any other characteristic protected by law.","$95,555 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2013,Unknown / Non-Applicable
"KPMG
3.8",3.8,"Austin, TX","Associate, Data Engineer","Known for being a great place to work and build a career, KPMG provides audit, tax and advisory services for organizations in today’s most important industries. Our growth is driven by delivering real results for our clients. It’s also enabled by our culture, which encourages individual development, embraces an inclusive environment, rewards innovative excellence and supports our communities. With qualities like those, it’s no wonder we’re consistently ranked among the best companies to work for by Fortune Magazine, Consulting Magazine, Working Mother Magazine, Diversity Inc. and others. If you’re as passionate about your future as we are, join our team.
KPMG is currently seeking an Associate, Data Engineering to join our Audit Technology organization.
Responsibilities:
Create artificial intelligence or generative artificial intelligence applications to support the execution of a high-quality audit and/or audit support activity
Define insights in large datasets by identifying trends and patterns and create data visualizations and dashboards to communicate insights to key stakeholders
Assist cross-functional teams with data-driven solutions
Support the execution of a high-quality audit and/or audit support through the diligent performance of assigned tasks and professional client and engagement team interactions
Qualifications:
Minimum one year of recent experience developing integrations using Jira, Python, REST API framework and SQL Alchemy
Bachelor’s degree from an accredited college or university
Strong technical aptitude and critical thinking and research skills
Ability to navigate various computer applications and technologies, including MS Office, ERP systems and data analysis tools
Excellent communication, time management and relationship-building skills
Able to employ sound professional judgment and professional skepticism; flexible and adaptable team player; leadership experience and resourceful in delivering high quality work
KPMG complies with all local/state regulations regarding displaying salary ranges. If required, the salary range(s) are displayed via the URL below. The range is specifically for those potential hires who will work in the location(s) listed. Any offered salary is determined based on relevant factors such as applicant's skills, performance, job responsibilities, prior relevant experience, certain degrees and certifications and market considerations. In addition, the firm is proud to offer a comprehensive, competitive benefits package, with options designed to help you make the best decisions for yourself, your family, and your lifestyle. Our Total Rewards package includes a variety of medical and dental plans, vision coverage, disability and life insurance, 401(k) plans, and a robust suite of personal well-being benefits to support your emotion and mental health. KPMG provides personal days off per fiscal year depending on job classification, standard work hours and years of service. Additionally, each year the firm publishes a calendar of holidays to be observed during the year. Available benefits are based on eligibility.
Colorado Salary Range: Low: $71300 - High: $122500
Albany Salary Range: Low: $67900 - High: $116700
Seattle Salary Range: Low: $74700 - High: $128400

Follow this link to obtain salary ranges by city:

https://www.kpmg.us/work-for-kpmg/pay-transparency.html/?id=6727-9
KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package. KPMG is an affirmative action-equal opportunity employer. KPMG complies with all applicable federal, state and local laws regarding recruitment and hiring. All qualified applicants are considered for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, citizenship status, disability, protected veteran status, or any other category protected by applicable federal, state or local laws. The attached link contains further information regarding the firm's compliance with federal, state and local recruitment and hiring laws. No phone calls or agencies please.
KPMG does not currently require partners or employees to be fully vaccinated or test negative for COVID-19 in order to go to KPMG offices, client sites or KPMG events, except when mandated by federal, state or local law. In some circumstances, clients also may require proof of vaccination or testing (e.g., to go to the client site).","$71,300 /yr (est.)",10000+ Employees,Company - Private,Management & Consulting,Business Consulting,1987,$1 to $5 billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Plano, TX",Lead Software Engineer - Data Platform Engineering,"JOB DESCRIPTION

We have an opportunity to impact your career and provide an adventure where you can push the limits of what's possible.
As a Lead Software Engineer at JPMorgan Chase within the GTI - IAM domain, you are an integral part of an agile team that works to enhance, build, and deliver trusted market-leading technology products in a secure, stable, and scalable way. As a core technical contributor, you are responsible for conducting critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job responsibilities:
Executes creative software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Develops secure high-quality production code, and reviews and debugs code written by others
Identifies opportunities to eliminate or automate remediation of recurring issues to improve overall operational stability of software applications and systems
Leads evaluation sessions with external vendors, startups, and internal teams to drive outcomes-oriented probing of architectural designs, technical credentials, and applicability for use within existing systems and information architecture
Leads communities of practice across Software Engineering to drive awareness and use of new and leading-edge technologies
Adds to team culture of diversity, equity, inclusion, and respect
Required qualifications, capabilities, and skills :
Bachelors Degree in Computer Science (preferably), Software or Computer Engineering, and 5+ years of applied experience
Hands-on practical experience delivering system design, application development, testing, and operational stability
Advanced in Java and similar programming languages
Proficiency in automation and continuous delivery methods
Proficient in all aspects of the Software Development Life Cycle
Advanced understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security
Passionate about full-stack development and learning new concepts of software engineering
Knowledge of systems analysis and designing platform capabilities, data formats and data flows
Knowledge of purpose built databases and polyglot storage and operating systems
Knowledge of Micro services architecture and Restful API development
Practical cloud native experience
Preferred qualifications, capabilities, and skills :
In-depth knowledge of the financial services industry and their IT systems
AWS Cloud experience is plus
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.","$124,105 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Geopaq Logic
4.7",4.7,Remote,GCP Data Engineer--W2,"Position: Data Engineer
Contract period:6 months
Work Location: Remote US (NJ preferred)
SUMMARY OF ESSENTIAL JOB FUNCTIONS
Design and develop analytical models and be the face to the data consumers
Perform data curation to meet the business requirements
Build batch and streaming data pipelines
Develop processes for automating, testing, and deploying your work
Identify risks and opportunities of potential logic and data issues within the data environment
Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUN REUIREMENTS
Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
3+ years of experience as Data Engineer or in a similar role
Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
Cloud to Cloud migration experience preferred
Strong PySpark skill is a must have
Have knowledge of data management fundamentals and data storage principles
Have knowledge of systems as it pertains to data storage and computing
Strong source to target mapping experience and ETL principles/knowledge
Excellent verbal and written communication skills.
Strong quantitative and analytical skills with accuracy and attention to detail
Ability to work well independently with minimal supervision and can manage multiple priorities
Job Types: Full-time, Contract
Salary: $60.00 - $65.00 per hour
Benefits:
Health insurance
Paid time off
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",$62.50 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2014,$1 to $5 million (USD)
"Stefanini, Inc
3.3",3.3,"Dearborn, MI",Data Management Product Engineer,"Stefanini Group is hiring!
Stefanini is looking for Data Management Product Engineer at Location: Remote
For quick apply, please reach out Utkarsh Dutt / Phone: 248 263 3997 /Email: utkarsh.dutt@stefanini.com

Project Description:
This fast-paced job position is intended for people who like to build analytics platforms and tooling which deliver real value to the business.
This is not a paper-pushing job. Applicants should have a strong desire to learn new technologies and be interested in providing guidance which will help drive the adoption of these tools.
The Analytics Data Management Product Engineer will assist with the engineering of strategic data management platforms from Informatica such as PowerCenter, Data Quality, Data Catalog, and Master Data Management.
This person will also collaborate with Infrastructure Architects to design and implement environments based on these technologies for use in enterprise data centers.
Platforms may be based on-premises, or hosted in various Cloud offerings which could include Google, Amazon, etc. Primary focus for this posting is PowerCenter and Data Quality (PCDQ). Responsibilities include: Thoroughly testing server and client functionality.
Developing custom installation guides and Chef/Habitat scripts that are consistent with IT security policy; Providing 2nd and 3rd level support regarding product related issues.
Developing new tools and processes to ensure effective implementation and use of the technologies.
Implementing, monitoring and analyzing usage data (DynaTrace, Splunk, etc.) to ensure optimal performance of the infrastructure. Maintaining a SharePoint site with relevant documentation, FAQs, processes, etc. necessary to promote and support the use of these technologies.



Required:
Bachelors
Required Skills Ability collect and clearly document requirements.
Ability to prioritize work and manage multiple assignments.
Ability to create & execute detailed project plans and test plans.
Preferred:
Hands on experience working with Analytics products.
Familiarity with Linux system administration, software installation, software support.
Familiarity with Google Cloud Platform. Experience working with PowerCenter and Data Quality, ideally installing and administering the platforms.
Ability to use Microsoft SharePoint to create information portal for engineered products.
Ability to use Microsoft Visio to edit Build Intent Diagrams for architected platforms.
Familiarity with Windows Server.

***Listed salary ranges may vary based on experience, qualifications, and local market. Also, some positions may include bonuses or other incentives***

Stefanini takes pride in hiring top talent and developing relationships with our future employees. Our talent acquisition teams will never make an offer of employment without having a phone conversation with you. Those face-to-face conversations will involve a description of the job for which you have applied. We also speak with you about the process including interviews and job offers.

About Stefanini Group

The Stefanini Group is a global provider of offshore, onshore and near shore outsourcing, IT digital consulting, systems integration, application, and strategic staffing services to Fortune 1000 enterprises around the world. Our presence is in countries like the Americas, Europe, Africa, and Asia, and more than four hundred clients across a broad spectrum of markets, including financial services, manufacturing, telecommunications, chemical services, technology, public sector, and utilities. Stefanini is a CMM level 5, IT consulting company with a global presence. We are CMM Level 5 company.",$76.00 /hr (est.),10000+ Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,1987,$1 to $5 billion (USD)
Foothill Ventures,#N/A,"Santa Clara, CA",Senior Software Engineer - Big Data,"Company Description

Foothill Ventures is a technology-focused venture fund based in Los Altos, California. We make pre-seed, seed (preferred), and A-round investments in startups across software, life science, and deep tech. We grew out of the TEEC Angel Fund, which made seed-stage, highly successful bets on companies like Zoom Communications, Quanergy, Iterable, Carta, Plus.ai, Opentrons, WeRide.ai and Ginkgo Bioworks, all subsequent Unicorns.
We provide support to our portfolio companies in various areas, including recruiting and talent acquisition. This role is posted on our website for our portfolio companies.

Job Description

One of our portfolio companies is looking for an experienced Big Data Engineer to design, develop, and optimize our large-scale data infrastructure. You will work with petabyte-scale datasets and build complex data pipelines that collect, transform, and organize big data for analytics and machine learning models.
Responsibilities:
Analyze and improve the performance and efficiency of the ETL pipelines by identifying bottlenecks, finding out root causes, applying best practices like incremental computation and parallel computation, and dogfooding Bluesky products.
Develop high-performance and scalable ETL pipelines, leveraging a powerful stack of modern tools and frameworks for data integration, transformation, and orchestration.
Effectively configure, monitor, and scale production environment involving Snowflake (similar DataWarehouse), dbt, Airbyte, and Prefect (any modern data frameworks/tools), ensuring seamless operation and optimal performance.
Build batch and real-time data processing pipelines for cleansing, transforming, and enriching data, and optimize data pipeline performance for speed, scalability, and cost efficiency
Monitor data pipelines end-to-end and troubleshoot issues proactively

Qualifications

Requirements:
Bachelor’s degree in a technical field or equivalent
5+ years of experience in big data engineering at a senior level
Expert knowledge of distributed data systems and architecture patterns
Proficiency in Scala, Python, Java, SQL, and Linux shell scripting
Experience with Spark, Hadoop, Hive, Kafka, Elasticsearch and NoSQL databases
Ability to optimize complex queries and ETL workflows
Strong problem-solving, communication and collaboration skills
Nice to Have:
1+ years of experience with Snowflake
1+ years of experience with dbt
Experience with other big data platforms: Databricks, BigQuery, Redshift, Spark, Presto
Experience in data modeling, data warehousing, and building enterprise data lakes

Additional Information

Foothill Ventures is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.","$159,134 /yr (est.)",1 to 50 Employees,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Mastech Digital
4.2",4.2,Remote,Data Platform/ DevOps Engineer - W2/Full Time,"Job Title: Data Platform/ DevOps Engineer
Duration - 6 months
Work Location: 100% remote
Job Description:
Deep technical knowledge of Databricks deployment in Azure, both from administrative and consultative standpoints.
Proven expertise in integrating Databricks into the Azure ecosystem, incl WebApp, GitHub Actions, and AKS.
Extensive experience with Azure Monitor, Sysdig, Splunk, and Dynatrace. Develop procedures for monitoring dashboards and alerts.
A good understanding of big data use cases and best practices, experience with large data & compute clusters.
Working knowledge of DevOps CI/CD tools (Jenkins, Github, Artifactory, docker images).
Strong working experience in monitoring tools Splunk and Dynatrace.
Experience creating a base view, Derived View, and Data source connections using Informatica (IICS) is a plus.
Experience with Fivetran-HVR, Snowflake, Collibra, and Apigee is a plus.
Flexible in work schedule to collaborate and guide the offshore development team.
Job Type: Contract
Schedule:
8 hour shift
Experience:
Databricks deployment in Azure: 2 years (Preferred)
integrating Databricks into the Azure ecosystem: 2 years (Preferred)
Work Location: Remote",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Information Technology Support Services,1986,$100 to $500 million (USD)
"Kroger General Office
3.1",3.1,"Blue Ash, OH",Senior Data Engineer (KTD),"Company Name: Kroger General Office
Position Type: Employee
FLSA Status: Exempt
Line of Business: Enterprise Retail Systems
See what life is like at Kroger Technology
at https://www.kroger.com/livekt

Additional Technology Information:

As a Sr. Data Engineer working on the Manufacturing Applications Engineering Team, you will have responsibility for helping convert from our legacy software which runs in our 32 Food Manufacturing Plants nationwide, to our new cloud-based ERP system.

Requirements:
Familiarity with Connect Direct, Xcom and MQFTE and other forms of data transfer
Experience with Microsoft Azure (Data Factory, ADLS, SQL Data Warehouse)
Experience in Java/Kafka coding and design
Experience with RDB and No SQL databases.
SQL Scripting/Stored Procedures
Windows Server

Tech Stack: Azure, Java, Kafka, Javascript, SQL, RDB, NoSQL
Position Summary

Accountable for developing and delivering technological responses to targeted business outcomes. Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for the enterprise. Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration with 84.51, where needed. Demonstrate the company's core values of respect, honesty, integrity, diversity, inclusion and safety.
Essential Job Functions
Utilize enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses
Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with 84.51
Leverage innovative new technologies and approaches to renovate, extend, and transform the existing core data assets, including SQL-based, NoSQL-based, and Cloud-based data platforms
Define high-level migration plans to address the gaps between the current and future state
Contribute to the development of cost/benefit analysis for leadership to shape sound architectural decisions
Analyze technology environments to detect critical deficiencies and recommend solutions for improvement
Promote the reuse of data assets, including the management of the data catalog for reference
Draft architectural diagrams, interface specifications and other design documents
Must be able to perform the essential job functions of this position with or without reasonable accommodation
Minimum Position Qualifications
Bachelor's Degree in computer science, software engineering, or related field
4+ years experience in the data development and principles including end-to-end design patterns
4+ years proven track record of delivering large scale, high quality operational or analytical data systems
4+ years successful and applicable experience building complex data solutions that have been successfully delivered to customers
Any experience in a minimum of two of the following technical disciplines: data warehousing, big data management, analytics development, data science, application programming interfaces (APIs), data integration, cloud, servers and storage, and database mgmt
Excellent oral/written communication skills
Desired Previous Experience/Education
Any experience with SSAS Tabular models, Power BI, Dataflows and DAX
Any experience with Azure Data Platform stack: Azure Data Lake, Data Factory and Databricks
Any experience with Python, Spark and SQL
Any experience with streaming technologies like Kafka, IBM MQ and EventHub
Any experience with data science solutions or platforms
Any experience with a variety of SQL, NoSQL and Big Data Platforms
Any experience building solutions using elastic architectures (preferably Microsoft Azure and Google Cloud Platform)
Education Level: Bachelor's Desired
Required Certifications/Licenses: None
Position Type: Full-Time
Shift(s): [[mfield4]]
States: Ohio; Alabama; Arizona; Arkansas; Colorado; Connecticut; Delaware; District of Columbia; Florida; Georgia; Idaho; Illinois; Indiana; Iowa; Kansas; Kentucky; Louisiana; Maine; Maryland; Massachusetts; Michigan; Minnesota; Mississippi; Missouri; Montana; Nebraska; Nevada; New Hampshire; New Jersey; New Mexico; New York; North Carolina; North Dakota; Oklahoma; Oregon; Pennsylvania; Rhode Island; South Carolina; South Dakota; Tennessee; Texas; Utah; Vermont; Virginia; Washington; West Virginia; Wisconsin; Wyoming
Keywords:

Jobs at Kroger: At Kroger, we hire people who have a passion for helping others and who want to build a relationship with our Customers. No matter what stage of your career, you can build your future at Kroger. We look for people who want more, aspire to be more and work hard to achieve their goals. Our focus on keeping the Customer first is what makes us successful. As the largest traditional grocery chain in the U.S. and one of the world's largest retailers, we employee nearly half a million Associates across 35 states. We offer many opportunities not only in our stores, but in Manufacturing, Logistics, Marketing, Finance, Human Resources, and many other fields.

Company Overview: Kroger Family of Companies employs nearly half a million associates who serve over 11 million customers daily through a seamless shopping experience under a variety of banner names. At The Kroger Co., we are Fresh for Everyone™ and dedicated to our Purpose: To Feed the Human Spirit®. We are committed to creating #ZeroHungerZeroWaste communities by 2025. Careers with The Kroger Co. and our family of companies offer competitive wages, flexible schedules, benefits and room for advancement.

Posting Notes: OH || Blue Ash || 11350 Grooms Road || 45242 || Kroger General Office || [[mfield2]] || Kroger Technology || Employee || Exempt || Full-Time || None","$110,239 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,Grocery Stores,#N/A,$10+ billion (USD)
"GEICO
2.9",2.9,"Chevy Chase, MD",Engineer II - Data (Support),"Position Summary
GEICO is seeking an experienced Engineer with a passion for building high-performance, low-latency platforms, and applications. You will help drive our insurance business transformation as we redefine experiences for our customers.
Position Description
Our Engineer II is a key member of the engineering staff working across the organization to provide a friction-less experience to our customers and maintain the highest standards of protection and availability. Our team thrives and succeeds in delivering high-quality technology products and services in a hyper-growth environment where priorities shift quickly. The ideal candidate has broad and deep technical knowledge, typically ranging from front-end UIs through back-end systems and all points in between.
Position Responsibilities
As an Engineer II, you will:
Scope, design, and build scalable, resilient distributed systems
Engage in cross-functional collaboration throughout the entire software lifecycle
Participate in design sessions and code reviews with peers to elevate the quality of engineering across the organization
Utilize programming languages like .NET, Python, SQL, and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of Azure tools and services
Consistently share best practices and improve processes within and across teams
Build product definition and leverage your technical skills to drive towards the right solution
This role will require 24x7 shift support, i.e., working day or night-time hours on a pre-defined schedule; this will also include holidays and weekends
Qualifications
Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design
Experience contributing to the architecture and design (architecture, design patterns, reliability, and scaling) of new and current systems
In-depth knowledge of CS data structures and algorithms
Understanding of existing Operational Portals such as Azure Portal
Understanding of HTML-5, JavaScript/TypeScript, XML, and JSON
Understanding of micro-services oriented architecture and extensible REST APIs
Understanding of Monitoring Tools such as Splunk or Application Insights
Intermediate PowerShell scripting skills
Intermediate level understanding of Azure Network such as security zones, VNETs, and Public Peered Services
Understanding of Azure PaaS and IaaS services
Understanding of security protocols and products such as of Active Directory, Windows Authentication, SAML, OAuth
Experience in Datacenter structure, capabilities, and offerings, including the Azure platform, and its native services
Knowledge of developer tooling across the software development life cycle (task management, source code, building, deployment, operations, real-time communication)
Understanding in DevOps Concepts, Cloud Architecture, and Azure DevOps Operational Framework
Experience with GIT and the overall GIT lifestyle
Experience with GraphDB
Experience with Big Data and the tooling on our Big Data Platform (Hadoop, Hive, Kafka)
Experience with Load test tooling (Gatling)
Experience with troubleshooting tools such as Splunk, Dynatrace, Thousand Eyes, Influx, Spark GUI, Yarn Logs, ETL Metrics, and Grafana
Experience with Containerization using Docker and Kubernetes
Understanding of Java programming fundamentals
Understanding of Spring Boot Framework
Web Service APIs with technologies such as Rest and GraphQL
Experience with SQL Queries
Experience with CI/CD tooling (Jenkins, Gradle, Artifactory, etc.)
Experience with Spark and Scala with a beginning understanding of DSaT MDF
Experience with Enterprise Reporting Tool (Qlik or MicroStrategy)
Analysis and Estimation skills
Strong problem-solving ability
Strong oral and written communication skills
Ability to excel in a fast-paced, startup-like environment
Experience
2+ years of non-internship professional software development experience in Big Data
2+ years of experience with architecture and design
2+ years of experience with AWS, GCP, Azure, or another cloud service
2+ years of experience in open-source frameworks
Education
Bachelor’s degree in Computer Science, Information Systems, or equivalent education or work experience
Benefits:
At GEICO, we make sure you have the support and resources to leverage and develop your skills, secure your financial future, and take care of your health and well-being. GEICO continually seeks to provide a workplace where everyone can be their authentic self. To help achieve this goal, we support associate-led Employee Resource Groups that foster a true sense of community. Through GEICO’s competitive benefits offerings and various training and development opportunities, we have you covered with our
Total Rewards Program
that includes:
Premier Medical, Dental and Vision Insurance with no waiting period**
Paid Vacation, Sick and Parental Leave
401(k) Plan
Tuition Assistance including Direct Billing and Reimbursement payment plan options
Paid Training, Licensures, and Certificates
Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.
**Coverage begins with the pay period after hire date. Must enroll in New Hire Benefits within 30 days of the date of hire for coverage to take effect.
GEICO is proud to be an equal opportunity employer. We are committed to cultivating an environment where equal employment opportunities are available to all associates and job applicants regardless of race, color, religious creed, national origin, ancestry, age, gender, pregnancy, sexual orientation, gender identity, marital status, familial status, disability or genetic information, in compliance with applicable federal, state and local law. GEICO celebrates diversity and believes it is critical to our success. As such, we are committed to recruit, develop and retain the most talented individuals to join our team
#LI-PK1 #DICE

At this time, GEICO will not sponsor a new applicant for employment authorization for this position.

Annual Salary
$76,000.00 - $157,000.00
The above annual salary range is a general guideline. Multiple factors are taken into consideration to arrive at the final hourly rate/ annual salary to be offered to the selected candidate. Factors include, but are not limited to, the scope and responsibilities of the role, the selected candidate’s work experience, education and training, the work location as well as market and business considerations.","$116,500 /yr (est.)",10000+ Employees,Subsidiary or Business Segment,Insurance,Insurance Carriers,1936,$10+ billion (USD)
"WSP
3.7",3.7,"Troy, NY",Associate Mechanical Engineer (Mission Critical/Data Centers),"Associate Mechanical Engineer (Mission Critical/Data Centers)

Who We Are
At WSP, we are driven by inspiring future-ready pioneers to innovate. We’re looking to grow our teams with people who are ready to collaborate in building communities and expanding our skylines. To do this, we hire candidates of all experiences, skillsets, backgrounds and walks of life. We actively foster a work environment and culture where inclusion and diversity is part of our fundamental structure. This is delivered behaviorally, through our policies, trainings, local partnerships with professional diverse organizations, internal networks and most importantly with the support and sponsorship of our leaders who help drive our commitment to an inclusive, diverse, welcoming and equitable work environment. Anything is within our reach and yours as a WSP employee. Come join us and help shape the future!
This Opportunity
kW Mission Critical Engineering, a member of WSP USA is currently initiating a search for a Mechanical Engineer for our Troy, NY office.

As a Mechanical Engineer with us, you will design complex cooling and HVAC systems including air distribution systems, chiller plants, and alternative energy solutions. The ideal candidate has familiarity with Building Information Modeling using REVIT, has strong communication skills, and an interest in liaising with internal and external design, client and construction team members.
Your Impact
Collect, compile, and analyze data from the physical work site, surveys, blueprints, schematics, data, technical drawings, computer-generated reports, and other matrices for project development, design, and construction.
Perform professional mechanical engineering work and conduct research and inspections of proposed and existing site conditions, equipment, resources, building, infrastructure, usage, and mechanical systems to determine conformance with applicable rules, standards, and construction or operating permits.
Participate in incorporating advanced technology, modeling techniques, concept development, design requirements, load calculations, and operating strategies to account for the proper installation and functioning of equipment and systems according to specifications; implementing future-ready solutions with mechanical engineering design standards.
Work under direct supervision of senior engineers and to perform a variety of assignments requiring the application of standard engineering and design techniques to support a variety of kW MCE clients
Work within multi-discipline project teams to develop drawing and specification documents for issuance to architects, contractors and building owners
Attend client meetings
Collaborate and coordinate with internal project discipline team members and external equipment vendors and manufacturers.
Perform cooling/heating load calculations
Design air distribution systems
Design hydronic systems
Schedule and select major equipment
Perform construction administrations tasks with oversight from experienced staff
Survey and evaluate existing conditions with oversight from experienced staff
Who You Are
Required Qualifications
Bachelor’s degree in Mechanical Engineering or Architectural Engineering with mechanical building systems emphasis
1-3 years of relevant post education experience in engineering discipline and prior mechanical design experience.
Engineer in Training Certification.
Knowledge of AutoCAD, Revit and TraneTrace
Knowledge of building, mechanical and energy codes
Interest in innovative design, specifically in renewable energies and sustainable, high performing, commercial, industrial or mission critical/data center buildings
Knowledge of mechanical engineering principles, practices, process, design/build, and the application to project work-related issues.
Experience with building and infrastructure planning, design, and construction management; including rehabilitation and new design.
Effective self-leadership with attention to detail, results orientation, and managing multiple priorities in a dynamic work environment.
Ability to learn new techniques, perform multiple tasks simultaneously, follow instruction, work independently, and comply with company policies.
Moderate proficiency with technical writing, office automation, software, technology, math principles, predictive models, spreadsheets, and tools.
Experience with discipline-specific design software (i.e., AutoCAD, CAM).
Critical thinking and problem-solving skills required to apply technical knowledge to reach conclusions from testing results, data collation, load calculations, statistical analysis and arriving at the most effective, economical, and logical solution.
Proven track record of upholding workplace safety and ability to abide by WSP’s health, safety and drug/alcohol and harassment policies.
Ability to work schedules conducive to project-specific requirements that may extend beyond the typical workweek.
Occasional travel may be required depending on project-specific requirements.
Preferred Qualifications:
Master’s Degree in Engineering.
PE License, or ability to obtain PE is preferable
Previous building design or construction internship experience preferred.
#LI-JB3
Additional Requirements
To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions.
Additional Details
Travel Required: 10%
Job Status: Regular
Employee Type: Full
Primary Location: TROY - RIVER ST
All locations: US-NY-Troy
About WSP
WSP USA is the U.S. operating company of WSP, one of the world's leading engineering and professional services firms. Dedicated to serving local communities, we are engineers, planners, technical experts, strategic advisors and construction management professionals. WSP USA designs lasting solutions in the buildings, transportation, energy, water and environment markets. With more than 15,000 employees in over 300 offices across the U.S., we partner with our clients to help communities prosper. www.wsp.com
WSP provides a flexible and agile workplace model while meeting client needs. Employees are also afforded a comprehensive suite of benefits including medical, dental, vision, disability, life, and retirement savings focused on providing health and financial stability throughout the employee’s career.
At WSP, we want to give our employees the challenges they seek to grow their careers and knowledge base. Your daily contributions to your team will be essential in meeting client objectives, goals and challenges. Are you ready to get started?
WSP USA (and all of its U.S. companies) is an Equal Opportunity Employer Race/Age/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability or Protected Veteran Status.
The selected candidate must be authorized to work in the United States.
NOTICE TO THIRD PARTY AGENCIES:
WSP does not accept unsolicited resumes from recruiters, employment agencies, or other staffing services. Unsolicited resumes include any resume or hiring document sent to WSP in the absence of a signed Service Agreement where WSP has expressly requested recruitment/staffing services specific to the position at hand. Any unsolicited resumes, including those submitted to hiring managers or other business leaders, will become the property of WSP and WSP will have the right to hire that candidate without reservation – no fee or other compensation will be owed or paid to the recruiter, employment agency, or other staffing service.","$77,502 /yr (est.)",10000+ Employees,Company - Private,#N/A,#N/A,#N/A,$5 to $25 million (USD)
"EY
3.9",3.9,"McLean, VA",Azure Data Engineer Support - REMOTE - Government and Public Sector,"At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

From strategy to execution, the Government & Public Sector (GPS) practice of Ernst & Young LLP provides a full range of consulting and audit services to help our Federal, State, Local and Education clients implement new ideas to help achieve their mission outcomes. We deliver real change and measurable results through our diverse, high-performing teams, quality work at the highest professional standards, operational know-how from across our global organization, and creative and bold ideas that drive innovation. We enable our government clients to achieve their mission of protecting the nation and serving the people; increasing public safety; improving healthcare for our military, veterans and citizens; delivering essential public services; and helping those in need. EY is ready to help our government build a better working world.

Our GPS Technology Organization is a structure within the US GPS practice that implements and maintains a new operate and technology model designed specifically to support U.S. defense and Government engagements.

The opportunity

This is a remote opportunity that can be performed within Continental United States.

You will be a key member of a dedicated operations team with responsibility of assuring overall health of data and database environments, making recommendations on performance improvements, job improvements, development of playbooks and implementation of Azure functions.

You will monitor applications and environments in Azure Gov for exceptions, review their performance, manage demand planning and capacity utilization. Your focus will be on stability and application uptime with an emphasis on quick incident resolution and automated solutions that prevent future outages. You will support promotion cycles of solutions, testing and executing version upgrades and patches.

You will be expected to keep up with industry developments and standards, ensuring innovative approaches to operate and support data environments.

You will support the delivery of processes to extract, transform and load data from disparate sources into a form that is consumable by analytics processes, for projects with moderate complexity, using strong technical capabilities.

You will help design, develop and produce data models of relatively high complexity, leveraging a sound understanding of data modelling standards to ensure high quality.

You will collaborate with other departments across the business to help define and deliver business value, and may interface and communicate with program teams, management and stakeholders as required to deliver small to medium-sized projects

Your key responsibilities

Lead delivery of on-going maintenance and management of pre-production, production environments, setting timelines and monitoring activities in alignment with business requirements
Contribute to the development of implementation plans for dealing with more complex requests for change
Review new product support documentation and design release packages for solutions
Monitor effectiveness of installations and ensure that appropriate recommendations for change are made
Oversee preliminary reviews for new environments and the adaption of findings to existing environments, including capacity and performance management recommendations,
Develop internal control standards and contribute to the development of procedures
Lead the production of high-quality data engineering deliverables, helping to ensure project timelines are met, and providing informal mentoring / training to junior members of the team
Lead the delivery of data quality reviews including data cleansing where required to ensure integrity and quality
Lead the delivery of data models, data storage models and data migration to manage data within the organization, for a small to medium-sized project
Resolve escalated design and implementation issues with moderate to high complexity
Analyze the latest industry trends such as cloud computing and distributed processing and beginning to infer risks and benefits of their use in business
Provide technical expertise to maximize value from current applications, solutions, infrastructure and emerging technologies and seek to continuously improve internal processes
Drive adherence to the relevant data engineering and data modelling processes, procedures and standards
Develop relationships with other engineering groups to gain a strong understanding of products and services as well as key business processes and apply technical support engineering expertise to ensure solutions are properly managed and maintained
Support data platforms, databases, and infrastructure in Azure Gov following a shift schedule with availability during afterhours.

Skills and attributes for success

Comprehensive understanding of Data and Database technologies with ability to troubleshoot underlying issues.
Knowledge of business processes, products, and services, within agreed areas of expertise and is able to provide input and advice to key stakeholders, such as Product Owners, business sponsors and Service Delivery Managers
Full stack knowledge of technologies in Azure Gov is a plus
Ability to systematically break apart complex problems (written, verbal or numerical). Ability to analyze figures to solve a problem.
Ability to be analytical and systematic whilst being open-minded and creative.
Able to base decisions on facts rather than emotions, and always using logic.
Ability to design an efficient way of processing high volumes of data where a group of transactions is collected over a period of time
Ability to design and implement models, capabilities and solutions to manage data within the enterprise (structured and unstructured, data archiving principles, data warehousing, data sourcing, etc.). This includes the data models, storage requirements and migration of data from one system to another
Ability to review (profile) a data set to establish its quality against a defined set of parameters and to highlight data where corrective action (cleansing) is required to remediate the data
Ability to discover, integrate, and ingest all available data from the machines that produce it, as fast as it’s produced, in any format, and at any quality

To qualify for the role, you must have

Bachelor's Degree in Computer Science or related discipline or equivalent work experience
5+ years Database Experience including administration and troubleshooting
DB Administration and troubleshooting experience in a technology area such as Azure SQL MI, SSIS, Azure SQL PaaS, Azure Data Factory
Working Knowledge of SQL Server Database configuration, support and administration tasks
Microsoft SQL Server, Windows Service Bus, IIS, .NET, Cloud Development Platforms
Excellent analytical and communication skills (verbal and written).
Ability to effectively prioritize and execute tasks in a dynamic and high-pressure environment
Ability to work in a team environment with in a high performing team
Ability to obtain and maintain Top Secret security clearance level
Flexibility to work weekends or afterhours as needed
Beginning to intermediate experience with the following tools and technologies:
Azure Data Catalogue / Purview
Azure Cloud
Databricks
Power BI Dataflows
Power Query
Azure Cosmos
Azure Monitor
PowerShell
Python
R

Ideally, you’ll also have

Experience working in a diverse fast paced environment in collaboration with other technical teams.
Willingness to work flexible hours, non-business hours, or other scenarios required by the flow of operations.
Detail-oriented, well-organized with ability to translate & communicate complex and abstract issues.
Experience in Installation, Administration and Troubleshooting of Data Technologies in Azure.
Experience working Agile/Scrum environment preferred.
Experience utilizing automated solutions with Azure Devops as the orchestrator of choice would be a plus.
ITIL Foundation Certification and other technology certifications are very beneficial
Certified Database Administrator
Basic experience with the following tools and technologies:
Amazon Web Services
Azure ADLS Gen 2
Azure Synapse
Alteryx
AWS DynamoDB
Splunk experience
SharePoint

What we look for

A self-starter, independent-thinker, curious and creative person with ambition and passion
History of continuous learning and continuous progression
What we offer
We offer a comprehensive compensation and benefits package where you’ll be rewarded based on your performance and recognized for the value you bring to the business. The salary range for this job in most geographic locations in the US is $83,000 to $150,700. The salary range for New York City Metro Area, Washington State and California (excluding Sacramento) is $99,600 to $171,200. Individual salaries within those ranges are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and geography. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Under our flexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances. You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, financial, and emotional well-being.
Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
EY | Building a better working world
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.
EY is an equal opportunity, affirmative action employer providing equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law.
EY is committed to providing reasonable accommodation to individuals with disabilities. If you are a qualified individual with a disability and either need assistance applying online or need to request an accommodation during the interview process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY’s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com.","$109,009 /yr (est.)",Unknown,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Black Knight
3.8",3.8,"Jacksonville, FL",Data Protection Engineer II,"Position:
Data Protection Engineer II
Job Description:
SUMMARY
Provides open systems enterprise data protection support functions to ensure data is protected with optimum system performance and availability.
LOCATION
This job is fully remote eligible within the United States. Local candidates to Jacksonville, FL will have a hybrid schedule with flexibility to work remote up to 2 days per week.
RESPONSIBILITIES
Completes backup and recovery, data migration, connectivity, and reporting requests.
Works with peers to develop and implement change management procedures.
Creates and maintains documentation for team use.
Collaborates on proposals and presents concepts during team meetings.
Provides assistance with system solution design.
Requires rotating 24x7 on-call support responsibility as well as weekend support.
Participate in Disaster Recovery Exercises as needed.
Some travel is required.
Performs other related duties as assigned.
MINIMUM REQUIREMENTS
Bachelor's degree or the equivalent combination of education, training, or work experience.
Requires 5+ years of experience in computer science or related technical field.
Proficient with Symantec/Veritas NetBackup Administration and Implementations, including NBU appliances
Solid understanding of operating systems and systems administration concepts both Wintel and *NIX
PREFERRED QUALIFICATIONS
Working knowledge of other Data Protection technologies such as Rubrik or Data Domain
Effective communication and team skills with an ability to cooperate, present to and participate with peers/team members
Demonstrated ability to learn new concepts and technologies as well as a personal commitment to stay current with latest technology concepts
Good problem-solving, analytical and critical thinking skills
Identifies and resolves less clearly defined problems using established procedures and/or protocols as guidelines
Ability to independently troubleshoot and escalate issues when solutions are not readily available or documented
Understanding and use of change management methodologies and tools
Black Knight carefully considers multiple factors to determine compensation, including a candidate’s education, training, specialty, experience, and work location. The base salary (exempt) or hourly rate (non-exempt) is just one component of the total rewards package offered to our employees, including potential bonus or commission eligibility, insurance (medical/dental/vision/life/disability), matching 401(k) plan and matching employee stock purchase plan
EEO Statement:
Black Knight is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, and protected veteran or military family status. Our employees’ diversity is our strength, and when we embrace our differences, it makes us better and brighter. Black Knight’s commitment to inclusion is at the core of who we are, and motivates us in how we do business each and every day.
Location:
Jacksonville, FL
Time Type:
Full time","$84,195 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Information Technology Support Services,2013,Less than $1 million (USD)
"DTCC
3.6",3.6,"Dallas, TX",Associate Director Data Integration Platform Engineer,"Are you ready to explore a world of possibilities?
Join our DTCC family, and you’ll grow your expertise and become the best version of you. As you embark on a new journey, you’ll be supported and surrounded by other professionals as you learn new skills, advance your career, and see the impact of your efforts every day.
Pay and Benefits:
Competitive compensation, including base pay and annual incentive
Comprehensive health and life insurance and well-being benefits, based on location
Retirement benefits
Paid Time Off and other leave of absence
DTCC offers a flexible/hybrid model of 3 days onsite and 2 days remote (Onsite Tuesdays, Wednesdays and a third day of your choosing)
Why you'll love this job:
The Lead Platform Engineer is a domain expert (SME) supporting DTCC’s Data Integration and Governance Platforms as part of the engineering team. We are looking for an individual who has a proven track record supporting and deploying Data Integration and Governance platforms in a large enterprise. The position will require an individual experienced in managing and supporting Talend and Collibra Platforms for administration and integration; life-cycle management; automation and improvement.
Your Primary Responsibilities:
Platform Engineering – Architecture & Design, Deployment and Post-Implementation Support.
Platform Support – Lifecycle Management, Level 3 Support, Adoption, Change Management, Incident and Problem management, Vendor management, Resiliency. Monitoring and managing Team service performance based on service level agreements (SLA) for Service requests, Incidents, Problems and Change tickets.
Audits & Regulatory Compliance – Identify & remediate gaps, Service readiness reviews.
Implement Operational Readiness – Implement new services following DTCC standards and processes.
Deliver targeted business outcomes by participating in the technical decision-making process.
Analyze changing business requirements to determine impact and optimal solution regarding defining the future state technical architecture.
Establish principles and models that guide technology decisions for the enterprise (best practices)
Ensure adherence to the governance, standards and best practices established by DTCC
Ensure delivered solutions enable infrastructure agility, scalability, and resilience to support required product needs throughout product lifecycle.
**NOTE: The Primary Responsibilities of this role are not limited to the details above. **
Talents Needed For Success:
Minimum of 8 years of related experience
Bachelor's degree preferred or equivalent experience
Additional Qualifications:
Minimum of 5 years of related experience in building and administering large scale, complex distributed Data Integration platforms.
Strong hands-on expertise on Data integrations tools like Talend, and DataStage.
Demonstrated ability in people management leading a team with proven hands-on staff performance management and mentoring.
Experience working in global setting with distributed teams.
Excellent communication skills and knowledge of common communication tools is a must.
Hands-on experience in problem and risk management related to delivery, resources, and dependencies
Solid understanding of Agile methodology, JIRA, and CI/CD pipeline
Exposure/Experience with AWS Cloud Data integration tools like Glue.
Exposure to Data Governance tools like Collibra
Who We Are:
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

DTCC safeguards the financial markets and helps them run efficiently, in times of prosperity and crisis. We are uniquely positioned at the center of global trading activity, processing over 100 million financial transactions every day, pioneering industry-wide, post-trade solutions and maintaining multiple data and operating centers worldwide. From where we stand, we can anticipate the industry’s needs and we’re working to continually improve the world’s most resilient, secure and efficient market infrastructure. Our employees are driven to deliver innovative technologies that improve efficiency, lower cost and bring stability and certainty to the post-trade lifecycle.

DTCC proudly supports Flexible Work Arrangements favoring openness and gives people freedom to do their jobs well, by encouraging diverse opinions and emphasizing teamwork. When you join our team, you’ll have an opportunity to make meaningful contributions at a company that is recognized as a thought leader in both the financial services and technology industries. A DTCC career is more than a good way to earn a living. It’s the chance to make a difference at a company that’s truly one of a kind.
Learn more about Clearance and Settlement by clicking here .

IT Risk and Data Services department seeks to meet our clients’ needs by capitalizing on the progress made in both the Risk Technology Program and the Data Analytics work and driving adoption of these capabilities across the enterprise. Important initiatives like the Modernization and Resiliency Programs count on these foundational capabilities to succeed.","$137,294 /yr (est.)",5001 to 10000 Employees,Company - Private,Financial Services,Financial Transaction Processing,1973,Unknown / Non-Applicable
"Pratt & Whitney
3.5",3.5,"East Hartford, CT",F135 Technical Data Customer Support Engineer (Hybrid),"Date Posted:
2023-06-12
Country:
United States of America
Location:
PW100: East Hartford 400 Main Street, East Hartford, CT, 06118 USA
Position Role Type:
Hybrid
Pratt & Whitney is working to, once again, transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious.
In addition to transforming the future of flight, we are also transforming how and where we work. Pratt & Whitney is laser focused on offering flexibility to our employees. We’ve introduced role types (Onsite, Hybrid, or Remote) and now list them in the job posting title so candidates know where they will operate in our blended work environment.
Please consider the following role type definition as you apply for this role:
Hybrid: employees who are working in Hybrid roles will work regularly both onsite and offsite.
Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future. Where the difference you make is on display every day. Just look up.
Are you ready to go beyond?
The engine program that powers the F-35 lightning II fighter aircraft has a position for self-starting Customer Support Engineer (CSE). The F135 Technical Data Authoring CSE will work closely with Limits Development Engineers to create Source Data for limits incorporation and expansion activities for scheduled, unscheduled, planned, and unplanned limits for depot and unit level maintenance on the F135 program. They will create Source Data to incorporate Engineering Changes and Non - Engineering changes into procedural F135 Technical Data. The Source Data created will be incorporated into Joint Technical Data (JTD).
Must be willing to flex work schedule to support business as needed.
Must become familiar with Tech Data Authoring Style Guide.
Must be able to obtain a government security clearances and access.
There may be some travel based on business needs (outsourcing vendors and /or customer sights)

Responsibilities will include:
Answer technical data inquiries and provide timely technical data updates to support maintenance and operations on the F135 engine.
Drive customer satisfaction by influencing the JTD through process improvements and incorporation of engineering requirements.
Review of limits incorporation documents from a sustainment perspective
Influence effective solutions for implementation plans for new configurations.
Support depot and unit level maintenance increased capability and implementation efforts.
Collaborate with internal engineering groups, customers, and vendors to ensure optimal instruction for inspection JTD.
Review JTD change requests.
Maintain the Scheduled Maintenance Plan (SMP) for depot overhaul
Identify support system issues with leadership and help develop solutions to meet the customer’s needs.

Basic Qualifications:
Bachelor's degree in a related field and 5+ years related experience; or an Advanced degree and 3+ years.
U.S. Citizenship required due to government contracts.

Preferred Qualifications:
Bachelor’s degree in technical field
F135 engine build, manufacturing or design experience
Knowledge or expertise in limits development
2+ years of experience of military engine knowledge and experience
Experience using technical data, drawings and requirements
Good work ethic with solid problem-solving ability
Strong attention to detail, excellent written, good communication skills, and tracking work at a micro level.
This requisition is eligible for an employee referral award. ALL eligibility requirements must be met to receive the referral award.
RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.
Privacy Policy and Terms:
Click on this link to read the Policy and Terms",#N/A,1001 to 5000 Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1922,$10+ billion (USD)
"Pratt & Whitney
3.5",3.5,"East Hartford, CT",Senior Data Scientist & Machine Learning Engineer (P3) - Hybrid,"Date Posted:
2023-05-08
Country:
United States of America
Location:
PW100: East Hartford 400 Main Street, East Hartford, CT, 06118 USA
Position Role Type:
Unspecified
Pratt & Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious.
Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future.
Innovation through diversity of thought. At Pratt & Whitney, we believe diversity of thought enables creativity, innovation, and a foundation for inclusion. By fostering an inclusive culture, we accept a shared accountability and responsibility to recognize, sponsor, coach, hire and promote talent equally. We welcome our employees to be their whole - best - selves at work because trust, respect and integrity, are a part of our DNA.
At Pratt & Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond?
Pratt & Whitney is seeking a Senior Data Scientist & Machine Learning Engineer to help drive our digital transformation, by joining our newly created Engineering Core Artificial Intelligence/Machine Learning (AI/ML) Team. The team is tasked with accelerating end-to-end AI/ML solutions across our value stream (from Engineering Design Optimization, Manufacturing and Aftermarket Defect Detection to Predictive Analytics), support multiple engine programs accelerate their adoption of AI/ML solutions through architecture, implementation, deployment, and integration, and work with others across the enterprise to build foundational solutions and standards for current and future AI/ML work. Immediate tasks include training models and building pipelines for one of:
Regression modeling and pipelines for Finite Element Analysis (FEA) /Computational Fluid Dynamics (CFD) surrogate modeling for design optimization and production quality control.
Computer vision defect detection on production and aftermarket data.
Key Responsibilities:
Architect and implement a state of the art AI/ML ecosystem.
Integrate end-to-end AI/ML solutions into existing and future domain specific systems.
Implement Machine Learning Operations (MLOps) pipelines and systems.
Evaluate commercial tool offerings .
Train, test, and deploy ML models .
Collaborate with experts to work with data and use cases across multiple domains.
Define and document AI/ML modeling practices and MLOps standards.
Engage and participate in the Pratt & Whitney AI/ML Community.
Coach AI/ML teams and individuals.
Basic Qualifications:
University Degree and 5+ years prior relevant work experience with a focus on AI/ML models and pipelines , OR an Advanced Degree in a related field and 3+ years prior relevant work experience with a focus on AI/ML models and pipelines.
US Citizenship required due to government programs.
Travel up to 7%.
Preferred Qualifications:
PhD graduate with directly applicable research.
Prior knowledge of the aerospace industry (design, analysis, manufacture, and/or aftermarket support).
AI/ML modeling experience (feature engineering, regression, classification, clustering, NLP, computer vision, etc.) .
AI/ML lifecycle experience (problem definition, data gathering, training, testing, deployment, MLOps pipelines).
Prior experience with MLOps pipelines.
Experience deploying and managing ML on edge devices.
Engineering experience with multi-disciplinary analysis and optimization (MDAO) experience with FEA or CFD and optimization.
Understanding of the scientific python ecosystem (scipy, numpy, pandas, scikit-learn).
Advanced modeling capability with ML libraries like Tensorflow or PyTorch.
Experience with ML Software like AWS Sagemaker, Databricks or Dataiku.
Cloud Experience with Amazon Web Services or Microsoft Azure.
Disciplined software engineering experience (e.g., automated testing, code reviews, CI/CD).
Experience working in an agile framework.
Possess a flexible attitude and willing to work with a range of technologies and languages.
Ability to align multiple customers to a set of requirements and drive tasks to completion.
Role Type: What is my role type?
In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is:
Hybrid: Employees who are working in Hybrid roles will work regularly both onsite and offsite. This means that responsibilities of the job need to be performed onsite on a regular basis.
Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility.
This requisition is eligible for an employee referral award. ALL eligibility requirements must be met to receive the referral award.
RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.
Privacy Policy and Terms:
Click on this link to read the Policy and Terms",#N/A,1001 to 5000 Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1922,$10+ billion (USD)
"Garver
4.4",4.4,"Kansas City, MO",Data Center Design Electrical Engineer,"As part of the Buildings Group for Garver, this Electrical Engineer will be responsible for the delivery of various Data center/Mission Critical projects. Specifically, this responsibility will include a variety of projects related to investigating, planning, design, and commissioning of:
Complex power systems
Medium voltage distribution systems
Uninterruptible power systems
Lighting systems
In addition, this role will include coordination with other support disciplines, and coordination with regional offices. Assisting project managers in management of projects. Following quality assurance and quality control plans. Travel to project locations will be required.
Abilities and attributes needed for this position:
Collaborate with multi-disciplinary project teams to develop drawing and specification documents.
Design complex electrical medium voltage and low voltage distribution systems, as well as electrical building systems.
Perform project management activities, including proposal writing, budgeting, and client interactions.
Attend and lead client meetings.
Ability to collaborate with internal and external design, client, and construction team members.
Requirements:
Bachelor’s degree in electrical engineering or architectural engineering with a focus on electrical building systems.
Minimum of 5 years of experience in designing electrical systems for mission-critical/data center buildings.
Registered Professional Engineer (PE) certification.
Strong knowledge of electrical systems and codes.
Proficiency in Building Information Modeling using Revit.
Preferred Skills:
Experience with short circuit coordination and arc flash studies.
Background in mission-critical/data center projects.
Additional credentials such as LEED and Uptime ATD are preferred.
Grow With Us
Garver offers its employees programs such as company-paid professional memberships, company support for industry licenses and continuing education opportunities that foster a progressive atmosphere. Garver provides the tools, resources, and environment to develop leaders, stimulate ideas, and accomplish projects. By offering highly competitive salary packages, attractive benefits, and a comprehensive wellness program; Garver walks the talk when it comes to work-life balance.
Founded in 1919, Garver is an employee-owned multidisciplined engineering, planning, and environmental services firm with more than 1,000 employees across the United States. Offering a wide range of services focused on aviation, buildings, construction, enterprise solutions, federal, survey, transportation, water, and wastewater, Garver sits in the top 100 of the Engineering News-Record's prestigious Top 500 Design Firms list and is consistently recognized as a best firm to work for. Learn more at GarverUSA.com.
Garver is committed to providing equal employment opportunities to all applicants and employees. Our employment practices are based upon an individual's capabilities and qualifications without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or any other category protected by law.
#Li-SM1","$75,151 /yr (est.)",501 to 1000 Employees,Private Practice / Firm,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1919,$100 to $500 million (USD)
"Olsson
4.0",4.0,"Oklahoma City, OK",On-Site Mechanical Engineer - Data Center,"Company Description

We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.
Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us — and will continue to allow us — to grow. The result? Inspired people, amazing designs, and projects with purpose.

Job Description

As an On-Site Mechanical Engineer, you will work directly with some of the world’s largest technology companies and other mission-critical clients. You will serve as a mechanical engineer on projects, design calculations, write technical reports, and prepare documents. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.

Qualifications

You are passionate about:
Working collaboratively with others
Having ownership in the work you do
Using your talents to positively affect communities
You bring to the team:
Strong communication skills
Ability to contribute and work well on a team
Bachelor’s degree in engineering preferred
3+ years of experience

Additional Information

Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we’re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.
As an Olsson employee, you’ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you’ll:
Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)
Engage in work that has a positive impact in communities
Receive an excellent 401(k) match
Participate in a wellness program promoting balanced lifestyles
Benefit from a bonus system that rewards performance
Have the possibility for flexible work arrangements
Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.
#LI-MP1","$67,892 /yr (est.)",1001 to 5000 Employees,Private Practice / Firm,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1956,$100 to $500 million (USD)
"KeyLogic Systems
4.1",4.1,"Dulles, VA",Cyber Security Data Integration Engineer/Developer - 3101,"Position: Cyber Security Data Integration Engineer/Developer - 3101
Location: Remote/Dulles, VA
Salary Range: $140-150K
Clearance: Secret (Refer to Required Skills)
KeyLogic is supporting a U.S. Government customer on a large mission critical development and sustainment program to design, build, deliver, and operate a network operations environment; including introducing new cyber capabilities to address emerging threats. KeyLogic is seeking a Cyber Security Data Integration Engineer/Developer to support the design, development, and deployment of advanced cybersecurity capabilities.

Job Responsibilities:
KeyLogic is seeking a Security Engineer to play a key role in supporting a statewide program providing cyber assessment services and management that will protect 20+ affiliates from growing and evolving cyber threats. The engineering effort will focus on cloud security, SIEM and log management, and endpoint detection/response protecting customers from the ever growing and evolving cyber threats. This person will also work with customers to ensure the organization’s compliance standards are met and maintained while also driving solid customer relationships to the next level.

This position requires a thorough understanding of network architecture fundamentals, protocols, routing, firewalls, cloud, and DevOps. This position is part of a larger team; however, the candidate is expected to work well on his or her own under general supervision, be self-directed, able to multi-task, and prioritize work.

Required Skills:
U.S. Citizenship required
Active Secret clearance and must be able to obtain a TS/SCI clearance
Must be able to obtain DHS Suitability
6+ years of directly relevant experience
4+ years of experience with administration of enterprise SIEM technologies (Splunk primarily)
Splunk Cloud experience: Architect, design, engineer, support, configure, administer content and maintain infrastructure for a highly available and disaster recovery configuration
Splunk experience: Administer Splunk and Splunk Application for Enterprise Security log or event management
Expertise with EDR toolsets – administration, analysis, and integrations preferably CrowdStrike
Familiarity with SOAR Products include Phantom and ThreatConnect
Experience with scripting (e.g., PowerShell, bash/ksh/sh,python)
Ability to assist team with Incident response and handling
Excellent demonstrated experience in communicating technical information to non-technical and technical audiences.
Experience working directly with senior leadership and management.

Desired Skills:
Automation: Experience related to Ansible for performing administration using code and Git/Gitlab for workflow management
Familiarity with Windows and Linux integration, SQL database technologies, troubleshooting, deployment, patching, and administration
Experience with Logstash and ability to collect, parse, and transform logs
Experience with the standards compliance process (e.g., NIST) and writing network security documentation

Required Education:
Bachelor’s degree in Systems Engineering, Computer Science or related degree. Two years of related work experience may be substituted for each year of degree level education.

Desired Certifications:
Splunk IT Service Intelligence Certified Admin, Splunk Enterprise Security Certified Admin, Splunk Cloud Certified Admin, CCNA, CCNP)
At KeyLogic we recognize that our employees are our most valuable resources. We hire talented, qualified professionals and provide each of our employees with every resource and opportunity to excel in their day-to-day activities as well as advance their career.
KeyLogic is a highly successful provider of professional and engineering services. We specialize in solutions that enable our customers to make better decisions for their organization. KeyLogic’s performance has earned the company a solid reputation for high standards, proactive solutions, and an outstanding commitment to the customer, best exemplified by the fact we have never had a one-time federal customer — all of our customers have provided repeat business. This has led us to achieve significant growth every year since our founding in 1999.
At KeyLogic, we're known for our extraordinary commitment to the success of the organizations we serve. Our client list includes the Department of Defense (DoD), Environmental Protection Agency (EPA), Energy (DOE), Transportation (DOT) and Treasury (including the Internal Revenue Service (IRS)), General Services Administration (GSA), and the National Aeronautics and Space Administration (NASA).
All qualified applicants will receive consideration for employment at KeyLogic without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital; or any other status protected by law. KeyLogic is proud to be an affirmative action and equal opportunity employer.
NOTE: KeyLogic is an Equal Employment/Affirmative Action employer. We do not discriminate in hiring on the basis of sex, gender identity, sexual orientation, race, color, religious creed, national origin, physical or mental disability, protected Veteran status, or any other characteristic protected by federal, state, or local law.
If you need a reasonable accommodation for any part of the employment process, please contact us by email at Recruiting@KeyLogic.com and let us know the nature of your request and your contact information. Request for accommodation will be considered on a case-by-case basis.
Job Code:
1907","$145,000 /yr (est.)",501 to 1000 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1999,$100 to $500 million (USD)
"City of Houston, TX
3.3",3.3,"Houston, TX",SENIOR IT PROFESSIONAL – APPLICATIONS (Senior Data Engineer),"POSITION OVERVIEW
Applications accepted from: ALL PERSONS INTERESTED
Job Classification: SENIOR IT PROFESSIONAL – APPLICATIONS (Senior Data Engineer)
Posting Number: 32138
Department: HOUSTON INFORMATION TECHNOLOGY SERVICES (HITS)
Division: ENTERPRISE APPLICATIONS SERVICES
Reporting Location: 611 WALKER, Houston, TX 77002
Workdays & Hours: MONDAY – FRIDAY 8:00 AM – 5:00 PM* *Subject to Change

DESCRIPTION OF DUTIES / ESSENTIAL FUNCTIONS
Houston, TX, is the fourth largest city in the country, with a budget of over 6 billion dollars, a workforce strong of 20,000 employees, and 23 departments with fascinating data and a wide range of questions. Houston promotes healthy and resilient communities through smart civic investments, dynamic partnerships, education, and innovation. It is a place where anyone can prosper and feel at home.
The City offers its employees various benefits, including healthcare, wellness, professional development, a work-from-home policy (Download PDF reader), and an excellent pension plan (Download PDF reader). The Enterprise Data Office is part of the Houston IT Services department and provides city-wide services. Our four focus areas are Open Data, Data Community, Data Governance, and a Modern Data Stack.
The Senior Data Engineer is responsible for designing, constructing, and maintaining systems and pipelines that enable the efficient collection, transformation, storage, and availability of data for analysis and business needs. This includes creating data pipelines, ensuring data quality and integrity, managing databases, optimizing data storage and retrieval, and collaborating with data scientists and analysts to support their data requirements. Regularly provides guidance and training to other team members.

The Senior Data Engineer will:
Deploy and use cloud data services such as Microsoft Azure (ADL, ADF), AWS, or Snowflake.
Review code and develop in SQL to update databases, customize features, improve functions efficiency, etc.
Create data integration with multiple techniques such as Azure Data Factory, API, ETL/ELT, SSIS…
Gather, document, and translate business needs into a proposed architecture, technology product, system requirements, database configuration, and data model.
Perform database administration mainly on SQL Server, including monitoring, version upgrade, performance tuning, backup/restore, and user access.
Implement standards and best practices, including appropriate level of Security Controls and compliance with IT Policies.
Leverage technologies to automate common activities, improving operational efficiency, service, and performance.
Contribute to different aspects of selected projects, including data modeling, integration, and migration.
Troubleshoot incidents and assist with complex change requests.
Perform other duties as assigned.

The candidate has:
Good analytical skills to investigate and propose solutions.
Organizational skills to balance and prioritize projects and operation activities.
The ability to successfully communicate technical concepts to stakeholders and instructions to users.
A solid understanding of the Software Development Life Cycle (SDLC) and ITIL framework.

WORKING CONDITIONS
There are no major sources of discomfort, i.e., essentially normal office environment with acceptable lighting, temperature, and air conditions.
MINIMUM REQUIREMENTS
EDUCATION
Requires a Bachelor's degree in Computer Science, Management and Information Systems (MIS) or a closely related field.
Usually has advanced technical certifications that demonstrate mastery of a specialized application.

EXPERIENCE
At least six (6) years of technology experience supporting applications. Advanced certifications and/or greater than six (6) years applicable experience may be substituted for up to two (2) years of the education requirement.

LICENSE
None
PREFERENCES
**Preference shall be given to eligible veteran applicants provided such persons possess the qualifications necessary for competent discharge of the duties involved in the position applied for, such persons are among the most qualified candidates for the position, and all other factors in accordance with Executive Order 1-6. **

Preference will be given to candidates with the following skillsets:
Supported a mission critical technology environment.
Actively used metadata.
Experience in a DevOps environments or using an Agile Framework
Developed or maintained a cloud-based data warehouse
Programed in Python
Created reports using modern analytical tools as Power BI, Tableau or Qlik
Demonstrated Interest in machine learning and artificial intelligence.
Configured and installed database server
Related certifications
GENERAL INFORMATION
SELECTION / SKILLS TESTS REQUIRED
Department may administer skills assessment test.

SAFETY IMPACT POSITION – NO
If yes, this position is subject to random drug testing and if a promotional position, candidate must pass an assignment drug test.

SALARY INFORMATION
Factors used in determining the salary offered include the candidate’s qualifications as well as the pay rates of other employees in this classification.

PAY GRADE: 29

APPLICATION PROCEDURES
Only online applications will be accepted for this City of Houston job and must be received by the Human Resources Department during active posting period. Applications must be submitted online at: www.houstontx.gov.

To view your detailed application status, please log-in to your online profile by visiting: http://agency.governmentjobs.com/houston/default.cfm or call (832) 393-0450.

If you need special services or accommodations, call (832) 393-0450. (TTY 7-1-1). If you need login assistance or technical support call 855-524-5627.

Due to the high volume of applications received, the Hiring Department will contact you directly, should you be selected to advance in our recruitment process.

All new and rehires must pass a pre-employment drug test and are subject to a physical examination and verification of information provided.

EOE Equal Opportunity Employer
The City of Houston is committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, genetic information, veteran status, gender identity, or pregnancy.

Agency
City of Houston
Address
901 Bagby St

Houston, Texas, 77002
Website
https://www.houstontx.gov/","$96,911 /yr (est.)",10000+ Employees,Government,Government & Public Administration,Municipal Agencies,1836,Unknown / Non-Applicable
"EPAM Systems
4.1",4.1,"Dallas, TX",Senior Data Engineer - AWS/Databricks,"We are hiring a Senior Engineer, who will support a critical digital transformation project for one of EPAM’s top clients. This is a high-impact role, with the opportunity to advance your skills and grow within a global organization.

We live and breathe big data. Daily, we ingest and extract useful information from hundreds of live TV channels as well as collect, analyze, and report on information from millions of active TVs. We’re all in with AWS and make extensive use of many of their services. On any given day we are running between 4500-5000 instances with 100+ internal services on a stack and application set that includes Ubuntu, C, Python, RDS, Kafka, Elastic, Redshift and Kinesis, Databricks.

As any organization that has grown organically and significantly over time there is a lot to manage and a fair amount of tech debt. This means you will have the opportunity to come in and manage what we have while helping reimagine how we approach specific operational challenges such as administration, monitoring, logging, configuration management and automation.

If you'd like to learn more about this position and project, apply now! Connect with a recruiter today!

Req.#514966428

RESPONSIBILITIES
Independently design, build and launch new data extraction, transformation and loading processes in production
Identify the data needed for a business problem and implement the logging required to ensure the availability of data, while working with data infrastructure to triage issues and resolve them
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design, build and launch new data models
Support existing processes running in production and implement optimized solutions with limited guidance
Work with terabyte-to-petabyte scale data

REQUIREMENTS
Minimum of 5 Years of relevant experience
Previous experience as a data engineer or in a similar role
Technical expertise with data models, data mining, and segmentation techniques
Good experience in Python, SQL, AWS is required
Experience with Big Data platforms such as Databricks is a must
Experience with Map-Reduce and/or spark computing frameworks
Experience in working with different Cloud Environment/s (AWS is highly preferred)
Hands-on experience with SQL database design, ETL Tools/scripts
Great numerical and analytical skills
Excellent written and verbal communication skills; proactive communication to your team, management, and business stakeholders
Degree in Computer Science, IT, or similar field; a Master’s is a plus

BENEFITS
Medical, Dental and Vision Insurance (Subsidized)
Health Savings Account
Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)
Short-Term and Long-Term Disability (Company Provided)
Life and AD&D Insurance (Company Provided)
Employee Assistance Program
Unlimited access to LinkedIn learning solutions
Matched 401(k) Retirement Savings Plan
Paid Time Off
Legal Plan and Identity Theft Protection
Accident Insurance
Employee Discounts
Pet Insurance
Employee Stock Purchase Program

ABOUT EPAM
EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential","$101,367 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1993,$1 to $5 billion (USD)
"AnaVation
4.9",4.9,"Chantilly, VA",Senior AI/ML Data Engineer - REMOTE!,"Be Challenged and Make a Difference

In a world of technology, people make the difference. We believe if we invest in great people, then great things will happen. At AnaVation, we provide unmatched value to our customers and employees through innovative solutions and an engaging culture.

Description of Task to be Performed:
AnaVation is looking for a talented AI/ML Data Engineer who is passionate about technology and working with customers and a strong team to provide solutions for our mission-critical customer. The ideal candidate appreciates partnering with our customer and team of engineers to create innovative engineering solutions. The selected candidate will work with a small group of developers building a Cyber data-lake by applying AI/ML technologies to extract insights from the data. If you are looking to be challenged, then this is the environment for you. This position supports 80% remote work with one day per week in our Chantilly, VA office.

The candidate will be required to pass a high-risk public trust background investigation.

Position Responsibilities:
Develop tools and processing applying AI/ML techniques such as entity recognition, sentiment analysis, and object recognition to extract insights from data
Developed and train models and run evaluation experiments
Develop and evaluate tools to search, analyze, discover, and otherwise exploit data in the data lake to support investigative operations
Required Qualifications:
3 years of experience programming in Python
Experience in machine learning platforms, frameworks, and libraries
Understanding of NLP techniques for text representation, semantic extraction techniques, data structures, and modeling
Documentation experience for complex software components
Experience in implementing the products lifecycle - design, development, quality, deployment, maintenance
Relational database design and development (PostgreSQL, Oracle, Microsoft SQL Server)
ETL/ELT development experience · Linux environment experience
Experience analyzing unstructured, structured, and semi-structured data
Strong technical and computational skills, coupled with the ability relate data to use cases, mission requirements, and end-user experience
Active Secret Clearance or High Risk Public Trust Suitability
Bachelor’s degree in Computer Science, Information Systems or related discipline
Preferred Qualifications:
Experience with Azure Cognitive Services or AWS Comprehend
Experience with NLP frameworks such as SpaCy and OpenNLP
Experience with cloud data solutions such as AWS RedShift, AWS DynamoDB and Azure Cosmos DB
Experience with search technologies such as Elasticsearch, AWS Opensearch, Azure Cognitive search, SOLR, etc.
Experience with Databricks, Azure Synapse, or Apache Spark
Experience with cloud concepts and big data architectures such as Hadoop, Kafka, etc.
Knowledge of Continuous Integration/Continuous Delivery tools and practices
Experience with cloud platforms such as AWS and Azure
Experience working in Agile Environments
Experience with DevOps toolsets
Familiarity with containerization (Docker, Containerd, Kubernetes, etc.)
Experience with microservices
Benefits
Generous cost sharing for medical insurance for the employee and dependents
100% company paid dental insurance for employees and dependents
100% company paid long-term and short term disability insurance
100% company paid vision insurance for employees and dependents
401k plan with generous match and 100% immediate vesting
Competitive Pay
Generous paid leave and holiday package
Tuition and training reimbursement
Life and AD&D Insurance

About AnaVation
AnaVation is the leader in solving the most complex technical challenges for collection and processing in the U.S. Federal Intelligence Community. We are a US owned company headquartered in Chantilly, Virginia. We deliver groundbreaking research with advanced software and systems engineering that provides an information advantage to contribute to the mission and operational success of our customers. We offer complex challenges, a top-notch work environment, and a world-class, collaborative team.

If you want to grow your career and make a difference while doing it, AnaVation is the perfect fit for you!","$83,864 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2013,$5 to $25 million (USD)
"Sense
4.3",4.3,"Cambridge, MA",Backend Data Engineer,"About Sense
Sense is a fast-growing greentech scale-up based in Cambridge, MA. We build smart home monitoring systems to help people take command of their energy usage, saving money while combating climate change. Our mission is to reduce global carbon emissions by making homes smart and efficient, and we’re looking to make an impact at scale: Sense’s technology has the potential to prevent one gigaton of carbon from entering the atmosphere every year.
We’re looking for talented self-starters who want to be part of the energy transformation and are ready, willing, and able to tackle tough challenges and complex technical problems. When you join the Sense team, you’re helping us build a cleaner, more resilient future.
What you'll do:
As a Software Engineer for the Data Science Team, you will collaborate closely with data scientists to design, develop, and maintain robust, scalable, and efficient tooling and infrastructure. Your contributions will directly impact the success of our data science initiatives by providing the technical backbone that accelerates experimentation, analysis, and model deployment.
Responsibilities:
Develop and maintain tools, libraries, and frameworks that facilitate data collection, preprocessing, analysis, visualization, and model deployment.
Collaborate with data scientists to understand workflows and pain points, and then design and implement solutions to streamline processes.
Build data pipelines to ensure smooth data flow from various sources into data scientists' work environments.
Optimize infrastructure to support large-scale data processing, storage, and computation.
Work on automating tasks such as model training and performance monitoring.
Stay up-to-date with the latest advancements in data science tooling and best practices, and proactively incorporate them into our ecosystem.
Requirements
Curious about seeing ML solutions applied to a novel domain
4+ years of professional data engineering experience
Experience with Linux, git, Python, PyTorch, relational databases, and AWS
Familiarity with CI/CD pipelines, unit testing frameworks, and observability frameworks
Great numerical and analytical skills
Degree in Computer Science, Data Science, or similar field – a Masters is a plus
Must be authorized to work in the U.S.
Benefits
Be a part of building something that will make a difference in the world.
Great opportunity to gain experience at a consumer smart home startup.
Competitive compensation including equity
Great work-life balance
Flexible work hours
Vacation starting at 3 weeks/year + 1 week paid sick time
Paid parental leave (5 weeks or more depending on location)
Dependent Care Accounts
Generous healthcare benefits for employees and dependents
Medical (90% of the premium and first 50% of the deductible)
Dental (90%)
Vision (100%)
Flexible Spending Accounts
Life, AD&D, long- and short-term disability insurance (100%)
401k plan with company match
Free Sense energy monitor for your home, discounts for friends and family
Competitive compensation including equity
Remote-friendly
Remote or local/hybrid in our Cambridge Central Square office
Home office setup allowance ($200/year)
Great work-life balance
Flexible work hours
Vacation starting at 3 weeks/year + 1 week paid sick time
Paid parental leave (5 weeks or more depending on location)
Dependent Care Accounts
Generous healthcare benefits for employees and dependents
Medical (90% of the premium and first 50% of the deductible)
Dental (90%)
Vision (100%)
Flexible Spending Accounts
Life, AD&D, long- and short-term disability insurance (100%)","$126,844 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2013,Unknown / Non-Applicable
"Geo Owl
4.4",4.4,"Fort Gordon, GA",Senior Data Engineer,"Geo Owl is currently looking for a motivated and qualified Senior Data Engineer to support our Department of Defense contract opportunity. To be qualified, you need knowledge of Army structure and defense level intelligence, intelligence collection, fusion, analysis, production, and dissemination for intelligence databases and products, and meet the requirements listed below. If interested, apply now, or contact one of our recruiters.
Location: Fort Gordon, GA
Clearance: TS/SCI
Requirements: Must meet all the requirements listed below.
Excellent written & oral communication, research, and analytic skills
Expert ability to manage personnel, requirements, and coordination of projects
Expert capabilities to research, create, develop, and deliver professional briefings, multimedia presentations, and written reports
Experience utilizing programming languages such as SAS, R, Java, C, MATLAB, ScaLa, or Python; experience accelerating large data transactions across industry-leading GPU architectures to answer analytic questions
Experience with assessments, enterprise data integration, governance, and metrics, including the application of metadata management techniques and ability to interrogate databases efficiently using SQL
Experience with tradecraft and publication; ability to coordinate and support cross-community meetings and working groups; assimilate large volumes of information, and independently produce reports using data science focused libraries such as Pandas, Scikit, TensorFlow and Gensim to answer analytical questions
Desired Requirements:
Knowledge of Army structure and defense level intelligence operations: intelligence collection, fusion,
analysis, production, and dissemination for intelligence databases and products
Knowledge and experience with intelligence operations and in assisting with drafting expert assessments
across operations priorities on behalf of the stakeholder
Specialized training from any intelligence collection and analysis school or certification to include GEOINT Professional Certification (GPC-F, GPC_IA-II, GPC_GA-II, GPC_IS-II, etc)
Knowledge and understanding of the National System for GEOINT (NSG) and Intelligence Community;
knowledge of private sector data science/analytics, machine learning, and data visualization communities
Education Requirements:
MA or MS in Data Science, Data Analytics, Informatics, Statistics, or related field AND 2 years CURRENT
Intelligence Analysis experience; OR
BA or BS in Data Science, Data Analytics, Informatics, Statistics, or related field AND 5 years CURRENT
Intelligence Analysis experience; OR
Undergraduate degree with graduate/professional certificate in Data Science, Data Analytics, Informatics,
Statistics, or related field AND at least 10 years of Intelligence Analysis experience

Benefits:
Health Insurance (Geo Owl pays 80%+ of the premium).
401k matching.
Dental, Vision, and other supplemental insurance plans available.
Company-paid short-term and long-term disability and life insurance.
Peer-to-Peer spot bonuses.
120 hours of PTO per year plus federal holidays.
Joining the Geo Owl Team | What to Expect
At Geo Owl, we highly value our team members. We offer challenging but rewarding opportunities for those who want to work hard to provide a great experience for the customer and strive to reach their professional goals. As a member of the Geo Owl family, you will be working alongside people who share this work ethic and are aiming to be the best partner for our customer. We are all proud to be a part of this company and we want you to be too.
Our Mission
Provide high quality solutions to our mission partners in the United States through our expert analysts.
Be recognized as the best at what we do by our customers.
Be a team our team members are proud and excited to be a part of.
Continually strive for excellence and seek to tackle the most difficult challenges our industry has to offer.
About Us
Geo Owl is a premiere provider of Full-Motion Video (FMV), Geospatial, ISR, Intelligence and IT services to the Department of Defense and Intelligence Community. We are vitalized by our engaged team of professionals that truly value each other and the important missions we support.
Equal Opportunities
Geo Owl is an equal opportunity employer and does not discriminate on the basis of race, color, religion, creed, sex, age, sexual orientation, national origin, disability, marital status, military status, genetic predisposition, or any other basis protected by law.
To stay up to date about new career opportunities:
Follow us on Twitter
Follow us on Instagram
Follow us on LinkedIn

I8pR3c9K0u","$110,670 /yr (est.)",51 to 200 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2013,Unknown / Non-Applicable
"Lockheed Martin
4.1",4.1,"North Charleston, SC",Logistics/Data Quality Engineer,"Job ID: 650844BR
Date posted: Aug. 30, 2023
Program: NCRC-CHS

Description:At Lockheed Martin Rotary and Mission Systems, Cyber Solutions, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and visionary thinking, everything is within our reach - and yours as Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!
We are seeking a Logistics/Data Quality Engineer to support the NCRC Charleston team. In this position the successful candidate will:
Perform Inventory Management using CMPRO
Preparation, review, revision, and maintenance of technical documents including software and systems engineering, system operations, testing, CDRL's, and user documentation.
Writes and edits technical documentation for all of the project's hardware and software to include installation, configuration and how-to documentation
Creates code documentation for software; produces implementation guides and end-user guides for capabilities; provides field, data definition, and data flow documentation and formats technical publications from pamphlets, technical drawings, and consultations with technical personnel and other available resources
Basic Qualifications:
Bachelor's degree in a technical or business discipline from an accredited college or university is required. Four (4) years of additional experience may be substituted for a bachelor's degree.
Experience with CMPRO Product Lifecycle Management
Expert level knowledge of MS Office tools
Understand basic concepts (to include basic grammar concepts), responsible for writing technical copy for various types of documents
Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.
Clearance Level: TS/SCI
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: Non- standard 40 hour work week as assigned by leader
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.
Experience Level: 4 yr and up College
Business Unit: RMS
Relocation Available: No
Career Area: Cyber Security
Type: Task Order/IDIQ
Shift: First",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1995,$10+ billion (USD)
"City of Burbank
4.3",4.3,"Burbank, CA",PRINCIPAL DATA ENGINEER,"JOB
Nestled between the Hollywood Hills and the Verdugo Mountains in the heart of Los Angeles County lies the City of Burbank, the “Media Capital of the World”. Burbank’s entertainment base is anchored by some of the biggest names in the business, including, among others, Walt Disney Studios, Warner Bros., ABC, iHeart Radio, Nickelodeon Animation, and Netflix Animation. Burbank is well-known for its strong sense of community and its superior City services. The City of Burbank workforce is powered by incredible people and teams who are committed to ensuring that the level of service Burbank is known for, remains unparalleled. The City of Burbank IT Department is seeking a Principal Data Engineer who will lead the data and analytics practice for the City, including planning, designing, creating and managing the organization’s data architecture, data pipeline strategy, and other data related programs. The Principal Data Engineer will perform a key role in helping the City to realize greater value from the data they possess, close gaps to create efficient digitized services, and leverage data and data driven insights to improve City services. OPEN COMPETITIVE RECRUITMENTOpen to all qualified candidates. Tentative examination dates for this recruitment: Week of 10/06/23- Blind application and supplemental scoring Week of 10/25/23 - Oral interviewDates may change due to unforeseen circumstances. Candidates who pass each phase of the recruitment process will be notified of the official examination dates.Under general direction, to act as a subject matter expert in a self-directed position; lead data and analytics initiatives for the City's digital business mission to include planning, designing, creating, deploying, and managing the organization's data architecture, data pipeline strategy and data related programs; and perform related work as required.

EXAMPLE OF DUTIES
Designs, creates, implements, and manages the City's enterprise data architecture by using relevant tools; integrates data architecture with business processes amongst cross functional business areas aligning with overall data architecture; builds, optimizes, and manages reusable data pipelines and data analytics solutions through successful production deployment; maintains complex databases; controls access methods, access time, device allocation, validation checks, organization, protection and security, and documentation and statistical methods; analyzes database needs of the organization; evaluates, designs, and implements database systems; formulates database strategies, policies, and procedures; ensures accuracy and completeness data in master files and various support tools; monitors and resolves database problems; performs validation checks; optimizes database performance; evaluates and promotes new technologies in database management; advises management on database concepts and functional capabilities; serves as key business liaison in operationalizing data and analytics on behalf of business stakeholders to plan and deliver optimal analytics and data science solutions for the City; automates and optimizes data pipelines, data flows, and data consumption with structured and unstructured data from different sources; builds processes supporting data transformation, data structures, metadata, and data stores; integrates data managed by heterogeneous systems, as well as any applications using or processing that data; supports data scientists, developers, business analysts, and database administrators in providing optimal data technology solutions; organizes data at a macro and micro level; addresses data infrastructure issues relating to velocity, variety, and volume of data; develops a logical data model as a standard for consuming applications; maps systems and interfaces used to manage data; sets standards for data management; analyzes current state and conceives desired future state, and conceives projects needed to address deficiencies between current state and future goals; participates in working groups and advisory committees related to data and database administration for innovative and proof of concept solutions; collaborates organization-wide to build and deliver analytic tools for users, stakeholders, and staff to provide actionable insight into the use of data, business performance metrics, and other relevant business objectives; manages department/Citywide data projects; recommends or defines the physical structure and functional capabilities of databases; ensures reliable interaction and interdependency of multiple database systems; administers databases for multi-system and highly complex commercial off-the-shelf (COTS) applications; sets data quality assurance policies and practices; ensures compliance and governance in data use; participates in working groups, and advisory committees related to data administration; performs related duties as required; supervises, trains, and evaluates employees; makes effective recommendations regarding hiring, promotions, transfers, and disciplinary action as needed up to and including termination; drives on City business.

SUPPLEMENTAL INFORMATION
None.","$135,352 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Palo Alto Networks
4.2",4.2,"Santa Clara, CA",Sr Principal Software Engineer (Data Plane),"Company Description

Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
FLEXWORK is an employee-centric reimagining of how we work. We built FLEXWORK based on employee feedback – it is about flexibility, trust, and choice whenever possible. It’s been a journey of disruption that has yielded the best of our values. We offer as much flexibility as possible, and choices that enable you to be most productive, including benefits that meet your needs and learning opportunities that you feel passionate about.
Our Approach to Work
At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!

Job Description

Your Career
As part of the Network Security data plane team, you are responsible for developing and innovating solutions for Palo Alto Networks next-generation Firewalls and Prisma Access Cloud. Specifically in the areas of network security, high throughput networking, next generation cluster and data plane architecture.
You will also be responsible for innovation, developing proof of concept and productizing 'new' ideas by implementing them and collaborating with team members.
Your Impact
Responsible for development of NextGen Network Security Components and Protocols for State-of-the-art firewalls deployed at Enterprise, Data Center, Public/Private Cloud, and Service Provider environments
Development of features and architecture for NextGen Security Hardware and Virtual platforms in areas of Network Security/Threats and stateful TCP/UDP inspection
Develop scalable flow architecture for packet processing pipeline for multi-core platforms
Develop scalable software solutions for a distributed session architecture spanning across a cluster of firewalls
Work with multi-functional team members on feature requirements, including but not limited to Product Management, QA, Support, etc
Product visionary, ideas on competitive edge, Effective decision maker, take ownership and independently drive, lead tasks and assignments

Qualifications

Your Experience
BS Degree in Computer Science and 10 plus years of work experience or and MS Degree in Computer Science with 8 plus years experience or equivalent military experience required
Proficient coding skills in C/C++/Python and large scale software development on Unix/Linux
Strong technical knowledge in computer architecture and operating systems
Strong experience in packet processing, networking (L2-L4) protocols - TCP/UDP/IP
Good understanding in IPSec/IKE
Experience in performance tuning of datapath
Experience in DPDK and performance tuning is desired
Can-do attitude and ability to take initiative and drive open issues to completion
Good communication skills to work effectively with multi-functional groups

Additional Information

The Team
To stay ahead of the curve, it’s critical to know where the curve is, and how to anticipate the changes we’re facing. For the fastest growing cybersecurity company, the curve is the evolution of cyberattacks, and the products and services that proactively address them. Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. They are constantly innovating – challenging the way we, and the industry, think about cybersecurity. These engineers aren’t shy about creating products to solve problems no one has tackled before. They define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Our engineering team is provided with an unrivaled opportunity to build the products and practices that will support our company growth over the next decade, defining the cybersecurity industry as we know it. If you see the potential of how incredible people products can transform a business, this is the team for you. If you don’t wait for directions, instead, identifying new features and opportunities we have to just get better, this is your new career.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000/yr to $275,000/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
#LI-134726041_SS2","$222,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
"Penske Truck Leasing and Logistics
3.6",3.6,"Reading, PA",ML Engineer - Data & Advanced Analytics,"As the Machine Learning Engineer working in Penske’s Advanced Analytics team, you will be in a high impact role. You will be supporting multiple businesses and functions within Penske with their data science initiatives. You will play a key role in maturing the AI/ML Ops at Penske organization. This is a great opportunity for someone who has some machine learning experience or planning to switch to machine learning as a career choice.
Responsibilities
As part of Penske’s Advanced Analytics team you will be responsible for implementation and operationalization of AI/ML models. You will work with other machine learning engineers, data scientists, software engineers and platform engineers to ensure success of the AI/ML implementations at Penske. Specific responsibilities will include:
Support data scientists with AI/ML model development and deployment with an emphasis on auditability, versioning, and data security.
Build and implement applications which makes use of AI/ML models
Work with data scientists to ensure ML models are performing with-in the expected ranges of accuracy
Lead Self Service AI (SSAI) initiatives by supporting the citizen data scientists across Penske
Support AI/ML platforms like Sage Maker, SAS Viya or Dataiku
Design data pipelines and engineering infrastructure to support our enterprise machine learning systems
Apply software engineering rigor and best practices to machine learning, including AI/MLOPs, CI/CD, automation, etc.
Facilitate the development and deployment of proof-of-concept machine learning systems.
Develop and deploy scalable tools and services for our clients to handle machine learning training and inference.
Take offline models data scientists build and turn them into a real machine learning production system.
Requirements
Bachelor’s Degree in Computer Science/Computer Engineering or equivalent years of experience.
1-3 years of experience developing software applications.
Experience in technologies, frameworks and architecture like Java or Python, Angular, React, Spring, Spring Boot, XML, JavaScript, JSON, Application Servers, CI/CD is required.
Experience in designing and building Web Applications, REST APIs is required.
Expertise in Relational Databases, MySQL, In-Memory databases, NoSQL databases, AWS is a significant plus.
Experience using AI/ML platforms such as Sage Maker, SAS Viya or Dataiku to deploy Models is a significant plus but not required.
Ability to identify and evaluate new technologies to improve performance, maintainability, and reliability of our machine learning systems.
Understanding of the full system development lifecycle.
Ability to work in a team environment and seek guidance on tasks from senior developers and leads.
Regular, predictable, full attendance is an essential function of the job.
Must be a team player with Team First attitude. Must be willing and able to contribute to brainstorming sessions in a meaningful way.
Willingness to travel as necessary, work the required schedule, work at the specific location required, complete Penske employment application, submit to a background investigation (to include past employment, education, and criminal history) and drug screening are required.
Penske Qualifications:
Bachelor’s Degree in Computer Science/Computer Engineering or equivalent years of experience.
1-3 years of experience developing software applications and exposure to Machine Learning
Experience in technologies, frameworks, architecture, and design patterns.
Strong coding skills in languages like Python and software engineering best practices.
Experience in designing and building REST APIs and Microservices is required.
Experience with Relational Databases, MySQL, In-Memory databases, NoSQL databases and writing SQL queries.
Experience with AWS cloud technologies is a significant plus.
Understanding of Machine Learning concepts, MLOps and experience using AI/ML platforms such as Dataiku, Sage Maker, or SAS Viya is a plus but not required.
As part of Advanced Analytics team you will be responsible for implementation and operationalization of Self-Service AI Models.
Experience customizing Conversation AI platforms is a plus.
Ability to identify and evaluate new technologies to improve performance, maintainability, and reliability of our machine learning systems.
Design data pipelines and engineering infrastructure to support our enterprise machine learning systems at scale is a significant plus
Apply software engineering rigor and best practices to machine learning, including AI/MLOPs, CI/CD, automation, etc. is a significant plus.
Support model development, with an emphasis on auditability, versioning, and data security.
Facilitate the development and deployment of proof-of-concept machine learning systems.
Develop and deploy scalable tools and services for our clients to handle machine learning training and inference.
Take offline models data scientists build and turn them into a real machine learning production system.
Ability to work in a team environment and seek guidance on tasks from senior developers and leads.
Regular, predictable, full attendance is an essential function of the job
Must be a team player with Team First attitude. Must be willing and able to contribute to brainstorming sessions in a meaningful way.
Willingness to travel as necessary, work the required schedule, work at the specific location required, complete Penske employment application, submit to a background investigation (to include past employment, education, and criminal history) and drug screening are required.
Physical Requirements:
The physical and mental demands described here are representative of those that must be met by an associate to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The associate will be required to: read; communicate verbally and/or in written form; remember and analyze certain information; and remember and understand certain instructions or guidelines.
While performing the duties of this job, the associate may be required to stand, walk, and sit. The associate is frequently required to use hands to touch, handle, and feel, and to reach with hands and arms. The associate must be able to occasionally lift and/or move up to 25lbs/12kg.
Specific vision abilities required by this job include close vision, distance vision, peripheral vision, depth perception and the ability to adjust focus.
Penske is an Equal Opportunity Employer.
About Penske Truck Leasing
Penske Truck Leasing Co., L.P., headquartered in Reading, Pennsylvania, is a partnership of Penske Corporation, Penske Automotive Group and Mitsui & Co., Ltd. A leading global transportation services provider, Penske operates a premier fleet of vehicles and serves its customers from locations in North America, South America, Europe, Australia, and Asia. Penske’s product lines include full-service truck leasing, contract maintenance, commercial and consumer truck rentals, used truck sales, transportation and warehousing management and supply chain management solutions. Visit www.GoPenske.com to learn more.
Job Category: Information Technology
Job Family: Analytics & Intelligence
Address: 100 Gundy Drive
Primary Location: US-PA-Reading
Employer: Penske Truck Leasing Co., L.P.
Req ID: 2325643",#N/A,10000+ Employees,Company - Private,Transportation & Logistics,Shipping & Trucking,1969,$5 to $10 billion (USD)
"Oracle
3.9",3.9,"Seattle, WA",Principal Data Engineer- OCI,"Create and maintain optimal data pipeline architecture to drive analytics across the different cloud resources created via the Oracle Cloud Infrastructure platform. Assemble large datasets to facilitate a variety of analyses to derive insights from data pertaining to their OCI resources to solve various inventory, operations, security, and FinOps use cases. Identify, design, and implement OCI resource inventory by implementing a data pipeline, optimizing data delivery, and designing infrastructure for greater scalability.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Java, SQL, and Oracle technologies. Work with the different OCI teams to assist with data-related technical issues and their data infrastructure needs. Create tools and services for analytics, allowing customers to build and optimize analyses that provide insights on resource usage and relationships. Collaborate closely with partners in design and product management to learn complex domains, assess needs, and be a technical advocate for enabling the right infrastructure to answer the the right questions.

Principal Member of Technical Staff - Observability and Developer Lifecycle, Oracle Cloud Infrastructure
The Oracle Cloud Infrastructure (OCI) team can provide you the opportunity to build and operate a suite of massive scale, integrated cloud services in a broadly distributed, multi-tenant cloud environment. OCI is committed to providing the best in cloud products that meet the needs of our customers who are tackling some of the world’s biggest challenges.
We offer unique opportunities for smart, hands-on engineers with the expertise and passion to solve difficult problems in distributed highly available services and virtualized infrastructure. At every level, our engineers have a significant technical and business impact designing and building innovative new systems to power our customer’s business critical applications.
What is Observability and Developer Lifecycle Group at OCI?
The Observability organization at Oracle's Cloud is building new services from scratch that operate at high scale in a broadly distributed multi-tenant cloud environment. In the observability space, we are addressing complex, large scale and connected event platforms that manifests as the following services - Logging, Monitoring and Event Correlation, CMDB services. These services are cornerstones of the DevOps capabilities offered by OCI and offer a wide variety of technical problems to be solved and customer focused innovations to be created.
https://www.oracle.com/cloud/products.html
Who are we looking for?
We are looking for engineers with distributed systems experience. You should have experience with the design of major features and launching them into production. You’ve operated high-scale services and understand how to make them more resilient. You work on most projects and tasks independently. You have experience working with services that require data to travel long distances, but have to abide by compliance and regulations.
The ideal candidate will own the software design and development for major components of Oracle’s Cloud Infrastructure. You should be both a rock-solid coder and a data engineer, able to dive deep into any part of the stack and low-level systems, as well as design a highly available/scalable data pipeline. You should value simplicity and scale, work comfortably in a collaborative, agile environment, and be excited to learn.
What are the biggest challenges for the team?
The team is building a brand new service.The dynamic and fast growth of the business is driving us to build brand new innovative technologies. We understand that software is living and needs investment. The challenge is making the right tradeoffs, communicating those decisions effectively, and crisp execution.
We need engineers who can build services that can reliably protect our customer cloud environment. We need engineers who can figure out how we can keep up our solution in a fast pace to securely protect our customers. We need engineers who can build services that enable us to offer even more options to customers and contribute to the overall growth of Oracle Cloud.
Required Qualifications
BS or MS degree in Computer Science or relevant technical field involving coding or equivalent practical experience
8+ years of total experience in software development
4+ years experience preferred with coding: SQL, PL/SQL, ETL and performance tuning
3+ years experience preferred in Application Development in a Cloud /DevOps Environment, e.g. Grafana, Octo, APEX
3+ years experience preferred in data modeling, data integration, and engineering for Reporting solutions e.g. OBIEE/OAC , Grafana
Ability to quickly learn new technologies, especially in a dynamic Cloud infrastructure
Good organization, communication, and interpersonal skills, good team player
Ability to work with geographically distributed teams and timezones.
Prior experience with Agile Methodologies
Preferred Qualifications
Hands-on experience developing and maintaining services on a public cloud platform (e.g., AWS, Azure, Oracle)
Experience with Oracle suite of Cloud products and services including APEX, Oracle Database, Oracle Autonomous Data Warehouse (ADW), Oracle Analytics Cloud (OAC), Oracle Data Integration Services, Oracle Data Science Services and APIs
Hands-on experience working with and coding solutions with cloud technologies and environments (OCI, AWS, Azure, GCP)","$162,429 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
"EY
3.9",3.9,"McLean, VA",Government and Public Sector - Data Engineer - Senior Consultant - TS/SCI FS Poly,"EY focuses on high-ethical standards and integrity among its employees and expects all candidates to demonstrate these qualities. At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

Government and Public Sector – Data Engineer – Senior

From strategy to execution, the Government and Public Sector practice of Ernst & Young LLP provides a full range of consulting and audit services to help our Federal, State, Local and Education clients implement new ideas to help achieve their mission outcomes. We deliver real change and measurable results through our diverse, high-performing teams, quality work at the highest professional standards, operational know-how from across our global organization, and creative and bold ideas that drive innovation. We enable our government clients to achieve their mission of protecting the nation and serving the people; increasing public safety; improving healthcare for our military, veterans, and citizens; delivering essential public services; and helping those in need. EY is ready to help our government build a better working world.

EY delivers unparalleled service in big data, business intelligence, and digital analytics built on a blend of custom-developed methods related to customer analytics, data visualization, and optimization. We leverage best practices and a high degree of business acumen that has been compiled over years of experience to ensure the highest level of execution and satisfaction for our clients. At EY, our methods are not tied to any specific platforms but rather arrived at by analyzing business needs and making sure that the solutions delivered meet all client goals.

The opportunity

You will help our clients navigate the complex world of modern data engineering and analytics. We'll look to you to provide our clients with a unique business perspective on how data science and analytics can transform and improve their entire organization – starting with key business issues they face. This is a high growth, high visibility area with plenty of opportunities to enhance your skillset and build your career.

Our Data Engineer opportunity requires skills working with AWS and hands on-experience implementing API workflow, event driven automation, autonomous infrastructure or autonomous software processes and workflows. Its imperative to have knowledge of multi-environment automation tooling, pipeline deployments or software application integration.
This role supports a mission critical development and sustainment for design, build and delivery of network operations to include cyber capabilities. Additionally, providing technical expertise to develop advanced cloud-orientated automation. You will also work with data consumers to meet specific requirements of a given data-related task.

Your key responsibilities

You'll spend most of your time working with your client(s) to deliver the latest data focused technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich, and analyze data from multiple sources. As a Data Engineer, you will be responsible for designing, developing, and maintaining data processing systems and data pipelines. You will also be working with large datasets, optimizing data storage, and ensuring data quality.

Skills and attributes for success

Design, develop, and maintain data processing systems and data pipelines that can handle large datasets
Work with Stakeholders to determine data requirements and implement solutions to meet those needs
Develop and maintain ETL workflows to move and transform data across different systems and platforms
Optimize data storage and retrieval to ensure system efficiency and scalability
Monitor data processing systems to ensure data quality and troubleshoot any issues that arise
Collaborate with data scientists, analysts, and other team members to ensure data solutions meet business needs
Stay up to date with industry trends and advancements in data processing technologies
Evaluate existing data architectures and recommend improvements to optimize data infrastructure
Experience on projects utilizing continuous delivery and deployment methodologies a plus
Experience leading data engineering efforts
Ability to estimate and plan data engineering efforts
Effective management skills
Exemplary leader

To qualify for the role, you must have

MUST have a TS/SCI Full Scope Poly Clearance
Bachelor's or Master's Degree in computer science or related field
3-5+ years of professional related experience in data engineering, with a focus on processing large datasets
2+ years of hands-on experience with Databricks Lakehouse Platform
Proficiency in programming languages such as Python or Java
Experience with big data processing technologies such as Hadoop, Spark or AWS
Solid understanding of data modeling, data warehousing, and data management principles
Excellent problem-solving skills and attention to detail
Strong communication and collaboration skills, with the ability to work effectively in a team environment
DoD or government experienced is highly preferred
Experience designing, building, and maintenance of data architecture
Administration of database and systems in the data architecture
Experience with design and build of ETL programs, interfaces, and data reconciliation processes
Management of information assurance and data governance requirements
End-user support for data reconciliation and interface validation
Experience developing reports and dashboards for data consumers
Must be willing to work on-site in the greater Washington, DC metro area including McLean, Reston and Chantilly, VA (this position is 100% on-site, no hybrid or remote options)

Ideally, you'll also have

Thorough business understanding of data science application and ability to communicate with key decision-makers
Communication is essential, must be able to listen and understand the question and develop and deliver clear insights.
Due to the nature of our work in the Government and Public Sector, work may be required to be completed at client, EY and/or contractor sites. Our goal is to assign professionals to projects within a commutable distance of their work location office. In certain circumstances, travel may be required beyond your work location based on client and project needs. Candidates should be willing to travel 20 – 30% or more

What we look for

We're interested in passionate leaders with strong vision and a desire to stay on top of trends in the Data Science and Big Data industry. If you have a genuine passion for helping businesses achieve the full potential of their data, this role is for you.

What we offer
We offer a comprehensive compensation and benefits package where you’ll be rewarded based on your performance and recognized for the value you bring to the business. The salary range for this job in most geographic locations in the US is $88,300 to $145,800. The salary range for New York City Metro Area, Washington State and California (excluding Sacramento) is $106,000 to $165,600. Individual salaries within those ranges are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and geography. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Under our flexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances. You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, financial, and emotional well-being.
Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.
Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.
Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.
Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.
If you can demonstrate that you meet the criteria above, please contact us as soon as possible.
The exceptional EY experience. It’s yours to build.
EY | Building a better working world
EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.
Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.
Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.
EY is an equal opportunity, affirmative action employer providing equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law.
EY is committed to providing reasonable accommodation to individuals with disabilities. If you are a qualified individual with a disability and either need assistance applying online or need to request an accommodation during the interview process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY’s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com.","$97,870 /yr (est.)",Unknown,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"EvolutionIQ
4.8",4.8,"Boston, MA","Staff Software Engineer, Data Platform Lead (AI / Insurtech)","About us: EvolutionIQ's mission is to improve the lives of injured and disabled workers and enable them to return to the workforce, saving billions of dollars in avoidable costs and lost productivity to the US and global economies and make insurance more affordable for everyone. We are currently experiencing massive growth and to accomplish our goals, we are hiring world-class talent who want to help build and scale internally, and transform the insurance space. We're backed by First Round Capital, FirstMark Capital, Foundation Capital, Brewer Lane Ventures, and have been named as Inc.'s top places to work!
Our Team: We are founded by a senior Google AI expert and a Bridgewater Associates Algorithmic Investor & Stanford MBA. We're not looking for employees. We're looking for partners in work, partners in culture-building, and partners in the future of data-driven insurance. The development team consists of world class engineers and leaders from companies like Google and Bloomberg. Each individual has had great success building large scale enterprise software and is now excited to try their hand at transforming the insurance industry.
Job Summary: We are looking for a Lead Engineer for our Data Platforms who will play an integral role in securing, architecting, and managing our highly sensitive insurance data. This position is tasked with overseeing our foundational datasets, data models, and analytics. The ideal candidate will have considerable experience in creating and managing secure data platforms, a strong engineering background, and a demonstrated record of technical leadership and effective communication.
In this critical role, you will not only ensure the robustness and reliability of our data systems, but also their security and compliance with stringent industry regulations. You will navigate the complexities of insurance data, bringing technical excellence and a security-first approach to safeguard our information assets. Your keen eye for security will be instrumental in protecting our company, customers, and stakeholders, while your technical expertise will shape the future of our data platform architecture.
Key Responsibilities:
Architect, design, and implement robust, secure, scalable, and high-quality data platforms, ensuring the availability, integrity, and confidentiality of the information.
Lead the development and maintenance of data pipelines, including personally coding and building the most critical components.
Work closely with product engineers, data scientists, analysts, and other stakeholders to understand data needs and deliver on those needs.
Define, design, and improve foundational data models to be used across the company to enable feature development and analytics.
Continuously improve our data quality toolkit
Provide guidance and technical leadership to the data engineering team, promoting continual team growth and individual team member skill development.
Be a role model for all engineers and provide mentorship as needed
Drive proof of concepts and experiments to explore new technologies that can level up the entire organization
Requirements:
7+ years of industry experience, holding staff/principal/lead level roles in Software Engineer or Data Engineer, with a focus in building scalable, mission critical, data platforms
Strong written and verbal communication skills
Extensive Python development experience
Experience with distributed data/computing tools, such as: Spark, Airflow, dbt
Proven track record of establishing engineering best practices for both coding and architecture
Experience building out systems and processes to enable secure handling of highly sensitive data
Experience using modern big data storage technologies such as Apache Parquet or Avro
Strong familiarity with modern data warehouse such as BigQuery or Snowflake
Ambitious, collaborative, and empathetic values
Even Better if You Have:
You have at least 3+ years experience in deploying systems on GCP or AWS
Experience with MLOps, such as feature engineering and model serving
You have worked with Dagster/Airflow, BigQuery, GCP, Terraform, Kubernetes, sklearn, keras/TensorFlow/pytorch, dbt, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions
The Fit: We're a team of architects and visionaries who thrive on being first. We've created a fun, passionate, humorous, friendly, and fiercely-driven engineering culture that values delivery and personal impact above everything else. We are open to sponsoring candidates who currently are in the US and need to transfer their active H1-B visa.
Work-life, Culture & Perks:
Compensation: The range is $210-240K depending on a candidate's background and experience.
Well-Being: Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%
Work/Life Balance: We would consider hiring the team member remote if they bring strong experience. We also have a flexible vacation policy and are closed for winter break at the end of the year.
Home & Family: Flexible PTO, 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn
We also have a flexible vacation policy and are closed for winter break at the end of the year
Office Life: Catered lunches, happy hours, and pet-friendly office space. $500 for your in home office setup and $200/year for upgrades every year after your initial setup
Growth & Training: $1,000/year for each employee for professional development, as well as upskilling opportunities internally
Sponsorship: We are open to sponsoring candidates currently in the U.S. who need to transfer their active H1-B visa

EvolutionIQ appreciates your interest in our company as a place of employment. EvolutionIQ is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees","$118,602 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2019,$25 to $100 million (USD)
"Oracle
3.9",3.9,"Seattle, WA",Senior Data Engineer OCI,"Create and maintain optimal data pipeline architecture to drive analytics across the different cloud resources created via the Oracle Cloud Infrastructure platform. Assemble large datasets to facilitate a variety of analyses to derive insights from data pertaining to their OCI resources to solve various inventory, operations, security, and FinOps use cases. Identify, design, and implement OCI resource inventory by implementing a data pipeline, optimizing data delivery, and designing infrastructure for greater scalability.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Java, SQL, and Oracle technologies. Work with the different OCI teams to assist with data-related technical issues and their data infrastructure needs. Create tools and services for analytics, allowing customers to build and optimize analyses that provide insights on resource usage and relationships. Collaborate closely with partners in design and product management to learn complex domains, assess needs, and be a technical advocate for enabling the right infrastructure to answer the the right questions.

Senior Data Engineer - Observability and Developer Lifecycle, Oracle Cloud Infrastructure
The Oracle Cloud Infrastructure (OCI) team can provide you the opportunity to build and operate a suite of massive scale, integrated cloud services in a broadly distributed, multi-tenant cloud environment. OCI is committed to providing the best in cloud products that meet the needs of our customers who are tackling some of the world’s biggest challenges.
We offer unique opportunities for smart, hands-on engineers with the expertise and passion to solve difficult problems in distributed highly available services and virtualized infrastructure. At every level, our engineers have a significant technical and business impact designing and building innovative new systems to power our customer’s business critical applications.
What is Observability and Developer Lifecycle Group at OCI?
The Observability organization at Oracle's Cloud is building new services from scratch that operate at high scale in a broadly distributed multi-tenant cloud environment. In the observability space, we are addressing complex, large scale and connected event platforms that manifests as the following services - Logging, Monitoring and Event Correlation, CMDB services. These services are cornerstones of the DevOps capabilities offered by OCI and offer a wide variety of technical problems to be solved and customer focused innovations to be created.
https://www.oracle.com/cloud/products.html
Who are we looking for?
We are looking for engineers with Data Engineering experience. You should have experience with the design of major features and launching them into production. You’ve operated high-scale services and understand how to make them more resilient. You work on most projects and tasks independently. You have experience working with services that require data to travel long distances but have to abide by compliance and regulations.
The ideal candidate will own the software design and development for major components of Oracle’s Cloud Infrastructure. You should be both a rock-solid coder and a data engineer, able to dive deep into any part of the stack and low-level systems, as well as design a highly available/scalable data pipeline. You should value simplicity and scale, work comfortably in a collaborative, agile environment, and be excited to learn.
What are the biggest challenges for the team?
The team is building a brand-new service. The dynamic and fast growth of the business is driving us to build brand-new innovative technologies. We understand that software is living and needs investment. The challenge is making the right tradeoffs, communicating those decisions effectively, and crisp execution.
We need data engineers who can build data pipelines and services that will provide our customers with meaningful insights about the cloud infrastructure. We need engineers who can deliver highly secure solutions at a fast pace. We need engineers who can build services that enable us to offer even more options to customers and contribute to the overall growth of Oracle Cloud.
Required Qualifications
BA, Master's or PhD degree in Computer Science, Statistics, Informatics, Information Systems, or a related field.
3+ years of Data engineering experience in a fast-paced software development environment
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, and workload management.
A successful history of processing and extracting value from large, disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with object-oriented/object function languages: Python, Java, Scala, etc.
Experience utilizing cloud services to monitor, store, and compute data as part of a pipeline development lifecycle.
Experience building multi-tenant, virtualized infrastructure a strong plus
Preferred Qualifications
Hands-on experience developing services on a public cloud platform (e.g., AWS, Azure, Oracle)
Building continuous integration/deployment pipelines with robust testing and deployment schedules
Experience with Oracle Data Warehouse and Analytics and other big data technologies","$144,790 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
"Google
4.4",4.4,"Omaha, NE","Data Center Engineer, Mechanical, Google Data Centers","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Council Bluffs, IA, USA; Omaha, NE, USA.
Minimum qualifications:
Bachelor's degree in Engineering, related technical field, or equivalent practical experience.
5 years of experience in the design-build environment for mission critical facilities (e.g., data centers, power plants, industrial, etc).
Experience in estimating, mechanical design, operation and commissioning of central utility plants, water processing systems, air distribution systems, and PLC/SCADA controls systems.

Professional Engineering License.
Experience with project total cost of ownership (TCO).
Construction administration or construction management experience.
Experience with large-scale mission critical facilities' mechanical infrastructure systems.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
In this role, you will have a primary focus on providing a deep technical understanding of Google’s data center design to field execution and operations teams in support of their initiatives. You will also support other teams in the development and evaluation of conceptual design.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.

The US base salary range for this full-time position is $136,000-$203,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities
Participate in the project specific design review process including conceptualizing ways to reduce total cost of ownership (TCO) while maintaining Google standards.
Coordinate with consulting engineers preparing construction documents as they develop detailed documentation based on the conceptual design standards developed and provided by others internally.
Work with the general contractor (GC) to develop a high level understanding of the design intent and on-time development of coordinated design details and delegated design elements in alignment with Google standards.
Monitor work in the field to ensure it is being executed in line with Google’s design intent and standards, as well as meeting the local codes and requirements.
Support systems startup and commissioning processes by providing a technical understanding of the gear being installed and how the systems are designed to function.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"Johns Hopkins Applied Physics Laboratory (APL)
4.2",4.2,"Laurel, MD",2024 PhD Graduate - AI/ML Data Scientist/Engineer - Analytic Capabilities,"Description

Are you searching for a place to build upon the foundation of your academic work?
Are you searching for engaging work with an employer that prioritizes impact, innovation, and personal development?
Are you motivated to apply your skills within a vibrant intellectual community?
If so, we're looking for someone like you to join our team at APL!
We are seeking recent college graduates to help us tackle the complex research, engineering, and analytical problems that present critical challenges to our nation. Our group is currently making critical contributions in the fight against online misinformation and development of the first truly autonomous UAV. Our work on the public health response to the COVID-19 pandemic was recognized by Time Magazine as one of the ""Best Inventions of 2020"". To address these emerging national challenges, we design and develop software systems that leverage the potential of data science, generative AI, large language models, and artificial intelligence across various domains, including social media analysis, healthcare, climate monitoring, cybersecurity, and signal & image processing.
As a member of our team you will...
Collaborate with dedicated colleagues in developing solutions that align with national priorities.
Harness your expertise in areas such as Artificial Intelligence, Machine Learning, Data Science, Cybersecurity, Software Engineering & DevOps, Signal and Image Processing, and Mathematics.


Qualifications

You meet our minimum qualifications for the job if you...
Have a PhD in Computer Science, Mathematics, Engineering, or related technical field.
Have maintained a minimum 3.0/4.0 GPA

Are able to obtain a Top Secret level security clearance. If selected, a government security clearance investigation will need to be conducted and the requirements met for access to classified information. Eligibility requirements include U.S. citizenship.

Why work at APL?
The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation’s most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates.

At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL’s campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers.


About Us

APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law.

APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.","$101,464 /yr (est.)",5001 to 10000 Employees,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,1942,$1 to $5 billion (USD)
"Onebridge
3.9",3.9,"Indianapolis, IN",MDM Data Engineer,"Onebridge is a Consulting firm with an HQ in Indianapolis, and clients dispersed throughout the United States and beyond. We have an exciting opportunity for a highly skilled MDM Data Engineer to join an innovative and dynamic group of professionals at a company rated among the top “Best Places to Work” in Indianapolis since 2015.
This role could be a full-time position on our team – or we would be open to engaging a consultant seeking their next contract experience.
MDM Data Engineer | About You
As an MDM Data Engineer, you are responsible for organizing and executing a Data Enablement program through project planning activities, cross-system coordination, and completion of deliverables. You are comfortable working with a team of data professionals to establish data management best practices and deliver high-quality data and information at scale to a wide variety of clients and industries. You are a strategic thinker who understands the impact that data quality can have on advancing an organization's BI Maturity, and you find excitement in building enterprise solutions to achieve an integrated data strategy.

MDM Data Engineer | Day-to-Day

Engineer end-to-end MDM solutions, including integration patterns (with operational and analytic systems), workflows, policies, support, and reporting associated with an enterprise MDM capability.
Develop and refine approved data models for enterprise integration.
Establish and improve relevant standards and governance.
Develop Master Data Management (MDM) technology-enabled solutions that address the needs of clients, including the design, automation, and orchestration of enterprise Master and Reference Data.
Use data quality tools to profile, cleanse, standardize, and enrich data.
Analyze problems and opportunities and their impacts on the business by considering all fact-based and stakeholder information to evaluate alternatives.
Define and implement data strategy, policies, controls, and programs to ensure the enterprise data are accurate, complete, secure, and reliable.
MDM Data Engineer | Skills & Experience

7+ years of progressive experience in Master Data Management (MDM) solution design, development, and implementation, with additional expertise in Reference Data Management, Data Governance, Data Management, Analytics, and Technology.
Support and maintain the MDM architecture by understanding the interaction of business processes with data entities/elements and ensuring the integrity of the MDM system.
Expertise working in a complex matrixed environment.
Expert-level SQL Skills.
Possess the ability to solve, design, and lead the implementation of MDM platforms and individual components.
Deep understanding of bi-directional MDM and the role it plays in an effective Data Management Strategy.
Skilled in working with at least one modern MDM platform, with knowledge of best-in-class options.
100% Employee-Owned & a Best Place to Work in Indiana, since 2015.","$103,378 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,Unknown / Non-Applicable
"CAI
3.9",3.9,"Charlotte, NC","Mechanical Commissioning Engineer II, Data Center Services","CAI seeks Mechanical Commissioning Engineers with a minimum of two years' experience in Data Center Commissioning to support development and execution of all mechanical aspects of commissioning projects.

Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range, not including benefits or compensatory time and possible discretionary bonuses.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.","$102,500 /yr (est.)",501 to 1000 Employees,Company - Private,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1996,$25 to $100 million (USD)
"American Business Solutions INC
3.8",3.8,"Columbus, OH",Data Engineer with Azure,"This position plays an important role in designing and constructing the agency’s data infrastructure using Microsoft Azure. This role will serve as the primary point of contact for the agency’s migration of its on-premises data warehouse and analysis workspace to Microsoft Azure.
The responsibilities and duties include:
Design and develop data infrastructure for the agency in Microsoft Azure
Recommend and implement solutions for data ingestion, ETL, data warehousing, and data analysis.
Manage access to data infrastructure datasets and analysis tools.
Develop budget for Microsoft Azure tools and provide recommendations on where to manage costs.
Build distributed computing analysis environment within Microsoft Azure in order to conduct more thorough analysis and integrate machine learning/AI tools to environment.
Design and develop database solutions using Microsoft SQL Server and Microsoft Azure tools (SSMS, SSRS, SSIS, Azure Data Factory, Azure Storage).
Manage data in variety of methods, to include SQL databases, NoSQL databases, file storage, and blob storage
Works with IT Architecture staff, CIO and/or IT Managers to design solutions that meet agency requirements
Design and implement high availability solutions
Data modeling to define and analyze data requirements for designing databases/data warehouses
Analyze on-premise database installations for Azure migration
Support data lake enterprise business initiatives
Support production and non-production environments incidents and requests
Code, test, debug, implement, and document data infrastructure design, construction, and remediation
Expert knowledge in SQL skills including stored procedure, trigger, index etc.
Experience with change management with respect to people, processes, and technologies
Develop, maintain, and support business applications (SQL/web-based apps)
Streamline and improve internal processes and reporting
Drive efficiency and operational improvement using data modeling techniques
Support and train users by providing directions, corrections, and enhancements; communicate with users to find solution to case
Analyze user requirements, procedures, and problems to provide coaching on system use, recommend changes and automation to improve efficiency
You’ll need the following qualifications and experience:
Bachelor’s degree in an appropriate field of study like Computer Science, Data Science, or Information Technology
Minimum seven years of database administration, data science, data engineering, and/or cloud-based data solution engineering.
Previous relevant experience with Microsoft suite of data solutions
Experience conducting performance tuning and configuration, creating data models, and managing data warehouses.
It’s a strong plus if you have:
Experience with Healthcare/Mental Health environment
Expertise in Python/R programming language
Familiar with reporting tools such as Power BI, Tableau, and Cognos
Collaborate with team leads to identify gaps and constraints associated with business requirements and processes and aid in providing solutions to resolve the process issues
Strong communication and interpersonal skills
Strong organization and time management skills
Ability to effectively handle multiple priorities
Ability to operate across the business and in different environments and cultures
Required/Desired Skills
SkillRequired/DesiredAmountof ExperienceBachelor’s degree in an appropriate fieldRequired0database administration, data science, data engineering, and/or cloud-based data solution engineeringRequired7YearsExpert knowledge in SQL skills including stored procedure, trigger, index etcRequired0Microsoft AzureRequired0Experience with Healthcare/Mental Health environmentNice to have0Expertise in Python/R programming languageNice to have0Familiar with reporting tools such as Power BI, Tableau, and CognosNice to have0
Job Type: Contract
Pay: $75.00 - $85.00 per hour
Experience level:
9 years
Schedule:
8 hour shift
Ability to commute/relocate:
Columbus, OH 43215: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 3 years (Preferred)
Data Engineering: 7 years (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person",$80.00 /hr (est.),51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,#N/A,$5 to $25 million (USD)
"BOEING
3.9",3.9,"Berkeley, MO",Phantom Works Systems Engineer and Data Architect (Experienced OR Lead),"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
Boeing Defense, Space, and Security (BDS) is seeking data architects to join a Digital Engineering team supporting a proprietary program developing next generation systems.

This is an exciting role to understand, architect and integrate data flows across the program lifecycle to create digital system models and digital twins of the as-designed, as-tested, as-built and as-operated product. In this role, you will apply an interdisciplinary, collaborative approach to plan, design, develop, integrate, and verify digital engineering solutions. We’re looking for data architects and integrators with interest and experience in model based engineering, who also have experience in one or more of the following areas: systems engineering, aircraft design, test, production, and product support. You will help build and mature the digital ecosystem, including: realizing the program data architecture, expanding digital threads, growing digital system models, connecting and controlling data, and enabling advanced data analytics.

Digital engineering is changing the way we execute our programs, collaborate with our customers and teammates, and enable advanced downstream capabilities.
Our teams are currently hiring for a broad range of experience levels including; Experienced or Lead Level Systems Engineers.
Primary Responsibilities:
Work across disciplines to model the data architecture of the program
Be the digital engineering focal to multiple aircraft design teams, production teams, verification/validation teams, and/or product support teams.
Develop and implement strategies to integrate data across multiple tools and technologies to create digital threads and enable digital twins.
Guide and coordinate development and deployment of new or revised processes in support of new computing systems, including documentation and training.
Define and validate complex requirements for new hardware and software systems.
Facilitate development of system integration strategies and architectures that promote use of common tools and processes.
Lead development of trade studies and other forms of analysis to formulate optimum solutions for users.
This position is expected to be 100% onsite. The selected candidate will be required to work onsite at one of the listed location options. (St. Louis or Huntsville)
This position requires an active U.S. Secret Security Clearance, for which the U.S. Government requires U.S. Citizenship. (A U.S. Security Clearance that has been active in the past 24 months is considered active)
Special Program Access or other Government Access Requirements are mandatory for this position.
Basic Qualifications (Required Skills and Experience):
A technical bachelor's degree with 5+ years, or MS/MA degree with 2+ years of relevant work experience, or a PhD degree with 1+ years of relevant work experience. A relevant degree is defined as one in a quantitative field such as Computer Science, Statistics, Mathematics, Computer Engineering, Software Engineering, Electrical Engineering, Aerospace Engineering, Physics, Chemistry, Operations Research, Bioinformatics, Economics, Computational Biology, or other technical degree.
Experience developing and documenting architecture using Cameo, or similar Model Based Systems Engineering (MBSE) tools
Ability to work effectively in a team environment and communicate with stakeholders of different backgrounds and skill levels
Preferred Qualifications (Desired Skills and Experience):
5 or more years' related work experience or an equivalent combination of education and experience
Experience with data modeling, ontology, and industry standards for data exchange
Experience with Siemens Product Lifecycle Management Suites
Prior experience in software development and test tools/IDEs (e.g. off the shelf or source code editors, compilers, configuration management tools, requirements management, and source control tools)
Experience in mechanical, structural, or electrical design
Experience with physics-based modeling tools
Experience with production engineering, future manufacturing systems, and/or supplier management
Experience with integration, verification, validation and/or flight test
Experience with product support, logistics, training systems, and/or maintenance systems
Typical Education and Experience:
Experienced Level 3:
Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) and typically 5 or more years' related work experience or an equivalent combination of education and experience (e.g. PhD, Master+3 years' related work experience). In the USA, ABET accreditation is the preferred, although not required, accreditation standard.
Lead Level 4:
Bachelor's degree and typically 9 or more years' experience in an engineering classification or a Master's degree with typically 7 or more years' experience in an engineering classification or a PhD degree with typically 4 or more years' experience in an engineering classification. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.
Relocation:
This position offers relocation based on candidate eligibility.
Drug Free Workplace:
Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies
""At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.
The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.
The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.
Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations.
Summary pay range for Mid-Level 3 Berkeley MO: $97,750 - $132,480
Summary pay range for Lead Level 4 Berkeley MO: $119,850 - $162,150
Summary pay range for Mid-Level 3 Huntsville AL: $97,750 - $132,250
Summary pay range for Lead Level 4 Huntsville AL: $119,850 - $162,150

Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Equal Opportunity Employer:
Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.","$86,177 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1916,$10+ billion (USD)
"HCA Healthcare
3.3",3.3,"Nashville, TN",Principal Data Engineer,"Introduction
Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As a Principal Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Principal Data Engineer to help us reach our goals. Unlock your potential!
Job Summary and Qualifications
HCA Healthcare ITG
Job Summary:
The role requires working closely with others, frequently in a matrixed environment, and with little supervision. As a Principal Data Engineer/Architect level, the role requires 'self-starters' who are proficient in problem solving and capable of bringing clarity to complex situations. It requires contributing to strategic technical direction and system architecture approaches for individual projects and platform migrations. The culture of the organization places an emphasis on teamwork, so social and interpersonal skills are equally important as technical capability. Due to the emerging and fast-evolving nature of GCP/Big Data technology and practice, the position requires that one stay well-informed of technological advancements and be proficient at putting new innovations into effective practice.
Responsible for leading GCP development efforts, driving adoption and appropriate use of technology and consulting on internal and external development efforts to ensure code quality and sound architecture. This position that assumes the responsibility for project success and the upward development of team members technical skills. They are the development team's point of contact that must interface with business partners of varying roles ranging from technical staff to executive leadership. In addition, this candidate will have a history of increasing responsibility in a multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement cutting-edge technical data solutions with minimal supervision.
As a Principal Data Engineer/Architect, you will work closely with all team members to create a modular, scalable solution that addresses current needs, but will also serve as a foundation for future success. The position will be critical in building the team’s engineering practices in test driven development, continuous integration, and automated deployment and is a hands-on team member who actively coaches the team to solve complex problems. She / he will be responsible for the design, development, performance and support of the Cloud Platform components.
This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team (consultant and employee) environment. In addition, the applicant must be willing to train and mentor other developers to prepare them for assuming the responsibilities.
General Responsibilities:
Responsible for building and supporting a GCP/Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
Bring new data sources into GCP/HDFS, transform and load to databases.
Lead projects in delivering the data and projects on-time
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Leads efforts to design, development, deploy, and support software systems
Experience with HL7, FHIR, and Whistle mapping.
Collaborates with business analysts, project lead, management and customers on requirements
Participates in large-scale development projects involving multiple areas outside of core team
Designs fit-for-purpose products to ensure products align to the customer's strategic plans and technology road maps
Demonstrates deep understanding and coaches’ value-based decision making and Agile principles across teams
Coaches team on clinical data, existing system structure, constraints and deficiencies with product
Shares knowledge and experience to contribute to growth of overall team capabilities
Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems
Work closely with management, architects and other teams to develop and implement the projects.
Actively participate in technical group discussions and adopt any new technologies to improve the development and operations.
Focuses on customer satisfaction
Rapidly prototypes and delivers just-in-time solutions
Gather requirements, designs, constructs and delivers solutions with minimal team interaction
Works in an environment with rapidly changing business requirements and priorities
Demonstrates deep understanding and acts as a leader in the team’s continuous integration and continuous delivery automation pipeline
Work collaboratively with Data Scientists, business, and IT leaders throughout the company to understand Cloud/Big Data needs and use cases.
Education, Experience and Certifications:
Bachelor's Degree in computer science or related field – Required
Master's Degree in computer science or related field – Preferred
3+ years of experience in Data Engineer – Required
1+ year(s) of experience in Healthcare – Preferred
10+ years of experience in Information Technology – Required
GCP Cloud Professional Data Architect certification – Preferred
GCP Cloud Professional Data Engineer certification – Preferred
Other Required Qualifications:
A successful candidate will have:

Strong understanding of best practices and standards for GCP application design and implementation.
Two Year of hands-on experience with GCP platform and experience with many of the following components:
GCS, Cloud Run, Cloud Functions
Bigtable, Cloud SQL
Kafka, Pub/Sub
Python, Golang, Spark, Scala or Java
BigQuery, Dataflow, Data Fusion
CICD process and Logging & Monitoring
OpenShift, Docker
Experience with Unstructured Data, Real-Time Streaming with GCP
Ability to multitask and to balance competing priorities.
Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support.
Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.
A successful candidate may have:
Experience in Healthcare Domain
Experience in Patient Data
Experience with Natural Language Processing (NLP)
Azure/AWS Cloud experience
Hands-on experience with Cloudera Distributed Hadoop (CDH)
Hardware/Operating Systems:
Linux, UNIX
GCP
Distributed, highly-scalable processing environments
Databases:
NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies
Build Systems – TFS, Github
Ability to integrate tools outside of the core Cloud ecosystem
Physical Demands/Working Conditions
Prolonged sitting or standing at computer workstation including use of mouse, keyboard, and monitor.
Requires ability to provide after-hours support.
Occasional Travel: The job may require travel from time- to-time, but not on a regular basis.
HCA Healthcare’s Information Technology Group (ITG) delivers healthcare IT products and services to HCA Healthcare's portfolio of business and partners, including Parallon, HealthTrust and Sarah Cannon.

For decades, ITG has been a pioneer in the industry, leading the transformation of healthcare into a new era of quality and connectivity. ITG relies on the breadth of the organization and depth of technical expertise to advance and enhance today’s healthcare and to enable our physicians and clinicians to provide world-class, innovative care for patients.

ITG employees rally around the noble cause of transforming healthcare through technology and find inspiration in the meaningful work they do—creating a culture that follows our mission statement which begins by saying “above all else we are committed to the care and improvement of human life.”

If you want a career in technology and have a heart for healthcare, apply your expertise to a mission that matters.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.
""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
Be a part of an organization that invests in you! We are reviewing applications for our Principal Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$120,425 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
"Wipro Limited
3.1",3.1,"Minneapolis, MN",Data Engineer - Apache Spark,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS
Role – Data Engineer - Apache Spark
Location – Minneapolis, MN (Day 1 onsite)
Yrs. of experience – 10+ Yrs.
Mode of employment – Full-Time

Job Description:
Strong in Spark Scala development (Minimum 5 years of experience).
Especially Persons should have good experience on building ETL pipeline using Scala.
Strong in SQL Concepts and Development
Must have worked on any ETL tool like Data stage, Spark /Scala etc... Preferred Data Stage.
Unix / Python Shell Scripting (Minimum 3 to 4 years)
Strong understanding of Hadoop eco system
Very well versed with Agile Methodology - Scrum boards.
Capable of handling scrum ceremonies in absence of scrum master.
Other tools – Jenkin, Autosys, GitHub, etc..
Any Cloud experience is plus. Preferred Azure

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.

#LI-AK2","$96,774 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1945,$5 to $10 billion (USD)
"Jack In The Box
3.4",3.4,"San Diego, CA",Lead Data Engineer,"Jack in the Box is seeking a Lead Data Engineer who will be responsible to provide analytic and strategic technical leadership & support to the Enterprise Data Team, which is responsible for scaling and maintaining the core data platform and maturing the analytical capabilities of the organization. Contributes to data & engineering innovations facilitating critical business insights that fuel Jack in the Box Inc.s vision and mission.

KEY DUTIES/RESPONSIBILITIES:
Collaborates with functional & business leaders and teams and works closely with the Data Engineering team to manage complex data systems in enabling decision support and key insights across the organization.

Implements data governance practices in partnership with business stakeholders and peers.

Works with a team of high-performing analysts, data engineering professionals and cross-functional teams to identify business opportunities, monitor data platform performance and optimize analytical capabilities.

Builds, evolves and maintains the infrastructure required for optimal transformation and integration from a wide variety of data sources using appropriate data integration technologies. Deploys pipelines using scheduling and orchestration frameworks to support the organizations growing data processing and analytics needs.

Takes ownership of core data pipelines that power the organizations analytical metrics.

Uses data expertise to evolve data models in several components of the data stack & helps architect, build, and launch scalable data pipelines to support the organizations growing data processing and analytics needs.

Creates proof of concepts per business requirements.

QUALIFICATIONS:
Education: Bachelors degree in Engineering, Computer Science, Information Systems or related field.

Experience: 12+ years staff/lead/senior software data engineer experience building and supporting data intensive applications, tackling challenging architectural, scalability and reliability problems. Experience includes working with Data Warehouse, Data Lake, Data Hub and the supporting processes (Data Integration, Governance, Metadata Management).

Skills/Knowledge/Abilities:
Skilled in building and maintaining data quality frameworks, data observability and monitoring frameworks.

Experience in leveraging Observability tools such as Splunk/Datadog/New Relic/MonteCarlo or equivalent.

Extensive experience manipulating and analyzing large data sets.

Experience designing, deploying, and maintaining business application on AWS stack, leveraging services such as EC2, ECS, Lambdas, AWS Step functions, Redshift, Tableau, AWS Glue OR equivalent expertise in other cloud platforms such as Azure, GCP etc. Experience with on-prem & relational platforms Oracle, SQL Server, PostGres , MySQL etc. Integration of cloud services with on premise technologies.

Experience working with DevOps capabilities like version control, automated builds, testing and release management capabilities using tools like Git, Jenkins etc.

Extensive knowledge in application monitoring, handling user tickets, analyzing data issues.

Experience with data modeling, data mining, and predictive analysis. Ability to effectively test and document work.

Possesses excellent interpersonal, communication, and problem solving skills.

Ability to juggle multiple projects, tasks, and deadlines.

Strong understanding of SQL and NOSQL database concepts.

Strong experience with advanced analytics tools for Object-oriented/scripting languages such as R, Python, Java, Scala, or others.

Comfortable working in an unstructured environment, taking ownership for results and self-directing your efforts to the subject areas and questions which have the greatest potential impact on the business. Comfortable working in an agile environment

Proven track record of being personally accountable for the analysis and technical enhancements that drive a business at a large scale.

Skilled in building reports and dashboards through the use of dashboarding tools like Tableau, PowerBI, Quicksight, Looker.

Will be a self-starter, initiate and drive projects to completion with minimal guidance.

PHYSICAL REQUIREMENTS:
Ability to speak/hear clearly in person and on the telephone and ability to operate a computer (desktop, tablet, etc.).

REASONABLE ACCOMMODATION:
Jack in the Box, Inc. and its affiliates will make reasonable accommodations to allow a qualified individual with a disability to enjoy equal employment opportunities and to perform the essential functions of the job. This position description should be applied accordingly. This description of duties is not intended to be all-inclusive or to limit managements discretion to assign other duties or responsibilities as necessary.

Jack in the Box Inc. offers a competitive salary and Total Rewards package that includes: medical, dental, vision, Health Savings Account (HSA), Flexible Spending Account (FSA), Life and Disability Plans, 401(k) plan with company match, Legal Plan, Pet Insurance, Tuition Reimbursement, and Employee Assistance Program.

Our culture is fun and innovative Work Happy with us!

The range for this position is $149,700 - $208,500 and is based on an employee located at our corporate headquarters in San Diego. If the candidate is hired in a different city to work remote, we will apply a geographic pay differential based on the cost of labor in the market in which the employee resides.

Brand: Jack In The Box
Address: 9357 Spectrum Center Blvd. San Diego, CA - 92123
Property Description: Jack in the Box Corporate
Property Number: XX9101","$153,458 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1951,$1 to $5 billion (USD)
"Synchrony
4.3",4.3,"Chicago, IL","AVP, Principal Data Engineer","Job Description:
Role Summary/Purpose:
We are looking for a Principal Data Engineer to lead the development of consumer-centric low latency analytic environment leveraging Big Data technologies and transform the legacy systems. This role is an exciting, fast-paced, constantly changing, and challenging work environment, and will play an important role in resolving and influencing high-level decisions across Synchrony.
We’re proud to offer you choice and flexibility. You have the option to be remote, and work from home, or come into one of our offices. You may be occasionally requested to commute to our nearest office for in person engagement activities such as team meetings, training and culture events.
Essential Responsibilities:
Understand and manage the data needs of stakeholders across multiple agile teams.
Lead the design & implementation of scalable & fault tolerant data applications on Big-Data & Cloud Platforms to store & process terabytes of data from upstream sources with high availability.
Engage with and take direction from information architects, platform architects, data scientists and product management on solution requirements to design solutions.
Contribute to high impact problems/projects through in-depth evaluation of complex business processes, system processes, enterprise standards & procedures.
Enforce data management standards and procedures
Lead design, development, testing oversight and production implementation using Spark, Hive, Kafka, RDBMS (Oracle, MySQL), NoSQL databases (Cassandra), Ab Initio and AWS.
Partner with multiple teams to ensure appropriate data solutions to meet goals as well as identify and define necessary system and process enhancements.
Provide technical leadership for data engineering agile teams to deliver against sprint and program increment objectives.
Work closely with Product Owners, Product Managers, Program Manager, Scrum Masters and Team Members in a Scaled Agile framework.
Stay up to date on latest trends in data engineering and recommended best practices.
Develop innovative frameworks to avoid redundancy by promoting automation.
Mentor and coach data engineering team members to promote Synchrony values and culture.
Perform other duties and/or special projects as assigned

Qualifications/Requirements:
Bachelor’s degree in Computer Science, Engineering, or a related field with 6+ years of experience in ETL/Data warehousing with 4+ years of experience with large scale Big Data environments such as Hortonworks/Cloudera and public cloud (AWS preferred).
Prior experience as a Hadoop Technical Lead / Architect
Strong experience and deep understanding of ETL, data warehousing, data lake technologies (Hadoop & Spark) and analytics concepts.
Experience owning a mission critical application on a big data platform.
Experience with batch and real-time data pipelines in a DevOps environment.
Willing to work in a fast-paced environment with globally located Agile teams working in different shifts.
Ability to develop and maintain strong collaborative relationships at all levels across IT and Business Stakeholders.
Excellent written and oral communication skills. Adept and presenting complex topics, influencing and executing with timely / actionable follow-through.
Desired Characteristics:
Prior work experience in a Credit Card/Banking/Fin Tech company.
Experience dealing with sensitive data in a highly regulated environment.
Demonstrated implementation of complex and innovative solutions.
Demonstrated leadership capabilities amongst peers and within prior teams.

Grade/Level: 11

The salary range for this position is 90,000.00 - 155,000.00 USD Annual and is eligible for an annual bonus based on individual and company performance.
Actual compensation offered within the posted salary range will be based upon work experience, skill level or knowledge.
Salaries are adjusted according to market in CA, NY Metro and Seattle.
Eligibility Requirements:
You must be 18 years or older
You must have a high school diploma or equivalent
You must be willing to take a drug test, submit to a background investigation and submit fingerprints as part of the onboarding process
You must be able to satisfy the requirements of Section 19 of the Federal Deposit Insurance Act.
New hires (Level 4-7) must have 9 months of continuous service with the company before they are eligible to post on other roles. Once this new hire time in position requirement is met, the associate will have a minimum 6 months’ time in position before they can post for future non-exempt roles. Employees, level 8 or greater, must have at least 18 months’ time in position before they can post. All internal employees must consistently meet performance expectations and have approval from your manager to post (or the approval of your manager and HR if you don’t meet the time in position or performance expectations).
Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
Our Commitment:
When you join us, you’ll be part of a diverse, inclusive culture where your skills, experience, and voice are not only heard—but valued. We celebrate the differences in all of us and believe that our individual, unique perspectives is what makes Synchrony truly a great place to work. Together, we’re building a future where we can all belong, connect and turn ideals into action. Through the power of our 8 Diversity Networks+, with more than 60% of our workforce engaged, you’ll find community to connect with an opportunity to go beyond your passions.
This starts when you choose to apply for a role at Synchrony. We ensure all qualified applicants will receive consideration for employment without regard to age, race, color, religion, gender, sexual orientation, gender identity, national origin, disability, or veteran status.
Reasonable Accommodation Notice:
Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.
If you need special accommodations, please call our Career Support Line so that we can discuss your specific situation. We can be reached at 1-866-301-5627. Representatives are available from 8am – 5pm Monday to Friday, Central Standard Time
Job Family Group:
Information Technology","$122,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,2014,$10+ billion (USD)
"Geopaqlogic Staffing
4.7",4.7,"Ridgefield Park, Bergen, NJ",Data Engineer (W2 only),"Position: Data Engineer
Work Location: Ridgefield Park, NJ (Hybrid - Need to be visit only once in a month)
Contract period: 6+ months (W2 only)
Note: Must have experience in GCP (Google Cloud Platform) and/or Spark
SUMMARY OF ESSENTIAL JOB FUNCTIONS:
· Design and develop analytical models and be the face to the data consumers
· Perform data curation to meet the business requirements
· Build batch and streaming data pipelines
· Develop processes for automating, testing, and deploying your work
· Identify risks and opportunities of potential logic and data issues within the data environment
· Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUM RETIREMENTS:
· Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
· Must have experience in GCP (Google Cloud Platform) and/or Spark
· 3+ years of experience as Data Engineer or in a similar role
· Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
· Cloud to Cloud migration experience preferred
· Strong PySpark skill is a must have
· Have knowledge of data management fundamentals and data storage principles
· Have knowledge of systems as it pertains to data storage and computing
· Strong source to target mapping experience and ETL principles/knowledge
· Excellent verbal and written communication skills.
· Strong quantitative and analytical skills with accuracy and attention to detail
· Ability to work well independently with minimal supervision and can manage multiple priorities
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Benefits:
Health insurance
Paid time off
Ability to commute/relocate:
Ridgefield Park, NJ 07660: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Engineering: 5 years (Preferred)
Software development: 5 years (Preferred)
Business intelligence: 3 years (Preferred)
GCP (Google Cloud Platform: 3 years (Preferred)
Pyspark: 5 years (Preferred)
Work Location: In person",$65.00 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2014,$1 to $5 million (USD)
"Oracle
3.9",3.9,"Seattle, WA",Senior Software Engineer (Join OCI: Horizon Data Warehouse team),"As a Senior Software Engineer on the Horizon Data warehouse team, you will help our development efforts as we build the technology platform that will act as the central data platform inside OCI for 100's of teams. You will be a core contributor on a team of software engineers working to grow and scale our service.

Basic Qualifications
4+ years of experience in the design and implementation of complex software systems
Strong Knowledge of Data Warehousing, ETL processes, Cloud Computing and Data Security concepts is a must.
Proven experience with a Programming language PLSQL is a must.
Sound fundamentals in coding, algorithm design, problem solving, and complexity analysis.
Proven experience with a major Programming language such as Java, Python, Go, C# or C++ is a plus.
Aptitude for problem solving.
Experience with massively scalable systems is a plus.
Experience with Cloud Platforms such as OCI, AWS, Azure or GCP is a plus.
Experience with enterprise-class RDBMS (Oracle, SQL*server), Cloud Data warehouse (Snowflake/Redshift).
Preferred Qualifications
Experience building distributed cloud services.","$146,533 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
"Logistics Management Institute
4.3",4.3,"Washington, DC",Data Engineer - TS/SCI Required,"Overview:
LMI is seeking a Senior Data Engineer to support our Intelligence Community client.

LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers’ unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies.

LMI has been named a 2022 #TopWorkplace in the United States by Top Workplaces! We are honored to be recognized as a company that values a people-centered culture, and we are grateful to our employees for making this possible!
LMI is seeking a skilled Senior Data Engineer to support data pipelining and sustainment of a client’s SQL database. Successful Data Engineers demonstrate competency in data acquisition, data analysis, programming, project execution, and critical thinking. In addition, LMI Data Engineers have demonstrated experience in collaborating with other Data Engineers and with effective communication with clients.
Responsibilities:
This data engineer will work as part of a team of experienced data scientists, data analysts, and full stack developers to develop and maintain applications that enable client business processes. Responsibilities include:
Defining and developing techniques to integrate, consolidate, and structure data for functional workflows and analytical use
Understanding complex and organization-specific datasets.
Producing dashboards and visualizations to support complex client requirements.
Conducting root cause analysis, identifying errors, and refactoring pipelines as needed.
Performing analyses to answer routine and ad hoc questions as identified in the data being leveraged
Developing and improving standard operating procedures.
Communicating with data analysts and developers to design tools and applications to improve response to repeat requests.
Researching, analyzing and documenting the benefits of various technical approaches.
Proposing alternative designs and processes to manage various types of data using both standard and custom tables and fields.
Working in teams and independently.
Understand and analyze complex and organization-specific datasets.
Support the maturation of data quality
Support the transformation of businesses process through automation
Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available visualization and dashboard tools
Advising on the interpretation and use of data analysis products, dashboards and reports to non-technical customers
Assisting the development of junior teammates through technical mentoring, code review, and other assistance.
Qualifications:
Required:
Bachelor’s degree in science, engineering, mathematics, computer science, information systems, data analytics, or other related business or quantitative discipline
7+ years experience in data engineering or related field
Experience with ETL process and concepts
Knowledge and experience manipulating and joining data from various sources and in various formats.
Ability to query datasets from multiple sources, knowledge of data refresh methodologies, and ability to leverage data models.
High level of competency with data engineering coding languages like SQL and Python
Self-starter with the vision to independently identify opportunities for improvement through data analytics
A true team player who maintains a positive attitude in a dynamic environment
Excellent communication skills, written and oral
Proven ability to work with business customers and technical teams
Highly organized and able to manage multiple projects simultaneously
Excellent customer relationship management skills
Innovative problem-solving skills and ability to thrive in a fast-paced environment
Ability to work on client site in the NCR in Washington, D.C.
This position requires an active security clearance at the TS/SCI level with the ability/willingness to receive a polygraph. Current polygraph preferred.
Desired:
Masters degree or higher
Experience developing dashboards using Tableau, Qlik, Power BI, RShiny, plotly, or d3.js
Experience with version control software like Git
Experience with Agile development
Management consulting experience desired

#LI-SH1","$112,206 /yr (est.)",1001 to 5000 Employees,Company - Private,Management & Consulting,Business Consulting,1961,$100 to $500 million (USD)
"Intellibus
4.6",4.6,"Newark, NJ",Sr. Data Engineer — Snowflake,"Are you a Data Engineer working at a Large Financial Institution and being told by your leadership that you are too hands-on or detail-oriented or think and work like a start-up?
Imagine working at Intellibus to engineer platforms that impact billions of lives around the world. With your passion and focus we will accomplish great things together!
We are looking forward to you joining our Platform Engineering Team.
Our Platform Engineering Team is working to solve the Multiplicity Problem. We are trusted by some of the most reputable and established FinTech Firms. Recently, our team has spearheaded the Conversion & Go Live of apps that support the backbone of the Financial Trading Industry.
We are looking for Engineers who can
Create Data modeling
Work on Snowflake modeling – roles, databases, schemas, ETL toolswith cloud-driven skills
Work on SQL performance measuring, query tuning, and database tuning
Handle SQL language and cloud-based technologies
Set up the RBAC model at the infra and data level.
Work on Data Masking / Encryption / Tokenization, Data Wrangling / ECreLT / Data Pipeline orchestration (tasks).
Setup AWS S3/EC2, Configure External stages and SQS/SNS
Perform Data Integration e.g. MSK Kafka connect and other partners like Delta lake (data bricks)
We work closely with
Data Wrangling
ETL
Talend
Jasper
Java
Python
Unix
AWS
Data Warehousing
Data Modeling
Database Migration
ECreLT
RBAC model
Data migration
Our Process
Schedule a 15 min Video Call with someone from our Team
4 Proctored GQ Tests (< 2 hours)
30-45 min Final Video Interview
Receive Job Offer
If you are interested in reaching out to us, please apply and our team will contact you within the hour.
Job Type: Full-time
Pay: $60.00 - $80.00 per hour
Schedule:
Monday to Friday
Experience:
Data Wrangling: 7 years (Preferred)
Snowflake: 7 years (Preferred)
ETL: 7 years (Preferred)
Work Location: In person",$70.00 /hr (est.),Unknown,Unknown,Information Technology,Information Technology Support Services,2015,Unknown / Non-Applicable
Bonsai Robotics,#N/A,"San Jose, CA",Senior ML Ops Engineer - Data,"Job Overview:

We are seeking a highly skilled Sr. ML Ops engineer to join our team. As a ML ops engineer, you will develop, implement, and optimize our custom data pipelines for our ML systems. You should have a strong background in any of the following technologies: Databases(SQL, MongoDb), Cloud frameworks (AWS) and ML Frameworks (Pytorch/tensorflow). The ideal candidate will be proficient in programming languages such as C++ and Python.
About Bonsai:
Bonsai Robotics' mission is to create the next leap forward in agriculture equipment efficiency by creating a new ecosystem of semi-autonomous robotic machinery. Orchards are dusty, hazard-filled, and GPS-denied. The GPS-based autosteer features that have driven row crop efficiencies cannot function in orchards. Our vision, AI, and machine control systems offer human-level environment understanding and local navigation capabilities and will be the platform for a new wave of innovation in agricultural production and management systems.
We simultaneously solve twin crises impacting nut growers and most of specialty agriculture: there is not enough human labor when you need it, and operational expenses are growing dramatically. Our state-of-the-art technology empowers orchard managers to optimize their operations, dramatically reduce operational expenses, and increase profitability. We are pursuing a Bonsai Inside strategy, and partnering with the largest orchard Original Equipment Manufacturers (OEMs) in the retrofitting of existing machines and design of new form factors.
Key Responsibilities:
Develop, implement, and optimize data pipelines for ML systems.
Collaborate with cross-functional teams to store, process and certify petabytes of Image+Video data.
Coordinate with 3rd parties to handle labeling pipelines.
Create and maintain code documentation and unit tests.
Collaborate with ML scientists and provide data insights
Qualifications:
Bachelor's or Master's degree in Computer Science, Robotics, Electrical Engineering or related field
Strong background in most of the following technologies: Backend engineering, Data engineering, Databases, Dev Ops
Expert in Creating ETL pipelines
Proficiency in programming languages such as C++ and Python
Strong problem-solving skills and ability to work in a fast-paced environment.
Strong verbal and written communication skills.
Bonus: Experience with Pytorch and Ros 2
If you have a passion for computer vision, robotics, and developing innovative technology solutions, we encourage you to apply for this exciting opportunity. Bonsai Robotics values diversity, inclusivity, and excellence in hiring and strongly encourages candidates from traditionally underrepresented backgrounds to apply.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Allata LLC
4.3",4.3,Remote,Data Architect/Lead Engineer - Consulting (Remote Possible),"Allata is growing our Data & Analytics Practice to serve our clients nationwide. Our data architect / lead engineer practitioners will be collaborating with data engineers, machine learning engineers, analysts, data scientists, and other Allata employees and client teams on projects for companies across the United States.
WHAT YOU'LL BE DOING
Work with customers to build cloud-based data platforms, including integration, data storage and analytics
Develop innovative architectures to solve complex business problems utilizing the latest cloud technologies
WHAT YOU'LL NEED
Data Architecture Best Practices. You’ve successfully built data solutions that use industry best practices and fit with an organization’s needs. You are excited by solving problems and voraciously consume technology to do so. You have a broad and deep technical background
Communication. You have a natural charisma and use it to build consensus. You can have a conversation with developers, business analysts, managers of all levels, and individuals in a business function. You are comfortable presenting in front of groups and explaining architectures in a variety of levels of detail.
Make teams better. You're excited to be part of a team that delivers with quality and works hard on new opportunities. You work well in fast-moving environments and have no problem working with others to resolve difficult problems. You support teams as much as others supports you.
DESIRED SKILLS & EXPERIENCE
8-10 years of experience in a data related field
Experience building data storage and analytic solutions utilizing Snowflake
Expertise in building data platforms in Azure or AWS
Experienced with ETL tools such as Azure Data Factory, AWS Glue, WhereScape RED, Streamsets, Informatica and SAP Convergent Mediation
Experience in one or more Cloud Data Warehouse (Azure SQL Data Warehouse / Synapse Analytics, Snowflake, Amazon Redshift, Google BigQuery)
Experience in one or more Data Visualization tool (Tableau, PowerBI)
Expertise modeling architectures and integrations for data environments including data pipelines, data lakes, data warehouses, and data marts.
Experience with data backup and recovery strategies, optimization of clusters, structured/semi structured data, and changing database storage and utilization requirements
Experience with scripting languages such as Python / R for Business
Experience with Event Driven Architecture (Kafka)
Experience with large-scale distributed storage and database systems (e.g. SQL, NoSQL, MySQL, Cassandra)
At Allata, we value differences.
Allata is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Allata makes employment determinations without regard to race, color, creed, religion, age, ancestry, national origin, veteran status, sex, sexual orientation, gender, gender identity, gender expression, marital status, disability, or any other legally protected category.
This policy applies to all terms and conditions of employment, including but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Software Development,2016,$25 to $100 million (USD)
"RSA
4.0",4.0,"Overland Park, KS",Archer Business Enablement Data Engineer,"Business Enablement Data Engineer
Archer Technologies, LLC is the 25-year unseated market leader of integrated risk management (IRM) SaaS platforms that enable customers to improve strategic decision-making and operational resilience with a modern technology platform that supports qualitative and quantitative analysis driven by both business and IT impacts. As true pioneers in ERM, compliance, audit and cyber risk, Archer’s 800 employees are solely dedicated to helping customers manage risk and compliance programs, from traditional audits to emerging issues such as ESG. With over 25 years in the risk management industry, the Archer customer base represents one of the largest pure risk user communities globally, with more than 1,300 customers including more than 50% of the Fortune 500. Learn more at www.ArcherIRM.com.
The primary focus of the Business Enablement Data Engineer is to provide technical expertise with the creation and maintenance of Archer’s Global Data Lakehouse. This role will execute on complex analytics to help drive business decisions across a wide variety of often fast-paced internal engagements. The Data Engineer role will build innovative tools and applications that can help solve Archer’s internal data issues, help execute cutting-edge analytical techniques, help drive technical roadmaps for the function and firm, and train our colleagues.
Responsibilities:
Assist with creating, defining, and driving data engineering solutions to meet functional business requirements.
Data engineering needs can include Data aggregation/creation, data cleaning/manipulation, data science (e.g., geospatial, machine
learning, predictive modeling, etc.), and visualizations.
Solve various complex analytical challenges, sometimes dynamically balancing multiple internal projects simultaneously.
Supporting project teams with their analytics work in a “consultancy/expert” capacity on best practices concerning data & analytics
engineering (e.g., on-prem databases & systems, data storage & warehousing, data management, big-data principles, analytics app
prototyping, ETL)
Develop and drive the data engineering roadmap needed to support the business.
Collaborate with various stakeholders to continuously innovate on the tools, services, and data assets we can offer.
Serve as the lead technical expert and thought leader in helping to innovate and develop offerings that require / benefit from advanced
analytics skills or capabilities.
Provide technical expertise and thought leadership on developing analytical tools, services, and data assets and contribute to building
these areas directly when applicable.
Create production-quality data pipelines to develop and deploy scalable data science projects.
Stay current on best-in-class software, tools, and techniques to ensure we can provide best-in-class solutions.
Support development and upskilling of staff on relevant software, tools, and techniques
Develop and drive the technical roadmap on data engineering capabilities and infrastructure to ensure we operate a best-in-class Data
& Analytics function.
Qualifications:
Degree in a quantitative or business discipline or previous business experience preferred; examples include: Computer Science,
Engineering, Information Technology, Data Science, Statistics, Mathematics, Operations Research, Economics
Minimum 5 years of experience in applied data engineering; deep expertise in data engineering, as well as strong business and
strategic analytical skills
Ability to understand and articulate requirements to/from technical and non-technical audiences working alongside a data science &
engineering team.
Strong SQL & Python knowledge and familiarity with Big Data tools such as Spark & Scala; familiarity with Alteryx and Tableau
Experience with data modeling, data structures (e.g., relational, and non-relational data), databases, and ETL/ELT processes and an in depth understanding of large-scale data sets including both structured and unstructured data.
Experience with designing, implementing, and delivering scalable data solutions and pipelines on one of the cloud platforms (e.g., AWS,
Azure, GCP) and on-prem platforms such as Microsoft SQL Server
Experience with building and deploying proprietary cloud-based analytics web apps.
Hands-on experience in the development, deployment, and operation of integration technologies (e.g., APIs)
Proficiency with data warehouses (e.g., Snowflake, Teradata, Redshift, Hadoop, BigQuery, etc.)
Experience with containerization technologies (e.g., Docker, Kubernetes)
Experience with DevOps, Git, CI/CD
Experience directly managing another individual or a team.
Prior experience in Strategic Data Consulting is preferred.

Archer is committed to the principle of equal employment opportunity for all employees and applicants for employment and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Archer are based on business needs, job requirements and individual qualifications, without regard to race, color, religion, national origin, sex (including pregnancy), age, disability, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, protected veteran status, genetic information, or any other characteristic protected by federal, state or local laws. Archer will not tolerate discrimination or harassment based on any of these characteristics. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. All Archer employees are expected to support this policy and contribute to an environment of equal opportunity.
If you need a reasonable accommodation during the application process, please contact talent-acquisition@archerirm.com. All employees must be legally authorized to work in the US. Archer participates in E-Verify. Archer and its approved consultants will never ask you for a fee to process or consider your application for a career with Archer. Archer reserves the right to amend or withdraw any job posting at any time, including prior to the advertised closing date.","$86,978 /yr (est.)",5001 to 10000 Employees,Company - Public,Insurance,Insurance Carriers,1710,$10+ billion (USD)
"AnaVation
4.9",4.9,"Chantilly, VA",Senior Full Stack Data Engineer - REMOTE!,"Be Challenged and Make a Difference

In a world of technology, people make the difference. We believe if we invest in great people, then great things will happen. At AnaVation, we provide unmatched value to our customers and employees through innovative solutions and an engaging culture.

Description of Task to be Performed:
AnaVation is looking for a talented Full Stack Data Engineer who is passionate about technology and working with customers and a strong team to provide solutions for our mission-critical customer. The ideal candidate appreciates partnering with our customer and team of engineers to create innovative engineering solutions. The selected candidate will work with a small group of developers building a Cyber data lake. If you are looking to be challenged, then this is the environment for you. This position supports 80% remote work with up to one day per week in our Chantilly, VA office. The candidate will be required to pass a high-risk public trust background investigation.

Position Responsibilities:
Develop tools and processes to ingest Cyber data into an enterprise data lake.
Make recommendations on standards for a common Cyber data model and standards for harmonization of common data elements on data ingest.
Develop and evaluate tools to search, analyze, discover, and otherwise exploit data in the data lake to support investigative operations.
Required Qualifications:
5 or more years of relational database design and development (PostgreSQL, Oracle, Microsoft SQL Server)
5 or more years of ETL/ELT development experience · 2 or more years with Linux environment experience
2 or more years’ experience with shell scripting
Experience implementing data access controls
Experience analyzing unstructured, structured, and semi-structured data
Strong technical and computational skills, coupled with the ability relate data to use cases, mission requirements, and end-user experience
Experience with development in one or more programming or scripting languages (Java/Python/Go)
Active Secret Clearance or High Risk Public Trust Suitability
Bachelor’s degree in Computer Science, Information Systems or related discipline
Preferred Qualifications:
Experience with PostgreSQL
Experience with cloud data solutions such as AWS RedShift, AWS DynamoDB and Azure Cosmos DB
Experience with search technologies such as Elasticsearch, AWS Opensearch, Azure Cognitive search, SOLR, etc
Experience with Databricks, Azure Syanpse, or Apache Spark
Experience with cloud concepts and big data architectures such as Hadoop, Kafka, etc.
Knowledge of Continuous Integration/Continuous Delivery tools and practices
Experience with cloud platforms such as AWS and Azure
Experience working in Agile Environments
Experience with DevOps toolsets
Familiarity with containerization (Docker, Containerd, Kubernetes, etc.)
Experience with microservices
Benefits
Generous cost sharing for medical insurance for the employee and dependents
100% company paid dental insurance for employees and dependents
100% company paid long-term and short term disability insurance
100% company paid vision insurance for employees and dependents
401k plan with generous match and 100% immediate vesting
Competitive Pay
Generous paid leave and holiday package
Tuition and training reimbursement
Life and AD&D Insurance

About AnaVation
AnaVation is the leader in solving the most complex technical challenges for collection and processing in the U.S. Federal Intelligence Community. We are a US owned company headquartered in Chantilly, Virginia. We deliver groundbreaking research with advanced software and systems engineering that provides an information advantage to contribute to the mission and operational success of our customers. We offer complex challenges, a top-notch work environment, and a world-class, collaborative team.

If you want to grow your career and make a difference while doing it, AnaVation is the perfect fit for you!","$97,431 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2013,$5 to $25 million (USD)
"US Signal Company LLC
2.8",2.8,"Grand Rapids, MI",Technical Support Engineer (Tier 3 Cloud and Data Protection),"Job Description
US Signal is a leading data center services provider, offering secure, reliable network, cloud hosting, colocation, data protection, and disaster recovery services — all powered by its expansive, robust fiber network. US Signal also helps customers optimize their IT resources through the provision of managed services and professional services.
We are seeking a Technical Support Engineer to join our team in Grand Rapids, Michigan. This role is performed mostly on-site but could be hybrid.
The Technical Support Engineer (Cloud and Data Protection) is part of the Technical Operations Center team and is responsible for all level one, two, and three customer support for the US Signal Hosted and Enterprise Cloud services, Object and File Storage, and Disaster Recovery and Data Protection services. The primary function of the Tier 3 Engineer is to provide a world-class level of customer service with an efficient and timely resolution of cases. This role acts as an escalation point and mentor to the Tier 1 Support Agents and Tier 2 Support Specialists. A Support Engineer must be competent in each of US Signal's Cloud and Data Protection offerings, including VMWare, SoftNAS, Zerto, Avamar, Acronis Backup, Veeam Backup Recovery and Archive, Cohesity Data Management, and Remote Monitoring and Management through nAble. This position requires competency in all facets of Windows and Linux Server problem isolation and resolution. Strong networking background is also a plus.
Engineers will analyze current processes, procedures, and case workflow to develop ways to improve the support experience for US Signal customers.
This position is required to participate in an alternating on-call schedule as outlined by the Supervisor of Technical Operations.
FUNCTIONS/RESPONSIBILITIES
Analyze current processes, procedures, and case workflow to develop ways to improve the support experience for US Signal customers.
Work independently and act as a point of escalation for level III Data Protection and Cloud related issues.
Mentor technicians and engineers to develop skills as opportunities present themselves.
Troubleshoot various levels of Windows Server related issues using available server access methods.
Troubleshoot backup issues on the US Signal backup or disaster recovery platforms.
Receive incoming customer calls for trouble/technical support, acting as a subject matter expert for Data Protection and Cloud related issues. Probe customers for most valuable information in relation to trouble for accurate trouble tickets.
Special projects and assignments as deemed necessary by USS management.
Experience and Skills
Competencies:
Expert in customer service.
Experience working with backup and disaster recovery platforms
Familiarity with best practices in Business Continuity and Disaster Recovery
Experience with VMWare, and Windows Server/Linux Operating Systems
Understanding of virtual environments and overall Cloud infrastructure.
High level of analytical ability
Attention to detail and accuracy and excellent organization skills.
Excellent oral and written communication skills.
Ability to work well with all areas of the US Signal organization as well as external customers and vendors
Knowledge of Data/IP Networking including IP Subnetting, NAT, DHCP, etc.
Knowledge of routing protocols including BGP and OSPF.
Education:
Technical training in VMware, virtualization, and/or cloud computing
Technical training in Backup and Disaster recovery platforms
BS in Computer Science, Information Systems, Network Administration or Systems Administration desirable.
Experience:
Experience in Windows Server is required.
Familiarity with server architecture and design is essential.
Previous experience with VMware or virtual environments required.
Extensive experience with Data/IP Network Maintenance is preferred.
Technical experience in a data center, ISP or telecom environment is desired.
Experience working in a process driven helpdesk environment
Working Conditions and Physical Demands:
The majority of the time is spent in a professional office environment and this role routinely uses standard office equipment.
Required License(s)/Certification(s):
Active CCNA (or higher) preferred.
All US Signal employees will comply with US Signal Information Security policies to ensure the confidentiality, integrity, and availability of US Signal and customer data. All employees are responsible to ensure actions comply with state and federal regulations and requirements.
We offer a competitive compensation and benefits package including a 401k plan with a match. If you are looking to be part of a dynamic team, please apply now.
Job Type: Full-time
Pay: From $65,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Supplemental pay types:
Bonus opportunities
Work Location: Hybrid remote in Grand Rapids, MI 49503","$65,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2001,Unknown / Non-Applicable
"Atkore
4.0",4.0,"Harvey, IL",Applications Engineer - Data Center Containment,"Applications Engineer
Who we are:
Atkore is forging a future where our employees, customers, suppliers, shareholders, and communities are building better together – a future focused on serving the customer and powering and protecting the world.
With a global network of manufacturing and distribution facilities, Atkore is a leading provider of electrical, safety and infrastructure solutions.

Who we are looking for:
We are currently looking for an Applications Engineer. You will manage and be the go-between for owner’s needs, building requirements and our factory delivered solutions by working closely with General Contractors, Mechanical and Electrical contractors, and system integrators across a wide range of sites for hyperscale, colocation, and retail providers in the space. You will be supported by a full commercial, estimating, factory engineering team delivering product from our owned manufacturing plant(s) in the USA.

What you’ll do:
Serve the customer’s needs as a critical member of our team to help support the launch of Atkore’s data center containment solution.
Work closely with Director of Sales to become the application expert to identify current and future customer needs and help the customer find appropriate solutions for customer applications whilst promoting Atkore portfolio.
Coordinate with our project management team and walk job sites (as required) to understand site conditions.
Coordinate with our factories to ensure critical to build issues are addressed including documenting technical requirements for both domestic and overseas project plans and project changes.
Examine and interpret blueprints/plans/drawings to find containment opportunities and coordinate requirements to the estimating team.
Lead the design and installation of our containment solutions to exceed customer expectations including developing installation manuals and on-site assistance to Unistrut Construction team during installation.
Maintain and update our technical library, including CAD models, drawings, specifications, test data, etc.
Support our Regional Sales Managers (RSM) team with client proposals and technical presentations.
Establish and build strong trusting relationships with key stakeholders and provide unmatched quality, delivery, and value.
Travel requirements are 15-25% of the time

What you’ll bring:
5+ years of hands-on field experience in applications engineering, engaging with the customer through the requirements definition, generating a concept and proposal through the delivery and installation of the solution
A history of building and maintaining customer relationships, preferably in the data center market.
Possess a technical aptitude and comfort in understanding blueprints and specifications.
High energy and integrity, strong team player, exceptional work ethic, and a history of proven sound decision making.
Ability to think strategically and develop long term goals
Engineering degree or relevant experience.
Autodesk Inventor, Microsoft Office Suite, CRM Tool experience
Word, Excel, PPT, and CRM tool experience.

Within 3 months, you’ll:
Complete Atkore’s immersion program to understand our mission, vision, values, business processes, products, people, and our culture.
Learn about our manufacturing, operations, and field installation teams capabilities for containment.
Understand how your role works closely with the sales, operations, and installation teams and contributes to Atkore’s overall strategy.
Gain buy-in with Unistrut Construction stakeholders that help support our sales objectives.
Develop a submittal and design process to work collaboratively with RSMs to improve our value and conversion rate.
Understand our value proposition and incorporate added value into the containment design.
Within 6-months, you’ll:
Become familiar with the design, build, and installation of Atkore’s containment solution
Create strong relationships with executives, key stakeholders, and strong influencers.
Use Autodesk Inventor to update, maintain and distribute technical and manufacturing drawings.
Develop bespoke installation manuals for each application
Provide on-site assistance to optimize installation efficiencies in support of client schedule.
Identify other resources needed to scale our business.
Within 12-months, you’ll:
Become the Atkore containment subject matter expert and make recommendations to improve the program
Proficient at reading drawings, specifications, and blueprints for data centers.
Take the lead as the conduit between sales and operations, working with the Manufacturing Engineers on delivery and installation to keep customers’ project on schedule.
Collaborate with the Global Director of Product Management, Global Director of Product Engineering on various projects and tasks related to new product development.
Assist Director of Sales with every data center containment internal scope review and external scope review with customers.
Build enough demand to recruit, hire, and train teammates.

Atkore is a recipient of a Great Place to Work© certification and a Top Workplaces USA award! We’re committed to creating an engaged and aligned workforce that drives collaborative culture. Our team strives for breakthrough results, stays focused on being standout leaders, and fully supports decisions of the Company. We consistently live the Atkore mission, strategic priorities, and behaviors, all in a way that’s consistent with our core values. Together, we build strong leaders that continually endeavor to move us forward.
Join our team and align yourself with an industry leader!
#LI-ET1
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$82,585 /yr (est.)",1001 to 5000 Employees,Company - Public,Manufacturing,Machinery Manufacturing,2010,$1 to $5 billion (USD)
"84.51°
4.3",4.3,"Cincinnati, OH",Senior Data Engineer (P996),"84.51° Overview:
84.51° is a retail data science, insights and media company. We help the Kroger company, consumer packaged goods companies, agencies, publishers and affiliated partners create more personalized and valuable experiences for shoppers across the path to purchase.
Powered by cutting edge science, we leverage 1st party retail data from nearly 1 of 2 US households and 2BN+ transactions to fuel a more customer-centric journey utilizing 84.51° Insights, 84.51° Loyalty Marketing and our retail media advertising solution, Kroger Precision Marketing.
Join us at 84.51°!
__________________________________________________________

As a member of our engineering team, you will use various cutting-edge technologies to develop applications that turn our data into actionable insights used to personalize the customer experience for shoppers at Kroger. We also work with Kroger's supply chain related data assets including but not limited to: Orders and Shipments, Inventory, Planogram and Pricing information to help Kroger, CPG and broker clients make tactical and strategic business decisions. We use agile development methodology bringing everyone into the planning process to build scalable enterprise applications and solutions.
What you'll do
Work within a team that owns the Semantic Layer of a large commercial reporting application.
Create and maintain complex retail customer loyalty measures and commercial data security rules.
Use strong business analysis skills to translate commercial requirements into technical requirements.
Use strong Data Warehouse and BI Tool background and understanding of every layer of the technical stack in order to convert requirements into platform wide implementation solutions.
Work with the team to implement the semantic layer portion of those solutions using a BI Tool framework.
Develop custom engineering tools to assist with the implementation, automation, and testing of the solution to reduce time to market for new Insights capabilities.
Responsibilities
Participate in design and development of highly visible data solutions
Support Commercial Facing data pipelines
Perform unit and integration testing
Collaborate with architecture and lead engineers to ensure consistent development practices
Participate in retrospective reviews
Participate in the estimation process for new work and releases
Collaborate with other engineers to solve and bring new perspectives to complex problems
Drive improvements in people, practices, and procedures
Embrace new technologies and an ever-changing environment
Requirements
3+ years proven ability of professional Data Development experience
Experience with a Business Intelligence Reporting Tool
Full understanding of ETL concepts and Data Warehousing concepts
Proficient with Relational Data Modeling
Thorough understanding of CI/CD concepts and best practices
Comprehensive Understanding of ANSI SQL
Foundational Understanding of Cloud Processing Concepts
Foundational Understanding of Agile Principles
Exposure to Retail Business Intelligence
Exposure to interacting with , enhancing and creating Cloud based services
Passion for Problem Solving
Passion for creating supportable technical solutions
Experience communicating to and with functional colleagues
Preferred Skills
dbt
Python
Python FAST API framework
Power BI
Snowflake
Alation
Microsoft Azure
MongoDB
Oracle
#LI-Remote #LI-DOLF","$84,414 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2015,Unknown / Non-Applicable
"Peraton
3.6",3.6,"Pacific, MO",Data Engineer – DoD TS/SCI – Camp Humphrey – Korea,"Responsibilities:
Peraton is seeking a Data Engineer, in support of a US Government client at Camp Humphrey in South Korea, who can leverage experience and expertise in data exploration, engineering, and ETL to architect, develop, and deploy scripts for processing structured and unstructured data into usable data formats for long term storage, search, and analysis
The successful Data Engineer candidate will work with a diverse team of data scientists, social scientists, cultural advisors, operations research systems analysts (ORSAs), and Irregular Warfare (IW) planners to translate empirical research findings into operational assessments.
The Data Engineer will be responsible for developing user interfaces, data extraction and transformation to improve data reliability, quality and utility.
The candidate should also be comfortable working with military IRC planners to break down and synthesize data in a fashion that best informs plans and operations.
Roles and responsibilities for this position include:
Utilize your experience with AWS, Azure, or Google Cloud
Creating a custom ingest pipeline to a Big Data platform with consistent performance and scalability
Understanding programming and data engineering concepts and best practice
Experience working with both structured, semi-structured, and unstructured data to include data parsing, transformation, schema definition, and query/analysis
Ability to manage and organize data while identifying trends and inconsistencies that will impact downstream analytics
Experience with data pipelines or be willing to learn a pipeline from bottom to top
Be able to troubleshoot files against an architecture to see where the upload process is failing
Be able to understand unit tests and add to them to increase stability to the entire pipeline
Be prepared to use GIT, Anaconda, Spyder, and Microsoft tools
Be prepared to express ideas and solutions and walk together with teammates through coding challenges
Qualifications:
Basic Qualifications:
Bachelor of Science in computer programming, mathematics or a related degree with 8-10 years of experience, 6-8 yrs. with a Master’s Degree
Demonstrated experience applying data engineering and software development expertise
Work / research history demonstrating applied experience with programming languages such as Python, SQL, Java, etc. with Linux OS (Ubuntu, CentOS, Red Hat), and Windows environments
Ability to work both independently and collaboratively with high levels of curiosity, creativity, and problem-solving capabilities
Strong written and verbal communication skills
Experience building ETL pipeline architectures and AWS, architectures with experience with ETL tools such as NiFi or Informatica
Must be willing and able to travel within the CCMD area of responsibility as required by the program.
Must be a U.S. Citizen with Current US Passport
Current DoD Top Secret clearance with SCI eligibility

Preferred Qualifications and Training:
A graduate degree in computer programming / science, mathematics, or related degree and 10 years of experience
AWS certifications such as AWS solutions architect or developer
Cyber security certifications
Statistical package expertise in programs such as IBM SPSS/PASW, R, STATA or MS Excel statistics
Experience applying data science to address defense or social science issues
Experience using geospatial analytic package (e.g., ArcGIS, QGIS, etc.)
Joint intelligence or operational assessment experience with Combatant Commands
Peraton Overview:
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers.
Target Salary Range: $146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors. EEO: An Equal Opportunity Employer including Disability/Veteran.","$190,000 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $10 billion (USD)
"Gentiva
3.3",3.3,"Mooresville, NC",Business Intelligence Developer / Data Engineer,"Our Company:

Gentiva is an industry leader in hospice, palliative and personal home care. Our place is by the side of those who need us, offering physical, spiritual and emotional support to patients and their families so they may make the most of every moment. We believe that better care for caregivers and clinicians means better care for everyone, so we offer ongoing professional training, lower nurse-to-patient ratios, and comprehensive benefits for eligible employees. Here, you’ll join gifted colleagues who make a lasting difference in people’s lives every day.

Overview:
We are looking for a remote Business Intelligence Developer / Data Engineer to join our team. This position reports to the Director Business Intelligence and Data Services and is responsible for developing, deploying, and maintaining BI interfaces. Those include query tools, data visualizations and interactive dashboards, ad hoc reporting, and data modeling.
Transform business requirements into technical specifications
Design and develop ETL processes to move/load data to/from various locations including files systems, ftp sites, and data bases
Define and develop internal teams’ Service Delivery KPIs dashboards to improve customer experience
Monitor and manage new and existing integration elements to ensure continued customer satisfaction
Act as Subject Matter Exert (SME) in a verity of data / analytics platforms such as SQL Server, Power BI and Microsoft Visual Studio/SSIS
Design and develop interfaces such as APIs. Forward thinking toward newer technologies and where these may be implemented
About You:
Bachelor's degree in computer science or a related field
5+ years’ of Experience with Microsoft SQL Server Integration service (SSIS)
5+ years’ experience with SQL, T-SQL, and stored procedures
5+ years’ of data engineering/modeling experience with both snowflake and star schema data modeling
2+ years’ of progressive experience in healthcare IT
3+ years’ experience with Business Intelligence tools such as Power BI and SSRS
Experience with Cloud Technologies such as Azure, AWS, etc is a plus
Requires demonstrated experience in project management
Good oral and written communication skills
Self-motivated and able to adapt to new technology and processes quickly
We Offer:
Comprehensive Benefits Package: Health Insurance, 401k Plan, Tuition Reimbursement, PTO
Opportunity to Participate In a Fleet Program
Competitive Salaries
Mileage Reimbursement
Professional Growth and Development Opportunities
Legalese:
This is a safety-sensitive position
Employee must meet minimum requirements to be eligible for benefits
Where applicable, employee must meet state specific requirements
We are proud to be an EEO employer
We maintain a drug-free workplace
Location: Gentiva",#N/A,10000+ Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2010,Unknown / Non-Applicable
CO,#N/A,Remote,Devops Data Engineer/Devops Data Analyst(W2 Only),"Devops/ Technical Data Analyst
6+ Months
Remote
W2 Only
Primary Skills:
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts applications and languages - preferably Oracle/Exadata SQL Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products ie ACH Wire Lockbox BAI EDI etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie XL Release Jenkins Git SVN test automation
Experience with unit functional regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Job Description
Enterprise Commercial Payments Data Mart Technical Data Analyst The Embedded Banking Data and API team is responsible for the Enterprise Commercial Payments Data Mart and Banking as a Service APIs. This position will primarily be focused on the Data Mart. Built on Oracle Exadata, the Mart is sourced with transactional Data from Core Payment systems (ACH, wire/RTP, lockbox, etc) through both batch/ETL and real-time feeds. The data is used as the source for reporting and inquiry APIs and Webhooks that are exposed to Commercial Clients, Fintech partners and internal Keybank systems. It is also used to generate BAI and other reports for Corporate Clients. Responsibilities will include:
Data Sourcing
Capturing requirements and designs for batch/ETL (Ab Initio) integrations
Capturing requirements and designs for real time (webMethods/Java) integrations
Identifying and implementing improvements to decrease load time and optimize database performance
Troubleshooting issues
Data Consumption
Capturing requirements and designs to meet requirements for Embedded Banking APIs
Capturing requirements and designs to meet requirements for BAI and other reports
Identifying and implementing improvements to improve API performance
Troubleshooting issues
Data SME
Working with SMEs from the source payment platforms to learn about and become expert on the critical data elements in the data mart
Respond to questions from consumers regarding data
Maintain documentation/data libraries
Interacting with the following:
Line of Business partners (Embedded Banking, Commercial Payments, Digital Channels)
Vendors/Clients
Production Support Team: provide knowledge transfer and assist with troubleshooting issues
Data Supply Chain (ETL/Abinitio, Data Model) Teams
Kafka Event Management Team
Open Banking Engineering Teams
Database Administrators
Infrastructure Teams
Internal Interfacing Teams
QAS/Testing Team: review test plans, help find data, and assist/supplement the testing
Working with and through direction of ECA Mart Technical Lead
Helping support, maintain and review dashboards in Kibana
Required Experience / Skills
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts, applications and languages - preferably Oracle/Exadata, SQL, Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products, ie, ACH, Wire, Lockbox, BAI, EDI, etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie, XL Release, Jenkins, Git, SVN, test automation
Experience with unit, functional, regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Preferred Experience / Skills
Experience with database design, analytics
Experience with other programming languages
Basic understanding/experience with APIs, developer portals; Fintech integrations
Experience in creating REST API Documentation using OpenAPI/Swagger Specs. Swagger and Yaml, or similar tools
Experience working on an Agile Team
Job Type: Contract
Pay: $65.00 - $67.00 per hour
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Experience:
DevOps: 9 years (Preferred)
Data Engineer: 9 years (Preferred)
CI/CD: 9 years (Preferred)
ETL/Ab Initio: 8 years (Preferred)
Agile: 9 years (Preferred)
WebMethods/Java: 6 years (Preferred)
Jenkins, SVN: 9 years (Preferred)
RESTful API: 8 years (Preferred)
Commercial Payments: 8 years (Preferred)
Kafka: 2 years (Preferred)
Work Location: Remote",$66.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Olsson
4.0",4.0,"Kansas City, MO",Senior Electrical Engineer - Arc Flash - Data Center (Remote),"Company Description

We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.
Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us — and will continue to allow us — to grow. The result? Inspired people, amazing designs, and projects with purpose.

Job Description

As an Electrical Engineer, you will work directly with some of the world’s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in performing short circuit analysis and producing arc flash studies is required. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.
We currently have one opening and will consider candidates interested in being located in most locations across the United States.

Qualifications

You are passionate about:
Working collaboratively with others
Having ownership in the work you do
Using your talents to positively affect communities
Electrical Engineering knowledge
You bring to the team:
Strong communication skills
Ability to contribute and work well on a team
Ability to be a self-starter to take on a variety of tasks to best serve the client and their project work
Investigation and troubleshooting of problems to find solutions
Ability to contribute and work well on a team
Bachelor's Degree in electrical engineering
8+ years or related electrical engineering experience
Registered professional engineer (PE) required
SKM and ETAP software experience is preferred

Additional Information

Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we’re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.
As an Olsson employee, you’ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you’ll:
Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)
Engage in work that has a positive impact in communities
Receive an excellent 401(k) match
Participate in a wellness program promoting balanced lifestyles
Benefit from a bonus system that rewards performance
Have the possibility for flexible work arrangements
Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.
#LI-MP1
#LI-REMOTE","$85,435 /yr (est.)",1001 to 5000 Employees,Private Practice / Firm,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1956,$100 to $500 million (USD)
"VISUAL SOFT, INC
4.1",4.1,"Washington, DC",Data Engineer - Active TOP SECRET - REMOTE-ONSITE,"Visual Soft, Inc is seeking qualified candidates to work on our efforts with a Prime for their end customer, a federal agency.

Position: Data Engineer - (50% REMOTE and 50% ONSITE)
Location: Washington, DC or Crystal City, Arlington, VA
Shift time: 8 am to 5 pm

JOB DESCRIPTION:
As a Data Engineer, you’ll implement data engineering activities on some of the most mission-driven projects in the industry. You’ll deploy and develop pipelines and platforms that organize and make disparate data meaningful. You will collaborate and work with and guide a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for your clients.
**Desirable skills include, Spark, Databricks, Data Lakes, Bigdata Tools and Technologies and AWS
Years of Experience:: 5+ years of experience
Education Requirement: BS degree preferred
Clearance requirement: Top SECRET is a MUST

Standard Benefits:
Our standard benefits include: Our standard benefits include 3 weeks of Paid time off (PTO that includes sick leave). Any unused PTO will be issued as a check at the end of an employee's anniversary with us. we also provide 2 floating and 8 public holidays. Floating and holidays expire at the end of every year of service of an employee. In addition, company will cover 50% of health and dental insurances only for all full time employees, however, dependents can be added at extra cost. Employee's health and dental coverage becomes effective after 30 days or first of the month after an employee completes initial 30 working days, we cover 50% for the employee's health and dental insurances. Dependents coverage for health and dental insurances is available as an out of pocket expense for employees. An employee has to finish all of your paper work for health and dental in the first 30 days of your employment with us. We provide STD, LTD and one time salary equivalent of life insurance at NO cost to all full time employees. All full time employees or w-2 employees with no benefits will be eligible to participate in company's 401k program after 90 days of employment with a company match of 4%, immediate vesting. In addition, all w-2 employees are eligible to be part of company's profit sharing, no employee contributions required. No commuting and/or parking expenses provided.","$93,472 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,$1 to $5 million (USD)
"Ansys
4.1",4.1,"Canonsburg, PA",Lead Application Engineer- Data Simulation Solutions,"When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.

Take a leap of certainty … with Ansys.

Summary / Role Purpose
Join the Ansys Customer Excellence team to partner with our customers to engineer what''s ahead, solve their real-world engineering problems, deploy Ansys software in their design workflows, and grow Ansys’ business. As a subject matter, industry and Ansys solutions expert, you will use advanced-level engineering knowledge to provide technical pre-sales support, perform professional services, and help guide Ansys product roadmap based on customer requirements. You will consult with customers on simulation-based solutions in support of their key business initiatives, lead project teams to create pervasive simulation solutions and mentor junior engineers.

Key Duties and Responsibilities
Lead in coordinating and executing all technical activities throughout the sales opportunity lifecycle such as technical discovery, negotiate technical success criteria, product presentations, demonstrations and evaluations. Work independently within multi-disciplinary teams
Help guide complex sales engagements to successful outcomes using subject matter expertise and industry knowledge
Interact with customers to understand their key business initiatives, product design needs and engineering design workflows; analyze how to address customers’ requirements using Ansys products and platform, articulate Ansys’ value proposition to Executive level audiences
Lead project teams to create differentiating simulation solutions using the Ansys platform and products; deploy the solutions within customers’ design workflows
Mentor junior engineers
Collaborate with the Ansys product development teams to guide Ansys product roadmap; lead project teams testing new releases of Ansys products on industrial problems, develop application best practices
Participate in corporate initiatives to further enhance Ansys technology, processes and people skills
Support Ansys field and digital marketing, author conference presentations
Contribute to consulting services, conduct intermediate and/or advanced training classes
Analyze business and technical needs, requirements, and the state of a customer’s current infrastructure, operations, and simulation & other engineering workflows
Consult our customers on process design and process optimization
Derive the technical specifications in collaboration with other business process analysts, subject matter experts, peers and Ansys Product Management
Develop creative and appealing Proof of Concepts to solve complex business problems
Lead/Assist in coordinating and executing all technical activities (design, develop, deploy) throughout the sales opportunity such as customer meetings and product presentations, demonstrations and evaluations with Ansys personnel and Services Partners
Utilize the components of the Ansys platform as the foundation for building complete solutions that digitally transform customer product development processes to facilitate more engineering in the digital domain by leveraging simulation
Participate in internal corporate initiatives to further enhance the solution suites, presales/sales enablement and business growth
Articulate the Ansys value proposition, which may encompass its entire suite of products (mechanical, fluid, electrical, electronics, optical, systems, software...).
Be a team player who can collaborate effectively with all key Ansys and customer stakeholders including sales, product development, project management, IT management, implementation engineers, and end users

Minimum Education/Certification Requirements and Experience
Required education and degree type: BS or MS or PhD in Mechanical/Chemical/Aerospace/Electrical Engineering or related field
Required minimum years of professional experience in an engineering software environment: BS+8, MS+6, or PhD+3
Subject matter expert in one or more relevant disciplines within Ansys’ business and is/will be sought out for advice by other Ansys engineers
Demonstrated understanding of engineering practices and product development, experience with building solutions using simulation technology and deploying those solutions within customers’ engineering workflows
Track record of delivering exceptional customer outcomes and revenue impact
Strong leadership and mentoring skills
Logical problem-solving, strong interpersonal and communication skills, fluent in writing and speaking English
Ability to organize and manage multiple projects which are complex in nature, possesses a sense of urgency
Projects a professional image and demonstrates business acumen, driven to succeed
Ability to travel domestically up to 25% of time
Proven track record of analyzing customer’s business and technical needs, requirements, and their state of current infrastructure, operations, and simulation & other engineering workflows
Proven track record of architecting solutions consisting of various (software) components and leading corresponding implementations
Experience in consulting customers on business process design and optimization
Self-starter who possesses a sense of urgency, strong organizational and follow up skills
Willing to evolve in a dynimic and innovative environment, eager to learn

Preferred Qualifications and Skills
Preferred education and years of professional experience in an engineering software environment: BS+12, MS+10, or PhD+7
4 years of experience in application engineering, customer support, or consulting services type customer facing roles using engineering software
Ability to interact effectively with senior business managers and C-level executives
Ability to travel domestically up to 50% of time
Demonstrated use of relevant Ansys software or knowledge of other commercial CAE, CAD, EDA, PLM software packages
Good understanding of enterprise class product development systems like SLM, SPDM, ERP, ALM, TDM, MIM/IMM, PDM, PLM (e.g. Aras Innovator, Siemens Teamcenter, Dassault ENOVIA or 3DEXPERIENCE, MSc SimManager, MSc MaterialCenter)
Basic understanding of programming languages such as: python, C# (.NET), Javascript, HTML,
Experience with DevOps/continuous integration and deployment
Practical knowledge of agility and agile project management
Ability in interest in obtaining a security clearance

This role is not available for sponsorship.

At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential in the knowledge that every day is an opportunity to observe, teach, inspire, and be inspired. Together as One Ansys, we are powering innovation that drives human advancement.

Our Commitments:
Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper
Our Values:
Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger

Our Actions:
We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results

OUR ONE ANSYS CULTURE HAS INCLUSION AT ITS CORE
We believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.

TAKE A LEAP OF CERTAINTY IN YOUR CAREER AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high - met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.

At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.

CREATING A PLACE WE’RE PROUD TO BE
Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: America’s Most Loved Workplaces, Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, U.K.).


For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.","$103,804 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Computer Hardware Development,1970,$1 to $5 billion (USD)
"EvolutionIQ
4.8",4.8,"New York, NY",Lead Data Infrastructure Engineer (AI / Insurtech),"About us: EvolutionIQ's mission is to improve the lives of injured and disabled workers and enable them to return to the workforce, saving billions of dollars in avoidable costs and lost productivity to the US and global economies and make insurance more affordable for everyone. We are currently experiencing massive growth and to accomplish our goals, we are hiring world-class talent who want to help build and scale internally, and transform the insurance space. We're backed by First Round Capital, FirstMark Capital, Foundation Capital, Brewer Lane Ventures, and have been named as Inc.'s top places to work!
Our Team: We are founded by a senior Google AI expert and a Bridgewater Associates Algorithmic Investor & Stanford MBA. We're not looking for employees. We're looking for partners in work, partners in culture-building, and partners in the future of data-driven insurance. The development team consists of world class engineers and leaders from companies like Google and Bloomberg. Each individual has had great success building large scale enterprise software and is now excited to try their hand at transforming the insurance industry.
Job Summary: We are looking for a Lead Engineer for our Data Platforms who will play an integral role in securing, architecting, and managing our highly sensitive insurance data. This position is tasked with overseeing our foundational datasets, data models, and analytics. The ideal candidate will have considerable experience in creating and managing secure data platforms, a strong engineering background, and a demonstrated record of technical leadership and effective communication.
In this critical role, you will not only ensure the robustness and reliability of our data systems, but also their security and compliance with stringent industry regulations. You will navigate the complexities of insurance data, bringing technical excellence and a security-first approach to safeguard our information assets. Your keen eye for security will be instrumental in protecting our company, customers, and stakeholders, while your technical expertise will shape the future of our data platform architecture.
Key Responsibilities:
Architect, design, and implement robust, secure, scalable, and high-quality data platforms, ensuring the availability, integrity, and confidentiality of the information.
Lead the development and maintenance of data pipelines, including personally coding and building the most critical components.
Work closely with product engineers, data scientists, analysts, and other stakeholders to understand data needs and deliver on those needs.
Define, design, and improve foundational data models to be used across the company to enable feature development and analytics.
Continuously improve our data quality toolkit
Provide guidance and technical leadership to the data engineering team, promoting continual team growth and individual team member skill development.
Be a role model for all engineers and provide mentorship as needed
Drive proof of concepts and experiments to explore new technologies that can level up the entire organization
Requirements:
7+ years of industry experience, holding staff/principal/lead level roles in Software Engineer or Data Engineer, with a focus in building scalable, mission critical, data platforms
Strong written and verbal communication skills
Extensive Python development experience
Experience with distributed data/computing tools, such as: Spark, Airflow, dbt
Proven track record of establishing engineering best practices for both coding and architecture
Experience building out systems and processes to enable secure handling of highly sensitive data
Experience using modern big data storage technologies such as Apache Parquet or Avro
Strong familiarity with modern data warehouse such as BigQuery or Snowflake
Ambitious, collaborative, and empathetic values
Even Better if You Have:
You have at least 3+ years experience in deploying systems on GCP or AWS
Experience with MLOps, such as feature engineering and model serving
You have worked with Dagster/Airflow, BigQuery, GCP, Terraform, Kubernetes, sklearn, keras/TensorFlow/pytorch, dbt, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions
The Fit: We're a team of architects and visionaries who thrive on being first. We've created a fun, passionate, humorous, friendly, and fiercely-driven engineering culture that values delivery and personal impact above everything else. We are open to sponsoring candidates who currently are in the US and need to transfer their active H1-B visa.
Work-life, Culture & Perks:
Compensation: The range is $210-240K depending on a candidate's background and experience.
Well-Being: Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%
Work/Life Balance: For this role we are hoping this person can work out of the NYC office regularly with much of our leadership with flexibility. We also have a flexible vacation policy and are closed for winter break at the end of the year
Home & Family: Flexible PTO, 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn
We also have a flexible vacation policy and are closed for winter break at the end of the year
Office Life: Catered lunches, happy hours, and pet-friendly office space. $500 for your in home office setup and $200/year for upgrades every year after your initial setup
Growth & Training: $1,000/year for each employee for professional development, as well as upskilling opportunities internally
Sponsorship: We are open to sponsoring candidates currently in the U.S. who need to transfer their active H1-B visa
EvolutionIQ appreciates your interest in our company as a place of employment. EvolutionIQ is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees","$88,635 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2019,$25 to $100 million (USD)
"Lyft
3.6",3.6,"San Francisco, CA",Senior Data Engineer,"At Lyft, community is what we are and it's what we do. It's what makes us different. To create the best ride for all, we start in our own community by creating an open, inclusive, and diverse organization where all team members are recognized for what they bring.
Here at Lyft, Data is the only way we make decisions. It is the core of our business, helping us create a transportation experience for our customers, and providing insights into the effectiveness of our product launch & features.
As a Data Engineer at Lyft, you will be a part of an early stage team that builds the data transport, collection, and storage, and exposes services that make data a first-class citizen at Lyft. We are looking for a Data Engineer to build a scalable data platform. You'll have ownership of our core data pipeline that powers Lyft's top-line metrics; You will also use data expertise to help evolve data models in several components of the data stack; You will help architect, building, and launching scalable data pipelines to support Lyft's growing data processing and analytics needs. Your efforts will allow access to business and user behavior insights, using huge amounts of Lyft data to fuel several teams such as Analytics, Data Science, Marketplace, and many others.
Responsibilities:
Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft
Evolve data model and data schema based on business and engineering needs
Implement systems tracking data quality and consistency
Develop tools supporting self-service data pipeline management (ETL)
SQL and MapReduce job tuning to improve data processing performance
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge
Unblock, support and communicate with internal & external partners to achieve results
Experience:
5+ years of relevant professional experience
Strong experience with Spark
Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet)
Strong skills in a scripting language (Python, Ruby, Bash)
Good understanding of SQL Engine and able to conduct advanced performance tuning
Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)
1+ years of experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)
Comfortable working directly with data analytics to bridge Lyft's business goals with data engineering
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.
Starting in September 2023, this role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.
The expected range of pay for this position in the San Francisco Bay Area is $162,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","$163,274 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Computer Hardware Development,2012,Unknown / Non-Applicable
"KaylaTek
4.2",4.2,"Andrews AFB, MD",Data Center Engineer- Senior - Secret Clearance,"$3,000 Referral Bonus for this position!
Come join our growing team with a 21st Century Vision! At KaylaTek, we understand that the key to our success is the quality of the people we employ. Our focus is not just on jobs, but on building and enhancing your career through ongoing professional development, training, and high quality of life. Our team members choose KaylaTek for a number of reasons including our competitive compensation and benefit packages, dedication to education, as well as our outstanding service. Our Grow Strong Vision encompasses a place for employees to grow, learn and feel a sense of belonging, not just a place to work.
Employee Benefit Offerings
Medical, Dental, Vision, 401(k) with company matching, Short-Term and Long-Term Disability, Life and AD&D Insurance, Paid Time Off, 11 Paid Holidays, Employee Assistance Program (EAP), Professional Development Program, Military Leave Support and much more.

Job Site: Joint Base Andrews, MD

Shift Hours: Day-Shift; core support hours are 0600 -1800. This is a 24/7/365 support environment; off-hours response/support may be required, however only standard M-F core hours working time for current position.
Overview: KaylaTek is seeking a Data Center Engineer to provide technical leadership and support in the areas of IT planning, solution specification/design, implementation and target architecture development for the AFNCR Consolidated Communication Center (CCC). The Data Center Engineer will support the 844th Communications Group at Joint Base Andrews (JBA). This role includes supporting the Air Force District of Washington (AFDW) and Headquarters Air Force (HAF) customers on both NIPRNet and SIPRNet domains for the development of the CCC building. The qualified candidate will have knowledge of information technology commercial solutions and experience designing and developing technical solutions. The preferred candidate will have excellent communications skills, a strong customer service orientation and experience serving as an advisor to Chief Architect and other Government/Contractor staff and managers.
Certifications required: Active Security + CE

Roles and Responsibilities:
Assist in planning, coordinating, and managing the technical aspects in projects related to the CCC datacenter. As well, identify and manage dependencies between these projects and with other ongoing activities.
Lead and assist with all design aspects of the CCC data center support systems, to include AC/DC power, UPS, HVAC, carrier infrastructures, internal/external cable plant, and overall data center layout.
Produce architectural artifacts to include system design diagrams, recommendation justifications, and technical specifications.
Communicate conceptual designs and create/maintain project documentation before, during, and after construction.
Create and review civil/structural/architectural design RFPs.
Assist with managing consultants/contractors through the design and construction process.
Effectively communicate design standards to internal and external project partners
Think outside of the box to find innovative solutions prior to and during the construction process to reduce costs without negative impacts on quality or reliability.
Conduct site assessments, internal design meetings, construction reviews.
Assess client's current IT and facility infrastructure.
Lead and assist with data center migration planning
Required Qualifications:
Bachelor's Degree with 15+ years in Civil Engineering or the equivalent relevant experience in datacenter or mission critical facilities design.
Possess an active Secret security clearance
Proficiency in building codes, regulations, and standards
Ability to build and maintain relationships, partnerships and external networks
Ability to work independently, with minimal supervision and work effectively in a collaborative team environment while keeping the team informed.
Excellent customer facing skills.
Excellent researching, decision-making and organizational skills are required.
Excellent written and verbal communication skills.
Proven analytical, evaluative, and problem-solving abilities.
Working knowledge of Microsoft Office Suite including Microsoft Visio or AutoCAD.
Maintain confidentiality and adhere to data protection and other guidelines where appropriate.
The above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of personnel so classified.
COMMITMENT TO DIVERSITY
KaylaTek is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.
E-VERIFY AND BACKGROUND CHECKS

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. KaylaTek participates in the DHS e-Verify program. KaylaTek also conducts a background check on all candidates post offer though PROScreening LLC.","$172,500 /yr (est.)",1 to 50 Employees,Company - Private,Government & Public Administration,National Agencies,#N/A,$1 to $5 million (USD)
"Google
4.4",4.4,"Omaha, NE","Data Center Engineer, Mechanical, Google Data Centers","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Council Bluffs, IA, USA; Omaha, NE, USA.
Minimum qualifications:
Bachelor's degree in Engineering, related technical field, or equivalent practical experience.
5 years of experience in the design-build environment for mission critical facilities (e.g., data centers, power plants, industrial, etc).
Experience in estimating, mechanical design, operation and commissioning of central utility plants, water processing systems, air distribution systems, and PLC/SCADA controls systems.

Preferred qualifications:
Professional Engineering License.
Experience with project total cost of ownership (TCO).
Construction administration or construction management experience.
Experience with large-scale mission critical facilities' mechanical infrastructure systems.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
In this role, you will have a primary focus on providing a deep technical understanding of Google’s data center design to field execution and operations teams in support of their initiatives. You will also support other teams in the development and evaluation of conceptual design.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.

The US base salary range for this full-time position is $136,000-$203,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities
Participate in the project specific design review process including conceptualizing ways to reduce total cost of ownership (TCO) while maintaining Google standards.
Coordinate with consulting engineers preparing construction documents as they develop detailed documentation based on the conceptual design standards developed and provided by others internally.
Work with the general contractor (GC) to develop a high level understanding of the design intent and on-time development of coordinated design details and delegated design elements in alignment with Google standards.
Monitor work in the field to ensure it is being executed in line with Google’s design intent and standards, as well as meeting the local codes and requirements.
Support systems startup and commissioning processes by providing a technical understanding of the gear being installed and how the systems are designed to function.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"Johns Hopkins Applied Physics Laboratory (APL)
4.2",4.2,"Laurel, MD",2024 PhD Graduate - AI/ML Data Scientist/Engineer - Analytic Capabilities,"Description

Are you searching for a place to build upon the foundation of your academic work?
Are you searching for engaging work with an employer that prioritizes impact, innovation, and personal development?
Are you motivated to apply your skills within a vibrant intellectual community?
If so, we're looking for someone like you to join our team at APL!
We are seeking recent college graduates to help us tackle the complex research, engineering, and analytical problems that present critical challenges to our nation. Our group is currently making critical contributions in the fight against online misinformation and development of the first truly autonomous UAV. Our work on the public health response to the COVID-19 pandemic was recognized by Time Magazine as one of the ""Best Inventions of 2020"". To address these emerging national challenges, we design and develop software systems that leverage the potential of data science, generative AI, large language models, and artificial intelligence across various domains, including social media analysis, healthcare, climate monitoring, cybersecurity, and signal & image processing.
As a member of our team you will...
Collaborate with dedicated colleagues in developing solutions that align with national priorities.
Harness your expertise in areas such as Artificial Intelligence, Machine Learning, Data Science, Cybersecurity, Software Engineering & DevOps, Signal and Image Processing, and Mathematics.


Qualifications

You meet our minimum qualifications for the job if you...
Have a PhD in Computer Science, Mathematics, Engineering, or related technical field.
Have maintained a minimum 3.0/4.0 GPA

Are able to obtain a Top Secret level security clearance. If selected, a government security clearance investigation will need to be conducted and the requirements met for access to classified information. Eligibility requirements include U.S. citizenship.

Why work at APL?
The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation’s most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates.

At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL’s campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers.


About Us

APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law.

APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.","$101,464 /yr (est.)",5001 to 10000 Employees,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,1942,$1 to $5 billion (USD)
"Onebridge
3.9",3.9,"Indianapolis, IN",MDM Data Engineer,"Onebridge is a Consulting firm with an HQ in Indianapolis, and clients dispersed throughout the United States and beyond. We have an exciting opportunity for a highly skilled MDM Data Engineer to join an innovative and dynamic group of professionals at a company rated among the top “Best Places to Work” in Indianapolis since 2015.
This role could be a full-time position on our team – or we would be open to engaging a consultant seeking their next contract experience.
MDM Data Engineer | About You
As an MDM Data Engineer, you are responsible for organizing and executing a Data Enablement program through project planning activities, cross-system coordination, and completion of deliverables. You are comfortable working with a team of data professionals to establish data management best practices and deliver high-quality data and information at scale to a wide variety of clients and industries. You are a strategic thinker who understands the impact that data quality can have on advancing an organization's BI Maturity, and you find excitement in building enterprise solutions to achieve an integrated data strategy.

MDM Data Engineer | Day-to-Day

Engineer end-to-end MDM solutions, including integration patterns (with operational and analytic systems), workflows, policies, support, and reporting associated with an enterprise MDM capability.
Develop and refine approved data models for enterprise integration.
Establish and improve relevant standards and governance.
Develop Master Data Management (MDM) technology-enabled solutions that address the needs of clients, including the design, automation, and orchestration of enterprise Master and Reference Data.
Use data quality tools to profile, cleanse, standardize, and enrich data.
Analyze problems and opportunities and their impacts on the business by considering all fact-based and stakeholder information to evaluate alternatives.
Define and implement data strategy, policies, controls, and programs to ensure the enterprise data are accurate, complete, secure, and reliable.
MDM Data Engineer | Skills & Experience

7+ years of progressive experience in Master Data Management (MDM) solution design, development, and implementation, with additional expertise in Reference Data Management, Data Governance, Data Management, Analytics, and Technology.
Support and maintain the MDM architecture by understanding the interaction of business processes with data entities/elements and ensuring the integrity of the MDM system.
Expertise working in a complex matrixed environment.
Expert-level SQL Skills.
Possess the ability to solve, design, and lead the implementation of MDM platforms and individual components.
Deep understanding of bi-directional MDM and the role it plays in an effective Data Management Strategy.
Skilled in working with at least one modern MDM platform, with knowledge of best-in-class options.
100% Employee-Owned & a Best Place to Work in Indiana, since 2015.","$103,378 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,Unknown / Non-Applicable
"CAI
3.9",3.9,"Charlotte, NC","Mechanical Commissioning Engineer II, Data Center Services","CAI seeks Mechanical Commissioning Engineers with a minimum of two years' experience in Data Center Commissioning to support development and execution of all mechanical aspects of commissioning projects.

Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range, not including benefits or compensatory time and possible discretionary bonuses.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.","$102,500 /yr (est.)",501 to 1000 Employees,Company - Private,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1996,$25 to $100 million (USD)
"American Business Solutions INC
3.8",3.8,"Columbus, OH",Data Engineer with Azure,"This position plays an important role in designing and constructing the agency’s data infrastructure using Microsoft Azure. This role will serve as the primary point of contact for the agency’s migration of its on-premises data warehouse and analysis workspace to Microsoft Azure.
The responsibilities and duties include:
Design and develop data infrastructure for the agency in Microsoft Azure
Recommend and implement solutions for data ingestion, ETL, data warehousing, and data analysis.
Manage access to data infrastructure datasets and analysis tools.
Develop budget for Microsoft Azure tools and provide recommendations on where to manage costs.
Build distributed computing analysis environment within Microsoft Azure in order to conduct more thorough analysis and integrate machine learning/AI tools to environment.
Design and develop database solutions using Microsoft SQL Server and Microsoft Azure tools (SSMS, SSRS, SSIS, Azure Data Factory, Azure Storage).
Manage data in variety of methods, to include SQL databases, NoSQL databases, file storage, and blob storage
Works with IT Architecture staff, CIO and/or IT Managers to design solutions that meet agency requirements
Design and implement high availability solutions
Data modeling to define and analyze data requirements for designing databases/data warehouses
Analyze on-premise database installations for Azure migration
Support data lake enterprise business initiatives
Support production and non-production environments incidents and requests
Code, test, debug, implement, and document data infrastructure design, construction, and remediation
Expert knowledge in SQL skills including stored procedure, trigger, index etc.
Experience with change management with respect to people, processes, and technologies
Develop, maintain, and support business applications (SQL/web-based apps)
Streamline and improve internal processes and reporting
Drive efficiency and operational improvement using data modeling techniques
Support and train users by providing directions, corrections, and enhancements; communicate with users to find solution to case
Analyze user requirements, procedures, and problems to provide coaching on system use, recommend changes and automation to improve efficiency
You’ll need the following qualifications and experience:
Bachelor’s degree in an appropriate field of study like Computer Science, Data Science, or Information Technology
Minimum seven years of database administration, data science, data engineering, and/or cloud-based data solution engineering.
Previous relevant experience with Microsoft suite of data solutions
Experience conducting performance tuning and configuration, creating data models, and managing data warehouses.
It’s a strong plus if you have:
Experience with Healthcare/Mental Health environment
Expertise in Python/R programming language
Familiar with reporting tools such as Power BI, Tableau, and Cognos
Collaborate with team leads to identify gaps and constraints associated with business requirements and processes and aid in providing solutions to resolve the process issues
Strong communication and interpersonal skills
Strong organization and time management skills
Ability to effectively handle multiple priorities
Ability to operate across the business and in different environments and cultures
Required/Desired Skills
SkillRequired/DesiredAmountof ExperienceBachelor’s degree in an appropriate fieldRequired0database administration, data science, data engineering, and/or cloud-based data solution engineeringRequired7YearsExpert knowledge in SQL skills including stored procedure, trigger, index etcRequired0Microsoft AzureRequired0Experience with Healthcare/Mental Health environmentNice to have0Expertise in Python/R programming languageNice to have0Familiar with reporting tools such as Power BI, Tableau, and CognosNice to have0
Job Type: Contract
Pay: $75.00 - $85.00 per hour
Experience level:
9 years
Schedule:
8 hour shift
Ability to commute/relocate:
Columbus, OH 43215: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 3 years (Preferred)
Data Engineering: 7 years (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person",$80.00 /hr (est.),51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,#N/A,$5 to $25 million (USD)
"BOEING
3.9",3.9,"Berkeley, MO",Phantom Works Systems Engineer and Data Architect (Experienced OR Lead),"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
Boeing Defense, Space, and Security (BDS) is seeking data architects to join a Digital Engineering team supporting a proprietary program developing next generation systems.

This is an exciting role to understand, architect and integrate data flows across the program lifecycle to create digital system models and digital twins of the as-designed, as-tested, as-built and as-operated product. In this role, you will apply an interdisciplinary, collaborative approach to plan, design, develop, integrate, and verify digital engineering solutions. We’re looking for data architects and integrators with interest and experience in model based engineering, who also have experience in one or more of the following areas: systems engineering, aircraft design, test, production, and product support. You will help build and mature the digital ecosystem, including: realizing the program data architecture, expanding digital threads, growing digital system models, connecting and controlling data, and enabling advanced data analytics.

Digital engineering is changing the way we execute our programs, collaborate with our customers and teammates, and enable advanced downstream capabilities.
Our teams are currently hiring for a broad range of experience levels including; Experienced or Lead Level Systems Engineers.
Primary Responsibilities:
Work across disciplines to model the data architecture of the program
Be the digital engineering focal to multiple aircraft design teams, production teams, verification/validation teams, and/or product support teams.
Develop and implement strategies to integrate data across multiple tools and technologies to create digital threads and enable digital twins.
Guide and coordinate development and deployment of new or revised processes in support of new computing systems, including documentation and training.
Define and validate complex requirements for new hardware and software systems.
Facilitate development of system integration strategies and architectures that promote use of common tools and processes.
Lead development of trade studies and other forms of analysis to formulate optimum solutions for users.
This position is expected to be 100% onsite. The selected candidate will be required to work onsite at one of the listed location options. (St. Louis or Huntsville)
This position requires an active U.S. Secret Security Clearance, for which the U.S. Government requires U.S. Citizenship. (A U.S. Security Clearance that has been active in the past 24 months is considered active)
Special Program Access or other Government Access Requirements are mandatory for this position.
Basic Qualifications (Required Skills and Experience):
A technical bachelor's degree with 5+ years, or MS/MA degree with 2+ years of relevant work experience, or a PhD degree with 1+ years of relevant work experience. A relevant degree is defined as one in a quantitative field such as Computer Science, Statistics, Mathematics, Computer Engineering, Software Engineering, Electrical Engineering, Aerospace Engineering, Physics, Chemistry, Operations Research, Bioinformatics, Economics, Computational Biology, or other technical degree.
Experience developing and documenting architecture using Cameo, or similar Model Based Systems Engineering (MBSE) tools
Ability to work effectively in a team environment and communicate with stakeholders of different backgrounds and skill levels
Preferred Qualifications (Desired Skills and Experience):
5 or more years' related work experience or an equivalent combination of education and experience
Experience with data modeling, ontology, and industry standards for data exchange
Experience with Siemens Product Lifecycle Management Suites
Prior experience in software development and test tools/IDEs (e.g. off the shelf or source code editors, compilers, configuration management tools, requirements management, and source control tools)
Experience in mechanical, structural, or electrical design
Experience with physics-based modeling tools
Experience with production engineering, future manufacturing systems, and/or supplier management
Experience with integration, verification, validation and/or flight test
Experience with product support, logistics, training systems, and/or maintenance systems
Typical Education and Experience:
Experienced Level 3:
Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) and typically 5 or more years' related work experience or an equivalent combination of education and experience (e.g. PhD, Master+3 years' related work experience). In the USA, ABET accreditation is the preferred, although not required, accreditation standard.
Lead Level 4:
Bachelor's degree and typically 9 or more years' experience in an engineering classification or a Master's degree with typically 7 or more years' experience in an engineering classification or a PhD degree with typically 4 or more years' experience in an engineering classification. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.
Relocation:
This position offers relocation based on candidate eligibility.
Drug Free Workplace:
Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies
""At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.
The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.
The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.
Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations.
Summary pay range for Mid-Level 3 Berkeley MO: $97,750 - $132,480
Summary pay range for Lead Level 4 Berkeley MO: $119,850 - $162,150
Summary pay range for Mid-Level 3 Huntsville AL: $97,750 - $132,250
Summary pay range for Lead Level 4 Huntsville AL: $119,850 - $162,150

Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Equal Opportunity Employer:
Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.","$86,177 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1916,$10+ billion (USD)
"HCA Healthcare
3.3",3.3,"Nashville, TN",Principal Data Engineer,"Introduction
Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As a Principal Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Principal Data Engineer to help us reach our goals. Unlock your potential!
Job Summary and Qualifications
HCA Healthcare ITG
Job Summary:
The role requires working closely with others, frequently in a matrixed environment, and with little supervision. As a Principal Data Engineer/Architect level, the role requires 'self-starters' who are proficient in problem solving and capable of bringing clarity to complex situations. It requires contributing to strategic technical direction and system architecture approaches for individual projects and platform migrations. The culture of the organization places an emphasis on teamwork, so social and interpersonal skills are equally important as technical capability. Due to the emerging and fast-evolving nature of GCP/Big Data technology and practice, the position requires that one stay well-informed of technological advancements and be proficient at putting new innovations into effective practice.
Responsible for leading GCP development efforts, driving adoption and appropriate use of technology and consulting on internal and external development efforts to ensure code quality and sound architecture. This position that assumes the responsibility for project success and the upward development of team members technical skills. They are the development team's point of contact that must interface with business partners of varying roles ranging from technical staff to executive leadership. In addition, this candidate will have a history of increasing responsibility in a multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement cutting-edge technical data solutions with minimal supervision.
As a Principal Data Engineer/Architect, you will work closely with all team members to create a modular, scalable solution that addresses current needs, but will also serve as a foundation for future success. The position will be critical in building the team’s engineering practices in test driven development, continuous integration, and automated deployment and is a hands-on team member who actively coaches the team to solve complex problems. She / he will be responsible for the design, development, performance and support of the Cloud Platform components.
This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team (consultant and employee) environment. In addition, the applicant must be willing to train and mentor other developers to prepare them for assuming the responsibilities.
General Responsibilities:
Responsible for building and supporting a GCP/Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
Bring new data sources into GCP/HDFS, transform and load to databases.
Lead projects in delivering the data and projects on-time
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Leads efforts to design, development, deploy, and support software systems
Experience with HL7, FHIR, and Whistle mapping.
Collaborates with business analysts, project lead, management and customers on requirements
Participates in large-scale development projects involving multiple areas outside of core team
Designs fit-for-purpose products to ensure products align to the customer's strategic plans and technology road maps
Demonstrates deep understanding and coaches’ value-based decision making and Agile principles across teams
Coaches team on clinical data, existing system structure, constraints and deficiencies with product
Shares knowledge and experience to contribute to growth of overall team capabilities
Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems
Work closely with management, architects and other teams to develop and implement the projects.
Actively participate in technical group discussions and adopt any new technologies to improve the development and operations.
Focuses on customer satisfaction
Rapidly prototypes and delivers just-in-time solutions
Gather requirements, designs, constructs and delivers solutions with minimal team interaction
Works in an environment with rapidly changing business requirements and priorities
Demonstrates deep understanding and acts as a leader in the team’s continuous integration and continuous delivery automation pipeline
Work collaboratively with Data Scientists, business, and IT leaders throughout the company to understand Cloud/Big Data needs and use cases.
Education, Experience and Certifications:
Bachelor's Degree in computer science or related field – Required
Master's Degree in computer science or related field – Preferred
3+ years of experience in Data Engineer – Required
1+ year(s) of experience in Healthcare – Preferred
10+ years of experience in Information Technology – Required
GCP Cloud Professional Data Architect certification – Preferred
GCP Cloud Professional Data Engineer certification – Preferred
Other Required Qualifications:
A successful candidate will have:

Strong understanding of best practices and standards for GCP application design and implementation.
Two Year of hands-on experience with GCP platform and experience with many of the following components:
GCS, Cloud Run, Cloud Functions
Bigtable, Cloud SQL
Kafka, Pub/Sub
Python, Golang, Spark, Scala or Java
BigQuery, Dataflow, Data Fusion
CICD process and Logging & Monitoring
OpenShift, Docker
Experience with Unstructured Data, Real-Time Streaming with GCP
Ability to multitask and to balance competing priorities.
Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support.
Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.
A successful candidate may have:
Experience in Healthcare Domain
Experience in Patient Data
Experience with Natural Language Processing (NLP)
Azure/AWS Cloud experience
Hands-on experience with Cloudera Distributed Hadoop (CDH)
Hardware/Operating Systems:
Linux, UNIX
GCP
Distributed, highly-scalable processing environments
Databases:
NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies
Build Systems – TFS, Github
Ability to integrate tools outside of the core Cloud ecosystem
Physical Demands/Working Conditions
Prolonged sitting or standing at computer workstation including use of mouse, keyboard, and monitor.
Requires ability to provide after-hours support.
Occasional Travel: The job may require travel from time- to-time, but not on a regular basis.
HCA Healthcare’s Information Technology Group (ITG) delivers healthcare IT products and services to HCA Healthcare's portfolio of business and partners, including Parallon, HealthTrust and Sarah Cannon.

For decades, ITG has been a pioneer in the industry, leading the transformation of healthcare into a new era of quality and connectivity. ITG relies on the breadth of the organization and depth of technical expertise to advance and enhance today’s healthcare and to enable our physicians and clinicians to provide world-class, innovative care for patients.

ITG employees rally around the noble cause of transforming healthcare through technology and find inspiration in the meaningful work they do—creating a culture that follows our mission statement which begins by saying “above all else we are committed to the care and improvement of human life.”

If you want a career in technology and have a heart for healthcare, apply your expertise to a mission that matters.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.
""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
Be a part of an organization that invests in you! We are reviewing applications for our Principal Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$120,425 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
"Wipro Limited
3.1",3.1,"Minneapolis, MN",Data Engineer - Apache Spark,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS
Role – Data Engineer - Apache Spark
Location – Minneapolis, MN (Day 1 onsite)
Yrs. of experience – 10+ Yrs.
Mode of employment – Full-Time

Job Description:
Strong in Spark Scala development (Minimum 5 years of experience).
Especially Persons should have good experience on building ETL pipeline using Scala.
Strong in SQL Concepts and Development
Must have worked on any ETL tool like Data stage, Spark /Scala etc... Preferred Data Stage.
Unix / Python Shell Scripting (Minimum 3 to 4 years)
Strong understanding of Hadoop eco system
Very well versed with Agile Methodology - Scrum boards.
Capable of handling scrum ceremonies in absence of scrum master.
Other tools – Jenkin, Autosys, GitHub, etc..
Any Cloud experience is plus. Preferred Azure

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.

#LI-AK2","$96,774 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1945,$5 to $10 billion (USD)
"Jack In The Box
3.4",3.4,"San Diego, CA",Lead Data Engineer,"Jack in the Box is seeking a Lead Data Engineer who will be responsible to provide analytic and strategic technical leadership & support to the Enterprise Data Team, which is responsible for scaling and maintaining the core data platform and maturing the analytical capabilities of the organization. Contributes to data & engineering innovations facilitating critical business insights that fuel Jack in the Box Inc.s vision and mission.

KEY DUTIES/RESPONSIBILITIES:
Collaborates with functional & business leaders and teams and works closely with the Data Engineering team to manage complex data systems in enabling decision support and key insights across the organization.

Implements data governance practices in partnership with business stakeholders and peers.

Works with a team of high-performing analysts, data engineering professionals and cross-functional teams to identify business opportunities, monitor data platform performance and optimize analytical capabilities.

Builds, evolves and maintains the infrastructure required for optimal transformation and integration from a wide variety of data sources using appropriate data integration technologies. Deploys pipelines using scheduling and orchestration frameworks to support the organizations growing data processing and analytics needs.

Takes ownership of core data pipelines that power the organizations analytical metrics.

Uses data expertise to evolve data models in several components of the data stack & helps architect, build, and launch scalable data pipelines to support the organizations growing data processing and analytics needs.

Creates proof of concepts per business requirements.

QUALIFICATIONS:
Education: Bachelors degree in Engineering, Computer Science, Information Systems or related field.

Experience: 12+ years staff/lead/senior software data engineer experience building and supporting data intensive applications, tackling challenging architectural, scalability and reliability problems. Experience includes working with Data Warehouse, Data Lake, Data Hub and the supporting processes (Data Integration, Governance, Metadata Management).

Skills/Knowledge/Abilities:
Skilled in building and maintaining data quality frameworks, data observability and monitoring frameworks.

Experience in leveraging Observability tools such as Splunk/Datadog/New Relic/MonteCarlo or equivalent.

Extensive experience manipulating and analyzing large data sets.

Experience designing, deploying, and maintaining business application on AWS stack, leveraging services such as EC2, ECS, Lambdas, AWS Step functions, Redshift, Tableau, AWS Glue OR equivalent expertise in other cloud platforms such as Azure, GCP etc. Experience with on-prem & relational platforms Oracle, SQL Server, PostGres , MySQL etc. Integration of cloud services with on premise technologies.

Experience working with DevOps capabilities like version control, automated builds, testing and release management capabilities using tools like Git, Jenkins etc.

Extensive knowledge in application monitoring, handling user tickets, analyzing data issues.

Experience with data modeling, data mining, and predictive analysis. Ability to effectively test and document work.

Possesses excellent interpersonal, communication, and problem solving skills.

Ability to juggle multiple projects, tasks, and deadlines.

Strong understanding of SQL and NOSQL database concepts.

Strong experience with advanced analytics tools for Object-oriented/scripting languages such as R, Python, Java, Scala, or others.

Comfortable working in an unstructured environment, taking ownership for results and self-directing your efforts to the subject areas and questions which have the greatest potential impact on the business. Comfortable working in an agile environment

Proven track record of being personally accountable for the analysis and technical enhancements that drive a business at a large scale.

Skilled in building reports and dashboards through the use of dashboarding tools like Tableau, PowerBI, Quicksight, Looker.

Will be a self-starter, initiate and drive projects to completion with minimal guidance.

PHYSICAL REQUIREMENTS:
Ability to speak/hear clearly in person and on the telephone and ability to operate a computer (desktop, tablet, etc.).

REASONABLE ACCOMMODATION:
Jack in the Box, Inc. and its affiliates will make reasonable accommodations to allow a qualified individual with a disability to enjoy equal employment opportunities and to perform the essential functions of the job. This position description should be applied accordingly. This description of duties is not intended to be all-inclusive or to limit managements discretion to assign other duties or responsibilities as necessary.

Jack in the Box Inc. offers a competitive salary and Total Rewards package that includes: medical, dental, vision, Health Savings Account (HSA), Flexible Spending Account (FSA), Life and Disability Plans, 401(k) plan with company match, Legal Plan, Pet Insurance, Tuition Reimbursement, and Employee Assistance Program.

Our culture is fun and innovative Work Happy with us!

The range for this position is $149,700 - $208,500 and is based on an employee located at our corporate headquarters in San Diego. If the candidate is hired in a different city to work remote, we will apply a geographic pay differential based on the cost of labor in the market in which the employee resides.

Brand: Jack In The Box
Address: 9357 Spectrum Center Blvd. San Diego, CA - 92123
Property Description: Jack in the Box Corporate
Property Number: XX9101","$153,458 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1951,$1 to $5 billion (USD)
"Synchrony
4.3",4.3,"Chicago, IL","AVP, Principal Data Engineer","Job Description:
Role Summary/Purpose:
We are looking for a Principal Data Engineer to lead the development of consumer-centric low latency analytic environment leveraging Big Data technologies and transform the legacy systems. This role is an exciting, fast-paced, constantly changing, and challenging work environment, and will play an important role in resolving and influencing high-level decisions across Synchrony.
We’re proud to offer you choice and flexibility. You have the option to be remote, and work from home, or come into one of our offices. You may be occasionally requested to commute to our nearest office for in person engagement activities such as team meetings, training and culture events.
Essential Responsibilities:
Understand and manage the data needs of stakeholders across multiple agile teams.
Lead the design & implementation of scalable & fault tolerant data applications on Big-Data & Cloud Platforms to store & process terabytes of data from upstream sources with high availability.
Engage with and take direction from information architects, platform architects, data scientists and product management on solution requirements to design solutions.
Contribute to high impact problems/projects through in-depth evaluation of complex business processes, system processes, enterprise standards & procedures.
Enforce data management standards and procedures
Lead design, development, testing oversight and production implementation using Spark, Hive, Kafka, RDBMS (Oracle, MySQL), NoSQL databases (Cassandra), Ab Initio and AWS.
Partner with multiple teams to ensure appropriate data solutions to meet goals as well as identify and define necessary system and process enhancements.
Provide technical leadership for data engineering agile teams to deliver against sprint and program increment objectives.
Work closely with Product Owners, Product Managers, Program Manager, Scrum Masters and Team Members in a Scaled Agile framework.
Stay up to date on latest trends in data engineering and recommended best practices.
Develop innovative frameworks to avoid redundancy by promoting automation.
Mentor and coach data engineering team members to promote Synchrony values and culture.
Perform other duties and/or special projects as assigned

Qualifications/Requirements:
Bachelor’s degree in Computer Science, Engineering, or a related field with 6+ years of experience in ETL/Data warehousing with 4+ years of experience with large scale Big Data environments such as Hortonworks/Cloudera and public cloud (AWS preferred).
Prior experience as a Hadoop Technical Lead / Architect
Strong experience and deep understanding of ETL, data warehousing, data lake technologies (Hadoop & Spark) and analytics concepts.
Experience owning a mission critical application on a big data platform.
Experience with batch and real-time data pipelines in a DevOps environment.
Willing to work in a fast-paced environment with globally located Agile teams working in different shifts.
Ability to develop and maintain strong collaborative relationships at all levels across IT and Business Stakeholders.
Excellent written and oral communication skills. Adept and presenting complex topics, influencing and executing with timely / actionable follow-through.
Desired Characteristics:
Prior work experience in a Credit Card/Banking/Fin Tech company.
Experience dealing with sensitive data in a highly regulated environment.
Demonstrated implementation of complex and innovative solutions.
Demonstrated leadership capabilities amongst peers and within prior teams.

Grade/Level: 11

The salary range for this position is 90,000.00 - 155,000.00 USD Annual and is eligible for an annual bonus based on individual and company performance.
Actual compensation offered within the posted salary range will be based upon work experience, skill level or knowledge.
Salaries are adjusted according to market in CA, NY Metro and Seattle.
Eligibility Requirements:
You must be 18 years or older
You must have a high school diploma or equivalent
You must be willing to take a drug test, submit to a background investigation and submit fingerprints as part of the onboarding process
You must be able to satisfy the requirements of Section 19 of the Federal Deposit Insurance Act.
New hires (Level 4-7) must have 9 months of continuous service with the company before they are eligible to post on other roles. Once this new hire time in position requirement is met, the associate will have a minimum 6 months’ time in position before they can post for future non-exempt roles. Employees, level 8 or greater, must have at least 18 months’ time in position before they can post. All internal employees must consistently meet performance expectations and have approval from your manager to post (or the approval of your manager and HR if you don’t meet the time in position or performance expectations).
Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
Our Commitment:
When you join us, you’ll be part of a diverse, inclusive culture where your skills, experience, and voice are not only heard—but valued. We celebrate the differences in all of us and believe that our individual, unique perspectives is what makes Synchrony truly a great place to work. Together, we’re building a future where we can all belong, connect and turn ideals into action. Through the power of our 8 Diversity Networks+, with more than 60% of our workforce engaged, you’ll find community to connect with an opportunity to go beyond your passions.
This starts when you choose to apply for a role at Synchrony. We ensure all qualified applicants will receive consideration for employment without regard to age, race, color, religion, gender, sexual orientation, gender identity, national origin, disability, or veteran status.
Reasonable Accommodation Notice:
Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.
If you need special accommodations, please call our Career Support Line so that we can discuss your specific situation. We can be reached at 1-866-301-5627. Representatives are available from 8am – 5pm Monday to Friday, Central Standard Time
Job Family Group:
Information Technology","$122,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,2014,$10+ billion (USD)
"Geopaqlogic Staffing
4.7",4.7,"Ridgefield Park, Bergen, NJ",Data Engineer (W2 only),"Position: Data Engineer
Work Location: Ridgefield Park, NJ (Hybrid - Need to be visit only once in a month)
Contract period: 6+ months (W2 only)
Note: Must have experience in GCP (Google Cloud Platform) and/or Spark
SUMMARY OF ESSENTIAL JOB FUNCTIONS:
· Design and develop analytical models and be the face to the data consumers
· Perform data curation to meet the business requirements
· Build batch and streaming data pipelines
· Develop processes for automating, testing, and deploying your work
· Identify risks and opportunities of potential logic and data issues within the data environment
· Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUM RETIREMENTS:
· Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
· Must have experience in GCP (Google Cloud Platform) and/or Spark
· 3+ years of experience as Data Engineer or in a similar role
· Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
· Cloud to Cloud migration experience preferred
· Strong PySpark skill is a must have
· Have knowledge of data management fundamentals and data storage principles
· Have knowledge of systems as it pertains to data storage and computing
· Strong source to target mapping experience and ETL principles/knowledge
· Excellent verbal and written communication skills.
· Strong quantitative and analytical skills with accuracy and attention to detail
· Ability to work well independently with minimal supervision and can manage multiple priorities
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Benefits:
Health insurance
Paid time off
Ability to commute/relocate:
Ridgefield Park, NJ 07660: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Engineering: 5 years (Preferred)
Software development: 5 years (Preferred)
Business intelligence: 3 years (Preferred)
GCP (Google Cloud Platform: 3 years (Preferred)
Pyspark: 5 years (Preferred)
Work Location: In person",$65.00 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2014,$1 to $5 million (USD)
"Oracle
3.9",3.9,"Seattle, WA",Senior Software Engineer (Join OCI: Horizon Data Warehouse team),"As a Senior Software Engineer on the Horizon Data warehouse team, you will help our development efforts as we build the technology platform that will act as the central data platform inside OCI for 100's of teams. You will be a core contributor on a team of software engineers working to grow and scale our service.

Basic Qualifications
4+ years of experience in the design and implementation of complex software systems
Strong Knowledge of Data Warehousing, ETL processes, Cloud Computing and Data Security concepts is a must.
Proven experience with a Programming language PLSQL is a must.
Sound fundamentals in coding, algorithm design, problem solving, and complexity analysis.
Proven experience with a major Programming language such as Java, Python, Go, C# or C++ is a plus.
Aptitude for problem solving.
Experience with massively scalable systems is a plus.
Experience with Cloud Platforms such as OCI, AWS, Azure or GCP is a plus.
Experience with enterprise-class RDBMS (Oracle, SQL*server), Cloud Data warehouse (Snowflake/Redshift).
Preferred Qualifications
Experience building distributed cloud services.","$146,533 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
"Logistics Management Institute
4.3",4.3,"Washington, DC",Data Engineer - TS/SCI Required,"Overview:
LMI is seeking a Senior Data Engineer to support our Intelligence Community client.

LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers’ unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies.

LMI has been named a 2022 #TopWorkplace in the United States by Top Workplaces! We are honored to be recognized as a company that values a people-centered culture, and we are grateful to our employees for making this possible!
LMI is seeking a skilled Senior Data Engineer to support data pipelining and sustainment of a client’s SQL database. Successful Data Engineers demonstrate competency in data acquisition, data analysis, programming, project execution, and critical thinking. In addition, LMI Data Engineers have demonstrated experience in collaborating with other Data Engineers and with effective communication with clients.
Responsibilities:
This data engineer will work as part of a team of experienced data scientists, data analysts, and full stack developers to develop and maintain applications that enable client business processes. Responsibilities include:
Defining and developing techniques to integrate, consolidate, and structure data for functional workflows and analytical use
Understanding complex and organization-specific datasets.
Producing dashboards and visualizations to support complex client requirements.
Conducting root cause analysis, identifying errors, and refactoring pipelines as needed.
Performing analyses to answer routine and ad hoc questions as identified in the data being leveraged
Developing and improving standard operating procedures.
Communicating with data analysts and developers to design tools and applications to improve response to repeat requests.
Researching, analyzing and documenting the benefits of various technical approaches.
Proposing alternative designs and processes to manage various types of data using both standard and custom tables and fields.
Working in teams and independently.
Understand and analyze complex and organization-specific datasets.
Support the maturation of data quality
Support the transformation of businesses process through automation
Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available visualization and dashboard tools
Advising on the interpretation and use of data analysis products, dashboards and reports to non-technical customers
Assisting the development of junior teammates through technical mentoring, code review, and other assistance.
Qualifications:
Required:
Bachelor’s degree in science, engineering, mathematics, computer science, information systems, data analytics, or other related business or quantitative discipline
7+ years experience in data engineering or related field
Experience with ETL process and concepts
Knowledge and experience manipulating and joining data from various sources and in various formats.
Ability to query datasets from multiple sources, knowledge of data refresh methodologies, and ability to leverage data models.
High level of competency with data engineering coding languages like SQL and Python
Self-starter with the vision to independently identify opportunities for improvement through data analytics
A true team player who maintains a positive attitude in a dynamic environment
Excellent communication skills, written and oral
Proven ability to work with business customers and technical teams
Highly organized and able to manage multiple projects simultaneously
Excellent customer relationship management skills
Innovative problem-solving skills and ability to thrive in a fast-paced environment
Ability to work on client site in the NCR in Washington, D.C.
This position requires an active security clearance at the TS/SCI level with the ability/willingness to receive a polygraph. Current polygraph preferred.
Desired:
Masters degree or higher
Experience developing dashboards using Tableau, Qlik, Power BI, RShiny, plotly, or d3.js
Experience with version control software like Git
Experience with Agile development
Management consulting experience desired

#LI-SH1","$112,206 /yr (est.)",1001 to 5000 Employees,Company - Private,Management & Consulting,Business Consulting,1961,$100 to $500 million (USD)
"Intellibus
4.6",4.6,"Newark, NJ",Sr. Data Engineer — Snowflake,"Are you a Data Engineer working at a Large Financial Institution and being told by your leadership that you are too hands-on or detail-oriented or think and work like a start-up?
Imagine working at Intellibus to engineer platforms that impact billions of lives around the world. With your passion and focus we will accomplish great things together!
We are looking forward to you joining our Platform Engineering Team.
Our Platform Engineering Team is working to solve the Multiplicity Problem. We are trusted by some of the most reputable and established FinTech Firms. Recently, our team has spearheaded the Conversion & Go Live of apps that support the backbone of the Financial Trading Industry.
We are looking for Engineers who can
Create Data modeling
Work on Snowflake modeling – roles, databases, schemas, ETL toolswith cloud-driven skills
Work on SQL performance measuring, query tuning, and database tuning
Handle SQL language and cloud-based technologies
Set up the RBAC model at the infra and data level.
Work on Data Masking / Encryption / Tokenization, Data Wrangling / ECreLT / Data Pipeline orchestration (tasks).
Setup AWS S3/EC2, Configure External stages and SQS/SNS
Perform Data Integration e.g. MSK Kafka connect and other partners like Delta lake (data bricks)
We work closely with
Data Wrangling
ETL
Talend
Jasper
Java
Python
Unix
AWS
Data Warehousing
Data Modeling
Database Migration
ECreLT
RBAC model
Data migration
Our Process
Schedule a 15 min Video Call with someone from our Team
4 Proctored GQ Tests (< 2 hours)
30-45 min Final Video Interview
Receive Job Offer
If you are interested in reaching out to us, please apply and our team will contact you within the hour.
Job Type: Full-time
Pay: $60.00 - $80.00 per hour
Schedule:
Monday to Friday
Experience:
Data Wrangling: 7 years (Preferred)
Snowflake: 7 years (Preferred)
ETL: 7 years (Preferred)
Work Location: In person",$70.00 /hr (est.),Unknown,Unknown,Information Technology,Information Technology Support Services,2015,Unknown / Non-Applicable
Bonsai Robotics,#N/A,"San Jose, CA",Senior ML Ops Engineer - Data,"Job Overview:

We are seeking a highly skilled Sr. ML Ops engineer to join our team. As a ML ops engineer, you will develop, implement, and optimize our custom data pipelines for our ML systems. You should have a strong background in any of the following technologies: Databases(SQL, MongoDb), Cloud frameworks (AWS) and ML Frameworks (Pytorch/tensorflow). The ideal candidate will be proficient in programming languages such as C++ and Python.
About Bonsai:
Bonsai Robotics' mission is to create the next leap forward in agriculture equipment efficiency by creating a new ecosystem of semi-autonomous robotic machinery. Orchards are dusty, hazard-filled, and GPS-denied. The GPS-based autosteer features that have driven row crop efficiencies cannot function in orchards. Our vision, AI, and machine control systems offer human-level environment understanding and local navigation capabilities and will be the platform for a new wave of innovation in agricultural production and management systems.
We simultaneously solve twin crises impacting nut growers and most of specialty agriculture: there is not enough human labor when you need it, and operational expenses are growing dramatically. Our state-of-the-art technology empowers orchard managers to optimize their operations, dramatically reduce operational expenses, and increase profitability. We are pursuing a Bonsai Inside strategy, and partnering with the largest orchard Original Equipment Manufacturers (OEMs) in the retrofitting of existing machines and design of new form factors.
Key Responsibilities:
Develop, implement, and optimize data pipelines for ML systems.
Collaborate with cross-functional teams to store, process and certify petabytes of Image+Video data.
Coordinate with 3rd parties to handle labeling pipelines.
Create and maintain code documentation and unit tests.
Collaborate with ML scientists and provide data insights
Qualifications:
Bachelor's or Master's degree in Computer Science, Robotics, Electrical Engineering or related field
Strong background in most of the following technologies: Backend engineering, Data engineering, Databases, Dev Ops
Expert in Creating ETL pipelines
Proficiency in programming languages such as C++ and Python
Strong problem-solving skills and ability to work in a fast-paced environment.
Strong verbal and written communication skills.
Bonus: Experience with Pytorch and Ros 2
If you have a passion for computer vision, robotics, and developing innovative technology solutions, we encourage you to apply for this exciting opportunity. Bonsai Robotics values diversity, inclusivity, and excellence in hiring and strongly encourages candidates from traditionally underrepresented backgrounds to apply.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Allata LLC
4.3",4.3,Remote,Data Architect/Lead Engineer - Consulting (Remote Possible),"Allata is growing our Data & Analytics Practice to serve our clients nationwide. Our data architect / lead engineer practitioners will be collaborating with data engineers, machine learning engineers, analysts, data scientists, and other Allata employees and client teams on projects for companies across the United States.
WHAT YOU'LL BE DOING
Work with customers to build cloud-based data platforms, including integration, data storage and analytics
Develop innovative architectures to solve complex business problems utilizing the latest cloud technologies
WHAT YOU'LL NEED
Data Architecture Best Practices. You’ve successfully built data solutions that use industry best practices and fit with an organization’s needs. You are excited by solving problems and voraciously consume technology to do so. You have a broad and deep technical background
Communication. You have a natural charisma and use it to build consensus. You can have a conversation with developers, business analysts, managers of all levels, and individuals in a business function. You are comfortable presenting in front of groups and explaining architectures in a variety of levels of detail.
Make teams better. You're excited to be part of a team that delivers with quality and works hard on new opportunities. You work well in fast-moving environments and have no problem working with others to resolve difficult problems. You support teams as much as others supports you.
DESIRED SKILLS & EXPERIENCE
8-10 years of experience in a data related field
Experience building data storage and analytic solutions utilizing Snowflake
Expertise in building data platforms in Azure or AWS
Experienced with ETL tools such as Azure Data Factory, AWS Glue, WhereScape RED, Streamsets, Informatica and SAP Convergent Mediation
Experience in one or more Cloud Data Warehouse (Azure SQL Data Warehouse / Synapse Analytics, Snowflake, Amazon Redshift, Google BigQuery)
Experience in one or more Data Visualization tool (Tableau, PowerBI)
Expertise modeling architectures and integrations for data environments including data pipelines, data lakes, data warehouses, and data marts.
Experience with data backup and recovery strategies, optimization of clusters, structured/semi structured data, and changing database storage and utilization requirements
Experience with scripting languages such as Python / R for Business
Experience with Event Driven Architecture (Kafka)
Experience with large-scale distributed storage and database systems (e.g. SQL, NoSQL, MySQL, Cassandra)
At Allata, we value differences.
Allata is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Allata makes employment determinations without regard to race, color, creed, religion, age, ancestry, national origin, veteran status, sex, sexual orientation, gender, gender identity, gender expression, marital status, disability, or any other legally protected category.
This policy applies to all terms and conditions of employment, including but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Software Development,2016,$25 to $100 million (USD)
"RSA
4.0",4.0,"Overland Park, KS",Archer Business Enablement Data Engineer,"Business Enablement Data Engineer
Archer Technologies, LLC is the 25-year unseated market leader of integrated risk management (IRM) SaaS platforms that enable customers to improve strategic decision-making and operational resilience with a modern technology platform that supports qualitative and quantitative analysis driven by both business and IT impacts. As true pioneers in ERM, compliance, audit and cyber risk, Archer’s 800 employees are solely dedicated to helping customers manage risk and compliance programs, from traditional audits to emerging issues such as ESG. With over 25 years in the risk management industry, the Archer customer base represents one of the largest pure risk user communities globally, with more than 1,300 customers including more than 50% of the Fortune 500. Learn more at www.ArcherIRM.com.
The primary focus of the Business Enablement Data Engineer is to provide technical expertise with the creation and maintenance of Archer’s Global Data Lakehouse. This role will execute on complex analytics to help drive business decisions across a wide variety of often fast-paced internal engagements. The Data Engineer role will build innovative tools and applications that can help solve Archer’s internal data issues, help execute cutting-edge analytical techniques, help drive technical roadmaps for the function and firm, and train our colleagues.
Responsibilities:
Assist with creating, defining, and driving data engineering solutions to meet functional business requirements.
Data engineering needs can include Data aggregation/creation, data cleaning/manipulation, data science (e.g., geospatial, machine
learning, predictive modeling, etc.), and visualizations.
Solve various complex analytical challenges, sometimes dynamically balancing multiple internal projects simultaneously.
Supporting project teams with their analytics work in a “consultancy/expert” capacity on best practices concerning data & analytics
engineering (e.g., on-prem databases & systems, data storage & warehousing, data management, big-data principles, analytics app
prototyping, ETL)
Develop and drive the data engineering roadmap needed to support the business.
Collaborate with various stakeholders to continuously innovate on the tools, services, and data assets we can offer.
Serve as the lead technical expert and thought leader in helping to innovate and develop offerings that require / benefit from advanced
analytics skills or capabilities.
Provide technical expertise and thought leadership on developing analytical tools, services, and data assets and contribute to building
these areas directly when applicable.
Create production-quality data pipelines to develop and deploy scalable data science projects.
Stay current on best-in-class software, tools, and techniques to ensure we can provide best-in-class solutions.
Support development and upskilling of staff on relevant software, tools, and techniques
Develop and drive the technical roadmap on data engineering capabilities and infrastructure to ensure we operate a best-in-class Data
& Analytics function.
Qualifications:
Degree in a quantitative or business discipline or previous business experience preferred; examples include: Computer Science,
Engineering, Information Technology, Data Science, Statistics, Mathematics, Operations Research, Economics
Minimum 5 years of experience in applied data engineering; deep expertise in data engineering, as well as strong business and
strategic analytical skills
Ability to understand and articulate requirements to/from technical and non-technical audiences working alongside a data science &
engineering team.
Strong SQL & Python knowledge and familiarity with Big Data tools such as Spark & Scala; familiarity with Alteryx and Tableau
Experience with data modeling, data structures (e.g., relational, and non-relational data), databases, and ETL/ELT processes and an in depth understanding of large-scale data sets including both structured and unstructured data.
Experience with designing, implementing, and delivering scalable data solutions and pipelines on one of the cloud platforms (e.g., AWS,
Azure, GCP) and on-prem platforms such as Microsoft SQL Server
Experience with building and deploying proprietary cloud-based analytics web apps.
Hands-on experience in the development, deployment, and operation of integration technologies (e.g., APIs)
Proficiency with data warehouses (e.g., Snowflake, Teradata, Redshift, Hadoop, BigQuery, etc.)
Experience with containerization technologies (e.g., Docker, Kubernetes)
Experience with DevOps, Git, CI/CD
Experience directly managing another individual or a team.
Prior experience in Strategic Data Consulting is preferred.

Archer is committed to the principle of equal employment opportunity for all employees and applicants for employment and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Archer are based on business needs, job requirements and individual qualifications, without regard to race, color, religion, national origin, sex (including pregnancy), age, disability, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, protected veteran status, genetic information, or any other characteristic protected by federal, state or local laws. Archer will not tolerate discrimination or harassment based on any of these characteristics. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. All Archer employees are expected to support this policy and contribute to an environment of equal opportunity.
If you need a reasonable accommodation during the application process, please contact talent-acquisition@archerirm.com. All employees must be legally authorized to work in the US. Archer participates in E-Verify. Archer and its approved consultants will never ask you for a fee to process or consider your application for a career with Archer. Archer reserves the right to amend or withdraw any job posting at any time, including prior to the advertised closing date.","$86,978 /yr (est.)",5001 to 10000 Employees,Company - Public,Insurance,Insurance Carriers,1710,$10+ billion (USD)
"AnaVation
4.9",4.9,"Chantilly, VA",Senior Full Stack Data Engineer - REMOTE!,"Be Challenged and Make a Difference

In a world of technology, people make the difference. We believe if we invest in great people, then great things will happen. At AnaVation, we provide unmatched value to our customers and employees through innovative solutions and an engaging culture.

Description of Task to be Performed:
AnaVation is looking for a talented Full Stack Data Engineer who is passionate about technology and working with customers and a strong team to provide solutions for our mission-critical customer. The ideal candidate appreciates partnering with our customer and team of engineers to create innovative engineering solutions. The selected candidate will work with a small group of developers building a Cyber data lake. If you are looking to be challenged, then this is the environment for you. This position supports 80% remote work with up to one day per week in our Chantilly, VA office. The candidate will be required to pass a high-risk public trust background investigation.

Position Responsibilities:
Develop tools and processes to ingest Cyber data into an enterprise data lake.
Make recommendations on standards for a common Cyber data model and standards for harmonization of common data elements on data ingest.
Develop and evaluate tools to search, analyze, discover, and otherwise exploit data in the data lake to support investigative operations.
Required Qualifications:
5 or more years of relational database design and development (PostgreSQL, Oracle, Microsoft SQL Server)
5 or more years of ETL/ELT development experience · 2 or more years with Linux environment experience
2 or more years’ experience with shell scripting
Experience implementing data access controls
Experience analyzing unstructured, structured, and semi-structured data
Strong technical and computational skills, coupled with the ability relate data to use cases, mission requirements, and end-user experience
Experience with development in one or more programming or scripting languages (Java/Python/Go)
Active Secret Clearance or High Risk Public Trust Suitability
Bachelor’s degree in Computer Science, Information Systems or related discipline
Preferred Qualifications:
Experience with PostgreSQL
Experience with cloud data solutions such as AWS RedShift, AWS DynamoDB and Azure Cosmos DB
Experience with search technologies such as Elasticsearch, AWS Opensearch, Azure Cognitive search, SOLR, etc
Experience with Databricks, Azure Syanpse, or Apache Spark
Experience with cloud concepts and big data architectures such as Hadoop, Kafka, etc.
Knowledge of Continuous Integration/Continuous Delivery tools and practices
Experience with cloud platforms such as AWS and Azure
Experience working in Agile Environments
Experience with DevOps toolsets
Familiarity with containerization (Docker, Containerd, Kubernetes, etc.)
Experience with microservices
Benefits
Generous cost sharing for medical insurance for the employee and dependents
100% company paid dental insurance for employees and dependents
100% company paid long-term and short term disability insurance
100% company paid vision insurance for employees and dependents
401k plan with generous match and 100% immediate vesting
Competitive Pay
Generous paid leave and holiday package
Tuition and training reimbursement
Life and AD&D Insurance

About AnaVation
AnaVation is the leader in solving the most complex technical challenges for collection and processing in the U.S. Federal Intelligence Community. We are a US owned company headquartered in Chantilly, Virginia. We deliver groundbreaking research with advanced software and systems engineering that provides an information advantage to contribute to the mission and operational success of our customers. We offer complex challenges, a top-notch work environment, and a world-class, collaborative team.

If you want to grow your career and make a difference while doing it, AnaVation is the perfect fit for you!","$97,431 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2013,$5 to $25 million (USD)
"US Signal Company LLC
2.8",2.8,"Grand Rapids, MI",Technical Support Engineer (Tier 3 Cloud and Data Protection),"Job Description
US Signal is a leading data center services provider, offering secure, reliable network, cloud hosting, colocation, data protection, and disaster recovery services — all powered by its expansive, robust fiber network. US Signal also helps customers optimize their IT resources through the provision of managed services and professional services.
We are seeking a Technical Support Engineer to join our team in Grand Rapids, Michigan. This role is performed mostly on-site but could be hybrid.
The Technical Support Engineer (Cloud and Data Protection) is part of the Technical Operations Center team and is responsible for all level one, two, and three customer support for the US Signal Hosted and Enterprise Cloud services, Object and File Storage, and Disaster Recovery and Data Protection services. The primary function of the Tier 3 Engineer is to provide a world-class level of customer service with an efficient and timely resolution of cases. This role acts as an escalation point and mentor to the Tier 1 Support Agents and Tier 2 Support Specialists. A Support Engineer must be competent in each of US Signal's Cloud and Data Protection offerings, including VMWare, SoftNAS, Zerto, Avamar, Acronis Backup, Veeam Backup Recovery and Archive, Cohesity Data Management, and Remote Monitoring and Management through nAble. This position requires competency in all facets of Windows and Linux Server problem isolation and resolution. Strong networking background is also a plus.
Engineers will analyze current processes, procedures, and case workflow to develop ways to improve the support experience for US Signal customers.
This position is required to participate in an alternating on-call schedule as outlined by the Supervisor of Technical Operations.
FUNCTIONS/RESPONSIBILITIES
Analyze current processes, procedures, and case workflow to develop ways to improve the support experience for US Signal customers.
Work independently and act as a point of escalation for level III Data Protection and Cloud related issues.
Mentor technicians and engineers to develop skills as opportunities present themselves.
Troubleshoot various levels of Windows Server related issues using available server access methods.
Troubleshoot backup issues on the US Signal backup or disaster recovery platforms.
Receive incoming customer calls for trouble/technical support, acting as a subject matter expert for Data Protection and Cloud related issues. Probe customers for most valuable information in relation to trouble for accurate trouble tickets.
Special projects and assignments as deemed necessary by USS management.
Experience and Skills
Competencies:
Expert in customer service.
Experience working with backup and disaster recovery platforms
Familiarity with best practices in Business Continuity and Disaster Recovery
Experience with VMWare, and Windows Server/Linux Operating Systems
Understanding of virtual environments and overall Cloud infrastructure.
High level of analytical ability
Attention to detail and accuracy and excellent organization skills.
Excellent oral and written communication skills.
Ability to work well with all areas of the US Signal organization as well as external customers and vendors
Knowledge of Data/IP Networking including IP Subnetting, NAT, DHCP, etc.
Knowledge of routing protocols including BGP and OSPF.
Education:
Technical training in VMware, virtualization, and/or cloud computing
Technical training in Backup and Disaster recovery platforms
BS in Computer Science, Information Systems, Network Administration or Systems Administration desirable.
Experience:
Experience in Windows Server is required.
Familiarity with server architecture and design is essential.
Previous experience with VMware or virtual environments required.
Extensive experience with Data/IP Network Maintenance is preferred.
Technical experience in a data center, ISP or telecom environment is desired.
Experience working in a process driven helpdesk environment
Working Conditions and Physical Demands:
The majority of the time is spent in a professional office environment and this role routinely uses standard office equipment.
Required License(s)/Certification(s):
Active CCNA (or higher) preferred.
All US Signal employees will comply with US Signal Information Security policies to ensure the confidentiality, integrity, and availability of US Signal and customer data. All employees are responsible to ensure actions comply with state and federal regulations and requirements.
We offer a competitive compensation and benefits package including a 401k plan with a match. If you are looking to be part of a dynamic team, please apply now.
Job Type: Full-time
Pay: From $65,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Supplemental pay types:
Bonus opportunities
Work Location: Hybrid remote in Grand Rapids, MI 49503","$65,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2001,Unknown / Non-Applicable
"Atkore
4.0",4.0,"Harvey, IL",Applications Engineer - Data Center Containment,"Applications Engineer
Who we are:
Atkore is forging a future where our employees, customers, suppliers, shareholders, and communities are building better together – a future focused on serving the customer and powering and protecting the world.
With a global network of manufacturing and distribution facilities, Atkore is a leading provider of electrical, safety and infrastructure solutions.

Who we are looking for:
We are currently looking for an Applications Engineer. You will manage and be the go-between for owner’s needs, building requirements and our factory delivered solutions by working closely with General Contractors, Mechanical and Electrical contractors, and system integrators across a wide range of sites for hyperscale, colocation, and retail providers in the space. You will be supported by a full commercial, estimating, factory engineering team delivering product from our owned manufacturing plant(s) in the USA.

What you’ll do:
Serve the customer’s needs as a critical member of our team to help support the launch of Atkore’s data center containment solution.
Work closely with Director of Sales to become the application expert to identify current and future customer needs and help the customer find appropriate solutions for customer applications whilst promoting Atkore portfolio.
Coordinate with our project management team and walk job sites (as required) to understand site conditions.
Coordinate with our factories to ensure critical to build issues are addressed including documenting technical requirements for both domestic and overseas project plans and project changes.
Examine and interpret blueprints/plans/drawings to find containment opportunities and coordinate requirements to the estimating team.
Lead the design and installation of our containment solutions to exceed customer expectations including developing installation manuals and on-site assistance to Unistrut Construction team during installation.
Maintain and update our technical library, including CAD models, drawings, specifications, test data, etc.
Support our Regional Sales Managers (RSM) team with client proposals and technical presentations.
Establish and build strong trusting relationships with key stakeholders and provide unmatched quality, delivery, and value.
Travel requirements are 15-25% of the time

What you’ll bring:
5+ years of hands-on field experience in applications engineering, engaging with the customer through the requirements definition, generating a concept and proposal through the delivery and installation of the solution
A history of building and maintaining customer relationships, preferably in the data center market.
Possess a technical aptitude and comfort in understanding blueprints and specifications.
High energy and integrity, strong team player, exceptional work ethic, and a history of proven sound decision making.
Ability to think strategically and develop long term goals
Engineering degree or relevant experience.
Autodesk Inventor, Microsoft Office Suite, CRM Tool experience
Word, Excel, PPT, and CRM tool experience.

Within 3 months, you’ll:
Complete Atkore’s immersion program to understand our mission, vision, values, business processes, products, people, and our culture.
Learn about our manufacturing, operations, and field installation teams capabilities for containment.
Understand how your role works closely with the sales, operations, and installation teams and contributes to Atkore’s overall strategy.
Gain buy-in with Unistrut Construction stakeholders that help support our sales objectives.
Develop a submittal and design process to work collaboratively with RSMs to improve our value and conversion rate.
Understand our value proposition and incorporate added value into the containment design.
Within 6-months, you’ll:
Become familiar with the design, build, and installation of Atkore’s containment solution
Create strong relationships with executives, key stakeholders, and strong influencers.
Use Autodesk Inventor to update, maintain and distribute technical and manufacturing drawings.
Develop bespoke installation manuals for each application
Provide on-site assistance to optimize installation efficiencies in support of client schedule.
Identify other resources needed to scale our business.
Within 12-months, you’ll:
Become the Atkore containment subject matter expert and make recommendations to improve the program
Proficient at reading drawings, specifications, and blueprints for data centers.
Take the lead as the conduit between sales and operations, working with the Manufacturing Engineers on delivery and installation to keep customers’ project on schedule.
Collaborate with the Global Director of Product Management, Global Director of Product Engineering on various projects and tasks related to new product development.
Assist Director of Sales with every data center containment internal scope review and external scope review with customers.
Build enough demand to recruit, hire, and train teammates.

Atkore is a recipient of a Great Place to Work© certification and a Top Workplaces USA award! We’re committed to creating an engaged and aligned workforce that drives collaborative culture. Our team strives for breakthrough results, stays focused on being standout leaders, and fully supports decisions of the Company. We consistently live the Atkore mission, strategic priorities, and behaviors, all in a way that’s consistent with our core values. Together, we build strong leaders that continually endeavor to move us forward.
Join our team and align yourself with an industry leader!
#LI-ET1
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$82,585 /yr (est.)",1001 to 5000 Employees,Company - Public,Manufacturing,Machinery Manufacturing,2010,$1 to $5 billion (USD)
"84.51°
4.3",4.3,"Cincinnati, OH",Senior Data Engineer (P996),"84.51° Overview:
84.51° is a retail data science, insights and media company. We help the Kroger company, consumer packaged goods companies, agencies, publishers and affiliated partners create more personalized and valuable experiences for shoppers across the path to purchase.
Powered by cutting edge science, we leverage 1st party retail data from nearly 1 of 2 US households and 2BN+ transactions to fuel a more customer-centric journey utilizing 84.51° Insights, 84.51° Loyalty Marketing and our retail media advertising solution, Kroger Precision Marketing.
Join us at 84.51°!
__________________________________________________________

As a member of our engineering team, you will use various cutting-edge technologies to develop applications that turn our data into actionable insights used to personalize the customer experience for shoppers at Kroger. We also work with Kroger's supply chain related data assets including but not limited to: Orders and Shipments, Inventory, Planogram and Pricing information to help Kroger, CPG and broker clients make tactical and strategic business decisions. We use agile development methodology bringing everyone into the planning process to build scalable enterprise applications and solutions.
What you'll do
Work within a team that owns the Semantic Layer of a large commercial reporting application.
Create and maintain complex retail customer loyalty measures and commercial data security rules.
Use strong business analysis skills to translate commercial requirements into technical requirements.
Use strong Data Warehouse and BI Tool background and understanding of every layer of the technical stack in order to convert requirements into platform wide implementation solutions.
Work with the team to implement the semantic layer portion of those solutions using a BI Tool framework.
Develop custom engineering tools to assist with the implementation, automation, and testing of the solution to reduce time to market for new Insights capabilities.
Responsibilities
Participate in design and development of highly visible data solutions
Support Commercial Facing data pipelines
Perform unit and integration testing
Collaborate with architecture and lead engineers to ensure consistent development practices
Participate in retrospective reviews
Participate in the estimation process for new work and releases
Collaborate with other engineers to solve and bring new perspectives to complex problems
Drive improvements in people, practices, and procedures
Embrace new technologies and an ever-changing environment
Requirements
3+ years proven ability of professional Data Development experience
Experience with a Business Intelligence Reporting Tool
Full understanding of ETL concepts and Data Warehousing concepts
Proficient with Relational Data Modeling
Thorough understanding of CI/CD concepts and best practices
Comprehensive Understanding of ANSI SQL
Foundational Understanding of Cloud Processing Concepts
Foundational Understanding of Agile Principles
Exposure to Retail Business Intelligence
Exposure to interacting with , enhancing and creating Cloud based services
Passion for Problem Solving
Passion for creating supportable technical solutions
Experience communicating to and with functional colleagues
Preferred Skills
dbt
Python
Python FAST API framework
Power BI
Snowflake
Alation
Microsoft Azure
MongoDB
Oracle
#LI-Remote #LI-DOLF","$84,414 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2015,Unknown / Non-Applicable
"Peraton
3.6",3.6,"Pacific, MO",Data Engineer – DoD TS/SCI – Camp Humphrey – Korea,"Responsibilities:
Peraton is seeking a Data Engineer, in support of a US Government client at Camp Humphrey in South Korea, who can leverage experience and expertise in data exploration, engineering, and ETL to architect, develop, and deploy scripts for processing structured and unstructured data into usable data formats for long term storage, search, and analysis
The successful Data Engineer candidate will work with a diverse team of data scientists, social scientists, cultural advisors, operations research systems analysts (ORSAs), and Irregular Warfare (IW) planners to translate empirical research findings into operational assessments.
The Data Engineer will be responsible for developing user interfaces, data extraction and transformation to improve data reliability, quality and utility.
The candidate should also be comfortable working with military IRC planners to break down and synthesize data in a fashion that best informs plans and operations.
Roles and responsibilities for this position include:
Utilize your experience with AWS, Azure, or Google Cloud
Creating a custom ingest pipeline to a Big Data platform with consistent performance and scalability
Understanding programming and data engineering concepts and best practice
Experience working with both structured, semi-structured, and unstructured data to include data parsing, transformation, schema definition, and query/analysis
Ability to manage and organize data while identifying trends and inconsistencies that will impact downstream analytics
Experience with data pipelines or be willing to learn a pipeline from bottom to top
Be able to troubleshoot files against an architecture to see where the upload process is failing
Be able to understand unit tests and add to them to increase stability to the entire pipeline
Be prepared to use GIT, Anaconda, Spyder, and Microsoft tools
Be prepared to express ideas and solutions and walk together with teammates through coding challenges
Qualifications:
Basic Qualifications:
Bachelor of Science in computer programming, mathematics or a related degree with 8-10 years of experience, 6-8 yrs. with a Master’s Degree
Demonstrated experience applying data engineering and software development expertise
Work / research history demonstrating applied experience with programming languages such as Python, SQL, Java, etc. with Linux OS (Ubuntu, CentOS, Red Hat), and Windows environments
Ability to work both independently and collaboratively with high levels of curiosity, creativity, and problem-solving capabilities
Strong written and verbal communication skills
Experience building ETL pipeline architectures and AWS, architectures with experience with ETL tools such as NiFi or Informatica
Must be willing and able to travel within the CCMD area of responsibility as required by the program.
Must be a U.S. Citizen with Current US Passport
Current DoD Top Secret clearance with SCI eligibility

Preferred Qualifications and Training:
A graduate degree in computer programming / science, mathematics, or related degree and 10 years of experience
AWS certifications such as AWS solutions architect or developer
Cyber security certifications
Statistical package expertise in programs such as IBM SPSS/PASW, R, STATA or MS Excel statistics
Experience applying data science to address defense or social science issues
Experience using geospatial analytic package (e.g., ArcGIS, QGIS, etc.)
Joint intelligence or operational assessment experience with Combatant Commands
Peraton Overview:
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers.
Target Salary Range: $146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors. EEO: An Equal Opportunity Employer including Disability/Veteran.","$190,000 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $10 billion (USD)
"Gentiva
3.3",3.3,"Mooresville, NC",Business Intelligence Developer / Data Engineer,"Our Company:

Gentiva is an industry leader in hospice, palliative and personal home care. Our place is by the side of those who need us, offering physical, spiritual and emotional support to patients and their families so they may make the most of every moment. We believe that better care for caregivers and clinicians means better care for everyone, so we offer ongoing professional training, lower nurse-to-patient ratios, and comprehensive benefits for eligible employees. Here, you’ll join gifted colleagues who make a lasting difference in people’s lives every day.

Overview:
We are looking for a remote Business Intelligence Developer / Data Engineer to join our team. This position reports to the Director Business Intelligence and Data Services and is responsible for developing, deploying, and maintaining BI interfaces. Those include query tools, data visualizations and interactive dashboards, ad hoc reporting, and data modeling.
Transform business requirements into technical specifications
Design and develop ETL processes to move/load data to/from various locations including files systems, ftp sites, and data bases
Define and develop internal teams’ Service Delivery KPIs dashboards to improve customer experience
Monitor and manage new and existing integration elements to ensure continued customer satisfaction
Act as Subject Matter Exert (SME) in a verity of data / analytics platforms such as SQL Server, Power BI and Microsoft Visual Studio/SSIS
Design and develop interfaces such as APIs. Forward thinking toward newer technologies and where these may be implemented
About You:
Bachelor's degree in computer science or a related field
5+ years’ of Experience with Microsoft SQL Server Integration service (SSIS)
5+ years’ experience with SQL, T-SQL, and stored procedures
5+ years’ of data engineering/modeling experience with both snowflake and star schema data modeling
2+ years’ of progressive experience in healthcare IT
3+ years’ experience with Business Intelligence tools such as Power BI and SSRS
Experience with Cloud Technologies such as Azure, AWS, etc is a plus
Requires demonstrated experience in project management
Good oral and written communication skills
Self-motivated and able to adapt to new technology and processes quickly
We Offer:
Comprehensive Benefits Package: Health Insurance, 401k Plan, Tuition Reimbursement, PTO
Opportunity to Participate In a Fleet Program
Competitive Salaries
Mileage Reimbursement
Professional Growth and Development Opportunities
Legalese:
This is a safety-sensitive position
Employee must meet minimum requirements to be eligible for benefits
Where applicable, employee must meet state specific requirements
We are proud to be an EEO employer
We maintain a drug-free workplace
Location: Gentiva",#N/A,10000+ Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2010,Unknown / Non-Applicable
CO,#N/A,Remote,Devops Data Engineer/Devops Data Analyst(W2 Only),"Devops/ Technical Data Analyst
6+ Months
Remote
W2 Only
Primary Skills:
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts applications and languages - preferably Oracle/Exadata SQL Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products ie ACH Wire Lockbox BAI EDI etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie XL Release Jenkins Git SVN test automation
Experience with unit functional regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Job Description
Enterprise Commercial Payments Data Mart Technical Data Analyst The Embedded Banking Data and API team is responsible for the Enterprise Commercial Payments Data Mart and Banking as a Service APIs. This position will primarily be focused on the Data Mart. Built on Oracle Exadata, the Mart is sourced with transactional Data from Core Payment systems (ACH, wire/RTP, lockbox, etc) through both batch/ETL and real-time feeds. The data is used as the source for reporting and inquiry APIs and Webhooks that are exposed to Commercial Clients, Fintech partners and internal Keybank systems. It is also used to generate BAI and other reports for Corporate Clients. Responsibilities will include:
Data Sourcing
Capturing requirements and designs for batch/ETL (Ab Initio) integrations
Capturing requirements and designs for real time (webMethods/Java) integrations
Identifying and implementing improvements to decrease load time and optimize database performance
Troubleshooting issues
Data Consumption
Capturing requirements and designs to meet requirements for Embedded Banking APIs
Capturing requirements and designs to meet requirements for BAI and other reports
Identifying and implementing improvements to improve API performance
Troubleshooting issues
Data SME
Working with SMEs from the source payment platforms to learn about and become expert on the critical data elements in the data mart
Respond to questions from consumers regarding data
Maintain documentation/data libraries
Interacting with the following:
Line of Business partners (Embedded Banking, Commercial Payments, Digital Channels)
Vendors/Clients
Production Support Team: provide knowledge transfer and assist with troubleshooting issues
Data Supply Chain (ETL/Abinitio, Data Model) Teams
Kafka Event Management Team
Open Banking Engineering Teams
Database Administrators
Infrastructure Teams
Internal Interfacing Teams
QAS/Testing Team: review test plans, help find data, and assist/supplement the testing
Working with and through direction of ECA Mart Technical Lead
Helping support, maintain and review dashboards in Kibana
Required Experience / Skills
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts, applications and languages - preferably Oracle/Exadata, SQL, Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products, ie, ACH, Wire, Lockbox, BAI, EDI, etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie, XL Release, Jenkins, Git, SVN, test automation
Experience with unit, functional, regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Preferred Experience / Skills
Experience with database design, analytics
Experience with other programming languages
Basic understanding/experience with APIs, developer portals; Fintech integrations
Experience in creating REST API Documentation using OpenAPI/Swagger Specs. Swagger and Yaml, or similar tools
Experience working on an Agile Team
Job Type: Contract
Pay: $65.00 - $67.00 per hour
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Experience:
DevOps: 9 years (Preferred)
Data Engineer: 9 years (Preferred)
CI/CD: 9 years (Preferred)
ETL/Ab Initio: 8 years (Preferred)
Agile: 9 years (Preferred)
WebMethods/Java: 6 years (Preferred)
Jenkins, SVN: 9 years (Preferred)
RESTful API: 8 years (Preferred)
Commercial Payments: 8 years (Preferred)
Kafka: 2 years (Preferred)
Work Location: Remote",$66.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Olsson
4.0",4.0,"Kansas City, MO",Senior Electrical Engineer - Arc Flash - Data Center (Remote),"Company Description

We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.
Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us — and will continue to allow us — to grow. The result? Inspired people, amazing designs, and projects with purpose.

Job Description

As an Electrical Engineer, you will work directly with some of the world’s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in performing short circuit analysis and producing arc flash studies is required. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.
We currently have one opening and will consider candidates interested in being located in most locations across the United States.

Qualifications

You are passionate about:
Working collaboratively with others
Having ownership in the work you do
Using your talents to positively affect communities
Electrical Engineering knowledge
You bring to the team:
Strong communication skills
Ability to contribute and work well on a team
Ability to be a self-starter to take on a variety of tasks to best serve the client and their project work
Investigation and troubleshooting of problems to find solutions
Ability to contribute and work well on a team
Bachelor's Degree in electrical engineering
8+ years or related electrical engineering experience
Registered professional engineer (PE) required
SKM and ETAP software experience is preferred

Additional Information

Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we’re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.
As an Olsson employee, you’ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you’ll:
Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)
Engage in work that has a positive impact in communities
Receive an excellent 401(k) match
Participate in a wellness program promoting balanced lifestyles
Benefit from a bonus system that rewards performance
Have the possibility for flexible work arrangements
Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.
#LI-MP1
#LI-REMOTE","$85,435 /yr (est.)",1001 to 5000 Employees,Private Practice / Firm,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1956,$100 to $500 million (USD)
"VISUAL SOFT, INC
4.1",4.1,"Washington, DC",Data Engineer - Active TOP SECRET - REMOTE-ONSITE,"Visual Soft, Inc is seeking qualified candidates to work on our efforts with a Prime for their end customer, a federal agency.

Position: Data Engineer - (50% REMOTE and 50% ONSITE)
Location: Washington, DC or Crystal City, Arlington, VA
Shift time: 8 am to 5 pm

JOB DESCRIPTION:
As a Data Engineer, you’ll implement data engineering activities on some of the most mission-driven projects in the industry. You’ll deploy and develop pipelines and platforms that organize and make disparate data meaningful. You will collaborate and work with and guide a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for your clients.
**Desirable skills include, Spark, Databricks, Data Lakes, Bigdata Tools and Technologies and AWS
Years of Experience:: 5+ years of experience
Education Requirement: BS degree preferred
Clearance requirement: Top SECRET is a MUST

Standard Benefits:
Our standard benefits include: Our standard benefits include 3 weeks of Paid time off (PTO that includes sick leave). Any unused PTO will be issued as a check at the end of an employee's anniversary with us. we also provide 2 floating and 8 public holidays. Floating and holidays expire at the end of every year of service of an employee. In addition, company will cover 50% of health and dental insurances only for all full time employees, however, dependents can be added at extra cost. Employee's health and dental coverage becomes effective after 30 days or first of the month after an employee completes initial 30 working days, we cover 50% for the employee's health and dental insurances. Dependents coverage for health and dental insurances is available as an out of pocket expense for employees. An employee has to finish all of your paper work for health and dental in the first 30 days of your employment with us. We provide STD, LTD and one time salary equivalent of life insurance at NO cost to all full time employees. All full time employees or w-2 employees with no benefits will be eligible to participate in company's 401k program after 90 days of employment with a company match of 4%, immediate vesting. In addition, all w-2 employees are eligible to be part of company's profit sharing, no employee contributions required. No commuting and/or parking expenses provided.","$93,472 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,$1 to $5 million (USD)
"Ansys
4.1",4.1,"Canonsburg, PA",Lead Application Engineer- Data Simulation Solutions,"When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.

Take a leap of certainty … with Ansys.

Summary / Role Purpose
Join the Ansys Customer Excellence team to partner with our customers to engineer what''s ahead, solve their real-world engineering problems, deploy Ansys software in their design workflows, and grow Ansys’ business. As a subject matter, industry and Ansys solutions expert, you will use advanced-level engineering knowledge to provide technical pre-sales support, perform professional services, and help guide Ansys product roadmap based on customer requirements. You will consult with customers on simulation-based solutions in support of their key business initiatives, lead project teams to create pervasive simulation solutions and mentor junior engineers.

Key Duties and Responsibilities
Lead in coordinating and executing all technical activities throughout the sales opportunity lifecycle such as technical discovery, negotiate technical success criteria, product presentations, demonstrations and evaluations. Work independently within multi-disciplinary teams
Help guide complex sales engagements to successful outcomes using subject matter expertise and industry knowledge
Interact with customers to understand their key business initiatives, product design needs and engineering design workflows; analyze how to address customers’ requirements using Ansys products and platform, articulate Ansys’ value proposition to Executive level audiences
Lead project teams to create differentiating simulation solutions using the Ansys platform and products; deploy the solutions within customers’ design workflows
Mentor junior engineers
Collaborate with the Ansys product development teams to guide Ansys product roadmap; lead project teams testing new releases of Ansys products on industrial problems, develop application best practices
Participate in corporate initiatives to further enhance Ansys technology, processes and people skills
Support Ansys field and digital marketing, author conference presentations
Contribute to consulting services, conduct intermediate and/or advanced training classes
Analyze business and technical needs, requirements, and the state of a customer’s current infrastructure, operations, and simulation & other engineering workflows
Consult our customers on process design and process optimization
Derive the technical specifications in collaboration with other business process analysts, subject matter experts, peers and Ansys Product Management
Develop creative and appealing Proof of Concepts to solve complex business problems
Lead/Assist in coordinating and executing all technical activities (design, develop, deploy) throughout the sales opportunity such as customer meetings and product presentations, demonstrations and evaluations with Ansys personnel and Services Partners
Utilize the components of the Ansys platform as the foundation for building complete solutions that digitally transform customer product development processes to facilitate more engineering in the digital domain by leveraging simulation
Participate in internal corporate initiatives to further enhance the solution suites, presales/sales enablement and business growth
Articulate the Ansys value proposition, which may encompass its entire suite of products (mechanical, fluid, electrical, electronics, optical, systems, software...).
Be a team player who can collaborate effectively with all key Ansys and customer stakeholders including sales, product development, project management, IT management, implementation engineers, and end users

Minimum Education/Certification Requirements and Experience
Required education and degree type: BS or MS or PhD in Mechanical/Chemical/Aerospace/Electrical Engineering or related field
Required minimum years of professional experience in an engineering software environment: BS+8, MS+6, or PhD+3
Subject matter expert in one or more relevant disciplines within Ansys’ business and is/will be sought out for advice by other Ansys engineers
Demonstrated understanding of engineering practices and product development, experience with building solutions using simulation technology and deploying those solutions within customers’ engineering workflows
Track record of delivering exceptional customer outcomes and revenue impact
Strong leadership and mentoring skills
Logical problem-solving, strong interpersonal and communication skills, fluent in writing and speaking English
Ability to organize and manage multiple projects which are complex in nature, possesses a sense of urgency
Projects a professional image and demonstrates business acumen, driven to succeed
Ability to travel domestically up to 25% of time
Proven track record of analyzing customer’s business and technical needs, requirements, and their state of current infrastructure, operations, and simulation & other engineering workflows
Proven track record of architecting solutions consisting of various (software) components and leading corresponding implementations
Experience in consulting customers on business process design and optimization
Self-starter who possesses a sense of urgency, strong organizational and follow up skills
Willing to evolve in a dynimic and innovative environment, eager to learn

Preferred Qualifications and Skills
Preferred education and years of professional experience in an engineering software environment: BS+12, MS+10, or PhD+7
4 years of experience in application engineering, customer support, or consulting services type customer facing roles using engineering software
Ability to interact effectively with senior business managers and C-level executives
Ability to travel domestically up to 50% of time
Demonstrated use of relevant Ansys software or knowledge of other commercial CAE, CAD, EDA, PLM software packages
Good understanding of enterprise class product development systems like SLM, SPDM, ERP, ALM, TDM, MIM/IMM, PDM, PLM (e.g. Aras Innovator, Siemens Teamcenter, Dassault ENOVIA or 3DEXPERIENCE, MSc SimManager, MSc MaterialCenter)
Basic understanding of programming languages such as: python, C# (.NET), Javascript, HTML,
Experience with DevOps/continuous integration and deployment
Practical knowledge of agility and agile project management
Ability in interest in obtaining a security clearance

This role is not available for sponsorship.

At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential in the knowledge that every day is an opportunity to observe, teach, inspire, and be inspired. Together as One Ansys, we are powering innovation that drives human advancement.

Our Commitments:
Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper
Our Values:
Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger

Our Actions:
We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results

OUR ONE ANSYS CULTURE HAS INCLUSION AT ITS CORE
We believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.

TAKE A LEAP OF CERTAINTY IN YOUR CAREER AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high - met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.

At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.

CREATING A PLACE WE’RE PROUD TO BE
Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: America’s Most Loved Workplaces, Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, U.K.).


For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.","$103,804 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Computer Hardware Development,1970,$1 to $5 billion (USD)
"EvolutionIQ
4.8",4.8,"New York, NY",Lead Data Infrastructure Engineer (AI / Insurtech),"About us: EvolutionIQ's mission is to improve the lives of injured and disabled workers and enable them to return to the workforce, saving billions of dollars in avoidable costs and lost productivity to the US and global economies and make insurance more affordable for everyone. We are currently experiencing massive growth and to accomplish our goals, we are hiring world-class talent who want to help build and scale internally, and transform the insurance space. We're backed by First Round Capital, FirstMark Capital, Foundation Capital, Brewer Lane Ventures, and have been named as Inc.'s top places to work!
Our Team: We are founded by a senior Google AI expert and a Bridgewater Associates Algorithmic Investor & Stanford MBA. We're not looking for employees. We're looking for partners in work, partners in culture-building, and partners in the future of data-driven insurance. The development team consists of world class engineers and leaders from companies like Google and Bloomberg. Each individual has had great success building large scale enterprise software and is now excited to try their hand at transforming the insurance industry.
Job Summary: We are looking for a Lead Engineer for our Data Platforms who will play an integral role in securing, architecting, and managing our highly sensitive insurance data. This position is tasked with overseeing our foundational datasets, data models, and analytics. The ideal candidate will have considerable experience in creating and managing secure data platforms, a strong engineering background, and a demonstrated record of technical leadership and effective communication.
In this critical role, you will not only ensure the robustness and reliability of our data systems, but also their security and compliance with stringent industry regulations. You will navigate the complexities of insurance data, bringing technical excellence and a security-first approach to safeguard our information assets. Your keen eye for security will be instrumental in protecting our company, customers, and stakeholders, while your technical expertise will shape the future of our data platform architecture.
Key Responsibilities:
Architect, design, and implement robust, secure, scalable, and high-quality data platforms, ensuring the availability, integrity, and confidentiality of the information.
Lead the development and maintenance of data pipelines, including personally coding and building the most critical components.
Work closely with product engineers, data scientists, analysts, and other stakeholders to understand data needs and deliver on those needs.
Define, design, and improve foundational data models to be used across the company to enable feature development and analytics.
Continuously improve our data quality toolkit
Provide guidance and technical leadership to the data engineering team, promoting continual team growth and individual team member skill development.
Be a role model for all engineers and provide mentorship as needed
Drive proof of concepts and experiments to explore new technologies that can level up the entire organization
Requirements:
7+ years of industry experience, holding staff/principal/lead level roles in Software Engineer or Data Engineer, with a focus in building scalable, mission critical, data platforms
Strong written and verbal communication skills
Extensive Python development experience
Experience with distributed data/computing tools, such as: Spark, Airflow, dbt
Proven track record of establishing engineering best practices for both coding and architecture
Experience building out systems and processes to enable secure handling of highly sensitive data
Experience using modern big data storage technologies such as Apache Parquet or Avro
Strong familiarity with modern data warehouse such as BigQuery or Snowflake
Ambitious, collaborative, and empathetic values
Even Better if You Have:
You have at least 3+ years experience in deploying systems on GCP or AWS
Experience with MLOps, such as feature engineering and model serving
You have worked with Dagster/Airflow, BigQuery, GCP, Terraform, Kubernetes, sklearn, keras/TensorFlow/pytorch, dbt, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions
The Fit: We're a team of architects and visionaries who thrive on being first. We've created a fun, passionate, humorous, friendly, and fiercely-driven engineering culture that values delivery and personal impact above everything else. We are open to sponsoring candidates who currently are in the US and need to transfer their active H1-B visa.
Work-life, Culture & Perks:
Compensation: The range is $210-240K depending on a candidate's background and experience.
Well-Being: Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%
Work/Life Balance: For this role we are hoping this person can work out of the NYC office regularly with much of our leadership with flexibility. We also have a flexible vacation policy and are closed for winter break at the end of the year
Home & Family: Flexible PTO, 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn
We also have a flexible vacation policy and are closed for winter break at the end of the year
Office Life: Catered lunches, happy hours, and pet-friendly office space. $500 for your in home office setup and $200/year for upgrades every year after your initial setup
Growth & Training: $1,000/year for each employee for professional development, as well as upskilling opportunities internally
Sponsorship: We are open to sponsoring candidates currently in the U.S. who need to transfer their active H1-B visa
EvolutionIQ appreciates your interest in our company as a place of employment. EvolutionIQ is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees","$88,635 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2019,$25 to $100 million (USD)
"Lyft
3.6",3.6,"San Francisco, CA",Senior Data Engineer,"At Lyft, community is what we are and it's what we do. It's what makes us different. To create the best ride for all, we start in our own community by creating an open, inclusive, and diverse organization where all team members are recognized for what they bring.
Here at Lyft, Data is the only way we make decisions. It is the core of our business, helping us create a transportation experience for our customers, and providing insights into the effectiveness of our product launch & features.
As a Data Engineer at Lyft, you will be a part of an early stage team that builds the data transport, collection, and storage, and exposes services that make data a first-class citizen at Lyft. We are looking for a Data Engineer to build a scalable data platform. You'll have ownership of our core data pipeline that powers Lyft's top-line metrics; You will also use data expertise to help evolve data models in several components of the data stack; You will help architect, building, and launching scalable data pipelines to support Lyft's growing data processing and analytics needs. Your efforts will allow access to business and user behavior insights, using huge amounts of Lyft data to fuel several teams such as Analytics, Data Science, Marketplace, and many others.
Responsibilities:
Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft
Evolve data model and data schema based on business and engineering needs
Implement systems tracking data quality and consistency
Develop tools supporting self-service data pipeline management (ETL)
SQL and MapReduce job tuning to improve data processing performance
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge
Unblock, support and communicate with internal & external partners to achieve results
Experience:
5+ years of relevant professional experience
Strong experience with Spark
Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet)
Strong skills in a scripting language (Python, Ruby, Bash)
Good understanding of SQL Engine and able to conduct advanced performance tuning
Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)
1+ years of experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)
Comfortable working directly with data analytics to bridge Lyft's business goals with data engineering
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.
Starting in September 2023, this role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.
The expected range of pay for this position in the San Francisco Bay Area is $162,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","$163,274 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Computer Hardware Development,2012,Unknown / Non-Applicable
"KaylaTek
4.2",4.2,"Andrews AFB, MD",Data Center Engineer- Senior - Secret Clearance,"$3,000 Referral Bonus for this position!
Come join our growing team with a 21st Century Vision! At KaylaTek, we understand that the key to our success is the quality of the people we employ. Our focus is not just on jobs, but on building and enhancing your career through ongoing professional development, training, and high quality of life. Our team members choose KaylaTek for a number of reasons including our competitive compensation and benefit packages, dedication to education, as well as our outstanding service. Our Grow Strong Vision encompasses a place for employees to grow, learn and feel a sense of belonging, not just a place to work.
Employee Benefit Offerings
Medical, Dental, Vision, 401(k) with company matching, Short-Term and Long-Term Disability, Life and AD&D Insurance, Paid Time Off, 11 Paid Holidays, Employee Assistance Program (EAP), Professional Development Program, Military Leave Support and much more.

Job Site: Joint Base Andrews, MD

Shift Hours: Day-Shift; core support hours are 0600 -1800. This is a 24/7/365 support environment; off-hours response/support may be required, however only standard M-F core hours working time for current position.
Overview: KaylaTek is seeking a Data Center Engineer to provide technical leadership and support in the areas of IT planning, solution specification/design, implementation and target architecture development for the AFNCR Consolidated Communication Center (CCC). The Data Center Engineer will support the 844th Communications Group at Joint Base Andrews (JBA). This role includes supporting the Air Force District of Washington (AFDW) and Headquarters Air Force (HAF) customers on both NIPRNet and SIPRNet domains for the development of the CCC building. The qualified candidate will have knowledge of information technology commercial solutions and experience designing and developing technical solutions. The preferred candidate will have excellent communications skills, a strong customer service orientation and experience serving as an advisor to Chief Architect and other Government/Contractor staff and managers.
Certifications required: Active Security + CE

Roles and Responsibilities:
Assist in planning, coordinating, and managing the technical aspects in projects related to the CCC datacenter. As well, identify and manage dependencies between these projects and with other ongoing activities.
Lead and assist with all design aspects of the CCC data center support systems, to include AC/DC power, UPS, HVAC, carrier infrastructures, internal/external cable plant, and overall data center layout.
Produce architectural artifacts to include system design diagrams, recommendation justifications, and technical specifications.
Communicate conceptual designs and create/maintain project documentation before, during, and after construction.
Create and review civil/structural/architectural design RFPs.
Assist with managing consultants/contractors through the design and construction process.
Effectively communicate design standards to internal and external project partners
Think outside of the box to find innovative solutions prior to and during the construction process to reduce costs without negative impacts on quality or reliability.
Conduct site assessments, internal design meetings, construction reviews.
Assess client's current IT and facility infrastructure.
Lead and assist with data center migration planning
Required Qualifications:
Bachelor's Degree with 15+ years in Civil Engineering or the equivalent relevant experience in datacenter or mission critical facilities design.
Possess an active Secret security clearance
Proficiency in building codes, regulations, and standards
Ability to build and maintain relationships, partnerships and external networks
Ability to work independently, with minimal supervision and work effectively in a collaborative team environment while keeping the team informed.
Excellent customer facing skills.
Excellent researching, decision-making and organizational skills are required.
Excellent written and verbal communication skills.
Proven analytical, evaluative, and problem-solving abilities.
Working knowledge of Microsoft Office Suite including Microsoft Visio or AutoCAD.
Maintain confidentiality and adhere to data protection and other guidelines where appropriate.
The above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of personnel so classified.
COMMITMENT TO DIVERSITY
KaylaTek is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.
E-VERIFY AND BACKGROUND CHECKS

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. KaylaTek participates in the DHS e-Verify program. KaylaTek also conducts a background check on all candidates post offer though PROScreening LLC.","$172,500 /yr (est.)",1 to 50 Employees,Company - Private,Government & Public Administration,National Agencies,#N/A,$1 to $5 million (USD)
"Google
4.4",4.4,"Omaha, NE","Data Center Engineer, Mechanical, Google Data Centers","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Council Bluffs, IA, USA; Omaha, NE, USA.
Minimum qualifications:
Bachelor's degree in Engineering, related technical field, or equivalent practical experience.
5 years of experience in the design-build environment for mission critical facilities (e.g., data centers, power plants, industrial, etc).
Experience in estimating, mechanical design, operation and commissioning of central utility plants, water processing systems, air distribution systems, and PLC/SCADA controls systems.

Preferred qualifications:
Professional Engineering License.
Experience with project total cost of ownership (TCO).
Construction administration or construction management experience.
Experience with large-scale mission critical facilities' mechanical infrastructure systems.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
In this role, you will have a primary focus on providing a deep technical understanding of Google’s data center design to field execution and operations teams in support of their initiatives. You will also support other teams in the development and evaluation of conceptual design.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.

The US base salary range for this full-time position is $136,000-$203,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities
Participate in the project specific design review process including conceptualizing ways to reduce total cost of ownership (TCO) while maintaining Google standards.
Coordinate with consulting engineers preparing construction documents as they develop detailed documentation based on the conceptual design standards developed and provided by others internally.
Work with the general contractor (GC) to develop a high level understanding of the design intent and on-time development of coordinated design details and delegated design elements in alignment with Google standards.
Monitor work in the field to ensure it is being executed in line with Google’s design intent and standards, as well as meeting the local codes and requirements.
Support systems startup and commissioning processes by providing a technical understanding of the gear being installed and how the systems are designed to function.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"Johns Hopkins Applied Physics Laboratory (APL)
4.2",4.2,"Laurel, MD",2024 PhD Graduate - AI/ML Data Scientist/Engineer - Analytic Capabilities,"Description

Are you searching for a place to build upon the foundation of your academic work?
Are you searching for engaging work with an employer that prioritizes impact, innovation, and personal development?
Are you motivated to apply your skills within a vibrant intellectual community?
If so, we're looking for someone like you to join our team at APL!
We are seeking recent college graduates to help us tackle the complex research, engineering, and analytical problems that present critical challenges to our nation. Our group is currently making critical contributions in the fight against online misinformation and development of the first truly autonomous UAV. Our work on the public health response to the COVID-19 pandemic was recognized by Time Magazine as one of the ""Best Inventions of 2020"". To address these emerging national challenges, we design and develop software systems that leverage the potential of data science, generative AI, large language models, and artificial intelligence across various domains, including social media analysis, healthcare, climate monitoring, cybersecurity, and signal & image processing.
As a member of our team you will...
Collaborate with dedicated colleagues in developing solutions that align with national priorities.
Harness your expertise in areas such as Artificial Intelligence, Machine Learning, Data Science, Cybersecurity, Software Engineering & DevOps, Signal and Image Processing, and Mathematics.


Qualifications

You meet our minimum qualifications for the job if you...
Have a PhD in Computer Science, Mathematics, Engineering, or related technical field.
Have maintained a minimum 3.0/4.0 GPA

Are able to obtain a Top Secret level security clearance. If selected, a government security clearance investigation will need to be conducted and the requirements met for access to classified information. Eligibility requirements include U.S. citizenship.

Why work at APL?
The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation’s most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates.

At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL’s campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers.


About Us

APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law.

APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.","$101,464 /yr (est.)",5001 to 10000 Employees,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,1942,$1 to $5 billion (USD)
"Onebridge
3.9",3.9,"Indianapolis, IN",MDM Data Engineer,"Onebridge is a Consulting firm with an HQ in Indianapolis, and clients dispersed throughout the United States and beyond. We have an exciting opportunity for a highly skilled MDM Data Engineer to join an innovative and dynamic group of professionals at a company rated among the top “Best Places to Work” in Indianapolis since 2015.
This role could be a full-time position on our team – or we would be open to engaging a consultant seeking their next contract experience.
MDM Data Engineer | About You
As an MDM Data Engineer, you are responsible for organizing and executing a Data Enablement program through project planning activities, cross-system coordination, and completion of deliverables. You are comfortable working with a team of data professionals to establish data management best practices and deliver high-quality data and information at scale to a wide variety of clients and industries. You are a strategic thinker who understands the impact that data quality can have on advancing an organization's BI Maturity, and you find excitement in building enterprise solutions to achieve an integrated data strategy.

MDM Data Engineer | Day-to-Day

Engineer end-to-end MDM solutions, including integration patterns (with operational and analytic systems), workflows, policies, support, and reporting associated with an enterprise MDM capability.
Develop and refine approved data models for enterprise integration.
Establish and improve relevant standards and governance.
Develop Master Data Management (MDM) technology-enabled solutions that address the needs of clients, including the design, automation, and orchestration of enterprise Master and Reference Data.
Use data quality tools to profile, cleanse, standardize, and enrich data.
Analyze problems and opportunities and their impacts on the business by considering all fact-based and stakeholder information to evaluate alternatives.
Define and implement data strategy, policies, controls, and programs to ensure the enterprise data are accurate, complete, secure, and reliable.
MDM Data Engineer | Skills & Experience

7+ years of progressive experience in Master Data Management (MDM) solution design, development, and implementation, with additional expertise in Reference Data Management, Data Governance, Data Management, Analytics, and Technology.
Support and maintain the MDM architecture by understanding the interaction of business processes with data entities/elements and ensuring the integrity of the MDM system.
Expertise working in a complex matrixed environment.
Expert-level SQL Skills.
Possess the ability to solve, design, and lead the implementation of MDM platforms and individual components.
Deep understanding of bi-directional MDM and the role it plays in an effective Data Management Strategy.
Skilled in working with at least one modern MDM platform, with knowledge of best-in-class options.
100% Employee-Owned & a Best Place to Work in Indiana, since 2015.","$103,378 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,Unknown / Non-Applicable
"CAI
3.9",3.9,"Charlotte, NC","Mechanical Commissioning Engineer II, Data Center Services","CAI seeks Mechanical Commissioning Engineers with a minimum of two years' experience in Data Center Commissioning to support development and execution of all mechanical aspects of commissioning projects.

Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range, not including benefits or compensatory time and possible discretionary bonuses.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.","$102,500 /yr (est.)",501 to 1000 Employees,Company - Private,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1996,$25 to $100 million (USD)
"American Business Solutions INC
3.8",3.8,"Columbus, OH",Data Engineer with Azure,"This position plays an important role in designing and constructing the agency’s data infrastructure using Microsoft Azure. This role will serve as the primary point of contact for the agency’s migration of its on-premises data warehouse and analysis workspace to Microsoft Azure.
The responsibilities and duties include:
Design and develop data infrastructure for the agency in Microsoft Azure
Recommend and implement solutions for data ingestion, ETL, data warehousing, and data analysis.
Manage access to data infrastructure datasets and analysis tools.
Develop budget for Microsoft Azure tools and provide recommendations on where to manage costs.
Build distributed computing analysis environment within Microsoft Azure in order to conduct more thorough analysis and integrate machine learning/AI tools to environment.
Design and develop database solutions using Microsoft SQL Server and Microsoft Azure tools (SSMS, SSRS, SSIS, Azure Data Factory, Azure Storage).
Manage data in variety of methods, to include SQL databases, NoSQL databases, file storage, and blob storage
Works with IT Architecture staff, CIO and/or IT Managers to design solutions that meet agency requirements
Design and implement high availability solutions
Data modeling to define and analyze data requirements for designing databases/data warehouses
Analyze on-premise database installations for Azure migration
Support data lake enterprise business initiatives
Support production and non-production environments incidents and requests
Code, test, debug, implement, and document data infrastructure design, construction, and remediation
Expert knowledge in SQL skills including stored procedure, trigger, index etc.
Experience with change management with respect to people, processes, and technologies
Develop, maintain, and support business applications (SQL/web-based apps)
Streamline and improve internal processes and reporting
Drive efficiency and operational improvement using data modeling techniques
Support and train users by providing directions, corrections, and enhancements; communicate with users to find solution to case
Analyze user requirements, procedures, and problems to provide coaching on system use, recommend changes and automation to improve efficiency
You’ll need the following qualifications and experience:
Bachelor’s degree in an appropriate field of study like Computer Science, Data Science, or Information Technology
Minimum seven years of database administration, data science, data engineering, and/or cloud-based data solution engineering.
Previous relevant experience with Microsoft suite of data solutions
Experience conducting performance tuning and configuration, creating data models, and managing data warehouses.
It’s a strong plus if you have:
Experience with Healthcare/Mental Health environment
Expertise in Python/R programming language
Familiar with reporting tools such as Power BI, Tableau, and Cognos
Collaborate with team leads to identify gaps and constraints associated with business requirements and processes and aid in providing solutions to resolve the process issues
Strong communication and interpersonal skills
Strong organization and time management skills
Ability to effectively handle multiple priorities
Ability to operate across the business and in different environments and cultures
Required/Desired Skills
SkillRequired/DesiredAmountof ExperienceBachelor’s degree in an appropriate fieldRequired0database administration, data science, data engineering, and/or cloud-based data solution engineeringRequired7YearsExpert knowledge in SQL skills including stored procedure, trigger, index etcRequired0Microsoft AzureRequired0Experience with Healthcare/Mental Health environmentNice to have0Expertise in Python/R programming languageNice to have0Familiar with reporting tools such as Power BI, Tableau, and CognosNice to have0
Job Type: Contract
Pay: $75.00 - $85.00 per hour
Experience level:
9 years
Schedule:
8 hour shift
Ability to commute/relocate:
Columbus, OH 43215: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 3 years (Preferred)
Data Engineering: 7 years (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person",$80.00 /hr (est.),51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,#N/A,$5 to $25 million (USD)
"BOEING
3.9",3.9,"Berkeley, MO",Phantom Works Systems Engineer and Data Architect (Experienced OR Lead),"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
Boeing Defense, Space, and Security (BDS) is seeking data architects to join a Digital Engineering team supporting a proprietary program developing next generation systems.

This is an exciting role to understand, architect and integrate data flows across the program lifecycle to create digital system models and digital twins of the as-designed, as-tested, as-built and as-operated product. In this role, you will apply an interdisciplinary, collaborative approach to plan, design, develop, integrate, and verify digital engineering solutions. We’re looking for data architects and integrators with interest and experience in model based engineering, who also have experience in one or more of the following areas: systems engineering, aircraft design, test, production, and product support. You will help build and mature the digital ecosystem, including: realizing the program data architecture, expanding digital threads, growing digital system models, connecting and controlling data, and enabling advanced data analytics.

Digital engineering is changing the way we execute our programs, collaborate with our customers and teammates, and enable advanced downstream capabilities.
Our teams are currently hiring for a broad range of experience levels including; Experienced or Lead Level Systems Engineers.
Primary Responsibilities:
Work across disciplines to model the data architecture of the program
Be the digital engineering focal to multiple aircraft design teams, production teams, verification/validation teams, and/or product support teams.
Develop and implement strategies to integrate data across multiple tools and technologies to create digital threads and enable digital twins.
Guide and coordinate development and deployment of new or revised processes in support of new computing systems, including documentation and training.
Define and validate complex requirements for new hardware and software systems.
Facilitate development of system integration strategies and architectures that promote use of common tools and processes.
Lead development of trade studies and other forms of analysis to formulate optimum solutions for users.
This position is expected to be 100% onsite. The selected candidate will be required to work onsite at one of the listed location options. (St. Louis or Huntsville)
This position requires an active U.S. Secret Security Clearance, for which the U.S. Government requires U.S. Citizenship. (A U.S. Security Clearance that has been active in the past 24 months is considered active)
Special Program Access or other Government Access Requirements are mandatory for this position.
Basic Qualifications (Required Skills and Experience):
A technical bachelor's degree with 5+ years, or MS/MA degree with 2+ years of relevant work experience, or a PhD degree with 1+ years of relevant work experience. A relevant degree is defined as one in a quantitative field such as Computer Science, Statistics, Mathematics, Computer Engineering, Software Engineering, Electrical Engineering, Aerospace Engineering, Physics, Chemistry, Operations Research, Bioinformatics, Economics, Computational Biology, or other technical degree.
Experience developing and documenting architecture using Cameo, or similar Model Based Systems Engineering (MBSE) tools
Ability to work effectively in a team environment and communicate with stakeholders of different backgrounds and skill levels
Preferred Qualifications (Desired Skills and Experience):
5 or more years' related work experience or an equivalent combination of education and experience
Experience with data modeling, ontology, and industry standards for data exchange
Experience with Siemens Product Lifecycle Management Suites
Prior experience in software development and test tools/IDEs (e.g. off the shelf or source code editors, compilers, configuration management tools, requirements management, and source control tools)
Experience in mechanical, structural, or electrical design
Experience with physics-based modeling tools
Experience with production engineering, future manufacturing systems, and/or supplier management
Experience with integration, verification, validation and/or flight test
Experience with product support, logistics, training systems, and/or maintenance systems
Typical Education and Experience:
Experienced Level 3:
Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) and typically 5 or more years' related work experience or an equivalent combination of education and experience (e.g. PhD, Master+3 years' related work experience). In the USA, ABET accreditation is the preferred, although not required, accreditation standard.
Lead Level 4:
Bachelor's degree and typically 9 or more years' experience in an engineering classification or a Master's degree with typically 7 or more years' experience in an engineering classification or a PhD degree with typically 4 or more years' experience in an engineering classification. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.
Relocation:
This position offers relocation based on candidate eligibility.
Drug Free Workplace:
Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies
""At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.
The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.
The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.
Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations.
Summary pay range for Mid-Level 3 Berkeley MO: $97,750 - $132,480
Summary pay range for Lead Level 4 Berkeley MO: $119,850 - $162,150
Summary pay range for Mid-Level 3 Huntsville AL: $97,750 - $132,250
Summary pay range for Lead Level 4 Huntsville AL: $119,850 - $162,150

Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Equal Opportunity Employer:
Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.","$86,177 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1916,$10+ billion (USD)
"HCA Healthcare
3.3",3.3,"Nashville, TN",Principal Data Engineer,"Introduction
Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As a Principal Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Principal Data Engineer to help us reach our goals. Unlock your potential!
Job Summary and Qualifications
HCA Healthcare ITG
Job Summary:
The role requires working closely with others, frequently in a matrixed environment, and with little supervision. As a Principal Data Engineer/Architect level, the role requires 'self-starters' who are proficient in problem solving and capable of bringing clarity to complex situations. It requires contributing to strategic technical direction and system architecture approaches for individual projects and platform migrations. The culture of the organization places an emphasis on teamwork, so social and interpersonal skills are equally important as technical capability. Due to the emerging and fast-evolving nature of GCP/Big Data technology and practice, the position requires that one stay well-informed of technological advancements and be proficient at putting new innovations into effective practice.
Responsible for leading GCP development efforts, driving adoption and appropriate use of technology and consulting on internal and external development efforts to ensure code quality and sound architecture. This position that assumes the responsibility for project success and the upward development of team members technical skills. They are the development team's point of contact that must interface with business partners of varying roles ranging from technical staff to executive leadership. In addition, this candidate will have a history of increasing responsibility in a multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement cutting-edge technical data solutions with minimal supervision.
As a Principal Data Engineer/Architect, you will work closely with all team members to create a modular, scalable solution that addresses current needs, but will also serve as a foundation for future success. The position will be critical in building the team’s engineering practices in test driven development, continuous integration, and automated deployment and is a hands-on team member who actively coaches the team to solve complex problems. She / he will be responsible for the design, development, performance and support of the Cloud Platform components.
This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team (consultant and employee) environment. In addition, the applicant must be willing to train and mentor other developers to prepare them for assuming the responsibilities.
General Responsibilities:
Responsible for building and supporting a GCP/Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
Bring new data sources into GCP/HDFS, transform and load to databases.
Lead projects in delivering the data and projects on-time
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Leads efforts to design, development, deploy, and support software systems
Experience with HL7, FHIR, and Whistle mapping.
Collaborates with business analysts, project lead, management and customers on requirements
Participates in large-scale development projects involving multiple areas outside of core team
Designs fit-for-purpose products to ensure products align to the customer's strategic plans and technology road maps
Demonstrates deep understanding and coaches’ value-based decision making and Agile principles across teams
Coaches team on clinical data, existing system structure, constraints and deficiencies with product
Shares knowledge and experience to contribute to growth of overall team capabilities
Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems
Work closely with management, architects and other teams to develop and implement the projects.
Actively participate in technical group discussions and adopt any new technologies to improve the development and operations.
Focuses on customer satisfaction
Rapidly prototypes and delivers just-in-time solutions
Gather requirements, designs, constructs and delivers solutions with minimal team interaction
Works in an environment with rapidly changing business requirements and priorities
Demonstrates deep understanding and acts as a leader in the team’s continuous integration and continuous delivery automation pipeline
Work collaboratively with Data Scientists, business, and IT leaders throughout the company to understand Cloud/Big Data needs and use cases.
Education, Experience and Certifications:
Bachelor's Degree in computer science or related field – Required
Master's Degree in computer science or related field – Preferred
3+ years of experience in Data Engineer – Required
1+ year(s) of experience in Healthcare – Preferred
10+ years of experience in Information Technology – Required
GCP Cloud Professional Data Architect certification – Preferred
GCP Cloud Professional Data Engineer certification – Preferred
Other Required Qualifications:
A successful candidate will have:

Strong understanding of best practices and standards for GCP application design and implementation.
Two Year of hands-on experience with GCP platform and experience with many of the following components:
GCS, Cloud Run, Cloud Functions
Bigtable, Cloud SQL
Kafka, Pub/Sub
Python, Golang, Spark, Scala or Java
BigQuery, Dataflow, Data Fusion
CICD process and Logging & Monitoring
OpenShift, Docker
Experience with Unstructured Data, Real-Time Streaming with GCP
Ability to multitask and to balance competing priorities.
Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support.
Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.
A successful candidate may have:
Experience in Healthcare Domain
Experience in Patient Data
Experience with Natural Language Processing (NLP)
Azure/AWS Cloud experience
Hands-on experience with Cloudera Distributed Hadoop (CDH)
Hardware/Operating Systems:
Linux, UNIX
GCP
Distributed, highly-scalable processing environments
Databases:
NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies
Build Systems – TFS, Github
Ability to integrate tools outside of the core Cloud ecosystem
Physical Demands/Working Conditions
Prolonged sitting or standing at computer workstation including use of mouse, keyboard, and monitor.
Requires ability to provide after-hours support.
Occasional Travel: The job may require travel from time- to-time, but not on a regular basis.
HCA Healthcare’s Information Technology Group (ITG) delivers healthcare IT products and services to HCA Healthcare's portfolio of business and partners, including Parallon, HealthTrust and Sarah Cannon.

For decades, ITG has been a pioneer in the industry, leading the transformation of healthcare into a new era of quality and connectivity. ITG relies on the breadth of the organization and depth of technical expertise to advance and enhance today’s healthcare and to enable our physicians and clinicians to provide world-class, innovative care for patients.

ITG employees rally around the noble cause of transforming healthcare through technology and find inspiration in the meaningful work they do—creating a culture that follows our mission statement which begins by saying “above all else we are committed to the care and improvement of human life.”

If you want a career in technology and have a heart for healthcare, apply your expertise to a mission that matters.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.
""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
Be a part of an organization that invests in you! We are reviewing applications for our Principal Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$120,425 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
"Wipro Limited
3.1",3.1,"Minneapolis, MN",Data Engineer - Apache Spark,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS
Role – Data Engineer - Apache Spark
Location – Minneapolis, MN (Day 1 onsite)
Yrs. of experience – 10+ Yrs.
Mode of employment – Full-Time

Job Description:
Strong in Spark Scala development (Minimum 5 years of experience).
Especially Persons should have good experience on building ETL pipeline using Scala.
Strong in SQL Concepts and Development
Must have worked on any ETL tool like Data stage, Spark /Scala etc... Preferred Data Stage.
Unix / Python Shell Scripting (Minimum 3 to 4 years)
Strong understanding of Hadoop eco system
Very well versed with Agile Methodology - Scrum boards.
Capable of handling scrum ceremonies in absence of scrum master.
Other tools – Jenkin, Autosys, GitHub, etc..
Any Cloud experience is plus. Preferred Azure

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.

#LI-AK2","$96,774 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1945,$5 to $10 billion (USD)
"Jack In The Box
3.4",3.4,"San Diego, CA",Lead Data Engineer,"Jack in the Box is seeking a Lead Data Engineer who will be responsible to provide analytic and strategic technical leadership & support to the Enterprise Data Team, which is responsible for scaling and maintaining the core data platform and maturing the analytical capabilities of the organization. Contributes to data & engineering innovations facilitating critical business insights that fuel Jack in the Box Inc.s vision and mission.

KEY DUTIES/RESPONSIBILITIES:
Collaborates with functional & business leaders and teams and works closely with the Data Engineering team to manage complex data systems in enabling decision support and key insights across the organization.

Implements data governance practices in partnership with business stakeholders and peers.

Works with a team of high-performing analysts, data engineering professionals and cross-functional teams to identify business opportunities, monitor data platform performance and optimize analytical capabilities.

Builds, evolves and maintains the infrastructure required for optimal transformation and integration from a wide variety of data sources using appropriate data integration technologies. Deploys pipelines using scheduling and orchestration frameworks to support the organizations growing data processing and analytics needs.

Takes ownership of core data pipelines that power the organizations analytical metrics.

Uses data expertise to evolve data models in several components of the data stack & helps architect, build, and launch scalable data pipelines to support the organizations growing data processing and analytics needs.

Creates proof of concepts per business requirements.

QUALIFICATIONS:
Education: Bachelors degree in Engineering, Computer Science, Information Systems or related field.

Experience: 12+ years staff/lead/senior software data engineer experience building and supporting data intensive applications, tackling challenging architectural, scalability and reliability problems. Experience includes working with Data Warehouse, Data Lake, Data Hub and the supporting processes (Data Integration, Governance, Metadata Management).

Skills/Knowledge/Abilities:
Skilled in building and maintaining data quality frameworks, data observability and monitoring frameworks.

Experience in leveraging Observability tools such as Splunk/Datadog/New Relic/MonteCarlo or equivalent.

Extensive experience manipulating and analyzing large data sets.

Experience designing, deploying, and maintaining business application on AWS stack, leveraging services such as EC2, ECS, Lambdas, AWS Step functions, Redshift, Tableau, AWS Glue OR equivalent expertise in other cloud platforms such as Azure, GCP etc. Experience with on-prem & relational platforms Oracle, SQL Server, PostGres , MySQL etc. Integration of cloud services with on premise technologies.

Experience working with DevOps capabilities like version control, automated builds, testing and release management capabilities using tools like Git, Jenkins etc.

Extensive knowledge in application monitoring, handling user tickets, analyzing data issues.

Experience with data modeling, data mining, and predictive analysis. Ability to effectively test and document work.

Possesses excellent interpersonal, communication, and problem solving skills.

Ability to juggle multiple projects, tasks, and deadlines.

Strong understanding of SQL and NOSQL database concepts.

Strong experience with advanced analytics tools for Object-oriented/scripting languages such as R, Python, Java, Scala, or others.

Comfortable working in an unstructured environment, taking ownership for results and self-directing your efforts to the subject areas and questions which have the greatest potential impact on the business. Comfortable working in an agile environment

Proven track record of being personally accountable for the analysis and technical enhancements that drive a business at a large scale.

Skilled in building reports and dashboards through the use of dashboarding tools like Tableau, PowerBI, Quicksight, Looker.

Will be a self-starter, initiate and drive projects to completion with minimal guidance.

PHYSICAL REQUIREMENTS:
Ability to speak/hear clearly in person and on the telephone and ability to operate a computer (desktop, tablet, etc.).

REASONABLE ACCOMMODATION:
Jack in the Box, Inc. and its affiliates will make reasonable accommodations to allow a qualified individual with a disability to enjoy equal employment opportunities and to perform the essential functions of the job. This position description should be applied accordingly. This description of duties is not intended to be all-inclusive or to limit managements discretion to assign other duties or responsibilities as necessary.

Jack in the Box Inc. offers a competitive salary and Total Rewards package that includes: medical, dental, vision, Health Savings Account (HSA), Flexible Spending Account (FSA), Life and Disability Plans, 401(k) plan with company match, Legal Plan, Pet Insurance, Tuition Reimbursement, and Employee Assistance Program.

Our culture is fun and innovative Work Happy with us!

The range for this position is $149,700 - $208,500 and is based on an employee located at our corporate headquarters in San Diego. If the candidate is hired in a different city to work remote, we will apply a geographic pay differential based on the cost of labor in the market in which the employee resides.

Brand: Jack In The Box
Address: 9357 Spectrum Center Blvd. San Diego, CA - 92123
Property Description: Jack in the Box Corporate
Property Number: XX9101","$153,458 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1951,$1 to $5 billion (USD)
"Synchrony
4.3",4.3,"Chicago, IL","AVP, Principal Data Engineer","Job Description:
Role Summary/Purpose:
We are looking for a Principal Data Engineer to lead the development of consumer-centric low latency analytic environment leveraging Big Data technologies and transform the legacy systems. This role is an exciting, fast-paced, constantly changing, and challenging work environment, and will play an important role in resolving and influencing high-level decisions across Synchrony.
We’re proud to offer you choice and flexibility. You have the option to be remote, and work from home, or come into one of our offices. You may be occasionally requested to commute to our nearest office for in person engagement activities such as team meetings, training and culture events.
Essential Responsibilities:
Understand and manage the data needs of stakeholders across multiple agile teams.
Lead the design & implementation of scalable & fault tolerant data applications on Big-Data & Cloud Platforms to store & process terabytes of data from upstream sources with high availability.
Engage with and take direction from information architects, platform architects, data scientists and product management on solution requirements to design solutions.
Contribute to high impact problems/projects through in-depth evaluation of complex business processes, system processes, enterprise standards & procedures.
Enforce data management standards and procedures
Lead design, development, testing oversight and production implementation using Spark, Hive, Kafka, RDBMS (Oracle, MySQL), NoSQL databases (Cassandra), Ab Initio and AWS.
Partner with multiple teams to ensure appropriate data solutions to meet goals as well as identify and define necessary system and process enhancements.
Provide technical leadership for data engineering agile teams to deliver against sprint and program increment objectives.
Work closely with Product Owners, Product Managers, Program Manager, Scrum Masters and Team Members in a Scaled Agile framework.
Stay up to date on latest trends in data engineering and recommended best practices.
Develop innovative frameworks to avoid redundancy by promoting automation.
Mentor and coach data engineering team members to promote Synchrony values and culture.
Perform other duties and/or special projects as assigned

Qualifications/Requirements:
Bachelor’s degree in Computer Science, Engineering, or a related field with 6+ years of experience in ETL/Data warehousing with 4+ years of experience with large scale Big Data environments such as Hortonworks/Cloudera and public cloud (AWS preferred).
Prior experience as a Hadoop Technical Lead / Architect
Strong experience and deep understanding of ETL, data warehousing, data lake technologies (Hadoop & Spark) and analytics concepts.
Experience owning a mission critical application on a big data platform.
Experience with batch and real-time data pipelines in a DevOps environment.
Willing to work in a fast-paced environment with globally located Agile teams working in different shifts.
Ability to develop and maintain strong collaborative relationships at all levels across IT and Business Stakeholders.
Excellent written and oral communication skills. Adept and presenting complex topics, influencing and executing with timely / actionable follow-through.
Desired Characteristics:
Prior work experience in a Credit Card/Banking/Fin Tech company.
Experience dealing with sensitive data in a highly regulated environment.
Demonstrated implementation of complex and innovative solutions.
Demonstrated leadership capabilities amongst peers and within prior teams.

Grade/Level: 11

The salary range for this position is 90,000.00 - 155,000.00 USD Annual and is eligible for an annual bonus based on individual and company performance.
Actual compensation offered within the posted salary range will be based upon work experience, skill level or knowledge.
Salaries are adjusted according to market in CA, NY Metro and Seattle.
Eligibility Requirements:
You must be 18 years or older
You must have a high school diploma or equivalent
You must be willing to take a drug test, submit to a background investigation and submit fingerprints as part of the onboarding process
You must be able to satisfy the requirements of Section 19 of the Federal Deposit Insurance Act.
New hires (Level 4-7) must have 9 months of continuous service with the company before they are eligible to post on other roles. Once this new hire time in position requirement is met, the associate will have a minimum 6 months’ time in position before they can post for future non-exempt roles. Employees, level 8 or greater, must have at least 18 months’ time in position before they can post. All internal employees must consistently meet performance expectations and have approval from your manager to post (or the approval of your manager and HR if you don’t meet the time in position or performance expectations).
Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job opening. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
Our Commitment:
When you join us, you’ll be part of a diverse, inclusive culture where your skills, experience, and voice are not only heard—but valued. We celebrate the differences in all of us and believe that our individual, unique perspectives is what makes Synchrony truly a great place to work. Together, we’re building a future where we can all belong, connect and turn ideals into action. Through the power of our 8 Diversity Networks+, with more than 60% of our workforce engaged, you’ll find community to connect with an opportunity to go beyond your passions.
This starts when you choose to apply for a role at Synchrony. We ensure all qualified applicants will receive consideration for employment without regard to age, race, color, religion, gender, sexual orientation, gender identity, national origin, disability, or veteran status.
Reasonable Accommodation Notice:
Federal law requires employers to provide reasonable accommodation to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job or to perform your job. Examples of reasonable accommodation include making a change to the application process or work procedures, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment.
If you need special accommodations, please call our Career Support Line so that we can discuss your specific situation. We can be reached at 1-866-301-5627. Representatives are available from 8am – 5pm Monday to Friday, Central Standard Time
Job Family Group:
Information Technology","$122,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,2014,$10+ billion (USD)
"Geopaqlogic Staffing
4.7",4.7,"Ridgefield Park, Bergen, NJ",Data Engineer (W2 only),"Position: Data Engineer
Work Location: Ridgefield Park, NJ (Hybrid - Need to be visit only once in a month)
Contract period: 6+ months (W2 only)
Note: Must have experience in GCP (Google Cloud Platform) and/or Spark
SUMMARY OF ESSENTIAL JOB FUNCTIONS:
· Design and develop analytical models and be the face to the data consumers
· Perform data curation to meet the business requirements
· Build batch and streaming data pipelines
· Develop processes for automating, testing, and deploying your work
· Identify risks and opportunities of potential logic and data issues within the data environment
· Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUM RETIREMENTS:
· Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
· Must have experience in GCP (Google Cloud Platform) and/or Spark
· 3+ years of experience as Data Engineer or in a similar role
· Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
· Cloud to Cloud migration experience preferred
· Strong PySpark skill is a must have
· Have knowledge of data management fundamentals and data storage principles
· Have knowledge of systems as it pertains to data storage and computing
· Strong source to target mapping experience and ETL principles/knowledge
· Excellent verbal and written communication skills.
· Strong quantitative and analytical skills with accuracy and attention to detail
· Ability to work well independently with minimal supervision and can manage multiple priorities
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Benefits:
Health insurance
Paid time off
Ability to commute/relocate:
Ridgefield Park, NJ 07660: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Engineering: 5 years (Preferred)
Software development: 5 years (Preferred)
Business intelligence: 3 years (Preferred)
GCP (Google Cloud Platform: 3 years (Preferred)
Pyspark: 5 years (Preferred)
Work Location: In person",$65.00 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2014,$1 to $5 million (USD)
"Oracle
3.9",3.9,"Seattle, WA",Senior Software Engineer (Join OCI: Horizon Data Warehouse team),"As a Senior Software Engineer on the Horizon Data warehouse team, you will help our development efforts as we build the technology platform that will act as the central data platform inside OCI for 100's of teams. You will be a core contributor on a team of software engineers working to grow and scale our service.

Basic Qualifications
4+ years of experience in the design and implementation of complex software systems
Strong Knowledge of Data Warehousing, ETL processes, Cloud Computing and Data Security concepts is a must.
Proven experience with a Programming language PLSQL is a must.
Sound fundamentals in coding, algorithm design, problem solving, and complexity analysis.
Proven experience with a major Programming language such as Java, Python, Go, C# or C++ is a plus.
Aptitude for problem solving.
Experience with massively scalable systems is a plus.
Experience with Cloud Platforms such as OCI, AWS, Azure or GCP is a plus.
Experience with enterprise-class RDBMS (Oracle, SQL*server), Cloud Data warehouse (Snowflake/Redshift).
Preferred Qualifications
Experience building distributed cloud services.","$146,533 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
"Logistics Management Institute
4.3",4.3,"Washington, DC",Data Engineer - TS/SCI Required,"Overview:
LMI is seeking a Senior Data Engineer to support our Intelligence Community client.

LMI is a consultancy dedicated to powering a future-ready, high-performing government, drawing from expertise in digital and analytic solutions, logistics, and management advisory services. We deliver integrated capabilities that incorporate emerging technologies and are tailored to customers’ unique mission needs, backed by objective research and data analysis. Founded in 1961 to help the Department of Defense resolve complex logistics management challenges, LMI continues to enable growth and transformation, enhance operational readiness and resiliency, and ensure mission success for federal civilian and defense agencies.

LMI has been named a 2022 #TopWorkplace in the United States by Top Workplaces! We are honored to be recognized as a company that values a people-centered culture, and we are grateful to our employees for making this possible!
LMI is seeking a skilled Senior Data Engineer to support data pipelining and sustainment of a client’s SQL database. Successful Data Engineers demonstrate competency in data acquisition, data analysis, programming, project execution, and critical thinking. In addition, LMI Data Engineers have demonstrated experience in collaborating with other Data Engineers and with effective communication with clients.
Responsibilities:
This data engineer will work as part of a team of experienced data scientists, data analysts, and full stack developers to develop and maintain applications that enable client business processes. Responsibilities include:
Defining and developing techniques to integrate, consolidate, and structure data for functional workflows and analytical use
Understanding complex and organization-specific datasets.
Producing dashboards and visualizations to support complex client requirements.
Conducting root cause analysis, identifying errors, and refactoring pipelines as needed.
Performing analyses to answer routine and ad hoc questions as identified in the data being leveraged
Developing and improving standard operating procedures.
Communicating with data analysts and developers to design tools and applications to improve response to repeat requests.
Researching, analyzing and documenting the benefits of various technical approaches.
Proposing alternative designs and processes to manage various types of data using both standard and custom tables and fields.
Working in teams and independently.
Understand and analyze complex and organization-specific datasets.
Support the maturation of data quality
Support the transformation of businesses process through automation
Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available visualization and dashboard tools
Advising on the interpretation and use of data analysis products, dashboards and reports to non-technical customers
Assisting the development of junior teammates through technical mentoring, code review, and other assistance.
Qualifications:
Required:
Bachelor’s degree in science, engineering, mathematics, computer science, information systems, data analytics, or other related business or quantitative discipline
7+ years experience in data engineering or related field
Experience with ETL process and concepts
Knowledge and experience manipulating and joining data from various sources and in various formats.
Ability to query datasets from multiple sources, knowledge of data refresh methodologies, and ability to leverage data models.
High level of competency with data engineering coding languages like SQL and Python
Self-starter with the vision to independently identify opportunities for improvement through data analytics
A true team player who maintains a positive attitude in a dynamic environment
Excellent communication skills, written and oral
Proven ability to work with business customers and technical teams
Highly organized and able to manage multiple projects simultaneously
Excellent customer relationship management skills
Innovative problem-solving skills and ability to thrive in a fast-paced environment
Ability to work on client site in the NCR in Washington, D.C.
This position requires an active security clearance at the TS/SCI level with the ability/willingness to receive a polygraph. Current polygraph preferred.
Desired:
Masters degree or higher
Experience developing dashboards using Tableau, Qlik, Power BI, RShiny, plotly, or d3.js
Experience with version control software like Git
Experience with Agile development
Management consulting experience desired

#LI-SH1","$112,206 /yr (est.)",1001 to 5000 Employees,Company - Private,Management & Consulting,Business Consulting,1961,$100 to $500 million (USD)
"Intellibus
4.6",4.6,"Newark, NJ",Sr. Data Engineer — Snowflake,"Are you a Data Engineer working at a Large Financial Institution and being told by your leadership that you are too hands-on or detail-oriented or think and work like a start-up?
Imagine working at Intellibus to engineer platforms that impact billions of lives around the world. With your passion and focus we will accomplish great things together!
We are looking forward to you joining our Platform Engineering Team.
Our Platform Engineering Team is working to solve the Multiplicity Problem. We are trusted by some of the most reputable and established FinTech Firms. Recently, our team has spearheaded the Conversion & Go Live of apps that support the backbone of the Financial Trading Industry.
We are looking for Engineers who can
Create Data modeling
Work on Snowflake modeling – roles, databases, schemas, ETL toolswith cloud-driven skills
Work on SQL performance measuring, query tuning, and database tuning
Handle SQL language and cloud-based technologies
Set up the RBAC model at the infra and data level.
Work on Data Masking / Encryption / Tokenization, Data Wrangling / ECreLT / Data Pipeline orchestration (tasks).
Setup AWS S3/EC2, Configure External stages and SQS/SNS
Perform Data Integration e.g. MSK Kafka connect and other partners like Delta lake (data bricks)
We work closely with
Data Wrangling
ETL
Talend
Jasper
Java
Python
Unix
AWS
Data Warehousing
Data Modeling
Database Migration
ECreLT
RBAC model
Data migration
Our Process
Schedule a 15 min Video Call with someone from our Team
4 Proctored GQ Tests (< 2 hours)
30-45 min Final Video Interview
Receive Job Offer
If you are interested in reaching out to us, please apply and our team will contact you within the hour.
Job Type: Full-time
Pay: $60.00 - $80.00 per hour
Schedule:
Monday to Friday
Experience:
Data Wrangling: 7 years (Preferred)
Snowflake: 7 years (Preferred)
ETL: 7 years (Preferred)
Work Location: In person",$70.00 /hr (est.),Unknown,Unknown,Information Technology,Information Technology Support Services,2015,Unknown / Non-Applicable
Bonsai Robotics,#N/A,"San Jose, CA",Senior ML Ops Engineer - Data,"Job Overview:

We are seeking a highly skilled Sr. ML Ops engineer to join our team. As a ML ops engineer, you will develop, implement, and optimize our custom data pipelines for our ML systems. You should have a strong background in any of the following technologies: Databases(SQL, MongoDb), Cloud frameworks (AWS) and ML Frameworks (Pytorch/tensorflow). The ideal candidate will be proficient in programming languages such as C++ and Python.
About Bonsai:
Bonsai Robotics' mission is to create the next leap forward in agriculture equipment efficiency by creating a new ecosystem of semi-autonomous robotic machinery. Orchards are dusty, hazard-filled, and GPS-denied. The GPS-based autosteer features that have driven row crop efficiencies cannot function in orchards. Our vision, AI, and machine control systems offer human-level environment understanding and local navigation capabilities and will be the platform for a new wave of innovation in agricultural production and management systems.
We simultaneously solve twin crises impacting nut growers and most of specialty agriculture: there is not enough human labor when you need it, and operational expenses are growing dramatically. Our state-of-the-art technology empowers orchard managers to optimize their operations, dramatically reduce operational expenses, and increase profitability. We are pursuing a Bonsai Inside strategy, and partnering with the largest orchard Original Equipment Manufacturers (OEMs) in the retrofitting of existing machines and design of new form factors.
Key Responsibilities:
Develop, implement, and optimize data pipelines for ML systems.
Collaborate with cross-functional teams to store, process and certify petabytes of Image+Video data.
Coordinate with 3rd parties to handle labeling pipelines.
Create and maintain code documentation and unit tests.
Collaborate with ML scientists and provide data insights
Qualifications:
Bachelor's or Master's degree in Computer Science, Robotics, Electrical Engineering or related field
Strong background in most of the following technologies: Backend engineering, Data engineering, Databases, Dev Ops
Expert in Creating ETL pipelines
Proficiency in programming languages such as C++ and Python
Strong problem-solving skills and ability to work in a fast-paced environment.
Strong verbal and written communication skills.
Bonus: Experience with Pytorch and Ros 2
If you have a passion for computer vision, robotics, and developing innovative technology solutions, we encourage you to apply for this exciting opportunity. Bonsai Robotics values diversity, inclusivity, and excellence in hiring and strongly encourages candidates from traditionally underrepresented backgrounds to apply.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Allata LLC
4.3",4.3,Remote,Data Architect/Lead Engineer - Consulting (Remote Possible),"Allata is growing our Data & Analytics Practice to serve our clients nationwide. Our data architect / lead engineer practitioners will be collaborating with data engineers, machine learning engineers, analysts, data scientists, and other Allata employees and client teams on projects for companies across the United States.
WHAT YOU'LL BE DOING
Work with customers to build cloud-based data platforms, including integration, data storage and analytics
Develop innovative architectures to solve complex business problems utilizing the latest cloud technologies
WHAT YOU'LL NEED
Data Architecture Best Practices. You’ve successfully built data solutions that use industry best practices and fit with an organization’s needs. You are excited by solving problems and voraciously consume technology to do so. You have a broad and deep technical background
Communication. You have a natural charisma and use it to build consensus. You can have a conversation with developers, business analysts, managers of all levels, and individuals in a business function. You are comfortable presenting in front of groups and explaining architectures in a variety of levels of detail.
Make teams better. You're excited to be part of a team that delivers with quality and works hard on new opportunities. You work well in fast-moving environments and have no problem working with others to resolve difficult problems. You support teams as much as others supports you.
DESIRED SKILLS & EXPERIENCE
8-10 years of experience in a data related field
Experience building data storage and analytic solutions utilizing Snowflake
Expertise in building data platforms in Azure or AWS
Experienced with ETL tools such as Azure Data Factory, AWS Glue, WhereScape RED, Streamsets, Informatica and SAP Convergent Mediation
Experience in one or more Cloud Data Warehouse (Azure SQL Data Warehouse / Synapse Analytics, Snowflake, Amazon Redshift, Google BigQuery)
Experience in one or more Data Visualization tool (Tableau, PowerBI)
Expertise modeling architectures and integrations for data environments including data pipelines, data lakes, data warehouses, and data marts.
Experience with data backup and recovery strategies, optimization of clusters, structured/semi structured data, and changing database storage and utilization requirements
Experience with scripting languages such as Python / R for Business
Experience with Event Driven Architecture (Kafka)
Experience with large-scale distributed storage and database systems (e.g. SQL, NoSQL, MySQL, Cassandra)
At Allata, we value differences.
Allata is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Allata makes employment determinations without regard to race, color, creed, religion, age, ancestry, national origin, veteran status, sex, sexual orientation, gender, gender identity, gender expression, marital status, disability, or any other legally protected category.
This policy applies to all terms and conditions of employment, including but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Software Development,2016,$25 to $100 million (USD)
"RSA
4.0",4.0,"Overland Park, KS",Archer Business Enablement Data Engineer,"Business Enablement Data Engineer
Archer Technologies, LLC is the 25-year unseated market leader of integrated risk management (IRM) SaaS platforms that enable customers to improve strategic decision-making and operational resilience with a modern technology platform that supports qualitative and quantitative analysis driven by both business and IT impacts. As true pioneers in ERM, compliance, audit and cyber risk, Archer’s 800 employees are solely dedicated to helping customers manage risk and compliance programs, from traditional audits to emerging issues such as ESG. With over 25 years in the risk management industry, the Archer customer base represents one of the largest pure risk user communities globally, with more than 1,300 customers including more than 50% of the Fortune 500. Learn more at www.ArcherIRM.com.
The primary focus of the Business Enablement Data Engineer is to provide technical expertise with the creation and maintenance of Archer’s Global Data Lakehouse. This role will execute on complex analytics to help drive business decisions across a wide variety of often fast-paced internal engagements. The Data Engineer role will build innovative tools and applications that can help solve Archer’s internal data issues, help execute cutting-edge analytical techniques, help drive technical roadmaps for the function and firm, and train our colleagues.
Responsibilities:
Assist with creating, defining, and driving data engineering solutions to meet functional business requirements.
Data engineering needs can include Data aggregation/creation, data cleaning/manipulation, data science (e.g., geospatial, machine
learning, predictive modeling, etc.), and visualizations.
Solve various complex analytical challenges, sometimes dynamically balancing multiple internal projects simultaneously.
Supporting project teams with their analytics work in a “consultancy/expert” capacity on best practices concerning data & analytics
engineering (e.g., on-prem databases & systems, data storage & warehousing, data management, big-data principles, analytics app
prototyping, ETL)
Develop and drive the data engineering roadmap needed to support the business.
Collaborate with various stakeholders to continuously innovate on the tools, services, and data assets we can offer.
Serve as the lead technical expert and thought leader in helping to innovate and develop offerings that require / benefit from advanced
analytics skills or capabilities.
Provide technical expertise and thought leadership on developing analytical tools, services, and data assets and contribute to building
these areas directly when applicable.
Create production-quality data pipelines to develop and deploy scalable data science projects.
Stay current on best-in-class software, tools, and techniques to ensure we can provide best-in-class solutions.
Support development and upskilling of staff on relevant software, tools, and techniques
Develop and drive the technical roadmap on data engineering capabilities and infrastructure to ensure we operate a best-in-class Data
& Analytics function.
Qualifications:
Degree in a quantitative or business discipline or previous business experience preferred; examples include: Computer Science,
Engineering, Information Technology, Data Science, Statistics, Mathematics, Operations Research, Economics
Minimum 5 years of experience in applied data engineering; deep expertise in data engineering, as well as strong business and
strategic analytical skills
Ability to understand and articulate requirements to/from technical and non-technical audiences working alongside a data science &
engineering team.
Strong SQL & Python knowledge and familiarity with Big Data tools such as Spark & Scala; familiarity with Alteryx and Tableau
Experience with data modeling, data structures (e.g., relational, and non-relational data), databases, and ETL/ELT processes and an in depth understanding of large-scale data sets including both structured and unstructured data.
Experience with designing, implementing, and delivering scalable data solutions and pipelines on one of the cloud platforms (e.g., AWS,
Azure, GCP) and on-prem platforms such as Microsoft SQL Server
Experience with building and deploying proprietary cloud-based analytics web apps.
Hands-on experience in the development, deployment, and operation of integration technologies (e.g., APIs)
Proficiency with data warehouses (e.g., Snowflake, Teradata, Redshift, Hadoop, BigQuery, etc.)
Experience with containerization technologies (e.g., Docker, Kubernetes)
Experience with DevOps, Git, CI/CD
Experience directly managing another individual or a team.
Prior experience in Strategic Data Consulting is preferred.

Archer is committed to the principle of equal employment opportunity for all employees and applicants for employment and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Archer are based on business needs, job requirements and individual qualifications, without regard to race, color, religion, national origin, sex (including pregnancy), age, disability, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, protected veteran status, genetic information, or any other characteristic protected by federal, state or local laws. Archer will not tolerate discrimination or harassment based on any of these characteristics. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. All Archer employees are expected to support this policy and contribute to an environment of equal opportunity.
If you need a reasonable accommodation during the application process, please contact talent-acquisition@archerirm.com. All employees must be legally authorized to work in the US. Archer participates in E-Verify. Archer and its approved consultants will never ask you for a fee to process or consider your application for a career with Archer. Archer reserves the right to amend or withdraw any job posting at any time, including prior to the advertised closing date.","$86,978 /yr (est.)",5001 to 10000 Employees,Company - Public,Insurance,Insurance Carriers,1710,$10+ billion (USD)
"AnaVation
4.9",4.9,"Chantilly, VA",Senior Full Stack Data Engineer - REMOTE!,"Be Challenged and Make a Difference

In a world of technology, people make the difference. We believe if we invest in great people, then great things will happen. At AnaVation, we provide unmatched value to our customers and employees through innovative solutions and an engaging culture.

Description of Task to be Performed:
AnaVation is looking for a talented Full Stack Data Engineer who is passionate about technology and working with customers and a strong team to provide solutions for our mission-critical customer. The ideal candidate appreciates partnering with our customer and team of engineers to create innovative engineering solutions. The selected candidate will work with a small group of developers building a Cyber data lake. If you are looking to be challenged, then this is the environment for you. This position supports 80% remote work with up to one day per week in our Chantilly, VA office. The candidate will be required to pass a high-risk public trust background investigation.

Position Responsibilities:
Develop tools and processes to ingest Cyber data into an enterprise data lake.
Make recommendations on standards for a common Cyber data model and standards for harmonization of common data elements on data ingest.
Develop and evaluate tools to search, analyze, discover, and otherwise exploit data in the data lake to support investigative operations.
Required Qualifications:
5 or more years of relational database design and development (PostgreSQL, Oracle, Microsoft SQL Server)
5 or more years of ETL/ELT development experience · 2 or more years with Linux environment experience
2 or more years’ experience with shell scripting
Experience implementing data access controls
Experience analyzing unstructured, structured, and semi-structured data
Strong technical and computational skills, coupled with the ability relate data to use cases, mission requirements, and end-user experience
Experience with development in one or more programming or scripting languages (Java/Python/Go)
Active Secret Clearance or High Risk Public Trust Suitability
Bachelor’s degree in Computer Science, Information Systems or related discipline
Preferred Qualifications:
Experience with PostgreSQL
Experience with cloud data solutions such as AWS RedShift, AWS DynamoDB and Azure Cosmos DB
Experience with search technologies such as Elasticsearch, AWS Opensearch, Azure Cognitive search, SOLR, etc
Experience with Databricks, Azure Syanpse, or Apache Spark
Experience with cloud concepts and big data architectures such as Hadoop, Kafka, etc.
Knowledge of Continuous Integration/Continuous Delivery tools and practices
Experience with cloud platforms such as AWS and Azure
Experience working in Agile Environments
Experience with DevOps toolsets
Familiarity with containerization (Docker, Containerd, Kubernetes, etc.)
Experience with microservices
Benefits
Generous cost sharing for medical insurance for the employee and dependents
100% company paid dental insurance for employees and dependents
100% company paid long-term and short term disability insurance
100% company paid vision insurance for employees and dependents
401k plan with generous match and 100% immediate vesting
Competitive Pay
Generous paid leave and holiday package
Tuition and training reimbursement
Life and AD&D Insurance

About AnaVation
AnaVation is the leader in solving the most complex technical challenges for collection and processing in the U.S. Federal Intelligence Community. We are a US owned company headquartered in Chantilly, Virginia. We deliver groundbreaking research with advanced software and systems engineering that provides an information advantage to contribute to the mission and operational success of our customers. We offer complex challenges, a top-notch work environment, and a world-class, collaborative team.

If you want to grow your career and make a difference while doing it, AnaVation is the perfect fit for you!","$97,431 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2013,$5 to $25 million (USD)
"US Signal Company LLC
2.8",2.8,"Grand Rapids, MI",Technical Support Engineer (Tier 3 Cloud and Data Protection),"Job Description
US Signal is a leading data center services provider, offering secure, reliable network, cloud hosting, colocation, data protection, and disaster recovery services — all powered by its expansive, robust fiber network. US Signal also helps customers optimize their IT resources through the provision of managed services and professional services.
We are seeking a Technical Support Engineer to join our team in Grand Rapids, Michigan. This role is performed mostly on-site but could be hybrid.
The Technical Support Engineer (Cloud and Data Protection) is part of the Technical Operations Center team and is responsible for all level one, two, and three customer support for the US Signal Hosted and Enterprise Cloud services, Object and File Storage, and Disaster Recovery and Data Protection services. The primary function of the Tier 3 Engineer is to provide a world-class level of customer service with an efficient and timely resolution of cases. This role acts as an escalation point and mentor to the Tier 1 Support Agents and Tier 2 Support Specialists. A Support Engineer must be competent in each of US Signal's Cloud and Data Protection offerings, including VMWare, SoftNAS, Zerto, Avamar, Acronis Backup, Veeam Backup Recovery and Archive, Cohesity Data Management, and Remote Monitoring and Management through nAble. This position requires competency in all facets of Windows and Linux Server problem isolation and resolution. Strong networking background is also a plus.
Engineers will analyze current processes, procedures, and case workflow to develop ways to improve the support experience for US Signal customers.
This position is required to participate in an alternating on-call schedule as outlined by the Supervisor of Technical Operations.
FUNCTIONS/RESPONSIBILITIES
Analyze current processes, procedures, and case workflow to develop ways to improve the support experience for US Signal customers.
Work independently and act as a point of escalation for level III Data Protection and Cloud related issues.
Mentor technicians and engineers to develop skills as opportunities present themselves.
Troubleshoot various levels of Windows Server related issues using available server access methods.
Troubleshoot backup issues on the US Signal backup or disaster recovery platforms.
Receive incoming customer calls for trouble/technical support, acting as a subject matter expert for Data Protection and Cloud related issues. Probe customers for most valuable information in relation to trouble for accurate trouble tickets.
Special projects and assignments as deemed necessary by USS management.
Experience and Skills
Competencies:
Expert in customer service.
Experience working with backup and disaster recovery platforms
Familiarity with best practices in Business Continuity and Disaster Recovery
Experience with VMWare, and Windows Server/Linux Operating Systems
Understanding of virtual environments and overall Cloud infrastructure.
High level of analytical ability
Attention to detail and accuracy and excellent organization skills.
Excellent oral and written communication skills.
Ability to work well with all areas of the US Signal organization as well as external customers and vendors
Knowledge of Data/IP Networking including IP Subnetting, NAT, DHCP, etc.
Knowledge of routing protocols including BGP and OSPF.
Education:
Technical training in VMware, virtualization, and/or cloud computing
Technical training in Backup and Disaster recovery platforms
BS in Computer Science, Information Systems, Network Administration or Systems Administration desirable.
Experience:
Experience in Windows Server is required.
Familiarity with server architecture and design is essential.
Previous experience with VMware or virtual environments required.
Extensive experience with Data/IP Network Maintenance is preferred.
Technical experience in a data center, ISP or telecom environment is desired.
Experience working in a process driven helpdesk environment
Working Conditions and Physical Demands:
The majority of the time is spent in a professional office environment and this role routinely uses standard office equipment.
Required License(s)/Certification(s):
Active CCNA (or higher) preferred.
All US Signal employees will comply with US Signal Information Security policies to ensure the confidentiality, integrity, and availability of US Signal and customer data. All employees are responsible to ensure actions comply with state and federal regulations and requirements.
We offer a competitive compensation and benefits package including a 401k plan with a match. If you are looking to be part of a dynamic team, please apply now.
Job Type: Full-time
Pay: From $65,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Schedule:
Monday to Friday
Supplemental pay types:
Bonus opportunities
Work Location: Hybrid remote in Grand Rapids, MI 49503","$65,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2001,Unknown / Non-Applicable
"Atkore
4.0",4.0,"Harvey, IL",Applications Engineer - Data Center Containment,"Applications Engineer
Who we are:
Atkore is forging a future where our employees, customers, suppliers, shareholders, and communities are building better together – a future focused on serving the customer and powering and protecting the world.
With a global network of manufacturing and distribution facilities, Atkore is a leading provider of electrical, safety and infrastructure solutions.

Who we are looking for:
We are currently looking for an Applications Engineer. You will manage and be the go-between for owner’s needs, building requirements and our factory delivered solutions by working closely with General Contractors, Mechanical and Electrical contractors, and system integrators across a wide range of sites for hyperscale, colocation, and retail providers in the space. You will be supported by a full commercial, estimating, factory engineering team delivering product from our owned manufacturing plant(s) in the USA.

What you’ll do:
Serve the customer’s needs as a critical member of our team to help support the launch of Atkore’s data center containment solution.
Work closely with Director of Sales to become the application expert to identify current and future customer needs and help the customer find appropriate solutions for customer applications whilst promoting Atkore portfolio.
Coordinate with our project management team and walk job sites (as required) to understand site conditions.
Coordinate with our factories to ensure critical to build issues are addressed including documenting technical requirements for both domestic and overseas project plans and project changes.
Examine and interpret blueprints/plans/drawings to find containment opportunities and coordinate requirements to the estimating team.
Lead the design and installation of our containment solutions to exceed customer expectations including developing installation manuals and on-site assistance to Unistrut Construction team during installation.
Maintain and update our technical library, including CAD models, drawings, specifications, test data, etc.
Support our Regional Sales Managers (RSM) team with client proposals and technical presentations.
Establish and build strong trusting relationships with key stakeholders and provide unmatched quality, delivery, and value.
Travel requirements are 15-25% of the time

What you’ll bring:
5+ years of hands-on field experience in applications engineering, engaging with the customer through the requirements definition, generating a concept and proposal through the delivery and installation of the solution
A history of building and maintaining customer relationships, preferably in the data center market.
Possess a technical aptitude and comfort in understanding blueprints and specifications.
High energy and integrity, strong team player, exceptional work ethic, and a history of proven sound decision making.
Ability to think strategically and develop long term goals
Engineering degree or relevant experience.
Autodesk Inventor, Microsoft Office Suite, CRM Tool experience
Word, Excel, PPT, and CRM tool experience.

Within 3 months, you’ll:
Complete Atkore’s immersion program to understand our mission, vision, values, business processes, products, people, and our culture.
Learn about our manufacturing, operations, and field installation teams capabilities for containment.
Understand how your role works closely with the sales, operations, and installation teams and contributes to Atkore’s overall strategy.
Gain buy-in with Unistrut Construction stakeholders that help support our sales objectives.
Develop a submittal and design process to work collaboratively with RSMs to improve our value and conversion rate.
Understand our value proposition and incorporate added value into the containment design.
Within 6-months, you’ll:
Become familiar with the design, build, and installation of Atkore’s containment solution
Create strong relationships with executives, key stakeholders, and strong influencers.
Use Autodesk Inventor to update, maintain and distribute technical and manufacturing drawings.
Develop bespoke installation manuals for each application
Provide on-site assistance to optimize installation efficiencies in support of client schedule.
Identify other resources needed to scale our business.
Within 12-months, you’ll:
Become the Atkore containment subject matter expert and make recommendations to improve the program
Proficient at reading drawings, specifications, and blueprints for data centers.
Take the lead as the conduit between sales and operations, working with the Manufacturing Engineers on delivery and installation to keep customers’ project on schedule.
Collaborate with the Global Director of Product Management, Global Director of Product Engineering on various projects and tasks related to new product development.
Assist Director of Sales with every data center containment internal scope review and external scope review with customers.
Build enough demand to recruit, hire, and train teammates.

Atkore is a recipient of a Great Place to Work© certification and a Top Workplaces USA award! We’re committed to creating an engaged and aligned workforce that drives collaborative culture. Our team strives for breakthrough results, stays focused on being standout leaders, and fully supports decisions of the Company. We consistently live the Atkore mission, strategic priorities, and behaviors, all in a way that’s consistent with our core values. Together, we build strong leaders that continually endeavor to move us forward.
Join our team and align yourself with an industry leader!
#LI-ET1
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$82,585 /yr (est.)",1001 to 5000 Employees,Company - Public,Manufacturing,Machinery Manufacturing,2010,$1 to $5 billion (USD)
"84.51°
4.3",4.3,"Cincinnati, OH",Senior Data Engineer (P996),"84.51° Overview:
84.51° is a retail data science, insights and media company. We help the Kroger company, consumer packaged goods companies, agencies, publishers and affiliated partners create more personalized and valuable experiences for shoppers across the path to purchase.
Powered by cutting edge science, we leverage 1st party retail data from nearly 1 of 2 US households and 2BN+ transactions to fuel a more customer-centric journey utilizing 84.51° Insights, 84.51° Loyalty Marketing and our retail media advertising solution, Kroger Precision Marketing.
Join us at 84.51°!
__________________________________________________________

As a member of our engineering team, you will use various cutting-edge technologies to develop applications that turn our data into actionable insights used to personalize the customer experience for shoppers at Kroger. We also work with Kroger's supply chain related data assets including but not limited to: Orders and Shipments, Inventory, Planogram and Pricing information to help Kroger, CPG and broker clients make tactical and strategic business decisions. We use agile development methodology bringing everyone into the planning process to build scalable enterprise applications and solutions.
What you'll do
Work within a team that owns the Semantic Layer of a large commercial reporting application.
Create and maintain complex retail customer loyalty measures and commercial data security rules.
Use strong business analysis skills to translate commercial requirements into technical requirements.
Use strong Data Warehouse and BI Tool background and understanding of every layer of the technical stack in order to convert requirements into platform wide implementation solutions.
Work with the team to implement the semantic layer portion of those solutions using a BI Tool framework.
Develop custom engineering tools to assist with the implementation, automation, and testing of the solution to reduce time to market for new Insights capabilities.
Responsibilities
Participate in design and development of highly visible data solutions
Support Commercial Facing data pipelines
Perform unit and integration testing
Collaborate with architecture and lead engineers to ensure consistent development practices
Participate in retrospective reviews
Participate in the estimation process for new work and releases
Collaborate with other engineers to solve and bring new perspectives to complex problems
Drive improvements in people, practices, and procedures
Embrace new technologies and an ever-changing environment
Requirements
3+ years proven ability of professional Data Development experience
Experience with a Business Intelligence Reporting Tool
Full understanding of ETL concepts and Data Warehousing concepts
Proficient with Relational Data Modeling
Thorough understanding of CI/CD concepts and best practices
Comprehensive Understanding of ANSI SQL
Foundational Understanding of Cloud Processing Concepts
Foundational Understanding of Agile Principles
Exposure to Retail Business Intelligence
Exposure to interacting with , enhancing and creating Cloud based services
Passion for Problem Solving
Passion for creating supportable technical solutions
Experience communicating to and with functional colleagues
Preferred Skills
dbt
Python
Python FAST API framework
Power BI
Snowflake
Alation
Microsoft Azure
MongoDB
Oracle
#LI-Remote #LI-DOLF","$84,414 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2015,Unknown / Non-Applicable
"Peraton
3.6",3.6,"Pacific, MO",Data Engineer – DoD TS/SCI – Camp Humphrey – Korea,"Responsibilities:
Peraton is seeking a Data Engineer, in support of a US Government client at Camp Humphrey in South Korea, who can leverage experience and expertise in data exploration, engineering, and ETL to architect, develop, and deploy scripts for processing structured and unstructured data into usable data formats for long term storage, search, and analysis
The successful Data Engineer candidate will work with a diverse team of data scientists, social scientists, cultural advisors, operations research systems analysts (ORSAs), and Irregular Warfare (IW) planners to translate empirical research findings into operational assessments.
The Data Engineer will be responsible for developing user interfaces, data extraction and transformation to improve data reliability, quality and utility.
The candidate should also be comfortable working with military IRC planners to break down and synthesize data in a fashion that best informs plans and operations.
Roles and responsibilities for this position include:
Utilize your experience with AWS, Azure, or Google Cloud
Creating a custom ingest pipeline to a Big Data platform with consistent performance and scalability
Understanding programming and data engineering concepts and best practice
Experience working with both structured, semi-structured, and unstructured data to include data parsing, transformation, schema definition, and query/analysis
Ability to manage and organize data while identifying trends and inconsistencies that will impact downstream analytics
Experience with data pipelines or be willing to learn a pipeline from bottom to top
Be able to troubleshoot files against an architecture to see where the upload process is failing
Be able to understand unit tests and add to them to increase stability to the entire pipeline
Be prepared to use GIT, Anaconda, Spyder, and Microsoft tools
Be prepared to express ideas and solutions and walk together with teammates through coding challenges
Qualifications:
Basic Qualifications:
Bachelor of Science in computer programming, mathematics or a related degree with 8-10 years of experience, 6-8 yrs. with a Master’s Degree
Demonstrated experience applying data engineering and software development expertise
Work / research history demonstrating applied experience with programming languages such as Python, SQL, Java, etc. with Linux OS (Ubuntu, CentOS, Red Hat), and Windows environments
Ability to work both independently and collaboratively with high levels of curiosity, creativity, and problem-solving capabilities
Strong written and verbal communication skills
Experience building ETL pipeline architectures and AWS, architectures with experience with ETL tools such as NiFi or Informatica
Must be willing and able to travel within the CCMD area of responsibility as required by the program.
Must be a U.S. Citizen with Current US Passport
Current DoD Top Secret clearance with SCI eligibility

Preferred Qualifications and Training:
A graduate degree in computer programming / science, mathematics, or related degree and 10 years of experience
AWS certifications such as AWS solutions architect or developer
Cyber security certifications
Statistical package expertise in programs such as IBM SPSS/PASW, R, STATA or MS Excel statistics
Experience applying data science to address defense or social science issues
Experience using geospatial analytic package (e.g., ArcGIS, QGIS, etc.)
Joint intelligence or operational assessment experience with Combatant Commands
Peraton Overview:
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers.
Target Salary Range: $146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors. EEO: An Equal Opportunity Employer including Disability/Veteran.","$190,000 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $10 billion (USD)
"Gentiva
3.3",3.3,"Mooresville, NC",Business Intelligence Developer / Data Engineer,"Our Company:

Gentiva is an industry leader in hospice, palliative and personal home care. Our place is by the side of those who need us, offering physical, spiritual and emotional support to patients and their families so they may make the most of every moment. We believe that better care for caregivers and clinicians means better care for everyone, so we offer ongoing professional training, lower nurse-to-patient ratios, and comprehensive benefits for eligible employees. Here, you’ll join gifted colleagues who make a lasting difference in people’s lives every day.

Overview:
We are looking for a remote Business Intelligence Developer / Data Engineer to join our team. This position reports to the Director Business Intelligence and Data Services and is responsible for developing, deploying, and maintaining BI interfaces. Those include query tools, data visualizations and interactive dashboards, ad hoc reporting, and data modeling.
Transform business requirements into technical specifications
Design and develop ETL processes to move/load data to/from various locations including files systems, ftp sites, and data bases
Define and develop internal teams’ Service Delivery KPIs dashboards to improve customer experience
Monitor and manage new and existing integration elements to ensure continued customer satisfaction
Act as Subject Matter Exert (SME) in a verity of data / analytics platforms such as SQL Server, Power BI and Microsoft Visual Studio/SSIS
Design and develop interfaces such as APIs. Forward thinking toward newer technologies and where these may be implemented
About You:
Bachelor's degree in computer science or a related field
5+ years’ of Experience with Microsoft SQL Server Integration service (SSIS)
5+ years’ experience with SQL, T-SQL, and stored procedures
5+ years’ of data engineering/modeling experience with both snowflake and star schema data modeling
2+ years’ of progressive experience in healthcare IT
3+ years’ experience with Business Intelligence tools such as Power BI and SSRS
Experience with Cloud Technologies such as Azure, AWS, etc is a plus
Requires demonstrated experience in project management
Good oral and written communication skills
Self-motivated and able to adapt to new technology and processes quickly
We Offer:
Comprehensive Benefits Package: Health Insurance, 401k Plan, Tuition Reimbursement, PTO
Opportunity to Participate In a Fleet Program
Competitive Salaries
Mileage Reimbursement
Professional Growth and Development Opportunities
Legalese:
This is a safety-sensitive position
Employee must meet minimum requirements to be eligible for benefits
Where applicable, employee must meet state specific requirements
We are proud to be an EEO employer
We maintain a drug-free workplace
Location: Gentiva",#N/A,10000+ Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2010,Unknown / Non-Applicable
CO,#N/A,Remote,Devops Data Engineer/Devops Data Analyst(W2 Only),"Devops/ Technical Data Analyst
6+ Months
Remote
W2 Only
Primary Skills:
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts applications and languages - preferably Oracle/Exadata SQL Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products ie ACH Wire Lockbox BAI EDI etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie XL Release Jenkins Git SVN test automation
Experience with unit functional regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Job Description
Enterprise Commercial Payments Data Mart Technical Data Analyst The Embedded Banking Data and API team is responsible for the Enterprise Commercial Payments Data Mart and Banking as a Service APIs. This position will primarily be focused on the Data Mart. Built on Oracle Exadata, the Mart is sourced with transactional Data from Core Payment systems (ACH, wire/RTP, lockbox, etc) through both batch/ETL and real-time feeds. The data is used as the source for reporting and inquiry APIs and Webhooks that are exposed to Commercial Clients, Fintech partners and internal Keybank systems. It is also used to generate BAI and other reports for Corporate Clients. Responsibilities will include:
Data Sourcing
Capturing requirements and designs for batch/ETL (Ab Initio) integrations
Capturing requirements and designs for real time (webMethods/Java) integrations
Identifying and implementing improvements to decrease load time and optimize database performance
Troubleshooting issues
Data Consumption
Capturing requirements and designs to meet requirements for Embedded Banking APIs
Capturing requirements and designs to meet requirements for BAI and other reports
Identifying and implementing improvements to improve API performance
Troubleshooting issues
Data SME
Working with SMEs from the source payment platforms to learn about and become expert on the critical data elements in the data mart
Respond to questions from consumers regarding data
Maintain documentation/data libraries
Interacting with the following:
Line of Business partners (Embedded Banking, Commercial Payments, Digital Channels)
Vendors/Clients
Production Support Team: provide knowledge transfer and assist with troubleshooting issues
Data Supply Chain (ETL/Abinitio, Data Model) Teams
Kafka Event Management Team
Open Banking Engineering Teams
Database Administrators
Infrastructure Teams
Internal Interfacing Teams
QAS/Testing Team: review test plans, help find data, and assist/supplement the testing
Working with and through direction of ECA Mart Technical Lead
Helping support, maintain and review dashboards in Kibana
Required Experience / Skills
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts, applications and languages - preferably Oracle/Exadata, SQL, Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products, ie, ACH, Wire, Lockbox, BAI, EDI, etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie, XL Release, Jenkins, Git, SVN, test automation
Experience with unit, functional, regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Preferred Experience / Skills
Experience with database design, analytics
Experience with other programming languages
Basic understanding/experience with APIs, developer portals; Fintech integrations
Experience in creating REST API Documentation using OpenAPI/Swagger Specs. Swagger and Yaml, or similar tools
Experience working on an Agile Team
Job Type: Contract
Pay: $65.00 - $67.00 per hour
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Experience:
DevOps: 9 years (Preferred)
Data Engineer: 9 years (Preferred)
CI/CD: 9 years (Preferred)
ETL/Ab Initio: 8 years (Preferred)
Agile: 9 years (Preferred)
WebMethods/Java: 6 years (Preferred)
Jenkins, SVN: 9 years (Preferred)
RESTful API: 8 years (Preferred)
Commercial Payments: 8 years (Preferred)
Kafka: 2 years (Preferred)
Work Location: Remote",$66.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Olsson
4.0",4.0,"Kansas City, MO",Senior Electrical Engineer - Arc Flash - Data Center (Remote),"Company Description

We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.
Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us — and will continue to allow us — to grow. The result? Inspired people, amazing designs, and projects with purpose.

Job Description

As an Electrical Engineer, you will work directly with some of the world’s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in performing short circuit analysis and producing arc flash studies is required. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.
We currently have one opening and will consider candidates interested in being located in most locations across the United States.

Qualifications

You are passionate about:
Working collaboratively with others
Having ownership in the work you do
Using your talents to positively affect communities
Electrical Engineering knowledge
You bring to the team:
Strong communication skills
Ability to contribute and work well on a team
Ability to be a self-starter to take on a variety of tasks to best serve the client and their project work
Investigation and troubleshooting of problems to find solutions
Ability to contribute and work well on a team
Bachelor's Degree in electrical engineering
8+ years or related electrical engineering experience
Registered professional engineer (PE) required
SKM and ETAP software experience is preferred

Additional Information

Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we’re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.
As an Olsson employee, you’ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you’ll:
Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)
Engage in work that has a positive impact in communities
Receive an excellent 401(k) match
Participate in a wellness program promoting balanced lifestyles
Benefit from a bonus system that rewards performance
Have the possibility for flexible work arrangements
Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.
#LI-MP1
#LI-REMOTE","$85,435 /yr (est.)",1001 to 5000 Employees,Private Practice / Firm,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1956,$100 to $500 million (USD)
"VISUAL SOFT, INC
4.1",4.1,"Washington, DC",Data Engineer - Active TOP SECRET - REMOTE-ONSITE,"Visual Soft, Inc is seeking qualified candidates to work on our efforts with a Prime for their end customer, a federal agency.

Position: Data Engineer - (50% REMOTE and 50% ONSITE)
Location: Washington, DC or Crystal City, Arlington, VA
Shift time: 8 am to 5 pm

JOB DESCRIPTION:
As a Data Engineer, you’ll implement data engineering activities on some of the most mission-driven projects in the industry. You’ll deploy and develop pipelines and platforms that organize and make disparate data meaningful. You will collaborate and work with and guide a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for your clients.
**Desirable skills include, Spark, Databricks, Data Lakes, Bigdata Tools and Technologies and AWS
Years of Experience:: 5+ years of experience
Education Requirement: BS degree preferred
Clearance requirement: Top SECRET is a MUST

Standard Benefits:
Our standard benefits include: Our standard benefits include 3 weeks of Paid time off (PTO that includes sick leave). Any unused PTO will be issued as a check at the end of an employee's anniversary with us. we also provide 2 floating and 8 public holidays. Floating and holidays expire at the end of every year of service of an employee. In addition, company will cover 50% of health and dental insurances only for all full time employees, however, dependents can be added at extra cost. Employee's health and dental coverage becomes effective after 30 days or first of the month after an employee completes initial 30 working days, we cover 50% for the employee's health and dental insurances. Dependents coverage for health and dental insurances is available as an out of pocket expense for employees. An employee has to finish all of your paper work for health and dental in the first 30 days of your employment with us. We provide STD, LTD and one time salary equivalent of life insurance at NO cost to all full time employees. All full time employees or w-2 employees with no benefits will be eligible to participate in company's 401k program after 90 days of employment with a company match of 4%, immediate vesting. In addition, all w-2 employees are eligible to be part of company's profit sharing, no employee contributions required. No commuting and/or parking expenses provided.","$93,472 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,$1 to $5 million (USD)
"Ansys
4.1",4.1,"Canonsburg, PA",Lead Application Engineer- Data Simulation Solutions,"When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.

Take a leap of certainty … with Ansys.

Summary / Role Purpose
Join the Ansys Customer Excellence team to partner with our customers to engineer what''s ahead, solve their real-world engineering problems, deploy Ansys software in their design workflows, and grow Ansys’ business. As a subject matter, industry and Ansys solutions expert, you will use advanced-level engineering knowledge to provide technical pre-sales support, perform professional services, and help guide Ansys product roadmap based on customer requirements. You will consult with customers on simulation-based solutions in support of their key business initiatives, lead project teams to create pervasive simulation solutions and mentor junior engineers.

Key Duties and Responsibilities
Lead in coordinating and executing all technical activities throughout the sales opportunity lifecycle such as technical discovery, negotiate technical success criteria, product presentations, demonstrations and evaluations. Work independently within multi-disciplinary teams
Help guide complex sales engagements to successful outcomes using subject matter expertise and industry knowledge
Interact with customers to understand their key business initiatives, product design needs and engineering design workflows; analyze how to address customers’ requirements using Ansys products and platform, articulate Ansys’ value proposition to Executive level audiences
Lead project teams to create differentiating simulation solutions using the Ansys platform and products; deploy the solutions within customers’ design workflows
Mentor junior engineers
Collaborate with the Ansys product development teams to guide Ansys product roadmap; lead project teams testing new releases of Ansys products on industrial problems, develop application best practices
Participate in corporate initiatives to further enhance Ansys technology, processes and people skills
Support Ansys field and digital marketing, author conference presentations
Contribute to consulting services, conduct intermediate and/or advanced training classes
Analyze business and technical needs, requirements, and the state of a customer’s current infrastructure, operations, and simulation & other engineering workflows
Consult our customers on process design and process optimization
Derive the technical specifications in collaboration with other business process analysts, subject matter experts, peers and Ansys Product Management
Develop creative and appealing Proof of Concepts to solve complex business problems
Lead/Assist in coordinating and executing all technical activities (design, develop, deploy) throughout the sales opportunity such as customer meetings and product presentations, demonstrations and evaluations with Ansys personnel and Services Partners
Utilize the components of the Ansys platform as the foundation for building complete solutions that digitally transform customer product development processes to facilitate more engineering in the digital domain by leveraging simulation
Participate in internal corporate initiatives to further enhance the solution suites, presales/sales enablement and business growth
Articulate the Ansys value proposition, which may encompass its entire suite of products (mechanical, fluid, electrical, electronics, optical, systems, software...).
Be a team player who can collaborate effectively with all key Ansys and customer stakeholders including sales, product development, project management, IT management, implementation engineers, and end users

Minimum Education/Certification Requirements and Experience
Required education and degree type: BS or MS or PhD in Mechanical/Chemical/Aerospace/Electrical Engineering or related field
Required minimum years of professional experience in an engineering software environment: BS+8, MS+6, or PhD+3
Subject matter expert in one or more relevant disciplines within Ansys’ business and is/will be sought out for advice by other Ansys engineers
Demonstrated understanding of engineering practices and product development, experience with building solutions using simulation technology and deploying those solutions within customers’ engineering workflows
Track record of delivering exceptional customer outcomes and revenue impact
Strong leadership and mentoring skills
Logical problem-solving, strong interpersonal and communication skills, fluent in writing and speaking English
Ability to organize and manage multiple projects which are complex in nature, possesses a sense of urgency
Projects a professional image and demonstrates business acumen, driven to succeed
Ability to travel domestically up to 25% of time
Proven track record of analyzing customer’s business and technical needs, requirements, and their state of current infrastructure, operations, and simulation & other engineering workflows
Proven track record of architecting solutions consisting of various (software) components and leading corresponding implementations
Experience in consulting customers on business process design and optimization
Self-starter who possesses a sense of urgency, strong organizational and follow up skills
Willing to evolve in a dynimic and innovative environment, eager to learn

Preferred Qualifications and Skills
Preferred education and years of professional experience in an engineering software environment: BS+12, MS+10, or PhD+7
4 years of experience in application engineering, customer support, or consulting services type customer facing roles using engineering software
Ability to interact effectively with senior business managers and C-level executives
Ability to travel domestically up to 50% of time
Demonstrated use of relevant Ansys software or knowledge of other commercial CAE, CAD, EDA, PLM software packages
Good understanding of enterprise class product development systems like SLM, SPDM, ERP, ALM, TDM, MIM/IMM, PDM, PLM (e.g. Aras Innovator, Siemens Teamcenter, Dassault ENOVIA or 3DEXPERIENCE, MSc SimManager, MSc MaterialCenter)
Basic understanding of programming languages such as: python, C# (.NET), Javascript, HTML,
Experience with DevOps/continuous integration and deployment
Practical knowledge of agility and agile project management
Ability in interest in obtaining a security clearance

This role is not available for sponsorship.

At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential in the knowledge that every day is an opportunity to observe, teach, inspire, and be inspired. Together as One Ansys, we are powering innovation that drives human advancement.

Our Commitments:
Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper
Our Values:
Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger

Our Actions:
We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results

OUR ONE ANSYS CULTURE HAS INCLUSION AT ITS CORE
We believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.

TAKE A LEAP OF CERTAINTY IN YOUR CAREER AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high - met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.

At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.

CREATING A PLACE WE’RE PROUD TO BE
Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: America’s Most Loved Workplaces, Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, U.K.).


For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.","$103,804 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Computer Hardware Development,1970,$1 to $5 billion (USD)
"EvolutionIQ
4.8",4.8,"New York, NY",Lead Data Infrastructure Engineer (AI / Insurtech),"About us: EvolutionIQ's mission is to improve the lives of injured and disabled workers and enable them to return to the workforce, saving billions of dollars in avoidable costs and lost productivity to the US and global economies and make insurance more affordable for everyone. We are currently experiencing massive growth and to accomplish our goals, we are hiring world-class talent who want to help build and scale internally, and transform the insurance space. We're backed by First Round Capital, FirstMark Capital, Foundation Capital, Brewer Lane Ventures, and have been named as Inc.'s top places to work!
Our Team: We are founded by a senior Google AI expert and a Bridgewater Associates Algorithmic Investor & Stanford MBA. We're not looking for employees. We're looking for partners in work, partners in culture-building, and partners in the future of data-driven insurance. The development team consists of world class engineers and leaders from companies like Google and Bloomberg. Each individual has had great success building large scale enterprise software and is now excited to try their hand at transforming the insurance industry.
Job Summary: We are looking for a Lead Engineer for our Data Platforms who will play an integral role in securing, architecting, and managing our highly sensitive insurance data. This position is tasked with overseeing our foundational datasets, data models, and analytics. The ideal candidate will have considerable experience in creating and managing secure data platforms, a strong engineering background, and a demonstrated record of technical leadership and effective communication.
In this critical role, you will not only ensure the robustness and reliability of our data systems, but also their security and compliance with stringent industry regulations. You will navigate the complexities of insurance data, bringing technical excellence and a security-first approach to safeguard our information assets. Your keen eye for security will be instrumental in protecting our company, customers, and stakeholders, while your technical expertise will shape the future of our data platform architecture.
Key Responsibilities:
Architect, design, and implement robust, secure, scalable, and high-quality data platforms, ensuring the availability, integrity, and confidentiality of the information.
Lead the development and maintenance of data pipelines, including personally coding and building the most critical components.
Work closely with product engineers, data scientists, analysts, and other stakeholders to understand data needs and deliver on those needs.
Define, design, and improve foundational data models to be used across the company to enable feature development and analytics.
Continuously improve our data quality toolkit
Provide guidance and technical leadership to the data engineering team, promoting continual team growth and individual team member skill development.
Be a role model for all engineers and provide mentorship as needed
Drive proof of concepts and experiments to explore new technologies that can level up the entire organization
Requirements:
7+ years of industry experience, holding staff/principal/lead level roles in Software Engineer or Data Engineer, with a focus in building scalable, mission critical, data platforms
Strong written and verbal communication skills
Extensive Python development experience
Experience with distributed data/computing tools, such as: Spark, Airflow, dbt
Proven track record of establishing engineering best practices for both coding and architecture
Experience building out systems and processes to enable secure handling of highly sensitive data
Experience using modern big data storage technologies such as Apache Parquet or Avro
Strong familiarity with modern data warehouse such as BigQuery or Snowflake
Ambitious, collaborative, and empathetic values
Even Better if You Have:
You have at least 3+ years experience in deploying systems on GCP or AWS
Experience with MLOps, such as feature engineering and model serving
You have worked with Dagster/Airflow, BigQuery, GCP, Terraform, Kubernetes, sklearn, keras/TensorFlow/pytorch, dbt, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions
The Fit: We're a team of architects and visionaries who thrive on being first. We've created a fun, passionate, humorous, friendly, and fiercely-driven engineering culture that values delivery and personal impact above everything else. We are open to sponsoring candidates who currently are in the US and need to transfer their active H1-B visa.
Work-life, Culture & Perks:
Compensation: The range is $210-240K depending on a candidate's background and experience.
Well-Being: Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%
Work/Life Balance: For this role we are hoping this person can work out of the NYC office regularly with much of our leadership with flexibility. We also have a flexible vacation policy and are closed for winter break at the end of the year
Home & Family: Flexible PTO, 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn
We also have a flexible vacation policy and are closed for winter break at the end of the year
Office Life: Catered lunches, happy hours, and pet-friendly office space. $500 for your in home office setup and $200/year for upgrades every year after your initial setup
Growth & Training: $1,000/year for each employee for professional development, as well as upskilling opportunities internally
Sponsorship: We are open to sponsoring candidates currently in the U.S. who need to transfer their active H1-B visa
EvolutionIQ appreciates your interest in our company as a place of employment. EvolutionIQ is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees","$88,635 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2019,$25 to $100 million (USD)
"Lyft
3.6",3.6,"San Francisco, CA",Senior Data Engineer,"At Lyft, community is what we are and it's what we do. It's what makes us different. To create the best ride for all, we start in our own community by creating an open, inclusive, and diverse organization where all team members are recognized for what they bring.
Here at Lyft, Data is the only way we make decisions. It is the core of our business, helping us create a transportation experience for our customers, and providing insights into the effectiveness of our product launch & features.
As a Data Engineer at Lyft, you will be a part of an early stage team that builds the data transport, collection, and storage, and exposes services that make data a first-class citizen at Lyft. We are looking for a Data Engineer to build a scalable data platform. You'll have ownership of our core data pipeline that powers Lyft's top-line metrics; You will also use data expertise to help evolve data models in several components of the data stack; You will help architect, building, and launching scalable data pipelines to support Lyft's growing data processing and analytics needs. Your efforts will allow access to business and user behavior insights, using huge amounts of Lyft data to fuel several teams such as Analytics, Data Science, Marketplace, and many others.
Responsibilities:
Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft
Evolve data model and data schema based on business and engineering needs
Implement systems tracking data quality and consistency
Develop tools supporting self-service data pipeline management (ETL)
SQL and MapReduce job tuning to improve data processing performance
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge
Unblock, support and communicate with internal & external partners to achieve results
Experience:
5+ years of relevant professional experience
Strong experience with Spark
Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet)
Strong skills in a scripting language (Python, Ruby, Bash)
Good understanding of SQL Engine and able to conduct advanced performance tuning
Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)
1+ years of experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)
Comfortable working directly with data analytics to bridge Lyft's business goals with data engineering
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.
Starting in September 2023, this role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.
The expected range of pay for this position in the San Francisco Bay Area is $162,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","$163,274 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Computer Hardware Development,2012,Unknown / Non-Applicable
"KaylaTek
4.2",4.2,"Andrews AFB, MD",Data Center Engineer- Senior - Secret Clearance,"$3,000 Referral Bonus for this position!
Come join our growing team with a 21st Century Vision! At KaylaTek, we understand that the key to our success is the quality of the people we employ. Our focus is not just on jobs, but on building and enhancing your career through ongoing professional development, training, and high quality of life. Our team members choose KaylaTek for a number of reasons including our competitive compensation and benefit packages, dedication to education, as well as our outstanding service. Our Grow Strong Vision encompasses a place for employees to grow, learn and feel a sense of belonging, not just a place to work.
Employee Benefit Offerings
Medical, Dental, Vision, 401(k) with company matching, Short-Term and Long-Term Disability, Life and AD&D Insurance, Paid Time Off, 11 Paid Holidays, Employee Assistance Program (EAP), Professional Development Program, Military Leave Support and much more.

Job Site: Joint Base Andrews, MD

Shift Hours: Day-Shift; core support hours are 0600 -1800. This is a 24/7/365 support environment; off-hours response/support may be required, however only standard M-F core hours working time for current position.
Overview: KaylaTek is seeking a Data Center Engineer to provide technical leadership and support in the areas of IT planning, solution specification/design, implementation and target architecture development for the AFNCR Consolidated Communication Center (CCC). The Data Center Engineer will support the 844th Communications Group at Joint Base Andrews (JBA). This role includes supporting the Air Force District of Washington (AFDW) and Headquarters Air Force (HAF) customers on both NIPRNet and SIPRNet domains for the development of the CCC building. The qualified candidate will have knowledge of information technology commercial solutions and experience designing and developing technical solutions. The preferred candidate will have excellent communications skills, a strong customer service orientation and experience serving as an advisor to Chief Architect and other Government/Contractor staff and managers.
Certifications required: Active Security + CE

Roles and Responsibilities:
Assist in planning, coordinating, and managing the technical aspects in projects related to the CCC datacenter. As well, identify and manage dependencies between these projects and with other ongoing activities.
Lead and assist with all design aspects of the CCC data center support systems, to include AC/DC power, UPS, HVAC, carrier infrastructures, internal/external cable plant, and overall data center layout.
Produce architectural artifacts to include system design diagrams, recommendation justifications, and technical specifications.
Communicate conceptual designs and create/maintain project documentation before, during, and after construction.
Create and review civil/structural/architectural design RFPs.
Assist with managing consultants/contractors through the design and construction process.
Effectively communicate design standards to internal and external project partners
Think outside of the box to find innovative solutions prior to and during the construction process to reduce costs without negative impacts on quality or reliability.
Conduct site assessments, internal design meetings, construction reviews.
Assess client's current IT and facility infrastructure.
Lead and assist with data center migration planning
Required Qualifications:
Bachelor's Degree with 15+ years in Civil Engineering or the equivalent relevant experience in datacenter or mission critical facilities design.
Possess an active Secret security clearance
Proficiency in building codes, regulations, and standards
Ability to build and maintain relationships, partnerships and external networks
Ability to work independently, with minimal supervision and work effectively in a collaborative team environment while keeping the team informed.
Excellent customer facing skills.
Excellent researching, decision-making and organizational skills are required.
Excellent written and verbal communication skills.
Proven analytical, evaluative, and problem-solving abilities.
Working knowledge of Microsoft Office Suite including Microsoft Visio or AutoCAD.
Maintain confidentiality and adhere to data protection and other guidelines where appropriate.
The above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of personnel so classified.
COMMITMENT TO DIVERSITY
KaylaTek is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.
E-VERIFY AND BACKGROUND CHECKS

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. KaylaTek participates in the DHS e-Verify program. KaylaTek also conducts a background check on all candidates post offer though PROScreening LLC.","$172,500 /yr (est.)",1 to 50 Employees,Company - Private,Government & Public Administration,National Agencies,#N/A,$1 to $5 million (USD)
"Google
4.4",4.4,"Omaha, NE","Data Center Engineer, Mechanical, Google Data Centers","Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Council Bluffs, IA, USA; Omaha, NE, USA.
Minimum qualifications:
Bachelor's degree in Engineering, related technical field, or equivalent practical experience.
5 years of experience in the design-build environment for mission critical facilities (e.g., data centers, power plants, industrial, etc).
Experience in estimating, mechanical design, operation and commissioning of central utility plants, water processing systems, air distribution systems, and PLC/SCADA controls systems.

Preferred qualifications:
Professional Engineering License.
Experience with project total cost of ownership (TCO).
Construction administration or construction management experience.
Experience with large-scale mission critical facilities' mechanical infrastructure systems.
About the job
Our thirst for technology is a part of everything we do. The Data Center Engineering team takes the physical design of our data centers into the future. Our lab mirrors a research and development department - cutting-edge strategies are born, tested and tested again. Along with a team of great minds, you take on complex topics like how we use power or how to run state-of-the-art, environmentally-friendly facilities. You're a visionary who optimizes for efficiencies and never stops seeking improvements - even small changes that can make a huge impact. You generate ideas, communicate recommendations to senior-level executives and drive implementation alongside facilities technicians.
In this role, you will have a primary focus on providing a deep technical understanding of Google’s data center design to field execution and operations teams in support of their initiatives. You will also support other teams in the development and evaluation of conceptual design.

Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.

The US base salary range for this full-time position is $136,000-$203,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities
Participate in the project specific design review process including conceptualizing ways to reduce total cost of ownership (TCO) while maintaining Google standards.
Coordinate with consulting engineers preparing construction documents as they develop detailed documentation based on the conceptual design standards developed and provided by others internally.
Work with the general contractor (GC) to develop a high level understanding of the design intent and on-time development of coordinated design details and delegated design elements in alignment with Google standards.
Monitor work in the field to ensure it is being executed in line with Google’s design intent and standards, as well as meeting the local codes and requirements.
Support systems startup and commissioning processes by providing a technical understanding of the gear being installed and how the systems are designed to function.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"Johns Hopkins Applied Physics Laboratory (APL)
4.2",4.2,"Laurel, MD",2024 PhD Graduate - AI/ML Data Scientist/Engineer - Analytic Capabilities,"Description

Are you searching for a place to build upon the foundation of your academic work?
Are you searching for engaging work with an employer that prioritizes impact, innovation, and personal development?
Are you motivated to apply your skills within a vibrant intellectual community?
If so, we're looking for someone like you to join our team at APL!
We are seeking recent college graduates to help us tackle the complex research, engineering, and analytical problems that present critical challenges to our nation. Our group is currently making critical contributions in the fight against online misinformation and development of the first truly autonomous UAV. Our work on the public health response to the COVID-19 pandemic was recognized by Time Magazine as one of the ""Best Inventions of 2020"". To address these emerging national challenges, we design and develop software systems that leverage the potential of data science, generative AI, large language models, and artificial intelligence across various domains, including social media analysis, healthcare, climate monitoring, cybersecurity, and signal & image processing.
As a member of our team you will...
Collaborate with dedicated colleagues in developing solutions that align with national priorities.
Harness your expertise in areas such as Artificial Intelligence, Machine Learning, Data Science, Cybersecurity, Software Engineering & DevOps, Signal and Image Processing, and Mathematics.


Qualifications

You meet our minimum qualifications for the job if you...
Have a PhD in Computer Science, Mathematics, Engineering, or related technical field.
Have maintained a minimum 3.0/4.0 GPA

Are able to obtain a Top Secret level security clearance. If selected, a government security clearance investigation will need to be conducted and the requirements met for access to classified information. Eligibility requirements include U.S. citizenship.

Why work at APL?
The Johns Hopkins University Applied Physics Laboratory (APL) brings world-class expertise to our nation’s most critical defense, security, space and science challenges. While we are dedicated to solving complex challenges and pioneering new technologies, what makes us truly outstanding is our culture. We offer a vibrant, welcoming atmosphere where you can bring your authentic self to work, continue to grow, and build strong connections with inspiring teammates.

At APL, we celebrate our differences and encourage creativity and bold, new ideas. Our employees enjoy generous benefits, including a robust education assistance program, unparalleled retirement contributions, and a healthy work/life balance. APL’s campus is located in the Baltimore-Washington metro area. Learn more about our career opportunities at www.jhuapl.edu/careers.


About Us

APL is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, sex, gender identity or expression, sexual orientation, national origin, age, physical or mental disability, genetic information, veteran status, occupation, marital or familial status, political opinion, personal appearance, or any other characteristic protected by applicable law.

APL is committed to promoting an innovative environment that embraces diversity, encourages creativity, and supports inclusion of new ideas. In doing so, we are committed to providing reasonable accommodation to individuals of all abilities, including those with disabilities. If you require a reasonable accommodation to participate in any part of the hiring process, please contact Accommodations@jhuapl.edu. Only by ensuring that everyone’s voice is heard are we empowered to be bold, do great things, and make the world a better place.","$101,464 /yr (est.)",5001 to 10000 Employees,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,1942,$1 to $5 billion (USD)
"Onebridge
3.9",3.9,"Indianapolis, IN",MDM Data Engineer,"Onebridge is a Consulting firm with an HQ in Indianapolis, and clients dispersed throughout the United States and beyond. We have an exciting opportunity for a highly skilled MDM Data Engineer to join an innovative and dynamic group of professionals at a company rated among the top “Best Places to Work” in Indianapolis since 2015.
This role could be a full-time position on our team – or we would be open to engaging a consultant seeking their next contract experience.
MDM Data Engineer | About You
As an MDM Data Engineer, you are responsible for organizing and executing a Data Enablement program through project planning activities, cross-system coordination, and completion of deliverables. You are comfortable working with a team of data professionals to establish data management best practices and deliver high-quality data and information at scale to a wide variety of clients and industries. You are a strategic thinker who understands the impact that data quality can have on advancing an organization's BI Maturity, and you find excitement in building enterprise solutions to achieve an integrated data strategy.

MDM Data Engineer | Day-to-Day

Engineer end-to-end MDM solutions, including integration patterns (with operational and analytic systems), workflows, policies, support, and reporting associated with an enterprise MDM capability.
Develop and refine approved data models for enterprise integration.
Establish and improve relevant standards and governance.
Develop Master Data Management (MDM) technology-enabled solutions that address the needs of clients, including the design, automation, and orchestration of enterprise Master and Reference Data.
Use data quality tools to profile, cleanse, standardize, and enrich data.
Analyze problems and opportunities and their impacts on the business by considering all fact-based and stakeholder information to evaluate alternatives.
Define and implement data strategy, policies, controls, and programs to ensure the enterprise data are accurate, complete, secure, and reliable.
MDM Data Engineer | Skills & Experience

7+ years of progressive experience in Master Data Management (MDM) solution design, development, and implementation, with additional expertise in Reference Data Management, Data Governance, Data Management, Analytics, and Technology.
Support and maintain the MDM architecture by understanding the interaction of business processes with data entities/elements and ensuring the integrity of the MDM system.
Expertise working in a complex matrixed environment.
Expert-level SQL Skills.
Possess the ability to solve, design, and lead the implementation of MDM platforms and individual components.
Deep understanding of bi-directional MDM and the role it plays in an effective Data Management Strategy.
Skilled in working with at least one modern MDM platform, with knowledge of best-in-class options.
100% Employee-Owned & a Best Place to Work in Indiana, since 2015.","$103,378 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,Unknown / Non-Applicable
"CAI
3.9",3.9,"Charlotte, NC","Mechanical Commissioning Engineer II, Data Center Services","CAI seeks Mechanical Commissioning Engineers with a minimum of two years' experience in Data Center Commissioning to support development and execution of all mechanical aspects of commissioning projects.

Position Description:
This position supports development and execution of all mechanical aspects of assigned commissioning projects from initial engagement, design reviews, checklists, safety support, script development, vendor coordination, testing and report development through turn over to the client. The Mechanical Commissioning Engineer will support the development of the mechanical test schedule, finalize mechanical test procedures, review project submittals for consistency with the design intent, basis of design and the owner’s project requirements, and maintain project cadence for the mechanical systems testing and associated Building Automation Systems. The Mechanical Commissioning Engineer is to support the planning and execution of commissioning for the mechanical infrastructure of the mission critical facility. They will be expected to execute against the project schedule through the coordination of contractors and/or vendors to complete the desired mechanical systems testing.
CAI DC Mechanical Commissioning Engineer will be exposed to cutting edge technologies in the Hyperscale and other spaces. You will have an opportunity to work with recognized subject matter experts allowing YOU to be a key player in bringing data technologies to market. As part of our company culture, we invest in YOUR future, and commit to hands on certifications as well as professional training. Our collaborative culture ensures that our customers benefit from exemplary work across our entire range of professional services.

Responsibilities:
Support and contribute to all aspects of safety for all mechanical tests.
Support complete commissioning and performance acceptance testing of the mechanical infrastructure systems.
Development of all mechanical test procedures, MOPS, SOO’s and checklists.
QA/QC of all mechanical test procedures.
Provide input and insight to the overall commissioning plan.
Develop reports for the mechanical testing and contribute to a daily report to the Commissioning Project Manager.
Attend and be an active participant of customer equipment Factory Witness Test
Assist with vendor coordination and management.
Perform equipment inspection to ensure build adherence to vendor submittal.
Provide test documentation that equipment is delivered, installed, and tested correctly and set to function properly for the customer.
Support and perform design specification review, manufacturer submittals, one line drawing sets, and project schedule documentation.
QA/QC of mechanical equipment installation\startup
Execute test scripts to confirm equipment and system operation to design specification.
Ensure safe work practices are followed by the commissioning team and customer site.
Engage with customers and vendors to ensure positive experience, goals achievement, and schedule adherence.
Provide daily status reports for mechanical commissioning team status.
Conduct facility walk downs, turnover, and punch list reviews.
General understanding of LEED specifications and requirements.
Look for new opportunities for CAI to provide service and value to customer.
Duties may be increased as experience and skill allow.

Requirements include:
Position Requirements:
Bachelor’s degree or equivalent experience
Minimum of 2 years Data Center Commissioning experience.
Knowledge of OSHA safety requirements.
Good written and verbal communication skills.
Ability to read and interpret mechanical drawings, P&ID’s and specifications.
Knowledge of mission critical design concepts.
Knowledge of various Building Automation/Monitoring Systems (BAS/BMS), Air Handlers, Humidifiers, Variable Refrigerant Flow, Computer Room Air Conditioners/Handlers (CRAC/CRAH), Evaporators, Adiabatic Coolers, Pressure/Temperature/Humidity sensors & Flowmeters.
Knowledge of basic thermodynamics and heat transfer and fluid flow.
Knowledge of the Test, Adjust and Balance (TAB) process.
Knowledge of mechanical trend analysis.
Strong experience with Word, Excel and PowerPoint. Can effectively create final products in all three programs.
Work under construction site conditions

Other Requirements:
Excellent oral and written English is required
Extensive travel may be required (75%)
Candidates must have a Passport or the ability to immediately get a Passport
Able to work in the US without sponsorship now or any time in the future.

About CAI
CAI is a 100% employee-owned company established in 1996, that has grown year over year to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and consulting services related to operational readiness to FDA regulated and other mission critical industries.

Meeting a Higher Standard
Our approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.
As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:
We act with integrity
We serve each other
We serve society
We work for our future

With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a can-do attitude. That is how we have grown exponentially.

Benefits
Our full-time positions offer competitive compensation and benefits which include: up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.
#LI-MR1
Average salary range, not including benefits or compensatory time and possible discretionary bonuses.
We are an equal opportunity employer; we are proud to employ veterans and promote a diverse culture in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.
This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the FCO.","$102,500 /yr (est.)",501 to 1000 Employees,Company - Private,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1996,$25 to $100 million (USD)
"American Business Solutions INC
3.8",3.8,"Columbus, OH",Data Engineer with Azure,"This position plays an important role in designing and constructing the agency’s data infrastructure using Microsoft Azure. This role will serve as the primary point of contact for the agency’s migration of its on-premises data warehouse and analysis workspace to Microsoft Azure.
The responsibilities and duties include:
Design and develop data infrastructure for the agency in Microsoft Azure
Recommend and implement solutions for data ingestion, ETL, data warehousing, and data analysis.
Manage access to data infrastructure datasets and analysis tools.
Develop budget for Microsoft Azure tools and provide recommendations on where to manage costs.
Build distributed computing analysis environment within Microsoft Azure in order to conduct more thorough analysis and integrate machine learning/AI tools to environment.
Design and develop database solutions using Microsoft SQL Server and Microsoft Azure tools (SSMS, SSRS, SSIS, Azure Data Factory, Azure Storage).
Manage data in variety of methods, to include SQL databases, NoSQL databases, file storage, and blob storage
Works with IT Architecture staff, CIO and/or IT Managers to design solutions that meet agency requirements
Design and implement high availability solutions
Data modeling to define and analyze data requirements for designing databases/data warehouses
Analyze on-premise database installations for Azure migration
Support data lake enterprise business initiatives
Support production and non-production environments incidents and requests
Code, test, debug, implement, and document data infrastructure design, construction, and remediation
Expert knowledge in SQL skills including stored procedure, trigger, index etc.
Experience with change management with respect to people, processes, and technologies
Develop, maintain, and support business applications (SQL/web-based apps)
Streamline and improve internal processes and reporting
Drive efficiency and operational improvement using data modeling techniques
Support and train users by providing directions, corrections, and enhancements; communicate with users to find solution to case
Analyze user requirements, procedures, and problems to provide coaching on system use, recommend changes and automation to improve efficiency
You’ll need the following qualifications and experience:
Bachelor’s degree in an appropriate field of study like Computer Science, Data Science, or Information Technology
Minimum seven years of database administration, data science, data engineering, and/or cloud-based data solution engineering.
Previous relevant experience with Microsoft suite of data solutions
Experience conducting performance tuning and configuration, creating data models, and managing data warehouses.
It’s a strong plus if you have:
Experience with Healthcare/Mental Health environment
Expertise in Python/R programming language
Familiar with reporting tools such as Power BI, Tableau, and Cognos
Collaborate with team leads to identify gaps and constraints associated with business requirements and processes and aid in providing solutions to resolve the process issues
Strong communication and interpersonal skills
Strong organization and time management skills
Ability to effectively handle multiple priorities
Ability to operate across the business and in different environments and cultures
Required/Desired Skills
SkillRequired/DesiredAmountof ExperienceBachelor’s degree in an appropriate fieldRequired0database administration, data science, data engineering, and/or cloud-based data solution engineeringRequired7YearsExpert knowledge in SQL skills including stored procedure, trigger, index etcRequired0Microsoft AzureRequired0Experience with Healthcare/Mental Health environmentNice to have0Expertise in Python/R programming languageNice to have0Familiar with reporting tools such as Power BI, Tableau, and CognosNice to have0
Job Type: Contract
Pay: $75.00 - $85.00 per hour
Experience level:
9 years
Schedule:
8 hour shift
Ability to commute/relocate:
Columbus, OH 43215: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 3 years (Preferred)
Data Engineering: 7 years (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person",$80.00 /hr (est.),51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,#N/A,$5 to $25 million (USD)
"BOEING
3.9",3.9,"Berkeley, MO",Phantom Works Systems Engineer and Data Architect (Experienced OR Lead),"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
Boeing Defense, Space, and Security (BDS) is seeking data architects to join a Digital Engineering team supporting a proprietary program developing next generation systems.

This is an exciting role to understand, architect and integrate data flows across the program lifecycle to create digital system models and digital twins of the as-designed, as-tested, as-built and as-operated product. In this role, you will apply an interdisciplinary, collaborative approach to plan, design, develop, integrate, and verify digital engineering solutions. We’re looking for data architects and integrators with interest and experience in model based engineering, who also have experience in one or more of the following areas: systems engineering, aircraft design, test, production, and product support. You will help build and mature the digital ecosystem, including: realizing the program data architecture, expanding digital threads, growing digital system models, connecting and controlling data, and enabling advanced data analytics.

Digital engineering is changing the way we execute our programs, collaborate with our customers and teammates, and enable advanced downstream capabilities.
Our teams are currently hiring for a broad range of experience levels including; Experienced or Lead Level Systems Engineers.
Primary Responsibilities:
Work across disciplines to model the data architecture of the program
Be the digital engineering focal to multiple aircraft design teams, production teams, verification/validation teams, and/or product support teams.
Develop and implement strategies to integrate data across multiple tools and technologies to create digital threads and enable digital twins.
Guide and coordinate development and deployment of new or revised processes in support of new computing systems, including documentation and training.
Define and validate complex requirements for new hardware and software systems.
Facilitate development of system integration strategies and architectures that promote use of common tools and processes.
Lead development of trade studies and other forms of analysis to formulate optimum solutions for users.
This position is expected to be 100% onsite. The selected candidate will be required to work onsite at one of the listed location options. (St. Louis or Huntsville)
This position requires an active U.S. Secret Security Clearance, for which the U.S. Government requires U.S. Citizenship. (A U.S. Security Clearance that has been active in the past 24 months is considered active)
Special Program Access or other Government Access Requirements are mandatory for this position.
Basic Qualifications (Required Skills and Experience):
A technical bachelor's degree with 5+ years, or MS/MA degree with 2+ years of relevant work experience, or a PhD degree with 1+ years of relevant work experience. A relevant degree is defined as one in a quantitative field such as Computer Science, Statistics, Mathematics, Computer Engineering, Software Engineering, Electrical Engineering, Aerospace Engineering, Physics, Chemistry, Operations Research, Bioinformatics, Economics, Computational Biology, or other technical degree.
Experience developing and documenting architecture using Cameo, or similar Model Based Systems Engineering (MBSE) tools
Ability to work effectively in a team environment and communicate with stakeholders of different backgrounds and skill levels
Preferred Qualifications (Desired Skills and Experience):
5 or more years' related work experience or an equivalent combination of education and experience
Experience with data modeling, ontology, and industry standards for data exchange
Experience with Siemens Product Lifecycle Management Suites
Prior experience in software development and test tools/IDEs (e.g. off the shelf or source code editors, compilers, configuration management tools, requirements management, and source control tools)
Experience in mechanical, structural, or electrical design
Experience with physics-based modeling tools
Experience with production engineering, future manufacturing systems, and/or supplier management
Experience with integration, verification, validation and/or flight test
Experience with product support, logistics, training systems, and/or maintenance systems
Typical Education and Experience:
Experienced Level 3:
Education/experience typically acquired through advanced technical education from an accredited course of study in engineering, computer science, mathematics, physics or chemistry (e.g. Bachelor) and typically 5 or more years' related work experience or an equivalent combination of education and experience (e.g. PhD, Master+3 years' related work experience). In the USA, ABET accreditation is the preferred, although not required, accreditation standard.
Lead Level 4:
Bachelor's degree and typically 9 or more years' experience in an engineering classification or a Master's degree with typically 7 or more years' experience in an engineering classification or a PhD degree with typically 4 or more years' experience in an engineering classification. Bachelor, Master or Doctorate of Science degree from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry. ABET is the preferred, although not required, accreditation standard.
Relocation:
This position offers relocation based on candidate eligibility.
Drug Free Workplace:
Boeing is a Drug Free Workplace where post offer applicants and employees are subject to testing for marijuana, cocaine, opioids, amphetamines, PCP, and alcohol when criteria is met as outlined in our policies
""At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.
The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.
The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.
Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations.
Summary pay range for Mid-Level 3 Berkeley MO: $97,750 - $132,480
Summary pay range for Lead Level 4 Berkeley MO: $119,850 - $162,150
Summary pay range for Mid-Level 3 Huntsville AL: $97,750 - $132,250
Summary pay range for Lead Level 4 Huntsville AL: $119,850 - $162,150

Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Equal Opportunity Employer:
Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.","$86,177 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1916,$10+ billion (USD)
"HCA Healthcare
3.3",3.3,"Nashville, TN",Principal Data Engineer,"Introduction
Last year our HCA Healthcare colleagues invested over 156,000 hours volunteering in our communities. As a Principal Data Engineer with HCA Healthcare you can be a part of an organization that is devoted to giving back!
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

Would you like to unlock your potential with a leading healthcare provider dedicated to the growth and development of our colleagues? Join the HCA Healthcare family! We will give you the tools and resources you need to succeed in our organization. We are looking for an enthusiastic Principal Data Engineer to help us reach our goals. Unlock your potential!
Job Summary and Qualifications
HCA Healthcare ITG
Job Summary:
The role requires working closely with others, frequently in a matrixed environment, and with little supervision. As a Principal Data Engineer/Architect level, the role requires 'self-starters' who are proficient in problem solving and capable of bringing clarity to complex situations. It requires contributing to strategic technical direction and system architecture approaches for individual projects and platform migrations. The culture of the organization places an emphasis on teamwork, so social and interpersonal skills are equally important as technical capability. Due to the emerging and fast-evolving nature of GCP/Big Data technology and practice, the position requires that one stay well-informed of technological advancements and be proficient at putting new innovations into effective practice.
Responsible for leading GCP development efforts, driving adoption and appropriate use of technology and consulting on internal and external development efforts to ensure code quality and sound architecture. This position that assumes the responsibility for project success and the upward development of team members technical skills. They are the development team's point of contact that must interface with business partners of varying roles ranging from technical staff to executive leadership. In addition, this candidate will have a history of increasing responsibility in a multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement cutting-edge technical data solutions with minimal supervision.
As a Principal Data Engineer/Architect, you will work closely with all team members to create a modular, scalable solution that addresses current needs, but will also serve as a foundation for future success. The position will be critical in building the team’s engineering practices in test driven development, continuous integration, and automated deployment and is a hands-on team member who actively coaches the team to solve complex problems. She / he will be responsible for the design, development, performance and support of the Cloud Platform components.
This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team (consultant and employee) environment. In addition, the applicant must be willing to train and mentor other developers to prepare them for assuming the responsibilities.
General Responsibilities:
Responsible for building and supporting a GCP/Hadoop-based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data.
Bring new data sources into GCP/HDFS, transform and load to databases.
Lead projects in delivering the data and projects on-time
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Leads efforts to design, development, deploy, and support software systems
Experience with HL7, FHIR, and Whistle mapping.
Collaborates with business analysts, project lead, management and customers on requirements
Participates in large-scale development projects involving multiple areas outside of core team
Designs fit-for-purpose products to ensure products align to the customer's strategic plans and technology road maps
Demonstrates deep understanding and coaches’ value-based decision making and Agile principles across teams
Coaches team on clinical data, existing system structure, constraints and deficiencies with product
Shares knowledge and experience to contribute to growth of overall team capabilities
Participates in the deployment, change, configuration, management, administration and maintenance of deployment process and systems
Work closely with management, architects and other teams to develop and implement the projects.
Actively participate in technical group discussions and adopt any new technologies to improve the development and operations.
Focuses on customer satisfaction
Rapidly prototypes and delivers just-in-time solutions
Gather requirements, designs, constructs and delivers solutions with minimal team interaction
Works in an environment with rapidly changing business requirements and priorities
Demonstrates deep understanding and acts as a leader in the team’s continuous integration and continuous delivery automation pipeline
Work collaboratively with Data Scientists, business, and IT leaders throughout the company to understand Cloud/Big Data needs and use cases.
Education, Experience and Certifications:
Bachelor's Degree in computer science or related field – Required
Master's Degree in computer science or related field – Preferred
3+ years of experience in Data Engineer – Required
1+ year(s) of experience in Healthcare – Preferred
10+ years of experience in Information Technology – Required
GCP Cloud Professional Data Architect certification – Preferred
GCP Cloud Professional Data Engineer certification – Preferred
Other Required Qualifications:
A successful candidate will have:

Strong understanding of best practices and standards for GCP application design and implementation.
Two Year of hands-on experience with GCP platform and experience with many of the following components:
GCS, Cloud Run, Cloud Functions
Bigtable, Cloud SQL
Kafka, Pub/Sub
Python, Golang, Spark, Scala or Java
BigQuery, Dataflow, Data Fusion
CICD process and Logging & Monitoring
OpenShift, Docker
Experience with Unstructured Data, Real-Time Streaming with GCP
Ability to multitask and to balance competing priorities.
Requires strong practical experience in agile application development, file systems management, and DevOps discipline and practice using short-cycle iterations to deliver continuous business value.
Knowledge of all facets of GCP Cloud ecosystem development including ideation, design, implementation, tuning, and operational support.
Ability to define and utilize best practice techniques and to impose order in a fast-changing environment. Must have strong problem-solving skills.
Strong verbal, written, and interpersonal skills, including a desire to work within a highly-matrixed, team-oriented environment.
A successful candidate may have:
Experience in Healthcare Domain
Experience in Patient Data
Experience with Natural Language Processing (NLP)
Azure/AWS Cloud experience
Hands-on experience with Cloudera Distributed Hadoop (CDH)
Hardware/Operating Systems:
Linux, UNIX
GCP
Distributed, highly-scalable processing environments
Databases:
NoSQL, Hbase, Cassandra, MongoDB, Cosmos, In-memory, Columnar, other emerging technologies
Build Systems – TFS, Github
Ability to integrate tools outside of the core Cloud ecosystem
Physical Demands/Working Conditions
Prolonged sitting or standing at computer workstation including use of mouse, keyboard, and monitor.
Requires ability to provide after-hours support.
Occasional Travel: The job may require travel from time- to-time, but not on a regular basis.
HCA Healthcare’s Information Technology Group (ITG) delivers healthcare IT products and services to HCA Healthcare's portfolio of business and partners, including Parallon, HealthTrust and Sarah Cannon.

For decades, ITG has been a pioneer in the industry, leading the transformation of healthcare into a new era of quality and connectivity. ITG relies on the breadth of the organization and depth of technical expertise to advance and enhance today’s healthcare and to enable our physicians and clinicians to provide world-class, innovative care for patients.

ITG employees rally around the noble cause of transforming healthcare through technology and find inspiration in the meaningful work they do—creating a culture that follows our mission statement which begins by saying “above all else we are committed to the care and improvement of human life.”

If you want a career in technology and have a heart for healthcare, apply your expertise to a mission that matters.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.
""There is so much good to do in the world and so many different ways to do it.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
Be a part of an organization that invests in you! We are reviewing applications for our Principal Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your application and help us raise the bar in patient care!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$120,425 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
"Wipro Limited
3.1",3.1,"Minneapolis, MN",Data Engineer - Apache Spark,"Overview:
About Wipro:
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.
A PROUD HISTORY OF OVER 75 YEARS
FY22 REVENUE 10.4 BN USD
WE’RE PRESENT IN 66 COUNTRIES
OVER 1,400 ACTIVE GLOBAL CLIENTS
Role – Data Engineer - Apache Spark
Location – Minneapolis, MN (Day 1 onsite)
Yrs. of experience – 10+ Yrs.
Mode of employment – Full-Time

Job Description:
Strong in Spark Scala development (Minimum 5 years of experience).
Especially Persons should have good experience on building ETL pipeline using Scala.
Strong in SQL Concepts and Development
Must have worked on any ETL tool like Data stage, Spark /Scala etc... Preferred Data Stage.
Unix / Python Shell Scripting (Minimum 3 to 4 years)
Strong understanding of Hadoop eco system
Very well versed with Agile Methodology - Scrum boards.
Capable of handling scrum ceremonies in absence of scrum master.
Other tools – Jenkin, Autosys, GitHub, etc..
Any Cloud experience is plus. Preferred Azure

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.

#LI-AK2","$96,774 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1945,$5 to $10 billion (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Jack In The Box
3.4",3.4,"San Diego, CA",Lead Data Engineer,"Jack in the Box is seeking a Lead Data Engineer who will be responsible to provide analytic and strategic technical leadership & support to the Enterprise Data Team, which is responsible for scaling and maintaining the core data platform and maturing the analytical capabilities of the organization. Contributes to data & engineering innovations facilitating critical business insights that fuel Jack in the Box Inc.s vision and mission.

KEY DUTIES/RESPONSIBILITIES:
Collaborates with functional & business leaders and teams and works closely with the Data Engineering team to manage complex data systems in enabling decision support and key insights across the organization.

Implements data governance practices in partnership with business stakeholders and peers.

Works with a team of high-performing analysts, data engineering professionals and cross-functional teams to identify business opportunities, monitor data platform performance and optimize analytical capabilities.

Builds, evolves and maintains the infrastructure required for optimal transformation and integration from a wide variety of data sources using appropriate data integration technologies. Deploys pipelines using scheduling and orchestration frameworks to support the organizations growing data processing and analytics needs.

Takes ownership of core data pipelines that power the organizations analytical metrics.

Uses data expertise to evolve data models in several components of the data stack & helps architect, build, and launch scalable data pipelines to support the organizations growing data processing and analytics needs.

Creates proof of concepts per business requirements.


Bachelors degree in Engineering, Computer Science, Information Systems or related field.

12+ years staff/lead/senior software data engineer experience building and supporting data intensive applications, tackling challenging architectural, scalability and reliability problems. Experience includes working with Data Warehouse, Data Lake, Data Hub and the supporting processes (Data Integration, Governance, Metadata Management).


Skilled in building and maintaining data quality frameworks, data observability and monitoring frameworks.

Experience in leveraging Observability tools such as Splunk/Datadog/New Relic/MonteCarlo or equivalent.

Extensive experience manipulating and analyzing large data sets.

Experience designing, deploying, and maintaining business application on AWS stack, leveraging services such as EC2, ECS, Lambdas, AWS Step functions, Redshift, Tableau, AWS Glue OR equivalent expertise in other cloud platforms such as Azure, GCP etc. Experience with on-prem & relational platforms Oracle, SQL Server, PostGres , MySQL etc. Integration of cloud services with on premise technologies.

Experience working with DevOps capabilities like version control, automated builds, testing and release management capabilities using tools like Git, Jenkins etc.

Extensive knowledge in application monitoring, handling user tickets, analyzing data issues.

Experience with data modeling, data mining, and predictive analysis. Ability to effectively test and document work.

Possesses excellent interpersonal, communication, and problem solving skills.

Ability to juggle multiple projects, tasks, and deadlines.

Strong understanding of SQL and NOSQL database concepts.

Strong experience with advanced analytics tools for Object-oriented/scripting languages such as R, Python, Java, Scala, or others.

Comfortable working in an unstructured environment, taking ownership for results and self-directing your efforts to the subject areas and questions which have the greatest potential impact on the business. Comfortable working in an agile environment

Proven track record of being personally accountable for the analysis and technical enhancements that drive a business at a large scale.

Skilled in building reports and dashboards through the use of dashboarding tools like Tableau, PowerBI, Quicksight, Looker.

Will be a self-starter, initiate and drive projects to completion with minimal guidance.


Ability to speak/hear clearly in person and on the telephone and ability to operate a computer (desktop, tablet, etc.).


Jack in the Box, Inc. and its affiliates will make reasonable accommodations to allow a qualified individual with a disability to enjoy equal employment opportunities and to perform the essential functions of the job. This position description should be applied accordingly. This description of duties is not intended to be all-inclusive or to limit managements discretion to assign other duties or responsibilities as necessary.

Jack in the Box Inc. offers a competitive salary and Total Rewards package that includes: medical, dental, vision, Health Savings Account (HSA), Flexible Spending Account (FSA), Life and Disability Plans, 401(k) plan with company match, Legal Plan, Pet Insurance, Tuition Reimbursement, and Employee Assistance Program.

Our culture is fun and innovative Work Happy with us!

The range for this position is $149,700 - $208,500 and is based on an employee located at our corporate headquarters in San Diego. If the candidate is hired in a different city to work remote, we will apply a geographic pay differential based on the cost of labor in the market in which the employee resides.

Jack In The Box
9357 Spectrum Center Blvd. San Diego, CA - 92123
Jack in the Box Corporate
XX9101","$153,458 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1951,$1 to $5 billion (USD)
"Geopaqlogic Staffing
4.7",4.7,"Ridgefield Park, Bergen, NJ",Data Engineer (W2 only),"Position: Data Engineer
Work Location: Ridgefield Park, NJ (Hybrid - Need to be visit only once in a month)
Contract period: 6+ months (W2 only)
Note: Must have experience in GCP (Google Cloud Platform) and/or Spark
SUMMARY OF ESSENTIAL JOB FUNCTIONS:
· Design and develop analytical models and be the face to the data consumers
· Perform data curation to meet the business requirements
· Build batch and streaming data pipelines
· Develop processes for automating, testing, and deploying your work
· Identify risks and opportunities of potential logic and data issues within the data environment
· Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUM RETIREMENTS:
· Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
· Must have experience in GCP (Google Cloud Platform) and/or Spark
· 3+ years of experience as Data Engineer or in a similar role
· Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
· Cloud to Cloud migration experience preferred
· Strong PySpark skill is a must have
· Have knowledge of data management fundamentals and data storage principles
· Have knowledge of systems as it pertains to data storage and computing
· Strong source to target mapping experience and ETL principles/knowledge
· Excellent verbal and written communication skills.
· Strong quantitative and analytical skills with accuracy and attention to detail
· Ability to work well independently with minimal supervision and can manage multiple priorities
Job Type: Contract
Pay: $60.00 - $70.00 per hour
Benefits:
Health insurance
Paid time off
Ability to commute/relocate:
Ridgefield Park, NJ 07660: Reliably commute or planning to relocate before starting work (Required)
Experience:
Data Engineering: 5 years (Preferred)
Software development: 5 years (Preferred)
Business intelligence: 3 years (Preferred)
GCP (Google Cloud Platform: 3 years (Preferred)
Pyspark: 5 years (Preferred)
Work Location: In person",$65.00 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2014,$1 to $5 million (USD)
"Oracle
3.9",3.9,"Seattle, WA",Senior Software Engineer (Join OCI: Horizon Data Warehouse team),"As a Senior Software Engineer on the Horizon Data warehouse team, you will help our development efforts as we build the technology platform that will act as the central data platform inside OCI for 100's of teams. You will be a core contributor on a team of software engineers working to grow and scale our service.

Basic Qualifications
4+ years of experience in the design and implementation of complex software systems
Strong Knowledge of Data Warehousing, ETL processes, Cloud Computing and Data Security concepts is a must.
Proven experience with a Programming language PLSQL is a must.
Sound fundamentals in coding, algorithm design, problem solving, and complexity analysis.
Proven experience with a major Programming language such as Java, Python, Go, C# or C++ is a plus.
Aptitude for problem solving.
Experience with massively scalable systems is a plus.
Experience with Cloud Platforms such as OCI, AWS, Azure or GCP is a plus.
Experience with enterprise-class RDBMS (Oracle, SQL*server), Cloud Data warehouse (Snowflake/Redshift).
Preferred Qualifications
Experience building distributed cloud services.","$146,533 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,"$112,206 /yr (est.)",1001 to 5000 Employees,Company - Private,Management & Consulting,Business Consulting,1961,$100 to $500 million (USD)
"Intellibus
4.6",4.6,"Newark, NJ",Sr. Data Engineer — Snowflake,"Are you a Data Engineer working at a Large Financial Institution and being told by your leadership that you are too hands-on or detail-oriented or think and work like a start-up?
Imagine working at Intellibus to engineer platforms that impact billions of lives around the world. With your passion and focus we will accomplish great things together!
We are looking forward to you joining our Platform Engineering Team.
Our Platform Engineering Team is working to solve the Multiplicity Problem. We are trusted by some of the most reputable and established FinTech Firms. Recently, our team has spearheaded the Conversion & Go Live of apps that support the backbone of the Financial Trading Industry.
We are looking for Engineers who can
Create Data modeling
Work on Snowflake modeling – roles, databases, schemas, ETL toolswith cloud-driven skills
Work on SQL performance measuring, query tuning, and database tuning
Handle SQL language and cloud-based technologies
Set up the RBAC model at the infra and data level.
Work on Data Masking / Encryption / Tokenization, Data Wrangling / ECreLT / Data Pipeline orchestration (tasks).
Setup AWS S3/EC2, Configure External stages and SQS/SNS
Perform Data Integration e.g. MSK Kafka connect and other partners like Delta lake (data bricks)
We work closely with
Data Wrangling
ETL
Talend
Jasper
Java
Python
Unix
AWS
Data Warehousing
Data Modeling
Database Migration
ECreLT
RBAC model
Data migration
Our Process
Schedule a 15 min Video Call with someone from our Team
4 Proctored GQ Tests (< 2 hours)
30-45 min Final Video Interview
Receive Job Offer
If you are interested in reaching out to us, please apply and our team will contact you within the hour.
Job Type: Full-time
Pay: $60.00 - $80.00 per hour
Schedule:
Monday to Friday
Experience:
Data Wrangling: 7 years (Preferred)
Snowflake: 7 years (Preferred)
ETL: 7 years (Preferred)
Work Location: In person",$70.00 /hr (est.),Unknown,Unknown,Information Technology,Information Technology Support Services,2015,Unknown / Non-Applicable
Bonsai Robotics,#N/A,"San Jose, CA",Senior ML Ops Engineer - Data,"Job Overview:

We are seeking a highly skilled Sr. ML Ops engineer to join our team. As a ML ops engineer, you will develop, implement, and optimize our custom data pipelines for our ML systems. You should have a strong background in any of the following technologies: Databases(SQL, MongoDb), Cloud frameworks (AWS) and ML Frameworks (Pytorch/tensorflow). The ideal candidate will be proficient in programming languages such as C++ and Python.
About Bonsai:
Bonsai Robotics' mission is to create the next leap forward in agriculture equipment efficiency by creating a new ecosystem of semi-autonomous robotic machinery. Orchards are dusty, hazard-filled, and GPS-denied. The GPS-based autosteer features that have driven row crop efficiencies cannot function in orchards. Our vision, AI, and machine control systems offer human-level environment understanding and local navigation capabilities and will be the platform for a new wave of innovation in agricultural production and management systems.
We simultaneously solve twin crises impacting nut growers and most of specialty agriculture: there is not enough human labor when you need it, and operational expenses are growing dramatically. Our state-of-the-art technology empowers orchard managers to optimize their operations, dramatically reduce operational expenses, and increase profitability. We are pursuing a Bonsai Inside strategy, and partnering with the largest orchard Original Equipment Manufacturers (OEMs) in the retrofitting of existing machines and design of new form factors.
Key Responsibilities:
Develop, implement, and optimize data pipelines for ML systems.
Collaborate with cross-functional teams to store, process and certify petabytes of Image+Video data.
Coordinate with 3rd parties to handle labeling pipelines.
Create and maintain code documentation and unit tests.
Collaborate with ML scientists and provide data insights
Qualifications:
Bachelor's or Master's degree in Computer Science, Robotics, Electrical Engineering or related field
Strong background in most of the following technologies: Backend engineering, Data engineering, Databases, Dev Ops
Expert in Creating ETL pipelines
Proficiency in programming languages such as C++ and Python
Strong problem-solving skills and ability to work in a fast-paced environment.
Strong verbal and written communication skills.
Bonus: Experience with Pytorch and Ros 2
If you have a passion for computer vision, robotics, and developing innovative technology solutions, we encourage you to apply for this exciting opportunity. Bonsai Robotics values diversity, inclusivity, and excellence in hiring and strongly encourages candidates from traditionally underrepresented backgrounds to apply.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Allata LLC
4.3",4.3,Remote,Data Architect/Lead Engineer - Consulting (Remote Possible),"Allata is growing our Data & Analytics Practice to serve our clients nationwide. Our data architect / lead engineer practitioners will be collaborating with data engineers, machine learning engineers, analysts, data scientists, and other Allata employees and client teams on projects for companies across the United States.
WHAT YOU'LL BE DOING
Work with customers to build cloud-based data platforms, including integration, data storage and analytics
Develop innovative architectures to solve complex business problems utilizing the latest cloud technologies
WHAT YOU'LL NEED
Data Architecture Best Practices. You’ve successfully built data solutions that use industry best practices and fit with an organization’s needs. You are excited by solving problems and voraciously consume technology to do so. You have a broad and deep technical background
Communication. You have a natural charisma and use it to build consensus. You can have a conversation with developers, business analysts, managers of all levels, and individuals in a business function. You are comfortable presenting in front of groups and explaining architectures in a variety of levels of detail.
Make teams better. You're excited to be part of a team that delivers with quality and works hard on new opportunities. You work well in fast-moving environments and have no problem working with others to resolve difficult problems. You support teams as much as others supports you.
DESIRED SKILLS & EXPERIENCE
8-10 years of experience in a data related field
Experience building data storage and analytic solutions utilizing Snowflake
Expertise in building data platforms in Azure or AWS
Experienced with ETL tools such as Azure Data Factory, AWS Glue, WhereScape RED, Streamsets, Informatica and SAP Convergent Mediation
Experience in one or more Cloud Data Warehouse (Azure SQL Data Warehouse / Synapse Analytics, Snowflake, Amazon Redshift, Google BigQuery)
Experience in one or more Data Visualization tool (Tableau, PowerBI)
Expertise modeling architectures and integrations for data environments including data pipelines, data lakes, data warehouses, and data marts.
Experience with data backup and recovery strategies, optimization of clusters, structured/semi structured data, and changing database storage and utilization requirements
Experience with scripting languages such as Python / R for Business
Experience with Event Driven Architecture (Kafka)
Experience with large-scale distributed storage and database systems (e.g. SQL, NoSQL, MySQL, Cassandra)
At Allata, we value differences.
Allata is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.
Allata makes employment determinations without regard to race, color, creed, religion, age, ancestry, national origin, veteran status, sex, sexual orientation, gender, gender identity, gender expression, marital status, disability, or any other legally protected category.
This policy applies to all terms and conditions of employment, including but not limited to, recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",#N/A,51 to 200 Employees,Company - Private,Information Technology,Software Development,2016,$25 to $100 million (USD)
"RSA
4.0",4.0,"Overland Park, KS",Archer Business Enablement Data Engineer,"Business Enablement Data Engineer
Archer Technologies, LLC is the 25-year unseated market leader of integrated risk management (IRM) SaaS platforms that enable customers to improve strategic decision-making and operational resilience with a modern technology platform that supports qualitative and quantitative analysis driven by both business and IT impacts. As true pioneers in ERM, compliance, audit and cyber risk, Archer’s 800 employees are solely dedicated to helping customers manage risk and compliance programs, from traditional audits to emerging issues such as ESG. With over 25 years in the risk management industry, the Archer customer base represents one of the largest pure risk user communities globally, with more than 1,300 customers including more than 50% of the Fortune 500. Learn more at www.ArcherIRM.com.
The primary focus of the Business Enablement Data Engineer is to provide technical expertise with the creation and maintenance of Archer’s Global Data Lakehouse. This role will execute on complex analytics to help drive business decisions across a wide variety of often fast-paced internal engagements. The Data Engineer role will build innovative tools and applications that can help solve Archer’s internal data issues, help execute cutting-edge analytical techniques, help drive technical roadmaps for the function and firm, and train our colleagues.
Responsibilities:
Assist with creating, defining, and driving data engineering solutions to meet functional business requirements.
Data engineering needs can include Data aggregation/creation, data cleaning/manipulation, data science (e.g., geospatial, machine
learning, predictive modeling, etc.), and visualizations.
Solve various complex analytical challenges, sometimes dynamically balancing multiple internal projects simultaneously.
Supporting project teams with their analytics work in a “consultancy/expert” capacity on best practices concerning data & analytics
engineering (e.g., on-prem databases & systems, data storage & warehousing, data management, big-data principles, analytics app
prototyping, ETL)
Develop and drive the data engineering roadmap needed to support the business.
Collaborate with various stakeholders to continuously innovate on the tools, services, and data assets we can offer.
Serve as the lead technical expert and thought leader in helping to innovate and develop offerings that require / benefit from advanced
analytics skills or capabilities.
Provide technical expertise and thought leadership on developing analytical tools, services, and data assets and contribute to building
these areas directly when applicable.
Create production-quality data pipelines to develop and deploy scalable data science projects.
Stay current on best-in-class software, tools, and techniques to ensure we can provide best-in-class solutions.
Support development and upskilling of staff on relevant software, tools, and techniques
Develop and drive the technical roadmap on data engineering capabilities and infrastructure to ensure we operate a best-in-class Data
& Analytics function.
Qualifications:
Degree in a quantitative or business discipline or previous business experience preferred; examples include: Computer Science,
Engineering, Information Technology, Data Science, Statistics, Mathematics, Operations Research, Economics
Minimum 5 years of experience in applied data engineering; deep expertise in data engineering, as well as strong business and
strategic analytical skills
Ability to understand and articulate requirements to/from technical and non-technical audiences working alongside a data science &
engineering team.
Strong SQL & Python knowledge and familiarity with Big Data tools such as Spark & Scala; familiarity with Alteryx and Tableau
Experience with data modeling, data structures (e.g., relational, and non-relational data), databases, and ETL/ELT processes and an in depth understanding of large-scale data sets including both structured and unstructured data.
Experience with designing, implementing, and delivering scalable data solutions and pipelines on one of the cloud platforms (e.g., AWS,
Azure, GCP) and on-prem platforms such as Microsoft SQL Server
Experience with building and deploying proprietary cloud-based analytics web apps.
Hands-on experience in the development, deployment, and operation of integration technologies (e.g., APIs)
Proficiency with data warehouses (e.g., Snowflake, Teradata, Redshift, Hadoop, BigQuery, etc.)
Experience with containerization technologies (e.g., Docker, Kubernetes)
Experience with DevOps, Git, CI/CD
Experience directly managing another individual or a team.
Prior experience in Strategic Data Consulting is preferred.

Archer is committed to the principle of equal employment opportunity for all employees and applicants for employment and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Archer are based on business needs, job requirements and individual qualifications, without regard to race, color, religion, national origin, sex (including pregnancy), age, disability, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, protected veteran status, genetic information, or any other characteristic protected by federal, state or local laws. Archer will not tolerate discrimination or harassment based on any of these characteristics. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. All Archer employees are expected to support this policy and contribute to an environment of equal opportunity.
If you need a reasonable accommodation during the application process, please contact talent-acquisition@archerirm.com. All employees must be legally authorized to work in the US. Archer participates in E-Verify. Archer and its approved consultants will never ask you for a fee to process or consider your application for a career with Archer. Archer reserves the right to amend or withdraw any job posting at any time, including prior to the advertised closing date.","$86,978 /yr (est.)",5001 to 10000 Employees,Company - Public,Insurance,Insurance Carriers,1710,$10+ billion (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"AnaVation
4.9",4.9,"Chantilly, VA",Senior Full Stack Data Engineer - REMOTE!,"Be Challenged and Make a Difference

In a world of technology, people make the difference. We believe if we invest in great people, then great things will happen. At AnaVation, we provide unmatched value to our customers and employees through innovative solutions and an engaging culture.

Description of Task to be Performed:
AnaVation is looking for a talented Full Stack Data Engineer who is passionate about technology and working with customers and a strong team to provide solutions for our mission-critical customer. The ideal candidate appreciates partnering with our customer and team of engineers to create innovative engineering solutions. The selected candidate will work with a small group of developers building a Cyber data lake. If you are looking to be challenged, then this is the environment for you. This position supports 80% remote work with up to one day per week in our Chantilly, VA office. The candidate will be required to pass a high-risk public trust background investigation.

Position Responsibilities:
Develop tools and processes to ingest Cyber data into an enterprise data lake.
Make recommendations on standards for a common Cyber data model and standards for harmonization of common data elements on data ingest.
Develop and evaluate tools to search, analyze, discover, and otherwise exploit data in the data lake to support investigative operations.
Required Qualifications:
5 or more years of relational database design and development (PostgreSQL, Oracle, Microsoft SQL Server)
5 or more years of ETL/ELT development experience · 2 or more years with Linux environment experience
2 or more years’ experience with shell scripting
Experience implementing data access controls
Experience analyzing unstructured, structured, and semi-structured data
Strong technical and computational skills, coupled with the ability relate data to use cases, mission requirements, and end-user experience
Experience with development in one or more programming or scripting languages (Java/Python/Go)
Active Secret Clearance or High Risk Public Trust Suitability
Bachelor’s degree in Computer Science, Information Systems or related discipline
Preferred Qualifications:
Experience with PostgreSQL
Experience with cloud data solutions such as AWS RedShift, AWS DynamoDB and Azure Cosmos DB
Experience with search technologies such as Elasticsearch, AWS Opensearch, Azure Cognitive search, SOLR, etc
Experience with Databricks, Azure Syanpse, or Apache Spark
Experience with cloud concepts and big data architectures such as Hadoop, Kafka, etc.
Knowledge of Continuous Integration/Continuous Delivery tools and practices
Experience with cloud platforms such as AWS and Azure
Experience working in Agile Environments
Experience with DevOps toolsets
Familiarity with containerization (Docker, Containerd, Kubernetes, etc.)
Experience with microservices
Benefits
Generous cost sharing for medical insurance for the employee and dependents
100% company paid dental insurance for employees and dependents
100% company paid long-term and short term disability insurance
100% company paid vision insurance for employees and dependents
401k plan with generous match and 100% immediate vesting
Competitive Pay
Generous paid leave and holiday package
Tuition and training reimbursement
Life and AD&D Insurance

About AnaVation
AnaVation is the leader in solving the most complex technical challenges for collection and processing in the U.S. Federal Intelligence Community. We are a US owned company headquartered in Chantilly, Virginia. We deliver groundbreaking research with advanced software and systems engineering that provides an information advantage to contribute to the mission and operational success of our customers. We offer complex challenges, a top-notch work environment, and a world-class, collaborative team.

If you want to grow your career and make a difference while doing it, AnaVation is the perfect fit for you!","$97,431 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2013,$5 to $25 million (USD)
"Atkore
4.0",4.0,"Harvey, IL",Applications Engineer - Data Center Containment,"Applications Engineer
Who we are:
Atkore is forging a future where our employees, customers, suppliers, shareholders, and communities are building better together – a future focused on serving the customer and powering and protecting the world.
With a global network of manufacturing and distribution facilities, Atkore is a leading provider of electrical, safety and infrastructure solutions.

Who we are looking for:
We are currently looking for an Applications Engineer. You will manage and be the go-between for owner’s needs, building requirements and our factory delivered solutions by working closely with General Contractors, Mechanical and Electrical contractors, and system integrators across a wide range of sites for hyperscale, colocation, and retail providers in the space. You will be supported by a full commercial, estimating, factory engineering team delivering product from our owned manufacturing plant(s) in the USA.

What you’ll do:
Serve the customer’s needs as a critical member of our team to help support the launch of Atkore’s data center containment solution.
Work closely with Director of Sales to become the application expert to identify current and future customer needs and help the customer find appropriate solutions for customer applications whilst promoting Atkore portfolio.
Coordinate with our project management team and walk job sites (as required) to understand site conditions.
Coordinate with our factories to ensure critical to build issues are addressed including documenting technical requirements for both domestic and overseas project plans and project changes.
Examine and interpret blueprints/plans/drawings to find containment opportunities and coordinate requirements to the estimating team.
Lead the design and installation of our containment solutions to exceed customer expectations including developing installation manuals and on-site assistance to Unistrut Construction team during installation.
Maintain and update our technical library, including CAD models, drawings, specifications, test data, etc.
Support our Regional Sales Managers (RSM) team with client proposals and technical presentations.
Establish and build strong trusting relationships with key stakeholders and provide unmatched quality, delivery, and value.
Travel requirements are 15-25% of the time

What you’ll bring:
5+ years of hands-on field experience in applications engineering, engaging with the customer through the requirements definition, generating a concept and proposal through the delivery and installation of the solution
A history of building and maintaining customer relationships, preferably in the data center market.
Possess a technical aptitude and comfort in understanding blueprints and specifications.
High energy and integrity, strong team player, exceptional work ethic, and a history of proven sound decision making.
Ability to think strategically and develop long term goals
Engineering degree or relevant experience.
Autodesk Inventor, Microsoft Office Suite, CRM Tool experience
Word, Excel, PPT, and CRM tool experience.

Within 3 months, you’ll:
Complete Atkore’s immersion program to understand our mission, vision, values, business processes, products, people, and our culture.
Learn about our manufacturing, operations, and field installation teams capabilities for containment.
Understand how your role works closely with the sales, operations, and installation teams and contributes to Atkore’s overall strategy.
Gain buy-in with Unistrut Construction stakeholders that help support our sales objectives.
Develop a submittal and design process to work collaboratively with RSMs to improve our value and conversion rate.
Understand our value proposition and incorporate added value into the containment design.
Within 6-months, you’ll:
Become familiar with the design, build, and installation of Atkore’s containment solution
Create strong relationships with executives, key stakeholders, and strong influencers.
Use Autodesk Inventor to update, maintain and distribute technical and manufacturing drawings.
Develop bespoke installation manuals for each application
Provide on-site assistance to optimize installation efficiencies in support of client schedule.
Identify other resources needed to scale our business.
Within 12-months, you’ll:
Become the Atkore containment subject matter expert and make recommendations to improve the program
Proficient at reading drawings, specifications, and blueprints for data centers.
Take the lead as the conduit between sales and operations, working with the Manufacturing Engineers on delivery and installation to keep customers’ project on schedule.
Collaborate with the Global Director of Product Management, Global Director of Product Engineering on various projects and tasks related to new product development.
Assist Director of Sales with every data center containment internal scope review and external scope review with customers.
Build enough demand to recruit, hire, and train teammates.

Atkore is a recipient of a Great Place to Work© certification and a Top Workplaces USA award! We’re committed to creating an engaged and aligned workforce that drives collaborative culture. Our team strives for breakthrough results, stays focused on being standout leaders, and fully supports decisions of the Company. We consistently live the Atkore mission, strategic priorities, and behaviors, all in a way that’s consistent with our core values. Together, we build strong leaders that continually endeavor to move us forward.
Join our team and align yourself with an industry leader!
#LI-ET1
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$82,585 /yr (est.)",1001 to 5000 Employees,Company - Public,Manufacturing,Machinery Manufacturing,2010,$1 to $5 billion (USD)
"84.51°
4.3",4.3,"Cincinnati, OH",Senior Data Engineer (P996),"84.51° Overview:
84.51° is a retail data science, insights and media company. We help the Kroger company, consumer packaged goods companies, agencies, publishers and affiliated partners create more personalized and valuable experiences for shoppers across the path to purchase.
Powered by cutting edge science, we leverage 1st party retail data from nearly 1 of 2 US households and 2BN+ transactions to fuel a more customer-centric journey utilizing 84.51° Insights, 84.51° Loyalty Marketing and our retail media advertising solution, Kroger Precision Marketing.
Join us at 84.51°!
__________________________________________________________

As a member of our engineering team, you will use various cutting-edge technologies to develop applications that turn our data into actionable insights used to personalize the customer experience for shoppers at Kroger. We also work with Kroger's supply chain related data assets including but not limited to: Orders and Shipments, Inventory, Planogram and Pricing information to help Kroger, CPG and broker clients make tactical and strategic business decisions. We use agile development methodology bringing everyone into the planning process to build scalable enterprise applications and solutions.
What you'll do
Work within a team that owns the Semantic Layer of a large commercial reporting application.
Create and maintain complex retail customer loyalty measures and commercial data security rules.
Use strong business analysis skills to translate commercial requirements into technical requirements.
Use strong Data Warehouse and BI Tool background and understanding of every layer of the technical stack in order to convert requirements into platform wide implementation solutions.
Work with the team to implement the semantic layer portion of those solutions using a BI Tool framework.
Develop custom engineering tools to assist with the implementation, automation, and testing of the solution to reduce time to market for new Insights capabilities.
Responsibilities
Participate in design and development of highly visible data solutions
Support Commercial Facing data pipelines
Perform unit and integration testing
Collaborate with architecture and lead engineers to ensure consistent development practices
Participate in retrospective reviews
Participate in the estimation process for new work and releases
Collaborate with other engineers to solve and bring new perspectives to complex problems
Drive improvements in people, practices, and procedures
Embrace new technologies and an ever-changing environment
Requirements
3+ years proven ability of professional Data Development experience
Experience with a Business Intelligence Reporting Tool
Full understanding of ETL concepts and Data Warehousing concepts
Proficient with Relational Data Modeling
Thorough understanding of CI/CD concepts and best practices
Comprehensive Understanding of ANSI SQL
Foundational Understanding of Cloud Processing Concepts
Foundational Understanding of Agile Principles
Exposure to Retail Business Intelligence
Exposure to interacting with , enhancing and creating Cloud based services
Passion for Problem Solving
Passion for creating supportable technical solutions
Experience communicating to and with functional colleagues
Preferred Skills
dbt
Python
Python FAST API framework
Power BI
Snowflake
Alation
Microsoft Azure
MongoDB
Oracle
#LI-Remote #LI-DOLF","$84,414 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2015,Unknown / Non-Applicable
"Peraton
3.6",3.6,"Pacific, MO",Data Engineer – DoD TS/SCI – Camp Humphrey – Korea,"Responsibilities:
Peraton is seeking a Data Engineer, in support of a US Government client at Camp Humphrey in South Korea, who can leverage experience and expertise in data exploration, engineering, and ETL to architect, develop, and deploy scripts for processing structured and unstructured data into usable data formats for long term storage, search, and analysis
The successful Data Engineer candidate will work with a diverse team of data scientists, social scientists, cultural advisors, operations research systems analysts (ORSAs), and Irregular Warfare (IW) planners to translate empirical research findings into operational assessments.
The Data Engineer will be responsible for developing user interfaces, data extraction and transformation to improve data reliability, quality and utility.
The candidate should also be comfortable working with military IRC planners to break down and synthesize data in a fashion that best informs plans and operations.
Roles and responsibilities for this position include:
Utilize your experience with AWS, Azure, or Google Cloud
Creating a custom ingest pipeline to a Big Data platform with consistent performance and scalability
Understanding programming and data engineering concepts and best practice
Experience working with both structured, semi-structured, and unstructured data to include data parsing, transformation, schema definition, and query/analysis
Ability to manage and organize data while identifying trends and inconsistencies that will impact downstream analytics
Experience with data pipelines or be willing to learn a pipeline from bottom to top
Be able to troubleshoot files against an architecture to see where the upload process is failing
Be able to understand unit tests and add to them to increase stability to the entire pipeline
Be prepared to use GIT, Anaconda, Spyder, and Microsoft tools
Be prepared to express ideas and solutions and walk together with teammates through coding challenges
Qualifications:
Basic Qualifications:
Bachelor of Science in computer programming, mathematics or a related degree with 8-10 years of experience, 6-8 yrs. with a Master’s Degree
Demonstrated experience applying data engineering and software development expertise
Work / research history demonstrating applied experience with programming languages such as Python, SQL, Java, etc. with Linux OS (Ubuntu, CentOS, Red Hat), and Windows environments
Ability to work both independently and collaboratively with high levels of curiosity, creativity, and problem-solving capabilities
Strong written and verbal communication skills
Experience building ETL pipeline architectures and AWS, architectures with experience with ETL tools such as NiFi or Informatica
Must be willing and able to travel within the CCMD area of responsibility as required by the program.
Must be a U.S. Citizen with Current US Passport
Current DoD Top Secret clearance with SCI eligibility

Preferred Qualifications and Training:
A graduate degree in computer programming / science, mathematics, or related degree and 10 years of experience
AWS certifications such as AWS solutions architect or developer
Cyber security certifications
Statistical package expertise in programs such as IBM SPSS/PASW, R, STATA or MS Excel statistics
Experience applying data science to address defense or social science issues
Experience using geospatial analytic package (e.g., ArcGIS, QGIS, etc.)
Joint intelligence or operational assessment experience with Combatant Commands
Peraton Overview:
Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world’s leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can’t be done, solving the most daunting challenges facing our customers.
Target Salary Range: $146,000 - $234,000. This represents the typical salary range for this position based on experience and other factors. EEO: An Equal Opportunity Employer including Disability/Veteran.","$190,000 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $10 billion (USD)
"Gentiva
3.3",3.3,"Mooresville, NC",Business Intelligence Developer / Data Engineer,"Our Company:

Gentiva is an industry leader in hospice, palliative and personal home care. Our place is by the side of those who need us, offering physical, spiritual and emotional support to patients and their families so they may make the most of every moment. We believe that better care for caregivers and clinicians means better care for everyone, so we offer ongoing professional training, lower nurse-to-patient ratios, and comprehensive benefits for eligible employees. Here, you’ll join gifted colleagues who make a lasting difference in people’s lives every day.

Overview:
We are looking for a remote Business Intelligence Developer / Data Engineer to join our team. This position reports to the Director Business Intelligence and Data Services and is responsible for developing, deploying, and maintaining BI interfaces. Those include query tools, data visualizations and interactive dashboards, ad hoc reporting, and data modeling.
Transform business requirements into technical specifications
Design and develop ETL processes to move/load data to/from various locations including files systems, ftp sites, and data bases
Define and develop internal teams’ Service Delivery KPIs dashboards to improve customer experience
Monitor and manage new and existing integration elements to ensure continued customer satisfaction
Act as Subject Matter Exert (SME) in a verity of data / analytics platforms such as SQL Server, Power BI and Microsoft Visual Studio/SSIS
Design and develop interfaces such as APIs. Forward thinking toward newer technologies and where these may be implemented
About You:
Bachelor's degree in computer science or a related field
5+ years’ of Experience with Microsoft SQL Server Integration service (SSIS)
5+ years’ experience with SQL, T-SQL, and stored procedures
5+ years’ of data engineering/modeling experience with both snowflake and star schema data modeling
2+ years’ of progressive experience in healthcare IT
3+ years’ experience with Business Intelligence tools such as Power BI and SSRS
Experience with Cloud Technologies such as Azure, AWS, etc is a plus
Requires demonstrated experience in project management
Good oral and written communication skills
Self-motivated and able to adapt to new technology and processes quickly
We Offer:
Comprehensive Benefits Package: Health Insurance, 401k Plan, Tuition Reimbursement, PTO
Opportunity to Participate In a Fleet Program
Competitive Salaries
Mileage Reimbursement
Professional Growth and Development Opportunities
Legalese:
This is a safety-sensitive position
Employee must meet minimum requirements to be eligible for benefits
Where applicable, employee must meet state specific requirements
We are proud to be an EEO employer
We maintain a drug-free workplace
Location: Gentiva",#N/A,10000+ Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2010,Unknown / Non-Applicable
CO,#N/A,Remote,Devops Data Engineer/Devops Data Analyst(W2 Only),"Devops/ Technical Data Analyst
6+ Months
Remote
W2 Only
Primary Skills:
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts applications and languages - preferably Oracle/Exadata SQL Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products ie ACH Wire Lockbox BAI EDI etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie XL Release Jenkins Git SVN test automation
Experience with unit functional regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Job Description
Enterprise Commercial Payments Data Mart Technical Data Analyst The Embedded Banking Data and API team is responsible for the Enterprise Commercial Payments Data Mart and Banking as a Service APIs. This position will primarily be focused on the Data Mart. Built on Oracle Exadata, the Mart is sourced with transactional Data from Core Payment systems (ACH, wire/RTP, lockbox, etc) through both batch/ETL and real-time feeds. The data is used as the source for reporting and inquiry APIs and Webhooks that are exposed to Commercial Clients, Fintech partners and internal Keybank systems. It is also used to generate BAI and other reports for Corporate Clients. Responsibilities will include:
Data Sourcing
Capturing requirements and designs for batch/ETL (Ab Initio) integrations
Capturing requirements and designs for real time (webMethods/Java) integrations
Identifying and implementing improvements to decrease load time and optimize database performance
Troubleshooting issues
Data Consumption
Capturing requirements and designs to meet requirements for Embedded Banking APIs
Capturing requirements and designs to meet requirements for BAI and other reports
Identifying and implementing improvements to improve API performance
Troubleshooting issues
Data SME
Working with SMEs from the source payment platforms to learn about and become expert on the critical data elements in the data mart
Respond to questions from consumers regarding data
Maintain documentation/data libraries
Interacting with the following:
Line of Business partners (Embedded Banking, Commercial Payments, Digital Channels)
Vendors/Clients
Production Support Team: provide knowledge transfer and assist with troubleshooting issues
Data Supply Chain (ETL/Abinitio, Data Model) Teams
Kafka Event Management Team
Open Banking Engineering Teams
Database Administrators
Infrastructure Teams
Internal Interfacing Teams
QAS/Testing Team: review test plans, help find data, and assist/supplement the testing
Working with and through direction of ECA Mart Technical Lead
Helping support, maintain and review dashboards in Kibana
Required Experience / Skills
Bachelor’s degree in Computer/Information Science or Information Systems Management or equivalent.
Technically sound in different database concepts, applications and languages - preferably Oracle/Exadata, SQL, Stored Procs.
At least 3 years of experience in this field.
Knowledge and experience with Commercial Payment products, ie, ACH, Wire, Lockbox, BAI, EDI, etc.
Knowledge of basic principles of ETL (Ab Initio)
Experience with DevOps/Continuous Delivery Tools - ie, XL Release, Jenkins, Git, SVN, test automation
Experience with unit, functional, regression and performance testing
Attention to details; logical approach to work; ability to prioritize; problem-solving and communication skills
Preferred Experience / Skills
Experience with database design, analytics
Experience with other programming languages
Basic understanding/experience with APIs, developer portals; Fintech integrations
Experience in creating REST API Documentation using OpenAPI/Swagger Specs. Swagger and Yaml, or similar tools
Experience working on an Agile Team
Job Type: Contract
Pay: $65.00 - $67.00 per hour
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Experience:
DevOps: 9 years (Preferred)
Data Engineer: 9 years (Preferred)
CI/CD: 9 years (Preferred)
ETL/Ab Initio: 8 years (Preferred)
Agile: 9 years (Preferred)
WebMethods/Java: 6 years (Preferred)
Jenkins, SVN: 9 years (Preferred)
RESTful API: 8 years (Preferred)
Commercial Payments: 8 years (Preferred)
Kafka: 2 years (Preferred)
Work Location: Remote",$66.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Olsson
4.0",4.0,"Kansas City, MO",Senior Electrical Engineer - Arc Flash - Data Center (Remote),"Company Description

We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.
Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us — and will continue to allow us — to grow. The result? Inspired people, amazing designs, and projects with purpose.

Job Description

As an Electrical Engineer, you will work directly with some of the world’s largest technology companies and other mission-critical clients. You will serve as an electrical engineer on projects, design calculations, write technical reports, and prepare documents. Experience in performing short circuit analysis and producing arc flash studies is required. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. You may travel to job sites for observation and attend client meetings.
We currently have one opening and will consider candidates interested in being located in most locations across the United States.

Qualifications

You are passionate about:
Working collaboratively with others
Having ownership in the work you do
Using your talents to positively affect communities
Electrical Engineering knowledge
You bring to the team:
Strong communication skills
Ability to contribute and work well on a team
Ability to be a self-starter to take on a variety of tasks to best serve the client and their project work
Investigation and troubleshooting of problems to find solutions
Ability to contribute and work well on a team
Bachelor's Degree in electrical engineering
8+ years or related electrical engineering experience
Registered professional engineer (PE) required
SKM and ETAP software experience is preferred

Additional Information

Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we’re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.
As an Olsson employee, you’ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you’ll:
Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)
Engage in work that has a positive impact in communities
Receive an excellent 401(k) match
Participate in a wellness program promoting balanced lifestyles
Benefit from a bonus system that rewards performance
Have the possibility for flexible work arrangements
Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.
#LI-MP1
#LI-REMOTE","$85,435 /yr (est.)",1001 to 5000 Employees,Private Practice / Firm,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1956,$100 to $500 million (USD)
"VISUAL SOFT, INC
4.1",4.1,"Washington, DC",Data Engineer - Active TOP SECRET - REMOTE-ONSITE,"Visual Soft, Inc is seeking qualified candidates to work on our efforts with a Prime for their end customer, a federal agency.

Position: Data Engineer - (50% REMOTE and 50% ONSITE)
Location: Washington, DC or Crystal City, Arlington, VA
Shift time: 8 am to 5 pm

JOB DESCRIPTION:
As a Data Engineer, you’ll implement data engineering activities on some of the most mission-driven projects in the industry. You’ll deploy and develop pipelines and platforms that organize and make disparate data meaningful. You will collaborate and work with and guide a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for your clients.
**Desirable skills include, Spark, Databricks, Data Lakes, Bigdata Tools and Technologies and AWS
Years of Experience:: 5+ years of experience
Education Requirement: BS degree preferred
Clearance requirement: Top SECRET is a MUST

Standard Benefits:
Our standard benefits include: Our standard benefits include 3 weeks of Paid time off (PTO that includes sick leave). Any unused PTO will be issued as a check at the end of an employee's anniversary with us. we also provide 2 floating and 8 public holidays. Floating and holidays expire at the end of every year of service of an employee. In addition, company will cover 50% of health and dental insurances only for all full time employees, however, dependents can be added at extra cost. Employee's health and dental coverage becomes effective after 30 days or first of the month after an employee completes initial 30 working days, we cover 50% for the employee's health and dental insurances. Dependents coverage for health and dental insurances is available as an out of pocket expense for employees. An employee has to finish all of your paper work for health and dental in the first 30 days of your employment with us. We provide STD, LTD and one time salary equivalent of life insurance at NO cost to all full time employees. All full time employees or w-2 employees with no benefits will be eligible to participate in company's 401k program after 90 days of employment with a company match of 4%, immediate vesting. In addition, all w-2 employees are eligible to be part of company's profit sharing, no employee contributions required. No commuting and/or parking expenses provided.","$93,472 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,$1 to $5 million (USD)
"Ansys
4.1",4.1,"Canonsburg, PA",Lead Application Engineer- Data Simulation Solutions,"When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.

Take a leap of certainty … with Ansys.

Summary / Role Purpose
Join the Ansys Customer Excellence team to partner with our customers to engineer what''s ahead, solve their real-world engineering problems, deploy Ansys software in their design workflows, and grow Ansys’ business. As a subject matter, industry and Ansys solutions expert, you will use advanced-level engineering knowledge to provide technical pre-sales support, perform professional services, and help guide Ansys product roadmap based on customer requirements. You will consult with customers on simulation-based solutions in support of their key business initiatives, lead project teams to create pervasive simulation solutions and mentor junior engineers.

Key Duties and Responsibilities
Lead in coordinating and executing all technical activities throughout the sales opportunity lifecycle such as technical discovery, negotiate technical success criteria, product presentations, demonstrations and evaluations. Work independently within multi-disciplinary teams
Help guide complex sales engagements to successful outcomes using subject matter expertise and industry knowledge
Interact with customers to understand their key business initiatives, product design needs and engineering design workflows; analyze how to address customers’ requirements using Ansys products and platform, articulate Ansys’ value proposition to Executive level audiences
Lead project teams to create differentiating simulation solutions using the Ansys platform and products; deploy the solutions within customers’ design workflows
Mentor junior engineers
Collaborate with the Ansys product development teams to guide Ansys product roadmap; lead project teams testing new releases of Ansys products on industrial problems, develop application best practices
Participate in corporate initiatives to further enhance Ansys technology, processes and people skills
Support Ansys field and digital marketing, author conference presentations
Contribute to consulting services, conduct intermediate and/or advanced training classes
Analyze business and technical needs, requirements, and the state of a customer’s current infrastructure, operations, and simulation & other engineering workflows
Consult our customers on process design and process optimization
Derive the technical specifications in collaboration with other business process analysts, subject matter experts, peers and Ansys Product Management
Develop creative and appealing Proof of Concepts to solve complex business problems
Lead/Assist in coordinating and executing all technical activities (design, develop, deploy) throughout the sales opportunity such as customer meetings and product presentations, demonstrations and evaluations with Ansys personnel and Services Partners
Utilize the components of the Ansys platform as the foundation for building complete solutions that digitally transform customer product development processes to facilitate more engineering in the digital domain by leveraging simulation
Participate in internal corporate initiatives to further enhance the solution suites, presales/sales enablement and business growth
Articulate the Ansys value proposition, which may encompass its entire suite of products (mechanical, fluid, electrical, electronics, optical, systems, software...).
Be a team player who can collaborate effectively with all key Ansys and customer stakeholders including sales, product development, project management, IT management, implementation engineers, and end users

Minimum Education/Certification Requirements and Experience
Required education and degree type: BS or MS or PhD in Mechanical/Chemical/Aerospace/Electrical Engineering or related field
Required minimum years of professional experience in an engineering software environment: BS+8, MS+6, or PhD+3
Subject matter expert in one or more relevant disciplines within Ansys’ business and is/will be sought out for advice by other Ansys engineers
Demonstrated understanding of engineering practices and product development, experience with building solutions using simulation technology and deploying those solutions within customers’ engineering workflows
Track record of delivering exceptional customer outcomes and revenue impact
Strong leadership and mentoring skills
Logical problem-solving, strong interpersonal and communication skills, fluent in writing and speaking English
Ability to organize and manage multiple projects which are complex in nature, possesses a sense of urgency
Projects a professional image and demonstrates business acumen, driven to succeed
Ability to travel domestically up to 25% of time
Proven track record of analyzing customer’s business and technical needs, requirements, and their state of current infrastructure, operations, and simulation & other engineering workflows
Proven track record of architecting solutions consisting of various (software) components and leading corresponding implementations
Experience in consulting customers on business process design and optimization
Self-starter who possesses a sense of urgency, strong organizational and follow up skills
Willing to evolve in a dynimic and innovative environment, eager to learn

Preferred Qualifications and Skills
Preferred education and years of professional experience in an engineering software environment: BS+12, MS+10, or PhD+7
4 years of experience in application engineering, customer support, or consulting services type customer facing roles using engineering software
Ability to interact effectively with senior business managers and C-level executives
Ability to travel domestically up to 50% of time
Demonstrated use of relevant Ansys software or knowledge of other commercial CAE, CAD, EDA, PLM software packages
Good understanding of enterprise class product development systems like SLM, SPDM, ERP, ALM, TDM, MIM/IMM, PDM, PLM (e.g. Aras Innovator, Siemens Teamcenter, Dassault ENOVIA or 3DEXPERIENCE, MSc SimManager, MSc MaterialCenter)
Basic understanding of programming languages such as: python, C# (.NET), Javascript, HTML,
Experience with DevOps/continuous integration and deployment
Practical knowledge of agility and agile project management
Ability in interest in obtaining a security clearance

This role is not available for sponsorship.

At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential in the knowledge that every day is an opportunity to observe, teach, inspire, and be inspired. Together as One Ansys, we are powering innovation that drives human advancement.

Our Commitments:
Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper
Our Values:
Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger

Our Actions:
We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results

OUR ONE ANSYS CULTURE HAS INCLUSION AT ITS CORE
We believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.

TAKE A LEAP OF CERTAINTY IN YOUR CAREER AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high - met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.

At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.

CREATING A PLACE WE’RE PROUD TO BE
Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: America’s Most Loved Workplaces, Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, U.K.).


For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.","$103,804 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Computer Hardware Development,1970,$1 to $5 billion (USD)
"EvolutionIQ
4.8",4.8,"New York, NY",Lead Data Infrastructure Engineer (AI / Insurtech),"About us: EvolutionIQ's mission is to improve the lives of injured and disabled workers and enable them to return to the workforce, saving billions of dollars in avoidable costs and lost productivity to the US and global economies and make insurance more affordable for everyone. We are currently experiencing massive growth and to accomplish our goals, we are hiring world-class talent who want to help build and scale internally, and transform the insurance space. We're backed by First Round Capital, FirstMark Capital, Foundation Capital, Brewer Lane Ventures, and have been named as Inc.'s top places to work!
Our Team: We are founded by a senior Google AI expert and a Bridgewater Associates Algorithmic Investor & Stanford MBA. We're not looking for employees. We're looking for partners in work, partners in culture-building, and partners in the future of data-driven insurance. The development team consists of world class engineers and leaders from companies like Google and Bloomberg. Each individual has had great success building large scale enterprise software and is now excited to try their hand at transforming the insurance industry.
Job Summary: We are looking for a Lead Engineer for our Data Platforms who will play an integral role in securing, architecting, and managing our highly sensitive insurance data. This position is tasked with overseeing our foundational datasets, data models, and analytics. The ideal candidate will have considerable experience in creating and managing secure data platforms, a strong engineering background, and a demonstrated record of technical leadership and effective communication.
In this critical role, you will not only ensure the robustness and reliability of our data systems, but also their security and compliance with stringent industry regulations. You will navigate the complexities of insurance data, bringing technical excellence and a security-first approach to safeguard our information assets. Your keen eye for security will be instrumental in protecting our company, customers, and stakeholders, while your technical expertise will shape the future of our data platform architecture.
Key Responsibilities:
Architect, design, and implement robust, secure, scalable, and high-quality data platforms, ensuring the availability, integrity, and confidentiality of the information.
Lead the development and maintenance of data pipelines, including personally coding and building the most critical components.
Work closely with product engineers, data scientists, analysts, and other stakeholders to understand data needs and deliver on those needs.
Define, design, and improve foundational data models to be used across the company to enable feature development and analytics.
Continuously improve our data quality toolkit
Provide guidance and technical leadership to the data engineering team, promoting continual team growth and individual team member skill development.
Be a role model for all engineers and provide mentorship as needed
Drive proof of concepts and experiments to explore new technologies that can level up the entire organization
Requirements:
7+ years of industry experience, holding staff/principal/lead level roles in Software Engineer or Data Engineer, with a focus in building scalable, mission critical, data platforms
Strong written and verbal communication skills
Extensive Python development experience
Experience with distributed data/computing tools, such as: Spark, Airflow, dbt
Proven track record of establishing engineering best practices for both coding and architecture
Experience building out systems and processes to enable secure handling of highly sensitive data
Experience using modern big data storage technologies such as Apache Parquet or Avro
Strong familiarity with modern data warehouse such as BigQuery or Snowflake
Ambitious, collaborative, and empathetic values
Even Better if You Have:
You have at least 3+ years experience in deploying systems on GCP or AWS
Experience with MLOps, such as feature engineering and model serving
You have worked with Dagster/Airflow, BigQuery, GCP, Terraform, Kubernetes, sklearn, keras/TensorFlow/pytorch, dbt, data modeling, Python/Pandas data frameworks, and scalable technical concepts/solutions
The Fit: We're a team of architects and visionaries who thrive on being first. We've created a fun, passionate, humorous, friendly, and fiercely-driven engineering culture that values delivery and personal impact above everything else. We are open to sponsoring candidates who currently are in the US and need to transfer their active H1-B visa.
Work-life, Culture & Perks:
Compensation: The range is $210-240K depending on a candidate's background and experience.
Well-Being: Full medical, dental, vision, short- & long-term disability, 401k matching. 100% of the employee contribution up to 3% and 50% of the next 2%
Work/Life Balance: For this role we are hoping this person can work out of the NYC office regularly with much of our leadership with flexibility. We also have a flexible vacation policy and are closed for winter break at the end of the year
Home & Family: Flexible PTO, 100% paid parental leave (4 months for primary caregivers and 3 months for secondary caregivers), sick days, paid time off. For new parents returning to work we offer a flexible schedule. We also offer sleep training to help you and your family navigate life schedules with a newborn
We also have a flexible vacation policy and are closed for winter break at the end of the year
Office Life: Catered lunches, happy hours, and pet-friendly office space. $500 for your in home office setup and $200/year for upgrades every year after your initial setup
Growth & Training: $1,000/year for each employee for professional development, as well as upskilling opportunities internally
Sponsorship: We are open to sponsoring candidates currently in the U.S. who need to transfer their active H1-B visa
EvolutionIQ appreciates your interest in our company as a place of employment. EvolutionIQ is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees","$88,635 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2019,$25 to $100 million (USD)
"Lyft
3.6",3.6,"San Francisco, CA",Senior Data Engineer,"At Lyft, community is what we are and it's what we do. It's what makes us different. To create the best ride for all, we start in our own community by creating an open, inclusive, and diverse organization where all team members are recognized for what they bring.
Here at Lyft, Data is the only way we make decisions. It is the core of our business, helping us create a transportation experience for our customers, and providing insights into the effectiveness of our product launch & features.
As a Data Engineer at Lyft, you will be a part of an early stage team that builds the data transport, collection, and storage, and exposes services that make data a first-class citizen at Lyft. We are looking for a Data Engineer to build a scalable data platform. You'll have ownership of our core data pipeline that powers Lyft's top-line metrics; You will also use data expertise to help evolve data models in several components of the data stack; You will help architect, building, and launching scalable data pipelines to support Lyft's growing data processing and analytics needs. Your efforts will allow access to business and user behavior insights, using huge amounts of Lyft data to fuel several teams such as Analytics, Data Science, Marketplace, and many others.
Responsibilities:
Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft
Evolve data model and data schema based on business and engineering needs
Implement systems tracking data quality and consistency
Develop tools supporting self-service data pipeline management (ETL)
SQL and MapReduce job tuning to improve data processing performance
Write well-crafted, well-tested, readable, maintainable code
Participate in code reviews to ensure code quality and distribute knowledge
Unblock, support and communicate with internal & external partners to achieve results
Experience:
5+ years of relevant professional experience
Strong experience with Spark
Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet)
Strong skills in a scripting language (Python, Ruby, Bash)
Good understanding of SQL Engine and able to conduct advanced performance tuning
Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)
1+ years of experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)
Comfortable working directly with data analytics to bridge Lyft's business goals with data engineering
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.
Starting in September 2023, this role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.
The expected range of pay for this position in the San Francisco Bay Area is $162,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","$163,274 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Computer Hardware Development,2012,Unknown / Non-Applicable
"KaylaTek
4.2",4.2,"Andrews AFB, MD",Data Center Engineer- Senior - Secret Clearance,"$3,000 Referral Bonus for this position!
Come join our growing team with a 21st Century Vision! At KaylaTek, we understand that the key to our success is the quality of the people we employ. Our focus is not just on jobs, but on building and enhancing your career through ongoing professional development, training, and high quality of life. Our team members choose KaylaTek for a number of reasons including our competitive compensation and benefit packages, dedication to education, as well as our outstanding service. Our Grow Strong Vision encompasses a place for employees to grow, learn and feel a sense of belonging, not just a place to work.
Employee Benefit Offerings
Medical, Dental, Vision, 401(k) with company matching, Short-Term and Long-Term Disability, Life and AD&D Insurance, Paid Time Off, 11 Paid Holidays, Employee Assistance Program (EAP), Professional Development Program, Military Leave Support and much more.

Job Site: Joint Base Andrews, MD

Shift Hours: Day-Shift; core support hours are 0600 -1800. This is a 24/7/365 support environment; off-hours response/support may be required, however only standard M-F core hours working time for current position.
Overview: KaylaTek is seeking a Data Center Engineer to provide technical leadership and support in the areas of IT planning, solution specification/design, implementation and target architecture development for the AFNCR Consolidated Communication Center (CCC). The Data Center Engineer will support the 844th Communications Group at Joint Base Andrews (JBA). This role includes supporting the Air Force District of Washington (AFDW) and Headquarters Air Force (HAF) customers on both NIPRNet and SIPRNet domains for the development of the CCC building. The qualified candidate will have knowledge of information technology commercial solutions and experience designing and developing technical solutions. The preferred candidate will have excellent communications skills, a strong customer service orientation and experience serving as an advisor to Chief Architect and other Government/Contractor staff and managers.
Certifications required: Active Security + CE

Roles and Responsibilities:
Assist in planning, coordinating, and managing the technical aspects in projects related to the CCC datacenter. As well, identify and manage dependencies between these projects and with other ongoing activities.
Lead and assist with all design aspects of the CCC data center support systems, to include AC/DC power, UPS, HVAC, carrier infrastructures, internal/external cable plant, and overall data center layout.
Produce architectural artifacts to include system design diagrams, recommendation justifications, and technical specifications.
Communicate conceptual designs and create/maintain project documentation before, during, and after construction.
Create and review civil/structural/architectural design RFPs.
Assist with managing consultants/contractors through the design and construction process.
Effectively communicate design standards to internal and external project partners
Think outside of the box to find innovative solutions prior to and during the construction process to reduce costs without negative impacts on quality or reliability.
Conduct site assessments, internal design meetings, construction reviews.
Assess client's current IT and facility infrastructure.
Lead and assist with data center migration planning
Required Qualifications:
Bachelor's Degree with 15+ years in Civil Engineering or the equivalent relevant experience in datacenter or mission critical facilities design.
Possess an active Secret security clearance
Proficiency in building codes, regulations, and standards
Ability to build and maintain relationships, partnerships and external networks
Ability to work independently, with minimal supervision and work effectively in a collaborative team environment while keeping the team informed.
Excellent customer facing skills.
Excellent researching, decision-making and organizational skills are required.
Excellent written and verbal communication skills.
Proven analytical, evaluative, and problem-solving abilities.
Working knowledge of Microsoft Office Suite including Microsoft Visio or AutoCAD.
Maintain confidentiality and adhere to data protection and other guidelines where appropriate.
The above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties and skills required of personnel so classified.
COMMITMENT TO DIVERSITY
KaylaTek is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.
E-VERIFY AND BACKGROUND CHECKS

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire. KaylaTek participates in the DHS e-Verify program. KaylaTek also conducts a background check on all candidates post offer though PROScreening LLC.","$172,500 /yr (est.)",1 to 50 Employees,Company - Private,Government & Public Administration,National Agencies,#N/A,$1 to $5 million (USD)
