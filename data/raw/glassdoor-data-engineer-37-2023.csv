company,company_rating,location,job_title,job_description,salary_estimate,company_size,company_type,company_sector,company_industry,company_founded,company_revenue
"SourceMantra
3.7",3.7,"Houston, TX",Data Engineer,"Hello,
Job Title: Data Engineer
Location: Houston-Texas Onsite
Duration: 6+Months
Responsibilities include:
Design and implement reliable data pipelines to integrate disparate data sources into a single Data Lakehouse
Design and implement data quality pipelines to ensure data correctness and building trusted datasets
Design and implement a Data Lakehouse solution which accurately reflects business operations
Assist with data platform performance tuning and physical data model support including partitioning and compaction
Provide guidance in data visualizations and reporting efforts to ensure solutions are aligned to business objectives
The successful candidate will meet the following qualifications:
5+ years of experience as a Data Engineer designing and maintaining data pipeline architectures
5+ years of programming experience in #Python, #ANSISQL, #PLSQL, and #TSQL
Experience in various data integration patterns including #ETL, #ELT, #Pub/Sub, and Change Data Capture
Experience with common Python Data Engineering packages including #pandas, #Numpy, #Pyarrow#Pytest, #Scikit-Learn, and #Boto3
Experience in software development practices such as Design Principles and Patterns, Testing, Refactoring, CI/CD, and version control
Experience in implementing a Data Lakehouse using #ApacheIceberg or #DeltaLake
Knowledgeable of modern data platform technologies including Apache Airflow, Kubernetes, and S3 Object Storage
Experience with Dremio and Airbyte is preferred
Thanks and Regards
Swarna | SourceMantra Inc
Sr US IT Recruiter
swarna@sourcemantra.com|| 908-381-0321
295, Durham Avenue, Suite #201, South Plainfield, New Jersey 07080, USA
Job Type: Contract
Salary: $65.00 - $70.00 per hour
Benefits:
Health insurance
Compensation package:
Hourly pay
Experience level:
9 years
Schedule:
8 hour shift
Experience:
Python: 5 years (Preferred)
Azure Data Lake: 3 years (Preferred)
Delta lake: 1 year (Preferred)
Work Location: On the road",$67.50 /hr (est.),Unknown,Company - Public,Financial Services,Accounting & Tax,#N/A,Unknown / Non-Applicable
"Cloud Shift Technologies LLC
5.0",5.0,"Columbus, OH",Data Engineer,"Data Engineer
Cleveland, Ohio
Video Interview
Duration: 1+ years
State of Ohio LOT
Job# 720856
Job Description
The posting is hybrid/remote- occasional check-in at a lottery office located in the State of Ohio may be necessary
*Urgent request*
The posting is hybrid/remote- occasional check-in at a Lottery office located in the State of Ohio may be necessary
615 West Superior Avenue Cleveland, Ohio 44113
Skills
Strong knowledge of SQL to aid in data visualization. Python experience is a bonus.
Working knowledge of Hadoop tools, such as Spark, Impala, Hue, and Kafka, to create, query, and manage ETL data flows for batch and streaming ingestion.
Ideally, working knowledge of data connectors for embedding data visualizations from Tableau Server or PowerBI into SharePoint.
Knowledge of Tableau Server and/or Microsoft PowerBI is helpful.
Practical understanding and experience with data cleaning/cleansing.
Conceptual understanding of networking schematics and data flows for ETL purposes.
Ability to conceptualize development of data mart environments using batch data for agency business analyst usage.
Some experience with newer data analysis tools, such as Tensorflow, is helpful.
Responsibilities
85%
Work with resources to provision necessary access to data sources for ingestion to agency Hadoop platform.
Utilizing service accounts, develop ETL pipelines through Spark and/or StreamSets to bring data from disparate source systems into agency’s Hadoop platform iteration. Validate data sets in Hadoop to ensure ingestion loads are as close to 1:1 as possible.
Commit table transformations within Hadoop platform where needed to allow agency analyst to develop requested visuals. Ensure data refresh schedule is consistent with departmental need. Validate and test connections between dataset and cloud analytics software.
Create a Data Mart DB for rolled-up and simplified tables for agency analyst consumption. One set of tables may be created for Sales staff, another may be created for Executive staff, etc. Further direction to be given once this stage is reached.
Assist with the automation of several existing reports and visualizations within Tableau Server.
Document work completed and publish FAQ on agency wiki. Work with department head to conduct agency training on data usage.
Validate and ingest streaming agency data, when available. Assist in transforming the data, with the data analyst, to create more on-demand, near-live visualizations of agency activity.
Validate and test connections between dataset and cloud analytics software.
10%
Work with enterprise and corporate resources to determine how outside data and software (to mean “outside of Microsoft ecosystem”) can be read within Microsoft SharePoint server.
Deploy data connectors where necessary to connect IOP datasets to Microsoft ecosystem. Deploy data connectors, if necessary, to connect Tableau Server environment to Microsoft ecosystem.
5%
Document work completed and publish FAQ on agency wiki. Conduct training, as directed, throughout.
Qualifications:
Bachelor's or masters degree in computer science, software or computer engineering, information systems or similar academic background.
Working practical experience in developing and deploying ETL pipelines in an enterprise big data environment.Skill
Required / Desired
Actual Year
Last Year Used
Strong knowledge of SQL to aid in data visualization
Required
Working knowledge of Hadoop tools, such as Spark, Impala, Hue, and Kafka, to create, query, and manage ETL data flows
Required
working knowledge of data connectors for embedding data visualizations from Tableau Server or PowerBI into SharePoint
Required
Knowledge of Tableau Server and/or Microsoft PowerBI
Required
Python experience is a bonus
Required
Job Types: Full-time, Contract
Pay: $50.00 - $54.00 per hour
Benefits:
Employee assistance program
Paid time off
Professional development assistance
Relocation assistance
Experience level:
6 years
7 years
8 years
Schedule:
8 hour shift
Work Location: Remote",$52.00 /hr (est.),1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
Fortek IT Solutions USA,#N/A,"Denver, NC",Data Engineer,"JD:
Engineer requirement:
· Bachelor's degree in Statistics, Computer Science, Data Science, or related quantitative field 3-5+ years of experience in business intelligence related roles and at least 2+ years spent as a BI Engineer Proficient with business intelligence platforms,
· Understand business requirements and translate them into consumable and governed solutions Capture data to design KPIs and visualization for different audiences across the enterprise.
· In-depth knowledge of Power BI, including data modeling, DAX expressions, and Power Query.
· Experience in designing and implementing data visualizations, such as charts, graphs, and maps, to present complex data in a user-friendly manner Familiarity with data warehousing concepts and best practices.
· Proficiency in writing complex SQL queries, preferably in Snowflake, for data extraction, manipulation, and optimization.
· Collaborate with key stakeholders to deliver on their data and analytics needs by producing live dashboards and/or reporting with a focus on Self-Service Enablement Maintain access controls to BI and Analytics Platforms, Reports, and Dashboards to ensure sensitive information is restricted.
· Power BI Experience working with stakeholders to gather requirements Expert in SQL and experience with databases such as Snowflake Proficient in concepts and implementation in developing reports, Dashboard, self-service BI, and visualizations AI/ML experience within Power BI
· Previous experience with Tableau is nice to have related to BI and Analytics Financial industry is a plus.
· Build the North Star metrics and models that orient the overall business and our product pods.
· Build and maintain automated forecasting models from the bottom up, including diff to actuals and explanatory models.
· Build anomaly detection routines that detect risks to growth at all margins.
· Proven experience as a Power BI Developer, with a strong background in developing interactive dashboards and reports.
· Strong analytical and problem-solving skills with a keen attention to detail
· Excellent communication and collaboration abilities to work effectively with stakeholders of various technical backgrounds.
· Ability to work independently and manage multiple priorities in a fast-paced environment.
· you will work with big data sets to build forecasts, attribution models, content and engagement value models, user journeys, retention/churn models, and more.
· Come up with quick hypotheses to diagnose and explain trends in our growth.
· Propose strategic initiatives and goals, and perform ad-hoc analysis, to help our functional partners to achieve their goals and drive growth.
· Effectively communicate with people in all disciplines and levels, including the C-suite
· Deep understanding of time
Job Type: Contract
Salary: $65.00 - $75.00 per hour
People with a criminal record are encouraged to apply
Ability to commute/relocate:
Denver, NC 28037: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person",$70.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Wiliot
4.5",4.5,Remote,Data Engineer,"Wiliot was founded by the team that invented one of the technologies at the heart of 5G. Their next vision was to develop an IoT sticker, a computing element that can power itself by harvesting radio frequency energy, bringing connectivity and intelligence to everyday products and packaging, things previously disconnected from the IoT. This revolutionary mixture of cloud and semiconductor technology is being used by some of the world’s largest consumer, retail, food, and pharmaceutical companies to change the way we make, distribute, sell, use, and recycle products. We’re driven by our passion for sustainability, ESG and waste reduction.
Our investors include Softbank, Amazon, Alibaba, Verizon, NTT DoCoMo, Qualcomm and PepsiCo.
We are growing fast and need people that want to be part of the journey, commercializing Sensing as a Service and enabling “Intelligence for Everyday Things”.
We are seeking an experienced data engineer to join our team and evolve our data and ML infrastructure. You will play a crucial role in bridging the gap between our clients, data science, data analytics, platform, and cloud teams. You will collaborate closely to understand their data requirements, design, and implement scalable data solutions, and provide ongoing support to ensure successful integration and utilization of our IoT products. You will be responsible for managing data pipelines, optimizing data workflows, and transforming raw data into structured data solutions.

Requirements:


Bachelor's or Master's degree in Computer Science, Data Engineering, or a related field.
Proven experience as a Data Engineer, preferably in a client-facing role.
Strong programming skills in languages such as Python, Java, or Scala.
Proficiency in designing and implementing data pipelines using technologies like Apache Kafka, Apache Spark, or similar frameworks.
Experience in Databricks preferred
Understanding of batch vs streaming based data pipelines and ML models
Familiarity with cloud-based data storage and processing platforms such as AWS, GCP, or Azure.
Experience with SQL and NoSQL databases, data modeling, and database optimization techniques.
Strong communication and interpersonal skills to effectively interact with clients and internal teams.
Ability to manage multiple projects and prioritize tasks in a fast-paced environment.

Responsibilities:


Develop machine learning applications according to requirements
Partner with data scientists to co-deliver data products
Engage directly with clients to understand their data needs and provide data engineering expertise.
Collaborate with cross-functional teams to design and implement data pipelines that meet client requirements and align with Wiliot's infrastructure.
Develop efficient data workflows to enable seamless data ingestion, transformation, storage, and retrieval.
Implement data quality rules/checks, data validation, and monitoring processes to ensure data integrity and accuracy.
Troubleshoot data-related issues and provide timely resolution to ensure client satisfaction.
Provide training and documentation to clients on data integration best practices and usage of Wiliot's data products.",#N/A,1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,2017,Unknown / Non-Applicable
"WCG
3.2",3.2,"Princeton, NJ",Data & Analytics Engineer (Remote),"Description and Requirements
JOB SUMMARY:

The Data & Analytics (D&A) Engineer is responsible for delivering business needs end-to-end in an iterative, agile pattern, starting from understanding the requirements to deploying scalable and robust software, utilizing cloud technology and full automation, into production. This role will solve integration needs by supplying and consuming information needed for analytics and operations. We use a variety of technology, from big data to open source frameworks including AI/ML, to integrate and present meaningful analytical insights into clinical trial business needs and customer uses. Our tools analyze historical data to identify insights, forecast trends, and recommend actionable items to improve clinical trial business and operations.

In addition to delivery, the D&A Engineer should have an automation first and continuous improvement mindset, driving the adoption of CI/CD & data ops tools while supporting the improvement of the tool sets/processes. This role requires being fluent in some technologies while being proficient in others and learning on the job to deliver value to both customers and to the business. Necessary attributes of the position include ownership, accountability, and resilience.

EDUCATION REQUIREMENTS:
Bachelor’s degree in a quantitative discipline (i.e. statistics, applied mathematics, computer science, data mining, machine learning, or some other empirical science) preferred.

QUALIFICATIONS/EXPERIENCE:

3+ years of experience in a Data or Analytics role with a proven track record of quality software development in a disciplined software development lifecycle and an ability to innovate outside of traditional architecture/software patterns when needed to deliver customer enterprise or customer facing applications.
1+ years of experience in the following:
Covering Big Data, Streaming, and Data Engineering related technologies such as spark, using scripting languages such as Python and using object-oriented languages such as Java/Scala/C++ or functional programming languages such as Scala in DevOps/CICD, using technologies such as docker/ kubernetes.
Familiarity with using Databricks or a similar platform for data engineering & data science.
Comfortable in configuring and using multiple operating systems (Mac/Windows/*nix).
Knowledge and/or experience with health care information domains is a plus.

ESSENTIAL DUTIES/RESPONSIBILITIES: To perform this job successfully, an individual must be able to perform each essential duty and responsibility satisfactorily. The requirements listed below are representative of the knowledge, skills, and/or ability required.
Contribute as part of a scrum team on requirements from a business/product owner and take direction from the tech lead.
Design, implement, test and release(deliver) technical solutions to business requirements.
Implement automated release (CICD) for solution delivery.
Actively participate in the agile delivery process.
Other duties as assigned by supervisor. These may, on occasion, be unrelated to the position described here.
Attendance and punctuality are essential functions of the position.

TRAVEL REQUIREMENTS:
0% - 5%

WHY WE LOVE WCG: At WCG, our employees are our most valuable asset and as with all our assets, we invest in them with an eye toward future success. We provide each eligible employee with a comprehensive set of benefits designed to protect their personal and financial health and to help them make the most of their future.

Comprehensive Benefits package - Health, Dental, Vision, Life Disability, 401k with match, and flexible spending accounts
Employee Assistance Programs and additional work/life resources
Referral Bonuses and Tuition Reimbursement
Paid time off including holidays, vacation, and sick time
Opportunities for career development with on-the-job training, certification assistance and continuing education reimbursement

EXPECTED ANNUAL BASE SALARY: $49,860 to $77,500
GPS LEVEL: P2

WCG is proud to be an equal opportunity employer – Qualified applicants will receive consideration for employment without regard to race, color, national origin or ancestry, religion or creed, sex, sexual orientation, gender identity, age, marital status, disability, genetic information, citizenship, veteran status, reprisal or any other legally recognized basis or status protected by federal, state or local law.","$63,680 /yr (est.)",1001 to 5000 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,#N/A,$100 to $500 million (USD)
wiselinkglobal,#N/A,"Plano, TX",Data Engineer,"Position: Data Engineer
Location: Plano, TX
Duration: Fulltime
Job Description:
Skilled in Business Intelligence/Data Warehouse, Data and Technical Architecture, Methodology, Architecture, Data Governance, Data Modeling, ETL Tools, Big Data, Data Lake. Strong expertise applying industry best practice methods and sound enterprise architecture, data architecture/ management, and integration techniques across domains.
What you will be doing:
End to End responsibility for data modeling (OLTP, OLAP)
Data analysis experience with writing complex queries, unions, joins and aggregations.
Data analysis experience using major RDBMS solutions like snowflake, redshift etc
Experience with ELT, ETL processes using glue, glue brew transformations.
Use airflow to schedule and time data transfers.
Understanding of deep JSON structures and partitioning using Kafka, spark, Scala, s3 etc.
Work with Data Scientist team to build segmentations, ML use cases, forecasting etc
Experience working with sagemaker, jupyter notebooks for deep data analysis.
Work with the BI specialists to design develop and enhance connectors to get closer to business use cases.
Migration of existing custom pipelines to a normalized connector approach
Help educate CT teams on data integration, validation standards and drive clean ingestion egestion patterns for the platform.
What you bring:
Work with APIs to extract and ingest data.
Work with virtual warehouses and configure them for optimal performance and efficiency.
Conduct ETL data integration, cleansing transformations using glue spark script.
Work on aggregations of data coming from applications and apis to store results in a historic table.
Experience with streaming data analytics and building of streaming pipelines and connectors.
Experience with connections to BI solutions like tableau which include configurations of roles, policies within aws
Leverage Lambda, glue and step functions to cleanse and transform data.
Work with DWH technologies like EC2, s3, redshift, athena, snowflake to churn large data sets and partition them in readable formats and in real time
Job Type: Full-time
Salary: From $100,000.00 per year
Schedule:
8 hour shift
Ability to commute/relocate:
Plano, TX 75023: Reliably commute or planning to relocate before starting work (Required)
Experience:
APIs: 1 year (Preferred)
SQL: 1 year (Required)
Data warehouse: 1 year (Required)
Work Location: In person","$100,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Clairvoyant
4.1",4.1,"Bethlehem, PA",Data Engineer,"Job type: Fulltime/W2
Location: Bethlehem, PA
Job Description:
Sr Data Engineer
Design, develop, implement, and maintain code, information architecture, and conceptual models to support data processing, and flows thru data lake
Work with clients to get the requirements and build codes accordingly
Translate client business requirements into data requirements
Communicate the data requirements to other members of the team
Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.
Reformulating existing frameworks to optimize their functioning.
Testing such structures to ensure that they are fit for use.
Preparing raw data for manipulation by data scientists or for visualization team.
Proven experience as a data engineer, software developer, or similar.
AWS: S3 Data Lake, Athena, Redshift, EMR, Glue, ECS
Proficiency with Python in a data engineering context. Ex: Pandas, PySpark
Experience using VCS like Github, Gitlab
Excellent analytical and problem-solving skills.
A knack for independence and group work.
Capacity to successfully manage a pipeline of duties with minimal supervision.
Job Type: Full-time
Salary: $80.00 - $85.00 per hour
Experience:
AWS: 4 years (Required)
Python: 3 years (Required)
GitHub/Gitlab: 2 years (Required)
Work Location: Remote",$82.50 /hr (est.),501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,2012,Unknown / Non-Applicable
"MARVEL TECHNOLOGIES INC
3.7",3.7,"Plano, TX",Data Engineer - Connected Technologies,"Our client is seeking a Data Engineer - Connected Technologies
Skilled in Business Intelligence/Data Warehouse, Data and Technical Architecture, Methodology, Architecture, Data Governance, Data Modeling, ETL Tools, Big Data, Data Lake. Strong expertise applying industry best practice methods and sound enterprise architecture, data architecture/ management, and integration techniques across domains.
Duties and Responsibilities:
End to End responsibility for data modeling (OLTP, OLAP)
Data analysis experience with writing complex queries, unions, joins and aggregations.
Data analysis experience using major RDBMS solutions like snowflake, redshift etc
Experience with ELT, ETL processes using glue, glue brew transformations.
Use airflow to schedule and time data transfers.
Understanding of deep JSON structures and partitioning using Kafka, spark, Scala, s3 etc.
Work with Data Scientist team to build segmentations, ML use cases, forecasting etc
Experience working with sagemaker, jupyter notebooks for deep data analysis.
Work with the BI specialists to design develop and enhance connectors to get closer to business use cases.
Migration of existing custom pipelines to a normalized connector approach
Help educate CT teams on data integration, validation standards and drive clean ingestion egestion patterns for the platform.
Required and Desired Skills/Certifications:
Work with APIs to extract and ingest data.
Work with virtual warehouses and configure them for optimal performance and efficiency.
Conduct ETL data integration, cleansing transformations using glue spark script.
Work on aggregations of data coming from applications and apis to store results in a historic table.
Experience with streaming data analytics and building of streaming pipelines and connectors.
Experience with connections to BI solutions like tableau which include configurations of roles, policies within aws
Leverage Lambda, glue and step functions to cleanse and transform data.
Work with DWH technologies like EC2, s3, redshift, athena, snowflake to churn large data sets and partition them in readable formats and in real time
Job Types: Full-time, Contract
Pay: $60.00 - $65.00 per hour
Compensation package:
Hourly pay
Yearly pay
Experience level:
8 years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Plano, TX 75023: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
Are you willing to work day one onsite?
Can you work Independently?
Experience:
Data Engineering: 8 years (Required)
Business intelligence: 3 years (Required)
Data warehouse: 3 years (Required)
ELT, ETL processes using glue: 1 year (Required)
API: 3 years (Required)
Big data: 2 years (Required)
Data Governance: 1 year (Required)
Work Location: In person",$62.50 /hr (est.),51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,#N/A,$5 to $25 million (USD)
"Datasys Software and Consulting Inc
4.4",4.4,"Plano, TX",Data Engineer,"Data Engineer
Plano, TX
Long-term Contract
Roles and Responsibilities:
Skilled in Business Intelligence/Data Warehouse, Data and Technical Architecture, Methodology, Architecture, Data Governance, Data Modeling, ETL Tools, Big Data, Data Lake. Strong expertise applying industry best practice methods and sound enterprise architecture, data architecture/ management, and integration techniques across domains.
End to End responsibility for data modeling (OLTP, OLAP)
Data analysis experience with writing complex queries, unions, joins and aggregations.
Data analysis experience using major RDBMS solutions like snowflake, redshift etc.
Experience with ELT, ETL processes using glue, glue brew transformations.
Use airflow to schedule and time data transfers.
Understanding of deep JSON structures and partitioning using Kafka, spark, Scala, s3 etc.
Work with Data Scientist team to build segmentations, ML use cases, forecasting etc.
Experience working with sagemaker, jupyter notebooks for deep data analysis.
Work with the BI specialists to design develop and enhance connectors to get closer to business use cases.
Migration of existing custom pipelines to a normalized connector approach
Help educate CT teams on data integration, validation standards and drive clean ingestion egestion patterns for the platform.
Experience and Qualifications:
Work with APIs to extract and ingest data.
Work with virtual warehouses and configure them for optimal performance and efficiency.
Conduct ETL data integration, cleansing transformations using glue spark script.
Work on aggregations of data coming from applications and APIs to store results in a historic table.
Experience with streaming data analytics and building of streaming pipelines and connectors.
Experience with connections to BI solutions like tableau which include configurations of roles, policies within AWS.
Leverage Lambda, glue and step functions to cleanse and transform data.
Work with DWH technologies like EC2, s3, redshift, athena, snowflake to churn large data sets and partition them in readable formats and in real time.
Job Type: Contract
Work Location: In person","$100,019 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"AgileEngine
5.0",5.0,Remote,Senior Data Engineer,"Remote position for USA residents;
What you will do
Work independently and with the business stakeholders to understand their requirements and drive business outcomes;
Utilize SQL Server database for backend development, Informatica for ETL processes, and
Control-M for automation. Experience with Postman is essential;
Provide engineering solutions, design and build data pipelines while considering scalability and efficiency;
Collaborate with the SDET team to incorporate testing aspects into the DevOps pipeline;
Take the initiative to improve team efficiency, actively contributing with ideas and innovative solutions;
Think strategically about the design and architectural aspects of the data infrastructure;
Previous experience in the financial industry, specifically wealth asset management, is highly desired;
This is a multi-year project with long-term stability and growth potential;
Conduct performance testing to ensure the smooth functioning of data pipelines;
Note that this role involves working on an existing platform and is not a support project.
Must haves
Strong proficiency in SQL Server database, Informatica, and Control-M automation;
Experience with Postman is required;
Solid understanding of data concepts, including ODS, data warehousing and data storage;
Ability to think strategically about design and architectural aspects of data infrastructure;
Previous experience in the financial industry, particularly asset management, is highly desired;
Strong problem-solving skills and ability to proactively contribute to the team’s efficiency;
Experience with performance testing and ensuring the efficiency of data pipelines.
Nice to haves
Cloud experience;
Experience with Data Modeling;
Experience with Python or Java, and familiarity with Java and Spring Batch is beneficial.
The benefits of joining us
Professional growth
Accelerate your professional journey with mentorship, TechTalks, and personalized growth roadmaps
Competitive compensation
We match your ever-growing skills, talent, and contributions with competitive USD-based compensation and budgets for education, fitness, and team activities
A selection of exciting projects
Join projects with modern solutions development and top-tier clients that include Fortune 500 enterprises and leading product brands
Flextime
Tailor your schedule for an optimal work-life balance, by having the options of working from home and going to the office – whatever makes you the happiest and most productive.
Job Types: Contract, Full-time
Work Location: Remote",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2010,Unknown / Non-Applicable
"Helm
3.8",3.8,Michigan,Data Engineer,"Description:
We are looking for a skilled and experienced Data Engineer to join our team. The successful candidate will be responsible for the development, optimization, and maintenance of our data pipeline architecture. They will work closely with data scientists, analysts, and other stakeholders to ensure that our data infrastructure meets the needs of the organization and supports our various client business processes.
Responsibilities:
Design, develop, and maintain scalable and robust data pipeline architectures, ensuring data quality and consistency across multiple data sources.
Collaborate with the Business Intelligence team and business stakeholders to understand data requirements and translate them into technical solutions.
Help implement best practices for data governance, data security, and data privacy, ensuring compliance with relevant industry regulations and standards.
Develop and maintain ETL (Extract, Transform, Load) processes to support data ingestion, transformation, and integration from various sources, including APIs, databases, and external data providers.
Monitor and troubleshoot data pipeline performance issues, ensuring timely resolution and minimal downtime.
Document data pipeline architectures, workflows, and procedures for internal and external stakeholders.
Work closely with cross-functional teams to support the integration of data-driven insights into business processes and decision-making.
Requirements:
Bachelor's or master's degree in computer science, Engineering, or a related field.
2+ years of experience in data engineering, with a proven track record of designing and implementing complex data pipelines.
Strong expertise in Microsoft SQL, data modeling, and data warehousing concepts.
Proficient in the Microsoft Azure framework (e.g., Analysis Service, Data Factory, …).
Experience with the Microsoft Power BI data visualization tool
Strong problem-solving skills, attention to detail, and ability to work both independently and as part of a team.
Excellent communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.
A strong desire to stay up to date with the latest industry trends and advancements in data engineering.
Experience with automotive data sources a plus.",#N/A,201 to 500 Employees,Company - Private,Media & Communication,Advertising & Public Relations,1943,$25 to $100 million (USD)
"SUMERU INC
3.9",3.9,"Sunnyvale, CA",Data Center Engineer,"Required Skills/Experience
· Principles and practices of excellent customer service.
· Principles and practices of ITSM (IT Service Management) systems to include incident/problem management; request fulfilment; knowledgebase; asset management and IT service catalogs.
· Network traffic and performance parameters, including understanding telecommunications theory and practice.
· Methods and procedures of systems administration and security and integrity maintenance.
· Connectivity, system integration, and network design.
· Structure development, features, and access including configurations protocol and interfacing.
· Current developments and trends of network technologies and/or server/data storage technologies.
· Principles and methods of system and storage capacity, physical, virtual and cloud-based Local Area Network wiring and distribution methods.
· Wide Areas Networking Connectivity utilizing T1, T3 and fiber backbone transports.
· Advanced cybersecurity practices and procedures.
· Office methods, procedures, software and equipment.
· Applicable industry and safety codes and technology standards.
· Principles of project management, task completion and resource management.
· Microsoft Office, Microsoft Project and Microsoft Visio.
· Team formation and execution; how to motivate teams.
· Cost-benefit analyses to recommend the most effective solution.
Job Type: Full-time
Salary: $43.00 - $47.00 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Sunnyvale, CA 94086: Reliably commute or planning to relocate before starting work (Preferred)
Experience:
Computer networking: 5 years (Preferred)
LAN: 5 years (Preferred)
Rack cables: 5 years (Preferred)
License/Certification:
CCNA, CCNP (Required)
Work Location: In person",$45.00 /hr (est.),201 to 500 Employees,Nonprofit Organization,Information Technology,Information Technology Support Services,2003,$5 to $25 million (USD)
Mind Mint,#N/A,"Scottsdale, AZ",Data Engineer,"JOIN AN AMAZING COMPANY AND GLOBALLY RECOGNIZED BRAND
DIVE INTO INTRIGUING PROJECTS AND LEVEL UP YOUR SKILLS
WORK WITH A FUN TEAM ONSITE IN SCOTTSDALE ARIZONA

Are you ready to embark on an exciting challenge in the field of data engineering?

Do you possess a genuine passion for unraveling patterns and crafting insightful solutions through data engineering?

Can you envision yourself delivering impactful outcomes that align with our company's objectives through data-driven solutions?

If so, we have an opportunity that will ignite your enthusiasm for data engineering and propel your career to new heights.

Mastermind.com, created in partnership by Dean Graziosi and Tony Robbins, is the #1 online platform for people who are looking to market and monetize their knowledge base. Mastermind has a worldwide following and touches lives all over the world.

We are seeking a world-class Data Engineer to join our IT team. Here is your chance to help take our company to new heights.

THE ROLE

️ Build tools and solutions that automate complex workflows

️ Create data pipelines and maintain the infrastructure and architecture for data generation, storage, and processing

Build systems that collect, manage, and convert raw data into usable information

This is a role that involves solving complex technical issues and working collaboratively with our team. You will report directly to the Chief Technology Officer.

Our interview process will include a technical assessment and peer code review to assess your technical proficiency.

This Data Engineer position is based in Phoenix, Arizona, and will require you to work from the Mastermind headquarters in Scottsdale, AZ.

We provide an excellent compensation model based on experience ranging from $100k-120k.

This opportunity is only available for USA residents with valid work authorization. We DO NOT offer sponsorship or relocation.

REQUIREMENTS
You must have 5 years experience in designing and maintaining MySQL
You must have experience with cloud data warehouses (preferably BigQuery), dbt, or Python experience
You must have SQL development experience
You must have experience with spreadsheet manipulation in SQL
You must be able to write custom queries to answer any question about the data without leaving a SQL environment.
You must have experience querying and manipulating large datasets
Bachelor’s degree in a technical field or equivalent related work experience
Ability to utilize Fivetran and Stitch for extracting and loading data into BigQuery
Strong understanding of database design
Experience with Web APIs and pulling data from them, preferably in Python, is a plus
Excellent problem-solving and communication skills
Experience querying and manipulating large datasets
Experience with data parsing, scripting, and automation

RESPONSIBILITIES

Design and create database objects, such as tables, stored procedures, and views.
Conduct technical research and data profiling on various data sources, utilizing technologies like Python, APIs, and SQL.
Innovatively propose technical data solutions to address business challenges.
Perform dimensional data modeling and optimize database objects for accessibility, performance, and consistency.
Collaborate with business stakeholders to gather and understand data requirements.
Communicate data concepts, reports, KPIs, and other technical subjects in a business-friendly language.
Develop ETL applications using SQL, Python, etc., for data extraction, transformation, and loading.
Document development standards, KPI calculations, business terms, table diagrams, and other relevant information related to data and reports.
Keep up-to-date with emerging technologies and trends in data engineering
Perform other duties as assigned.

PERKS & BENEFITS

Competitive salary and compensation
Excellent Medical benefits
EOY Profit Sharing
401(k) administration and matching program
Incredible opportunities for growth and development
Amazing in-office culture
Become part of a mission-team making a difference!

HOW TO APPLY

Ready to dive into the fascinating realm of data engineering and take your skills to new heights as a Data Engineer?

If so, we invite you to join our exceptional team, where you'll have the opportunity to unleash the power of data, shape the future of data-driven decision-making, and embark on a fulfilling career journey.

Click the ""Apply Now"" button below to take the first step toward an exciting future.
We can't wait to review your application and explore the endless possibilities of working together.

About Mastermind.com
Mastermind.com, created in partnership by Dean Graziosi and Tony Robbins, is the #1 online platform for people who are looking to market and monetize their knowledge base. We are redefining what ""Self-Education"" means to the world.

Mastermind is not just ""another software"" but an all-in-one platform for Education, Entertainment, Implementation & Community. Mastermind serves people worldwide who seek transformation, fulfillment, and success outside the traditional education path.

The Mastermind software empowers and enables you to implement what you learn & actually get paid, in addition providing a community where you are surrounded by like-minded individuals cheering you on to YOUR NEXT LEVEL.","$110,000 /yr (est.)",Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"RJW Logistics
2.9",2.9,"Bolingbrook, IL",Data Engineer,"Our Software Engineering team is seeking a Data Engineer to join their team! As a Data Engineer your focus will be involved with the engineering and maintenance of RJW’s data warehouse environment. Your goals are to make the company more efficient and provide better customer service through connecting the business and technology teams. The Data Engineer maintains smooth communications between business-critical systems and ensuring easy transitions when changes or maintenance are required. Daily activities will include partnering with the business to determine data solutions, effective methods of data visualization, and executing the plan to create results.
Essential Duties and Responsibilities:
Must be able to prioritize multiple projects, while meeting deadlines and quality expectations
Must be able to adapt quickly in a changing environment
Has strong interpersonal communication skills working with both internal and external customers
Ability to relate or explain technical information to non-industry personnel
Adept at working with cross-functional IT teams to meet customer objectives
Qualifications:
Bachelor's Degree or equivalent experience in Information Systems, Information Technology, Computer Science, Informatics, or a related technology field
3+ years experience with SQL & ETL development
3+ years experience in data warehouse environments.
3+ years experience reporting tools including SSRS and Crystal Reports
3+ years experience with BI tools such as Power BI or Tableau
Respond quickly to identify and resolve issues
Proven critical and analytical thinking skills
Excellent verbal and written communication skills
High level of professionalism
Motivated and results driven attitude
Some after-hours support depending on business requirements
Experience with the following will be viewed as a plus
Transportation Management Systems
Warehouse Management Systems
Both SQL Server and Oracle
Data Democratization","$86,241 /yr (est.)",Unknown,Company - Private,Transportation & Logistics,Shipping & Trucking,#N/A,Unknown / Non-Applicable
"Pomeroy
3.1",3.1,Remote,Data Engineer,"Please note this role is NOT eligible for C2C.
Pomeroy is seeking a Data Software Engineer for a 6 month project with the possibility of extending the contract duration. The ideal candidate has at least 4 years as a Data Engineer and hands on experience with AWS and ETL deployments.
Key Responsibilities:
Design, develop, and deploy robust and scalable data solutions using AWS data analytics services, with a focus on Redshift.
Collaborate with data scientists, analysts, and stakeholders to understand data requirements and translate them into effective ETL processes and reporting solutions.
Create and maintain data pipelines, ensuring data quality, reliability, and performance.
Develop and maintain Python routines/scripts to support ETL processes, data transformation, and reporting needs.
Optimize and fine-tune existing data infrastructure to ensure efficient query performance and cost-effectiveness.
Perform database design and optimization, including schema design and indexing, to support evolving business needs.
Mentor and provide guidance to junior data engineers in best practices for data engineering, AWS, and Python development.
Stay up-to-date with industry trends, emerging technologies, and best practices in data engineering and analytics.
Qualifications:
Senior Engineer with 4+ yrs of Exp in AWS , Redshift and Database design, dev, deploy in reporting & ETL space
Design, Build and operationalize the enterprise data solutions and applications using AWS data analytics with Redshift and Python.
Experience in design and also hands on development of Python routines/scrip
Job Types: Full-time, Contract
Pay: $40.00 - $50.00 per hour
Benefits:
401(k)
Schedule:
8 hour shift
Monday to Friday
Experience:
Data Engineer: 3 years (Required)
AWS: 2 years (Preferred)
ETL: 2 years (Required)
Work Location: Remote",$45.00 /hr (est.),1001 to 5000 Employees,Contract,Information Technology,Information Technology Support Services,1982,Unknown / Non-Applicable
"Foodsmart
2.6",2.6,Remote,Senior Data Engineer,"About us:

We are the world’s largest telenutrition and foodcare solution, backed by a national network of Registered Dietitians and designed to yield consistently healthier food choices, lasting behavior change and long-term results. Foodsmart’s highly personalized, digital platform guides members through a personalized journey to eating well while saving them time and money. Foodsmart seamlessly integrates dietary assessments and nutrition counseling with online food ordering and cost-effective meal planning for the whole family that makes the most of ingredients at home and on the go. With national and regional retail partners across the US now accepting SNAP/EBT, Foodsmart helps bring healthier food within reach to eligible members and can also assist with SNAP enrollment.

Founded in 2010 by CEO Jason Langheier, MD, MPH, Foodsmart has supported over 1.5 million members from over 700 health plan, employer and health system clients, and raised over $70 million in funding from leading strategic and venture investors like Advocate Aurora Health, Blue Cross Blue Shield Massachusetts, Seventure (Natixis), Mayfield and Founder Collective.

Learn more at www.foodsmart.com

About the role:

The Senior Data Engineering is a critical role responsible for constructing and optimizing our data pipeline architecture, collaborating closely with data scientists and analysts to facilitate data-related functionalities. The Senior Data Engineer will be pivotal in designing, building, and maintaining highly scalable data pipelines, optimizing data delivery, and automating data processes. They will work closely with cross-functional teams to ensure efficient data flow and contribute to the success of our data-driven initiatives.

You will
Own the optimization of data delivery for various cross-functional teams.
Design, construct, install, test, and maintain highly scalable data pipelines.
Collaborate closely with data architects, data scientists, and analysts to fulfill data requirements.
Develop automated data processes for cleaning, validation, correction, and data mining.
Identify, implement, and enhance internal process improvements, automating manual processes, and enhancing scalability.

You are
Proactive and act as a driving force for efficient data delivery and infrastructure.
Focused on quality and approach every data-related project with enthusiasm.
Diligent in ensuring secure and compliant handling of data in accordance with relevant regulations.
Collaborative and adept at addressing data-related technical issues and supporting stakeholders' data infrastructure needs.
An expert in data warehouse architecture, data modeling, and automated data pipelines

You have
A minimum of 3 years of experience in a Data Engineering role.
Hands-on experience with data warehouse solutions such as Snowflake, Redshift, or BigQuery.
Advanced SQL knowledge and proficiency in working with relational databases.
Familiarity with data pipeline and workflow management tools like Apache Airflow or Luigi.
Strong analytical skills and the ability to thrive in a fast-paced environment.
Familiarity with healthcare data standards like FHIR and HL7 is advantageous but not mandatory.
Bachelor’s degree in Computer Science, Engineering, Mathematics, or related field; Master’s degree is a plus.

Role: Senior Data Engineer
Level: IC4-IC5
Location: Remote
Base Salary Range: $160,000/yr to $220,000/yr + equity + benefits

Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries at our headquarters in San Francisco, California. Individual pay is determined by work location, job-related skills, experience, and relevant education or training.
Foodsmart is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any other protected class.","$190,000 /yr (est.)",51 to 200 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2019,Unknown / Non-Applicable
"Land Intelligence Inc
1.8",1.8,Remote,Data Engineer,"Who We Are
Land Intelligence is a software technology company serving the commercial real estate industry. We focus on Land Development. We have been recognized as an industry technology leader in providing solutions on a national scale. Our team are visionaries that see a better, faster, and more valuable way to research, finance, and trade land.

Our Culture
We are entrepreneurs first. Which means we manage the people, processes and product. We create new ways of doing things to drive value. We are builders and growth minded. Our leadership team has been recognized as a Best Places to work in the industry nationally. Our team drives for personal and professional development, as personal growth is instrumental to our success. Your learning will be supported by specialized in-house training programs and mentoring by the industry’s leading experts, many of whom are our investors and strategic partners.
Job Overview
Land Intelligence is seeking a savvy Data Engineer to join our growing team and help us continue to enhance our SaaS platform, LandSUITE®. The hire will be responsible for expanding and optimizing our data and data pipeline architecture to support product development and internal tools. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. The right candidate will be excited by the prospect of re-designing our company's data architecture to support our next generation of products and data initiatives.
Responsibilities
Create and maintain optimal data pipeline architecture
Assemble large, complex datasets that meet business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies
Build analytics tools that use the data pipeline to provide actionable insights into user behavior and market trends
Work with stakeholders including the executive and product development teams to assist with data-related technical issues and support their data infrastructure needs
Keep our data separated and secure across AWS regions
Create data tools for analytics and team members that assist them in building and optimizing LandSUITE® into an innovative industry leader
Qualifications
We are looking for a candidate with 5+ years of experience in a Data Engineer role who has attained a degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Strong analytic skills related to working with unstructured datasets
Build processes supporting data transformation, data structures, metadata, dependency and workload management
A successful history of manipulating, processing and extracting value from large, disconnected datasets
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores
Strong project management and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment
Experience with the following software/tools:
Experience with relational SQL and NoSQL databases, including Postgres, MySQL, and Cassandra
Experience with data pipeline and workflow management tools
Experience with stream-processing systems
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with object-oriented/object function scripting languages: Python, Java
We are a startup, but this isn't our first time doing this. As a result, you can get the thrill of working at a startup, with the resources of a publicly traded company. We offer a best-in-class benefits package, as we are a Professional Employment Organization (PEO) with our partner Insperity that includes medical, vision, dental and life insurance. Our 401 (k) program offers an employer match, along with a 401(k)-profit sharing and performance-based bonuses. • Generous paid time off

Land Intelligence is an EOE/Affirmative Action Employer M/F/D/V. If you are interested in applying for employment and need special assistance to apply for a posted position, please send an e-mail to careers@landintelligence.net.",#N/A,1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Arthur Grand Technologies Inc
3.8",3.8,"Columbus, OH",AWS Data Engineer,"Position: AWS Data Engineer(10+years)
Location: Columbus, OH
Duration: Contract Day 1 Onsite
Must Have:
BS/BA degree or equivalent experience
General: Strong organizational, problem-solving, and critical thinking skills; Strong documentation skills
Coding: Proficiency in Java
Cluster Computing frameworks: Proficiency in Spark and Spark SQL
AWS Data Services: Proficiency in Lake formation, Glue ETL (or) EMR, S3, Glue Catalog, Athena, Kinesis (or) MSK, Airflow (or) Lambda + Step Functions + Event Bridge
Data De/Serialization: Expertise in at least 2 of the formats: Parquet, Iceberg, AVRO, JSON-LD
AWS Data Security: Good Understanding of security concepts such as: Lake formation, IAM, Service roles, Encryption, KMS, Secrets Manager
Good to Have:
Linux Scripting, Jenkins
DevOps: Git, CI/CD, JIRA, TDD
About Arthur Grand Technologies:
Arthur Grand Technologies is a leading provider of staffing and technology consulting services. Our company is managed by a team of professionals who have worked for big 5 consulting firms for 20+ years. We are a minority-owned staff augmentation and technology consulting company.
At Arthur Grand Technologies, we value our employees & contractors and strive to provide them with challenging, interesting work, market-relevant benefits, and opportunities for professional growth. If you have the necessary qualifications, and are excited to join a dynamic team, please send your resume to indhu.s@arthurgrand.com for immediate consideration.
Thank you for considering Arthur Grand Technologies. We look forward to hearing from you soon.
Best Regards,
Indhu
E: indhu.s@arthurgrand.com
Arthur Grand Technologies Inc
www.arthurgrand.com
Arthur Grand Technologies is an Equal Opportunity Employer (including disability/vets)
Job Type: Contract
Work Location: In person","$103,060 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Software Development,2012,Unknown / Non-Applicable
"Coveros, Inc.
3.4",3.4,"Fairfax, VA",Data Engineer,"A Great Place to Share Your Passion and Make a Difference
Coveros helps organizations modernize their software development process by embracing agility, while integrating application security and software quality into the software lifecycle. We provide consulting, coaching, and learning opportunities in Agile, DevOps, AppSec, and Test Automation to enterprises, teams, and individuals. We aim to be Trusted Advisors to our clients who are undergoing change.
Culture at Coveros
As a remote-first company, we provide a stimulating, friendly, and casual work environment, where we live our core values of Client Focused Delivery, Openness, Shared Success, and Building Strong Relationships. In an atmosphere of continuous growth and learning, we invite employee input and employ active mentoring.
Coveros is an equal opportunity employer, dedicated to a policy of non-discrimination in employment on any basis including age, sex, color, race, creed, national origin, religion, marital status, sexual orientation, political belief, or disability.
The Opportunity
Coveros employees share a passion for helping organizations advance and accelerate their software development and security processes. We celebrate great work and teammates who consistently give their best. Our remote team of collaborative experts is expanding and adding an experienced, quality-obsessed Data Engineer as its newest member.
As an exceptional data engineer, you will fulfill a core position on our consulting team. Through your dedication and knowledge, you will help clients replace time-consuming, manual processes in order to make informed, real-time, intelligent decisions.
For a skilled and dedicated data nerd who abhors mediocrity, this opportunity positions you to lead the team in discovering truth and finding meaning in data. An ideal addition to our team is a hands-on engineer who is proficient in data management and governance standards. Equally important, we seek someone with strong interpersonal skills who is comfortable working cross-functionally across internal teams as well as directly with end users and client platform SMEs.
A curious and eager problem solver will thrive in our environment where we value the delivery of high-quality data solutions. You shine when figuring out complex problems and providing smart, simple solutions to them. And always, while multiple answers to a problem may exist, you capably lead the team through constructive dialogue to implement the best path forward.
Qualifications
US Citizenship is required – Due to the nature of this role supporting U.S. government organizations, individuals who are not U.S. Citizens will not be considered.
Required
Bachelor's degree in Computer Science, Mathematics or related technical field
3-5 years of experience in programmatically transforming data
RDBMS experience
Advanced SQL programming experience
Python programming experience
Knowledge and use of Apache Spark
Proficient use of common data formats such as CSV, XML, and JSON
Strong analytical ability and attention to detail
Ability to work independently with little supervision
A drive to create sustainable solutions that solve hard problems
Nice-to-Have
Experience using Amazon Web Services
Experience with OpenSearch
Experience automating ETL pipelines
Hands-on knowledge working with large amounts (multiple terabytes) of data
Experience in (or exposure to) the nuances of a startup or other entrepreneurial environment
Any specific experience in MLOps is a plus!
Responsibilities
Define and lead the data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage.
Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository.
Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison, and classification.
Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts.
Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency.
Work across functional teams to understand advanced statistical, machine learning, and text processing models and incorporate them into the existing data engineering infrastructure.
Actively collaborate with the DevOps team to automate processes where possible.
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures and, using non-technical language, articulate techniques and results.
We firmly believe that past performance is the best indicator of future performance. If you thrive in a fast-paced environment, have a bias toward action, and care about solving technical problems in the national security domain, apply today for consideration.
Coveros is a melting pot of seasoned IT and business professionals from Fortune 500 and leading consulting companies who deliver high value on challenging client engagements. We hire great people and provide room and support for employees' professional growth. For talented computer scientists and software engineers who share our passion for software, joining Coveros provides an opportunity to work alongside and to learn from brilliant, technical software engineers.
We believe that employees are our greatest asset. Our business model and benefits package reflect that belief.
Competitive base salaries
Company-wide profit sharing plan
401K with matching percentage
Comprehensive health benefits, including dental and vision
Generous paid time off and holidays plan
Basic Life & Personal Accident Insurance and Disability Insurance
Voluntary Life and Personal Accident Insurance
Tuition Reimbursement, plus comprehensive competency-based online skill development training programs
Adoption Assistance
Apply today and move toward a Coveros career where management values you and actively looks to help you advance your skills.
By submitting your application, you are also agreeing to receive future company news, offers, and product communications from Coveros/TechWell. You may unsubscribe at anytime.","$94,726 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Software Development,2008,Unknown / Non-Applicable
"Mechanics Bank
3.7",3.7,"Irvine, CA",Associate Data Engineer,"Mechanics Bank is currently searching for an Associate Data Engineer to join our team. Here at Mechanics Bank, we value connection, partnership, long term relationships and working together in person. This role will be working on-site at our Irvine location.
The Associate Data Engineer plays a crucial role in supporting our data infrastructure and contributing to the development and maintenance of data pipelines. Responsibilities will include data ingestion, transformation, and integration, as well as assisting in the design and optimization of databases and data storage solutions.
What you will do:
Builds systems and infrastructures that collect and process data according to company needs and goals. Builds, evolves and scales out infrastructure to ingest, process and extract meaning out data.
Designs, develops and implements statistical models to carry out various novel aspects of classification and information extraction from data.
Leverages existing data infrastructure to fulfill all data-related requests, perform necessary data housekeeping, data cleansing, normalization, hashing, and implementation of required data model changes. Analyzes data to spot anomalies, trends and correlate similar data sets
Troubleshoots data pipeline issues and work on identifying and resolving data quality problems.
Designs, develops and implements natural language processing software modules. Troubleshoots problems, identifies possible solutions, and resolves accordingly.
Who you are:
Bachelor’s Degree preferred.
Minimum 2 years related experience required. Familiarity with programming languages such as Python, Java, or Scala; and experience with data integration tools and technologies (e.g., Apache Spark, Azure Data Factory, etc.).
Understanding of data engineering concepts, including ETL processes, data modeling, and database design.
Familiarity with programming languages such as Python, Java, or Scala.
Basic knowledge of Microsoft SQL and experience with relational databases.
Experience with cloud platforms (e.g., AWS, Azure, GCP) and big data technologies is a plus.
Strong analytical and problem-solving skills, with a keen attention to detail.
Excellent communication skills and the ability to work collaboratively in a team environment.
Eagerness to learn and adapt to new technologies and tools.
#LI-AS1
Pay Range: $64,480 - $83,700
Final compensation package will be determined by the work experience, education, and/or skill level of the applicant along with internal equity and alignment with geographic market data.
Mechanics Bank is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, religion, national origin, age, genetic information, veteran status, or on the basis of disability, gender identity, sexual orientation or other bases prohibited by applicable law.
Please view Equal Employment Opportunity Posters provided by OFCCP
here
.
To learn more about Mechanics Bank’s California privacy and security policies, including your right to a Notice At Collection as a California Resident, please visit
https://www.mechanicsbank.com/California-Consumer-Residents","$74,090 /yr (est.)",1001 to 5000 Employees,Company - Private,Financial Services,Banking & Lending,1905,Unknown / Non-Applicable
State of California,#N/A,Remote,Data Warehouse Engineer,"***Candidate needs to be located in the Pacific Time Zone
Mandatory Qualifications
7 years of experience building end-to-end data solutions using Data models, Data pipelines and BI products.
Five (5) years of experience installing, maintaining, and administrating Microsoft SQL
Data Warehouse concept and architectures, Online Analytical Processing (OLAP) technologies, Star-schema, Snowflake schema and Aggregation etc
5 years of experience using Azure platform, in the use of Azure Data Factory, Azure Data Lake, Azure SQL Data Warehouse, Azure SQL, and Azure App Service
Experience using Data Warehousing/ETL tools (SQL Server, SSIS, SSRS, SSAS)
Experience designing and implementing data extract using Replication, Stored Procedures and SQL Server Integration Services (SSIS)
Experience with stored procedures creation, debugging, optimization and database performance tuning and monitoring
Experience in SQL Server 2016 in-built performance tuning functionalities.
Producing requirements documents, systems architecture and interfaces, data model diagrams, configuration management documents etc.
A couple of years experience in some of the following are required:
Supporting enterprise solutions within a health care environment
Experience with Organizational change management
SQL Server/Oracle database development/administration
PowerBI development and administration
Experience using System Center Operations Manager (SCOM) and Idera Monitoring tools.
Job Types: Full-time, Contract
Expected hours: 40 per week
Schedule:
Monday to Friday
Experience:
SQL: 5 years (Required)
Data warehouse: 5 years (Required)
Azure: 5 years (Required)
Database administration: 5 years (Preferred)
Change management: 5 years (Preferred)
Cloud development: 5 years (Required)
ETL: 5 years (Required)
Business intelligence: 5 years (Required)
Work Location: Remote",$90.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Excelgens
4.6",4.6,"Toronto, OH",Data Engineer,"Client- NASDAQ
Job Type- Contract (1 year)
Location- Toronto/Montreal (Hybrid)
Job Description:
- Experience with large databases cleaning processes = strong understanding of the data, Excel manipulations
- Build and maintain a scalable data infrastructure, complex calculation (Data engineering - Python)
- Capacity to run strong quality assessment processes
- Data visualization understanding (Data science)
- Develop processes allowing our ESG platform to grow and gain velocity
- Experience working in team (with project manager) – strong communication skills
- Client facing capabilities, delivers a best-in-class customer experience – technical support.
Nice to have:
- Use to work in a start-up environment - fast-paced environment
- Use to Agile methodology: sprints
- ESG interest, knowledge!
Job Type: Contract
Salary: $40.00 - $50.00 per hour
Experience level:
3 years
Schedule:
8 hour shift
Ability to commute/relocate:
Toronto, OH 43964: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
Working experience in start-up/fast paced environment
Experience:
Python: 3 years (Required)
Data science: 3 years (Required)
Data cleaning: 3 years (Required)
Work Location: In person",$45.00 /hr (est.),51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2011,$5 to $25 million (USD)
"APPIC Solutions LLC
5.0",5.0,"Foster City, CA",Data Engineer,"Location: Foster City, CA (Onsite DAY ONE)
Mid-level Data Engineer
About the Role:
Our client is looking for a highly skilled and experienced Senior Data Engineer to join our team. You will play a crucial role in building and maintaining data pipelines and architecting data models. You will collaborate with cross-functional teams to understand data requirements and translate them into technical solutions. You will be the go-to person for any data requirement for the team.
Day to Day Responsibilities:
● Develop and maintain robust, scalable, and efficient data pipelines using SQL/Python/Spark, primarily within the AWS Cloud Infrastructure
● Design and implement data models and architectures to support data processing, analysis, and reporting needs.
● Collaborate with cross-functional teams to understand data requirements and translate them into technical solutions.
● Optimize and tune data pipelines and queries for improved performance and reliability.
● Ensure data quality and integrity through rigorous testing, monitoring, and troubleshooting.
● Implement data security measures and best practices to protect sensitive information. ● Mentor and provide technical guidance to junior data engineers, fostering their growth and development.
● Stay updated with industry trends, emerging technologies, and best practices in data engineering.
Must Have:
● Bachelor's degree in Computer Science, Engineering, or a related field. ● Minimum of 4 years of experience in data engineering, with a focus on SQL and Python.
● Strong proficiency in SQL for data extraction, transformation, and loading (ETL) processes.
● Expertise in Python programming language for data manipulation, scripting, and automation tasks.
● Solid understanding of data modeling concepts and experience in designing efficient and scalable data architectures.
● Experience with AWS services, such as EC2, S3, Lambda, Redshift, Glue, or Athena, for building data pipelines.
● Familiarity with version control systems, such as Git, for managing code repositories. ● Proficiency in optimizing and fine-tuning SQL queries for performance and efficiency. ● Strong problem-solving skills and ability to troubleshoot complex data-related issues. ● Excellent communication and collaboration skills to work effectively with
cross-functional teams.
Nice to Have:
● Master's degree in Computer Science, Engineering, or a related field. ● Experience with big data technologies, such as Hadoop, Spark, or Kafka. ● Knowledge of data warehousing concepts and experience with tools like Snowflake or Google BigQuery.
● Familiarity with data visualization tools, such as Tableau or Power BI, for creating insightful reports and dashboards.
● Understanding of machine learning concepts and experience with ML pipelines and frameworks.
● Certification in AWS or other relevant technologies.
● Active participation in data engineering communities, conferences, or open-source projects.
Job Types: Full-time, Contract
Pay: $45.00 - $50.00 per hour
Benefits:
Dental insurance
Health insurance
Vision insurance
Schedule:
8 hour shift
Ability to commute/relocate:
Foster City, CA: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
This role is onsite, day one in Foster City, CA. Please confirm that you are within the area or willing to relocate.
Experience:
Data engineering: 4 years (Required)
SQL: 4 years (Required)
Python: 4 years (Required)
ata manipulation, scripting, and automation: 4 years (Preferred)
AWS services: 4 years (Required)
Work Location: In person",$47.50 /hr (est.),1 to 50 Employees,Company - Private,Information Technology,Software Development,2017,$1 to $5 million (USD)
"Teaching Strategies, LLC
4.3",4.3,Remote,Senior Data Engineer (Remote),"Be a Part of our Team!
Join a working family that is dedicated to the mission of the work we do!
Teaching Strategies is an innovative edtech organization focused on connecting teachers, children, and families. As front runners in the early childhood education market, we build dynamic, top-quality digital products that integrate all of the essential elements of a high-quality solution: curriculum, assessment, professional development, and family engagement. We are building a team of results-oriented individuals who will thrive in a collaborative, work-hard/play-hard culture. We pride ourselves on the impact we have on the early childhood field through supporting teachers who are doing the most important work there is, teaching children to become creative, confident thinkers.
Position Overview
The Senior Data Engineer will be a hands-on key player in our Data Infrastructure and Analytics team, not only designing and architecting but also actively coding to develop, manage, and optimize our data architecture, pipelines, and data sets. This role will require you to get your hands dirty with code, ensuring the availability, accuracy, and consistency of our data ecosystem. We are looking for someone who possesses a profound passion for data, demonstrates exceptional problem-solving skills, and can articulate intricate technical details with clarity.
Specific Roles & Responsibilities:
Design, construct, install, and maintain large-scale processing systems and other infrastructure.
Set up complex, high volume, scalable data pipelines to process structured and unstructured data.
Consolidate our disparate data sources into our data lake and transform data for analytics and data science purposes.
Collaborate with data scientists and architects on several projects.
Improve data reliability, efficiency, and quality. Enhance data quality through testing, tooling, and continuously evaluating performance.
Work on expanding and optimizing our data and data pipeline architecture.
Conduct data analysis and troubleshoot data-related issues in real-time.
Keep up to date with state-of-the-art data processing technologies and practices.
Document intricate procedures, architectures, and design strategies.
Qualifications:
Bachelor's degree in computer science, engineering, or a related field. Master's degree preferred. Seven (7) or more years of experience in a data engineering or data system development role.
Experience in building and optimizing 'big data' pipelines and architectures.
Proficiency in SQL, Python, Scala, and other data processing languages.
Experienced with big data tools like Hadoop, Spark, PySpark, Kafka, etc.
Solid grasp on data modeling, data warehousing, and ETL techniques.
Advanced expertise in relational databases.
Experience supporting machine learning operations and aid in the management of the entire machine learning lifecycle
Strong collaboration ethos with outstanding verbal and written communication abilities.
High attention to detail and proven problem-solving prowess.
Why Teaching Strategies
At Teaching Strategies, our solutions and services are only as strong as the teams that create them. By bringing passion, dedication, and creativity to your job every day, there's no telling what you can do and where you can go! We provide a competitive compensation and benefits package, flexible work schedules, opportunities to engage with co-workers, access to career advancement and professional development opportunities, and the chance to make a difference in the communities we serve.
Let's open the door to your career at Teaching Strategies!
Some additional benefits & perks while working with Teaching Strategies
Teaching Strategies offers our employees a robust suite of benefits and other perks which include:
Competitive compensation package, including Employee Equity Appreciation Program
Health insurance benefits
401k with employer match
100% remote work environment
Unlimited paid time off (which includes paid holidays and Winter Break)
Paid parental leave
Tuition assistance and Professional development and growth opportunities
100% paid life, short and long term disability insurance
Pre-tax medical and dependent care flexible spending accounts (FSA)
Voluntary life and critical illness insurance
Teaching Strategies, LLC is committed to creating a diverse workplace and is proud to be an equal opportunity employer of Minorities, all Genders, Protected Veterans, and Individuals with Disabilities.",#N/A,201 to 500 Employees,Company - Private,Education,Primary & Secondary Schools,1988,$100 to $500 million (USD)
Expression,#N/A,"Washington, DC",Data Engineer,"We are looking for a mid-level Data Engineer to join our team and add to the continued growth of our Data Science division. This position will work in a team led by a principal/senior data engineer on tasks related to designing and delivering high-impact data architecture and engineering solutions to our customers across a breadth of domains and use cases.
Location:
Hybrid with the expectation of 40% time onsite (Annapolis, MD) when needed
Local (DC/VA/MD Metropolitan area or Annapolis, MD) is required
Relocation assistance available for highly qualified candidates
Security Clearance:
US Citizenship required
Ability to obtain Secret Clearance or higher
Responsibilities:
Developing, testing, and documenting software code for data extraction, ingestion, transformation, cleaning, correlation, and analytics
Participating in end-to-end architectural design and development lifecycle for new data services/products, and making them operate at scale
Participating in cross-functional team collaboration to understand customer requirements, design prototypes, and optimize existing data services/products
Demonstrating Data Science excellence in the teams you work with across the organization, and mentoring junior members in the Data Science division
Participating in research, case studies, and prototypes on cutting-edge technologies and how they can be leveraged
Required Qualifications:
2+ years of experience bringing databases, data integration, and data analytics/ML technologies to production with a Bachelor's degree in Computer Science/Data Science/Computer Engineering or relevant field
Proficient in developing software code in one or more programming languages (Python, JavaScript, Java, C++, etc.)
Proficient in databases (SQL, NoSQL, Graph, etc.) and data architecture (Data Lake, Delta Lake)
Preferred Qualifications:
Experience with AWS solutions
Knowledgeable in machine learning/AI methodologies
Experience with one or more SQL-on-Hadoop technology (Spark SQL, Hive, Impala, Presto, etc.)
Experience in short-release cycles and the full software lifecycle
Experience with Agile development methodology (e.g., Scrum)
Strong writing and oral communication skills to deliver design documents, technical reports, and presentations to a variety of audiences
Benefits:
Expression Networks offers competitive salaries and benefits, such as:
401k matching
PPO and HDHP medical/dental/vision insurance
Education reimbursement
Complimentary life insurance
Generous rollover PTO and 11 days of holiday leave
Onsite gym facility and trainer
Commuter Benefits Plan
In office Cold Brew Coffee
About Expression Networks
Founded in 1997 and headquartered in Washington DC, Expression provides data fusion, data analytics, software engineering, information technology, and electromagnetic spectrum management solutions to the U.S. Department of Defense, Department of State, and national security community. Expression's “Perpetual Innovation” culture focuses on creating immediate and sustainable value for our clients via agile delivery of tailored solutions built through constant engagement with our clients. Expression was ranked #1 on the Washington Technology 2018's Fast 50 list of fastest-growing small business Government contractors and a Top 20 Big Data Solutions Provider by CIO Review.

Equal Opportunity Employer/Veterans/Disabled","$90,133 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Tri Counties Bank
3.4",3.4,"Chico, CA",Data Engineer (Remote a Possibility),"The hiring range for this opportunity is $89,000 - $135,000 annually along with incentive opportunities, creating a competitive total compensation package based on our pay scale, and may be modified by location and is commensurate with qualifications and experience.
POSITION SUMMARY
The Data Engineer manages the entire back-end development life cycle for the Bank’s data warehouse. The implementation of Extract, Transform, Load (ETL) procedures, cube building for database and performance management, and dimensional design of the table structure are all tasks that fall under the purview of the Data Engineer. The position collaborates closely with the Product Management, other Data Engineers, and Analyst teams to achieve insights, provide the organization with valuable data solutions, and enable reliably informed strategic decisions. Data Engineers must be able to work independently on projects with little oversight from senior leadership. They also need strong communication skills and effectively convey their ideas to senior leadership and other members of the team.
MAJOR RESPONSIBILITIES
Create data models used to extract information from various sources and store it in a usable format.
Maintain data integrity by designing backup and recovery procedures.
Identify opportunities to enhance performance by improving database structure or indexing methods.
Conduct research to identify new technologies that can be applied to current projects.
Deliver reports, dashboards, and custom solutions for various business lines’ critical requirements.
Lead all aspects of data engineering from delivery planning, estimating and analysis, all the way through to data architecture and pipeline design, delivery, and production implementation.
Analyze data to find patterns or insights that can be used to develop strategies or make business decisions.
Develop new dashboards using existing data sets to create new products or improve existing services.
Maintain existing applications by updating existing code or adding new features to meet new requirements.
Design and implement security measures to protect data from unauthorized access or misuse.
Recommend infrastructure changes to improve storage capacity or performance.
Analyze and organize raw data, build data systems and pipelines.
Evaluate business needs, objectives, interpret trends and patterns.
Conduct complex data analysis and report on results.
Prepare data for prescriptive and predictive modeling.
Build algorithms and prototypes.
Combine raw information from different sources.
Explore ways to enhance data quality and reliability.
Identify opportunities for data acquisition.
Collaborate with data analysts and architects on several projects.
Contribute and maintain a data dictionary.
SECONDARY RESPONSIBILITIES
Maintain a current understanding of stated procedures and policies, including regulatory compliance issues as it relates to all pertinent FDIC, DFPI, and other Federal security regulations related to Data Governance and Data Security.
Maintain a current understanding of Bank policies and procedures in compliance with all federal and state laws, including but not limited to Bank Secrecy Act (SARs, CIP, OFAC), Information Security (GLBA), Privacy Laws (CCPA), Identity Theft Red Flags, Financial Elder Abuse Reporting, and any other applicable regulations that may be specific to your job duties.
Understand data privacy and data security concepts and experience with delivering data-related projects.
Ability to communicate across disciplines (ex. security, privacy, legal, risk).
OTHER RESPONSIBILITIES
Firm understanding of Data Governance, specifically in the banking and financial sector.
Review, comprehend and maintain a current knowledge of all applicable laws, rules and regulations governing assigned area of responsibility.
Extensive experience managing corporate data warehouse programs within medium to large organizations.
Knowledge of evolving and current threats including Cyber terrorism.
Maintain confidentiality regarding all customer and employee information.
Perform other duties as assigned.
EDUCATION, EXPERIENCE AND OTHER SKILLS REQUIRED
Bachelor’s degree in Information Security, Information Technology or related field, strongly preferred.
5+ years of proven data and performance engineering experience.
Expert in SQL.
Python experience
Snowflake experience (developing ETL pipelines)
Data Bricks experience
Writing Workflows and Notebooks in python/scala/sql
Knowledge of AWS
A proven track record of developing custom-built data/analytics solutions and experience in supporting large scale programs.
Experience with system analysis, data analysis or programming, using a variety of computer languages and procedures.
Experience working in Agile environments.
Banking experience strongly preferred.
Experience leading complex regulatory projects.
Experience across multiple bank departments desired.
Knowledge of laws and regulations impacting data protection and confidentiality, integrity, and availability of systems and data in the financial industry such as Sarbanes-Oxley, and state regulations.
Effective interpersonal skills with the ability to work effectively with individuals and groups at all organizational levels.
Leadership ability to provide guidance, coaching and training to staff and to other Bank employees.
Ability to take initiative and prioritize tasks, good time-management, problem prevention and problem-solving skills.
Proven track record of success demonstrating leadership and management skills.
Effective verbal and written communication skills, including presentation skills.
COMPANY PROFILE
Established in 1975, Tri Counties Bank is a wholly-owned subsidiary of TriCo Bancshares (NASDAQ: TCBK) headquartered in Chico, California, with assets of nearly $10 billion and more than 45 years of financial stability. Tri Counties Bank provides a unique brand of Service With Solutions® for communities throughout California with a breadth of personal, small business and commercial banking services, plus an extensive branch network, more than 37,000 surcharge-free ATMs nationwide, and advanced online and mobile banking.
Tri Counties Bank remains strong and profitable through our top-down commitment to our core values, sound business principles and responsible lending practices.
Our success is also based on our community engagement. We still believe in the vision of the helpful and caring community banker. As we grow and serve more communities, we become more involved, providing substantial financial and volunteer support to local economies and community organizations. We applaud our employees who roll up their sleeves to work and volunteer for a greater good in our communities.
Tri Counties Bank hires individuals who are qualified for the role and who represent the communities in which we serve. We look to place people in positions where they can best utilize their abilities and strengths, and where they are able to grow with the Bank.
Tri Counties Bank is an Affirmative Action and Equal Opportunity Employer, Race/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disability/Veteran.","$112,000 /yr (est.)",501 to 1000 Employees,Company - Public,Financial Services,Investment & Asset Management,1975,$100 to $500 million (USD)
"Geisinger
3.5",3.5,"Danville, PA",Data Engineer Associate,"Job Summary
Responsible for building and maintaining modules for ingesting, processing and integrating real time and batch data in the organization’s data environment(s).
Job Duties
Builds data ingestion pipelines for the organization’s data environment(s).
Programming for a distributed computing environment using Java, Scala or similar object-oriented programming languages.
Programming data processing and integration algorithms inside of the organization’s technology stack.
Leverages a variety of tools, technologies, and programming languages to complete tasks. These include but not limited to: Java, SQL/Hive, Red Hat Linux, Hadoop/Cloudera, Microsoft SQL Server, Docker, and Git/Source Control.
Coordinates projects and responsible for timely and accurate execution.
Collaborates and participates in the design and implementation of various projects.
Involves high-level participation in the design and management of a computational infrastructure for different purposes including applied medical research.
Collaborates with other technology team members, clinicians and researchers on projects requiring data and analytic services.
Works closely with data architects to define and execute an enterprise data architecture for complex healthcare data flows.
Writes code for parallel computing.
Develops new programs and responsible for moving existing code to high performance distributed systems code.
Responsible to document all changes completed on the system within designated timeframes.
Responsible for following department coding/programming guidelines to produce efficient routines.
Provides preliminary code review, testing, debugging, and general testing instructions.

Work is typically performed in an office environment. Accountable for satisfying all job specific obligations and complying with all organization policies and procedures. The specific statements in this profile are not intended to be all-inclusive. They represent typical elements considered necessary to successfully perform the job.

Position Details

Education
Bachelor's Degree-Technology Related Degree (Required)
Experience
Minimum of 2 years-Information Technology (Preferred)
Certification(s) and License(s)

OUR PURPOSE & VALUES: Everything we do is about caring for our patients, our members, our students, our Geisinger family and our communities. KINDNESS: We strive to treat everyone as we would hope to be treated ourselves. EXCELLENCE: We treasure colleagues who humbly strive for excellence. LEARNING: We share our knowledge with the best and brightest to better prepare the caregivers for tomorrow. INNOVATION: We constantly seek new and better ways to care for our patients, our members, our community, and the nation. SAFETY: We provide a safe environment for our patients and members and the Geisinger family We offer healthcare benefits for full time and part time positions from day one, including vision, dental and domestic partners. Perhaps just as important, from senior management on down, we encourage an atmosphere of collaboration, cooperation and collegiality. We know that a diverse workforce with unique experiences and backgrounds makes our team stronger. Our patients, members and community come from a wide variety of backgrounds, and it takes a diverse workforce to make better health easier for all. We are proud to be an affirmative action, equal opportunity employer and all qualified applicants will receive consideration for employment regardless to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or status as a protected veteran.",#N/A,10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1915,$500 million to $1 billion (USD)
"Ora Apps
4.4",4.4,"Herndon, VA",Quantitative Data Engineer,"Job Title: Quantitative Data Engineer
Location: Remote
Duration: Long Term
Rate: $52/hr. on W2 All Inclusive
What We’re Looking For:
Bachelor/Master’s degree in Computer Science, Information Systems, or related field
Strong analytical, data and programming skills (Python/SQL/NoSQL/JavaScript)
3+years of experience with large data sets ETL and techniques to architect them for performance, experience using alternative unstructured data is a plus
1+ year of experience with cloud computing services, AWS preferred
Aptitude for designing infrastructure, and data products for Quant/Data Scientists is a plus
Ability to work effectively in an agile environment with numerous stakeholders on complex research and new development projects
A genuine interest in investment strategies, equities, and fixed income. Asset management industry experience is a plus.
Strong verbal and written communication skill, must be a team player
Job Type: Full-time
Salary: $52.00 per hour
Compensation package:
1099 contract
Experience level:
5 years
6 years
Schedule:
8 hour shift
Experience:
Quantitative Data Engineer: 5 years (Preferred)
Work Location: Remote",$52.00 /hr (est.),Unknown,Company - Private,Information Technology,Computer Hardware Development,#N/A,$5 to $25 million (USD)
"Kipu Health
3.7",3.7,United States,Data Engineer,"Kipu is bettering the behavioral health landscape, helping treatment centers achieve the best outcomes and empowering patients and caregivers on every step of the recovery journey. Join us in our work to advance behavioral health care in our communities.
Our innovative solutions support providers in treating addiction, eating disorders and many other behavioral health conditions. Our EMR, CRM and revenue cycle solutions help behavioral health facilities succeed in managing their patients’ entire care journey, but it’s through our people that we truly make a difference.

Your Responsibilities
Acquiring data from primary or secondary data sources and maintaining Enterprise Data Warehouse, Data Marts and Data Lakes.
Write complex SQL queries, with SQL standard, or T-SQL, combining multiple sets of data.
Create timely and accurate results using BI (QuickSight, PowerBI, etc.) Dashboards and Visualizations.
Developing and implementing data models.
Interpret data, analyze results using visualizations techniques and dashboards.
Proficient with database systems, such as Postgres and SQ SQL Server, hosted in multiple cloud solutions like AWS, Heroku, Azure, or on-premises.
Support integration of embedded BI solutions using AWS services such as API Gateway, Lambda, and others.

Your Qualifications
Proven industry experience as a data engineer writing complex SQL queries, with SQL standard, or T-SQL, combining multiple sets of data
Technical expertise in designing and developing scalable data warehouse
Strong knowledge of and experience with data visualizations solutions (PowerBI, QuickSight, etc.), databases (Postgres, AWS Redshift, SQL Server), programming and Excel.
Knowledge of AWS services: S3, Lambda, Kinesis Firehose, Kinesis Streams.
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, dashboard designs and presenting findings
BS in Mathematics, Computer Science, Information Management, or Statistics.

Benefits & Compensation
Highly competitive salary based on your local market’s compensation data.
Unlimited paid time off.
11 Paid Holidays.
Health, Dental, Vision, Disability, and Life Insurance.
Parental Leave.
Pet Insurance.
Employee Career Path Program.
401(K) with Company Match.

Kipu Promise
In an environment of rapid change, millions are struggling to cope. Kipu is here to help. Having shaped the industry for 10 years, today we focus on advancing our New Vision for the behavioral health ecosystem, evolving how it operates, interacts, communicates, and heals.
We are an equal-opportunity employer and highly value diversity at our company. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, gender identity, or disability status.",#N/A,201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2012,Unknown / Non-Applicable
Stone Alliance Group,#N/A,"New York, NY",Data Engineer,"We are partnering with our client to assist with their search for a Data Engineer. Our client is an independent, national nonprofit dedicated to transforming the lives of children and families struggling with mental health and learning disorders. They work to deliver the highest standards of care, advance the science of the developing brain, and empower parents, professionals, and policymakers to support children when and where they need it most.
As a Data Engineer, your primary responsibilities will encompass designing, developing, and maintaining pipelines for efficient data storage and retrieval. You will create pipelines for data extraction, transform data to standardized formats, and load these data into databases. You will work with vital neuroimaging, physiological, and phenotypic research data, ensuring data quality, security, and compliance with privacy regulations. You will develop strategies and implement processes for data integration to unify diverse data sources. You will work on large open-science initiatives and closely collaborate with research staff, the IT team, and external collaborators. Your efforts will greatly contribute to our mission of advancing the field of mental health research.
Responsibilities:
Design, develop, and maintain data pipelines for efficient storage and retrieval of data.
Create pipelines for data transformation.
Implement data integration strategies to unify diverse data sources.
Ensure data quality, security, and compliance with privacy regulations.
Perform quality assurance of pipelines/processes.
Create interactive visualizations and dashboards to communicate data insights.
Write documentation and relevant text for scientific, clinical, or public dissemination of knowledge.
Qualifications:
Minimum requirements:
BSc in Computer Science, Engineering, or relevant field.
Minimum of 5+ years of experience in Extract, Transform, Load (ETL) processes.
Expertise in scripting languages (Python, Bash, R, or Matlab) to create processes and pipelines to manipulate, clean, and analyze large datasets.
Experience working with database management languages (SQL, NoSQL).
Knowledge of cloud-based platforms and data storage solutions.
Experience with Linux environment and code versioning.
Experience with data visualization tools to communicate insights effectively.
Understanding data privacy regulations (HIPAA, GDPR) and research ethics.
Experience using cloud-based solutions (AWS, GP, or Azure).
Analytical Thinking and Problem-Solving Skills.
Strong verbal, written, and visual communication skills with a team-oriented mindset.
Preferred additional qualifications:
MS or PhD in Computer Science, Engineering, or relevant field.
Knowledge of data analysis and signal processing.
Knowledge in creating visualization dashboards.
Team management experience.
Familiarity with neuroimaging data (EEG or MRI).
Knowledge of writing code in PHP and HTML.
The anticipated salary range for this position is $119,000 to $147,000 annually. Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography.
Special Considerations:
All new hires must be vaccinated and must stay up to date with vaccines against the COVID-19 virus unless they have been granted a reasonable accommodation for religion or disability. If you are offered employment with our client, this requirement must be met by your date of hire, unless a reasonable accommodation for exemption is received and approved by our client.
Our client is an equal opportunity employer and does not discriminate in employment based on race, religion (including religious dress and grooming practices), color, sex/gender (including pregnancy, childbirth, breastfeeding or related medical conditions), sex stereotype, gender identity/gender expression/transgender (including whether or not you are transitioning or have transitioned) and sexual orientation; national origin (including language use restrictions and possession of a driver's license issued to persons unable to prove their presence in the United States is authorized under federal law [Vehicle Code section 12801.9]); ancestry, physical or mental disability, medical condition, genetic information/characteristics, marital status/registered domestic partner status, age (40 and over), sexual orientation, military or veteran status, or any other basis protected by federal, state or local law or ordinance or regulation.
Job Type: Full-time
Pay: $119,000.00 - $147,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible schedule
Flexible spending account
Health insurance
Health savings account
Paid time off
Parental leave
Professional development assistance
Retirement plan
Vision insurance
Schedule:
Monday to Friday
Application Question(s):
Are you able to commute into Manhattan 2-3 days per week?
How many years of experience do you have working in ETL processes?
Do you have experience using cloud-based solutions?
Do you have experience working with medical/healthcare data?
How many years of people management experience do you have?
Work Location: In person","$133,000 /yr (est.)",1 to 50 Employees,Unknown,Human Resources & Staffing,HR Consulting,#N/A,Unknown / Non-Applicable
Helix Tech IT solution,#N/A,"California, KY",Data Engineer,"About us
We are professional and agile.
Our work environment includes:
Modern office setting
Food provided
Data Engineer
Duties:
- Design, develop, and maintain scalable and efficient data pipelines and workflows
- Collaborate with cross-functional teams to gather requirements and understand data needs
- Implement data models and database designs to support business analytics and reporting
- Develop RESTful APIs for data retrieval and integration with other systems
- Utilize programming languages such as Python, SQL, VBA, and Shell Scripting to manipulate and analyze data
- Perform data cleansing, transformation, and validation to ensure data accuracy and integrity
- Optimize database performance and troubleshoot any issues that arise
- Collaborate with data scientists and analysts to provide them with the necessary data for their analysis
- Stay up-to-date with the latest trends and technologies in data engineering and analytics
Qualifications:
- Bachelor's degree in Computer Science, Engineering, or a related field
- Proven experience in database design, development, and optimization
- Strong knowledge of SQL and relational databases
- Experience with Agile methodologies for software development
- Proficiency in programming languages such as Python, VBA, Shell Scripting, etc.
- Familiarity with RESTful APIs and web services
- Strong analytical skills with the ability to analyze complex datasets
- Excellent problem-solving skills and attention to detail
- Strong communication skills to effectively collaborate with cross-functional teams
Note: This job description is not intended to be all-inclusive. Employee may perform other related duties as negotiated to meet the ongoing needs of the organization.
If you are a highly motivated individual who is passionate about data engineering and analytics, we would love to hear from you. Apply now to join our dynamic team!
Job Type: Full-time
Pay: $110,583.00 - $117,880.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Parental leave
Tuition reimbursement
Vision insurance
Compensation package:
1099 contract
Bonus opportunities
RSU
Stock options
Yearly pay
Experience level:
Under 1 year
Schedule:
8 hour shift
Ability to commute/relocate:
California, KY 41007: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Hybrid remote in California, KY 41007","$114,232 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Amgen
4.1",4.1,"Tampa, FL",Data Engineer,"HOW MIGHT YOU DEFY IMAGINATION?
You’ve worked hard to become the professional you are today and are now ready to take the next step in your career. How will you put your skills, experience and passion to work toward your goals? At Amgen, our shared mission—to serve patients—drives all that we do. It is key to our becoming one of the world’s leading biotechnology companies, reaching over 10 million patients worldwide. Come do your best work alongside other innovative, driven professionals in this meaningful role.
Data Engineer
Live
What you will do
Let’s do this. Let’s change the world. In this vital role you will be part of the established technical/engineering team, develop web UI interface, plus data flow pipelines to extract, transform, and load data from various data sources in various data format to enterprise data lake and data warehouse system in three regions in AWS. Provide data analytics and predictive analysis to business users.
Be a key team member assisting in design and development of the data pipeline for Global Data and Analytics team
Collaborate with Data Architects, Business SME’s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions
Serve as system admin to manage AWS and Databricks platform;
Adhere to best practices for coding, testing and designing reusable code/component
Able to explore new tools, technologies that will help to improve ETL platform performance
Participate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with the product teams
Win
What we expect of you
We are all different, yet we all use our unique contributions to serve patients. The engineering professional we seek will have these qualifications:
Basic Qualifications:
Master’s Degree
OR
Bachelor’s degree with 2 years Data Engineering and/or and Software Engineering experience
Or
Associate’s degree 6 years of Data Engineering and/or Software Engineering experience
Or
High school diploma and 8 years of Data Engineering and/or Software Engineering experience
Preferred Qualifications:
Experience with software development (Java, Python preferred), end-to-end system design
Experience with data modeling for both OLAP and OLTP databases, hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL; SQL performance tuning
Experience with web development, java script, html, CSS, any web framework or microservice architecture
Experience with software DevOps CI/CD tools, such Git, Jenkins
Experience on AWS, familiar with EC2, S3, Redshift/Spectrum, Glue, Athena, RDS, Lambda, DynamoDB, and API gateway
Experience with docker container, Kubernetes container orchestration
Experience with Apache Airflow and Apache Spark; Spark performance turning
Experience with Tableau Dashboard and Tableau Server
Experience with Pharmaceutical industry, commercial operations
Ability to learn quickly, be organized and detail oriented
Thrive
What you can expect of us
As we work to develop treatments that take care of others, we also work to care for our teammates’ professional and personal growth and well-being.
The annual base salary range for this opportunity in the U.S. is $92,155-$130,042 USD
In addition to the base salary, Amgen offers a Total Rewards Plan comprising health and welfare plans for staff and eligible dependents, financial plans with opportunities to save towards retirement or other goals, work/life balance, and career development opportunities including:
Comprehensive employee benefits package, including a Retirement and Savings Plan with generous company contributions, group medical, dental and vision coverage, life and disability insurance, and flexible spending accounts.
A discretionary annual bonus program, or for field sales representatives, a sales-based incentive plan
Stock-based long-term incentives
Award-winning time-off plans and bi-annual company-wide shutdowns
Flexible work models, including remote work arrangements, where possible
Apply now
for a career that defies imagination
Objects in your future are closer than they appear. Join us.
careers.amgen.com
#NBMBAA

Join Us

If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.

Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancers, kidney disease, rheumatoid arthritis and other serious illnesses.

As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.

Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",#N/A,10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1980,$10+ billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Wilmington, DE",Data Engineer,"JOB DESCRIPTION

The Workforce Planning Product team is part of Consumer & Community Banking Operations Management and is responsible for developing an integrated data management, Advanced Analytics Platform and reporting process that supports the successful execution of CCB Operations business objectives. As a Data Engineer, you are an integral part of an agile team that works to enhance, build, and deliver data collection, storage, access, and analytics solutions in a secure, stable, and scalable way. As a core technical contributor, you are responsible for maintaining critical data pipelines and architectures across multiple technical areas within various business functions in support of the firm’s business objectives.
Job Responsibilities
Design and implement end-to-end data pipelines supporting analytical and operational needs accounting for data management practices focused on data quality, metadata management etc.
Architect, design, and implement cloud native solutions on AWS.
Define and implement event driven architecture patterns leveraging messaging / streaming solutions like Kafka, Kinesis, Flink, and Spark
Ability to decompose large initiatives / designs into manageable smaller bodies of work to demonstrate continuous progress
Collaborate with business stakeholders, product owners, architects, data domain owners to understand current landscape and develop solutions in alignment with business & technology strategy. Assist in refining /evolving data strategy highlighting clear outcomes.
Deep understanding or desire to continue to learn new database technologies, cloud computing & storage services
Understanding of the pros / cons associated with various technology choices and ability to pick the right technology based on the use case
Required qualifications, capabilities, and skills
Formal training, or certification on data engineering concepts, and 5+ years of experience. In addition, demonstrated coaching and mentoring experience
Programming experience in Java, Python, Scala etc.
Experience in using distributed frameworks like Spark, Hadoop etc.
Experience with AWS services like Lambda, EC2, EMR, Redshift, Glue, S3, IAM, RDS, Aurora, DynamoDB etc.
Knowledge of cloud networking, security, storage, and compute services
Infrastructure provisioning experience using Cloud Formation, Terraform etc.
Experience implementing solutions leveraging CI / CD etc.
Preferred qualifications, capabilities, and skills
AWS Solutions Architect / Developer or any advanced level certification preferred
Experience and proficiency across the data lifecycle
Experience with database back-up, recovery, and archiving strategy
Proficient knowledge of linear algebra, statistics, and geometrical algorithms
ABOUT US

Chase is a leading financial services firm, helping nearly half of America’s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs.
We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.

The health and safety of our colleagues, candidates, clients and communities has been a top priority in light of the COVID-19 pandemic. JPMorgan Chase was awarded the “WELL Health-Safety Rating” for all of our 6,200 locations globally based on our operational policies, maintenance protocols, stakeholder engagement and emergency plans to address a post-COVID-19 environment.
As a part of our commitment to health and safety, we have implemented various COVID-related health and safety requirements for our workforce. Employees are expected to follow the Firm’s current COVID-19 or other infectious disease health and safety requirements, including local requirements. Requirements include sharing information including your vaccine card in the firm’s vaccine record tool, and may include mask wearing. Requirements may change in the future with the evolving public health landscape. JPMorgan Chase will consider accommodation requests as required by applicable law.
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
Equal Opportunity Employer/Disability/Veterans



ABOUT THE TEAM
Our Consumer & Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.


The CCB Data & Analytics team responsibly leverages data across Chase to build competitive advantages for the businesses while providing value and protection for customers. The team encompasses a variety of disciplines from data governance and strategy to reporting, data science and machine learning. We have a strong partnership with Technology, which provides cutting edge data and analytics infrastructure. The team powers Chase with insights to create the best customer and business outcomes.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Paramount
3.5",3.5,"New York, NY",Data Engineer,"The Paramount Technology department supports our global content company through the delivery of a high-quality viewing experience, system infrastructure support, and crafting innovative ways for our employees to collaborate. If you are interested in a strategy that has growth, transformation, and ongoing innovation where you can help “reinvent the broadcasting wheel” Paramount Tech has a role for you!

We are seeking a highly skilled and motivated Data Integration Engineer to join our team! The ideal candidate will play a crucial role in building APIs and data pipelines using Python, orchestrating data workflows, and chipping in to a time-sensitive project environment where the ability to manage competing priorities is essential. Additionally, you will actively participate in meetings with our engineering team and business users to drive data integration initiatives forward.

API and Data Pipeline Development:
Craft and construct robust APIs and data pipelines applying Python to ensure efficient data integration and transfer.

Data Workflow Orchestration:
Collaborate with multi-functional teams to orchestrate data workflows that streamline data processing and optimize data integration.

Time-sensitive Project Management:
Thrive in a dynamic project environment by effectively managing competing priorities and meeting project deadlines.

Collaborative Engagement:
Actively engage in meetings and discussions with engineering and business teams to gather requirements, provide updates, and ensure alignment on data integration initiatives.

Basic Qualifications

Minimum 5 years of hands-on experience as a data engineer.
Strong ability to develop solutions with Python.
Possesses in-depth knowledge of enterprise integration and automation patterns and paradigms (ESB, ETL, ELT, API broker, consolidating and rationalizing microservices).

Additional Qualifications

Database Programming
Scripting in a Linux environment
Solid grasp of Data Lake and Cloud Data Warehousing platforms such as Snowflake, Redshift, or BigQuery.
Hands-on experience with Amazon Web Services.
Ability to function collaboratively as part of a fast-paced, customer-focused team, perform effectively as an independent producer under broad management direction, and a demonstrated willingness to support the team on all levels to get the job done.
Proficient communication skills in working with technical and non-technical users and the ability to cultivate and maintain collaborative relationships among all levels of an organization.
Bachelor’s degree in Computer Science, Mathematics, Engineering, Data Science, or Statistics preferred.

#LI-IT

Paramount Global (NASDAQ: PARA, PARAA) is a leading global media and entertainment company that creates premium content and experiences for audiences worldwide. Driven by iconic studios, networks and streaming services, Paramount's portfolio of consumer brands includes CBS, Showtime Networks, Paramount Pictures, Nickelodeon, MTV, Comedy Central, BET, Paramount+, Pluto TV and Simon & Schuster, among others. Paramount delivers the largest share of the U.S. television audience and boasts one of the industry's most important and extensive libraries of TV and film titles. In addition to offering innovative streaming services and digital video products, the company provides powerful capabilities in production, distribution and advertising solutions.

ADDITIONAL INFORMATION

Hiring Salary Range: $115,000.00 - 130,000.00.

The hiring salary range for this position applies to New York City, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.

https://www.paramount.com/careers/benefits

Paramount is an equal opportunity employer (EOE) including disability/vet.

At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.

If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.","$122,500 /yr (est.)",1 to 50 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1998,$1 to $5 million (USD)
"CoreLogic
3.9",3.9,United States,Data Engineer,"At CoreLogic, we are driven by a single mission—to make the property industry faster, smarter, and more people-centric. CoreLogic is the trusted source for property intelligence, with unmatched precision, depth, breadth, and insights across the entire ecosystem. Our talented team of 5,000 employees globally uses our network, scale, connectivity and technology to drive the largest asset class in the world. Join us as we work toward our vision of fueling a thriving global property ecosystem and a more resilient society.
CoreLogic is committed to cultivating a diverse and inclusive work culture that inspires innovation and bold thinking; it's a place where you can collaborate, feel valued, develop skills and directly impact the real estate economy. We know our people are our greatest asset. At CoreLogic, you can be yourself, lift people up and make an impact. By putting clients first and continuously innovating, we're working together to set the pace for unlocking new possibilities that better serve the property industry.
Job Description:
Remote - US
Summary:
Working under minimal supervision, the Data Engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The Data Engineer will support our software developers, data architects, data analysts on initiatives and will ensure optimal data delivery is consistent throughout ongoing projects. This position, in partnership with TPM, business partners/product owners, gathers information and analyzes needs to determine feasibility of client requests. This position also takes an active mentoring role and provides design scope and specifications to less experienced team members. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Main Job Responsibilities include:
Create and maintain optimal data pipeline architecture.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for extraction, transformation, and loading of data from a wide variety of data sources using SQL and GCP ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with data and analytics experts to strive for greater functionality in our data systems.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Explore and research new and alternate BigData technologies and platforms.
Evaluate feasibility and make recommendations, considering things such as customer requirements, time limitations, system limitations.
Serve as a mentor to junior staff by conducting technical training sessions and reviewing project outputs.
Build documentation repository for knowledge transfer and developing expertise in multiple areas.
Provide operational support on complex/escalated issues to diagnose and resolve incidents in production data pipelines.
Job Qualifications:
Job Qualifications:
Education, Experience, Knowledge and Skills
BS Degree or equivalent work experience in a software engineering discipline
Typically has 4+ experience in an applicable software development environment.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases (SQL, Postgres)
Experience with diverse coding, profiling, and visualization approaches including authoring SQL queries, BigQuery, Python, Looker, Google Cloud or equivalent.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Hands on experience with Cloud Platforms (AWS, GCP, or Azure)
Experience in designing and implementing large-scale event-driven architectures.
Understanding of data warehousing and data modeling techniques
Understanding of Big Data, Cloud, Machine Learning approaches and concepts (preferred)
Experience working as a member of a distributed team. Ability to organize and coordinate with stakeholders across multiple functions and geographic locations.
Ability to develop and write technical specifications.
Coaching and teaching skills to mentor less experienced team members
Excellent analytical and problem management skills
Good interpersonal skills and positive attitude
Experience with the following tools and technologies:
Elastic Search, Kafka
Google Cloud Dataflow and Airflow (preferred)
Python, Java, C++
Big Query
#LI-Remote
Annual Pay Range:
81,900 - 120,000 USD
CoreLogic benefits information can be found here:
http://www.yourcorebenefits.com/
. Qualifications, locations and experience of the individual ultimately selected for the position may impact the final actual offered compensation, which may vary from any posted range.
CoreLogic's Diversity Commitment:
CoreLogic is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences and values. We offer an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support and recognize our differences.
EOE AA M/F/Veteran/Disability:
CoreLogic is an Equal Opportunity/Affirmative Action employer committed to attracting and retaining the best-qualified people available, without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, disability or status as a veteran of the Armed Forces, or any other basis protected by federal, state or local law. CoreLogic maintains a Drug-Free Workplace.
Please apply on our website for consideration.
Privacy Policy -
http://www.corelogic.com/privacy.aspx
By providing your telephone number, you agree to receive automated (SMS) text messages at that number from CoreLogic regarding all matters related to your application and, if you are hired, your employment and company business. Message & data rates may apply. You can opt out at any time by responding STOP or UNSUBSCRIBING and will automatically be opted out company-wide.
Connect with us on social media! Click on the quicklinks below to find out more about our company and associates.","$100,950 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Information Technology Support Services,2010,$1 to $5 billion (USD)
"Zillow
4.0",4.0,Remote,Software Development Engineer (Big Data),"About the team
Zillow's Property Data Platform teams are responsible for ensuring our most critical data is available around the clock. This includes all listings of what's available on the housing market, all public record information, personalization data, and market derivatives data (such as regional housing statistics and Zestimate). Property data is the beating heart of Zillow; it is a foundational component that powers all of Zillow's products!

The Data Consolidation Platform (DCP) team is building a framework to consolidate data from multiple sources and deliver a single unified document to applications throughout the Zillow Group enterprise. Our platform is built on open source data streaming software such as Flink and Kafka. Given our critical role in the end-user experience, we care deeply about the performance, resiliency, scalability, and adaptability of our services.

Zillow, the top real estate website in the U.S., is building an on-demand real estate experience. Whether selling, buying, renting or financing, customers can turn to Zillow to find and get into their next home with speed, certainty and ease.
About the role
As a Data Engineer on the DCP team, you will architect and build foundational data pipelines and platforms to deliver up to date information to the entire Zillow infrastructure. You will work within a small team of software developers.
We believe in autonomy and fast paced product development, so self-motivation and high energy are must-haves for ideal candidates. This is a successful remote team, so it's important that candidates have a high level of comfort with remote and asynchronous collaboration.
This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice which must be identified to the Company. Employees may live in any of the 50 US States, with limited exceptions. In certain cases, an employee in a remote-designated job may need to live in a specific region or time zone to support customers or clients as part of their role.
In California, Colorado, Connecticut, Nevada, New York City and Washington the standard base pay range for this role is $132,400.00 - $211,600.00 Annually. This base pay range is specific to California, Colorado, Connecticut, Nevada, New York City and Washington and may not be applicable to other locations.
In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location.
Who you are
You thrive in ambiguity and learn quickly
You have excellent communication skills
You are at ease collaborating in a remote-first work environment
Qualifications:
Highly Proficient in Java or similar language
Experience building and maintaining sophisticated data pipelines, writing scalable and reliable code
Familiarity with a Cloud platform (e.g. AWS) and with Infrastructure-as-Code (e.g. Terraform)
Understanding of the concepts behind distributed databases, and both streaming and batch processing systems
A degree in Computer Science or related field; or equivalent work experience

Get to know us
Zillow is reimagining real estate to make home a reality for more and more people.
As the most-visited real estate website in the United States, Zillow® and its affiliates help movers find and win their home through digital solutions, first class partners, and easier buying, selling, financing and renting experiences. Millions of people visit Zillow Group sites every month to start their home search, and now they can rely on Zillow to help make it easier to move. The work we do helps people get home and no matter what job you're in, you will play a critical role in making home a reality for more and more people.
Our efforts to streamline the real estate transaction are supported by a deep-rooted culture of innovation, our passion to redefine the employee experience, a fundamental commitment to Equity and Belonging, and world-class benefits. These benefits include comprehensive medical, dental, vision, life, and disability coverages as well as parental leave, family benefits, retirement contributions, and paid time off. We’re also setting the standard for work experiences of the future, where our employees are supported in doing their best work and living a flexible, well-balanced life. But don’t just take our word for it. Read recent reviews on Glassdoor and recent recognition from multiple organizations, including: the 100 Best Companies to Work For, Glassdoor Employees’ Choice Award, Bloomberg Gender-Equality Index, Human Rights Campaign (HRC) Corporate Equity Index, and TIME 100 Most Influential Companies list.
Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact us at RecruitingAccessibility@zillowgroup.com.
Applicants who receive job offers from Zillow Group will be asked to sign a Proprietary Rights Agreement which includes confidentiality, intellectual property assignment, customer and employee non-solicitation, and non-competition provisions. If you are contacted for a role at Zillow Group and wish to review a copy of the Proprietary Rights Agreement prior to receiving an offer, you may request a copy from your Recruiter.","$172,000 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Internet & Web Services,2005,$1 to $5 billion (USD)
"Bose
3.8",3.8,"Framingham, MA",Data Engineer Co-Op,"Job Description
ABOUT BOSE
You know the moment. It’s the first notes of that song you love, the intro to your favorite movie, or simply the sound of someone you love saying “hello.” It’s in these moments that sound matters most.
At Bose, we believe sound is the most powerful force on earth. And we’ve dedicated ourselves to improving it for nearly 60 years. Ever since our founder, Dr. Amar Bose, bought a stereo system and thought, “I can make this better,” we’ve been relentlessly pushing forward to the next best thing.
Innovation is more than what we do. It’s who we are — constantly learning and constantly curious. We never stop imagining what better sound sounds like. We’re music fanatics and audio engineers. We’re explorers and inventors and dreamers. And we’re passionate down to our bones about making whatever you’re listening to a little more magical.
THE PROGRAM
We're looking for students to join our Co-Op Program who are obsessively curious about 'what's next'. You'll get hands on experience with our products and learn from the best of the best in the business. You will immerse yourself into Bose for 6 months and get the opportunity to grow the skills your learned in the classroom with hands on work experience. By the time you end your time with us, you will have been given the opportunity to truly make a real impact in the future of Bose and your career!
Opportunities don't stop at your day-to-day work. While you're getting an in depth look at your area of expertise, we'll expose you to other areas of the company. Our Co-Ops are given the opportunity to connect with senior leadership across the business to understand different perspectives at Bose. You'll network with other Co-Ops and colleagues to grow your network for the future!
Timeframe - January-June 2024
THE ROLE
The Bose Data Engineering team is responsible for design, development and enhancement of Bose Data Platforms (Analytics & Customer Data Platforms) in leading and supporting Advanced Analytics. This team is highly impactful and a key enabler of Bose Digital journey by playing a central role in the Data driven transformation.

What you will be working on?
As a junior Data Engineer, you will work closely with internal customers to build and design data pipelines, spanning from data acquisition to ML model deployment and monitoring. Being part of an agile delivery team, you will design, develop, deploy, and support data pipelines, applying best practices and implementing necessary integrations with our Data Platform ecosystem. This role requires a passion for operations, AWS Serverless solutions, Python, and SQL coding.
Under the supervision of a Senior Data Engineer, some of your responsibilities will include:
Continuing the full life cycle management of data pipelines: designing, developing, and providing production support for data pipelines that support customer experiences on connected devices, web applications, and mobile applications.
Staying up to date on relevant technologies, participating in user groups, understanding trends, and identifying opportunities to ensure the adoption of the best techniques and tools. For instance, we are currently utilizing Snowflake, databricks, and AWS Serverless technologies.
Collaborating with AWS Cloud Architects to optimize and evaluate scalable, serverless solutions, becoming the Subject Matter Expert (SME) for AWS solutions.
Working in multi-functional agile teams to continuously experiment, iterate, and deliver on new data product objectives.
Bose is an equal opportunity employer that is committed to inclusion and diversity. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, genetic information, national origin, age, disability, veteran status, or any other legally protected characteristics. For additional information, please review: (1) the EEO is the Law Poster (http://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf); and (2) its Supplements (http://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm). Please note, the company's pay transparency is available at http://www.dol.gov/ofccp/pdf/EO13665_PrescribedNondiscriminationPostingLanguage_JRFQA508c.pdf. Bose is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the application or employment process, please send an e-mail to Wellbeing@bose.com and let us know the nature of your request and your contact information.","$123,004 /yr (est.)",5001 to 10000 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1964,$1 to $5 billion (USD)
"Meta
3.9",3.9,"Dekalb, IL",SiteOps Data Center Infrastructure Services Engineer,"The Site Operations team is responsible for the delivery of data center compute and storage at Meta, enabling our family of apps and services to support a growing global community. We are seeking a forward thinking technologist skilled across multiple disciplines to lead global initiatives on this team. The Infrastructure Services Engineer works across multiple teams and disciplines to identify and take on multifaceted technical, business, and operational problems, delivering effective and impactful solutions while working and communicating with stakeholders. This position requires working collaboratively with cross-functional partners to bring initiatives from concept through solution in data centers around the globe. The ideal candidate should thrive in a matrixed organizational structure that is complex, highly technical and requires innovative design, planning, execution, and communication to succeed.


SiteOps Data Center Infrastructure Services Engineer Responsibilities:
Represent Site Operations in leading work to define and architect new solutions on global initiatives, by working with key partner teams across multiple disciplines.
Understand and assess risks and challenges associated with emerging new hardware, data center, and software technologies, and define plans for how to address and mitigate these.
Effectively bridge between the logical and physical world, ensuring a holistic understanding of the full infrastructure stack.
Serve as a communication and advisory point of contact for the design, implementation and delivery of projects that affect our global data center and server fleet, and facilitate resolution of issues drawing on local expertise and global support partners.
Address issues that often are ambiguous and of global nature, requiring leadership and collaboration across time zones, teams, and technical domains.
Leverage data-driven methodologies to identify and understand a problem at the onset, defining a plan, and being able to measure progress throughout a project. Provide data supplied narratives and ensure a strong focus on continuous improvement.
Build and support strong cross-functional connections with teams across the globe and serve as an advocate for the Site Operations Team with key partners, influencing policies and procedures to improve global data center operations.
Ability to travel 20-30% required.



Minimum Qualifications:
BS or BA in technical field or commensurate experience
10+ years of technical and/or operational experience in a large-scale data center or IT Infrastructure environment.
Experience building and operating globally scalable solutions and translating global strategic initiatives into local executable projects.
Knowledge of the interdependencies of data center functions and technologies including electrical, cooling, structured cabling, security, network, server, and storage systems.
Experience communicating the results of analysis and insights to cross functional teams and influencing the strategy of these teams.
Proven communication skills and experience working in a highly distributed environment, across teams/department boundaries



Preferred Qualifications:
Six Sigma certification, with a preference for Green Belt or higher levels of certification.
Proven track record of championing and supporting innovation, including the successful adoption of new technologies, piloting new designs and delivery methods, and promoting best practices on both local and global levels.
Extensive experience as a continuous improvement agent, applying industry-leading operations and business reviews to gain deep visibility into business health and facilitating data-driven decision-making processes.
Demonstrated expertise in strategic thinking methodology, with a strong experience to develop and execute strategies for complex cross-functional site and global initiatives.
Strong background in driving data analytics and metrics in a complex environment, adept at identifying inefficiencies, opportunities, exceptions, correlations, and proactively responding to potential impacts on the business.
Proven experience to challenge and collaborate with world-class technical operations teams, delivering operational performance and providing valuable engineering insights and tools to effectively manage a hyperscale infrastructure.
Demonstrated experience assembling and leading cross-functional teams to tackle operational challenges, showcasing a broad understanding of Meta’s overall infrastructure.



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$156,999 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"REPS & Co.
4.5",4.5,"Arizona City, AZ",Data Engineer,"Founded in 2017, REPS & Co. is a leader in the entertainment industry specializing in ticketing for live events. We provide tickets to many events and shows across the nation including music, sports and theatrical performances. We pride ourselves in offering the best experience for the best price to our customers. Our technology is what allows us to outperform our competitors and deliver an unforgettable experience to fans.
We are looking for an organized, experienced, and driven Data Engineer. The Data Engineer is responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
We are excited to add a Data Engineer to our growing team!
Responsibilities:
Work on data architecture and use a systematic approach to plan, create, and maintain data while also keeping it aligned with business requirements
Collect and obtain data from appropriate sources after formulating a set of dataset processes
Conduct research in the industry to address any issues that can arise while tackling a business problem
Create models and identify patterns
Dive into data and pinpoint tasks where manual participation can be eliminated with automation
Use programming languages and tools
Identify ways to improve data reliability, efficiency, and quality
Use large data sets to address business issues
Prepare data for predictive and prescriptive modeling
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems
Qualifications:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with relational SQL and NoSQL databases, including RDS, Postgres, MySQL, Mongo / DynamoDB, and Cassandra.
Experience in data pipeline and workflow tools: DBT, Lambda, AirByte, Airflow, etc.
Experience with BigData cloud services: BigQuery, EMR, RDS, Redshift, Glue, Athena
Experience with stream-processing systems: Druid, Storm, Spark-Streaming, etc.
Experience with object-oriented languages: Python, Java, Javascript, etc.
Benefits
Medical, Dental and Vision insurance
PTO
Sick Leave
Paid Holidays
Volunteer Time Off
401k with Match
ESOP
Parental Leave
100% Employer Paid Life Insurance & Long Term Disability
EAP Program
Bonus
Gym Membership Reimbursement
Ticket Benefit
#Li-Remote","$95,248 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,Unknown / Non-Applicable
"Reorg Research
3.6",3.6,Remote,Senior Data Engineer,"A market leader in credit intelligence, Reorg brings together journalists, financial analysts, legal analysts, technologists, and data scientists to collect and synthesize highly complex information into actionable intelligence. Since 2013, tens of thousands of professionals across hedge funds, investment banks, management consulting, and law firm verticals have come to rely on Reorg to make better, faster, and more confident decisions in pace with the fast-moving credit markets. For more information, visit: www.reorg.com

Working at Reorg
Consistent with our growth, Reorg hires innovators and trailblazers across the globe to drive our business and our incredible corporate culture alike. Our core values – Action Oriented, Customer First Mindset, Effective Team Players, and Driven to Excel – define an organizational ethos that’s as high-performing as it is human. Among other perks, Reorg employees enjoy competitive health benefits, matched 401k and pension plans, Paid time off, generous parental leave, gym subsidies, educational reimbursements for career development, recognition programs, pet-friendly offices, and much more.
The Role
We are seeking a highly skilled and experienced Senior Data Engineer with a strong background in building and managing data pipelines, data warehouses, and data lakes. As a Senior Data Engineer, you will play a pivotal role in our organization's data infrastructure, enabling efficient and reliable data processing, storage, and analysis.
Responsibilities:
Design and develop robust, scalable, and efficient data pipelines to support the extraction,
transformation, and loading (ETL) processes from various data sources into data warehouses
and data lakes.
Collaborate closely with cross-functional teams, including data scientists, analysts, and software
engineers, to understand data requirements and design optimal solutions.
Build and manage data warehouses and data lakes to store and organize large volumes of
structured and unstructured data efficiently.
Implement data governance processes and best practices to ensure data quality, integrity, and
security throughout the data lifecycle.
Identify and address performance bottlenecks, data inconsistencies, and data quality issues in
data pipelines, warehouses, and lakes.
Develop and maintain monitoring and alerting systems to proactively identify and resolve data-related issues.
Continuously evaluate and explore emerging technologies and tools in the data engineering space to improve data processing efficiency and scalability.
Mentor and guide junior data engineers, providing technical leadership and fostering a collaborative and innovative environment.
Requirements:
Bachelor's degree in Computer Science or a related field.
Proven experience (minimum 5 years) in building and managing data pipelines, data warehouses, and data lakes in a production environment.
Proficiency in programming languages such as Python, SQL and experience with data processing frameworks like Apache Spark or Apache Beam.
Experience ETL/ELT frameworks and tools like AWS Glue, dbt, Airflow, Airbyte, etc.
In-depth knowledge of relational databases (e.g., MySQL, PostgreSQL) and experience with columnar storage technologies (e.g., Redshift, Snowflake).
Strong understanding of distributed systems, data modeling, and database design principles.
Familiarity with cloud platforms (e.g., AWS, Azure, GCP) and experience in deploying data infrastructure on the cloud.

At Reorg, we consider a range of factors in connection with compensation decisions, including experience, skills, location, and our business needs and limitations. As a result, compensation may vary within and across similar roles and positions. Please note that the salary range information below is a good faith estimate for this position and actual compensation for any individual may fall outside this range if warranted by the circumstances applicable to that individual. If we identify a role that would be suitable for a broader range of skills and experience such that we would consider hiring at multiple levels then the range listed below may reflect that breadth.
The salary range estimate for this position is $140,000-$150,000.
The actual compensation will be at Reorg’s sole discretion and will be determined by the aforementioned and other relevant factors. This position is eligible for an annual discretionary bonus.
Reorg provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Reorg complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.","$145,000 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Research & Development,2012,Unknown / Non-Applicable
"Mariner Wealth Advisors
4.2",4.2,Remote,Data Engineer - Remote,"Overview:
If you are looking to build your career with a firm that puts the client first by providing 360° advice designed to last, then Mariner Wealth Advisors is the right firm for you. We actively nurture the next generation of professionals, give back to the community and focus on building a diverse culture where everyone genuinely loves where they work and has the support needed to meet their career goals.

We are seeking candidates for a full-time, remote software and data engineering role. The candidate will join a team developing data-pipelines, building curated enterprise data products, and constructing system integrations for Mariner’s ecosystem of enterprise platforms and partners. This position will require developers to weave together ETL/ELT tools and practices, cloud and legacy databases, APIs and enterprise platforms, and automation systems to build scalable business tools and products driving Mariner’s front and back-office. As a Data & Integrations Engineer, you will be working in conjunction with like-minded departments such as Data Management, Operations, Trading, Business Intelligence, and Compliance. We are searching for positive, data obsessed engineers with a passion for the industry and a capacity to leverage a variety of technical disciplines to support Mariner’s growing portfolio of businesses.

Responsibilities:
Building and maintaining data extraction pipelines using Python and scripting tools
Mastering and blending enterprise datasets using DBT and SQL
Building systems integrations using Python, APIs, low-code tools, SAAS platforms, and scripting languages
Developing and maintaining automation configurations and scheduling
Addressing issues in automations and processes, debugging failures, and escalating to internal and external resources as required
Building tools and processes for data validation, testing, alerting, and monitoring
Administering and maintaining SQL based infrastructure in Snowflake, SQLServer, etc
Provide oversight and consulting to technology-focused associates and projects across the organization
Qualifications:
Professional experience in software development, data-engineering, database administration, or wealth advisor operations
Prior experience in the financial services, investments, trading, or related industries highly preferred
Skills and Knowledge
Familiarity with relation databases (Snowflake, MS-SQLServer, Redshift, etc) and data analysis/pipelining development (DBT, Python/Pandas, Alteryx, Spark, etc).
Experience with SAAS and cloud platforms (AWS, Azure, Mulesoft) for developing API integrations and ETL
Familiarity with common data formats and data exchanges (JSON, CSV, APIs, ODBC, FTP, S3)
DevOps platforms such as GitHub and Terraform
Enterprise systems such as Salesforce, ERPs, portfolio management platforms, order-management systems, and reporting tools (Tableau/Streamlit)
Experience with scripting languages (PowerShell, Python, Bash/Sh, etc)
Automation and orchestration platforms (ActiveBatch, Airflow, Dagster)
Mariner Wealth Advisors is a top-ranked, national wealth advisory firm with locations across the United States. Our mission to put our clients first drives everything we do.

We welcome your interest in being a part of our firm. We believe in giving associates progressive opportunities, actively nurturing professional growth and giving back to the community. We are dedicated to building a diverse culture where everyone has the support they need to achieve their career goals. We offer an innovative workplace and a culture that fosters camaraderie, teamwork and work-life balance.#LI-REMOTE

EOE M/F/D/V

Top RIA Firms: Barron’s awarded 2022, 2021, and 2020 #5, 2019 #4, and 2018 #3 rankings to Mariner Wealth Advisors (MWA) based on data compiled for MWA and the 2017 #2 and 2016 #1 rankings to Mariner Holdings (MH) based upon data compiled for MH registered investment adviser subsidiaries. Rankings for 2016 through 2022 were published in September of each award year and were based on June 30th data, including annual figures for the previous three years. The ranking is based on assets managed by the firms, technology spending, staff diversity, succession planning, and other metrics. The number of firms included in the rankings was: 20 (2016), 30 (2017), 40 (2018), 50 (2019), and 100 (2020 - 2022). The published rankings are based on firm surveys, and the firm’s filings with the regulatory databases were used to cross-check the data provided. The formula Barron’s uses to rank advisors is proprietary. The ranking is not indicative of future performance, and there is no guarantee of future success. For additional information, visit www.barrons.com.",#N/A,501 to 1000 Employees,Company - Private,Financial Services,Investment & Asset Management,2006,$10+ billion (USD)
"Meta
3.9",3.9,"Austin, TX","Data Engineer, Product Analytics","As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.


Data Engineer, Product Analytics Responsibilities:
Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design, build and launch new data models and visualizations in production, leveraging common development toolkits
Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
Support existing processes running in production and implement optimized solutions with limited guidance
Define and manage SLA for data sets in allocated areas of ownership



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
2+ years of work experience in data engineering
Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)



Preferred Qualifications:
Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy
Experience working with terabyte to petabyte scale data



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$137,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Mozilla
4.4",4.4,Remote,Senior Data Engineer,"Why Mozilla?
Mozilla Corporation is the non-profit-backed technology company that has shaped the internet for the better over the last 25 years. We make pioneering brands like Firefox, the privacy-minded web browser, and Pocket, a service for keeping up with the best content online. Now, with more than 225 million people around the world using our products each month, we're shaping the next 25 years of technology. Our work focuses on diverse areas including AI, social media, security and more. And we're doing this while never losing our focus on our core mission – to make the internet better for everyone.
The Mozilla Corporation is wholly owned by the non-profit 501(c) Mozilla Foundation. This means we aren't beholden to any shareholders — only to our mission. Along with 60,000+ volunteer contributors and collaborators all over the world, Mozillians design, build and distribute open-source software that enables people to enjoy the internet on their terms.
About this team and role:
As a Senior Data Engineer at Mozilla, your primary area of focus will be on our Analytics Engineering team. This team focuses on modeling our data so that the rest of Mozilla has access to it, in the appropriate format, when they need it, to help them make data informed decisions. This team is also tasked with helping to maintain and make improvements to our data platform. Some recent improvements include introducing a data catalog, building in data quality checks among others. Check out the Data@Mozilla blog for more details on some of our work.
What you'll do:
Work with other data engineers to design and maintain scalable data models and ETL pipelines
Help design, build, and improve the infrastructure for ingesting, storing, and transforming data at a scale of tens of terabytes per day
Help design and build systems to monitor and analyze data from Mozilla's products
Work with data scientists to answer questions and guide product decisions
What you'll bring:
At a minimum 3 years of professional experience in data engineering
Proficiency with the programming languages used by our teams (SQL and Python)
Strong software engineering fundamentals: modularity, abstraction, data structures, and algorithms
Ability to work collaboratively with a distributed team
Our team requires skills in a variety of domains. You should have proficiency in one or more of the areas listed below, and be interested in learning about the others:
You have used data to answer specific questions and guide company decisions.
You are opinionated about data models and how they should be implemented; you partner with others to map out a business process, profile available data, design and build flexible data models for analysis.
You have experience recommending / implementing new data collection to help improve the quality of data models.
You have experience with data infrastructure: databases, message queues, batch and stream processing
You have experience building modular and reusable ETL/ELT pipelines in distributed databases
You have experience with highly scalable distributed systems hosted on cloud providers (e.g. Google Cloud Platform)
Commitment to our values:
Welcoming differences
Being relationship-minded
Practicing responsible participation
Having grit
What you'll get:
Generous performance-based bonus plans to all regular employees - we share in our success as one team
Rich medical, dental, and vision coverage
Generous retirement contributions with 100% immediate vesting (regardless of whether you contribute)
Quarterly all-company wellness days where everyone takes a pause together
Country specific holidays plus a day off for your birthday
One-time home office stipend
Annual professional development budget
Quarterly well-being stipend
Considerable paid parental leave
Employee referral bonus program
Other benefits (life/AD&D, disability, EAP, etc. - varies by country)
About Mozilla
Mozilla exists to build the Internet as a public resource accessible to all because we believe that open and free is better than closed and controlled. When you work at Mozilla, you give yourself a chance to make a difference in the lives of Web users everywhere. And you give us a chance to make a difference in your life every single day. Join us to work on the Web as the platform and help create more opportunity and innovation for everyone online.
Commitment to diversity, equity, inclusion, and belonging
Mozilla understands that valuing diverse creative practices and forms of knowledge are crucial to and enrich the company's core mission. We encourage applications from everyone, including members of all equity-seeking communities, such as (but certainly not limited to) women, racialized and Indigenous persons, persons with disabilities, persons of all sexual orientations, gender identities, and expressions.
We will ensure that qualified individuals with disabilities are provided reasonable accommodations to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment, as appropriate. Please contact us at hiringaccommodation@mozilla.com to request accommodation.
We are an equal opportunity employer. We do not discriminate on the basis of race (including hairstyle and texture), religion (including religious grooming and dress practices), gender, gender identity, gender expression, color, national origin, pregnancy, ancestry, domestic partner status, disability, sexual orientation, age, genetic predisposition, medical condition, marital status, citizenship status, military or veteran status, or any other basis covered by applicable laws. Mozilla will not tolerate discrimination or harassment based on any of these characteristics or any other unlawful behavior, conduct, or purpose.
Group: D
#LI-REMOTE
Req ID: R2293
To learn more about our Hiring Range System, please click this link.
Hiring Ranges:
US Tier 1 Locations
$137,000—$200,000 USD
US Tier 2 Locations
$126,000—$185,000 USD
US Tier 3 Locations
$116,000—$170,000 USD",#N/A,501 to 1000 Employees,Company - Private,Information Technology,Software Development,2005,$100 to $500 million (USD)
"CVS Health
3.1",3.1,"Irving, TX",Associate Data Engineer,"Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
CVS Health has a rich set of healthcare data for more than 150 million individuals and provides the best foundation for any ambitious data engineer to:

Solve the complex business problems using all the modern tools and technologies
Securely store, process, transform and enrich terabyte to petabyte scale of highly confidential healthcare data that helps in taking data driven business decisions
Provide best-in-class environment where everyone brings their heart to work to build technical solutions to support customers.
Training and development will be a part of your role.

As an Associate Data Engineer you will:

Manage and support production platform to ensure the quality, performance, and availability of the services that meets business requirements for various CVS Lines of Business
Identify, design, and implement engineering process improvements through automating manual processes, optimizing data pipelines, re-designing services for greater scalability.
Required to support an on call 24 x 7 cloud Production Environment supporting and administering products & Services involving platform technologies like GCP, Azure, etc.
Work hands-on with customers to develop, migrate, and debug services issues.
Ensure server/process documentation is up to date and appropriate or create documentation where none may exist.
Tier 2 triage, troubleshooting, remediation, and escalation of tickets tied to the product support function.
Build data pipelines using Azure/GCP platform.

Required Qualifications
6 months of related work experience (can include internships/course work) including:

Experience in Azure/GCP (Big Query, GCS, Pub/Sub, DataProc, Airflow/Composer, Snowflake, Azure Cloud Services etc.)
Experience in Unix/Shell Scripting
Experience in Python
Experience in SQL

Preferred Qualifications
Experience in Service Now ticketing system
Hands on experience in designing and building data engineering solutions in cloud environments (preferably Azure/GCP).
Hands-on experience with languages like Python, PySpark, SQL, UNIX/Linux scripting to access, extract, manipulate and summarize data.
Strong understanding of query optimization, data structures, transformation, metadata, dependency, and workload management
Experience with CI/CD pipeline, and other DevOps principles/best practices
Experience with Cloud based tech stack and Cloud components including cluster management, Kubernetes, or other containerized services, storage, and workspace management.
Experience working in multi-developer environment, using version control (i.e. Git).
Certified Cloud Engineer in Data engineering track: Azure/GCP preferred
Good articulation in communicating complex technical subjects to non-technical audience
Working experience with automation and orchestration tools
Experience with modern API and microservice patterns
Knowledge and working experience in agile frameworks like Scrum. Kanban etc.
Familiarity in Retail / Healthcare / Insurance industry

Education
Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline

Master’s degree or PhD preferred
Pay Range
The typical pay range for this role is:
$60,000.00 - $144,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health colleagues can initiate a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through myHR (1-888-694-7287, or through myLeave at myHR). If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.","$102,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1963,$10+ billion (USD)
"Workday
4.2",4.2,"Boulder, CO",Senior Front End Engineer - Data Collab,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
Your work days are brighter here!

Do you like solving hard and sophisticated at-scale problems? Love working with spreadsheets? Help support and enhance Workday's very own spreadsheet product!

The Workday Worksheets team is dedicated to building an extensible platform and a consumer based interface to enable our customers to work securely with their Workday data in a familiar UX.

Enhance your career with an opportunity that connects you to a strong network, enables you to do your best work, and places an emphasis on fun. Workday’s office in Boulder, Colorado is home to Productivity Technology, the team that is delivering our next generation of collaborative tools and features, focused on enabling customers to get the most out of their Workday data.

Some reasons why our engineers love working on our team:

No tech ruts: Expand your role. We work across all areas of the user interface to improve the product as a whole and share the knowledge we have acquired across the team.

Collaboration: Our agile team works closely together, enabling us to rapidly learn from each other.

A Learning Culture: We encourage creativity and experimentation in development practices, which allows us to constantly evolve our methodology and tools.

Influence: Every developer is encouraged and empowered to make things better – product, technology, processes, and culture.

Location: With a growing tech scene, 300 days of sunshine, 300 miles of dedicated bikeways, and an almost embarrassing abundance of outdoor adventure opportunities, Boulder is an amazing place to live.

Work/life balance: We love where we live, and we want to enjoy it. Balancing life and Work is a Workday value and a team value.
About the Role
The Worksheets team is looking for exceptional front-end engineers to help build out the next generation of Workday integrations with a focus on financials (FINS). You will join our team in Boulder to help iterate and enhance the React/Redux worksheets application for new integrations within Workday. You'll be involved in bringing the integration from idea to delivery and beyond!
As a Senior Software Engineer at Workday, you will be responsible for developing and maintaining a UI platform for content editing applications. You will work closely with software engineers, product managers, and designers to deliver high-quality applications and platform tools that meet the needs of our customers internally and externally.
About You
Basic Qualifications:
Senior Software Development Engineer:
5+ years of front-end development experience using modern web frameworks (such as React or Vue)
Bachelor's degree in Computer Science or a related field or 5+ years equivalent experience
Other Qualifications:
A solid understanding of HTML and CSS.
Experience with TypeScript and Redux
Strong problem-solving and analytical skills
You are looking to grow and have mentorship opportunities.
Strong communicator, who takes the initiative to get stuff done.
You are ready to partner with Product Managers and Design to build prototypes and iterate towards solutions.
Bonus Qualifications:
Experience in building and supporting libraries, platforms, or frameworks
An interest in building scalable and extensible solutions
#LI-TS10

Workday Pay Transparency Statement - United States
The annualized base salary ranges for the primary location and any additional locations in the United States (US) are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please
click here
.

Primary Location: USA.CO.Boulder
Primary Location Base Pay Range: $142,400 - $213,600
Additional US Location(s) Base Pay Range: $135,300 - $240,000

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.
Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!","$178,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
"Pomeroy
3.1",3.1,Remote,Sr. Data Engineer,"Pomeroy is seeking a Senior Data Engineer to work for one of our clients on a contract basis for a 6 month project with the possibility of extension. This is a fully remote role however you must be in the eastern standard time zone.
Note: W2 employment only. No C2C options available. Must be legally authorized to work in the United States without sponsorship now or in the future.
Key Responsibilities:
Design, develop, and deploy robust and scalable data solutions using AWS data analytics services, with a focus on Redshift.
Collaborate with data scientists, analysts, and stakeholders to understand data requirements and translate them into effective ETL processes and reporting solutions.
Create and maintain data pipelines, ensuring data quality, reliability, and performance.
Develop and maintain Python routines/scripts to support ETL processes, data transformation, and reporting needs.
Optimize and fine-tune existing data infrastructure to ensure efficient query performance and cost-effectiveness.
Perform database design and optimization, including schema design and indexing, to support evolving business needs.
Mentor and provide guidance to junior data engineers in best practices for data engineering, AWS, and Python development.
Stay up-to-date with industry trends, emerging technologies, and best practices in data engineering and analytics.
Qualifications:
Senior Engineer with 7+ yrs of Exp in AWS , Redshift and Database design, dev, deploy in reporting & ETL space
Design, Build and operationalize the enterprise data solutions and applications using AWS data analytics with Redshift and Python.
Experience in design and also hands on development of Python routines/scrip
Job Types: Full-time, Contract
Pay: $38.00 - $40.00 per hour
Experience level:
7 years
Application Question(s):
Are you a vendor or looking for a C2C role? If yes, please leave employer information. If no please write No. Any other answer will result in auto rejection.
Experience:
AWS: 7 years (Required)
Redshift: 7 years (Required)
Database design: 7 years (Required)
Database development: 7 years (Required)
ETL: 7 years (Required)
Work Location: Remote",$39.00 /hr (est.),1001 to 5000 Employees,Contract,Information Technology,Information Technology Support Services,1982,Unknown / Non-Applicable
"The Cigna Group
3.6",3.6,Missouri,Data Engineer,"Must be a current contractor with Cigna Healthcare, Evernorth Health Services, or one of their subsidiaries.

This is a hybrid role and will require the ability to work in-person

Responsibilities:
Work with business and technical leadership to understand requirements

Design to the requirements and document the designs

Ability to write product-grade performant code for data extraction, transformations and loading using Spark, Py-Spark

Do data modeling as needed for the requirements

Write performant queries using Teradata SQL, Hive SQL and Spark SQL against Teradata and Hive

Implementing dev-ops pipelines to deploy code artifacts on to the designated platform/servers like AWS or Hadoop Edge Nodes

Implement Hadoop job orchestration using Shell scripting, Apache Oozie, CA7 Enterprise Scheduler and Airflow

Troubleshooting the issues, providing effective solutions and jobs monitoring in the production environment

Participate in sprint planning sessions, refinement/story-grooming sessions, daily scrums, demos and retrospectives

Skills:
Strong development experience in Spark, Py-Spark, Shell scripting, Teradata, Hive and Hadoop

Strong experience in writing complex and effective SQLs (using Teradata SQL, Hive SQL and Spark SQL) and Stored Procedures

Excellent work experience on Hadoop as data warehouse/Data Lake implementations

Unix/Linux Shell scripting (KSH) and basic administration of Unix servers

CA7 Enterprise Scheduler

AWS (S3, EC2, SNS, SQS, Lambda, ECS, Glue, IAM, and CloudWatch)

Databricks (Delta lake, Notebooks, Pipelines, cluster management, Azure/AWS integration)

Exercises considerable creativity, foresight, and judgment in conceiving, planning, and delivering initiatives.

Qualifications:
Must be a current contractor with Cigna Healthcare, Evernorth Health Services, or one of their subsidiaries.

Bachelor’s degree

Experience in Agile and working knowledge on DevOps tools (Git, Jenkins, Artifactory)

Experience of Ab Initio is a bonus

Experience in Jira and Confluence

Health care domain knowledge is a plus

If you will be working at home occasionally or permanently, the internet connection must be obtained through a cable broadband or fiber optic internet service provider with speeds of at least 10Mbps download/5Mbps upload.

About The Cigna Group
Doing something meaningful starts with a simple decision, a commitment to changing lives. At The Cigna Group, we’re dedicated to improving the health and vitality of those we serve. Through our divisions Cigna Healthcare and Evernorth Health Services, we are committed to enhancing the lives of our clients, customers and patients. Join us in driving growth and improving lives.

Qualified applicants will be considered without regard to race, color, age, disability, sex, childbirth (including pregnancy) or related medical conditions including but not limited to lactation, sexual orientation, gender identity or expression, veteran or military status, religion, national origin, ancestry, marital or familial status, genetic information, status with regard to public assistance, citizenship status or any other characteristic protected by applicable equal employment opportunity laws.

If you require reasonable accommodation in completing the online application process, please email: SeeYourself@cigna.com for support. Do not email SeeYourself@cigna.com for an update on your application or to provide your resume as you will not receive a response.

The Cigna Group has a tobacco-free policy and reserves the right not to hire tobacco/nicotine users in states where that is legally permissible. Candidates in such states who use tobacco/nicotine will not be considered for employment unless they enter a qualifying smoking cessation program prior to the start of their employment. These states include: Alabama, Alaska, Arizona, Arkansas, Delaware, Florida, Georgia, Hawaii, Idaho, Iowa, Kansas, Maryland, Massachusetts, Michigan, Nebraska, Ohio, Pennsylvania, Texas, Utah, Vermont, and Washington State.",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1865,$10+ billion (USD)
Urbane Systems LLC,#N/A,Remote,Azure Data Engineer with Salesforce,"Qualifications and Skills:Qualifications and Skills:
Needs hands- on CRM experience in Salesforce Cloud Marketing
Experience in Azure Databricks
Experience with Control M
Experience in SQL is good to have
Job Type: Contract
Schedule:
8 hour shift
Work Location: Remote",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"GTA (Global Technology Associates)
4.6",4.6,"Plano, TX",Data Logging Engineer,"Looking for a Data Logging Engineer
What you will be doing as a Data Logging Engineer
· Perform system level log captures/analysis of several Network elements in the 4G/5G Network architecture to identify root causes of product and key performance issues.
· Document and maintain the troubleshooting steps including updating technical documentation for primary areas of responsibility
· Identify automation opportunities & implement scripts for log analysis, for discussions with external customers/internal customers
· Strong on customer support as well as data analysis of logs, etc.
· Must be able to drive for issue resolution with other Engineering team
· Initial analysis of Network KPI degradation to quantify and qualify the issue
· Be able to proactively perform Ad-hoc/periodic parameter audit, issue signature audit and SW/FW audit
· Ensure the latest ticket status ticket status is provided to the customers
· Software and patch upgrades on network element to support feature testing and issue resolution verification
· Provide 24X7 support as needed for commercial Network outages and network performance issues. Also provide technical reviews and provide support to customers as needed
What you will bring to the table as a Data Logging Engineer:
· Bachelor’s Degree in Telecommunication or Network Engineering with at least 2 years of experience in Wireless Telecom environment.
· Good knowledge of UNIX/LINUX operating systems
· Good Scripting skills using but not limited to Python, Shell or Perl
· Strong knowledge of MS office tools like Excel, power point and Word.
· Good analytical skills to investigate and evaluate trending data for issue resolution
· Good knowledge of 4G and 5G wireless network architecture concepts, RAN protocols and eNB interfaces S1-MME, S1-U is a plus
· Good knowledge of trouble ticket and knowledge management systems
· Willing to work during night to accommodate debugging involving offshore R&D teams
What you didn’t know about us:
· Competitive salary
· Health, Dental and Vision Benefits
· Short/Long Term Disability and Critical Care/Illness Protection
· Life Insurance and Retirement Plans
· Employee Assistance Program
· With this position, you will get the opportunity to work with our game changing clients and further advance your already valuable experience in the telecom industry!
We are Connectors. We thrive on ‘quality over quantity’ and put in the work building strong relationships. We create connections, discover qualities, uncover skills, and place people with accuracy. We are your true partner!
We are Collaborators. You’ll be working with a wholly-owned subsidiary of Kelly and part of the Kelly Telecom division. It allows us to be as nimble and fiercely competitive as a startup while having the backing of a multibillion dollar publicly traded company which has been in business for 75 years. With direct access to hiring managers, services don’t stop at standard recruiting processes. We use our expertise to improve your application skills and provide ongoing career support.
We give 24/7 Support. We are in this together. We provide around the clock availability, competitive employee benefits, and continuously check-in to make sure things are going smoothly. Check out our Glassdoor page!
Kelly Telecom is an equal opportunity employer and will consider all applications without regard to race, genetic information, sex, age, color, religion, national origin, veteran status, disability, or any other characteristic protected by law. For more information click Equal Employment Opportunity is the law.
You should know: Your safety matters! Vaccination against COVID-19 may be a requirement for this job in compliance with current client and governmental policies. A recruiter will confirm and share more details with you during the interview process.
#JobsAtKellyTelecom
Job Types: Full-time, Contract
Salary: From $50.00 per hour
Schedule:
8 hour shift
Work Location: In person",$50.00 /hr (est.),Unknown,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Kaiser Permanente
3.9",3.9,"Oakland, CA",Data Engineer - R/Python Programming (100% Remote),"Job Summary:

An R / Python Data Engineer, will be responsible for developing, maintaining, and improving data pipelines that integrate a variety of data sources, including APIs, databases, and shared network drives. The developer will work alongside a team of data analysts and developers, primarily experienced in R, to introduce robust Python-based ETL processes into our data infrastructure.

This individual contributor is primarily responsible for driving strategic data-informed decisions, gathering data and information on targeted variables in an established systematic fashion, preparing data for analytic efforts, and interpreting data analyses. This position executes creative data analytic approaches leading to actionable outcomes, develops, implements, and automates business and reporting solutions, and develops analytical and/or statistical models enabling informed business decisions.

Essential Responsibilities:

Design, implement, and maintain data pipelines leveraging multiple data sources.

Ensure the optimization, scalability, and resilience of data extraction, transformation, and load (ETL) processes.

Manage and maintain on-prem data infrastructure, ensuring high availability, security, and performance.

Collaborate with data analysts and developers to understand data needs and deliver efficient solutions.

Contribute to and advocate for coding best practices, robust documentation, and continuous improvement in data engineering practices.

Work closely with geospatial datasets and tools, ensuring efficient and accurate processing of spatial data.

Practices self-development and promotes learning in others by proactively providing information, resources, advice, and expertise with coworkers and customers; building relationships with cross-functional stakeholders; influencing others through technical explanations and examples; adapting to competing demands and new responsibilities; listening and responding to, seeking, and addressing performance feedback; providing feedback to others; creating and executing plans to capitalize on strengths and develop weaknesses; supporting team collaboration; and adapting to and learning from change, difficulties, and feedback.

Completes work assignments and supports business-specific projects by applying expertise in subject area; supporting the development of work plans to meet business priorities and deadlines; ensuring team follows all procedures and policies; coordinating resources to accomplish priorities and deadlines; collaborating cross-functionally to make effective business decisions; solving complex problems; escalating high priority issues or risks as appropriate; and recognizing and capitalizing on improvement opportunities.

Executes creative data analytic approaches leading to actionable outcomes by defining and calculating metrics to be analyzed; defining, calculating, and validating algorithms; and conducting analyses, including descriptive, correlational, inferential, and/or predictive statistics.

Develops, implements, and automates business and reporting solutions by working with stakeholders in their design, planning, and implementation while ensuring consistency and coherency; evaluating and summarizing data and results; creating summary statistics; developing data reports, visualizations, and/or interactive Business Intelligence (BI) reports; reporting to stakeholders on key findings; identifying needs for the development and implementation of additional reporting solutions; and preparing documentation as appropriate.

Interprets data analyses by applying findings to contextual settings; and developing insights, reports, and presentations telling a compelling story to stakeholders to enable and influence decision making; and providing context related to data interpretations and/or limitations as appropriate.

Drives strategic data-informed decisions by consulting with clients to identify and clarify key business needs; developing outcomes and process measures; translating business requirements; determining data/information needs and data collection methods; developing analysis plans; measuring the impact of business decisions on clients, customers, and/or members; working with clients and staff to identify opportunities and methods to improve efficiencies with analysis; supporting and training end-users; and documenting processes and deliverables.

Gathers data and information on targeted variables in an established systematic fashion by validating data sources; querying, merging, and extracting data across sources; completing routine data refresh and update; developing and/or delivering tools for electronic data collection; and providing user training, support, and documentation.

Develops analytical and/or statistical models enabling informed business decisions by determining data and analytical requirements; creating models leading to actionable insights; and testing, refining, and validating models.

Prepares data for analytic efforts by integrating and consolidating data; ensuring data quality and accuracy; profiling data inaccuracies and recommending process improvements or system changes to enhance overall quality of the data; and cleaning and creating final data set(s) for analysis.

Minimum Qualifications:

Minimum one (1) year experience in a leadership role with or without direct reports.

Bachelors degree in Mathematics, Statistics, Engineering, Social/Physical/Life Science, Business, or related field and Minimum five (5) years experience in data analytics or a directly related field. Additional equivalent work experience in a directly related field may be substituted for the degree requirement.

Additional Requirements:

Knowledge, Skills, and Abilities (KSAs): Negotiation; Business Planning; Written Communication; Data Extraction; Data Mining; Data Visualization Tools; Statistical Programming Language; Relational Database Management; Vendor Management; Project Management

PrimaryLocation : California,Oakland,Kaiser Center
HoursPerWeek : 40
Shift : Day
Workdays : Mon, Tue, Wed, Thu, Fri
WorkingHoursStart : 08:00 PM
WorkingHoursEnd : 05:00 PM
Job Schedule : Full-time
Job Type : Standard
Employee Status : Regular
Employee Group/Union Affiliation : NUE-PO-01|NUE|Non Union Employee
Job Level : Individual Contributor
Job Category : Data Analytics
Department : Po/Ho Corp - Ntl Provider Contracting-Proj - 0315
Travel : No
Kaiser Permanente is an equal opportunity employer committed to a diverse and inclusive workforce. Applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy), age, sexual orientation, national origin, marital status, parental status, ancestry, disability, gender identity, veteran status, genetic information, other distinguishing characteristics of diversity and inclusion, or any other protected status.","$142,720 /yr (est.)",10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1945,$10+ billion (USD)
"Procter & Gamble
4.1",4.1,"North Chicago, IL",Data Analytics Engineer,"Job Location
Cincinnati
Job Description
If data is in your blood, then we have the job to get your heart pumping!
From day 1, you'll be a key member of the engineering team driving end-to-end data and analytical solutions supporting the development, learning, and operational insights for our critical new engineering led initiatives in equipment, process, packaging, customization and supply chain.
As a Data Analysis Engineer, you will:
Work across important Data & Analytics Community of Excellence capability areas of: Data Science, Dana Engineering, Data Wrangling, Edge Programming, SME Analyst/Business Intelligence, Visualization/Citizen Scientist Ux.
Engage project teams to understand project needs/requirements and provide technical expertise with data and analytical tools.
Collaborate with data leaders and multi-discipline teams to design, develop and ensure critical data systems infrastructures and integration offer critical data model availability and scalability.
Ensure relevant data and analytics are available to meet initiatives and technical readiness needs by continuously addressing the data models, wrangling and cleansing data, and improving data solutions and platforms.
Explore emerging capabilities and Artificial Intelligence/Machine Learning for flawless integration and application between data scientist, functional specialists and their key user cases.
We believe the following skills will help you be successful:
Technical Mastery: Strategic, systems problem solver who will automate existing manual decision support and data workflows to drive key innovation and business performance improvement.
Builds Diverse and Collaborative Relationships: We seek an independent, collaborator who sees the interaction in our enterprise and systems while understanding the role that data and intelligence play in dramatically improving the user cases for the subject matter systems.
Leadership: Have the ability to set technical direction by applying and building mastery in our Product Supply Engineering innovation and delivery efforts, while demonstrating diverse data, analytics and visualization skills. Seeking immediate impact to accelerate our engineering processes, improve technical readiness of initiatives and enhance product and service execution in our manufacturing sites and supply network.
We offer you:
Dynamic and respectful work environment. At P&G our employees are at the core, we value every individual and encourage initiatives, promoting agility and work/life balance.
Continuous coaching. You will work with passionate people and receive ongoing coaching and mentoring from your line manager and other colleagues. Corporate and functional training will enable you to succeed and develop from day one.
Benefits. You will receive a competitive salary as well as other great benefits including a competitive pension, share ownership scheme and private healthcare.
Are you ready to join our Engineering team?
Job Qualifications
REQUIRED:
BS/MS in a quantitative field (Engineering, Data Science, Operations Research, Applied Math, Statistics, Analytics)
These positions are entry-level with up to 4 years work experience
PREFERRED EXPERIENCE:
Data management, ingesting new data, transforming/harmonizing data
Data analytics insights and work processes for learning and decision
support
Strong leadership, business problem definition, and priority setting skills
Prior Innovation Development, or Supply Chain, or IoT or related experience
An aptitude for communicating insights and collaborating across teams/organizations
Skills in data visualization (Tableau, Power BI, or similar) and script program languages (SQL, Python/Scala, R, JAVA, C+)
Data analytics and insight environments (Apache Hadoop, Spark, Hive, SQL Server, SAP Bus, WH)
Passion to learn/develop and bring in emerging trends/technology that drive further insight value
Proven success of applied analytics through related full-time or internship experience
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Job Schedule
Full time
Job Number
R000084077
Job Segmentation
Recent Grads/Entry Level (Job Segmentation)
Starting Pay / Salary Range
$85,000.00 - $115,000.00 / year","$100,000 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1837,$10+ billion (USD)
"Smart IMS
4.2",4.2,United States,Senior Data Engineer,"Job Title: Senior Data Engineer

Location: Remote (EST)

Duration: 6 Months+

Roles and responsibilities of Senior Data Engineer

Senior Engineer with 7+ yrs of Exp in AWS , Redshift and Database design, dev, deploy in reporting & ETL space

Design, Build and operationalize the enterprise data solutions and applications using AWS data analytics with Redshift and Python.

Experience in design and also hands on development of Python routines/scrip",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,1994,$100 to $500 million (USD)
"Soligent
3.5",3.5,Remote,Senior Data Engineer,"Soligent is the largest pure play solar distributor in the Americas. At Soligent, we envision a world where solar isn't just the cleanest choice for power: it's the obvious choice. Our mission is to empower homeowners and installers with a tool-set that transforms the way the world produces energy. We do this by hiring talented people, empowering our team, and being mission driven. Soligent has been featured by the White House, Forbes, Wall Street Journal, The World Economic Forum, and the Atlantic among other publications. In this role, you will see and participate in the interworking of a high growth entrepreneurial large company in a sector that changes the world.
Why Soligent?
We are the largest business of its kind in the world. With 5,000 customers in 45 countries, Soligent is an established industry leader in solar with the fast-paced and entrepreneurial spirit of a startup.
You will be part of a vital team at the forefront of transforming how people use energy. Drive positive change in the world while working with the best and brightest. Our executives have built and led successful billion-dollar companies.
We invest in you. You will learn the ins and outs of solar, be exposed to roles across the company, and receive quality training.
Why You?
Are you mission driven? At Soligent, solar is more than a job; it's our future.
Do you see solutions where others see problems? You're not satisfied with the status quo; you constantly think about how to improve processes.
Do you enjoy getting your hands dirty? You understand the big picture but also have an innate ability to drill down and execute with high attention to detail.
Can you execute individually but enjoy working with a team? We support a strong culture of teamwork where it's about the collective gain. Feedback is a big part of that.
Does your word mean everything, you take responsibility for outcomes, and are incredibly persistent? We have a culture of integrity and accountability.
Do you connect the dots easily? You can see how your role fits in with the organization.
Are you fun to be around and able to wear many hats? Soligent is a fast-paced entrepreneurial culture. We believe saving the world should be fun.

As Soligent, the leading pure-play solar distributor in the US, continues to grow rapidly, we're seeking a highly skilled Senior Data Engineer to build the foundational datasets and pipelines for robust financial, supply chain, and operations reporting. You'll be at the forefront of integrating our product, financial, and business systems to create rock-solid processes that will propel us forward. If you're passionate about analytics use cases, data models, and solving complex data problems, then we want you on our team. The perfect candidate will bring expertise in developing and maintaining high-quality and robust datasets housed within our data warehouse to power our Power BI infrastructure. It will be beneficial for the candidate to understand NetSuite's SuiteQL, SuiteAnalytics, and the NetSuite2 schema. Additionally, the ideal candidate will have hands-on experience with Fivetran and DBT for creating scalable and trustworthy data pipelines. Understanding the software development lifecycle and having a knack for building and leading data teams will be an added advantage. This role requires proficiency with AWS Redshift, and familiarity with Microsoft's Azure Synapse Analytics is considered advantageous. Mastery of SQL, with an intimate understanding of aggregation functions, window functions, UDFs, self-joins, partitioning, and clustering approaches for optimal query performance, is a key requirement for this role.
Responsibilities:
Work closely with stakeholders in engineering, finance, sales, marketing, strategy, and governance to make high-quality datasets available to consumers in a timely manner.
Collaborate proactively with the Business Intelligence team to translate business requirements into technical specifications.
Establish and adhere to quality assurance practices and procedures, performing detailed testing of data pipelines.
Construct scalable and dependable data pipelines using Fivetran to bolster robust reporting across finance, sales, supply chain, and operations.
Spearhead troubleshooting initiatives and determine root causes of issues to ensure their resolution.
Minimum Qualifications:
BS/BA degree in Computer Science, Math, Physics, or a related field, or equivalent years of experience in a relevant field
3+ years experience in SQL with a deep understanding of aggregation functions, window functions, UDFs, self-joins, partitioning, and clustering for high-performing queries.
Preferred Qualifications:
Comprehensive understanding and experience with the new NetSuite2 schema.
Documented experience with Microsoft's Power BI and business intelligence data modeling.
Hands-on experience with Fivetran for building data pipelines.
Proficiency with DBT is highly desirable.
Must have experience with AWS Redshift.
Familiarity with Microsoft's Azure Synapse Analytics is considered a plus.
In-depth understanding of the software development lifecycle.
Experience building and leading data teams is a significant advantage.
Profound knowledge of ETL processes, data management, and data warehouse principles.
Proven capability to troubleshoot and resolve complex technical issues. Excellent interpersonal skills with the ability to collaborate effectively in cross-functional teams.
Certified NetSuite Developer or equivalent professional experience is a plus.

Compensation for this role for a candidate based in Colorado is expected to be between $150,000 - $200,000 and for a candidate in NYC is expected to be between $150,000 - $200,000, but may be higher or lower in other States due to geographic differentials in the labor market.

#ZR
Benefits
Medical, Dental, Vision, 401K, HSA, FSA, Flexible PTO
California Privacy Protection Notice",#N/A,51 to 200 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,#N/A,$100 to $500 million (USD)
"Workday
4.2",4.2,"Pleasanton, CA",Data Governance Engineer,"Your work days are brighter here.
At Workday, it all began with a conversation over breakfast. When our founders met at a sunny California diner, they came up with an idea to revolutionize the enterprise software market. And when we began to rise, one thing that really set us apart was our culture. A culture which was driven by our value of putting our people first. And ever since, the happiness, development, and contribution of every Workmate is central to who we are. Our Workmates believe a healthy employee-centric, collaborative culture is the essential mix of ingredients for success in business. That’s why we look after our people, communities and the planet while still being profitable. Feel encouraged to shine, however that manifests: you don’t need to hide who you are. You can feel the energy and the passion, it's what makes us unique. Inspired to make a brighter work day for all and transform with us to the next stage of our growth journey? Bring your brightest version of you and have a brighter work day here.
About the Team
The Enterprise Data Governance Team will drive the creation of policies, procedures, and operating models that will improve the overall quality and reliability of data across Workday in support of operational and analytical strategic business outcomes. Reporting to Senior Director of Data Governance, The Senior Data Governance Engineer will support Workday’s analytics consumers to accelerate the speed of delivery and the trust of business in the analytics that they consume. The ideal candidate is a top-tier professional with experience in data governance and leading business change through data.
About the Role
As a part of the Enterprise Data and Analytics organization and our growing Governance team, you will be in a unique position to directly impact the future of Workday. We are looking to expand with a member who brings technical knowledge of data governance and application to data warehouse/data lake (Snowflake), personal drive and passion in data to the team. Our highly collaborative environment means you will be working with a diverse group of talented people committed to innovation and continuous improvement.
About You
Basic Qualifications
4+ years of experience with enterprise data management, governance, analytics, compliance, and security.
Contribute to the creation and provide technical input to Data Governance policies, standards and processes related to data, access and security in all environments from ingestion into Snowflake all the way to consumption.
Work closely with Data Engineering / Platform team to create onboarding and intake documentation and definitions as repeatable processes
Ensure that Data Governance policies and procedures are adhered to for onboarding intake requests, data classification and data ownership
Ensure controls are in place for access and security for IT managed and self-service environments
Implement remediation plans to resolve incidents
Track and certify remediation plans and exceptions are followed as planned
Create success criteria and KPIs and report on them as the (Snowflake) Data Governance status to CDO Office
Define the SLAs for Data Warehouse Governance and apply Service Management where applicable
Audit and report the Data Warehouse ecosystem to ensure governance adherence
Work with business functions to create a plan for compliance and access control
Evaluate and recommend 3rd party technologies that advance the Data Governance roadmap
Identify areas of continuous improvement and automation
Keep up to date on data warehouse and data lakes on the market as well as Snowflake feature releases, and coordinate with Data Engineering team on development opportunities
Proficient with data lakes/lake houses/warehouses relating to administration, security, and data architecture.
Solid experience with SQL
Experience with data catalogs, glossaries, and metadata management
Experience in crafting data governance and security policies, standards, and playbooks.
Experience in defining business requirements for tools and platforms for vendors.
Knowledge of relevant compliance regulations and frameworks such as GDPR, CCPA, HIPPA, SOC II, etc.
Other Qualifications:
Self-drive and proactive approach
Experience with Snowflake, Fivetran (or similar ELT/ETL tools), and Collibra (or similar data cataloging tools).
Ability to communicate effectively with technical and business teams.
Strong time management and organizational skills.
Ability to collaborate on multiple initiatives or projects concurrently
Ability to work independent while enjoying teamwork for result

Workday Pay Transparency Statement - United States
The annualized base salary ranges for the primary location and any additional locations in the United States (US) are listed below. Workday pay ranges vary based on work location. As a part of the total compensation package, this role may be eligible for the Workday Bonus Plan or a role-specific commission/bonus, as well as annual refresh stock grants. Recruiters can share more detail during the hiring process. Each candidate’s compensation offer will be based on multiple factors including, but not limited to, geography, experience, skills, job duties, and business need, among other things. For more information regarding Workday’s comprehensive benefits, please
click here
.

Primary Location: USA.CA.Pleasanton
Primary Location Base Pay Range: $176,400 - $264,600
Additional US Location(s) Base Pay Range: $128,900 - $264,600

Our Approach to Flexible Work

With Flex Work, we’re combining the best of both worlds: in-person time and remote. Our approach enables our teams to deepen connections, maintain a strong community, and do their best work. We know that flexibility can take shape in many ways, so rather than a number of required days in-office each week, we simply spend at least half (50%) of our time each quarter in the office or in the field with our customers, prospects, and partners (depending on role). This means you'll have the freedom to create a flexible schedule that caters to your business, team, and personal needs, while being intentional to make the most of time spent together. Those in our remote ""home office"" roles also have the opportunity to come together in our offices for important moments that matter.
Pursuant to applicable Fair Chance law, Workday will consider for employment qualified applicants with arrest and conviction records.
Workday is an Equal Opportunity Employer including individuals with disabilities and protected veterans.
Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!","$196,750 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
"Encore Technologies
4.5",4.5,Ohio,Data Engineer,"Data Engineer
Job Details
City :
State :
OH

Job Description:
Must Have
Data Architecture
Data Modeling
ETL

Nice To Have
Apache Kafka
Cloud Data Warehousing - Snowflake preferred.
ETL Tools:
Talend BigData 7.x/6.x
Talend Integration Suite 7.x/6.x
Talend ESB
Matillion ETL for Redshift 1.39.9
DataStage 11.x/9.x/8.x/7.x PX
Quality Stage, profile stage
Information Analyzer
Fast Track, Business Glossary
Metadata Work Bench
Informatica
Languages:
SQL
PL/SQL
UNIX Shell Script
Java
Python
SCALA
Basic C & C++
Amazon Redshift databases
Databases:
Big Data, Hadoop
Hive, NoSQL
Oracle 8i/9i/10g
IBM DB2
TeraData
SQL Server
Sybase
MS-Access 2007
Other DW-BI Application Tools:
Toad 7.x, DB2-AQT 7.x
DataStage version control tool
HP-PVCS Versioning tool
Micro strategy 8.1.0
Business Objects
Cognos
QlikView
Tableau.
Environment:
Spark-Hadoop v2.4.2
AIX Unix 5.2
Windows 98
XP
2K, Windows7/10
AWS. Methodologies:
ER*win Data Modeler
Dimension Modeling
ER Modeling

MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED:
Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience.
Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group.
Fundamental understanding of distributed computing principles
Knowledge of application and data security concepts, best practices, and common vulnerabilities.
Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, Bi and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.

ESSENTIAL DUTIES AND RESPONSIBILITIES:
Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities.
Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the Bank.
Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc.
Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics.
Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes.
Evaluate software products and provide documented recommendations as needed.
Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents.
Participate in the planning process for hardware and software.
Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation.
Provide technical guidance and mentoring for other team members.
Manage and prioritize multiple assignments.

Encore Technologies is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce.",#N/A,201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2014,$100 to $500 million (USD)
"Ignite Digital Services
4.3",4.3,Remote,Data Engineer,"Data Engineer
Are you searching for an opportunity to take your career to the next level? Ignite Digital Services is a fast-growing small business delivering innovative business solutions to the national security sector. We bring data science and analytics together to optimize program integration and empower operational decisions for national security clients.
Ignite Digital Services has a fantastic opportunity for a Data Engineer to support our client engagements within the federal government. The ideal candidate is a self-starter with strong analytical skills and a strong work ethic. This position serves an important role in supporting senior-level executive customers at Assistant Secretary of the Navy for Research, Development, and Acquisition (ASN/RDA) Research and Development to understand their business challenges within a multi-functional team and offer data centric solutions to enhance decision-making.
Perks of Working at Ignite Digital Services:
Competitive pay and benefits, including PTO
Education stipends and referral bonuses
Compelling work with the U.S. federal government
Strong emphasis on volunteer and community engagement
Opportunity to shape the future of our industry
Supportive colleagues and management who invest in your growth
Responsibilities:
Develop, test, and deploy data pipelines within the Databricks platform to process, transform, and model data for use in analytic solutions leveraged by clients and end users for strategic decision making.
Collaborate with SMEs to translate high-level business requirements into defined business rules and data transformations from source to target environments supporting key performance indicators & metrics.
Data modeling and script development to support AI/ML models and Qlik dashboard solutions
Identify methods to collect, analyze, and manage data with the goal of making recommendations to improve data quality and the efficiency of data processes
Evaluate the performance and applicability of tools against customer and client requirements
Foster collaborative business relationships with stakeholders, business partners, and team members
Minimum Qualifications:
Ability to obtain a DoD security clearance
Bachelor’s Degree in Computer Science, Information Technology, Data Science, Business, Economics or other related field
6+ years of technical experience with Business Intelligence and Data Analytics solutions
2+ years of experience implementing data pipelines supporting enterprise analytics and visualization platforms
Experience with programming languages (R, Python, SQL, etc. ) for data transformation, modeling, and custom visualizations in cloud data platforms such as Databricks or Snowflake
Hands on experience in performance tuning and optimizing code running in environments such as Apache Spark, Databricks, Snowflake, Cloudera, or Amazon EMR
Experience working with a variety of stakeholders to translate business requirements into transformation logic and data schemas to support dashboards and analytics.
Demonstrated experience in handling a variety of data formats such as JSON, CSV, Parquet, ORC, and Delta Lake.
Ability to take initiative and work independently, and quickly transition to reassess priorities
Preferred Qualifications:
Active DoD security clearance
Experience with DoD business practices and data management systems / processes like ADVANA/Jupiter tools including Databricks and Qlik
Knowledge of the system development life cycle, software project management approaches and requirements, design and test techniques including experience working in a DevOps/DevSecOps delivery environment
Experience in mentoring/training/coaching others in technical concepts
Adapts quickly to new situations, is willing to learn new technologies and works well in a team environment, leading individual projects without the need for supervision
*Ability to obtain a DoD Government Security Clearance is mandatory for this position*
Salary: $95,000+ to align with education & experience
Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information.
Ignite Digital Services is a Small Business committed to providing exceptional service to government agencies at competitive prices. The capabilities and experience of our staff and our extensive industry relationships distinguish Ignite Digital Services among government contractors.
Ignite Digital Services is an EEO/AA/Disability/VETS Employer. Hiring, promotion, transfer, compensation, benefits, discipline, termination, and all other employment decisions are made without regard to race, color, religion, sex, sexual orientation, gender identity, age, disability, national origin, citizenship/immigration status, veteran status, or any other protected status.
For individuals who would like to request an accommodation, please visit https://bit.ly/2XqZoLM(CA) or https://bit.ly/3Eo922f(SC) or contact Human Resources. Ignite Digital Services will not make any posting or employment decision that does not comply with applicable laws relating to labor and employment, equal employment opportunity, employment eligibility requirements or related matters. Nor will Ignite Digital Services require, in a posting or otherwise, U.S. citizenship or lawful permanent residency in the U.S. as a condition of employment except as necessary to comply with law, regulation, executive order, or federal, state, or local government contract.
AAP - Atlas Executive Consulting LLC (CA) 2022 Policy Statement
OFCCP'S Pay Transparency Rule
EEO is the Law Poster
AAP - Atlas Executive Consulting LLC (SC) 2022 Policy Statement
Job Type: Full-time
Pay: From $95,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
6 years
Schedule:
8 hour shift
Experience:
SQL: 6 years (Preferred)
Data warehouse: 6 years (Preferred)
Work Location: Remote","$95,000 /yr (est.)",51 to 200 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2006,$5 to $25 million (USD)
"Disney
3.9",3.9,"Santa Monica, CA",Sr Data Engineer,"Sr Data Engineer
Job ID
10055150
Location
Santa Monica, California, United States / New York, New York, United States / Seattle, Washington, United States
Business
Disney Media & Entertainment Distribution
Date posted
Sep. 21, 2023
Job Summary:
We are seeking a motivated and experienced senior data engineer for the search platform team for our Disney Streaming apps (Disney+, Hulu and Star+). As a data engineer on this team, you will work alongside a team to design, build, and manage scalable data pipelines that power search functionality for Disney Streaming. This team has an enormous impact on millions of users of our streaming applications.
Responsibilities:
Expand and optimize our search technology’s data pipeline architecture to enhance the user experience for Disney Streaming customers
Collaborate with Machine Learning engineers and data scientists across the organization to support a robust data delivery pipeline for Search use cases
Collaborate with cross-functional teams like Product and Program to identify search-related business requirements and provide technical solutions
Mentor, empower and provide career growth opportunities for team members
Foster and maintain effective communication channels with your team members, stakeholders, and leadership.
Monitor and improve the performance, scalability, and reliability of our search infrastructure’s data pipelines
Keep Search data separated and secure across multiple data centers and AWS regions
Leave systems better than you found them
Qualifications:
Bachelor's or Master's degree in Computer Science, Software Engineering, or a related field.
At least 5 years of experience in software engineering or data engineering, with a focus on building well-designed databases, data pipelines and contributing to a positive team environment
Demonstrated success in being part of a team problem-solving, designing and implementing end-to-end software at scale
Mentorship experience & a desire to help your fellow engineers get better at what they do
Excellent communication and collaboration skills, with experience presenting and explaining complex technical ideas to peers and leadership
Biased towards action, with experience delivering high-quality software solutions on time, at scale and within budget.
Nice To Haves:
Solid understanding of search technologies, such as Elasticsearch, Solr, or Lucene, and applied machine learning techniques, such as supervised and unsupervised learning, deep learning, and natural language processing.

The hiring range for this position in California is $145,400 - $181,700 per year, in New York is $139,040 - $173,800 per year and Washington is $139,040 - $173,800 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$156,420 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Publicis Media
3.9",3.9,"New York, NY",Senior Data Engineer,"Company Description

Publicis Media is one of Publicis Groupe’s four solution hubs, aligning all of Publicis Groupe’s media agencies and operations. Publicis Groupe (Euronext Paris Exchange: FR0000130577; CAC 40 index), is the world’s third largest communications group. The Data, Technology and Innovation Global Practice was created to deliver best-in-class programmatic solutions as well as to consolidate Publicis Media’s data and technology to transform our business from a service business to a platform business.

Job Description

Our team is looking for a high-performing Data Engineer who will be responsible for the design, development, implementation and on-going support of a data driven software platform. The candidate should be able to enjoy and thrive in a fast-paced environment on multiple projects simultaneously, including both enhancements as well as new project development. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.
Responsibilities:
Analyze business requirements and partner with stakeholders to provide a strategic solution
Work independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard
Collaborate across the organization to build solutions that achieve business objectives, including with frontend engineers to design or modify schema for optimal software performance
Guide stakeholders with operational decisions that impact data structures and connectivity
Bring best practices in data architecture and data visualization to the table
Build tools in a generic fashion for reuse across other solutions
Develop technical documentation for each solution
Manage projects in an agile environment

Qualifications
Minimum Bachelor’s Degree in Computer Sciences, Information Technology, or its equivalent
3+ years’ experience with building ETL pipelines using Python
Experience and thorough understanding of RESTful APIs is required
Knowledge of a variety of digital marketing platform APIs is preferred
5+ years’ experience with SQL and databases
Comfortable with data warehousing concepts, preparing data, and configuring automated workflows
Excellent communication and presentation skills as well as an analytical mindset
Experience with complex logic
Strong data analysis skills
Experience connecting and merging disparate datasets
Strong organizational skills & attention to detail
Possess a desire to work for a fast-paced, results-based company
Experience managing multiple projects simultaneously
Desired Skills/Experience:
Experience with the entire AWS product range specifically:
Redshift
AWS Glue and Lambda functions
Python / Spark
Familiarity with CI/CD concepts

Additional Information

Compensation Range: $81,500 - $128,000 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off.
All your information will be kept confidential according to EEO guidelines.
REQ # 23-7229","$104,750 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Advertising & Public Relations,1926,$5 to $10 billion (USD)
"Michigan Farm Bureau Family of Companies
3.4",3.4,"Lansing, MI",Data Analytics Engineer,"OBJECTIVE:
To design and build datasets and structures, integrated from a variety of data sources, to be used by a broad range of advanced analyses performed by the Data Analytics (DA) team. To develop, optimize, test, operationalize, monitor, and improve dynamic data pipelines that feed advanced analytical models and solutions developed by the DA team. To collaboratively partner with technical resources, DA team members, and project teams in the deployment of datasets, pipelines, and ultimately the advanced analytical solutions they support into production environments. To respond to requests for queries, data, and analyses as needs arise from various areas and committees within the organization.
RESPONSIBILITIES:
Gather, create, and prepare complex, multivariable datasets for use in support of a wide variety of DA models and solutions. Regularly transform, profile, cleanse, and blend data from a variety of sources. Actively partner with other DA and business stakeholders to understand use cases and their related data requirements.

Refactor, refine, and optimize data acquisition and preparation processes to be transparent, efficient, and reproducible. Extend such processes into on-demand or fully automated production-level pipelines. Engineer components to support multiple DA solutions, whenever possible.

Maintain a close and collaborative working relationship with the Data Scientist role in iteratively engineering datasets and pipelines supporting DA models and solutions. As needed, produce queries and analyses requested of the DA team. Communicate results and present insights back to various audiences.

Comfortably utilize a wide variety of technologies and platforms, both on-premises and in the cloud, for retrieving, processing, and storing data. Maintain a particularly proficient SQL skillset, comfort using Python and R, and familiarity with Spark, Knime, Azure, and Databricks. Demonstrate flexibility working with various formats of data, including unstructured data, as well as techniques necessary to handle, parse, and extract features. Possess a foundational understanding of data warehousing, data modeling, and related architectural concepts.
QUALIFICATIONS:
Required:
Bachelor’s degree required, preferably in information systems, computer science, data engineering, database systems, data analytics, or other technical fields. Equivalent experience may be considered.

Three to five years of experience working with Microsoft SQL Server, T-SQL, Visual Studio IDE, SSIS, or equivalent ETL platforms required.

Three years of experience building automated, dynamic data pipelines required.

Preferred:
Experience working with data handling tools in cloud environments, such as Azure or Databricks, strongly preferred.

Experience working in a data engineering role in support of a data science team strongly preferred.

Experience working with transactional data strongly preferred.

Experience working with insurance data preferred.

Associate/Certified Insurance Data Manager (AIDM/CIDM), Certified Data Management Professional (CDMP), Azure Certification, Certified Business Intelligence Professional (CBIP), Associate in Insurance Data Analytics (AIDA), or related certification preferred.

Note: This is a Hybrid position working both remotely, and in the Farm Bureau Home Office located in Lansing, Michigan.

Farm Bureau offers a full benefit package including medical, dental, vision, and 401K.

PM19","$83,500 /yr (est.)",51 to 200 Employees,Company - Private,Agriculture,Crop Production,#N/A,Unknown / Non-Applicable
"MicroStrategy Services Corp.
3.8",3.8,"Tysons Corner, VA",Data Analytics Engineer,"Company Description

4000+ customers. Direct operations in 27+ countries. 5 global development centers. MicroStrategy is the largest independent publicly traded analytics and business intelligence company in the world. And we are all about innovation.
Since our inception in 1989, we have continuously pushed boundaries and transformed the landscape of enterprise analytics. In 2010, it was with MicroStrategy Mobile, one of the first mobile analytics platforms for enterprises. In 2019, it was with HyperIntelligence, the most comprehensive embedded BI tool. And we are doing it again with MicroStrategy ONE, an AI-integrated Business Intelligence platform that will transform how organizations approach analytics.
We are consistently ranked as the best Enterprise Analytics platform. And we drive value all around – for organizations around the world with innovative data analytics solutions; for investors with our sound financial strategies; and for our employees by giving them an agile working environment where they can grow.

Job Description

We are seeking a highly motivated Data Analytics Engineer to join our team. As a Data Analytics Engineer, you will be responsible for designing, developing, and implementing natural language processing (NLP) and AI-based solutions to enhance our products and services. You will work collaboratively with cross-functional teams to identify and solve complex problems using NLP and AI techniques.
Responsibilities:
Design, develop, and implement NLP and AI-based solutions to enhance our products and services.
Collaborate with cross-functional teams, including data scientists, software engineers, customer support specialists and product managers, to define and deliver NLP and AI solutions.
Conduct data analysis and exploratory research to identify potential areas for improvement.
Build and maintain large-scale data pipelines and ETL processes to support NLP and AI workflows.
Utilize programming languages such as Python, R, and SQL to develop and deploy NLP and AI models. Leverage and integrate with GPT models.
Implement best practices for NLP and AI model training, validation, and deployment to ensure accuracy, scalability, and maintainability.
Monitor and evaluate the performance of NLP and AI models, and refine them to improve accuracy and efficiency.
Keep up-to-date with the latest NLP and AI research and techniques, and share your knowledge with the team.

Qualifications

Required Experience and Skills:
Motivation, Innovation, Passion, Integrity, Teamwork, Customer-Focus.
Qualifications:
Bachelor's or Master's degree in Computer Science or a related field.
Proven experience in developing and deploying NLP and AI-based solutions.
Strong programming skills in Python, R, and SQL.
Experience with NLP and AI frameworks such as NLTK, Spacy, TensorFlow, or PyTorch.
Familiarity with data visualization tools such as MicroStrategy preferred.
Strong analytical and problem-solving skills.
If you are a passionate and driven Data Analytics Engineer who wants to make an impact with cutting-edge technologies, we would love to hear from you!

Additional Information

MicroStrategy is an Equal Employment and Affirmative Action employer F/M/Disability/Vet/Sexual Orientation/Gender Identity. All qualified applicants will receive consideration for employment without regard to race, creed, color, religion, national origin, sexual orientation, gender identity, disability, veteran status, sex age, genetic information, or any other legally-protected basis.

MicroStrategy is an Equal Employment /Affirmative Action employer and provides reasonable accommodation for qualified individuals with disabilities and disabled veterans in job application procedures. If you have any difficulty using our online system and you need an accommodation due to a disability, you may contact us about your interest in employment at 703-848-8600.","$107,544 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Computer Hardware Development,1989,$500 million to $1 billion (USD)
"Steampunk
4.6",4.6,"McLean, VA",Data Visualization Engineer,"Overview:
Steampunk wants you to join our awesome team as Data Visualization Engineer. In this role you'll be working with a large team of Steampunk and clients to identify data sources, tools, and mission challenges that can all be brought together to create decision-supporting insights and information. Your main goal in this work is to use the data that we have as a team and client base to provide meaningful information and representations of data to enable our client to make better and quicker decisions. We are looking for more than just a ""Data Visualization Engineer"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.
Contributions:
Will be a Subject Matter Expert for a large contract supporting a major federal agency and will be responsible for creating visually appealing and operationally impactful dashboards and reports. This impactful work will translate our client's data into actionable insights
Use expert knowledge of data visualization tools to deliver information that allows client users to quickly understand data, ask better questions, and take action
Design, develop, and deliver analytics solutions with consideration for functionality, data, security, integration, infrastructure, and performance
Collaborate with clients and stakeholders
Help define enterprise data and technology needs to support business intelligence and analytics
Facilitate meetings with diverse and sometimes conflicting points of view
Support an Agile software development lifecycle
You will contribute to the growth of our Data Exploitation Practice!
Qualifications:
US Citizen Only
Ability to hold a position of public trust with the US government.
Bachelor’s degree and 5 overall years of experience
2-4 years of experience in designing, developing, and configuring data visualizations for different types of users
2-4 years of experience using Tableau, Power BI, or other tools to create and develop robust reporting applications
2-4 years of experience with data management disciplines including data governance, data architecture, data modeling, data storage, data security, data integration, and data quality
Ability to lead or participate in business sessions to identify and document analytic use cases
Ability to be a self-starter, take ownership of opportunities, work independently, and manage simultaneous projects
Excellent written and verbal communications skills with the ability to explain advanced concepts to audiences of varying levels using simple terms
About steampunk:
Steampunk is a Change Agent in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our Human-Centered delivery methodology, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an employee owned company, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com.

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.","$85,408 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2003,Unknown / Non-Applicable
"Onebridge
3.9",3.9,"Indianapolis, IN",AWS Data Engineer,"Onebridge is a Consulting firm with an HQ in Indianapolis, and clients dispersed throughout North America and beyond. We have an exciting opportunity for a highly skilled AWS Data Engineer to join an innovative and dynamic group of professionals at a company rated among the top “Best Places to Work” in Indianapolis since 2015.
AWS Data Engineer | About You
As an AWS Data Engineer, you are responsible for designing, building, and maintaining scalable data pipelines and infrastructure in AWS. You will collaborate with technical professionals to provide high-quality data that powers our analytics and reporting solutions. You possess strong analytical skills and the ability to combine data from different sources. You are naturally inquisitive and open to the exploration of underlying data, finding valuable insights, and working with functional areas to drive identified actions.
AWS Data Engineer | Day-to-Day
Assist with the planning, designing, development, and execution of the migration.
Provide recommendations for optimization of AWS environment including the development and creation of tables, views, materialized views, indexes, constraints, and ETL routines.
Perform data profiling and data quality to find discrepancies, missing values, aggregation, and other data quality issues.
Partner with Solution Architects and API Developers to build and deploy a best-in-class solution while adhering to global compliance standards.
Proactively identify and implement opportunities to automate tasks and develop reusable frameworks.
AWS Data Engineer | Skills & Experience
8+ years of professional IT experience with at least 4+ years working with Amazon Web Services (AWS).
Experience working on at least two recent large-scale projects migrating from on-prem to AWS.
Expert-level Python Development and SQL experience.
Highly skilled in all aspects of AWS including Code Pipeline, Cloud Formation, Lambda, Glue, Event Bridge, Secrets Manager, Redshift, RDS, and DMS.
Hands-on experience with GitHub repository creation and management.
Experience with Profisee, Jira, and ServiceNow is a bonus.
100% Employee-Owned & a Best Place to Work in Indiana, since 2015.","$101,509 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,Unknown / Non-Applicable
"Hashmap
3.5",3.5,"Costa, WV",Data Engineer,"Req ID: 255243
NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Data Engineer to join our team in Heredia, Heredia (CR-H), Costa Rica (CR).
Data Engineer Job Description
JOB PURPOSE AND IMPACT
The Data Engineer will design, build and operate high performance data centric solutions utilizing the comprehensive big data capabilities for the company’s data platform environment. In this role, you will act as an authority for data access pathways and techniques working with analysts within the functional data analytics team. You will design data structures and pipelines to collect data and design and implement data transformations, combinations or aggregations.
KEY ACCOUNTABILITIES
Collaborate with businesses, application and process owners, and product team members to define requirements and design solutions for the company’s big data and analytics solutions.
Participate in the decision-making process related to architecting solutions.
Develop technical solutions utilizing big data and cloud-based technologies and ensuring they are designed and built to be sustainable and robust.
Perform data modeling and prepare data in governed databases for use in various analytics tools and configurate and develop data pipelines to move and optimize data assets.
Provide necessary technical support through all phases of solution life cycle.
Build prototypes to test new concepts and be a key contributor of ideas and code that improve the core software infrastructure, patterns and standards.
Help drive the adoption of new technologies and methods within the functional data and analytics team and be a role model and mentor for data engineers.
Independently handle complex issues with minimal supervision, while escalating only the most complex issues to appropriate staff.
Other duties as assigned.
MINIMUM QUALIFICATIONS
Bachelor’s degree in a related field or equivalent experience
Proficiency in at least one backend programming language such as Java, Python, Scala, Golang.
Experience building CI/CD pipelines ensuring Code Quality and best standards with market tools (SonarQube, Veracode, Vela.io)
Proven experience using SQL (stored procedures) or NoSQL, performance tuning and query optimization.
Proven experience using Snowflake to build solutions that deliver value through leveraging data as an asset and assuring best practices around the solution usage.
Understanding of Cloud Computing, preferability for AWS
Experience with Unix shell scripting
Experience developing software using agile methodologies such as Scrum and/or Kanban
Strategic thinking, problem solving, and analytical skills
Strong interpersonal skills, ability to build trust and relationships and influencing others
Result orientation and ability to work in ambiguous situations where requirements are not clear
5 + experience in data and Intelligence- Data Warehouse- Snowflake.
PREFERRED QUALIFICATIONS
Experience with data modeling, data warehousing and/or analytical tools
Experience in building batch and streaming data pipelines using AWS Glue, Kafka and/or Spark.
About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.","$90,832 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1967,$10+ billion (USD)
"Katalyst Healthcares & Life Sciences Inc
3.6",3.6,"Morton, IL",Data Engineer,"Responsibilities:
The main function of a data engineer is to ensure that the data assets of an organization are supported by an architecture that supports the organization in achieving its strategic goal.
A typical data engineer is responsible for setting enterprise standards for databases, data integration, and the means to get to the data.
Test programs or databases, correct errors and make necessary modifications.
Modify existing databases and database management systems or direct programmers and analysts to make changes.
Write and code logical and physical database descriptions and specify identifiers of database to management system or direct others in coding descriptions.
Work is typically directed by a direct supervisor, project or team lead. Decisions on routine, medium risk issues that may affect the project team, suppliers or internal customers may be made by this position.
Challenges include meeting expectations in delivering results, learning to refine solutions to better fit complex situations, making timely decisions, and communicating effectively with all project stakeholders.
Requirements:
Familiarity with database such as Snowflake, DB2, SQL Server, Oracle (2-3 of these are required)
Programming languages - SQL(required), Python(required) and SAS(preferred)
Experience working with large data sets, preferably in several GB or millions of transactions.
Visualization - PowerBI(required), Tableau(preferred)
Experience working with platform integration tool like Snaplogic is preferred
Experience working with AWS (required)
Top 3 technical skills: Python, Snowflake, PowerBI
Communication, Team-work, Problem Solving, Customer Focus
Associate's degree in computer programming or a relevant field required. Bachelor's degree preferred.
2-4 years experience required.
Job Type: Contract
Experience level:
3 years
Schedule:
Day shift
Monday to Friday
Ability to commute/relocate:
Morton, IL 61550: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person","$84,430 /yr (est.)",51 to 200 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,#N/A,Unknown / Non-Applicable
"Zipongo
4.0",4.0,Remote,Senior Data Engineer,"About us:

We are the world’s largest telenutrition and foodcare solution, backed by a national network of Registered Dietitians and designed to yield consistently healthier food choices, lasting behavior change and long-term results. Foodsmart’s highly personalized, digital platform guides members through a personalized journey to eating well while saving them time and money. Foodsmart seamlessly integrates dietary assessments and nutrition counseling with online food ordering and cost-effective meal planning for the whole family that makes the most of ingredients at home and on the go. With national and regional retail partners across the US now accepting SNAP/EBT, Foodsmart helps bring healthier food within reach to eligible members and can also assist with SNAP enrollment.

Founded in 2010 by CEO Jason Langheier, MD, MPH, Foodsmart has supported over 1.5 million members from over 700 health plan, employer and health system clients, and raised over $70 million in funding from leading strategic and venture investors like Advocate Aurora Health, Blue Cross Blue Shield Massachusetts, Seventure (Natixis), Mayfield and Founder Collective.

Learn more at www.foodsmart.com

About the role:

The Senior Data Engineering is a critical role responsible for constructing and optimizing our data pipeline architecture, collaborating closely with data scientists and analysts to facilitate data-related functionalities. The Senior Data Engineer will be pivotal in designing, building, and maintaining highly scalable data pipelines, optimizing data delivery, and automating data processes. They will work closely with cross-functional teams to ensure efficient data flow and contribute to the success of our data-driven initiatives.

You will
Own the optimization of data delivery for various cross-functional teams.
Design, construct, install, test, and maintain highly scalable data pipelines.
Collaborate closely with data architects, data scientists, and analysts to fulfill data requirements.
Develop automated data processes for cleaning, validation, correction, and data mining.
Identify, implement, and enhance internal process improvements, automating manual processes, and enhancing scalability.

You are
Proactive and act as a driving force for efficient data delivery and infrastructure.
Focused on quality and approach every data-related project with enthusiasm.
Diligent in ensuring secure and compliant handling of data in accordance with relevant regulations.
Collaborative and adept at addressing data-related technical issues and supporting stakeholders' data infrastructure needs.
An expert in data warehouse architecture, data modeling, and automated data pipelines

You have
A minimum of 3 years of experience in a Data Engineering role.
Hands-on experience with data warehouse solutions such as Snowflake, Redshift, or BigQuery.
Advanced SQL knowledge and proficiency in working with relational databases.
Familiarity with data pipeline and workflow management tools like Apache Airflow or Luigi.
Strong analytical skills and the ability to thrive in a fast-paced environment.
Familiarity with healthcare data standards like FHIR and HL7 is advantageous but not mandatory.
Bachelor’s degree in Computer Science, Engineering, Mathematics, or related field; Master’s degree is a plus.

$160,000 - $220,000 a year
Role: Senior Data Engineer
Level: IC4-IC5
Location: Remote
Base Salary Range: $160,000/yr to $220,000/yr + equity + benefits

Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries at our headquarters in San Francisco, California. Individual pay is determined by work location, job-related skills, experience, and relevant education or training.
Foodsmart is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any other protected class.","$190,000 /yr (est.)",51 to 200 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2011,$25 to $100 million (USD)
Second Dinner,#N/A,California,Mid-Level Data Engineer,"Who We Are
Second Dinner is an award-winning independent game development studio that is here to make the most fun games in the world. Not super fun games. Not SUPER DUPER fun games. We mean the MOST fun games. In fact, our game MARVEL SNAP has earned multiple Mobile Game of the Year Awards (Game Awards, DICE), Best Strategy Game (IGN), and the Apple Design Award for Innovation!
Second Dinner is a remote-first studio, so while we are headquartered in Irvine, California, most of our team is fully remote across the United States. We want the most talented teammates wherever they call home. A diverse team with varied perspectives makes us a better company and will help us make better games. If you can bring something new to the table and expand our point of view, that's a huge upside.
Our Data Team
At Second Dinner, data plays a crucial role in conveying the voices of our players and informing our decisions, which leads us to great games and player experiences. Our team enables decision-making with scientific and methodological rigor for Marvel SNAP and our new projects. We partner with teams across the studio to build data-powered player experiences directly into the games. We innovate in analytics tooling and data engineering capabilities to redefine what is possible in game development and operations.
Your Role
You will report to the Data Engineering Lead. You will play a critical role in shaping data-driven insights across our organization. You will develop and operate data pipelines to empower analytics, data science, marketing, product management, and design teams to create incredible player experiences. You will build and operate large-scale cloud data infrastructure. You will collaborate with cross-functional teams to ensure the collection and serving of timely high-quality data. Moreover, you will partner with the AI team to innovate in self-service analytics tools. If you are passionate about building high-impact core capabilities to help craft world-class game experiences and are excited to influence millions of players by leveraging your expertise in data engineering, then APPLY!!!

What You'll Do:
Develop and operate data infrastructure and pipelines to enable robust data for analytics and reporting in Marvel SNAP
Empower the SNAP Marketing team with high-quality data to improve user acquisition (UA)
Enable SNAP Product Management, Analytics, Design, Engineering, and Production teams to gain insights from analytics quickly
Partner with data scientists, analysts, and software engineers to ensure high-quality and relevant data collection
Partner with the AI team to innovate, develop, and operate self-service analytics tooling

What You’ll Need:
Extensive expertise with data infrastructure and data engineering
Demonstrated experience in large-scale distributed data systems (Spark, Flink)
Deep expertise in analytical database technologies (SQL and NoSQL)
Proficiency in SQL and Python
Experience with database technologies and ETL/ELT
Experience with orchestration and automation tools (Airflow, Beam)
Experience with Looker or Tableau
Familiarity with Databricks and data/analytics solutions on AWS
Experience with marketing platforms and data tools (Braze, AppsFlyer)
Demonstrated success in a highly collaborative cross-functional work environment
Passionate player of mobile games
Mindset for serving a diverse and global player base

Nice to Have But Not Necessary:
Experience working in online video games, preferably mobile free-to-play games
Experience in .NET/C# and backend software development
Experience in building and integrating data pipelines for customer-facing live services (e.g., recommenders)
Experience in operational database and storage technologies (e.g., DynamoDB, Cassandra, and Redis)

The total compensation for this position includes a new hire offer base salary range of $80,000 - $160,000 USD + equity + comprehensive benefits + potential for discretionary performance bonuses.

Individual pay within this salary range may span multiple levels within the discipline and is determined by assessed job-related skills, experience, relevant education or training. It also factors in market demands and business needs. The disclosed range is not adjusted based on location and may be subject to change or modification based on business needs in the future. Your recruiter can answer any questions about new hire total compensation during the hiring process.

An overview of the benefits and perks at Second Dinner:
Medical, Dental, and Vision insurance plans with Second Dinner paying 100% of premiums for employees and 75% for dependents for many plans
401(k) contribution with no waiting period
16 weeks paid parental leave with no waiting period
Home office improvement bonus
Paid Vacation & Sick time
Company Winter Holiday shutdown (Dec 25-Jan 1)
Company Summer Holiday shutdown (week of July 4)
Company Events - In-person Summer all-hands gathering, in-person holiday party, annual camping event, and virtual events throughout the year

We are an equal opportunity employer that places high value on diversity and inclusion. We do not discriminate on the basis of race, color, ancestry, national origin, religion, age, disability status, sex (including pregnancy), gender, gender identity, gender expression, sexual orientation, medical condition, genetic information, marital status, military status, or veteran status.

You must be eligible to work in the United States to be considered for this position.","$120,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Inclusively
5.0",5.0,"Seattle, WA","Software Engineer, Data Platform","Inclusively is partnering with a one of the largest transportation networks to hire a Software Engineer, Data Platform.
ABOUT INCLUSIVELY:
Inclusively is a digital tech platform that connects candidates with disabilities, who may benefit from workplace accommodations, to inclusive employers. This includes all disabilities under the ADA, including mental health conditions (e.g. anxiety, depression, PTSD), chronic illnesses (e.g. diabetes, Long COVID), and neurodivergence (e.g. autism, ADHD). Applicants with one or more of these conditions are encouraged to apply; Inclusively does not require applicants to disclose their specific disability.
Responsibilities:
Design, develop, deploy, monitor, operate and maintain existing or new elements of our platform
Help establish roadmap and architecture based on technology and our needs
Write well-crafted, well-tested, readable, maintainable code
Analyze our internal systems and processes and locate areas for improvement/automation
Collaborate with product org stakeholders to address and prioritize custom edge cases
Help lead large projects from inception to positive execution
Unblock, support and communicate with internal partners to achieve results
Experience:
3+ years of software engineering industry experience and with data structures/algorithms
2+ years of experience building and developing large-scale infrastructure, distributed systems or networks, and/or experience with data infrastructure
Experience working with kubernetes and container technologies (e.g. Docker, cri-o, etc)
Familiar with a cloud-based environments such as AWS/GCP/Azure
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Team members get an exclusive opportunity to test new benefits of our Ridership Program
Job Type: Full-time
Pay: $103,785.00 - $165,600.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Parental leave
Vision insurance
Schedule:
Monday to Friday
Work Location: In person","$134,693 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"LufCo
4.9",4.9,"Annapolis Junction, MD",Software Engineer Level 2 - Cloud-based Big Data,"Software Engineer Level 2 - Cloud-based Big Data:

Passionate about Big Data? LufCo is hiring a Software Engineer to work on a team committed to analyze, design and code new software or modify existing software where necessary. The work is heavily focused on Cloud-based Big Data and is part of a great team.

Location: :Annapolis Junction, MD

The Software Engineer will be responsible for the following duties: :
Assist with maintenance, testing, tuning, and debugging of cloud-based analytics to various production environments
Re-designing, implementing, deploying, and maintaining multiple full-scoped distributed CNS systems
Backend and frontend development
Design and code new software or modify existing software to add new features
Integrate existing software into new or modified systems or operating environments
Provide recommendations for improving documentation and software development process standards
Requirements::
A TS/SCI with Polygraph level clearance is required
B.S. degree in Computer Science or related discipline
Four (4) additional years may be substituted for a bachelor’s degree
Fourteen (14) years experience as a SWE in programs and contracts of similar scope
Java development
Writing analytics
Developing RESTful API
Knowledge of Maven, GIT, JIRA, LINUX
Desired:
Experience with Lucene based open-source search tools like Solr or ElasticSearch
Experience in frontend web development and high level javascript frameworks (Angular, React, etc...)
Experience with Hadoop
Experience with Apache PIG

What We Offer::
Get Real Mentorship! :Excellent cadre of senior level mentors are available across the technical spectrum, such as software architecture, DevSecOps, and other specialized domains (DSP, RF, Android, Etc)
Competitive Pay
Flexibility and autonomous work with frequent collaboration
Continuing Education and Workforce Development
Positive work environment with professionals, no drama!
Professional growth and mentorship
Flexible Schedule

LufCo provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.",#N/A,1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,2004,Unknown / Non-Applicable
"The Travelers Companies, Inc.
4.1",4.1,"Hartford, CT",Data Engineer I (SQL/ETL/AWS),"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$102,600.00 - $169,200.00
Target Openings
1
What Is the Opportunity?
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.","$135,900 /yr (est.)",10000+ Employees,Company - Public,Insurance,Insurance Carriers,1853,$10+ billion (USD)
Grepr,#N/A,"San Francisco, CA",Data Platform Engineer,"Hi I’m Jad and I’m the Founder and CEO at Grepr, Inc. I’m very excited to start growing our team. The company is still only 2 people, and every person we add will make an enormous impact. So we’re looking for the kind of people who want to build not just a product but a whole company.

Being an engineer at a company smaller than 10 people is special. You’ll have a ton of autonomy, be expected to own and build a significant part of the product, and design the product’s growth for the next set of engineers who will be joining us. You’ll wear many hats: developer, designer, product owner, mentor, architect, support engineer, and sales engineer. Our engineers are strongly opinionated people who want to continuously improve the product they’re working on, the team they’re in, the company they’re working at, and the world around them.

Much of our product is still being discovered, but the need is very apparent through tens of conversations with heads of engineering, posts on Twitter and LinkedIn, and the fact that we have a good number of companies who want to sign up as design partners. There’s not much out there about us yet, but we are well funded by investors like Andreessen Horowitz and Boldstart Capital. I’ll share more once we meet.

A couple of formalities: we do require at least 4 years of experience as a full-time software engineer for this role, and the position requires at least three days of in-office presence per week (office currently in San Francisco).

The Role: Data Platform Engineer
We are building the core of our application on top of Apache Flink. The role would be to own the operations for Apache Flink and related streaming infrastructure, ensure its uptime and scalability, and help us build out all the infrastructure needed to deliver real-time experiences to our users at a reasonable cost. Experience with running Flink, Kafka, and Kubernetes or similar systems at a significant scale is important.
The ideal candidate believes in infrastructure-as-code (using tools like Terraform) and in automating operations to reduce risk and increase leverage. They have been hands-on managing large distributed data processing infrastructure. It would be great if they’ve been at an early stage startup before and understand the type of environment it is and are comfortable with its rapidly evolving nature.

Engineering Culture
We believe very strongly that engineering teams work best when everyone is an equally motivated strong contributor to the team, and when egos are dropped and communication and feedback are open and constant. Our motto is “team over self”. We always think, plan, and execute, and we always look back at our successes and failures and try to do better. Our goal is to work smarter, not harder.

Team Over Self
A significant part of every team member’s role is to help others on the team. We expect managers to be facilitators and team members to collaborate to execute a common vision. Each member of the team is expected to balance their time between upleveling others on the team, unblocking them when they’re blocked, and completing their own work. We’re a kind and welcoming team and we show that through the support we give our members.

Work Smarter, Not Harder

Many of us have families and kids. We want to balance our family lives with our work lives, but we still want to build something great. So we want to maximize our effectiveness at work and make sure that every moment we spend has an impact. We are relentless in our efforts to not waste time and increase focus. We plan our execution, we love prototyping over speculating, we automate whenever we can and the cost is justified, and we don’t follow rules dogmatically.

In-office Work
Having worked in both remote and in-person teams, I have found that in-person teams are vastly superior bootstrapping new projects where there’s a ton of iteration and real-time collaboration needed as execution evolves and changes. That’s why our team will be an in-person team with at least 3 days of in-office days per week.

Ownership and Accountability
Engineers on the team own our product end-to-end. They are ultimately responsible for the user experience which is at the heart of what we’re doing. So engineers talk to our customers, they help them through their issues, they listen to feedback, and they figure out what we should build next. The flip side of this is that engineers are also accountable for the success of what they build, and they take pride in building the right thing for the user and for the company. This means setting measurable goals and making progress towards those goals, and refining or completely changing course as they learn more about what they’re building.

Interview Process
Our interview process is meant to help us understand who you are, what you’re best at, and what your impact on the team would be. It’s also meant to help you picture yourself working with us and the team, and understand what life at Grepr would look like.
The interview process has three rounds:
30-minute intro call with the CEO to learn about you and tell you a bit about what we do and see if this is the right role for you.
A technical screen which is either an overnight take-home or 60-minute in-person interview.
Three in-person interviews with members of the team, totaling 3 hours and 30 minutes.

Technology Stack
We’re very early, so this is all still in flux! But at the moment, we’re building using Java on top of Flink for our data processing, Kafka for our queueing, Java for the backend, and React + Typescript for the frontend. Our infrastructure is currently in AWS, running on top of Kubernetes.

Benefits
Competitive salary and significant equity as one of the first few people on the team.
Flexible PTO: we really want you to take some time off!
90% paid healthcare coverage for employees and their dependents
Standard 401(k)
Ultimately, a company is the people that form it, and we want to build a place where people will do the best work of their lives. You’ll have a huge impact in helping us figure out all the right pieces to make it an amazing place to work. I hope that makes it as exciting for you as it does for me.

Grepr provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity, or gender expression. We are committed to a diverse and inclusive workforce and welcome people from all backgrounds, experiences, perspectives, and abilities.
Compensation Range: $160K - $200K","$180,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"GTA (Global Technology Associates)
4.6",4.6,"San Francisco, CA",Data Communications Engineer - III,"Looking for a Data Communications Engineer - III
What you will be doing as a Data Communications Engineer – III
This member of technical staff will be responsible for managing the standalone IT network and 4G/5G infrastructure and mobile edge cloud environments for a test and development lab program.
This is a technical position focused on supporting the development of technology solutions testing and incubation of new platforms and the product engineering of greenlit projects.
In this role the candidate will work with internal technology and product groups and external partners to support the development of new solutions.
He/She will be responsible for the architecture design and deployment of new 4G/5G and MEC platforms and features and will work very closely with Device testing Product engineering Business groups and peer TPD teams.
The candidate will be a member of a small team of Sr. Network engineers who manage remote lab access configure and manage virtual environments to support projects monitor and troubleshoot problems and make recommendations on how to streamline development with internal and external partners.
What you will bring to the table as a Data Communications Engineer - III
BA in IT/EE or Computer Engineering
The ideal candidate needs to have a strong technical background with experience in wireless and wireline networks hands on integration experience with MEC/Cloud/IT
Experience working in a customer facing environment Expert understanding of computer technologies and architectures including O/S Database NFV Cloud and SDN.
Passion for working with cutting edge technology Ability to work well in a team environment.
What you didn’t know about us:
Competitive salary
Health, Dental and Vision Benefits
Short/Long Term Disability and Critical Care/Illness Protection
Life Insurance and Retirement Plans
Employee Assistance Program
With this position, you will get the opportunity to work with our game changing clients and further advance your already valuable experience in the telecom industry!
We are Connectors. We thrive on ‘quality over quantity’ and put in the work building strong relationships. We create connections, discover qualities, uncover skills, and place people with accuracy. We are your true partner!
We are Collaborators. You’ll be working with a wholly-owned subsidiary of Kelly and part of the Kelly Telecom division. It allows us to be as nimble and fiercely competitive as a startup while having the backing of a multibillion dollar publicly traded company which has been in business for 75 years. With direct access to hiring managers, services don’t stop at standard recruiting processes. We use our expertise to improve your application skills and provide ongoing career support.
We give 24/7 Support. We are in this together. We provide around the clock availability, competitive employee benefits, and continuously check-in to make sure things are going smoothly. Check out our Glassdoor page!
Kelly Telecom is an equal opportunity employer and will consider all applications without regard to race, genetic information, sex, age, color, religion, national origin, veteran status, disability, or any other characteristic protected by law. For more information click Equal Employment Opportunity is the law.
You should know: Your safety matters! Vaccination against COVID-19 may be a requirement for this job in compliance with current client and governmental policies. A recruiter will confirm and share more details with you during the interview process.
#JobsAtKellyTelecom
Job Types: Full-time, Contract
Salary: $91,144.17 - $180,998.90 per year
Work Location: In person","$136,072 /yr (est.)",Unknown,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"PitchBook Data
4.1",4.1,"Seattle, WA",Data Engineer,"At PitchBook, we are always looking forward. We continue to innovate, evolve and invest in ourselves to bring out the best in everyone. We're deeply collaborative and thrive on the excitement, energy and fun that reverberates throughout the company.
Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there's going to be some ambiguity along the way, but we excel when we challenge ourselves. We're willing to take risks, fail fast and do it all over again in the pursuit of excellence.
If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you.

About the Role:
As a member of the Product and Engineering team at PitchBook, you will be part of a team of big thinkers, innovators and problem solvers who strive to deepen the positive impact we have on our customers and our company every day. We value curiosity and the drive to find better ways of doing things. We thrive on customer empathy, which remains our focus when creating excellent customer experiences through product innovation.
We know that greatness is achieved through collaboration and diverse points of view, so we work closely with partners around the globe. As a team, we assume positive intent in each other's words and actions, value constructive discussions and foster a respectful working environment built on integrity, growth and business value. We invest heavily in our people, who are eager to learn and constantly improve. Join our team and grow with us!
To that end, as our scope of data integration and analysis expands so do the needs of the Business Intelligence team. We're looking for a person with the ability to work with a range of data and reporting technologies (eg. Python, Docker, Tableau, Power BI) in order to build upon a strong foundation of rigor, quantitative techniques and efficient processing. The Data Engineer will join other Engineers and Analytics professionals as part of the team that develops data pipelines and insights for our internal stakeholders across Sales, Customer Success, Marketing, Research, Product, Finance and Administration.

Primary Job Responsibilities:
You'll be PitchBook's expert at building unified data tech to support advanced and automated business analytics
Design, develop, document and maintain database and reporting structures used to compile insights
Define, develop and review extract, transform and load processes and data modeling solutions
Consistently evolve data processes and techniques in accordance with industry best practices
Establish and help define reports and dashboards used to translate business data into insights, identify and prioritize operational improvement opportunities and measure business performance against objectives
Contribute to the ongoing improvement of quality assurance standards and procedures
Support the vision and values of the company through role modeling and encouraging desired behaviors
Participate in various company initiatives and projects as requested

Skills and Qualifications:
Bachelor's degree in Economics, Business, Finance, Engineering, Statistics, Computer Science or related fields
2+ years of relevant work experience creating and maintaining data pipelines and architecture
Understanding of advanced data warehousing concepts, data modeling and extract, transform and load development
Advanced SQL skills with experience querying large datasets from multiple sources and developing automated reporting
Python skills for scripting, data manipulation, custom extract, transform and loads and statistical/regression analysis particularly, as they apply to sales and marketing operations and performance
Experience with software programs, such as Tableau, Microsoft Power BI, Docker, Linux and Postgres
Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner
Capable of investigating, familiarizing and mastering new data sets quickly
Excellent interpersonal skills, with the ability to communicate complex data issues correctly and clearly to both internal and external customers
Experience with presenting actionable insights to business stakeholders
Experience with: Airflow, Luigi, Amazon Web Services, Microsoft Azure, Git, Postgres, Debezium and Kafka is preferred
Experience with Snowflake development and cloud data warehousing is preferred
Proficiency with the Microsoft Office suite including in-depth knowledge of Outlook, Word and Excel with the ability to pick up new systems and software easily

Benefits + Compensation at PitchBook:
Physical Health
Comprehensive health benefits
Additional medical wellness incentives
STD, LTD, AD&D and life insurance

Emotional Health
Paid sabbatical program after four years
Paid family and paternity leave
Annual educational stipend
Ability to apply for tuition reimbursement
CFA exam stipend
Robust training programs on industry and soft skills
Employee assistance program
Generous allotment of vacation days, sick days and volunteer days

Social Health
Matching gifts program
Employee resource groups
Subsidized emergency childcare
Dependent Care FSA
Company-wide events
Employee referral bonus program
Quarterly team building events

Financial Health
401k match
Shared ownership employee stock program
Monthly transportation stipend

Please be aware the above PitchBook benefit and perk offerings are subject to corresponding plan and policy documents and may change during the course of your employment.

Compensation
Annual base salary: $111,550-$188,600
Target annual bonus percentage: 10%

Starting pay will be based on several factors and commensurate with qualifications & experience. We also have a location-based compensation structure; there may be different ranges for candidates by location.

Working Conditions:
The job conditions for this position are in a standard office setting. Employees in this position use PC and phone on an on-going basis throughout the day. Limited corporate travel may be required to remote offices or other business meetings and events.

Life At PB:
We are consistently recognized as a Best Place to Work and our culture is at the heart of our success. It's our fundamental belief that people do and create great things and that people are the cornerstone of prosperity. We believe that proactively seeking out different points of view, listening to others, learning and reflecting on what we've heard creates a sense of belonging within PitchBook and strengthens the PitchBook community.

We are excited to get to know you and your background. Concerned that you might not meet every requirement? We encourage you to still apply as you might be the right candidate for the role or other roles at PitchBook.

#LI-JH1","$150,075 /yr (est.)",1001 to 5000 Employees,Company - Public,Management & Consulting,Research & Development,2007,$500 million to $1 billion (USD)
"Mindgruve
3.7",3.7,"San Diego, CA",Data Engineer,"We are a global digital agency comprised of strategists, creatives, media experts, data scientists, and engineers driven by one common purpose — accelerate business growth through marketing and digital transformation. Named a top 3% Google Premier Partner and recognized by Inc. 5000 and Adweek’s 75 Fastest Growing Companies, we’re constantly looking for “A” players to join our team.
The rapid growth is attributed to our strongest asset — our people. Our teams are highly collaborative and work closely with each client to set clear goals and objectives so that we can deliver exceptional results. Mindgruve is a place where every opinion is valued. Not only will you be empowered to contribute ideas, but you will also play a key role in the execution and driving success for brands across a variety of industries. Sound fun? Perfect — you’ll fit right in.
Mindgruve is seeking a self-motivated, results-driven Data Engineer. Our ideal candidate will have a strong foundation in data modeling, transformation, cleaning, and can confidently combine disparate data from multiple sources to ultimately produce meaningful reports.
What You'll Do Here:
Bachelor’s degree – preferably in information systems, computer science, mathematics, statistics, or other related discipline (with relevant work experience).
2+ years experience working with relational databases and/or data warehouses (i.e. Google Bigquery, AWS redshift, MSSQL).
2+ years experience with SQL or similar.
2+ years utilizing data replication tools and/or ETL tools (i.e. Supermetrics, Fivetran, SSIS, Airflow, Informatica).
1-3 years experience utilizing object oriented programming to transform data and perform data analysis (i.e. Python, R).
1-3 years experience with BI tools (i.e. Tableau, Google Data Studio, Looker).
1-3 years experience at a digital agency, and/or consulting firm, and/or corporate online marketing department, and/or software provider in an analytical capacity.
Exposure to Big Data and the challenges associated with harnessing data to drive insight
Excellent problem solving skills when it comes to troubleshooting data discrepancies to support team members in determining the most likely causes of errors or inconsistencies
Experience in web analytics using Google Analytics, Adobe Analytics, or similar
Knowledge of online ad serving platforms, such as Campaign Manager 360 or Sizmek, and online ad networks, such as Google, Bing, etc.
Ability to work both independently and in a team environment
Professional and personal integrity
A detail-oriented mindset, focused on driving results and analyzing data to gain insights and opportunities for growth
Excellent verbal and written communication skills
We Need a Person With:
Empower our clients and analysts with clean and timely data for reporting, predictive analytics, and data visualization.
Develop and maintain client data in ETL processes and the data warehouse.
Implement creative solutions to solve problems related to data integrity issues and data transformation using cutting edge technologies.
Increase your technical expertise in digital marketing, data management, and data analysis.
Provide general support to all analytics team members facing obstacles related to reporting and data management
Identification of opportunities for efficiencies in processes (i.e. automation).
Identification opportunities for better use of client data (i.e. novel analysis techniques, advanced analytics, predictive analytics).
Create and occasionally present dashboards in BI tools such as Tableau and Looker to effectively communicate performance to clients.
Create data-driven insights about visitor behavior from website data on traffic patterns, order volume, conversion, navigation behavior, product selections, etc.
Deliver online and digital reporting to executive management and internal teams as it relates to budget, campaign performance and testing results.
Follow and stay on top of industry best practices
Build and maintain an understanding of current topics in Performance Media, web analytics, data management, tools and technologies related to team’s core responsibilities
Compensation will be commensurate with experience. Additionally, for eligible full-time employees, we offer a competitive benefits package including medical, dental, and vision insurance; a flexible spending account; voluntary life and accident plans; and a 401(k) retirement plan with matching. We are also committed to providing employees with flexible workplace locations, with the option to work in-office, hybrid, or remotely. However, being a local applicant from the San Diego area is definitely a plus. (Bonus points if you’re bilingual in Spanish and/or Portuguese.)
Mindgruve is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$106,753 /yr (est.)",51 to 200 Employees,Company - Private,Media & Communication,Advertising & Public Relations,2001,$25 to $100 million (USD)
"RADcube, LLC
3.6",3.6,"Cincinnati, OH",Data Engineer,"Description:
The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data. The person in this role creates scalable and reusable solutions for gathering, collecting, storing, processing, and serving data on both small and very large (i.e. Big Data) scales. These solutions can include on-premise and cloud-based data platforms, and solutions in any of the following domains ETL, business intelligence, analytics, persistence (relational, NoSQL, data lakes), search, messaging, data warehousing, stream processing, and machine learning.

Responsible and accountable for risk by openly exchanging ideas and opinions, elevating concerns, and personally following policies and procedures as defined. Accountable for always doing the right thing for customers and colleagues, and ensures that actions and behaviors drive a positive customer experience. While operating within the Bank's risk appetite, achieves results by consistently identifying, assessing, managing, monitoring, and reporting risks of all types.

ESSENTIAL DUTIES AND RESPONSIBILITIES:
Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities.
Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the Bank.
Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc.
Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics.
Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes.
Evaluate software products and Provide documented recommendations as needed.
Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents.
Participate in the planning process for hardware and software.
Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation.
Provide technical guidance and mentoring for other team members.
Manage and prioritize multiple assignments.

MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED:
Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience.
Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group.
Fundamental understanding of distributed computing principles
Knowledge of application and data security concepts, best practices, and common vulnerabilities.
Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, Bi and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.
Requirements:
The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data. The person in this role creates scalable and reusable solutions for gathering, collecting, storing, processing, and serving data on both small and very large (i.e. Big Data) scales. These solutions can include on-premise and cloud-based data platforms, and solutions in any of the following domains ETL, business intelligence, analytics, persistence (relational, NoSQL, data lakes), search, messaging, data warehousing, stream processing, and machine learning.

Responsible and accountable for risk by openly exchanging ideas and opinions, elevating concerns, and personally following policies and procedures as defined. Accountable for always doing the right thing for customers and colleagues, and ensures that actions and behaviors drive a positive customer experience. While operating within the Bank's risk appetite, achieves results by consistently identifying, assessing, managing, monitoring, and reporting risks of all types.

ESSENTIAL DUTIES AND RESPONSIBILITIES:
Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities.
Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the Bank.
Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc.
Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics.
Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes.
Evaluate software products and Provide documented recommendations as needed.
Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents.
Participate in the planning process for hardware and software.
Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation.
Provide technical guidance and mentoring for other team members.
Manage and prioritize multiple assignments.

MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED:
Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience.
Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group.
Fundamental understanding of distributed computing principles
Knowledge of application and data security concepts, best practices, and common vulnerabilities.
Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, Bi and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.","$95,588 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research focused on Visa Risk , you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.

You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.

Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.

Essential Functions
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.

This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:

5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.


Preferred Qualifications:

6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$131,093 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
Tiger Lilies Consulting,#N/A,"Waltham, MA",Data Engineer,"Data Engineer - Waltham, MA - Hybrid opportunity
*Please note: applicants must be US Residents or Citizens - NO C2C
Employers DO NOT submit your employees resumes.
This is an exciting opportunity for a Data Engineer who is passionate about analyzing and smashing large datasets. Join our team and contribute to the development of robust data solutions that drive analytics and insights for our organization.
Our client is an American robotics and technology company.
Their award-winning technology, engineered for uninterrupted work between autonomous mobile robots, labor, and systems, makes business go.
With more than 5 million traditional forklifts moving over 5 billion pallets around the world, there is a ton of work to do to make that vision a reality. Their fundamental values reflect the diverse corporate culture that they need to make it happen, with people who are curious to explore what is possible, brave enough to try new things and be vulnerable, kind in how they engage with the world, and committed to the transformative potential of our work and our responsibility to each other.
THE ROLE | DATA ENGINEER |
If you’re into data, robots, and data on robots, this is your position!
The experienced Data Engineer will develop programs and procedures to solve design problems, scalability, and integration issues.
- The Data Engineer will transform the data they produce around productivity and performance to inform data-driven decision-making, predictive analytics, and learning.
- Working cross-functionally, the Data Engineer will manage, utilize, and transform data to understand the learning their robots provide and how to optimize their function based on customer needs.
-The ideal candidate is highly independent and can work in a fast-paced environment to design and develop the tools needed to interpret the feedback and learning received from our robots.
- Reporting to the VP of Autonomy,
DATA ENGINEER
- Ensure robust and resilient data pipeline from robot to cloud.
-Design and develop analytics tools to interpret large amounts of data for internal and external consumption.
-Work cross-functionally to create optimized programs to improve understanding and efficiency of our products.
-Act as a subject matter expert to own and architect the data pipeline (data pipeline management, data modeling, and testing).
-Understanding the connection between our data models and real-world applications to enable the creation of valuable data for the end user.
-Develop and maintain documentation.
SKILLS and QUALIFICATIONS
- Proficiency experience in Python required, Java, C++ a plus.
- Strong analytical skills with the ability to analyze complex datasets and derive meaningful insights
- Strong knowledge of SQL and experience working with relational databases (e.g., MySQL, PostgreSQL) data visualization, and statistics.
- Experience with AWS, ETL, and Linux environments required.
- MS in Computer Science, Data Science, or a related major with 4+ years of experience in designing and supporting data warehouse systems, maintenance processes, and projects required.
- Deep understanding and experience of methodologies like data warehousing, data visualization, and data integration.
Experience with any of the following is a plus:
Tableau
Robotic or IoT platforms
Machine Learning
ADDITIONAL INFORMATION
Excellent benefits!!
Hybrid role based in Waltham, MA | full-time, salaried role with benefits. Our client is an equal-opportunity employer. They encourage and celebrate diversity.
Job Type: Full-time
Pay: $150,000.00 - $180,000.00 per year
Benefits:
401(k)
Dental insurance
Employee discount
Flexible schedule
Health insurance
Life insurance
Paid time off
Professional development assistance
Vision insurance
Compensation package:
Yearly pay
Experience level:
5 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Waltham, MA 02452: Reliably commute or planning to relocate before starting work (Required)
Experience:
Python: 5 years (Required)
SQL: 5 years (Required)
Data warehouse: 5 years (Required)
AWS: 5 years (Required)
Data science: 5 years (Required)
Java: 5 years (Preferred)
Work Location: Hybrid remote in Waltham, MA 02452","$165,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
Caden,#N/A,"New York, NY",Data Engineer,"Data Engineer

Job Summary:
Caden is looking for a rockstar Data Engineer seeking to grow their careers with interesting and innovative problems to work on in the Data and AI space.

Caden’s mission is to create an equitable and fair data economy online by giving users ownership of their personal data, the ability to securely control it, and various ways to put it to work to create value with brands they trust, while always preserving their privacy. We strive to be the world’s most ethical, intelligent and valuable data company. We will achieve this by continually innovating in three areas: integrating users into the personal data economy, pushing the boundaries of Knowledge Graph technology, and enabling enterprise products via AI.

We’re led by industry veterans, backed by powerhouse investors, and crewed by the brightest minds in the game. We exist to make the internet a better place for all.

This position will report to the VP, Data and Technology as part of an agile and dynamic team to bring the CadenOS platform to life.
What You'll Do
Work within the Data Science and Analytics team to implement various data pipelines for our end-to-end solutions and especially our B2B data platform.
Provide active input into the design of our data product offerings portfolio and our data dissemination framework
Integrate the right tools and methods for data enhancement, data quality, data obfuscation, privacy measurement and enhancement
Implement data security and access controls throughout the data pipeline.
Develop actionable tools for monitoring the health of implemented pipelines and identify and fix issues in real-time.
What You’ve Done
Required:
2-3 years of industry experience developing ETL (Data processing pipeline) to integrate large volumes of data from various sources with a variety of database technologies.
Advanced SQL knowledge and experience in no-SQL, GraphQL, etc.
Experience in delivering production-ready code (Python, Java, etc.) to retrieve, cleanse, transform the data for analytical/modeling purpose
Experience using modern big data pipelines (AWS, GCP, Snowflake)
Experience with BigData frameworks (Hadoop, Hive, Spark, Kafka, Airflow, etc.)
Ability to think out-of-box and evaluate results based on customer value
Preferred
Experience with Triple stores / ontology databases (RDF, OWL, SPARQL, Jena, etc.) and knowledge graphs
Knowledge of AI/ML models, Natural language process (NLP) and data mining.

Salary: $110,000 - $140,000 base. Salary may vary based on experience.
If you are a passionate and experienced Data Engineer, we encourage you to apply.
Caden is an equal opportunity employer. We encourage applications from candidates of all backgrounds and experiences.

** This position is based out of our New York, NY office. There is currently no relocation and/or visa (immigration) assistance provided for this position.

3baVJavoCZ","$125,000 /yr (est.)",Unknown,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Finfare
2.5",2.5,"Irvine, CA",Data Engineer,"About Finfare
Finfare is dedicated to empowering SMBs, by providing the ultimate expense management solution for growing businesses seeking to streamline their financial operations and maximize cash back rewards. Finfare offers easy expense tracking, personalized spend controls, seamless accounting integration, powerful analytics, and reliable charge card services. Our cardholders can tap into our vast network of reward program publishers and card-linked merchant offers, ensuring even bigger cash back rewards for their business.
We are always working on redefining the boundaries of digital financial services and aim to stay one step ahead in the ever-evolving fintech landscape.
About the Role
As a Data Engineer at Finfare, you will play a pivotal role in developing data pipelines and administering relational databases. In this rapidly evolving field, you will be responsible for maintaining a robust data infrastructure and staying up-to-date with emerging techniques and technologies. We are seeking a proactive and adaptable individual who can deliver high-quality code, design data models, and ensure the security and reliability of our data systems.
Responsibilities
Define and deliver high-quality code and queries for feature development and bug fixes with minimal assistance.
Enhance and support the database/warehouse to ensure its robustness and reliability.
Design data models and implement data pipelines in accordance with established software development guidelines and data security standards.
Assist with database administration, scripting, and the development of data structures while managing tables and access controls.
Demonstrate a strong proficiency in SQL and database design principles.
Utilize extensive experience with MySQL databases and big data technologies.
Manage data warehousing and work with large data sets effectively.
Collect data and build data pipelines to ensure data availability and accuracy.
Other duties as assigned.
Qualifications and Requirements
Bachelor's degree in a related field
3-5 years of experience in data engineering or a related field.
Proficiency in Python and SQL for creating and maintaining database pipelines.
Familiarity with data platform technologies (preferred but not mandatory).
Strong database administration skills, including the ability to design and maintain databases and data models.
Experience with data partitioning and data extraction to manage and scale database size effectively.
Bonus Points
Previous experience in a fintech or data-intensive industry.
Knowledge of data security best practices and data governance.
A proactive mindset with a willingness to learn and adapt to emerging technologies and techniques.
Compensation
The salary range for this position is $100k- 140k (depending on experience).
Benefits at Finfare
Competitive Health, Vision, and Dental benefits (covering 100% premium for employee and all dependent(s))
Unlimited PTO
401K (Employer matching)
Parental Leave
Employee Stock Purchase Plan (if applicable)
On-site gym membership (Irvine, CA HQ)
Catered lunches and Weekly Café Stipend
Hybrid
Work Sponsorship (if applicable)
Other Employee Perks
As part of our dedication to the diversity of our workforce, Finfare is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee on the basis of race, color, religion, creed, national origin or ancestry, sex, gender, gender identity, gender expression, sexual orientation, age, physical or mental disability, medical condition, marital/domestic partner status, military and veteran status, genetic information or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances.
AZhHnHWb7D","$120,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Seven Hills Group Technologies inc.
3.0",3.0,"Reston, VA",Data Engineer,"Location:- Reston VA(Once in a Month Onsite)
Job Description :
Advanced knowledge of AWS Services/Architecture
Experience in AWS Compute such as EC2, Lambda, Beanstalk, Batch or ECS
Experience with AWS Storage services such as: S3, EFS, Glacier.
Experience in AWS Management and Governance suite of products such as CloudTrail, CloudWatch
Experience in AWS Analytics such as Athena, EMR, Glue, Redshift, Kinesis
Strong knowledge in Python object-oriented programming
Strong experience with AWS Database services such as: RDS, DynamoDB
Experience using APIs for developing or programming software
Experience using AWS Application Integration Services such as: Simple Notification Service (SNS), Simple Queue Service (SQS), Step Functions.
Experience with AWS Developer tools such as: CodeDeploy, CodePipeline
Experience with JSON
Strong experience with SQL
Experience with enterprise data lakes, data warehouses, data marts, and big data.
Strong experience with data migration, cloud migration, and ETL processes.
Experience determining causes of operating errors and taking corrective action
Thanks and Regards
Nick Awasth
Job Type: Contract
Experience level:
10 years
Schedule:
8 hour shift
Experience:
Python: 4 years (Preferred)
AWS: 5 years (Preferred)
Overall: 10 years (Preferred)
Work Location: In person","$85,336 /yr (est.)",Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Milwaukee Brewers
4.5",4.5,"Milwaukee, WI",Data Engineer,"Job Description:
The Data Engineer will work closely with the Data Engineering team to maintain, enhance, and extend Brewers Baseball Operations data pipelines to meet baseball needs.

Core duties for this role include, but are not limited to:
Design, build, and maintain robust and scalable data pipelines for collecting, processing, and storing data from diverse sources such as databases, Application Programming Interface(APIs), and streaming services.
Collaborate with cross-functional teams to integrate data from different systems and ensure data consistency and quality.
Collaborate with data scientists, analysts, and other stakeholders to understand their data requirements and provide the necessary support and data access.
The ideal candidate will have 3 years of experience in Information Systems or related fields as well as experience programming languages such as Python, Java, or Scala and writing and maintaining queries in SQL.

Our Team
Baseball Systems is the software backbone of Baseball Operations. We provide data and decision-making tools for analysts, coaches, and front office personnel to help win a World Series. Our department consists of a team of data engineers and a team of software engineers who work across all different aspects of Baseball Operations providing support and tools relevant to each group. We work directly with stakeholders in every department of Baseball Operations to ensure every project we work on drives value to the organization and helps us win more games on the field. We help drive technical innovation to find new ways to solve baseball problems

Our Pitch
You come here to make a difference. We are a purpose-led organization, focused on building an inclusive and engaging culture that fosters excellence, collaboration and ingenuity. We strive to be a model employer and cultivator of talent, empowering our teams to drive innovation through the inclusion of diverse thoughts, ideas and perspectives. We operate at the highest standard of excellence, investing in the development of our staff across all levels and embracing differences through a culture of respect and understanding.

We are proud to offer a highly competitive perks and benefits package including:
Exceptional health and dental rates, and fully covered vision package
401(K) match and an additional annual contribution from the Club
Unlimited vacation time
Paid parental leave
Collaborative recognition program and incentives
Leadership development programming
Online educational platform for personal and professional development
Employee Resource Groups
Paid time off for volunteering
Year-round diversity, equity and inclusion training and development
Brewers Home Game tickets, promotional giveaways and other discounts!
For more information about our Crew, other benefits and insight into our Club culture please visit our Careers Page.","$80,995 /yr (est.)",51 to 200 Employees,Company - Private,"Arts, Entertainment & Recreation",Sports & Recreation,1970,$1 to $5 million (USD)
"PSI Proteam Solutions Inc,",#N/A,"Columbus, OH",Data Engineer - Hybrid,"Data Engineer - Hybrid

Direct Hire Opportunity!
Location: Columbus, OH or Baltimore, MD or Philadelphia, PA.
***HYBRID WORK- REQUIRES SOME ONSITE - NOT REMOTE.***
***Must be authorized to work in the United States without Visa Sponsorship.***
***W-2 only or 1099, no Corp to Corp- Third Party Vendors, please do not apply.***

Required Skills:
Strong Experience in ETL (Extract, Transform, Load)
SQL and SQL Server Management
Azure
Databricks
Data Modeling
Snowflake
Experience in Legacy Data
Desired Skills:
Power BI
Tableau
Position Summary:

Responsible for architecting, documenting, and developing data architectures models and business reporting applications, providing technical leadership for database development efforts. Conducts complex data mapping and Extract, Transform and Load (ETL) efforts.
Essential Functions and Responsibilities:
Conduct complex data mapping efforts between systems in a clear and well defined manner.
Perform data analysis and develop the data models to support ETL development.
Complete complex data migrations (ETL) processes to support development efforts.
Collaborate with Software Architects, Software Developers, and BI Developers to design appropriate solutions for our internal team and external clients..
Mentor software developers in data architecture and database design best practices.
Perform and assign database development tasks of medium complexity across multiple projects.
Work directly with third party solutions to design, document, and develop data integrations.
Create, contribute to, review and collaborate on data and database designs and implementations.
Work with IT to deploy solutions.
Innovate and contribute to improving development standards, techniques, tools, and processes.
Train and test for industry certifications.
Identify, set, monitor, and achieve individual goals.
Leverage mentorship and peer relationships to increase proficiency in development.
Provide support to team members.
Participate in the development personnel interview process.
Collaborate with project managers, business systems analysts, UX designers, and application developers to deliver high-quality deliverables.
Support production systems as urgent and critical issues arise; including non-business hours support on a rotating basis.","$90,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
shaped.ai Inc.,#N/A,"New York, NY",Data Engineer,"Hello! We’re building the future of content discovery infrastructure with AI — come join us!

Shaped (YC W22) is an API for developers to seamlessly add personalized ranking and recommendation to their products. These frictionless discovery experiences help end-users find what they want faster, and, consequently, grow conversion and engagement business metrics. Behind the scenes, we’re building state-of-the-art ML infrastructure for training and deploying large AI models to power our personalization engine.
We’re a seed stage start-up backed by top-tier investors (e.g. Y-Combinator, Susa Ventures, Tribe Capital etc…) and executives (e.g. Google, Amazon, Uber, Dropbox etc…). Our team comes from Meta, Google, Apple and Uber. We’re a remote team but have a small office in Brooklyn, New York.
We’ve been lucky to have a huge amount of success since our initial launch earlier this year and now looking to expand our real-time data engineering capabilities. We are looking for a data engineer to design, build and optimize Shaped's real-time streaming data ingestion endpoints. You will be a founding engineer working on state-of-the-art infrastructure. As one of Shaped’s early employees you will help shape our product, culture and vision.
This role is for a full-time data engineer at $120k - $200k a year and 0.1 - 0.5% equity.

Responsibilities:
Manage the unification of our batch and real-time data processing pipelines.
Work on our real-time and batch data ingestion pipelines using modern data engineering pipelines/streams.
Work closely with a small team to inform the roadmap and co-develop a strong engineering culture with best practices.
Work on our real-time and batch data ingestion pipelines using modern data engineering pipelines/streams.
Work closely with a small team to inform the roadmap and co-develop a strong engineering culture with best practices.
Requirements:
Bachelor's in computer science, data science or mathematics related field. Master's degree or PhD will be advantageous.
5+ years of data engineering experience, ideally applied to machine learning use-cases.
Experience with AWS or common cloud technologies
Proficient with Python, SQL.
Extensive knowledge of both offline and online large scale data processing frameworks: Spark, Beam, Flink.
Extensive knowledge with stream technologies like Kakfa or Kinesis.
Excellent written and verbal communication skills.
We’re excited to work with you. Come build the future of AI and discovery with us!","$160,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Broad Institute
4.4",4.4,"Cambridge, MA",Data Engineer,"Job Description
Data Engineer
Our team at the Broad Institute is seeking a skilled Data Engineer to help us build and maintain the tools necessary for processing and managing large genomic datasets for display in public resources such as
gnomAD
,
genebass
, SCHEMA, and other resources for visualizing exome association results and genome-wide association study (GWAS) data. The ideal candidate will be familiar with a variety of database technologies (NoSQL and SQL) and be excited about creating data models and data processing graphs that automate regular data generation based on a variety of data inputs. They should also be interested in writing pipelines that process datasets at scale using the
Hail
python package. These pipelines should be executable in various environments and scales and integrate with our CI/CD systems.
As a Data Engineer, you will work with a team of software engineers, computational biologists, and researchers. You will also work closely with the frontend software engineering team to ensure applications are fast, reliable, and scalable. Ideally, you are excited to learn about genetics, genomics, biology, and human health.
Requirements:
Bachelor's or Master's degree in Computer Science or related field or equivalent experience.
At least two years of full time employment in a Data Engineering role
Experience with SQL and NoSQL databases.
Experience with Python.
Experience building scalable data architectures.
Experience with a pipeline tool such as Airflow, Luigi, Prefect, or Dagster.
Experience with cloud computing platforms such as AWS or Google Cloud.
Highly collaborative attitude and ability to work well in a team setting.
Excellent communication skills.
Demonstrated attention to detail and analytical skills.
An ideal candidate could have any of the following:
Experience with Docker, Kubernetes, and a major cloud provider (Compute, Object Storage, IAM, Functions-as-a-Service) is a plus.
Experience with bioinformatics datasets and analyses is a big plus.
What we offer:
The chance to work on a project of international significance with a clear impact on families affected by rare genetic disorders.
The opportunity to share your work: many of our projects are open source, allowing you to showcase your contributions with the community.
Flexible remote work setting.
Comprehensive benefits package: paid vacation and sick time, health/dental care, matching 401K, commuter benefits, child care.
We are an Equal Opportunity Employer and encourage applicants from all backgrounds to apply.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.
EEO is The Law - click here for more information
Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled
Check out this video for a look into our community!","$106,355 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2004,$100 to $500 million (USD)
"Alterra Mountain Company
3.7",3.7,"Denver, CO",Data Engineer,"Year Round

AUTHENTICITY | PASSION | COMMUNITY | INNOVATION | ADVENTURE

Alterra Mountain Company is a family of 17 iconic year-round resorts, the world's largest heli-skiing operation, and Ikon Pass - the premier ski and snowboard season pass offering access to more than 50 iconic mountain destinations around the world.

Headquartered in Denver, Colorado and born out of a shared love of the mountains and adventure, the company has brought together some of the world's most aspirational brands, including: Steamboat and Winter Park in Colorado; Palisades Tahoe, Mammoth Mountain, June Mountain, Big Bear Mountain Resort and Snow Valley in California; Stratton Mountain and Sugarbush Resort in Vermont; Snowshoe Mountain in West Virginia; Tremblant in Quebec and Blue Mountain in Ontario, Canada; Crystal Mountain in Washington; Schweitzer in Idaho; Deer Valley Resort and Solitude Mountain Resort in Utah; and CMH Heli-Skiing & Summer Adventures in British Columbia. Also included in the portfolio is Alpine Aerotech, a worldwide helicopter support and maintenance service center in British Columbia, Canada, Aspenware, the ski industry leader in technology services and e-commerce, and Ski Butlers, the global leader in ski and snowboard rental delivery.

A career with Alterra Mountain Company is more than what you do today; it's being part of creating a community rooted in the spirit of the mountains, united by a passion for adventure, and celebrating the legendary adventures and enduring memories that mountains bring to everyone.

BESIDES WORKING SOMEWHERE AWESOME, WHAT'S IN IT FOR YOU?
Free Ikon Pass for all eligible employees, with additional free skiing + riding privileges across the family of Alterra Mountain Company resorts for all eligible employees and their dependents
Discounted skiing + riding for friends and family of eligible employees across the family of Alterra Mountain Company Resorts
Flexible Time Off (FTO) and Paid Time Off (PTO) policies for eligible employees to rest, relax and recharge
Generous discounts on outdoor gear, apparel, rental cars, etc.
Medical, dental, vision, life, AD&D, short term & long-term disability insurance, EAP, HSAs, FSAs, and more
401(k) plan with generous company match
Discounted tuition with partner online university for all Alterra Mountain Company employees to further their education
Paid parental leave of up to 6 weeks for eligible employees
Commuter benefits (Denver employees only)
Flexible/hybrid workplace policy empowering employees to work from home while encouraging regular in-person collaboration in our dog-friendly company headquarters office located in Denver's RiNo Art District neighborhood

For information on Alterra Mountain Company's Social Responsibility work including our Diversity, Equity, & Inclusion actions, please see our webpage at www.alterramtnco.com/social-responsibility. Among other resources, Alterra has Employee Resource Groups to support the BIPOC (Black, Indigenous, and people of color), disability, LGBTQIA2S+, and women communities within our workforce.

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily with or without reasonable accommodations.

POSITION SUMMARY

Alterra is hungry to convert our troves of data into actionable information. We need data engineering pros, all-stars, and evangelists to satisfy that hunger. We're a target rich environment, with opportunities to transform the way we understand the performance of our operations across lines of business. As a Data Engineer, you'll be a member of the team responsible for transforming our industry by delivering best-in-class data architecture solutions and driving more accurate data-driven decision making. We are looking for an experienced, innovative Data Engineer with the ability to deliver data solutions that are customer focused, easy to consume and create business impact. You will be part of a group of talented engineers that build data products and services to help solve complex problems in a simple way.

WHAT YOU'LL BE DOING:
Develop and optimize large-scale batch and real-time data pipelines that ingest structured and unstructured data from a variety of sources (API, DB, Cloud Store, etc)
Manage incoming data requests and prioritize the highest value projects in an organized fashion
Use your advanced SQL skills to craft cutting edge data solutions
Tackle ambiguity and a growing level of complexity when it comes to our organization's data
Communicate data-backed findings to a diverse constituency of stakeholders
Other duties as assigned

PROJECTS YOU'LL BE WORKING ON:
Scaling our Azure based Snowflake data platform and Matillion environments
Building data infrastructure that brings together tech, product, and operational functions and informs strategic decision-making at the executive level
Building new data pipelines and integrations from the ground up

YOU SHOULD HAVE:
3+ years in a data engineer role
Strong Knowledge of Snowflake DW
Expert-level SQL skills
Strong experience with ELT design and best practices
Good experience in Python scripting
Analyze production workloads and develop strategies to run Snowflake database with scale and efficiency.
Experience in Snowflake performance tuning, capacity planning, handling cloud spend and utilization.
Strong in Agile with work estimation and providing input to managers on resource and risk planning
Familiarity with Data Visualization Tools (PowerBI, Looker, Tableau)
Knowledge of Cloud Data eco-system
Track record of success in building new data engineering processes and an ability to work through ambiguity
Demonstrated ability to work across disparate teams to achieve consensus on key business decisions
Exposure to Matillion or other cloud ELT tools
Willingness to roll up your sleeves and fix problems in a hands-on manner
Intellectual curiosity and research abilities
Expertise in Azure specifically in compute, storage & security services is a plus
Your own unique skills! If you do not meet 100% of the qualifications above, tell us why you would be a great fit for this role in your cover letter.

The base salary range below represents the low and high end of the Alterra Mtn Co Shared Services Inc. salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to experience, education, training, location, merit system, quantity or quality of production, responsibilities, and regular and/or necessary travel. The range listed is just one component of Alterra Mtn Co Shared Services Inc.'s total compensation package for employees. Other rewards may include short-term and long-term incentives and many region-specific benefits.

Denver area base salary range: $85,000 - $128,000 per year

PHYSICAL REQUIREMENTS

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to walk, talk, see, hear, and operate a computer and other office productivity machinery.

WORKING CONDITIONS

Indoor/Outdoor: While performing the duties of this job, the employee may be exposed to harsh and varying outside weather conditions.

Hazardous Materials/Noise: The noise level in the work place is usually moderate.

This job description is not an exhaustive list of all functions and responsibilities that an employee may be required to perform in this position. Alterra Mtn Co Shared Services Inc. and its affiliates reserve the right to modify, increase, decrease, suspend, and or eliminate any of the essential duties and/or the position in its entirety.

This job description is not an express or implied contract, guarantee, promise, or covenant of employment for any set term or duration, or for termination only for cause.

Employment with Alterra Mtn Co Shared Services Inc. or any of its affiliates is ""at will"" meaning either party may terminate the employment relationship at any time with or without cause and with or without notice.

This position is located in Colorado, and the work is primarily in Denver, CO and, as such, employment in this position is subject to the labor and employment laws of the state of Colorado.

Alterra Mtn Co Shared Services Inc. and its affiliates are equal opportunity employers and maintain drug-free workplaces. All employees and candidates are reminded that Alterra Mtn Co Shared Services Inc. and its affiliates adhere to all applicable labor and employment laws, and State, County, and City-specific labor and employment regulations, where applicable.","$106,500 /yr (est.)",10000+ Employees,Company - Private,"Arts, Entertainment & Recreation",Sports & Recreation,2018,Unknown / Non-Applicable
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Experient Group
4.8",4.8,"Atlanta, GA",Sr AWS Data Engineer,"Work With Us
At Experient Group, we value community, collaboration and people who are willing to roll up their sleeves to get the job done. While functional and technical skills are critical, we place a priority on hiring people who match our values. Our philosophy is simple: we attract and hire talented people, then provide them with a supportive community, career opportunities and guidance from our experienced leadership so they can thrive. In short, we strive to serve our people better than anyone else.
We are seeking an Sr. AWS Data Engineer to join our development team. This individual will be responsible for being a lead for the team, and hands-on building, enhancing, and supporting multiple high-volume data pipelines used by our client to process business critical order transaction data.

What you’ll do
Building ETL / ELT and data streaming pipelines using Apache Airflow, Spark, Flink or similar technologies
Programming big data processing pipelines using Python on AWS lambdas or other pipelining technologies
Follow modern agile development standards from requirements to delivery
Maintain and support multiple databases, Data / Delta Lake, and the processing pipelines.
Mentor and guide more junior engineers
What you will bring
7+ years of experience using one or more of the following:
Apache Airflow
AWS Glue/ PySpark
AWS S3 based Data Lakes
RDS
Redshift
AWS DMS
AWS Athena
Strong SQL Experience with Database Design and maintenance
Experience with programming languages such as Java or Python
Solid leadership experience
Strong analytical and problem-solving skills
Excellent verbal and written communication skills
Passion for learning and a passion for solving business problems with technology.
A strong record of academic accomplishment and a 4-year college degree with a major in Computer Science or related field
Strong team player, self-motivated, and willing to learn
Preferred
Experience using databases such as Postgres and MySQL
Experience using Graph databases
Experience using NoSQL databases such as AWS DynamoDB
Experience using AWS' SQS and SNS services
Basic level experience with Active Directory or other LDAP based directory
About Us
Experient Group is an Atlanta-based business + IT consultancy that offers flexible and innovative solutions tailored to our clients' business environment, culture and budget. We don't assume anything - we set out to continually prove ourselves by going above and beyond in every client engagement. We work collaboratively to understand our clients' business and provide guidance that enables them to achieve results.
Experient Group is an Equal Employment Opportunity (EEO) employer and welcomes all qualified applicants. Applicants will receive fair and impartial consideration without regard to race, sex, religion, national origin, age, sexual orientation, disability, veteran status, genetic data, or other legally protected status
bCNkpPq7S4","$99,395 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,2001,$5 to $25 million (USD)
"Nike
4.2",4.2,"Beaverton, OR",Data Engineer,"Become a Part of the NIKE, Inc. Team

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

NIKE is a technology company. From our flagship website and five-star mobile apps to developing products, managing big data and providing leading edge engineering and systems support, our teams at NIKE Global Technology exist to revolutionize the future at the confluence of tech and sport. We invest and develop advances in technology and employ the most creative people in the world, and then give them the support to constantly innovate, iterate and serve consumers more directly and personally. Our teams are innovative, diverse, multidisciplinary and collaborative, taking technology into the future and bringing the world with it.

Data Engineer -NIKE, Inc., Beaverton, OR. Develop, mentor, design and implement features in collaboration with team engineers, product owners, data analysts, and business partners using Agile and Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Build utilities, user defined functions, and frameworks to better enable data flow patterns. Research, evaluate and utilize new technologies, tools, frameworks centered around high-volume data processing. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Build, incorporate, and drive teams to write automated unit tests and integration scripts using the Python test unit framework. Ensure quality solutions are implemented and engineering standard methodologies are defined and adhered to. Implement security around sensitive data.

Employer will accept a Master's degree in Engineering Management, Computer Engineering, Computer Information Systems or Data Discipline 2 years of experience in the job offered or in an engineering-related position.

#LI-DNI

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.



At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.




Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$100,364 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"WOOD Consulting Services
3.4",3.4,"Dulles, VA",Data Engineer,"Overview:
Data Engineer
woodcons.com

Seeking a Data Engineer to support the design, development, and deployment of advanced cybersecurity capabilities.

Security Clearance Requirements:
This position requires all candidates to be U.S. Citizens and possess an Active Secret clearance with the ability to obtain a TS/SCI. Candidates must be able to receive DHS suitability prior to starting employment.
Responsibilities:
Collaborate with software developers and architects to conceptualize and implement database schemas in alignment with microservice architecture principles.
Leverage experience as a SQL database administrator and SQL database developer to craft robust solutions.
Utilize data analytics techniques to derive valuable insights from the data stored within our databases.
Harness the power of Erwin to streamline and optimize database design processes.
Work within an Agile development framework, adapting quickly to evolving requirements and delivering results efficiently.
Bring your expertise in one or more of the following database platforms: MS SQL Server, Oracle, Sybase, DB2, MySQL, to bear on assigned projects.
Develop and maintain high-performance RDBMS database solutions that stand as paragons of reliability and scalability.
Be the go-to expert for optimizing SQL queries and database performance, ensuring optimal response times and resource utilization.
Diagnose and resolve database-related issues with agility and precision.
Establish stringent data security measures and access controls to uphold data integrity and compliance with security policies.
Oversee and manage all aspects of database performance, including capacity planning and backups.
Collaborate closely with DevOps teams to automate database deployment and management processes.
Actively participate in code reviews, lending your considerable expertise to software developers on database-related matters.
Stay at the forefront of the industry, continuously updating your knowledge of the latest database technologies and best practices.
Apply your understanding of Service SOA (Service-Oriented Architecture) and object-oriented principles to align database solutions with broader architectural goals.
Qualifications:
Required Education & Years of Experience
BS Computer Science, Computer Engineering, Computer Information Systems, OR Computer Systems Engineering.
Two years of related work experience may be substituted for each year of degree level education.
10+ years of directly relevant experience as an SQL database developer/engineer.
Required Skills
Proficiency in data analytics techniques to extract actionable insights from the data.
Extensive experience with Erwin for efficient database design.
Agile development mindset, with a track record of success in Agile environments.
Expertise in one or more of the following database platforms: MS SQL Server, Oracle, Sybase, DB2, MySQL.
Exceptional skills in crafting and optimizing complex SQL queries for peak database performance.
Proven ability to diagnose and resolve intricate database-related issues swiftly.
Strong background in implementing data security and access controls.
Demonstrated capability in overseeing database performance, including capacity planning and backup strategies.
Familiarity with DevOps practices and tools for automating database deployment and management.
Outstanding problem-solving skills and a demonstrated ability to thrive in cross-functional team environments.
Excellent communication skills, both written and verbal.
Desired Skills
Experience with other database technologies (e.g., NoSQL databases).
Understanding of Service-Oriented Architecture (SOA) and object-oriented principles.
Proficiency as a full lifecycle developer/administrator for comprehensive database management.
Desired Certifications
DoD 8570.1 IAT Level I or II
WOOD is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.","$93,334 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,1997,$5 to $25 million (USD)
"Liberated Brands
3.7",3.7,"Costa Mesa, CA",SQL Data Engineer,"Title: SQL Data Engineer

From boutique-brand culture to big-box retail, Liberated Brands thinks differently and has global scale servicing over 60+ countries. With over three decades of experience in brand-building, we are enhancing what a full-service license model can look like. We focus on the fundamentals of designing, producing, distributing, and marketing our brands and products, but always leave room for the x-factors to lead the way. Our expertise spans all sales channels, from direct-to-consumer to specialty wholesale and everything in between, both physical and digital. This Liberated approach creates a unique and powerful balance between brand-culture and sustainable growth. Join us and experience the benefits of being truly Liberated.

WHAT YOU’LL DO:
The SQL Data Engineer will be responsible for designing, developing, and deploying data solutions in the data enablement, data integration and business intelligence space. Their role will assist our growing company in producing a viable and scalable data ecosystem.
Design and development of various business intelligence models and objects to support data enablement and analytics
RDBMS modeling to support the operation and development of the EDW and ODS
Design and development of error-processing, logging and notification frameworks and routines
Creation of ETL templates, logic and transformation
Development of reports and queries using enterprise report platforms (Power BI, SSRS)
Maintenance and implementation of data security methodologies and best practices
Database/SQL refactoring and optimizations in order to meet performance requirements and SLAs
Monitor and troubleshoot database instances, work on root-cause analysis (why did this happen anyway), identify opportunities for improvement and assist team with implementations
Work with the System Administration team to support infrastructure enhancements and maintenance
Support the adoption and implementation of industry standards and best practices
Documentation of systems, including data standards, procedures and definitions for team knowledge base

WHAT YOU’LL NEED:
Bachelor’s Degree in Information Technology, Information Security/Assurance, Computer Science, Data Engineering, or related field of study, or any combination of relevant equivalent experience, education and training
5+ years of experience in SQL SERVER, SQL/T-SQL development: stored procedures, database triggers, views, and other database manipulation languages/methods
3+ years of experience in Microsoft BI Tools (SSRS, SSIS, Power BI) projects development
The ability to adapt quickly to a fast-paced environment
Must have an analytical and logical thought process for developing project solutions
Proficient interpersonal and communication skills (written and oral communication); works well in a team environment
Ability to deliver under competing priorities and pressures
Experience designing, building, testing, implementing, and scaling data solutions in a growing organization
Strong organizational skills when coding, commenting and documenting benefiting team communication during development

LIBERATED PERKS:
Collaborative culture with amazing family vibe
Discounts on Liberated Merch
Medical, Dental, and Vision Benefits (majority employer paid)
401k, including employer contribution
Surf and Snow Team Building Days
Summer Half Day Fridays
Paid Time Off
Referral Program

Liberated Brands is committed to fair and equitable compensation practices. The salary range for this role in Costa Mesa, CA is $105,000 - $120,000. This position is hybrid and, as such, compensation will ultimately be in line with the location in which the position is filled. Final compensation for this role will be determined by several factors such as a candidate’s relevant work experience, skill set, certifications, and specific work location.

We are an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, veteran status, sexual orientation, gender identity or any other characteristic protected by law.
If you are unable to complete this application due to a disability, please contact Customer Service to ask for an accommodation or an alternative application process: 1 (855) 330-0188 or ADAaccommodations@liberatedbrands.com.","$98,017 /yr (est.)",501 to 1000 Employees,Subsidiary or Business Segment,Manufacturing,Consumer Product Manufacturing,1991,$100 to $500 million (USD)
"Millennium Corporation
4.3",4.3,United States,Data Engineer,"Overview:
Millennium is a strategic management, cybersecurity and systems engineering firm – driven by results and focused on people as we help our customers achieve mission success. With a proven track record of performance with the Army, Navy, OSD, DHS and other agencies, Millennium is a uniquely qualified and committed partner to the Federal Government. It is through our work that the U.S. military and government are able to identify, manage and defeat threats.
What We Believe:
We believe that diversity is a fact, inclusion is a choice. At Millennium Corporation, we are inclusive. We celebrate multiple approaches and different points of view. We strongly believe that diversity drives innovation, and we are building a culture where differences are valued. We are always growing our programs and we offer tools to help our employees grow and manage their careers.

Millennium is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. Millennium promotes affirmative action for women, minorities, disabled persons, LGBTQ+ and veterans.
Responsibilities:
Millennium Corporation is hiring a Data Engineer to work 100% remotely. Candidate must have an active Secret Clearance.
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Serve as lead on projects.
Qualifications:
Candidate must have an active Secret Clearance
Bachelor’s Degree in Business, Computer Science, Engineering, Finance, Accounting, Mathematics, Statistics, or Economics or a related field
6 years of relevant experience in data engineering, data management, and transformation OR a High School Diploma with at least 13 years of relevant experience.
Business Development:
Assist with Business Development activities as required to support Millennium's strategic business objectives, which may include but not limited to participation in technical interviews, creation of technical documentation, general proposal writing support and proposal color reviews.
Physical Requirements:
Must be comfortable with prolonged periods of sitting at a desk and working on a computer.
Must be able to lift up to 10-15 pounds at a time.
Travel Requirements:
Up to 10% travel required",#N/A,201 to 500 Employees,Company - Private,Management & Consulting,Business Consulting,2004,$25 to $100 million (USD)
"Meta
3.9",3.9,Remote,"Data Engineer, Product Analytics","As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.


Data Engineer, Product Analytics Responsibilities:
Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems
Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve
Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way
Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership
Design, build and launch new data models and visualizations in production, leveraging common development toolkits
Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries
Support existing processes running in production and implement optimized solutions with limited guidance
Define and manage SLA for data sets in allocated areas of ownership



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
2+ years of work experience in data engineering
Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)



Preferred Qualifications:
Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy
Experience working with terabyte to petabyte scale data



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$137,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Xylem
3.7",3.7,"Morrisville, NC",Data Engineer,"We’re Hiring for a Data Engineer!
If you are excited and passionate about helping #LetsSolveWater, consider joining our team today! Xylem, Inc. is a leading global water technology company servicing more than 150 countries and is dedicated to solving the world’s most challenging water issues. We are looking for individuals to join our mission by exceeding customer expectations through smart sustainable solutions. At Xylem, you will have the opportunity to solve water by participating in our paid Volunteer Program, Xylem Watermark!
THE ROLE: The Data Engineer is responsible for critical design, support, and management of key internal data platform applications. We offer a full benefits package to include Flexible Time Off (FTO) for salaried positions, health, dental, vision, investment savings plan, and additional miscellaneous benefits.
CORE RESPONSIBILITIES: To perform the job successfully, an individual must be able to perform each essential duty satisfactorily.
Build data pipelines to aggregate, clean, and distribute data sourced from numerous systems including but not limited to DB2, Progress OpenEdge, DynamicsAX, Oracle, Salesforce.com.
Design and implement data models for back-end databases and front-end BI applications
Manage deployment pipelines and data platform infrastructure (Devops)
Develop and implement custom business automation and analytics apps as needed
Coordinate the collection of requirements gathering across multiple business areas during the application design process
Partner with Business Units, Global/Regional Process Owners and IT on aspects of global and local data continually evolving business processes to streamline efficiencies.
Monitor and troubleshoot critical issues and outages related to team applications
Document and develop business automation processes to optimize process efficiency
Develop and deploy key business metrics dashboards and reporting

QUALIFICATIONS:
Bachelor’s degree in a technical field of study or Business Information Systems
3+ years relevant work experience in a technology and/or business environment
Experience in building or maintaining ETL processes
Knowledge of relational database management systems (PostgreSQL preferred)
Familiarity with Linux environments (Redhat preferred)
Programming experience
SQL (strongly preferred)
Python (strongly preferred)
JavaScript / Vue.js
Understanding of business processes and related software applications (MRP, ERP, CRM systems)
Strong communication and analytics skills

The estimated salary range at this professional level is $103,000 to $118,000 plus bonus. Starting pay is dependent on multiple factors, such as skills, experience and work location, and is not typically at the top of the range. At Xylem we offer a competitive compensation package with a generous benefit package, including Medical, Dental, Vision plans, Wellness programs, 401(k) with company contribution, paid time off, paid parental leave and tuition reimbursement.

At Xylem, we embrace diversity and strive to create avenues where employees feel valued and appreciated through our DE&I initiatives and Employee Resources Groups (ERG). Xylem is proud to be an Equal Employment Opportunity and Affirmative Action workplace. Xylem prohibits discrimination, harassment of any kind and does not discriminate in employment on the basis of race, color, religion, sex or sexual orientation (including pregnancy and gender identity), national origin, political affiliation, marital status, medical conditions or disability, genetic information, age, or other non-merit factors.

Join the global Xylem team today! Xylem is a team creating advanced technology solutions to the world’s water challenges through developing new technologies and services that will improve the way water is used, conserved, and re-used in the future is central to our work. Our products and services move, treat, analyze, monitor, and return water to the environment, in public utility, industrial, residential, and commercial building services settings. Xylem also provides a leading portfolio of smart metering, network technologies and advanced analytics solutions for water, electric and gas utilities.

Disclaimer: The information listed within this job description is designed to indicate the general nature of work expected for this position and shall not be viewed as a comprehensive inventory of all duties, responsibilities, and qualifications required in this position. Employees must be able to perform the essential functions of the position satisfactorily and if requested, reasonable accommodations will be made to enable employees with disabilities to perform the essential functions of their job absent undue hardship. Xylem reserves the right to modify this job description or assign other duties to this position as needed.","$110,500 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,2011,$1 to $5 billion (USD)
"CareQuest Institute for Oral Health Inc
3.0",3.0,United States,Data Engineer,"JOB SUMMARY:
The Data Engineer will lead activities in expanding and optimizing our data pipeline architecture as well as optimizing the data flow. Design and build out data models used for analytical reporting and data science needs. Support data analysts and data scientists on projects and will ensure data are consistently formatted and accurate for ongoing work. Manage the operational aspects of data platform solutions, including administering accessing controls, performance tuning, and automation of tasks. Develop and implement standard operating procedures associated with data engineering in line with organizational goals. Perform routine and ad hoc data extractions, create and deliver reports in a timely manner, and other analysis summaries as requested. Additional responsibilities include facilitating secure transfer of prepared datasets to external and internal partners and assisting in configuration and ongoing maintenance of Azure Cloud environment.

PRIMARY JOB RESPONSIBILITIES:
Setup and configure data warehouse of dental and medical claims, practice management systems, electronic health records data, and other structured and unstructured health data.
Implement Data Warehouse development methodologies.
Use the following tools and platforms: Azure Data Factory, Azure Storage Account, Azure DevOps, Azure Storage Explorer, Databricks, and Snowflake.
Ingest Data from various third-party data sources.
Develop and implement standard operating procedures to ensure compliance with licensing, legal, and ethical requirements.
Recommend the best practices for management, monitoring & optimization of data.
Ensure that data pipelines and data stores are high-performing, efficient, organized, and reliable, given a specific set of business requirements and constraints.
Process and analyze extracts of data from practice management system such as Dentrix, EagleSoft, Curve Dental, EPIC, Ace Dental.
Prepare routine and ad hoc data extractions, reports, and analysis summaries.
Facilitate secure storage and transfer of prepared datasets to external and internal partners.
Research and design Electronic Data Interchange processes.
Serve as technical resource for all department staff.
Lead technical implementation projects.
Develop and maintain database and dashboard applications for monitoring measures by CareQuest Institute staff.
Handle technical application development projects as assigned.
Perform new and existing set-up and maintenance processes.
Other duties as needed or required.

JOB QUALIFICATIONS:
Required:
Bachelor’s degree in computer science or a related information technology field.
1-3 years prior related technical and business experience required.
1-3 years of experience with SQL programming.
1-2 years of experience with cloud database technologies, such as Azure, AWS, Google Cloud, Databricks, or Snowflake.
Proficiency in the following technical applications/programs necessary.
Relational Databases (SQL Server preferred)
Knowledge of one or more data science languages/programs (Python or R preferred)
Preferred:
Experience with medical or dental claims data, electronic health records, and/or dental practice management software preferred.
Experience using data analytics and/or report development tools like PowerBI and Tableau.
Hands-on expertise with SQL, Python, Azure data services, and Snowflake experience building out a complex ETL/ELT pipeline.
Experience implementing security and compliance requirements and working with different data modeling techniques.
Experience designing and implementing data warehouse methodologies.

PHYSICAL DEMANDS:
Incumbent must be able to communicate effectively.
Manual dexterity and sitting is required in carrying out position own position responsibilities (i.e., use of personal computer).
Ability to travel or move about within and outside serviced facilities required.
Incumbent works primarily in either a private or shared office environment.

The specific statements shown in each section of this description are not intended to be all-inclusive. They represent typical elements and criteria necessary to successfully perform this position.
** In accordance with CareQuest Institute for Oral Health’s Compliance Plan, all employees must conduct CareQuest Institute for Oral Health business and activities in accordance with applicable laws, regulations, professional standards and ethical standards and report potential compliance or ethical issues to CareQuest Institute for Oral Health’s designated Compliance Officer. **
CareQuest Institute for Oral Health’s Affirmative Action Program affirms our commitment to make reasonable accommodation for known physical or mental limitation of otherwise-qualified individuals with disabilities or special disabled veterans, unless the accommodation would impose an undue hardship on the operation of our business and activities. Please see Human Resources for additional information regarding this program.",#N/A,51 to 200 Employees,Nonprofit Organization,Nonprofit & NGO,Grantmaking & Charitable Foundations,2021,Unknown / Non-Applicable
"Georgia-Pacific
3.6",3.6,"Atlanta, GA",Data Engineer,"Your Job
Georgia-Pacific is seeking a motivated and organized Data Engineer to join our team. The Data Engineer will be based out of our Collaboration and Support Center (CSC) in Atlanta, Georgia.
Our Team
The CSC team partners with our operating facilities by providing collaboration and support across multiple disciplines of expertise (GP and Vendors) to achieve scalable problem-solving across manufacturing sites and businesses. The team uses the best available technology with an enterprise-wide approach. This role will focus on designing innovative ways to communicate insights to the CSC and its partners.
What You Will Do
Collaborate with remote process engineers, process control engineers, and data scientists to develop compelling process-visualizations, advanced analytics, AI models, and data integrations
Interpret new work requests with an understanding of the customer's context - convey requirements, track action steps, facilitate technical discussions
communicate project status and updates to team members and partner teams
Facilitate discussions between vendors, internal development, and deployment partners
Educate others on technical standards, best practices, and critical system features
Contribute to the prioritization of demand from several customers across multiple teams
Develop and maintain technical, training, and end-user documentation
Who You Are (Basic Qualifications)

At least 2 years of experience in a manufacturing operations or support role
Proven ability to manage complex projects and prioritize tasks effectively
Excellent communication and interpersonal skills
Legal authorization to work permanently in the United States for any employer without requiring a visa transfer or sponsorship
Ability to travel up to 25%

What Will Put You Ahead
Experience in IT/OT networks and PLC/DCS communication
Experience with time-series data
Experience with Azure DevOps, Jira, ServiceNow Agile or similar tool
Experience with Amazon Web Services environment
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company and a leading manufacturer of bath tissue, paper towels, paper-based packaging, cellulose, specialty fibers, building products and much more, Georgia-Pacific works to meet evolving needs of customers worldwide with quality products. In addition to the products we make, we operate one of the largest recycling businesses. Our more than 30,000 employees in over 150 locations are empowered to innovate every day -to make everyday products even better.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf
#LI-SB3","$94,914 /yr (est.)",10000+ Employees,Subsidiary or Business Segment,Manufacturing,Consumer Product Manufacturing,1928,$1 to $5 billion (USD)
"JLL
3.9",3.9,"Chicago, IL",Data Engineer,"JLL supports the Whole You, personally and professionally.

Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you’ve got deep experience in commercial real estate, skilled trades, and technology, or you’re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally.

If you live and breathe digital, we want to offer you a super challenging and exciting role in LaSalle’s Digital Transformation Team. Imagine using digital technologies to disrupt the real estate investment industry.

Our job in LaSalle’s Digital Transformation Team is to be brave and accelerate the impact of digital transformation by partnering closely with our business units, we prototype ideas, test them in the real business scenarios, and quickly adapt the solution. Combining data science, human-centered design, and the latest rapid development techniques—such as agile, microservices and DevOps—we help deliver breakthrough products, experiences, and businesses.

For our Digital Transformation, we are building a LaSalle’s Digital Experience (LDX) Platform on Azure. The LDX platform will be powered by multiple COTS/Custom Build applications and unified data and content platforms. We are setting up Digital Engineering Hub in Bangalore to support the global implementation of LaSalle’s Digital Transformation Program, this position will be based in US preferable in central time zone..

Responsibilities
5+ years of proven experience in Power BI Data model, debug DAX queries and functions in Power BI.
Strong in Looker data modelling and LookML understanding
Suggest essential technical and strategic changes to improvise present business intelligence systems.
Collaborate with database owners and ETL/ELT to achieve the best BI solutions.
Collaborate with team to resolve issues, help is designing best enhanceable solutions.
Capable of implementing row-level security on data along with an understanding of application security layer models in Power BI.
Good understanding of Jira, work in Jira Agile environment with strong sense of responsibility and delivery.
Desire to learn and excel in career, willing to adopt and learn as per business needs.
Strong communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams and stakeholders.
Identify, analyze, and interpret the requirements from Business as an architectural process, and data modelling.
Good working knowledge of SQL queries, python, and JSON.
Consult with business users, clients, technical stakeholders to identify, assess, and solve complex business problems
Excellent problem-solving and analytical skills.

Nice to have:
Design and build solutions for data warehouse.
Experience with Azure.
Experience with Python.
Experience in Asset Management.
Working with greenfield projects.

Sounds like you? To apply you need to be:
Experience & Education
Bachelor’s or master’s degree in an Computer Science, Data Science, Engineering or a related field.
5+ years of technical experience in Power BI / DAX, Snowflake or SSMS.
Strong database knowledge and proven experience with data analysis.
Good understanding of Star and Snowflake schema and strong knowledge of SQL.
Good written and verbal skills, ability to communicate with technical and non-technical stakeholders.
Expertise in designing and building solutions for data warehouse working with large data sets.
Strong database knowledge and proven experience with data analysis and database design for operational, transactional systems.
Experience in building solutions using Python and experience in working with large data sets
Expertise in ETL and data warehouse concepts
Strong software engineering skills, preferably Python, Pyspark and SQL
Expertise in Azure, Databricks: hands-on experience in Python.
Experience in Agile methodologies
Good understanding of Star and Snowflake schema and good command on SQL queries and views.
If this job description resonates with you, we encourage you to apply even if you don’t meet all of the requirements below. We’re interested in getting to know you and what you bring to the table!

Personalized benefits that support personal well-being and growth:

JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health.

About JLL –

We’re JLL—a leading professional services and investment management firm specializing in real estate. We have operations in over 80 countries and a workforce of over 102,000 individuals around the world who help real estate owners, occupiers and investors achieve their business ambitions. As a global Fortune 500 company, we also have an inherent responsibility to drive sustainability and corporate social responsibility. That’s why we’re committed to our purpose to shape the future of real estate for a better world. We’re using the most advanced technology to create rewarding opportunities, amazing spaces and sustainable real estate solutions for our clients, our people, and our communities.

Our core values of teamwork, ethics and excellence are also fundamental to everything we do and we’re honored to be recognized with awards for our success by organizations both globally and locally.

Creating a diverse and inclusive culture where we all feel welcomed, valued and empowered to achieve our full potential is important to who we are today and where we’re headed in the future. And we know that unique backgrounds, experiences and perspectives help us think bigger, spark innovation and succeed together.","$106,266 /yr (est.)",10000+ Employees,Company - Public,Real Estate,Real Estate,#N/A,$5 to $10 billion (USD)
"Katalyst Healthcares & Life Sciences
3.6",3.6,"Morton, IL",Data Engineer 2,"Responsibilities:
The main function of a data engineer is to ensure that the data assets of an organization are supported by an architecture that supports the organization in achieving its strategic goal.
A typical data engineer is responsible for setting enterprise standards for databases, data integration, and the means to get to the data.
Test programs or databases, correct errors and make necessary modifications.
Modify existing databases and database management systems or direct programmers and analysts to make changes.
Write and code logical and physical database descriptions and specify identifiers of database to management system or direct others in coding descriptions.
Work is typically directed by a direct supervisor, project or team lead. Decisions on routine, medium risk issues that may affect the project team, suppliers or internal customers may be made by this position.
Challenges include meeting expectations in delivering results, learning to refine solutions to better fit complex situations, making timely decisions, and communicating effectively with all project stakeholders.
Requirements:
Familiarity with database such as Snowflake, DB2, SQL Server, Oracle (2-3 of these are required)
Programming languages - SQL(required), Python(required) and SAS(preferred)
Experience working with large data sets, preferably in several GB or millions of transactions.
Visualization - PowerBI(required), Tableau(preferred)
Experience working with platform integration tool like Snaplogic is preferred
Experience working with AWS (required)
Top 3 technical skills: Python, Snowflake, PowerBI
Communication, Team-work, Problem Solving, Customer Focus
Associate's degree in computer programming or a relevant field required. Bachelor's degree preferred.
2-4 years experience required.","$90,855 /yr (est.)",51 to 200 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,#N/A,Unknown / Non-Applicable
"Catholic Charities of the Archdiocese of Chicago
3.1",3.1,"Chicago, IL",Data Engineer,"Catholic Charities of Chicago is seeking a talented and passionate Data Engineer with specialized skills in Power BI and Data ETL (Extract, Transform, Load). As a Data Engineer at Catholic Charities, you will be at the forefront of leveraging data to support our mission of providing essential services to those in need. Your role will involve designing, implementing, and maintaining data solutions that enable data-driven decision-making and enhance our organization's impact.
Essential Functions of the position are detailed below, and include any physical requirements below that.

1. Data Extraction and Integration: Gather data from various internal and external sources, ensuring data quality and integrity. Develop processes for integrating and consolidating data from disparate systems.
2. Data Transformation: Clean, transform, and preprocess raw data into formats suitable for analysis. Implement data enrichment and normalization techniques as needed.
3. Data Modeling: Design and implement data models that support reporting, analytics, and business intelligence needs. Ensure that data structures align with organizational goals.
4. ETL Development: Create and maintain efficient ETL pipelines to automate the extraction, transformation, and loading of data into our data warehouse or data lakes.
5. Power BI Development: Develop visually compelling and interactive Power BI reports and dashboards that enable stakeholders to gain insights into our programs, services, and impact.
6. Data Governance: Implement and enforce data governance policies, ensuring compliance with relevant regulations and maintaining data security and privacy.
7. Performance Optimization: Continuously monitor and optimize data processes, ETL jobs, and Power BI reports for performance, scalability, and efficiency.
8. Collaboration: Collaborate with cross-functional teams, including program managers, analysts, and IT professionals, to understand data requirements and deliver solutions that address their needs.
9. Documentation: Maintain thorough documentation of data processes, data models, and Power BI reports to facilitate knowledge sharing and ensure data lineage.
10.Training and Support: Provide training and support to end-users, helping them make the most of data tools and resources.
Qualifications:
Expertise in Power BI and proficiency in other BI tools
Strong SQL skills for data manipulation and querying
Familiarity with data warehousing concepts and technologies (e.g., SQL Server, Snowflake)
Experience with data integration tools and technologies (SSIS, web Connectors, or Informatica)
Commitment to Catholic Charities' mission and values
Strong problem-solving skills and attention to detail
Excellent communication and collaboration skills
Ability to work in a mission-driven, nonprofit environment

PLEASE NOTE: Essential functions include all other duties and responsibilities as assigned.
Kneel and move from sitting, bending, kneeling or standing multiple times a day
X Push and pull objects up to 25 pounds
Climb up and down up to 4 flights of stairs at a time
X Lift up to 25 pounds

Other Requirements Comply with program and/or Agency requirements related to (check all that apply).
X Background check, including any program specific requirements
Physical examination
TB Testing
Drug Testing
Driver's License and reliable transportation
Agency-specified automobile insurance
Immediate Supervisor: VP, Data Strategy & Insights
Education and Experience Requirements:
Relevant Education:
Preferred: Master's degree in Computer Science, Information Technology, or a related field
Minimum: Bachelor's degree in Computer Science, Information Technology, or a related field
Relevant Experience:
Preferred: 5 years Proven experience in data engineering, ETL development, and data modeling. Expertise in Power BI and proficiency in other BI tools. Strong SQL skills for data manipulation and querying.Familiarity with data warehousing concepts and technologies (e.g., SQL Server, Snowflake). Experience with data integration tools and technologies (SSIS, web Connectors, or Informatica).
Minimum: 3-5 Proven experience in data engineering, ETL development, and data modeling. Expertise in Power BI and proficiency in other BI tools. Strong SQL skills for data manipulation and querying.Familiarity with data warehousing concepts and technologies (e.g., SQL Server, Snowflake). Experience with data integration tools and technologies (SSIS, web Connectors, or Informatica).
Certification/Licensure:
Preferred:
Minimum: N/A
At Catholic Charities of Chicago, we believe that data can drive positive change and help us better serve those in need. If you are a dedicated Data Engineer with a heart for making a difference and possess the Power BI and Data ETL skills to help us achieve our goals, we encourage you to apply. Join our team and contribute to the meaningful work of Catholic Charities as we continue to serve our community with compassion and excellence.","$89,603 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Nonprofit & NGO,Religious Institutions,#N/A,$100 to $500 million (USD)
"MetroStar
3.6",3.6,"Washington, DC",Data Engineer 4724,"Data Engineer
Remote
As Data Engineer, you'll take a leadership role in architecting, building, and optimizing our data pipelines, data warehouses, and data lakes. Your deep technical expertise and extensive experience will drive the development of scalable, efficient, and reliable data solutions that empower our analytics and business intelligence initiatives. You will collaborate closely with cross-functional teams including data scientists, analysts, and software engineers to ensure our data ecosystem meets both current and future requirements.
We know that you can't have great technology services without amazing people. At MetroStar, we are obsessed with our people and have led a two-decade legacy of building the best and brightest teams. Because we know our future relies on our deep understanding and relentless focus on our people, we live by our mission: A passion for our people. Value for our customers.
If you think you can see yourself delivering our mission and pursuing our goals with us, then check out the job description below!
What you'll do:
Lead the design and implementation of complex, end-to-end data pipelines to collect, process, and transform data from various sources into usable formats.
Develop and maintain ETL/ELT processes to ensure data integrity, accuracy, and availability for downstream applications.
Collaborate with data scientists and analysts to understand data requirements and assist in the creation of data models, dashboards, and visualizations.
Optimize data infrastructure for performance, scalability, and cost-effectiveness, making use of both traditional relational databases and modern big data technologies.
Ensure data security and compliance with relevant data protection regulations throughout the data lifecycle.
Identify and resolve data-related issues, troubleshoot performance bottlenecks, and provide timely support to maintain data operations.
Mentor and guide junior data engineers, providing technical leadership and fostering a culture of continuous learning.
What you'll need to succeed:
Bachelor's or Master's degree in Computer Science, Information Technology, or a related field.
Minimum of 8 years of professional experience in data engineering, with a proven track record of designing and implementing robust data solutions.
Expertise in building and maintaining data pipelines using tools such as Talend.
Experience implementing data integration within tools such as Pentaho.
Strong programming skills in languages such as Python, Java, Scala, or SQL for data processing and manipulation.
Proficiency in working with CI/CD (e.g. Jenkins) and containerization technologies (e.g., Docker, Kubernetes) to deploy data platforms such as Talend and Pentaho.
Experience with data warehousing solutions and data modeling concepts.
Familiarity with version control systems (e.g., Git) and collaborative development practices.
Excellent problem-solving skills and the ability to tackle complex technical challenges.
Strong communication skills to collaborate effectively with cross-functional teams and present technical concepts to non-technical stakeholders.
Like we said, we are big fans of our people. That's why we offer a generous benefits package, professional growth, and valuable time to recharge. Learn more about our company culture code and benefits. Plus, check out our accolades.
Don't meet every single requirement?
Studies have shown that women, people of color and the LGBTQ+ community are less likely to apply to jobs unless they meet every single qualification. At MetroStar we are dedicated to building a diverse, inclusive, and authentic culture, so, if you're excited about this role, but your previous experience doesn't align perfectly with every qualification in the job description, we encourage you to go ahead and apply. We pride ourselves on making great matches, and you may be the perfect match for this role or another one we have. Best of luck! – The MetroStar People & Culture Team
What we want you to know:
In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.
MetroStar Systems is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of MetroStar Systems.
Not ready to apply now?
Sign up to join our newsletter here.","$96,415 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,1999,$25 to $100 million (USD)
"Vestwell
3.8",3.8,"Austin, TX","Associate, Data Engineer","Who Are We?
There are over 30M small businesses in the United States, but only a tiny fraction of them have a workplace savings program in place. As the savings gap in the country widens, it's imperative that every worker has access to and participates in their company's savings program, such as a 401(k) or 403(b). We believe that American workers should have easy access to an inexpensive, flexible, and intuitive solution to save for a brighter future.
Unfortunately, prior to Vestwell, small businesses have been neglected and underserved, with expensive, inflexible, poorly designed offerings built on old, mainframe software. Vestwell is changing that, starting with rebuilding the core infrastructure for the modern era.
Vestwell's north star is to be the engine behind a $30T industry, powering all payroll-deducted workplace savings programs for small-to-midsize businesses, such as 401(k), 403(b), IRA, emergency savings accounts (ESA), health savings accounts (HSA), 529 college savings, and alike.
Vestwell's focus is to build the most flexible, powerful workplace savings and investment platform, delivered through the hands and minds of their financial services partners with the help of payroll provider partners. The team at Vestwell makes the hard stuff look easy, by combining the expertise of financial advice with the sophistication of a technology provider.
As a result, workplace providers are able to bestow the advice and solution employers and employees have been asking for, while growing and scaling along the way. Employers get a cost-effective solution designed for their needs without all the headaches, and employees get a user-friendly portal that helps them achieve their long-term saving goals.
Why Vestwell?
With backing from leading FinTech investors, as well as a growing team of dedicated professionals of strong industry pedigree, Vestwell is at the forefront of a much-needed change in a 40-year old industry. Our team believes in the mission we've set out to achieve and we are working hard to get there. We're ambitious, honest, thoughtful, and fun.
WHO ARE WE LOOKING FOR?
The Engineering team is seeking an Associate Data Engineer, eager to learn and grow in our data landscape. You should be enthusiastic about the world of data, willing to contribute to our Reporting stack, and excited to partner with more experienced engineers to deepen your knowledge and skills.
You're a great fit for our team if you're curious, committed, and eager to learn. While you might not have vast experience yet, your passion for data engineering and its potential impact stands out. That's what we value the most.
Day to day, you may additionally…
Assist in maintaining our data pipeline architecture
Help in assembling data sets that meet both functional and non-functional business requirements.
Support the creation of infrastructure required for data extraction, loading, and transformation from various data sources
Contribute to analytics tools that leverage the data warehouse to provide insights into business performance metrics
Collaborate with stakeholders including the Executive, Product, and Operations teams to assist in their data infrastructure needs
Receive training and guidance from senior engineers and participate in code reviews to further your development skills
REQUIREMENTS
The Necessities
Open to recent graduates or those with up to 2 years of experience in a Data Engineer or related role
Familiarity with SQL and experience working with relational databases
Experience with Python programming
Exposure to or eagerness to learn about data pipelines and their optimization
Interest in processes supporting data transformation, data structures, metadata, dependency, and workload management
Basic understanding or willingness to learn about Snowflake Cloud Computing and various AWS services such as EMR, Glue, S3, and EC2
Analytical mindset with a propensity for working with data sets, structured or unstructured
Curiosity about message queueing, stream processing, and scalable data stores
Excellent team player and interested in working collaboratively with cross-functional teams
The Extras
Experience with Snowflake database
Experience with ETL/ELT tools such as FiveTran, DBT, etc.
Experience with Business Intelligence tools such as Tableau, MetaBase, Looker, etc.
CS or related Data Analytics Degree
Our Benefits
We're a growth stage startup with lots of exciting milestones ahead. We value health and wellness at Vestwell and in addition to a dedicated Employee Wellbeing Committee, we offer competitive health coverage and an open vacation policy. We have adopted a remote-hybrid office policy, but all employees are welcome at our bright, comfortable office with many workspace options in midtown Manhattan so everyone has a setting that is the most productive for them. We provide our team with all the equipment they need (plus a few perks!) to work effectively remotely. Oh, and naturally we have a great 401(k) plan!","$79,470 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2016,Unknown / Non-Applicable
"The MITRE Corporation
3.0",3.0,"Bedford, MA",Data Analytics Engineer,"Why choose between doing meaningful work and having a fulfilling life? At MITRE, you can have both. That's because MITRE people are committed to tackling our nation's toughest challenges—and we're committed to the long-term well-being of our employees. MITRE is different from most technology companies. We are a not-for-profit corporation chartered to work for the public interest, with no commercial conflicts to influence what we do. The R&D centers we operate for the government create lasting impact in fields as diverse as cybersecurity, healthcare, aviation, defense, and enterprise transformation. We're making a difference every day—working for a safer, healthier, and more secure nation and world. Our workplace reflects our values. We offer competitive benefits, exceptional professional development opportunities, and a culture of innovation that embraces diversity, inclusion, flexibility, collaboration, and career growth. If this sounds like the choice you want to make, then choose MITRE—and make a difference with us.
The System Engineering Analytics Department is seeking a motivated, creative Data Scientist to apply cutting edge tools and techniques to challenging problems facing the US government. This position offers the opportunity to combine Systems Engineering with Data Analytics to build end to end data analytic pipelines. You will have the opportunity to learn from seasoned data professionals in a fast paced and dynamic atmosphere. You will have the opportunity to make strategic differences and have real long-term impacts on some of the most challenging problems in the government space.
Roles and Responsibilities:
Be passionate about applying data analytics to real world problems.
Work with a spectrum of government sponsors to gain understanding of their challenges, evaluate possible solutions and conduct insightful, actionable analyses.
Combine Systems Engineering with Data Analytics to build end to end data analytic pipelines.
Support the development and application of a variety of analytical models to sponsor challenges, with a willingness to adapt and learn.
Have an innate curiosity and interest in developing research questions and testing hypotheses with open ended tasking.
Present results in an intuitive, actionable manner that can be understood by all sponsor audiences, regardless of technical expertise.
Minimum Qualifications:
Bachelor's Degree in Computer Science, Computer Engineering, Mathematics, Statistics, Systems Engineering, Software Engineering, or related field and 2 + years applicable work experience or equivalent academic / internships; or equivalent combination of related education and work experience
Must have an active Secret clearance for consideration.
Demonstrated ability to manipulate large datasets
Experience with analytic tools such as Python, SAS, MATLAB, JavaScript, R, Java
Data Visualization tools such as Tableau, QuickSight, PowerBI, etc.
Ability to formulate complex algorithms and process to solve complex data problems
Proficiency in use of Microsoft Office including Outlook, Excel, and Word
Must have demonstrated proficiency and strength in verbal, written, PC, presentation, and communications skills
Preferred Qualifications:
Candidates that possession TS-SCI are preferred
Academic/ project experience working with databases (e.g., Oracle, PostgreSQL, MySQL, SQL Server, MongoDB)
Software Development experience in a shared environment leveraging tools such as GIT
Experience with full-stack development (e.g. HTML, JS, HTML, NodeJS, SQL, Python, etc.)
This requisition requires the candidate to have a minimum of the following clearance(s):
Secret
This requisition requires the hired candidate to have or obtain, within one year from the date of hire, the following clearance(s):
Top Secret
Work Location Type:
Hybrid
MITRE is proud to be an equal opportunity employer. MITRE recruits, employs, trains, compensates, and promotes regardless of age; ancestry; color; family medical or genetic information; gender identity and expression; marital, military, or veteran status; national and ethnic origin; physical or mental disability; political affiliation; pregnancy; race; religion; sex; sexual orientation; and any other protected characteristics. For further information please visit the Equal Employment Opportunity Commission website EEO is the Law Poster and Pay Transparency.
MITRE intends to maintain a website that is fully accessible to all individuals. If you are unable to search or apply for jobs and would like to request a reasonable accommodation for any part of MITRE’s employment process, please email recruitinghelp@mitre.org.
Copyright © 1997-2023, The MITRE Corporation. All rights reserved. MITRE is a registered trademark of The MITRE Corporation. Material on this site may be copied and distributed with permission only.
Benefits information may be found here",#N/A,5001 to 10000 Employees,Nonprofit Organization,Government & Public Administration,National Agencies,1958,$1 to $5 billion (USD)
"Kinertia
5.0",5.0,"Pittsburgh, PA",Sr. Data Engineer,"Do you like working with big data? Looking for a great company to work for with great clients, too? We are seeking a strong data professional with the experience and know-how to take charge of our largest client's needs while keeping things sane with strong organization of assets. We work with one of the top cloud providers in the world…if this interests you, read on.
As a Data Engineer with a focus on GoogleSQL, you will be responsible for designing, developing, and maintaining the data infrastructure for the company. This includes building and managing data warehouses, data lakes, and data pipelines using GoogleSQL. You will also be responsible for developing and implementing data security and governance policies.
Responsibilities:
Design, develop, and maintain optimal data pipeline architecture
Build and manage data warehouses, data lakes, and data pipelines using GoogleSQL
Assemble large, complex data sets that meet functional / non-functional business requirements
Develop and implement data security and governance policies
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and other ‘big data’ technologies.
Work with business stakeholders to understand their data needs and requirements.
Stay up-to-date on the latest data technologies and trends
Qualifications:
Must be authorized to work in the United States of America
Bachelor's degree in computer science, information technology, or a related field
5+ years of experience in data engineering, with a focus on GoogleSQL
Prefer 2-3 years of knowledge and experience in development and tuning of ETL processes
Experience with data warehousing, data lakes, and data pipelines using GoogleSQL
Experience with data security and governance using GoogleSQL
Experience with programming languages such as Python, Java, or Scala
Experience with big data technologies such as Hadoop, Spark, or Hive
Strong problem-solving and analytical skills
Excellent communication ( strong command of English) and teamwork skills
Results driven, ability to explain projects to both internal and external stakeholders
Benefits:
Competitive salary and great benefits (medical, dental, vision), matching 401(k), company-paid life insurance and long-term disability
Opportunity to work on cutting-edge data projects
Collaborative and supportive work environment
Chance to make a real impact on the business
Job Type: Full-time
Pay: $140,000.00 - $160,000.00 per year
Benefits:
401(k) matching
Dental insurance
Employee assistance program
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Compensation package:
Performance bonus
Yearly pay
Experience level:
5 years
Schedule:
Day shift
Monday to Friday
Ability to commute/relocate:
Pittsburgh, PA: Reliably commute or planning to relocate before starting work (Required)
Education:
Bachelor's (Required)
Experience:
Big data: 5 years (Required)
SQL: 2 years (Preferred)
Data warehouse: 2 years (Preferred)
Work Location: In person","$150,000 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Fanatics
3.5",3.5,"Portland, OR",Senior Data Engineer,"Company Overview
Fanatics is building a leading global digital sports platform. The company ignites the passions of global sports fans and maximizes the presence and reach for hundreds of sports partners globally by offering innovative products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting & Gaming, allowing sports fans to Buy, Collect and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans, a global partner network with over 900 sports properties, including major national and international professional sports leagues, teams, players associations, athletes, celebrities, colleges, and college conferences, and over 2,000 retail locations, including its Lids retail business stores.
As a market leader with more than 18,000 employees, and hundreds of partners, suppliers, and vendors worldwide, we take responsibility for driving toward more ethical and sustainable practices. We are committed to building an inclusive Fanatics community, reflecting and representing society at every level of the business, including our employees, vendors, partners and fans. Fanatics is also dedicated to making a positive impact in the communities where we all live, work, and play through strategic philanthropic initiatives.

COMPANY OVERVIEW
We are PWCC. We're based in Tigard, Oregon and are the largest trading card marketplace in the world. PWCC is brokering nearly a half-billion in trading card sales annually (and you thought those baseball cards in your mom's basement were worthless!), with the goal of expanding and becoming the name for collectibles storage, research, and liquidity. We are growing rapidly and need the right person to expand our team and help us provide the care our client base needs.

POSITION OVERVIEW
We are seeking a highly skilled and motivated Senior Data Engineer with expertise in implementing cross functional solutions and building a world class data practice. As a Senior Data Engineer, you will play a foundational role in designing, implementing, and maintaining our data infrastructure to support efficient and scalable data processing. You will work closely with cross-functional teams including software engineers, other members of the data team and business stakeholders to ensure our data systems are driving the business forward, have high availability, and are end-user friendly. This role is critical to the establishment, socialization, and implementation of our data infrastructure and business processes that will drive organizational, institutional, and marketplace success.

POSITION RESPONSIBILITIES:
Be a technical subject matter expert and provide technical leadership for data solutions across the enterprise.
o Support current technologies in place (Snowflake, DBT, Airbyte, Rudderstack, Python, Tableau, GCS, AWS) and champion better or more appropriate technologies as the need arises.
o Collaborate with the Head of Data and Analytics to set the roadmap for data infrastructure projects.
o Collaborate with the Head of Data and Analytics to set the roadmap for analytics and product projects.
Design, own and develop highly scalable and available services for data ingestion, data processing and business intelligence.
o Support and develop real time data pipelines to support operations and trust teams.
o Maintain and tune currently nightly data processes.
o Design and build machine learning pipelines and process that impact auction performance and increase customer loyalty.
o Collaborate with data colleagues across Fanatics Collectables to ensure awareness and appropriate coordination to achieve enterprise goals.
Lead collaboration with executive and director level stakeholders to understand data requirements and design data models that answer key business questions.
o Be a frequent data subject matter expert in business and analytics projects.
o High level of execution required to drive significant growth in the business. Only barrier to growth is higher levels of insight and business intelligence.
Design and own data quality control and validation.
o You should know before anyone else if there is a data quality or data processing issue.
o You will be responsible to use existing tools or selecting new tools and building out the data quality control and validation system.
o Escalate system issues as needed to impact/responsible business partners.
Analyze and improve existing data sources.
Continuously improve efficiency by tuning low performing data processes. Support the scalability of the data practice through automating and labeling workflows and maintaining up to date documentation of the data processes and models.
Additional duties as assigned.

QUALIFICATIONS:
5+ years of experience in data engineering, software engineering, or other related roles
B.S. or higher in Computer Science or equivalent training and experience
Experience in relational database concepts with a solid knowledge of SQL, SQL Tuning, Big Data technologies
Demonstrated success in generating and maintaining data pipelines from various data sources, in collaboration with diverse stakeholders
Demonstrable experience working with AWS, DMS, S3, DBT, Snowflake, other ETL Tools, Tableau etc.
Proven track record of experience with best practices for development including query optimization, version control, code reviews, and documentation
Demonstrated knowledge of data structures
Experience in designing foundations of operational excellence, particularly in a CoE environment
Curiosity and passion to learn with a strong bias to action
Highly effective problem-solving skills and the ability to analyze complex data-related issues.
Demonstrably effective interpersonal skills, both verbal and written

BENEFITS
We offer generous benefits including, but not limited to: 401(k), 401(k) matching, dental insurance, vision insurance, employee assistance program, flexible schedule, health insurance, life insurance, paid time off.

Our clients come from all walks of life and so do we. We hire great people from a wide variety of backgrounds because it makes our company stronger. If you share our passion, please do not hesitate to apply. We are also happy to look into any ADA accommodation requests that may be needed.

PWCC is an equal opportunity employer. Must be able to pass relevant criminal background check if offered the job, however, we believe in second chance employment and encourage everyone to apply.

TEAM BIO
We are responsible for conceiving, specifying, designing, programming, documenting, testing, & bug fixing involved in keeping the PWCC website and our auctions functioning and operational.
Ensure your Fanatics job offer is legitimate and don’t fall victim to fraud. Fanatics never seeks payment from job applicants. Feel free to ask your recruiter for a phone call or other type of communication for interview, and ensure your communication is coming from a Fanatics or Fanatics Brand email address. For added security, where possible, apply through our company website at www.fanaticsinc.com/careers

Tryouts are open at Fanatics! Our team is passionate, talented, unified, and charged with creating the fan experience of tomorrow. The ball is in your court now.

Fanatics is committed to responsible planning and purchasing (RPP) practices, working with its business partners across its global and multi-layered supply chain, to ensure that planning, sourcing, and purchasing decisions, along with other supporting processes, do not impede or conflict with the fulfillment of Fanatics’ fair labor practices.

NOTICE TO CALIFORNIA RESIDENTS/APPLICANTS: In connection with your application, we collect information that identifies, reasonably relates to or describes you (“Personal Information”). The categories of Personal Information that we collect include your name, government issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, criminal record, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or other types of positions, recordkeeping in relation to recruiting and hiring, conducting criminal background checks as permitted by law, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies. For additional information on how we collect and use personal information in connection with your job application, review our Candidate Privacy Policy-CA","$150,000 /yr (est.)",5001 to 10000 Employees,Company - Private,Information Technology,Internet & Web Services,1996,$1 to $5 billion (USD)
"Agama Solutions
3.9",3.9,United States,Data Engineer,"Notes :
Expert at Python and SQL experience is a must
Must haves in the cloud space ( preferred azure, snowflake)
Hive/spark, going away from this, so this is not really needed so if the candidate is more on the Hive/spark side then they are not going to be a fit.
Data modeling and architecture. (no architect people) hands on engineer. She does not want to see Architect level people.
Ross has 4 people, 3 others that come from Accenture.
8 + years in-depth, data engineering experience and execution of data pipelines, data ops, scripting and SQL queries

5+ years proven data modeling skills - must have demonstrable experience designing models for data warehousing and modern analytics use-cases (e.g., from operational data store to semantic models)

2-3 years’ experience in modern data architecture that support advanced analytics including Snowflake, Azure, etc. Experience with Snowflake and other Cloud Data Warehousing / Data Lake preferred

Expert in engineering data pipelines using various data technologies – ETL/ELT, big data technologies (Hive, Spark) on large-scale data sets demonstrated through years of experience

Hands on data warehouse design, development, and data modeling best practices for modern data architectures

Highly proficient in at least one of these programming languages: Java, Python

Experience with modern data modelling tools, data preparation tools

Experience with adding data lineage, technical glossary from data pipelines to data catalog tools

Highly proficient in Data analysis – analyzing SQL, Python scripts, ETL/ELT transformation scripts

Highly skilled in data orchestration with experience in tools like Ctrl-M, Apache Airflow. Hands on DevOps/Data Ops experience required

Knowledge/working experience in reporting tools such as MicroStrategy, Power BI would be a plus

Self-driven individual with the ability to work independently or as part of a project team

Experience working in an Agile Environment preferred, Familiarity with Retail domain preferred

Experience with Streamsets, dbt preferred

Strong communication skills are required with the ability to give and receive information, explain complex information in simple terms and maintain a strong customer service approach to all users

Ability to work independently, creatively problem solve complex technical problems and can provide guidance and training/mentoring to other team members

Ability to provide accurate estimates of timeframes necessary to complete potential projects and develop project implementation plans

Bachelor’s Degree in Computer Science, Information Systems, Engineering, Business Analytics, Business Management",#N/A,51 to 200 Employees,Contract,Information Technology,Computer Hardware Development,#N/A,$5 to $25 million (USD)
"Crimson Wine Group LTD
4.1",4.1,"Napa, CA",Data Engineer,"At Crimson Wine Group, we are the guardians of 1,000 acres of pristine vineyards, iconic estates, forests, and wildlife habitats along the West Coast. Our enviable portfolio of brands includes Pine Ridge Vineyards (Napa, Calif.), Seghesio Family Vineyards (Healdsburg, Calif.), Archery Summit (Dayton, Ore.), Chamisal Vineyards (San Luis Obispo, Calif.), Double Canyon (West Richland, Wash.), Seven Hills Winery (Walla Walla, Wash.) and Malene Wines (Santa Barbara County, Calif.).
We are committed to creating a workplace and culture that celebrates diversity, equity, and inclusion as part of what makes us a little different and a lot better. Our success is informed by the wide range of experiences and perspectives that our team brings to each of our wines – from vine to bottle and beyond. We encourage all applicants with a vision for creating a more equitable, inclusive, and diverse wine industry to apply to join our team. For more information, please visit www.crimsonwinegroup.com.
Position Summary
As a member of the IT team, the Data Engineer will take the lead role in designing, implementing, and maintaining data systems and data-related processes that support internal business teams, customers, and partners. Your realm includes data warehouses, databases, integrations, analytics/reporting tools, data wrangling/remediation, and associated processes. The right individual has experience in all stages of database project work (requirements gathering, logical and physical design, implementation, testing, and deployment) and expertise in the technologies needed to implement robust data warehouse and business intelligence solutions. We are seeking someone who is passionate about answering questions with data and has the ambition to help take our team and the company to the next level. Because CWG is in a regulated environment, a strong understanding of compliance and security controls is key.
Essential Duties & Responsibilities
The following reflects management’s definition of essential functions for this job but does not restrict the tasks that may be assigned. Management may assign or reassign duties and responsibilities to this job at any time due to reasonable accommodations or other reasons.
Collaborates with IT and business stakeholders to design and implement data warehouse, reporting/analytics, and integration solutions that align with the technology roadmap and data architecture.
Defines, documents, and socializes procedures and standards to ensure data handling meets objectives for data quality, business process enablement, and compliance. Designs and builds workflows, tools, integrations, and data structures to improve data accuracy, availability, and usability.
Identifies, designs, and implements internal process improvements such as automating manual processes and optimizing data delivery.
Leverages integration platforms and services to assemble complex data sets that meet end user and business requirements. Builds analytical tools to provide actionable insights from key business performance metrics.
Designs, implements, and maintains integrations with internal and 3rd party systems. Monitors and ensures timely data flows related to business facing solutions, CRM, ERP, and other SOX applications in CWG’s environment.
Establishes and maintains procedures, FAQs, SOPs, and other documentation required for internal/external audits and end user support.
Qualifications
Bachelor’s degree in business, finance, economics, technology, computer science, statistics, analytics, data science, or mathematics preferred; equivalent work experience will be considered.
3+ years of experience in a similar role
The ability to be well organized and to perform with minimal supervision in a remote work environment while maintaining high attention to detail is essential.
Demonstrated ability to successfully manage multiple projects and workflows.
Hands on experience with:
Microsoft Azure data, storage, and integration services, including Azure Data Lake, Azure SQL Database, SSIS, PowerBI
Modern data warehouse platforms (e.g., Azure, Snowflake)
Integration platforms (e.g., MuleSoft, WebMethods, Celigo, Informatica)
Programming languages (e.g., Python, R, SQL)
Web APIs (e.g., SOAP, REST, OData)
Service-oriented personality, positive attitude, a passion for data and delivering creative solutions.
Excellent interpersonal and communication skills and the ability to work well with all levels of personnel.
Experience working in a regulated (e.g., SOX) environment preferred.

All applicants will receive consideration for employment without regard to all federally and state protected classes. If you require assistance to participate in the application process, please contact us at HR@Crimsonwinegroup.com.
The projected (base) pay range for this position is $90k to $95k per year in addition to the annual bonus. This is the projected compensation for the position however the actual compensation offered may vary based on job-related factors such as (but not limited to) candidate qualifications, related experience and education, candidate work location and market data. Crimson Wine Group reserves the right to modify the pay range/rate at any time in the future.","$92,500 /yr (est.)",51 to 200 Employees,Company - Public,Manufacturing,Food & Beverage Manufacturing,#N/A,$25 to $100 million (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"CVS Health
3.1",3.1,"Irving, TX",Data Software Engineer,"Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.

Position Summary
CVS Health is seeking a highly skilled and experienced Software Engineer to join our dynamic team. The ideal candidate will have profound technical knowledge, aptitude for logical reasoning and problem-solving skills. As a software engineer on our team, you will be responsible for designing and developing high-quality software that meets business needs. You will build highly scalable microservices, event driven systems and real time streaming pipelines. You must be comfortable working in a fast-paced and dynamic environment with a deep understanding of software engineering principles.
Software engineering: Candidate should have basic knowledge Object oriented concepts. Knowledge about UI technologies like ReactJS, RESTful APIs (FASTAPI preferred), AKS, Microservices would be a plus
Programming: Candidate should have a basic knowledge of programming using Python (preferred) or Java and in the Linux environment. Knowledge in SQL and Data Engineering concepts will be helpful otherwise candidate will need to ramp-up on these skills.
Cloud: Should have basic understanding of working with Cloud platforms (Azure/GCP preferred). Should have basic understanding of integration methodologies (APIs/Connectors/Microservices etc.) as well as using CI/CD pipelines. Any hands-on experience will certainly be added advantage
Communication: Ability to effectively communicate and explain technical solutions to peers, leaders and partners. Also, ability to ask questions to get clarity on goals and technical requirements
Agile & Pro-active: Work and collaborate with a cross-functional POD in an agile/nimble fashion to drive assigned data-engineering tasks.
Problem-solving: Analyze business problems and come up with innovative solutions to help analytical partners enable data science and analytical solutions to solve the business problem.
Attitude: Candidate should be an enthusiast to learn new technologies and contribute quickly as project demands
Location: Dallas Area in Texas or Woonsocket RI or Boston Area in MA or NYC, NY or Hartford CT

Required Qualifications
1+ years of progressively complex related experience
Experience with bash shell scripts, UNIX utilities & UNIX Commands
Experience with ReactJS
Python f/w for Backend – preferably FAST API
Kubernetes/Docker (preferably AKS)
Strong Hands-on experience (this is not a project management role at onsite)
Experience on –
o Handling large volumes of data on web pages (preferably from any OLAP Data stores in the backend)
o Performance Optimization
o Deployment strategies (like hosting multiple applications under same platform)
o Data Integrity
o Caching Strategies
o Authentication and Authorization modules; Security aspects related to developing applications.

Preferred Qualifications
Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources
Ability to understand complex systems and solve challenging analytical problems
Strong problem-solving skills and critical thinking ability
Strong collaboration and communication skills within and across teams
Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar
Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment
Python f/w for Backend – preferably FAST API
Experience building data transformation and processing solutions
Strong knowledge of large-scale search applications and building high volume data pipelines
Education

Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline
Pay Range

The typical pay range for this role is:
$70,000.00 – $170,000.00

This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits

CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.

You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.

CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health colleagues can initiate a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through myHR (1-888-694-7287, or through myLeave at myHR). If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.

Apply","$120,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1963,$10+ billion (USD)
"Object Technology Solutions Inc
4.4",4.4,"Coppell, TX",Data Engineer,"Object Technology Solutions, Inc (OTSI) has an immediate opening for a Data Engineer
Duration –Contract
Primary Responsibilities:
Design, Develop and Deploy advanced machine learning and Artificial Intelligence algorithms/predictive models for use in Underwriting, Customer Management, Marketing, Portfolio Management and Operations.
Assess, clean, merge, and analyze large datasets adhering to standardized data manipulation techniques and methodology by leveraging R, SAS, Python and/or Apache Spark.
Perform parallel processing computations both within R as well as cluster computing technologies such as Apache Spark.
Design, Develop and Deploy multiple linear and nonlinear models for testing, development and deployment into our underwriting engine in the application of risk management in all of acquisition channels.
Efficiently apply data mining methodologies to minimize credit/fraud losses, maximize response and approval rates, and develop methods to enhance profitability of Elevate products.
Successfully implement scoring models on multiple decision platforms Including R instance deployment, On premise deployment and cloud deployment and multiple forms such as Java objects, R Object Models and Apache Spark Models.
Provide knowledge, insight and guidance of third party data providers such as Transunion, Clarity/Experian and Equifax to include knowledge of products and data available, products to purchase or discontinue, cost benefit analysis of retrospective analysis, effective use of variables, data dictionaries as well as advantages and limitations.
Maintain clear, detailed model documentation on our Wiki Server by leveraging reproducible research technologies such as Rmarkdown, IPython, Jupyter Notebook, etc.
Functional lead and point of contact with business partners to support the needs and goals of all portfolios.
Lead analytical projects by leveraging and coaching Jr Data Scientists.
Experience and Education:
Minimum Master’s degree in highly quantitative field (Statistics, Economics, Mathematics, Engineering, or other quantitatively-oriented degree) required.
At least three years of experience in Data Science or Modeling for consumer lending; Professional experience waived with at least two years of Data Science or Modeling experience and Ph.D. Degree in highly quantitative field (Statistics, Economics, Mathematics, or other quantitatively-oriented degree).
Experience with third-party consumer credit data and non-FCRA compliant consumer data.
Demonstrated proficiency with advanced statistical modeling and substantial experience with machine learning techniques (e.g., Random Forest, Gradient Boosting, LASSO, Elastic Net, etc). Knowledge of penalized regression and classification methods a plus.
Strong data skills, with ability to conduct substantial data munging/engineering.
Proficiency with SAS and R, Python, or Java; expertise with versioning software (e.g., Git), big data solutions and data processing frameworks (e.g., Spark, Hadoop).
Experience with at least four database technologies such as MSSQL Server, SAS Datasets, Hadoop, Apache Hive/Impala, Spark, Redshift, HBASE, Kafka, Spark Streaming, Neo4j, Teradata, Oracle, MySQL, DB2, Amazon AWS, Cassandra, PostgreSQL, NoSQL, JSON & XML parsing, etc.
Proven experience working in fast-paced environment with ever-changing demands.
Superior communication skills for communication with Risk Management peers and executive team.
Proficiency of contemporary supervised and unsupervised data mining techniques a plus.
Required Skills and Abilities:
Motivation Skills - History of achieving aggressive organizational goals and objectives, conveying sense of urgency while moving beyond challenges and obstacles.
Thinking and Administrative Skills - Solid analytical and problem solving skills. Ability to analyze trends and suggest solutions to challenges.
Achieve Successful Results – Takes the initiative to get things done.
Demonstrates Adaptability – Works effectively in the face of stress, ambiguity, difficult situations and shifting priorities.
Innovates – Challenges the status quo thinking to generate new ideas; takes open minded approach to situations.
Communication Skills - Refined written and verbal communication skills. Ability to foster open communications, listen effectively and build strong partnership networks.
Technological Competence – Extensive knowledge of R, Python, Scala, Java, SAS, MATLAB, SQL, and/or SPSS and risk management technology with the ability to leverage such tools to improve the organization’s decision making criteria.
About us
OTSI is a leading global technology company offering solutions, consulting, and managed services for businesses worldwide since 1999. OTSI serves clients from its 15 offices across 6 countries around the globe with a “Follow-the-Sun” model. Headquartered in Overland Park, Kansas, we have a strong presence in North America, Central America, and Asia-Pacific with a Global Delivery Center based in India. These strategic locations offer our customers the competitive advantages of onshore, nearshore, and offshore engagement and delivery options, with 24/7 support. OTSI works with 100+ enterprise customers, of which many are Fortune ranked, OTSI focuses on industry segments such as Banking, Financial Services & Insurance, Healthcare & Life Sciences, Energy & Utilities, Communications & Media Entertainment, Engineering & Telecom, Retail & Consumer Services, Hi-tech, Manufacturing, Engineering, transport logistics, Government, Defense & PSUs.
Our Center of Excellence:
Data & Analytics
Digital Transformation
QA & Automation
Enterprise Applications
Disruptive Technologies
Job Type: Contract
Benefits:
401(k)
Dental insurance
Health insurance
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: On the road","$86,975 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,1999,$25 to $100 million (USD)
"Orange County's Credit Union
4.0",4.0,"Santa Ana, CA",Data Engineer,"Great Opportunity At Orange County's Credit Union
Must reside in the state of CA, AZ, NV or TX.
Are you looking to join a dynamic, fast-paced team environment with a culture of collaboration and belonging? If so, let’s talk.
Orange County's Credit Union is now seeking a talented and driven individual to accelerate our efforts and be a major part of our team and culture.
Our team members are grounded in core values, have a strong capacity to learn, the energy to get things done, and bring real world experiences to help us think in new ways. Orange County's Credit Union actively invest in our team members to support their long-term growth so they can continue to advance our mission and achieve their highest potential.
Are you passionate about the future? Are you a data engineer who specializes in wrangling a wide range of data into versatile, accessible sources of knowledge? If yes, PLEASE APPLY IMMEDATELY!
More about Orange County's Credit Union:
Workplace Excellence. Through our associates' opinions and voices, Orange County's Credit Union is proud to be recognized year over year as one of the best places to work in Orange County and is a recipient of the Peter Barron Stark Best of the Best Award for highest associate satisfaction in the workplace.
As a leading financial service provider with over 80 years of experience serving 117,000+ members, Orange County's Credit Union is currently over $2 billion in assets & growing. Generous benefits include paid health insurance, time-off benefits, 401(k), and a professional, friendly work environment (with remote and hybrid options) focused on achieving goals, recognizing successes and excelling at member service.
Putting People First: Connect, Discover, Deliver & Wow is Orange County’s Credit Union mantra. If you’re passionate about serving people, this role is rewarding, brings purpose, and the opportunity to make a difference!
Overview:
Are you our next Data Engineer? With your strong understanding of financial services operations (e.g., banking, asset management, insurance, mortgage, consumer & business lending) you will be part of an innovative team that will architect, design and implement data analytics solutions to further advance the organization’s strategic goals. In collaboration with Business and IT partners, you will support our efforts in re-engineering, optimizing and advancing the organization’s data platform with modern cloud-based analytics technologies that will address near-term and future business needs. Be part of our vision to advance data-driven insights and decision making for our mission driven organization.
Essential Functions:
Collaborate with delivery team and engage with organizational stakeholders (Business and IT) to design, develop and deliver end-to-end enterprise data analytics solutions to enable data-driven insights and decision making.
Translate business requirements to technical solutions by applying technical knowledge and strong business acumen.
Solve business problems and complex data requirements/challenges by incorporating standards and best practices into engineering solutions, and leveraging modern data science programming languages (e.g., SQL, Python, R, Scala, SAS) and Azure data and analytics services.
Develop and implement database designs (logical and physical) and data models (normalized and dimensional) to support the new analytics platform.
Design, implement and maintain data ingestion/integration and end-to-end data pipeline processes using Azure technologies for a wide variety of traditional and non-traditional data sources/formats (structured, unstructured, and semi-structured) through various protocols (e.g., REST, SOAP, SFTP, MQ, etc).
Technical Must Haves for this Role:
5+ years of experience in Information Technology within a medium to large enterprise with complex business and IT environment.
3+ years of experience as a Data Engineer working with cross-functional teams (within IT and/or Business) on enterprise level business intelligence/data analytics implementations using Azure cloud-based analytics platforms/technologies (including hands-on experience with Microsoft/Azure stack, e.g., Synapse, Data Factory, Data Bricks, Data Lake, Data Catalog, SSIS, SQL, etc., and NoSQL databases).
3+ years of hands-on experience in designing, implementing and maintaining data ingestion /integration and end-to-end data pipeline using Azure technologies for a wide variety of traditional and non-traditional data sources/formats (structured, unstructured, and semi-structured) through various protocols (e.g., REST, SOAP, SFTP, MQ, etc.).
2+ years of experience working with and developing database designs (logical and physical) and data models (normalized and dimensional) for data warehouse, data marts and operational data stores.
2+ years of hands-on experience working with data science programming languages (e.g., SQL, Python, R, Scala, SAS).
Experience working in an agile delivery environment with working knowledge of continuous integration/continuous delivery (CI/CD) and DevOps practices.

The targeted hourly range is $36.55 - $54.83. Final offer will be determined based on experience, education, training/certifications and specialized skills.

We perform thorough background checks and credit checks. EOE.","$98,916 /yr (est.)",201 to 500 Employees,Nonprofit Organization,Financial Services,Banking & Lending,1938,$25 to $100 million (USD)
"Advanced Systems Design
4.2",4.2,"Montgomery, AL",Data Engineer - 2032,"Advanced Systems Design is seeking a Data Warehouse Analyst for our client located in Montgomery, AL.
Sorry, remote work will not be considered or negotiated for this position.
Job Overview:
Responsible for gathering and assessing business information needs to support the Agency's development of a DataOps environment.
Performs analyses, development, and evaluation of DataOps processes and practices in a data lake/warehouse environment, including data design, data systems, databases infrastructure/architecture, metadata, and repository creation.
Uses data governance and data analysis tools.
Reviews and validates data observability processes and analysis to support data quality, integrity, and accuracy.
Interacts with the user community to produce data pipelines to understand their data product/reporting requirements.
Provides technical assistance to users of the various data sources and advises users on optimal data sets and effective, efficient data usage.
Responsible for developing solutions, preparing test scripts, and conducting tests and for data extraction, transformation, loading, and cleansing
Provides technical assistance to users for data modeling formation and pipelines for optimal data delivery.
Maintains knowledge of software tools, languages, scripts, and shells that effectively support the data warehouse environment in different operating system environments.
Possesses working knowledge of Relational Database Management Systems (RDBMS) and data warehouse front-end tools.
Must have extensive knowledge of data pipelines, data fabrics, data mesh, data warehouse, and data mart concepts.
Required Qualifications:
3-5 years in a professional-level role with progressive experience as a member of a DataOPS team or unit.
Knowledge of programming languages in combination with business needs to design, monitor, and update data systems.
Excellent interpersonal communication skills for interaction with various LOBs to address technical problems or data needs.
An investigative mindset that enables them to troubleshoot issues with data systems and isolate defects in data process or software.
Working with data fabric and data mesh architectural design, development and support in multi-platform environments
Working on multiple projects as a team member and may lead projects of moderate complexity.
Assembling large, complex sets of data that meet non-functional and functional business requirements.
Creating and maintaining an optimal pipeline architecture,
3 years of Working Knowledge of RDBMS
Typical duties and responsibilities for a Data Engineer position may include:
Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery and automating manual processes.
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies
Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition
Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues
Working with stakeholders including the Executive, Product, Data and Design teams to support their data infrastructure needs while assisting with data-related technical issues.
May coach more junior technical staff.
3 years of Data Governance and Data Analysis Tolls
3 years of Data Observability and Data Quality
Preferred Qualifications:
3 years of Interacting with User Community
3 years of Data Warehouse Front-end Tools
1-2 years' experience in implementing practices outlined in Data Management Book of Knowledge (DMBOK).
Experience working in a Health Care delivery or Payer environment such as an Medicaid, Medicare, or Integrated Health System.
Education:
Bachelor’s Degree in Computer Science, Information Systems, or other related field. Or equivalent work experience.

Advanced Systems Design, Inc. is:
A leading Information Technology provider for Federal, State & Local government agencies.
A certified minority-owned small business government contractor with capabilities related to Public Health IT, Criminal Justice, Transportation, and Defense.
A certified service-disabled veteran-owned company with a proud 42-year track record of providing successful innovative solutions for our government customers.
A drug-free workplace in accordance with the Drug-Free Workplace Act of 1988.
Applicants who have a signed offer of employment or contractor agreement are subject to:
the pre-employment testing protocol:
background investigation
drug screening
Our Employees:
Are actively working on next-generation technology projects with the U.S. Department of Veterans Affairs, CDC, and a wide array of Federal, State, and Local agencies throughout the United States
Are eligible for wide-ranging benefits and perks, including but not limited to:
Comprehensive Health Insurance with PPO and HDHP/HSA options
Dental Insurance
Vision Insurance
Short/Long-Term Disability
Group Life Insurance - Company Paid
Voluntary Life Insurance
401(k) Plan with Employer Match
Paid Time Off (Vacation/Sick)
Holiday Pay - Company Paid Federal Holidays
Tuition Assistance
Professional Certification Incentive Plan
Employee Referral Plan
Technology Exposure
For additional information regarding Advanced Systems Design, please check out our WEBSITE or click HERE for all current job openings.
Advanced Systems Design is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
qwLK8uwfBh","$104,916 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,1979,$5 to $25 million (USD)
"Quility
4.2",4.2,"Swannanoa, NC",Data Engineer,"Quility is a leading technology-enabled provider of insurance protection and financial wellness solutions. Operating nationwide with thousands of agents in all 50 states and a corporate staff exceeding 150, we specialize in curating life insurance solutions that meet the evolving needs of American families. Ranked in the Inc. 5000 list for the past five years, we are one of America’s fastest-growing private companies.

Position Overview
Quility is actively seeking a seasoned Data Engineer to join our Data Products group. You will play a pivotal role in leading technology innovations, and significantly contribute to our Data Strategy by designing and building robust, scalable, and secure data solutions that drive actionable insights and operational excellence.
Responsibilities
Architect, build, and maintain data pipelines using Azure Data Lake Storage (ADLS), Azure Data Factory (ADF), and ETL/ELT processes.
Employ batch and streaming data processing methodologies, leveraging Kafka and Azure Function technologies.
Design and manage databases on Azure including but not limited to Azure SQL Database, Postgres, MongoDB, MySQL, and MariaDB.
Create end-to-end data pipelines in databricks and ADF, integrating data from source systems to target data repositories like Snowflake and Azure Databases (Postgres, MySQL, MariaDB, MongoDB).
Contribute to the evolution and optimization of our data model.
Collaborate with the data team to design and implement data models that serve business requirements, ensuring data integrity and availability.
Leverage Azure Functions and App Service for serverless data operations and tasks.
Utilize Azure API Management (APIM) to facilitate data interaction between various services and applications.
Utilize DevOps principles for deployment and automation using Azure DevOps or Bitbucket.
Create and maintain CI/CD pipelines using BitBucket or Azure DevOps for automated deployment and data transformations.
Ensure data quality, consistency, and security throughout the data pipelines.
Implement monitoring, logging, and alerting tools such as New Relic to ensure the robustness and performance of data operations.
Develop comprehensive documentation including data catalogs, dictionaries, and system configurations to ensure robust knowledge sharing and compliance.
Requirements
Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field.
Minimum of 5 years of experience working with Azure Cloud services.
In-depth experience with Azure Data Lake Storage (ADLS), Azure Data Factory (ADF), and ETL/ELT processes.
Extensive experience with Azure Cloud services including Azure Databricks, Azure Data Factory (ADF), Azure Synapse, Azure Data Lake Storage (ADLS), Azure Analysis Services, HDInsight, Power BI, SSIS, and Event Hub.
Solid understanding of data modeling techniques and proficiency in SQL and NoSQL databases like Azure SQL Database, Postgres, MongoDB, MySQL, and MariaDB.
Familiarity with real-time data processing and streaming technologies such as Kafka.
Strong experience with Azure Functions, Azure App Service, and Azure API Management (APIM).
Hands-on experience with CI/CD tools like BitBucket or Azure DevOps.
Proficiency in monitoring and alerting tools like New Relic.
Excellent communication skills, both written and verbal, and the ability to clearly document processes, systems, and data structures.
Highly analytical and detail-oriented, with a commitment to quality and data accuracy.","$102,508 /yr (est.)",51 to 200 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"UCLA
4.1",4.1,"Los Angeles, CA",Data Lake Engineer,"When you join UCLA Advancement Services, you become part of a team that performs vital administrative, financial, and technology services throughout all our External Affairs (EA) departments. Your work will facilitate and support the broad range of our customers' activities through a variety of value-added services including the development and enhancement of applications and other technical systems. As our Data Lake Engineer, your technical expertise, planning and implementation abilities will make you a key partner in major initiatives across EA encompassing a wide variety of business applications and system technologies. You will receive the tools to grow and excel in an innovative and supportive environment.

As the Data Lake Engineer, you will work collaboratively with the Senior Director, Cloud Platforms, ATS and Information Security in the design and implementation of a data lake that consolidates and catalogues data from multiple existing systems . As a project lead, you will evaluate solution options, design application architecture, and lead this and other complex medium- and large-size application development projects of broad scope and complexity in tandem with gaining a comprehensive understanding of business requirements and challenges. You will perform analysis of user requirements; train users; and assist in the use of the data for advanced analytics. In this role, you will develop a data catalogue, manage inbound and outbound data transformation, and modernize legacy data analytics processes using modern technology and methods. You will work closely with other Advancement Technology Solutions colleagues to provide valuable analytical insight to key departments and teams, using AWS services to consolidate, manage, and present data. As the Data Lake Engineer, you will also assist in the conversion of existing Tableau and QuickSight reports, and other workflows to present data to support External Affairs' marketing, organizational and internal website needs. You will deploy solutions on AWS and be responsible for the performance, security, and safety of data running on AWS. In addition, you will produce technical documentation and participate in team cross-training activities. We encourage you to join our Advancement Technology Solutions team in a role that offers long-term opportunities for personal and professional development as part of a robust External Affairs enterprise serving UCLA.

**Please note, this is a hybrid position.** **UCLA External Affairs is unable to offer visa sponsorship.**

Percentage of Time:
100

Shift Start:
8:00 am

Shift End:
5:00 pm

Qualifications for Position

17
Records

Qualifications

Required/Preferred

1. Minimum of 5 years of experience in application development and related projects involving moderate to highly complex software and systems.

Required

2. Ability to introduce new technology to the team's current technology portfolio that will help enhance operational efficiency by leveraging proven architectural frameworks, tooling platforms and software development methodologies.

Required

3. Detailed working knowledge of data management and analysis tools, including tools for data storage, transformation, presentation, and analysis.

Required

4. Expert knowledge of AWS data lake tools, including Lake Formation, S3, Athena, QuickSight, Glue, and Kenesis.

Required

5. Practical experience with DevOps principles as a way to modernize operational workflows and automate manual, repetitive tasks.

Required

6. Experience in creating data ETL jobs to ingest relational data and output into a Bronze/Silver/Gold environment.

Required

7. Experience creating a secure, access-controlled environment with varying levels of access based on the audience's particular job function.

Required

8. Experience working with cloud platforms such as AWS, Azure, etc., and familiar with the concept of creating cloud-native solutions; understanding of serverless architecture and the benefit of leveraging AWS services to build complex data environments.

Required

9. Expert knowledge of origin data sources. Working experience with relational and key-value data stores, and extraction of the data either in whole, incrementally over time, or streaming in real time.

Required

10. Skills in writing code according to coding conventions and ability to ensure that it is easily maintainable and transferrable with clear comments and documentation, working knowledge of development and source code management tools, test automation, continuous integration and deployment. Experience with DevOps pipeline preferred.

Required

11. Ability to utilize monitoring tools to proactively catch application performance issues, troubleshoot the root cause of problems and solve issues quickly, accurately, independently and with adequate follow-up.

Required

12. Ability to analyze complex technical and functional information, to identify relevant concerns, to recognize alternatives, to formulate logical and objective conclusions, and to communicate these with end-users and management; ability to write clear and detailed technical specifications and user documentation before and after a project/initiative.

Required

13. Excellent interpersonal skills to work effectively as a team member and diplomatically with a wide variety of internal and external constituents.

Required

14. Ability to evaluate technology tools in order to recommend solutions for current or planned projects; must be able to adapt to changing technology and business environment.

Required

15. Ability to independently perform functional analysis and systems research that is thorough, accurate, practical, identifies technical restraints, meets user requirements and maintains consistency with department planning strategies.

Required

16. Highly organized and detail oriented with excellent time and project management skills; able to independently plan, organize, prioritize and work on multiple projects simultaneously with a high level of accuracy under minimal direction.

Required

17. Working knowledge of relevant UCLA and functional office policies, processes, and procedures that affect application systems is preferred.

Preferred

Additional Posting Information

Bargaining Unit:
99-Policy Covered

Application Deadline:
10-06-2023

External Posting Date:",#N/A,1001 to 5000 Employees,College / University,Education,Colleges & Universities,1919,$500 million to $1 billion (USD)
"Northrop Grumman
4.0",4.0,California,Data Engineer,"Requisition ID: R10130919
Category: Research and Sciences
Location: Unknown City, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: None
Telecommute: Yes- May Consider Full Time Teleworking for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Positions Available: 3
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman's Chief Data Office, in support of the Aeronautics Systems sector, has an opening for a Data Engineer to join our team of qualified, diverse individuals.
This position can be performed as a virtual telecommuter with potential travel to a Northrop site upon business need. Position can be hired as either a Level 3 or Level 4, depending upon the candidate's experience and education.
The selected candidate will build, support, maintain and analyze the organization’s data storage and processing systems. Additionally, the individual will perform various code development and query needs for integration with new and existing applications, dashboards and machine learning pipelines.
Essential Functions:
Develop and troubleshoot SQL code, stored procedures, functions, tables, and views
Develop complex queries and routines to extract data form disparate sources
Experience in extracting and analyzing data from multiple data sources via APIs, Alteryx workflows, SQL Stored Procedures, or Python scripts.
Build and maintain streaming and batch data pipelines using various communication protocols and technologies, e.g. OPC, MQTT, Telegraf, Apache NiFi, Alteryx, Python, SSIS
Research, evaluate, and determine best fit of tools and techniques for data storage, data mining, data transformation, and data integration
Design, develop, test, and deploy scalable data solutions
Collaborate with external functional organizations for data and system understanding
Consult with customers and stakeholder to clearly define needs and objectives
Communicate project status and results to various levels of leadership
Basic Qualifications for Level 3:
Bachelor’s degree in Science, Technology, Engineering or Mathematics (STEM) discipline from an accredited university and 5 years of data analytics or data engineering experience; OR a Master's degree with 3 years’ experience
Work experience in MS SQL Server, SQL queries, scripting, and automation
Experience building and maintaining Extraction Transfer Load (ETL) and data migration pipelines
Working knowledge in programming languages such as Python, R, and Java
Basic Qualifications for Level 4:
Bachelor’s degree in Science, Technology, Engineering or Mathematics (STEM) discipline from an accredited university and 9 years of data analytics or data engineering experience; OR a Master's degree with 7 years’ experience
Work experience in MS SQL Server, SQL queries, scripting, and automation
Experience building and maintaining Extraction Transfer Load (ETL) and data migration pipelines
Working knowledge in programming languages such as Python, R, and Java
Preferred Qualifications:

Degree in Software Engineering, Computer Science or Data Science
Working knowledge in statistical modeling, data mining and machine learning
Experience with Azure Data Factory, AWS Glue and AWS Lambda
Experience building Tableau Dashboards
Experience with data virtualization technologies
Salary Range: $92,200 - $138,400
Salary Range 2: $117,900 - $176,900
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$115,300 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"Shamrock Foods Company
3.5",3.5,"Phoenix, AZ",Data Analytics Engineer,"Provide enterprise managed, certified datasets that are prepared and modeled to to empower end-users to create their own business intelligence & analytics.
This position requires someone to be on-site at least 2 days a week in Phoenix, Arizona.
Essential Duties:
Develop effective business intelligence strategies and analytics solutions to solve complex business problems and facilitate data-driven decision making
Apply software engineering and DataOps best practices to establish reusable data assets and analytical data capabilities, i.e., version control, unit testing, continuous integration and delivery
Transforms data to support analytical use-cases
Establishes universal data governance policies, rules, standards and metrics while maintaining documentation, linage and definitions
Train and enable business users and data workers with enterprise data visualization and BI reporting tools
Other duties as assigned.
Qualifications:
Bachelors or masters in disciples such as Statistics, Mathematics, Computer Science, Software Engineering or Analytics
4+ years’ experience delivering Business Intelligence and analytics at enterprise scale
4+ years’ experience with modern BI and Data tools like Power BI, Tableau, Looker, etc.
2+ years’ experience with cloud data platforms like Databricks, Snowflake, AWS, GCP or Azure
Dynamics 365 Dynamics 2012 experience
Advanced level SQL for data transformations, queries & data modeling
Expertise with Git or other commonly used version control systems
Strong background with advanced data languages like Python, R or SAS
Must be flexible and willing to work the demands of the department which may be subject to evenings, weekends, and holidays.
Corporate Summary:
At Shamrock Foods Company, people come first – our associates, our customers, and the families we serve across the nation. A privately held, family-owned and -operated Forbes 500 company, Shamrock is an innovator in the food industry and has been since being founded in Arizona in 1922.
Our Mission: At Shamrock Foods Company, we live by our founding family’s motto to “treat associates like family and customers like friends.”
Why work for us?
Benefits are a major part of your overall compensation, and we believe offering them at an affordable cost is not only the right thing to do, but it helps keep you and your family healthy. That’s why Shamrock Foods pays for the majority of your health insurance, allowing you to take home more of your paycheck. And it doesn’t stop there - our associates also enjoy additional benefits such as 401(k) Savings Plan, Profit Sharing, Paid Time Off, as well as our incredible growth opportunities, continued education, wellness programs.
Equal Opportunity Employer
At Shamrock Foods Co all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, veteran status, sexual orientation, gender identity or any other basis protected by applicable law.
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$93,427 /yr (est.)",5001 to 10000 Employees,Company - Private,Manufacturing,Food & Beverage Manufacturing,1922,$1 to $5 billion (USD)
Neo Tech Solutions,#N/A,"Morton, IL",Data Engineer,"Job Title: Data Engineer
Location: Peoria, IL/Morton, IL (Onsite)
Client: Caterpillar
Duration: Full time
Job id: 16479-1
Job Description:
Technical Skills
· Familiarity with database such as Snowflake, DB2, SQL Server, Oracle (2-3 of these are required)
· Need strong python programming skills
· Programming languages - SQL(required), Python(required) and SAS(preferred)
· Experience working with large data sets, preferably in several GB or millions of transactions. Visualization - PowerBI (required), Tableau(preferred)
· Experience working with platform integration tool like Snaplogic is preferred
· Experience working with AWS (required) Soft Skills Communication Team-work Problem Solving Customer Focus
Education
· Minimum BS in information technology, computer science, mechanical engineering, applied math, statistics, data science etc. 5-7 years of relevant experience is required.
· MS is preferred. 3-5 years of relevant experience is required.
Thanks & Regards,
Dileep | Talent Acquisition Specialist
D: 908-279-0221 | dileep@neotechusa.com
One Cragwood Rd | South Plainfield, NJ 07080
eFax: 888-828-9871 | www.neotechusa.com
Job Type: Full-time
Salary: $90,000.00 - $95,000.00 per year
Experience level:
7 years
Schedule:
8 hour shift
Work Location: In person","$92,500 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Apple
4.2",4.2,"San Diego, CA",Software Engineer - Big Data Technologies,"Summary
Posted: Aug 22, 2023
Weekly Hours: 40
Role Number:200496616
Meaningful insights require a solid infrastructure that is able to scale with the large amount of data coming in. Our team is responsible for discovering such great insights from a sea of data, and our infrastructure needs innovative ideas to improve its performance and ease-of-use. Would you like to help understand the challenges of building and maintaining a large-scale analytics infrastructure? Are you excited about identifying areas for improvement and creating out-of-the-box solutions? If this describes you, we would love to hear from you!
Key Qualifications
At least 2 years of programming experience in C, C++, Python or Java
Experience designing and developing production-level software
Strong analytical thinking
Self-motivated and able to work independently
Excellent spoken and written communication skills
Description
We're looking for a motivated engineer with excellent programming, problem solving and communication skills. In this role, you will be responsible for effective provisioning, installation/configuration, operation, and maintenance of our team’s analytics infrastructure. You will enable continued innovation and progress within the infrastructure through research and development. You will help and support the execution, test and roll-out of solutions. To be successful in this role, you must have a solid software engineering background and be able to write production level code. As a member of this team, you will have the opportunity to solve challenging engineering problems across a broad range of Apple products.
Education & Experience
B.S., M.S. or Ph.D. in Computer Science, Electrical Engineering or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $131,500 and $243,300, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Mastercard
4.3",4.3,"Atlanta, GA",Lead Data Engineer,"Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Lead Data Engineer
Job Description Summary

Overview

The Technology Risk Management team is looking for a Data Engineer to inform the build-out of information systems to collect, manage, and convert raw data into actionable intelligence for risk analysts and technology stakeholders. The ideal candidate is knowledgeable and experienced in the design of relational databases to provide a coherent, extensible informational infrastructure supporting a range of interrelated workflows and analysis/reporting requirements.

Role. In this position, you will:
Provide high-level recommendations on the design and implementation of data models in the technology risk management space, spanning policy governance, issue management, control testing, stakeholder assurance, compliance, and related functions.
Design information architectures that facilitate efficient workflows for the creation, processing, and disposition of records; maintain data quality; and yield insightful analysis and reporting.
Identify and prioritize opportunities for Governance, Risk, and Compliance (GRC) tools to interface with each other and access authoritative external data repositories, to include the identification and configuration of APIs.
Initiate and manage projects to harness Natural Language Processing (NLP) for technology risk management functions.
Translate data model requirements into specific features for development by adjacent teams.

About you. The ideal candidate for this position should be:
Highly motivated to design information systems, data storage solutions, and processes that empower colleagues working with large volumes of complex data.
A reliable and productive member of a high-performing team, able to balance requirements of multiple stakeholders.
Effective at communicating the rationale for data model decisions to senior executives.
Familiar with general practices for configuring RSA Archer, Audit Board, or similar GRC tools.
Proficient in setting up and maintaining data feeds and enforcing data quality using SQL, Python, Alteryx, Informatica, or similar tools.
Capable of basic project management .
Familiar with Agile development concepts.
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.
Pay Ranges
Atlanta, Georgia: $100,000 - $155,000 USD","$130,358 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Douglas County School District - Colorado
3.7",3.7,United States,Data Visualization Engineer,"Please complete this application using your full legal name as it appears on your government issued forms of identification when you have time to go from start to finish. Application details cannot be saved along the way, and you must complete and submit the application in one sitting. If you leave your computer and return later, you may time out.
REMINDER: Current DCSD employees must apply through their district log-on, this application is for external candidates only!

Job Posting Title:
Data Visualization Engineer

Job Description:
Supports and contributes to district initiatives and processes to provide data-driven decision-making related to district goals by transforming data into meaningful and actionable insights through the creation of visually appealing and interactive data visualizations, dashboards, infographics, reports, and models. You will work closely with cross-functional teams to understand data requirements, design effective visualizations, and provide valuable insights to support both tactical and strategic decision-making.

MINIMUM EDUCATION OR FORMAL TRAINING:
Bachelor’s Degree in a related field (e.g., Data Science, Computer Science, Statistics, or a relevant discipline)

ESSENTIAL ENVIRONMENTAL DEMANDS:
Mostly clean and comfortable.

ESSENTIAL PHYSICAL REQUIREMENTS:
Occasional travel throughout 900 sq mi school district, requiring personal vehicle.
- Occasional lifting of 10 -20 pounds.
Frequent bending, stooping, walking, standing, kneeling, squatting, reaching, and sitting.

Position Specific Information (if Applicable):

Responsibilities:
Data Visualization: Create visually stunning and interactive data visualizations using industry-standard tools such as Tableau, or Python libraries (matplotlib, Seaborn, Plotly, etc.).
Data Analysis: Analyze complex datasets to identify trends, patterns, and outliers that can be communicated effectively through visualizations.
Requirements Gathering: Collaborate with stakeholders to understand their data needs and translate these requirements into actionable visualization designs.
Dashboard Development: Build and maintain dashboards that provide real-time insights and allow end-users to interact with the data.
Data Storytelling: Craft compelling narratives around data visualizations to effectively communicate findings to both technical and non-technical audiences.
Quality Assurance: Ensure the accuracy, consistency, and reliability of data visualizations by performing data analysis, validation and quality checks.
Data Management and Integration: Work with data engineering teams to source, integrate and transform data from various sources into usable formats for visualization purposes.
Collaborate with stakeholders to establish business requirements. Analyze business requirements and design systems to support those needs.
Review tasks in progress and completed assignments for accuracy, efficiency, maintainability and adherence to established standards. Engage in knowledge transfer and cross-training between skills and applications.
Review documentation for new software releases and work with users to determine impacts and modifications necessary.
Plan, prepare and conduct system level testing. Analyze test results to detect technical or logical errors.
Adhere to and keep current the Information Services standards, programming procedures and techniques. Act as technical consultant to the ITS staff and to others outside the organization. Develop the knowledge and skills of other team members.
Detect, isolate and resolve application issues and serve as a technical resource in the evaluation, analysis, design, development, testing, integration and support of the District’s applications.
Perform other related duties as assigned or requested.

Certifications:
Valid Colorado Driver's License - Colorado Dept of Transportation

Education:
Bachelor's Degree (Required)

Skills:
Ability to learn new technologies and methodologies., Ability to mentor and provide leadership in processes and development activities., Ability to work collaboratively in a team and meet tight deadlines, Ability to work independently., Accountability: take pride and ownership of work; ensuring process and outcomes; solutions and results based; candid and forthwith of issues; maintain integrity at all times; Observes all District policies and procedures, Attention to detail and a commitment to producing high-quality visualizations, Attitude: Always respectful of others time and ideas; approachable by both customers and co-workers; consistent positive “can do” attitude; passion to meet customer objectives, Collaboration: commitment to communication to customers and team; foster the exchange of ideas; willing to teach others; excellence in customer service; commitment to regularly share helpful and relevant information; timely, clearly, candidly, and with transparency, Competency: continuous self-improvement and mastering of technology skills; maintain agility to customer needs; rapid and effective engineering; results based without sacrificing quality in workmanship; commitment to innovation; ability to understand and follow complex oral and written instructions, Computer applications skills: Microsoft Office, Project, Excel, Visio, etc., Customer-focused, Team oriented, and ability to collaborate with team members and provide user training., Excellent communication and storytelling skills, Excellent verbal and written communication skills in English and a demonstrated ability to read and comprehend written/graphic and oral instructions, Knowledge of and experience with SQL, R, Python, Knowledge of data warehousing and ETL processes is a plus, Knowledge of statistical analysis methods, Proficiency in data visualization tools like Tableau or equivalent, Project management and multi-tasking skills., Strong organization, analytical, problem solving, and prioritizing skills.
Position Type:
Regular

Primary Location:
West Support Center

One Year Only (Yes or No):
No

Scheduled Hours Per Week:
40

FTE:
1.00

Approx Scheduled Days Per Year:
260 Work Days
(260 days indicates a year-round position. Time off [or Off-Track Days] are then granted based on the position. Any exceptions to the normal off-track time will be noted in the Additional Position Details section above, as scheduled work days.)

Minimum Hire Rate:
$76,556.52 USD Annual

Maximum Hire Rate:
$94,859.47 USD Annual

Full Salary Range:
$76,556.52 USD - $113,162.43 USD Annual
All salary amounts listed above are based on a full-time (1.0) FTE. If applicable, part-time salaries will be prorated according to the assigned FTE.

Benefits:
This position is eligible for health, vision, dental, health savings account (HSA), flexible spending accounts (FSA), District paid and voluntary additional (supplemental) life and accidental death and dismemberment insurance, short and long-term disability, critical illness and accident voluntary insurance, employee assistance program (EAP), voluntary 401(k), 403(b) and 457 retirement plan options. There is also a voluntary 403(b) savings plan with up to 4% District match for up to 5 years from date of hire.
Time Off Plans:
This position is eligible for paid off-track, sick and personal time.
This position will be open until filled, but will not be open past:
December 21, 2023","$76,557 /yr (est.)",5001 to 10000 Employees,School / School District,Education,Primary & Secondary Schools,1958,$500 million to $1 billion (USD)
"Philips
3.6",3.6,"Plymouth, MN",Data Engineer,"Job Title
Data Engineer
Job Description
Data Engineer – Cambridge, MA, San Diego, CA, Plymouth, MN or Colorado Springs, CO
Do you like to tackle challenges and solve them using data and facts? Enjoy collaborative work, cross-functionally connecting execution, analytics, and business strategy?
We need you to bring your in-depth knowledge of business processes, analysis, and cooperation skills to make you a trusted advisor in this role!
Your role:
Work cross-functionally to understand business objectives and translate them into data science projects.
Design data models, visualizations and tools to enable reporting of key commercial metrics through single source of truth.
Develop and manage ETL frameworks to generate accurate, efficient and impactful analytics.
You're the right fit if:
5+ years of previous experience as a data engineer with emphasis on Big Data analytics in commercial or manufacturing settings.
Well-versed in Python programming and Qlik Sense/Power BI data visualizations development.
Strong business and financial acumen with experience using your interpersonal skills to support senior leadership.
Bachelor’s or master’s degree in computer sciences.
You must be able to successfully perform the following minimum Physical, Cognitive and Environmental job requirements with or without accommodation for this position.
About Philips
We are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help improve the lives of others.
Learn more about our business.
Discover our rich and exciting history.
Learn more about our purpose.
Read more about our employee benefits.
If you’re interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our commitment to diversity and inclusion here.
Philips Transparency Details
The pay range for this position is $75,180 – $ 128,880 annually. The actual base pay offered may vary depending on multiple factors including, job-related knowledge/skills, experience, business needs, geographical location, and internal equity.
In addition, other compensation, such as an annual incentive bonus, sales commission or long-term incentives may be offered. Employees are eligible to participate in our comprehensive Philips Total Rewards benefits program, which includes a generous PTO, 401k (up to 7% match), HSA (with company contribution), stock purchase plan, education reimbursement and much more. Details about our benefits can be found here.
At Philips, it is not typical for an individual to be hired at or near the top end of the range for their role and compensation decisions are dependent upon the facts and circumstances of each case.
Additional Information
US work authorization is a precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa, now or in the future.
Company relocation benefits will not be provided for this position. For this position, you must reside in or within commuting distance to the locations listed above.
Philips is an Equal Employment and Opportunity Employer/Disabled/Veteran and maintains a drug-free workplace.
#LI-PHI
#LI-Hybrid
#circa
Philips is an Equal Employment and Opportunity Employer/Disabled/Veteran and maintains a drug-free workplace.",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1891,$10+ billion (USD)
"Aristocrat
3.9",3.9,"Las Vegas, NV",Data Engineer I,"Job Posting Title
Data Engineer I
Summary
We are pioneers in our field and relentless in our pursuit of excellence. Aristocrat is an ideas company at heart, which means innovation is embedded into every aspect of our business. Whether we are designing sleek new cabinets, premium game content or award-winning systems, we apply fresh thinking and creativity to deliver the world's greatest gaming experience, every day. With cool new titles, such as Game of Thrones TM, Sons of Anarchy and Lightning Link along with our award-winning app Heart of Vegas, we are continually pushing the bar of creativity.
What You'll Do
Aristocrat is seeking an energetic, enthusiastic, and well-organized Data Engineer who would like to work in a multi-disciplinary environment. The Data Engineer plays a lead technical role in Analytics, Data Mining, Data Architecture and Data Science in general. The Data Engineer has a high-level of proficiency in analytic, and BI design producing high quality, robust, and maintainable products. This engineer has strong SDLC (Software Development Life Cycle) experience and is expected to work with little or no supervision. In this role, you will be an integral part of the team that creates and implements a vision for the data applications that support critical revenue generation for the company. If you are an exceptionally motivated, smart, and driven individual who wants to work in a fast-paced, ever-changing environment, this position is for you.
Job Requirements
Build and support data solutions that deliver strategic business value.
Drive world-class design and development of end-to-end analytics solutions for products that support high volumes and enable advanced analytical modeling.
Lead the technical evaluation and recommendations for platforms/tools that enable data mining, advanced analytics, data visualization, statistical analysis, and reporting.
Identify and propose software development process improvement initiatives for improving execution speed and quality.
Extract data from disparate sources and transform into data platforms.
Partner with stakeholders and data team members to improve data availability, automation, and quality.
What We're Looking For
Required Skills
At least 3 years of software and database development
At least 1 year of experience in Data Mining, Data Science, Business Intelligence or Analytics
Solid hands-on experience with data architecting, data mining, data modeling, automation and data integration
Expertise in SQL
Working knowledge of MS SQL Server and SSIS
Working knowledge of object-oriented programming languages including but not limited to Python, Javascript, R. Python
Experience implementing, deploying, and operating big-data platform with an enterprise environment.
Preferred Skills
Experience with MS SQL Server configuration and management
Experience in data warehousing technologies such as BigQuery
Experience in cloud technologies such as AWS, Azure and GCP
Experience with NoSQL, Hadoop and other Big Data technologies
Experience in Agile SDLC development methodologies
Additional Skills
Strong attention to detail and data quality
Proven analytical, conceptual, and problem-solving abilities
Possess the ability to identify, analyze, and resolve problems logically and systematically
Proficient in authoring, editing, and presenting technical documents
Ability to elicit requirements and communicate clearly with non-technical individuals, development teams and other team members
Applies effective communication techniques, engages in focused dialogue, and demonstrates good listening skills
Drive operational efficiency by maintaining data ecosystems, sourcing analytics, and fulfilling ad-hoc requests to promote continuous insights and improvements
Recommend and advise on all data components, roadmap, and emerging technologies
Possesses high integrity and exceptional work ethic. Fosters mutual trust and respect and is an excellent team player
Meets challenges consistently and confidently with energy and drive. Motivated by results, urgency, and personal commitment
Understands the link between excellence in data acquisition/warehousing/insights, and how to leverage this as a competitive advantage in the marketplace
Why Aristocrat?
Aristocrat is a world leader in gaming content and technology, and a top-tier publisher of free-to-play mobile games. We deliver great performance for our B2B customers and bring joy to the lives of the millions of people who love to play our casino and mobile games. And while we focus on fun, we never forget our responsibilities. We strive to lead the way in responsible gameplay, and to lift the bar in company governance, employee wellbeing and sustainability. We’re a diverse business united by shared values and an inspiring mission to bring joy to life through the power of play.
We aim to create an environment where individual differences are valued, and all employees have the opportunity to realize their potential. We welcome and encourage applications from all people regardless of age, gender, race, ethnicity, cultural background, disability status or LGBTQ+ identity. We offer a range of flexible working options through all.flex, our flexible hybrid work model and invite you to have a conversation with us about flexible working. EEO M/F/D/V
World Leader in Gaming Entertainment
Robust benefits package
Global career opportunities
Our Values
All about the Player
Talent Unleashed
Collective Brilliance
Good Business Good Citizen
The US based roles may require registration with the Nevada Gaming Control Board (NGCB) and/or other gaming jurisdictions in which we operate.

Pay Range
$56,998-$105,853

Pay Rate Type: Salary

Our goal is to pay a market competitive salary focusing near the median of our pay ranges. However, final offers for all positions will be based on several factors such as experience level, education, skills, work location, and internal pay equity.","$81,426 /yr (est.)",5001 to 10000 Employees,Company - Public,"Arts, Entertainment & Recreation",Gambling,1953,$1 to $5 billion (USD)
"Trenchant Employee Services Limited
3.8",3.8,"Irving, TX",Big Data Platform Engineer,"This is a hybrid role, based in G-Research’s office in Dallas.
G-Research is Europe’s leading quantitative finance research firm. We hire the brightest minds in the world to tackle some of the biggest questions in finance. We pair this expertise with machine learning, big data, and some of the most advanced technology available to predict movements in financial markets.
Opened in 2022, the Dallas office is a key infrastructure hub where we work on the latest technologies in a cutting-edge environment.
The role
G-Research is a fast-growing, software-driven organisation. We use large-scale deployments of distributed systems to drive research and monitoring capabilities within the business.
Key responsibilities of the role include:
Developing, maintaining and supporting scalable and reliable big data solutions
Collaborating with cross-functional teams to gather requirements, assess technical feasibility, and provide recommendations for optimal solution implementation
Owning the design and delivery of small to medium sized projects, ensuring adherence to best practices, performance optimisation, and alignment with overall platform architecture
Proactively identifying and addressing system performance bottlenecks, potential security vulnerabilities, and areas for improvement to ensure systems are stable and robust
Providing metrics, documentation, and self-service infrastructure that help our users to work at pace and optimise their use of the platform
Keeping up-to-date with industry trends, emerging technologies, and best practices in the field of big data platform engineering, and contributing to the continuous improvement of the platform
Who are we looking for?
The Big Data Platform Engineering team have a diverse set of complementary skills. Typically, team members will have strong abilities in infrastructure automation, Big Data technologies or software development. Whatever your technical background, strong coding skills are key.
The ideal candidate will have the following skills and experience:
A strong desire to continually learn about new technologies, approaches, and systems, along with the agility to work across multiple teams
A willingness to learn by working with users across different business areas, experiences and cultures to drive towards the best outcome for G-Research
Excellent problem solving skills
Linux and Networking fundamentals
Python, used for automation and integration
Experience with CI/CD (preferably Jenkins and ArgoCD) and Configuration Management tools, such as Ansible and Terraform
Experience deploying and running applications on Docker and Kubernetes, including the creation of Helm charts
Experience working with distributed systems
Highly desirable but not essential:
Experience working with the Prometheus Grafana monitoring stack
Experience working with Big Data technologies, such as Spark, Trino, Hive, Airflow, YARN, HDFS, and Ozone
Experience working with distributed storage systems
Data Engineering experience (Spark application development, SQL)
Why should you apply?
Market-leading compensation plus annual discretionary bonus
Informal dress code and excellent work/life balance
Excellent paid time off allowance
Sick days, military leave, and family and medical leave
Generous 401(k) plan
12-weeks’ fully paid parental leave
Medical and Prescription, Dental, and Vision insurance
Life and Accidental Death & Dismemberment (AD&D) insurance
Employee Assistance and Wellness programs
Generous relocation allowance and support
Great selection of office snacks, and hot and cold drinks
On-site gym and car park
Job Type: Full-time
Salary: $200,000.00 - $350,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Relocation assistance
Vision insurance
Compensation package:
Bonus opportunities
Schedule:
Monday to Friday
Ability to commute/relocate:
Irving, TX 75039: Reliably commute or planning to relocate before starting work (Required)
Work Location: Hybrid remote in Irving, TX 75039","$275,000 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Computer Hardware Development,2001,Unknown / Non-Applicable
"Tandem Diabetes Care Inc.
3.4",3.4,"San Diego, CA",Sr Data Engineer I,"GROW WITH US:
Tandem Diabetes Care creates new possibilities for people living with diabetes, their loved ones, and their healthcare providers through a positively different experience. We’d love for you to team up with us to “innovate every day,” put “people first,” and take a “no-shortcuts” approach that has propelled us to become a leader in the diabetes technology industry.
STAY AWESOME:
Tandem Diabetes Care is proud to manufacture and sell the t:slim X2 insulin pump with Control-IQ technology. We’re also so much more than that. Our company’s human-centered approach to design, development, and support delivers innovative products and services for people who use insulin. Since many of our own team members live with type 1 diabetes, or have a loved one impacted by diabetes, the work is personal, and we are committed to the cause. Learn more at tandemdiabetes.com.
A DAY IN THE LIFE:
The Data Science team at Tandem is tasked with empowering stakeholders to use data for better and faster decision making across all aspects of the business lifecycle. As a Data Engineer on the Tandem Data Science Team, you will use cloud technology to develop robust data pipelines and operationalize machine learning models and algorithms. This team member will use Tandem’s data assets to solve data-driven problems at scale, improve operational efficiency through forecasting and automation, and improve business outcomes.
Partners with data scientists and data architects to operationalize machine learning models and algorithms
Builds robust, fault-tolerant data pipelines
Builds monitoring infrastructure to give visibility into the data pipeline’s status and the impact of jobs on cluster performance
Lays the groundwork for data scientists to easily access data they need to research and prototype parallelizable models, algorithms, and visualizations
Cleans, consolidates, and processes unstructured data
Provides subject matter expertise in data and software engineering
Supports the team in the development and/or implementation of data products or models.
Attends industry and academic conferences to keep up to date with the state of technology.
Ensures compliance with company policies, including Privacy/HIPAA, and other legal and regulatory requirements.
Collaborate with DevOps to define and build CI/CD automation pipelines.
YOU’RE AWESOME AT:
Expert knowledge of software engineering, distributed computing, and cloud platforms
Experience deploying machine learning models and algorithms using cloud platforms
Programming skills in Spark, Python, or similar programming languages
Knowledge of SQL and data warehousing
T-shaped: strong in data engineering, but also strong capabilities to deliver actionable results in a collaborative environment: excellent pragmatic problem solving, attention to detail, strong written and verbal communication skills, curiosity, and a demonstrated ability to learn and grow new skills
Ability to think strategically
Comfortable with a wide array of technologies and programming languages, with demonstrated ability to learn new tools quickly
Familiarity with Databricks is a plus
EXTRA AWESOME:
BA in computer science or other quantitative discipline
4 years of experience as a data engineer, through a combination of work experience and higher education
WHAT’S IN IT FOR YOU?
In addition to innovative technology, we have a culture that fosters the idea that the happiest people are the most productive people. Not only do we hire forward-thinking achievers to join our workforce; we reward, develop, and retain them too. Just one of the many reasons of how we #StayAwesome! To learn more about our culture and benefits please visit https://www.tandemdiabetes.com/careers.
BE YOU, WITH US!
Tandem is firmly committed to being an equal opportunity employer and maintaining a diverse and inclusive environment. We value and embrace that every single one of us brings value to the table. But sometimes we forget that when we don’t meet 100% of a job description’s criteria – maybe you’re feeling that way right now? We encourage you to apply anyway. Because we want you to be you, with us.
COMPENSATION & BENEFITS:
The starting base pay range for this position is $120,000 - $135,000 annually. Base pay will vary based on job-related knowledge, skills, experience and may also fluctuate depending on candidate’s location and the overall job market. In addition to base pay, Tandem offers a competitive compensation package that includes bonus, equity, and a robust benefits package.
Tandem offers health care benefits such as medical, dental, vision, health savings accounts and flexible saving accounts. You’ll also receive 10 paid holidays per year, a minimum of 20 days of paid time off (starting in year 1) and have access to a 401k plan with company match. Learn more about Tandem’s benefits here!
YOU SHOULD KNOW:
Potential new employees must successfully complete a drug screen and background check which includes criminal search, education certification and employment verification prior to hire.
REFERRALS:
We love a good referral! If you know someone that would be a great fit for this position, please share!
If you are applying for this job and live in California, please read Tandem’s CCPA Notice: https://www.tandemdiabetes.com/careers/california-consumer-privacy-act-notice-for-job-applicants.
#LI-Remote #LI-KT1","$127,500 /yr (est.)",1001 to 5000 Employees,Company - Public,Manufacturing,Health Care Products Manufacturing,2006,$100 to $500 million (USD)
"Kraft Heinz Company
3.5",3.5,"Chicago, IL",Sr. Data Engineer,"General information
All posting locations: Chicago, Illinois, United States of America
Job Function: 16 - Digital
Date Published: 19-Sep-2023
Ref #: R-65959
Base Salary Range: $83,400.00 - $104,200.00
Target Total Cash Range: $104,250.00 - $130,250.00
Target Total Cash: Target total cash represents this role's annualized cash earning potential at target (base salary + target bonus). Target total cash is contingent on targeted company performance achievement and individual attainment of performance goals. Therefore, target total cash is not guaranteed earnings.
Compensation Disclaimer: The compensation offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors.
Description & Requirements
As a Senior Data Engineer- you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data- enabling Kraft Heinz to advance data-driven decision-making capabilities across the enterprise. You will have a deep understanding of data architecture- data engineering- data analysis- and reporting - and a basic understanding of data science techniques and workflows- as well as the business processes supported by the data pipeline. Examples of problems you will tackle include helping R&D determine the next generation of household products- revolutionizing consumer engagement with personally relevant content- and reinventing our supply chain to eliminate food waste. Furthermore- you will:

Design- develop- optimize- and maintain data architecture and pipelines that adhere to ELT principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for Business Intelligence Engineers- Business Analyst and data scientist team members to improve their productivity
Advise- consult- mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing- re-use- design for scale stability- and operational efficiency of data and analytical solutions
Lead the evaluation- implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
Develop and deliver communication and education plans on analytic data engineering capabilities- standards- and processes
Partner with machine learning engineers- business intelligence engineers and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning- data science- computer vision- artificial intelligence- statistics- and/or applied mathematics.

WHO YOU ARE
Bachelor’s degree required; Computer Science- MIS- or Engineering preferred
5+ years of experience working in data engineering or architecture role- 7+ preferred (3 years with 5 preferred for Jr. role)
Expertise in ELT and data analysis and experience with SQL and at least one programming language (Python/R preferred)
Experience developing and maintaining data warehouses in big data solutions e.g. Snowflake
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)
Database development experience using Hadoop- SPARK or BigQuery and experience with a variety of relational- NoSQL- and cloud database technologies
Worked with BI tools such as Alteryx- Tableau- Power BI- Looker
Conceptual knowledge of data and analytics- such as dimensional modeling- ELT- reporting tools- data governance- data warehousing- structured and unstructured data.
Big Data Development experience using Hive- Impala- Spark and familiarity with Kafka (Preferred)
Familiarity with the Linux operating system
Exposure to machine learning- data science- computer vision- artificial intelligence- statistics- and/or applied mathematics
An agile learner who brings strong problem-solving skills- and enjoys working as part of a technical- cross functional team to solve complex data problems
A hard worker and consensus gainer who brings a strong numbers sense; you are intellectually curious and willing to adjust your position based on additional information
About Us
Kraft Heinz is a global food company with a delicious heritage. With iconic and emerging food and beverage brands around the world, we deliver the best taste, fun and quality to every meal table we touch. We’re on a mission to disrupt not only our own business, but the global food industry. A consumer obsession and unexpected partnerships fuel our progress as we drive innovation across every part of our company.
Around the world, our people are connected by a culture of ownership, agility and endless curiosity. We also believe in being good humans, who are working to improve our company, communities, and planet. We’re proud of where we’ve been – and even more thrilled about where we’re headed – as we nourish the world and lead the future of food.
Why Us
We grow our people to grow our business. We champion great people who bring ambition, curiosity, and high performance to the table as the guardians of our beloved and nostalgic brands. Good isn't good enough. We choose greatness every day by challenging the ordinary and making bold decisions. All while celebrating our wins - and our failures – as we work together to lead the future of food.
Challenging the status quo takes talent. We invest in your purpose and potential by developing skills and nurturing strengths that leave a legacy on our business and a lasting impact on your career. Because great people make great companies, and we’re growing something great here at Kraft Heinz.
Office Collaboration & Hybrid Work Environment
We believe our office environment fuels our collaboration, connection & community as an organization and allows our employees to grow toward greatness. We also believe providing a more flexible and agile model is essential in today’s workplace. A majority of our office-based employees will be able to work remotely for up to two days each week. Additionally, employees who are subject to this hybrid model will be eligible to work from anywhere for up to six weeks in a rolling 12-month period (in maximum two-week increments and according to benefits and tax guidelines). Some jobs may be required to be performed fully in office depending on the role’s responsibilities and requirements.
Kraft Heinz is an Equal Opportunity Employer that prohibits discrimination or harassment of any type. All qualified applicants are considered for employment without regard to race, color, national origin, age, sex, sexual orientation, gender, gender identity or expression, disability status, protected veteran status, or any other characteristic protected by law. Applicants who require an accommodation to participate in the job application or hiring process should contact NATAI@kraftheinz.com.","$93,800 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Food & Beverage Manufacturing,2015,$10+ billion (USD)
"ServiceNow
4.4",4.4,"Santa Clara, CA",Software QA Engineer - PlatformX - Data QE,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For® and World's Most Admired Companies® 2022.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

What you get to do in this role:
Build high-quality, clean, scalable and reusable code by enforcing best practices around software engineering architecture and processes (Code Reviews, Unit testing, etc.)
Work with the product owners to understand detailed requirements and own your code from design, implementation, test automation and delivery of high-quality product to our users.
Design software that is simple to use to allow customers to extend and customize the functionality to meet their specific needs
Help design and implement new products and features while also enhancing the existing product suite

Qualifications

To be successful in this role you have:
2+ years of experience with Java or a similar OO language
Passion for JavaScript and the Web as a platform, reusability, and componentization
Experience with data structures, algorithms, object-oriented design, design patterns, and performance/scale considerations
Experience with any of the modern UI frameworks like Angular, React or Vue
Analytical and design skills
Working knowledge and ability to use tools to assist with daily tasks (IDE, debugger, build tools, source control, ServiceNow instances, profilers, system administration/Unix tools)
For positions in California in the Bay Area, we offer a base pay of $98,000K to $152,000K, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. For individuals who will be working in the Bay Area, there is a pay enhancement for positions located in that geographical area; please contact your recruiter for additional information.

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.","$123,378 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Technology Solutions Provider Inc.
4.5",4.5,Remote,Data Engineer (mid-level),"TSPi Position Description
TSPi is a leading-edge and trusted IT solutions provider to multiple government agencies. Using our technological expertise and industry specific knowledge, we offer our clients end-to-end solutions to address their specific challenges. We are looking for a Data Engineer with an entrepreneur’s mindset to support a fast-paced and growing data science team working on projects critical to farming, conservation, and environmental government missions.
Required Skills/Experience:
Proficiency in data engineering concepts, including ETL processing, data warehousing, and data modeling
Knowledge or experience with geospatial databases such as PostgreSQL/PostGIS/SQL Server/SQL Server Spatial, including schema design and optimization
Proficiency in Python and R
Strong SQL skills for data querying and manipulation, including spatial queries
Familiarity with ETL tools and frameworks for data pipeline development
Experience working with database tools in AWS (S3, DMS, EC2)

Equal Employment Opportunity Statement:
TSPi is an equal-opportunity employer and is committed to providing an inclusive, diverse, and equitable workplace. We welcome and celebrate the diversity of our workforce, and we strive to create an environment where all employees feel valued and can contribute their best.
We do not discriminate on the basis of race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), national origin, age, disability, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations, and ordinances.",#N/A,51 to 200 Employees,Private Practice / Firm,Information Technology,Information Technology Support Services,2001,Unknown / Non-Applicable
"SpaceX
3.9",3.9,"Hawthorne, CA","Application Software Engineer, Data","SpaceX was founded under the belief that a future where humanity is out exploring the stars is fundamentally more exciting than one where we are not. Today SpaceX is actively developing the technologies to make this possible, with the ultimate goal of enabling human life on Mars.
APPLICATION SOFTWARE ENGINEER, DATA
The application software team is the central nervous system of SpaceX – we create mission critical applications that are used throughout SpaceX to accelerate launch vehicle production and flight as well as systems that allow Starlink to grow into a worldwide fast, reliable Internet service.
We are looking for engineers who treat fellow teammates with fairness, respect, and support.
Our team is creating systems to ingest and store concurrent streams of data from many always-on assets to manage the world's largest satellite constellation, reusable rockets, and Dragon spacecraft. Other applications range from platforms that enable rapid build and reuse of Starship, designing the next generation manufacturing software that will be used in high throughput factories for Starlink, and public facing systems where customers can join our Starlink network globally.
We work closely with engineers throughout the company to create and update our systems with respect to crewed launches, Starship flights, changes to the Starlink network and much more.
Aerospace experience is not required to be successful here - rather we look for smart, motivated, collaborative engineers who love solving problems and want to make an impact on a super inspiring mission. You will have full ownership of challenging problems, working with a team of enthusiastic engineers to design and produce solutions that enable SpaceX to move towards our goals at a rapid pace. The success of the missions at SpaceX depends on the software that you and your team produce.
RESPONSIBILITIES:
Develop highly reliable and scalable data pipelines to empower engineers across SpaceX
Create new applications that improve how the business at SpaceX operates
Collaborate with peers on architecture, design, and code reviews
Build prototypes to prove out key design concepts and quantify technical constraints
Own all aspects of software engineering and product development
Deep dive into business problems, find efficient solutions and apply first principles thinking
BASIC QUALIFICATIONS:
Bachelor's degree in computer science, data science, engineering, math, physics, or scientific discipline; OR 2+ years of professional experience building software in lieu of a degree
Experience in full stack development, software engineering, data engineering, or data science
PREFERRED SKILLS AND EXPERIENCE:
Programming experience in Python, C#, Java, Scala, Go or similar languages
Experience working with in-stream, big data processing and analytics using Apache Kafka, Spark, Flink, SQL or similar
Experience with relational and non-relational databases, data lakes e.g. HBase, Hive, Delta Lake, PostgreSQL, CockroachDB or similar
Experience with data exploration tools like Grafana, Jupyter Notebooks, Metabase, PowerBI or similar
Good understanding of version control, testing, continuous integration, build, deployment and monitoring
Some front-end experience in Angular, React, or similar JavaScript framework
Good understanding of statistics, machine learning algorithms and frameworks
ADDITIONAL REQUIREMENTS:
Willing to work extended hours and weekends when needed
COMPENSATION AND BENEFITS:
Pay Range:
Application Software Engineer/Level I: $120,000.00 - $145,000.00/per year
Application Software Engineer/Level II: $140,000.00 - $170,000.00/per year
Your actual level and base salary will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.

Base salary is just one part of your total rewards package at SpaceX. You may also be eligible for long-term incentives, in the form of company stock, stock options, or long-term cash awards, as well as potential discretionary bonuses and the ability to purchase additional stock at a discount through an Employee Stock Purchase Plan. You will also receive access to comprehensive medical, vision, and dental coverage, access to a 401(k) retirement plan, short & long-term disability insurance, life insurance, paid parental leave, and various other discounts and perks. You may also accrue 3 weeks of paid vacation & will be eligible for 10 or more paid holidays per year. Exempt employees are eligible for 5 days of sick leave per year.
ITAR REQUIREMENTS:
To conform to U.S. Government space technology export regulations, including the International Traffic in Arms Regulations (ITAR) you must be a U.S. citizen, lawful permanent resident of the U.S., protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Department of State. Learn more about the ITAR here.
SpaceX is an Equal Opportunity Employer; employment with SpaceX is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.
Applicants wishing to view a copy of SpaceX's Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department at (310) 363-6000.","$132,500 /yr (est.)",5001 to 10000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2002,Unknown / Non-Applicable
"Adisys Corporation
4.3",4.3,"Bellevue, WA",Data Engineer,"Job Brief
Data Engineer
Bellevue / Seattle Area (Hybrid)

As a Data Engineer, you will build scalable tools and data pipelines to manage the datasets our customers use to fine tune models and for business analytics.
You will routinely deal with petabytes of data and help produce artifacts such as domain specific datasets.
You will be responsible for expanding our data pipeline architecture in order to manage our data lake.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.
You will be responsible for ensuring an optimal data delivery architecture.
Requirements
3+ years of experience in a Data Engineer role.
Bachelor's degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field.
Experience building and optimizing ‘ big data’ data pipelines, architectures , and data sets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Experience with vector databases such as Pinecone, Chroma, Milvus, or PostgreSQL with vector type (Pgvector)
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Data ingestion using one or more modern ETL compute and orchestration frameworks (e.g., Apache Airflow, Luigi, Spark, Apache Nifi, and Apache Beam).
Experience with relational SQL and NoSQL databases.
Industry level experience working with public cloud environments (AWS, GCP, or Azure) and associated deep understanding of failover, high-availability, and high scalability.
Experience with one or more of Python , Go, or C++.
GPU programming, NCCL, Cuda knowledge a plus.
Experience with Pytorch or Tensorflow a plus.
Experience with Kubernetes and containerization, VPNs, AI workloads, and blockchain based protocols a plus.
Experience with stream-processing systems: Kafka, Storm, Spark-Streaming, etc. a plus.
Strong project management and organizational skills.
A self-starter and able to operate independently.

Roles And Responsibilities
Design and develop highly scalable and resilient services/data pipelines for data ingestion and processing using modern big data technologies.
Partner with Machine Learning researchers and Platform Engineering teams to develop and deploy production quality code.
Develop and champion modern Data Engineering concepts to technical audience and business stakeholders.
Implement new and innovative deployment techniques, tooling, and infrastructure automation within our company and customers.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources for both Machine Learning training and business analytics.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.
Develop and maintain our real time analytics/low latency data access layer built on top of modern OLAP solutions.
Automate and handle the lifecycle of data sets (schema evolution, metadata management, change and backfill management, deprecation, and migration).
Improve the data quality and reliability of the pipelines through properly monitoring and failure detection.
Comfortably collaborate with cross functional partners and lead technical initiatives end to end.
Write, review, or provide feedback on a technical design proposal from others.

About Us
Adisys has proven track record in delivering innovative software product development solutions. This position is for our important client who specialized in Artificial Intelligence. To meet our customer's changing needs in all aspects of strategy, technique, and organization management to achieve the best result that exceeds customer expectations and provides success.


visit us at www.adisys.com","$103,931 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2009,$5 to $25 million (USD)
"FedML, Inc.",#N/A,"Sunnyvale, CA",Back-end and Data Platform Software Engineer,"Responsibilities
Participate in the development of machine learning platform and open source communities
Responsible for the foundational research and product development, and continuously improve the R&D efficiency
Responsible for feature development, algorithm optimization of the platform, improving user experience and usability through cutting-edge or mature technologies
Participate in or lead design reviews with peers and stakeholders to decide amongst available technologies
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency)
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback
Minimum Qualifications
Bachelor’s degree or equivalent practical experience in computer science or related areas.
2 years of experience with software development in one or more programming languages (Python, Java, JavaScript, C/C++), or 1 year of experience with an advanced degree
2 years of experience with data structures or algorithms in either an academic or industry setting
Good communication and writing skills in English environment
Preferred Qualifications
Proficient in Java, familiar with Linux, Spring, Mybatis, Spring Cloud, MySQL, common NoSQL systems and distributed architecture
Familiar with the application of Kubernetes, Docker, DevOPS and other cloud native (Cloud Native) technologies, experience in medium and large-scale back-end application development is preferred, and experience in machine learning platform development is preferred
Familiar with underlying middleware and distributed technologies (such as RPC framework, cache, message system, etc.)
Familiar with the use/principle/tuning of common big data frameworks is preferred, such as Flume/Kafka/Hadoop/Hbase/Spark/Storm/ELK/ETL/kafka/Hive, etc.
About the Job
FedML, Inc. (https:/fedml.ai) empowers our clients to build & scale any machine learning or artificial intelligence models anywhere. That includes the latest foundation models as well as more traditional ML models. Our products cover both training, serving with a low-code UI MLOPs & LLMOps platform. We also offer a Federated Machine Learning solution for cross-silo training for data privacy sensitive applications.
Our earliest products power federated machine learning missions for clients in several industries, where data privacy, low latency serving, and low cost of data storage are important to the client. Our easy-to-use FedML MLOps solution enables data science and machine learning engineering to work seamlessly together to deploy & manage their model to production machines. Our federated learning and serving solutions support siloed edge devices, smartphones, and IoT.
Our next generation of solutions includes geo-distributed machine learning and serving that continues our tradition of delivering easy-to-use, simple, low-cost, and enterprise grade MLOPs solutions. Our MLOps and evolving LLMOps platform will always empower experimentation, observability, evaluation, governance, and collaboration for our clients’ AI & ML training and serving needs, as well as other general computing needs.
FedML supports vertical solutions across a broad range of industries (healthcare, finance, insurance, automotive, advertising, smart cities, IoT etc,) and applications (computer vision, natural language processing, data mining, and time-series forecasting). Its core technology is backed by more than 3 years of cutting-edge research of its co-founders who are recognized leaders in the federated machine learning community.
FedML's researchers and software engineers and product teams are busy developing the next-generation FedML platform for machine learning and artificial intelligence and we're looking to grow our team with skilled professionals who bring fresh ideas from all areas, including machine learning and its applications, computer vision, natural language processing, large-scale system design, distributed/cloud computing/systems, MLOps, security/privacy, mobile/IoT systems, and networking. We’re an early stage startup, hence you will work on projects which are critical to our customers' and our business needs. If you love to learn, and love to convert ideas into real and scalable machine learning infrastructure products and applications, FedML may be a great place for you.
Location
Our HQ is in Sunnyvale California. Preference is for someone local who can be at our office regularly. Hybrid is ok.
How to apply
If you are interested, please apply via the link.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Grainger
4.1",4.1,"Lake Forest, IL",Data Engineer II,"Company Overview
Grainger is North America’s leading distributor of maintenance, repair, and operating products and services. Our wide assortment, deep expertise, innovative technology solutions and unparalleled customer service keep customers’ operations running and their people safe.
We’re looking for passionate people who can move our company forward. We have a welcoming workplace where you can build a career for yourself while fulfilling our purpose to keep the world working. We embrace new ways of thinking and recognize everyone is an individual. Find your way at Grainger.
You Have
3+ years of experience with Modern Data Engineering projects and practices: designing, building, and deploying scalable data pipelines
2+ years of experience in designing building deploying cloud native solutions
2+ years of experience with Power Apps, AWS, SQL, Python, Docker/Kubernetes, CI/CD, Git, familiarity with: Snowflake, DBT, Airflow
Developed data products/systems using large and complex data sets to meet business and technical requirements
Experience partnering with internal departments to establish requirements
Familiarity with BI tools such as Tableau, PowerBI
Bachelor's degree in Computer Science, information systems, or a related study or equivalent project-related experience
You Will
Build and maintain customized web tools consumed by our internal business partners and sales team members
Enable analytics and reporting by centralizing and integrating high quality, large, complex data sets in a highly performant and scalable cloud analytical platform
Design, and implement data pipelines to ingest, cleanse and enrich data for analytics
Design and implement secure, performant data models to meet the scalability and performance needs of data product
Partner with stakeholders including data, design, product, and executive teams and assisting them with data-related technical issues

DE&I Statement
Grainger is an Equal Opportunity Workplace and an Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status.","$102,224 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,Wholesale,1927,$10+ billion (USD)
"Electronic Arts
4.0",4.0,"Austin, TX","Senior Software Engineer in Data, Game Creation","Electronic Arts Inc. is a global leader in interactive entertainment. We develop and deliver games, content and online services across platforms. We have a broad portfolio of brands that span the most popular genres.
We exist to Inspire the World to Play. We create extraordinary new game experiences for our millions of players everywhere by bringing together accomplished people that combine creativity, innovation, and passion. We immerse our employees into an inclusive culture and provide opportunities for learning and leading that allow our employees to do the most impactful and rewarding work of their careers. Join us in driving the next revolution in games..
The Challenge Ahead
This technical role in the Game Creation team reports to an Engineering Manager, and you can be fully remote in the US. It involves envisioning, designing, and building enterprise-level solutions for EA's video games and central services teams. You'll create architectures integrating custom, COTS, and packaged applications, and work with products like JIRA, Perforce, and GitLab. Our cloud-first approach uses Azure and AWS, and you'll lead agile teams supporting thousands of users across game teams like FIFA, Madden, Battlefield, and central teams like Frostbite and Origin
Key Responsibilities
You will address complex challenges and create solutions using the latest Game Creation products to empower game creators
You will be a Game Creation product SME, comprehending business intricacies, collaborating with teams, and enriching the game development experience using our Azure data platform.
You will lead data insights by identifying patterns, correlations, and trends for impactful reports and visualizations.
Job qualifications and requirements
5+ years of experience managing and serving as an SDLC/ALM tools SME for products such as JIRA, Gitlab, Perforce, Artifactory, Azure DevOps, Jenkins; more tools = stronger candidate.
5+ years of experience using the mentioned SDLC/ALM tools for data analysis, monitoring, and reporting.
5+ years of experience working with .NET, including .NET Core, C#, ASP.NET, JavaScript, REST.
5+ years of experience in database development, queries, and ETL processes.
3+ years of experience with Azure, including VMs, Networks, Azure Data Factory, Azure Data Lake, Azure Data Explorer, Bicep, and Logic Apps
3+ years of experience identifying data patterns, correlations, and trends, constructing reports, dashboards, analytics and visualizations
3+ years of experience with PowerBI constructing reports, dashboards, analytics and visualizations
Bonus Requirements
Azure Synapse, Fabric
Terraform
Docker and Kubernetes
AWS
Tableau
Python
US COMPENSATION AND BENEFITS
The base salary ranges listed below are for the defined geographic market pay zones in these states. If you reside outside of these locations, a recruiter will advise on the base salary range and benefits for your specific location. EA has listed the base salary ranges it in good faith expects to pay applicants for this role in the locations listed, as of the time of this posting. Salary offered will be determined based on numerous relevant business and candidate factors including, for example, education, qualifications, certifications, experience, skills, geographic location, and business or organizational needs.
BASE SALARY RANGES
California (depending on location e.g. Los Angeles vs. Sacramento): $149,150 - $233,500
New York (depending on location e.g. Manhattan vs. Buffalo): $136,000 - $233,500
Jersey City, NJ: $171,100 - $233,500
Colorado (depending on location e.g. Denver vs. Colorado Springs):$136,000 - $190,850
Washington (depending on location e.g. Seattle vs. Spokane): $136,000 - $218,900
Base salary is just one part of the overall compensation at EA. We also offer a package of benefits including paid time off (3 weeks per year to start), 80 hours per year of sick time, 16 paid company holidays per year, 10 weeks paid time off to bond with baby, medical/dental/vision insurance, life insurance, disability insurance, and 401(k) to regular full-time employees. Certain roles may also be eligible for bonus and equity.
#LI-Remote, #LI-Hybrid, #LI-Onsite #FlexibleWork

We are a global team of creators, storytellers, technologists, experience originators, innovators and so much more. We believe amazing games and experiences start with teams as diverse as the players and communities we serve. At Electronic Arts, the only limit is your imagination.","$177,450 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Video Game Publishing,1982,$5 to $10 billion (USD)
"Fiserv, Inc.
3.1",3.1,"Berkeley Heights, NJ",Data & Analytics Engineer,"Calling all innovators – find your future at Fiserv.
We’re Fiserv, a global leader in Fintech and payments, and we move money and information in a way that moves the world. We connect financial institutions, corporations, merchants, and consumers to one another millions of times a day – quickly, reliably, and securely. Any time you swipe your credit card, pay through a mobile app, or withdraw money from the bank, we’re involved. If you want to make an impact on a global scale, come make a difference at Fiserv.
Job Title
Data & Analytics Engineer
What does a successful Data & Analytics Engineer do at Fiserv?
Join our team at Fiserv as a Data & Analytics Engineer and play a pivotal role in maintaining core development for our Data Warehouse projects. As a Data & Analytics Engineer, you'll collaborate closely with business partners, internal project managers, and development resources to identify business needs and create technical solutions for applications. This position involves data analysis, providing valuable business insights, and offering data-driven strategy recommendations.
What you will do:
Responsible for migration of existing data center BI/Analytics platform to AWS/Snowflake. Also lead development areas like FDM (File Delivery Manager)
Design and develop application architecture, offering estimations, designing data security layers, and crafting comprehensive design documents.
Fulfill ad hoc data requests using SQL, Toad, and other available tools.
Provide Development and Tier 3 support for an Oracle Datawarehouse called Open Data for DNA. This includes monitoring jobs, conducting root cause analysis, resolving issues, and maintaining transparent communication with customers regarding expected ETAs and resolutions.
Collaborate with an offshore team to drive efficient development work.
Utilize your Unix Shell scripting proficiency and familiarity with Unix Commands to optimize workflows.
What you will need to have:
Bachelor’s degree required, STEM or related majors preferred, or equivalent experience
7 to 8 years of Oracle DB management/development, demonstrating your expertise in this critical area.
3+ years of ETL experience pulling from SQL Server and/or Oracle
Experience BI Platform Administration, Security, and Migrations
Strong SQL and Database configuration experience
Proficiency in Unix Shell scripting experience and familiarity with Unix Commands.
Familiarity and adherence Software Development Life Cycle processes and rules.
What would be great to have:
Cloud experience with AWS
IT experience in the Merchant Services or Credit Services industry or Financial industry
Experience with Streamsets, React.js, IDM Ping
Big Data experience with Snowflake, Greenplum, Netezza or Teradata
This role is not eligible to be performed in Colorado, California, New York or Washington.
Please note that salary ranges provided for this role on external job boards are salary estimates made by outside parties and may not be accurate.
Thank you for considering employment with Fiserv. Please:
Apply using your legal name
Complete the step-by-step profile and attach your resume (either is acceptable, both are preferable).
What you should know about us:
Fiserv is a global fintech leader with 40,000-plus (and growing) associates proudly serving clients in more than 100 countries. As a FORTUNE™ 500 company, one of Fast Company’s Most Innovative Companies, and a top scorer on Bloomberg’s Gender-Equality Index, we are committed to excellence and purposeful innovation.
Our commitment to Diversity and Inclusion:
Fiserv is an Equal Opportunity Employer, and we welcome and encourage diversity in our workforce that reflects our world. All qualified applicants will receive consideration for employment without regard to race, color, religion, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other category protected by law.
We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
Warning about fake job posts:
Please be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information.
Any communications from a Fiserv representative will come from a legitimate business email address. We will not hire through text message, social media, or email alone, and any interviews will be conducted in person or through a secure video call. We won’t ask you for sensitive information nor will we ask you to pay anything during the hiring process. We also won’t send you a check to cash on Fiserv’s behalf.
If you see suspicious activity or believe that you have been the victim of a job posting scam, you should report it to your local FBI field office or to the FBI’s Internet Crime Complaint Center.","$96,810 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1984,$10+ billion (USD)
"Citi
3.9",3.9,"Tampa, FL",Senior Data Engineer - VP - Hybrid,"About Citi:
Citi, the leading global bank, has approximately 200 million customer accounts and does business in more than 160 countries and jurisdictions. Citi provides consumers, corporations, governments, and institutions with a broad range of financial products and services, including consumer banking and credit, corporate and investment banking, securities brokerage, transaction services, and wealth management.
As a bank with a brain and a soul, Citi creates economic value that is systemically responsible and in our clients’ best interests. As a financial institution that touches every region of the world and every sector that shapes your daily life, our Enterprise Operations & Technology teams are charged with a mission that rivals any large tech company. Our technology solutions are the foundations of everything we do from keeping the bank safe, managing global resources, and providing the technical tools our workers need to be successful to designing our digital architecture and ensuring our platforms provide a first-class customer experience. We reimagine client and partner experiences to deliver excellence through secure, reliable, and efficient services.
Our commitment to diversity includes a workforce that represents the clients we serve from all walks of life, backgrounds, and origins. We foster an environment where the best people want to work. We value and demand respect for others, promote individuals based on merit, and ensure opportunities for personal development are widely available to all. Ideal candidates are innovators with well-rounded backgrounds who bring their authentic selves to work and complement our culture of delivering results with pride. If you are a problem solver who seeks passion in your work, come join us. We’ll enable growth and progress together.
Job Description:
The Operational Excellence (OE) group sits in the Enterprise Operations and Technology organization. Our team is responsible for designing and delivering new strategies and tools to assist enterprise-wide Operations groups to articulate their performance at delivering against Citi’s objectives. To deliver these objectives we work with leaders across PBWM, CSS and ICG Operations with a total influence across 80,000 employees. The Data & Analytics team, within OE, consists of 3 streams, Operational Metrics, Data, and Dashboarding. The team’s focus is delivering business functionality – providing Enterprise Operations with the data to make effective decision making, balancing efficiency, risk, and client experience, streamlining operations by automating processes from beginning to end, reducing manual touch points, and creating simpler processes across the firm.
Operations undergoing rapid infrastructure transformation and we spend a significant amount of time designing forward thinking, smart technologies, and applied intelligence to understand, optimize and simplify these processes, reimagining the way we communicate with one another to become more efficient.
This Senior Data Engineer will play a key role to support the Data & Analytics pillar within the OE organization, will work closely with Operations, Technology, Transformation, and Risk & Controls groups across all sectors of the bank (i.e., ICG, PBWM, and CSS Operations) to ensure tangible results aligned to the firm’s strategic priorities. The priority for this roll will be the strategic build of Capacity Planning frameworks through the Planning Analytics tool (PAW):
Key responsibilities include:
Innovative Data Modeling: You'll be instrumental in translating complex business requirements into scalable, robust data models that power critical initiatives like capacity modeling and process mining, shaping the future of our operations.
Architecting Data Excellence: You'll design forward-thinking data architectures and guide their implementation for enterprise-level initiatives, incorporating rules-based, configurable data processes that drive our strategic priorities.
Data Strategy Development: Contribute to the development of the organization's data strategy, providing insights and recommendations on how data can drive business growth and operational efficiency.
Innovative Data Solutions: Act as a driving force for innovation by researching and implementing emerging data technologies and solutions that enhance our data capabilities and support strategic initiatives.
Mastery of Data Logic: Your expertise will shine as you craft complex stored procedures, enhance existing database code, and fine-tune queries, ensuring top-notch performance and reliability, even with intricate data structures.
End-to-End Ownership: Take charge of the entire development process, from analysis and design to testing and implementation. Your support will extend to assisting business users and setting operating standards that keep us at the forefront.
Autonomy and Mentorship: Operate with a high level of autonomy, providing valuable insights as a subject matter expert to senior stakeholders and mentorship to junior analysts.
Business Leadership: Lead requirements discussions with business team to inform optimum strategic approaches for data structure and dev builds.
Cross-functional Collaboration: Foster collaboration across departments, working closely with Data Scientists, Business Analysts, and other stakeholders to create holistic data-driven solutions.
Problem Solving: Address complex data-related challenges with creative and effective solutions, enabling the organization to overcome obstacles and achieve its objectives.
Documentation and Knowledge Sharing: Maintain thorough documentation of data models, processes, and best practices while actively sharing knowledge within the team and the broader organization.
Requirements/Qualifications:
Motivated; Proactive, studious and tenacious self-starter
Data Prowess: Proven hands-on experience in data modeling, database architecture, and administration, along with a knack for data analytics and data science, complemented by proficiency in MS Excel.
Database Proficiency: Strong expertise in Oracle database PL/SQL and data analytics for large databases, including experience with ETL tools, preferably Talend.
Performance Optimization: A track record of excelling in query performance tuning and database optimization, particularly with complex datasets.
Scripting Skills: Proficiency in scripting languages such as Python and Linux shell, with exposure to various database technologies like Snowflake, Teradata, and Starburst.
Data Reporting: Familiarity with data reporting / Creation of visualizations and integration of analytics into existing platforms and analysis using tools like Tableau.
Educational : A bachelor’s degree in computer science or computer Engineering is required, and a Master's degree is a plus.
Additional information may be found at www.citigroup.com| Twitter: @Citi | YouTube: www.youtube.com/citi| Blog: http://blog.citigroup.com| Facebook: www.facebook.com/citi| LinkedIn: www.linkedin.com/company/citi.
-
Job Family Group:
Technology
-
Job Family:
Applications Development
-
Time Type:
Full time
-
Primary Location:
Tampa Florida United States
-
Primary Location Salary Range:
$110,090.00 - $165,130.00
-
Citi is an equal opportunity and affirmative action employer.
Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.
Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.
View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.
View the EEO Policy Statement.
View the Pay Transparency Posting","$137,610 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1812,$10+ billion (USD)
"Amex
4.2",4.2,"Itasca, IL",Senior Software Engineer (Big Data),"Accertify is the trusted partner to the world’s leading eCommerce brands. We help our clients grow revenue and protect against loss with industry-leading fraud prevention and digital identity offerings. When you join Accertify, you become part of the digital solution to enable legitimate eCommerce, delivering peace of mind to merchants and their customers across the globe. #TeamAccertify provides a solution merchants trust and a career you can trust.
Accertify is a wholly owned subsidiary of American Express-which means our team has access to the amazing perks and benefits offered by our parent company. We are proud to be #TeamAmex and #TeamAccertify.
Accertify is growing and we are looking to add a Senior Software Engineer with a focus on Big Data to our global fraud-fighting team.
How will you make an impact in this role?
This individual will use their software development background and strong analytical skills to help build and enhance Accertify’s industry-leading tools with a focus on interacting with our large datasets. This individual’s day-to-day work will involve using Java, Python, SQL, Big Data, Linux, git, and gradle to design and build software solutions that are fast, scalable, and flexible.
Essential Duties and Responsibilities:
Work with business representatives, Lead Developers, and the Director of Software Development to design, build and test new products and features
Use the IDE of your choice to write code in Java
Work independently or on small team projects
Participate in requirement gathering and design sessions
Participate in peer code reviews
Troubleshoot and optimize code for usability, performance, and scalability
Required Skills/Qualifications:
Bachelor’s degree in computer science
Advanced and demonstrable analytical, problem-solving, and debugging skills
Professional programming experience in an enterprise setting
High-volume transactional environment experience
4+ years of software development experience as a Java developer
2+ years of software development experience as a Python developer
A solid understanding of ""how things work"" in the world of computers, the Internet, databases, and the Java programming language
Familiarity with basic programming constructs (conditionals, loops, data structures)
Strong Relational database skills (SQL, JDBC - Oracle, and PostgreSQL preferred)
Desired Skills:
SQL databases such as MapR DB, HBase, Cassandra
Big Data Components/Frameworks such as Hadoop (MapR), Spark, Yarn, Kafka, Flink, ELK, etc.
Big Data querying tools such as Drill, Presto, Hive, Ojai, etc.
Salary Range: $110,000.00 to $190,000.00 annually + bonus + benefits
Employment eligibility to work with American Express in the U.S. is required as the company will not pursue visa sponsorship for these positions.
The above represents the expected salary range for this job requisition. Ultimately, in determining your pay, we'll consider your location, experience, and other job-related factors.
We back our colleagues and their loved ones with benefits and programs that support their holistic well-being. That means we prioritize their physical, financial, and mental health through each stage of life. Benefits include:
Competitive base salaries
Bonus incentives
6% Company Match on retirement savings plan
Free financial coaching and financial well-being support
Comprehensive medical, dental, vision, life insurance, and disability benefits
Flexible work arrangements and schedules with hybrid and virtual options with Amex Flex
20+ weeks paid parental leave for all parents, regardless of gender, offered for pregnancy, adoption or surrogacy
Free access to global on-site wellness centers staffed with nurses and doctors (depending on location)
Free and confidential counseling support through our Healthy Minds program
Career development and training opportunities
For a full list of Team Amex benefits, visit our Colleague Benefits Site.
At American Express, you’ll be recognized for your contributions, leadership, and impact—every colleague has the opportunity to share in the company’s success. Together, we’ll win as a team, striving to uphold our company values and powerful backing promise to provide the world’s best customer experience every day. And we’ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.
American Express is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran status, disability status, age, or any other status protected by law.
We back our colleagues with the support they need to thrive, professionally and personally. That's why we have Amex Flex, our enterprise working model that provides greater flexibility to colleagues while ensuring we preserve the important aspects of our unique in-person culture. Depending on role and business needs, colleagues will either work onsite, in a hybrid model (combination of in-office and virtual days) or fully virtually.
US Job Seekers/Employees - Click here to view the “Know Your Rights” poster and supplement and the Pay Transparency Policy Statement.
If the links do not work, please copy and paste the following URLs in a new browser window: https://www.dol.gov/agencies/ofccp/posters to access the three posters.","$150,000 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1850,$10+ billion (USD)
"M&T Bank
3.7",3.7,"Buffalo, NY",Senior Data Center Engineer,"This role offers a hybrid work schedule; offering the flexibility to work remotely two days a week, while providing the opportunity for in-person collaboration at our Buffalo, NY Tech Hub.
Overview:
As a Data Center Engineer at M&T Bank, you will play a pivotal role in the maintenance, optimization, and expansion of our data center infrastructure. You will be responsible for ensuring the reliability, performance, and security of our data center operations, with a focus on Arista and Cisco networking technologies.
Primary Responsibilities:
Network Infrastructure Management: Configure, monitor, and maintain Arista and Cisco network devices to ensure high availability and performance within the data center.
Data Center Operations: Perform routine data center tasks such as equipment installations, cabling, and hardware replacements while adhering to industry best practices.
Network Security: Implement and maintain security measures to protect data center assets and ensure compliance with security policies.
Troubleshooting: Identify and resolve network and system-related issues promptly to minimize downtime and disruptions.
Capacity Planning: Collaborate with cross-functional teams to assess data center capacity requirements and plan for future expansion.
Documentation: Maintain accurate records and documentation of network configurations, changes, and procedures.
Team Player: Collaborate with peers and cross-functional colleagues to deliver results for both large and small projects.
Education and Experience Required:
Combined minimum of 8 years’ higher education and/or work experience in systems design, management and/or architecture
Strong understanding of the system development and infrastructure lifecycle and architecture, vendor best practices, IT Service Management, and systems design
Education and Experience Preferred:
Bachelor’s Degree in Computer Science or Computer Engineering
Minimum of 8 years’ professional experience in a technical engineering position involving infrastructure design technologies, data management and interchange, system design and/or development for complex applications
#LI-KB1
M&T Bank is committed to fair, competitive, and market-informed pay for our employees. The pay range for this position is $107,412.63 - $179,021.06 Annual (USD). The successful candidate’s particular combination of knowledge, skills, and experience will inform their specific compensation.
Location:
Buffalo, New York, United States of America",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1856,$5 to $10 billion (USD)
"Lumen
3.5",3.5,Remote,Sr. Data Engineer,"About Lumen
Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.
The Role
Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen’s reputation as a technology leader?

In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence.
The Main Responsibilities
You are a great fit for this position if you:
Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions.
Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments.
Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in.
Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations.
What We Look For in a Candidate
Qualifications:
Experience building data models and performing complex queries using SQL
Experience performance tuning large datasets
Experience building large data pipelines and/or web services
Strong programming skills with Python and other scripting languages
4+ years of Business Intelligence or software development experience using industry technologies
3+ years of experience in building integration with upstream and downstream systems with REST APIs
Excellent problem solving, critical thinking, and communication skills
Ability to communicate effectively with technical and business teams, drive issues to closure
Strong understanding of data engineering and data stewardship roles in an organization
Strong time management and organization skills. Ability to work on multiple projects concurrently.
BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science

Other Qualifications:
Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable
Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable
Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies
Combined IT and Marketing background
Machine Learning, Data Science, and statistical modeling experience are highly valued
Azure experience.
Requisition #: 329671
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
72540
Salary Max :
161520
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.","$117,030 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1968,$10+ billion (USD)
"Netflix
4.2",4.2,Remote,Distributed Systems Engineer (L4) - Data Platform,"Remote, United States
Data Platform
At Netflix, we want to entertain the world and are constantly innovating on how entertainment is imagined, created and delivered to a global audience. We currently stream content in more than 30 languages in 190 countries, topping over 220 million paid subscribers and are expanding into new forms of entertainment such as gaming.

The data infrastructure teams at Netflix enable us to leverage data to bring joy to our members in many different ways. We provide centralized data platforms and tools for various business functions at Netflix, so they can utilize our data to make critical data-driven decisions. We do all the heavy lifting to make it easy for our business partners to work with data efficiently, securely, and responsibly. We aspire to lead the industry standard in building a world-class data infrastructure, as Netflix leads the way to be the most popular and pervasive destination for global internet entertainment.

We are looking for distributed systems engineers to help evolve and innovate our infrastructure as we work towards our ambitious goal of 500 million members worldwide. We are committed to building a diverse and inclusive team to bring new perspectives as we solve the next set of challenges. In addition, we are open to remote candidates. We value what you can do, from anywhere in the U.S.

Spotlight on Data Infrastructure Teams:

Database Access Platform |Learn More
The Database Access Platform team builds and operates a flexible query gateway that facilitates data abstractions to operate at sub-millisecond latencies while allowing Netflix microservices to more easily store, consume, and manage their data. This team holds a substantial responsibility in enabling Netflix microservices to satisfy their ever-growing and evolving data needs.
This team is passionate about distributed data systems technology. We are active in the open source community and believe in operating what we own. We are a small team responsible for business critical systems and are committed to a culture of feedback and engineering

Data Platform Infrastructure |Learn More
The Data Platform Infrastructure team acts as a platform for our own data platforms. Our shared infrastructure and tooling enable Netflix to quickly innovate on providing state-of-the-art data and analytics systems to the rest of the company without building bespoke scaffolding for each new system. To do this, we create high-leverage infrastructure, control, and deployment systems that are fine-tuned for the needs of running our data systems at scale; uniquely, many of our tools and systems are written in Python, so this is a great team to consider if you enjoy working in a variety of languages.

Data Movement and Processing |Learn More
Offers an abstracted self-service paved-paved path product to enable varied user persona across Netflix meet their low-latency Data Movement and Processing requirements; enables abstraction over complex Real-Time frameworks such as Kafka and Flink; offers a Schema driven processing experience; invests in operational automation, reliability and tools for predictable data quality.

Big Data Compute |Learn More
Responsible for providing the cloud-native platform for distributed data processing at Netflix. This team is central to batch data processing in Data Platform. It provides support for Spark, to ETL data into the Petabytes-scale data warehouse and access that data using Spark and Presto/TrinoDB. It also provides sub-second latency for a certain class of queries using Druid. We are looking for exceptional talent with experience in Spark, Presto / Trino, Druid, Iceberg and distributed database systems in general. Roles in this team involve solving super interesting and challenging problems of working with data at scale, building features and performance enhancements and working closely with open source communities to shape the projects and make contributions.

Big Data Orchestration |Learn More
Offers the platform for scheduling, orchestrating and executing big data jobs and workflows in a self serve manner. These platforms include foundational services that host all ETL and ML workloads running on Big Data Systems at Netflix. These fully distributed systems are constantly evolving for Netflix scale with state of the art technology. We are moving towards event driven and intelligent orchestration which would need minimal user input/intervention.

This would be your dream job if you enjoy:
Solving real business needs at large scale by applying your software engineering and analytical problem-solving skills.
Architecting and building a robust, scalable, and highly available distributed infrastructure.
Leading cross-functional initiatives and collaborating with engineers, product managers, and TPM across teams.
Sharing our experiences with the open source communities and contributing to Netflix OSS.
About you:
You have 2+ years of experience in building large-scale distributed systems features or applications.
You are proficient in the design and development of RESTful web services.
Experienced in building and operating scalable, fault-tolerant, distributed systems
You are experienced in Java or other object-oriented programming languages.
Multi-threading is a challenge that you are comfortable tackling.
You have a BS in Computer Science or a related field.

A few more things about us:

As a team, we come from many different countries and our fields of education range from the humanities to engineering to computer science. Our team includes product managers, program managers, designers, full-stack developers, distributed systems engineers, and data scientists. Folks have the opportunity to wear different hats, should they choose to. We strongly believe this diversity has helped us build an inclusive and empathetic environment and look forward to adding your perspective to the mix!

At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.

The overall market range for roles in this area of Netflix is typically $100,000 - $700,000

This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Our culture is unique, and we tend to live by our values, so it’s worth learning more about Netflix here.

We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.",#N/A,5001 to 10000 Employees,Company - Public,Information Technology,Internet & Web Services,1997,$5 to $10 billion (USD)
"DMI
4.0",4.0,"Plano, TX",Data Engineer,"About DMI:
DMI is a leading global provider of digital services working at the intersection of public and private sectors. With broad capabilities across IT managed services, cybersecurity, cloud migration and application development, DMI provides on-site and remote support to clients within governments, healthcare, financial services, transportation, manufacturing, and other critical infrastructure sectors. DMI has grown to over 2,100+ employees globally and has been continually recognized as a Top Workplace in both regional and national categories.
About the Opportunity:
DMI is seeking a Data Engineer - Connected Technologies

Skilled in Business Intelligence/Data Warehouse, Data and Technical Architecture, Methodology, Architecture, Data Governance, Data Modeling, ETL Tools, Big Data, Data Lake. Strong expertise applying industry best practice methods and sound enterprise architecture, data architecture/ management, and integration techniques across domains.
Duties and Responsibilities:

End to End responsibility for data modeling (OLTP, OLAP)
Data analysis experience with writing complex queries, unions, joins and aggregations.
Data analysis experience using major RDBMS solutions like snowflake, redshift etc
Experience with ELT, ETL processes using glue, glue brew transformations.
Use airflow to schedule and time data transfers.
Understanding of deep JSON structures and partitioning using Kafka, spark, Scala, s3 etc.
Work with Data Scientist team to build segmentations, ML use cases, forecasting etc
Experience working with sagemaker, jupyter notebooks for deep data analysis.
Work with the BI specialists to design develop and enhance connectors to get closer to business use cases.
Migration of existing custom pipelines to a normalized connector approach
Help educate CT teams on data integration, validation standards and drive clean ingestion egestion patterns for the platform.
Qualifications:

Required and Desired Skills/Certifications:

Work with APIs to extract and ingest data.
Work with virtual warehouses and configure them for optimal performance and efficiency.
Conduct ETL data integration, cleansing transformations using glue spark script.
Work on aggregations of data coming from applications and apis to store results in a historic table.
Experience with streaming data analytics and building of streaming pipelines and connectors.
Experience with connections to BI solutions like tableau which include configurations of roles, policies within aws
Leverage Lambda, glue and step functions to cleanse and transform data.
Work with DWH technologies like EC2, s3, redshift, athena, snowflake to churn large data sets and partition them in readable formats and in real time
Location: Plano TX area preferred

#LI-SA1","$91,683 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,2002,$100 to $500 million (USD)
"Toyota
3.9",3.9,"Plano, TX",Principal Engineer 1 – Big Data Engineering,"Overview
Who we are
Collaborative. Respectful. A place to dream and do. These are just a few words that describe what life is like at Toyota. As one of the world’s most admired brands, Toyota is growing and leading the future of mobility through innovative, high-quality solutions designed to enhance lives and delight those we serve. We’re looking for diverse, talented team members who want to Dream. Do. Grow. with us.
This position is based in Plano, TX.
Toyota encourages all employees to live within a reasonable commuting distance of their assigned work location. Hybrid work from outside of the assigned work location may be permitted in a pre-approved list of states (AZ, CA, CO, GA, IL, IN, KY, MA, MI, MO, NJ, NY, OH, OR, TN, TX, VA, WV) with certain stipulations.
Speak with your recruiter and hiring manager to learn more about our hybrid work program.
To save time applying, Toyota does not offer sponsorship of job applicants for employment-based visas or any other work authorization for this position currently.
Who we’re looking for
Toyota’s Data and Analytics Department is looking for a passionate and highly motivated Big Data Engineer.
The primary responsibility of this role is to engineer a best-in-class enterprise Data Platform with cutting-edge technologies guided by principles of Agility, DevSec Ops, and continuous innovation. This is an individual contributor role that requires working with cross-functional teams across the company to ensure the Big Data platform is built for adoption with high standards of performance, and scalability while optimizing the cost and using emerging technologies in the Data universe.
Reporting to the Data Engineering Lead, the person in this role will support the Data and Analytics department's objective to enable data-driven decision-making in our journey towards creating mobility for all.
What you’ll be doing
Design and develop highly scalable and state-of-the-art Big Data solutions in AWS and GCP to enable advanced analytics capabilities in the company.
Design and Build scalable data infrastructures required for optimal extraction, transformation, and loading (ELT, ETL) of data from a wide variety of data sources using Big Data and Integration technologies
Develop data models and features required for data scientists to build data science models.
Perform design, feature, and code reviews to drive excellence in engineering and ensure high quality & maintainability
Support the build of analytics tools that utilize the data pipeline to provide actionable insights for business stakeholders, including data preparation for predictive and prescriptive modeling
Be current on latest industry developments and trends to help lead the development of system/process improvements
Collaborate with Product owners, Data Scientists, Platform Team, Business SMEs as well as different sub-groups within the Data organization to effectively lead data and analytics solutions
What you bring
Bachelor’s degree in information systems, Computer Science, or related discipline or equivalent work experience
5 years of demonstrated experience in developing Big Data solutions that support business analytics and data science teams
8 or more years of proficient experience developing data platforms, data warehouses, ETL/ELT pipelines, and programming in SQL, Python, Java, Scala-Spark, Bash, and other scripting languages
Strong knowledge and hands-on experience in Big Data technologies in Cloud such as AWS EMR, Apache Spark, Databricks, AWS Redshift, Snowflake, S3, GCP Big Query, Google Cloud Storage, and Google Data Proc
Competent with various batch & real-time streaming ingestion patterns with Sqoop, Kafka, Kinesis, GCP Pub/Sub
Proven knowledge in cloud engineering (Terraform, Cloud Formation) and provisioning Lambda, SNS, EC2, Airflow, Elastic Cache, Redis, and RESTful APIs in AWS
Experience with DevOps methodology and automation experience with Jenkins, Ansible, Chef, XL Release and XL Deploy
Strong written and verbal communication skills with the ability to create and present concepts, roadmaps, and recommendations to executive management.
Added bonus if you have
Master’s degree in Computer Science or related discipline
AWS/GCP cloud certifications
AWS/GCP Data Engineering certifications
Experience with Automobile and/or Manufacturing organizations
What we’ll bring
During your interview process, our team can fill you in on all the details of our industry-leading benefits and career development opportunities. A few highlights include:
A work environment built on teamwork, flexibility and respect
Professional growth and development programs to help advance your career, as well as tuition reimbursement
Vehicle purchase & lease programs
Comprehensive health care and wellness plans for your entire family
Flextime and virtual work options (if applicable)
Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute
Paid holidays and paid time off
Referral services related to prenatal services, adoption, childcare, schools and more
Flexible spending accounts
Belonging at Toyota
Our success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. Respect for all is our North Star. Toyota is proud to have 10+ different Business Partnering Groups across 100 different North American chapter locations that support team members’ efforts to dream, do and grow without questioning that they belong. As a company that has been one of DiversityInc’s Top 50 Companies for Diversity and a member of The Billion Dollar Roundtable supporting minority and woman-owned suppliers for over 10 years, we are proud to be an equal opportunity employer that celebrates the diversity of the communities where we live and do business.

Applicants for our positions are considered without regard to race, ethnicity, national origin, sex, sexual orientation, gender identity or expression, age, disability, religion, military or veteran status, or any other characteristics protected by law.
Have a question or need assistance with your application? Please send an email to talent.acquisition@toyota.com.","$138,489 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1957,$10+ billion (USD)
Buxton,#N/A,Remote,Data Engineer AI/ML W2 Contract,"Job Title: Senior Software Engineer, ML/AI
Location: Moline, IL (Remote)
Duration: 12+ Months W2 Contract
Position Overview:
We are seeking Senior Software Engineers to join our fully remote team, specializing in Artificial Intelligence (AI) and Machine Learning (ML) platforms. These positions play a crucial role in developing AI and ML solutions for Deere, focusing on data engineering, generative AI, data serving, and vector database (DB) technologies.
Key Responsibilities:
Data Engineering: Apply a deep understanding of data engineering principles, including data wrangling for structured and unstructured data, basic data feature analysis, and loading structured data into cloud storage or data lakes. Proficiency in handling unstructured data through cracking and chunking is essential.
Generative AI: Collaborate on AI models offered by OpenAI, leverage open-source foundation models, and apply knowledge of langchain to contribute to generative AI solutions.
Data Serving: Develop expertise in retrieval mechanisms that support RAG (other than ACS). Showcase innovative thinking in RAG, going beyond boilerplate examples to create unique solutions.
Vector Database (DB): Utilize intermediate knowledge of Vector DB and embeddings to optimize data storage and retrieval processes.
Jupyter Notebooks: Create and maintain Jupyter Notebooks to facilitate data analysis and experimentation.
Databricks and Pipeline Tools: Leverage Databricks or similar pipeline tools to streamline data processing workflows.
Skill Set Requirements:
Strong familiarity with Data Engineering concepts, including data wrangling, feature analysis, and structured data loading into cloud storage or data lakes.
In-depth knowledge of generative AI, including models by OpenAI, open-source foundation models, and langchain.
Experience with various data serving mechanisms, showcasing creative problem-solving skills.
Intermediate knowledge of Vector Database (DB) and embeddings.
Proficiency in creating and using Jupyter Notebooks.
Familiarity with Databricks or similar pipeline tools.
Skills that Set You Apart:
Python experience and expertise in backend AWS API engineering for REST services.
Experience with React and frontend engineering.
Knowledge of or experience with emerging benchmarking tools for RAG, whether open-source or vendor-specific.
Qualifications:
Bachelor's or higher degree in Computer Science or a related field.
Proven experience in AI/ML development and data engineering.
Strong problem-solving and critical-thinking abilities.
Excellent communication and collaboration skills, especially in remote team environments.
Job Type: Contract
Experience level:
7 years
Schedule:
Monday to Friday
Experience:
Data Engineering concepts: 6 years (Required)
AI: 3 years (Required)
ML: 2 years (Preferred)
Work Location: Remote",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Ascendion
4.3",4.3,"Dallas, TX",Lead Data engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next. Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role: Here we are having full time position with Ascendion
Key Responsibilities:
Must Haves:
SQL - very strong
Python
Hadoop Ecosystem (Hadoop, Hive, Python, ETL required)
Soft Skills:
Good communication skills
Team player
Ability to work in onshore / offshore model
Flexible to work and learn on new technologies
Location: 100% Remote
Salary Range: 115k to 125k pa
If you are interested you can share your updated resume on vanshika.tiwari@ascendion.com or else you can give me call directly on 3147105352
Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk



Preferred Skills:
Hadoop
hive
ETL
PYTHON
SQL
Job details
Job ID
328614
Job Requirements
Lead Data engineer
Location
Dallas, Texas, US
Recruiter
Vanshika
Email
vanshika.tiwari@ascendion.com
Phone
vanshika.tiwari","$120,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Nutrisystem, Inc.
3.1",3.1,"Fort Washington, PA",Sr. Data Engineer,"*Nutrisystem is on a hybrid schedule. We are in-office Tuesday-Thursday and remote on Monday and Friday each week*

Job Purpose:

The Enterprise Data Warehouse (EDW) is the corporate repository of integrated operational data. Nutrisystem is moving from on-premises management of it’s Data Warehouse and Business Intelligence to cloud Data Management and reporting. Working with EIS and offshore resources, this role will lead the development of the cloud DW while supporting the current DW environment.

Interaction with Others:

External Contact: This position will work with external data and system vendors to exploit cutting edge Data Management technologies and integrate/export data following Nutrisystem security guidelines.
Internal Contact: This position will have significant contact with
Offshore development resources
EIS physical IT resource management and Architecture staff
Internal business sponsors and subject matter experts.

Essential Job Responsibilities:

Working with IT and business resources, support the Data Warehouse strategy and Business Intelligence initiatives:
Lead development activities to migrate the current on-premises SQL Server DW to Snowflake on AWS.
Gather requirements for Data Warehouse improvements and translate them to high level design documents including Physical Data Models. Provide technical architecture vision and recommend strategy/solutions.
Design and develop transformation processes and data structures for the Data Warehouse following best practice procedures.
Lead resolution of Data Warehouse load issues.
Support the analytical needs of the business users. Build strong relationships to help identify opportunities to enhance the analytical capabilities of the Data Warehouse.
Partnering with business stakeholders and technical report developers, establish, maintain, and promote consistent methodology for reporting and analytics deployment. Perform ad hoc data analysis to meet business unit data validation needs.
Participate in Data Quality initiatives and lead the data transformation component design to improve and maintain high quality data. Support performance tuning.
Foster teamwork through cooperative interactions with co-workers. Where needed, ensure project integration by communicating activities and status to project manager, appropriate project team members, and business users.

Job Qualifications:

BS degree, preferably in Information Technology, Management Information Systems, Computer Science or similar discipline.
Post-college training in Data Management and vendor tool use
4-6+ years of Data Warehousing/ BI experience.
This role serves as the primary technical resource for managing and moving data in and out of the Data Warehouse. The candidate must:
Be well versed in Data Warehouse design concepts including Kimball and Inmon methodologies
Have hands-on experience with ETL and ELT methodologies and tools.
Have experience with SQL Server 2016 and SSIS.
Experience with business reporting requirements analysis.
Familiarity with Data Management and Business Intelligence tools, such as Business Objects, Microsoft Power BI, QlikSense, Tableau, Looker, AWS S3 and Redshift, or Snowflake.
Demonstrated ability to clearly communicate with all levels within an organization.
Have experience leading small or offshore development teams
understanding and experience with building and deploying Business Intelligence and analytics applications.
Familiarity with Financial, Sales, Marketing, and Logistics reporting environments.
Strong sense of leadership, strong analytical skills, excellent communication. Have expert skills and good technical abilities.

Preferred candidates will have experience with:

SSAS.
Analytics design and development is preferred.
Hands on development experience with .Net and/or Java is a plus.
Comfortable working in a fast-paced team. Capable of grasping new concepts quickly and acting with a sense of urgency.

Preferred candidate may have certifications like:

CBIP (Certified Business Intelligence Professional)
CDMP (Certified Data Management Professional)
Vendor-specific certifications","$108,219 /yr (est.)",201 to 500 Employees,Company - Private,Retail & Wholesale,Drug & Health Stores,1971,Unknown / Non-Applicable
"MX Technologies Inc.
3.7",3.7,"Lehi, UT","Senior Software Engineer, Investment Data","Life at MX

We are driven by our moral imperative to advance mankind - and it all starts with our people, product and purpose. We always carry a deep sense of drive and passion with us. If you thrive in a challenging work environment, surrounded by incredible team members who will help you grow, MX is the right place for you.

Come build with us and be part of an award-winning company that’s helping create meaningful and lasting change in the financial industry.
MX makes financial data accessible and actionable for everyone. Our mission is to empower the world to be financially strong. We do this by building the largest open finance ecosystem to help drive innovation and improve experiences through secure and reliable access to financial data. The MX ecosystem connects more than 13,000 financial institutions and FinTechs with a combined reach of more than 200 million consumers.
MX provides the most trusted and reliable open finance APIs to unlock the value of financial data.
Our current offerings are focused on:
Connectivity: Securely connecting to and verifying consumer financial data.
Data: Making financial data actionable with context, cleansing, and categorization.
Experience: Delivering personalized digital and mobile money experiences that drive growth
Job Summary
Our software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with their finances. Our products need to handle data on a massive scale. You’ll work alongside the best and the brightest engineering talent in the industry. We have opportunities in a wide range of areas including development, design, search, platform, test, quality, big data, front end, and back end. As a core participant of your team, you’ll estimate engineering efforts, design your changes, implement and test your changes, push to live, and triage production issues. You need to be dynamic, collaborative, and curious as we build new experiences, improve existing products, and develop distributed systems powering the world to be financially strong
We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full stack as we continue to push technology forward. With your technical expertise, you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.
Job Duties
Write product or system development code.
Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies.
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
Enforce clean code and excellent coding practices by conducting thoughtful code reviews
Help us build and maintain a world-class technology system so we can achieve our mission of making the world financially strong
Collaborate closely with Product Managers to meet and exceed customer needs in the simplest possible ways
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
Triage product or system issues and debug/track/resolve them by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.
Actively participate in system architecture discussions and technical design reviews to ensure the scalability, reliability, and security
You will lead by example, and elevate the design, implementation, quality, and strong engineering practices across the team
Drive projects and initiatives to implement high-quality systems and products
Influence, coach, and support engineers on the team, with a strong focus on feedback and growth.
Basic Job Requirements
Bachelor’s Degree or equivalent experience
3-5 years of experience with software development in one or more object-oriented programming languages (such as Ruby & Python, Javascript) with data structures or algorithms and Agile Scrum framework
3 years of experience testing, maintaining, or launching software products
1 year of experience with software design and architecture.
Advanced Job Requirements (not required)
Master's Degree or Ph.D. in Computer Science or related technical fields
Work Environment
At MX, we prioritize flexible working arrangements, which allow us to attract top talent, provide improved work-life balance, and increase productivity. Our flex philosophy is centered on trust, responsibility, and communication. Our team members enjoy a balance of remote work and monthly in-person collaboration meetings. Travel expectations are about 15%, and the company covers travel expenses for remote employees. Local employees are encouraged to utilize in-office time on a weekly basis. Both local and remote employees can take advantage of our incredible office space with onsite perks like company-paid meals, onsite massage therapist, golf simulator, and meditation room to name a few.
Compensation
The expected on-target earnings (OTE), which is comprised of a base salary and other forms of cash compensation, such as bonus or commissions is currently $113,500 - $136,000. This pay range is just one component of MX's total rewards package. MX takes a number of factors into account when determining individual starting pay, including job and level they are hired into, location, skillset, and peer compensation.

MX is proudly committed to recruiting and retaining a diverse and inclusive workforce. As an Equal Opportunity Employer, we never discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, military or veteran status, status as an individual with a disability, or other applicable legally protected characteristics. We particularly welcome applications from veterans and military spouses. All your information will be kept confidential according to EEO guidelines. You may request reasonable accommodations by sending an email to hr@mx.com.",#N/A,501 to 1000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2010,Unknown / Non-Applicable
"Swisher International
3.8",3.8,"Jacksonville, FL",DATA PLATFORM ENGINEER,"Swisher is a leading lifestyle brand for adult consumers headquartered in Jacksonville, Florida. Our superior customer relationships, innovative thinking, and action have driven the company to grow and adapt for 160 years. The legendary company we are today is a result of our unrelenting drive to shape the experiences of tomorrow.
As we shape the future, we are looking for people to continue to build on our history of pushing boundaries, shattering expectations, and evolving to solidify connections with adult consumers. In pursuing our mission, we require a passionate team of diverse backgrounds, viewpoints, and ideas. Our strong brand heritage provides our employees with challenging and rewarding careers, along with real growth opportunities.
Position Overview
As the Data Platform Engineer, you will be responsible for designing, building, testing, and maintaining cloud-native data pipelines to support various analytics algorithms. You will optimize systems for data collection, storage, access, and analytics. You will create data pipelines that convert raw data into formats that are available and accessible to stakeholders.
The Role

Develop and maintain databases by acquiring data from primary and secondary sources and build scripts that will make our data evaluation process more flexible or scalable across data sets.
Design, build, and manage data pipelines to support data and analytics needs in the organization.
Implement data warehousing solutions using a range of methodologies including – but not limited to – Inmon, Kimball, and Medallion methodologies.
Utilize Azure Databricks and Azure Synapse to manage and transform data
Utilize SQL databases, understanding the best cases for their use and how to optimize performance.
Facilitate the inclusion of multiple disparate data sources located in the data platform/data warehouse into the overall reporting framework.
Collaborate with Principal Solutions Architects to ensure the data platform design/process is optimally aligned with overall architecture to enhance the ‘end-user experience.’
Collaborate on project teams, systems and data analysis, design, development, integration, and enhancement activities, as well as related maintenance and more complex production support
Assist in the development of project scopes for multiple complex projects in collaboration with the project team and serves as a project point of contact when necessary
Provide architectural ownership, governance control, and solution management across all reporting initiatives.
The Experience Needed

5 Years experience as a Data Engineer or similar role.
Experience designing, building, and maintaining efficient, reusable, and reliable data marts using Microsoft SQL Server and Azure.
Experience with data and analytics experts to strive for greater functionality in our data systems.
Experience developing and implementing data standards, protocols, and procedures for effective data management and quality.
Experience monitoring data performance and modifying infrastructure requirements
Experience with data pipeline and workflow management tools
Ability to build effective partnerships with coworkers and coordinate overall efforts to contribute to the team, department, and organizational objectives
Knowledge of understanding and implementing security and data privacy settings and standards
Ability to optimize data delivery and re-design infrastructure for greater scalability
Ability to with data scientists and architects on multiple, concurrent projects
Strong analytical skills and problem-solving aptitude
High School diploma or equivalent
The Preferred Experience
Bachelor's Degree required in Computer Science, Information Systems, or related field
Working industry experience with Big Data systems and projects
Experience in building large-scale distributed systems in a product environment
Experience in writing, analyzing, and debugging SQL queries
Experience in data privacy and security-related projects
Certification in one or more of the following:
Generative AI,
Project Leadership &
IT Strategy
Data Engineering Foundations
Statistics Foundations
What we offer
Great benefits package, including a full suite of health benefits, a generous 401(k) Plan, paid parental leave, a strong rewards and recognition program, and a focus on mental health and well-being.
An inclusive environment with Employee Resource Groups to join and volunteer opportunities.
A Hybrid work schedule.
Professional growth and development programs to help advance your career.
Challenging environment with big goals and the opportunity to make a significant impact.
#MON","$99,309 /yr (est.)",501 to 1000 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1861,$1 to $5 billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Wilmington, DE",Big Data AWS Software Engineer III,"JOB DESCRIPTION

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.
As a Big Data AWS Software Engineer III with Cloud Migration at JPMorgan Chase, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job responsibilities
Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems
Produces architecture and design artifacts for complex applications while being accountable for ensuring design constraints are met by software code development
Gathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems
Proactively identifies hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture
Contributes to software engineering communities of practice and events that explore new and emerging technologies
Adds to team culture of diversity, equity, inclusion, and respect
Required qualifications, capabilities, and skills
Formal training, or certification on software engineering concepts and 3+ years applied experience
Proficient in coding in one or more languages (Scala, Spark, Python)
Strong experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages (Big Data toolset - Hadoop, Hive, Impala, Hbase)
Strong experience in scripting and comfortable working in Linux/UNIX environments.
Overall knowledge of the Software Development Life Cycle
Solid understanding of agile methodologies such as CI/CD (Jenkins/Maven), Applicant Resiliency, and Security
Demonstrated knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)
Preferred qualifications, capabilities, and skills
Exposure to AWS/cloud technologies and AWS certifications are preferred.
Experience in using version controls systems such as GIT/Bit Bucket, agility tools such as Jira/Confluence, and infrastructure as code tools such as Terraform.
Experience in using Job scheduling tools such as Control-M, Autosys, Airflow.
Knowledge in building and maintaining app support/monitoring tools/dashboards such as Kibana, Elastic Stack, Grafana, DataDog, AWS cloud watch etc.
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our professionals in our Corporate Functions cover a diverse range of areas from finance and risk to human resources and marketing. Our corporate teams are an essential part of our company, ensuring that we’re setting our businesses, clients, customers and employees up for success.","$107,965 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Johnson & Johnson
4.2",4.2,"Cincinnati, OH",Assistant/Associate Data Science Engineer,"At Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. Our Corporate, Consumer Health, Medical Devices, and Pharmaceutical teams leverage data, real-world insights, and creative minds to make life-changing healthcare products and medicines. We're disrupting outdated healthcare ecosystems and infusing them with transformative ideas to help people thrive throughout every stage of their lives. With a reach of more than a billion people every day, there’s no limit to the impact you can make here. Are you ready to reimagine healthcare?
Here, your career breakthroughs will change the future of health, in all the best ways. And you’ll change, too. You’ll be inspired, and you’ll inspire people across the world to change how they care for themselves and those they love. Amplify your impact. Join us!
ETHICON, part of the Johnson & Johnson Family of Companies, is recruiting new college graduates for Data Science in Cincinnati, OH. This position offers exposure to projects across the R&D organization, focusing on both data and engineering principles as tools to transform the landscape of surgery. Are you ready for challenging data science and engineering roles, delivering tomorrow’s surgical innovations?
At Johnson & Johnson, we use technology and the power of teamwork to discover new ways to prevent and overcome the world’s the most significant healthcare challenges. In particular, the ETHICON business in Cincinnati, OH offers a broad range of products, platforms, and technologies—including surgical staplers, advanced energy devices, robotic surgery, capital equipment, and advanced visualization systems. Our innovations are used in a wide variety of minimally invasive and open surgical procedures in specialties including colorectal, thoracic, women’s health, cancer, and obesity treatment. Our Cincinnati site was founded 30 years ago and has developed innovative devices that have driven ground-breaking shifts in modern surgery!
As an Assistance/Associate Engineer in a Data Science position you will:
Contribute to Data Science, Machine Learning, Data Engineering, and Software Development for R&D, supporting the development of innovative medical devices and digital health technologies.
Have a strong support network of seasoned data scientists, engineers, and mentors guiding your technical and career development.
Leverage powerful tools and fundamental principles of engineering and data science to contribute to engineering solutions in a dynamic, team-focused environment.
Collaborate with external partners and across Johnson and Johnson to identify and implement project solutions.
Continue your technical growth and development through training in anatomy, statistics, data modeling, signal processing, cloud tools, and software development practices.
Qualifications
Candidate must be a new college graduate, graduating no more than 12 months prior to their 2024 start date, with a Bachelor’s, Master’s, or PhD in Computer Science, Data Science, Statistics, Mechanical Engineering, Electrical Engineering, Biomedical Engineering, or a related field.
Possess previous co-op, internship or work experience and proven leadership/participation in campus programs and/or community service activities.
Demonstrate past experience with several data analysis and data science tools and techniques, such as, but not limited to: Python, Pandas, R Shiny, SQL, Tableau, Machine Learning, Regression, Signal Processing, and Git.
Ability to work in a regulated environment
Must be permanently authorized to work in the United States and not require sponsorship now or in the future . (ie. H1B Visa status)
Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.","$92,898 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1887,$10+ billion (USD)
"Equinix
4.2",4.2,"Frisco, TX",Data Center - Critical Facilities Engineer,"Data Center - Critical Facilities Engineer
Critical Facilities Engineer
Equinix is the world’s digital infrastructure company, operating in 240+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, sophisticated infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.
We are a fast-growing global company with 80 consecutive quarters of growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of 10,000+ companies, including 2,000+ networks and 3,000 cloud and IT service providers in 31 countries spanning six continents! We embrace diversity in thought and contribution and are committed to providing an equitable work environment that is foundational to our core values as a company and is vital to our success.
Do you want to be at the forefront of maintaining critical facilities infrastructure? Would you enjoy being part of a close-knit team delivering outstanding service to our data center customers? Then read about the role and requirements for an Equinix Critical Facilities Engineer!
Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, and public safety centers. Simply put - We cannot go dark. In this crucial role, a Critical Facilities Engineer:
Performs specialized installations and preventative and corrective maintenance on-site to critical facility components and systems.
Performs specialized site logs and data gathering for issuing permits.
Supervises the Building Monitoring System (BMS) and resolves alarms.
Makes recommendations for solutions and understands the implications of work.
Performs sophisticated equipment maintenance with problem-solving and repairs to avoid/minimize downtime.
Performs Root Cause Analysis (RCA).
Identifies Single Points of Failure (SPOFs).
May recommend infrastructure projects, including energy efficiency measures.
Coordinates and advises vendors to ensure maintenance activities are carried out per standards and requirements.
Assists with the creation and submission of scripts for maintenance.
Tracks and implements the work approval process for service providers for critical maintenance.
Responsibilities in facility and infrastructure maintenance include performing checks, repairs, installations, and preventative and corrective maintenance on-site to facility components. Supervise and resolve Building Monitoring System (BMS) alarm issues. Operate and maintain plumbing, fire suppression, and safety systems.
Supports the work approval process for vendors/service providers on maintenance work by ensuring vendor maintenance activities are carried out as per Equinix's standard operating procedures. Cooperate with vendors in modifying technical files for plants and equipment ensuring files and builds are up-to-date.
Site administration and incident support responsibilities include performing site logs for permits. Identify Single Points of Failure (SPOFs) and make recommendations. Respond to all on-site incidents, including failures, problems, and delays. Display a substantial understanding of operating procedures to support on-site administration.
Completes routine work requests and maintains office equipment; supports auxiliary equipment and machines with problem-solving and repairs to avoid/minimize downtime. Makes minor changes to mechanical, electrical, and specialized systems. Carries out infrastructure projects.
Collaborates with others to resolve moderately sophisticated facility incidents. Optimally collaborates within the department; mentors team members on general maintenance activities. Notifies team members of inventory needs to maintain efficient stock levels of critical parts and equipment. Recommend infrastructure projects, process improvements, and energy-saving tactics.
Qualifications
4+ years of commercial MEP (mechanical/HVAC/electrician) experience
High School Diploma
A natural curiosity and strong troubleshooting skills
Experience working in a critical facility
Able to perform crucial job functions, including walking, standing, bending, stooping, climbing, lifting, and manual dexterity, with or without reasonable accommodation.
You are available to work days/nights/weekends/holidays if needed and required.
Can lift heavy equipment/items up to 50 pounds
Locations:
Ashburn, VA, Silicon Valley, Seattle, Chicago, Dallas, Secacus, NJ
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you need assistance in applying for an open position, send an email to Staffing @ equinix.com. Please provide your contact information and let us know how we can assist you.
Equinix is an equal-opportunity employer. All applicants will receive consideration for employment regardless of race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, or a qualified individual with a disability.

***U.S. ONLY - EOE/M/F/Vet/Disability
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $78,000 to $124,000 • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $72,000 to $114,000 • Colorado, Nevada, Rhode Island: $65,000 to $103,000 Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $78,000 to $124,000 • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $72,000 to $114,000 • Colorado, Nevada, Rhode Island: $65,000 to $103,000 Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $89,000 to $142,000 • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $82,000 to $130,000 • Colorado, Nevada, Rhode Island: $74,000 to $118,000 Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.
The targeted pay range for this position in the following location is / locations are: • San Francisco, CA / Bay Area: $89,000 to $142,000 • California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $82,000 to $130,000 • Colorado, Nevada, Rhode Island: $74,000 to $118,000 Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training. This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process. The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position. As an employee, you become important to Equinix’s success. Details about our company benefits can be found at the following link: USA Benefits eBook",#N/A,10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1998,$1 to $5 billion (USD)
"R1 RCM, Inc.
3.4",3.4,Remote,Data Quality Engineer,"We are seeking an experienced Data Quality Analyst (QA position)
Qualifications:
Must have ETL Experience
Must have SQL
Must have Python experience
Manual testing
Nice to have Experience with Apache Spark
Generic skills like Bug reporting, JIRA, Agile methodologies
Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests.

Our associates are given valuable opportunities to contribute, to innovate and create meaningful work that makes an impact in the communities we serve around the world. We also offer a culture of excellence that drives customer success and improves patient care. We believe in giving back to the community and offer a competitive benefits package including:
Comprehensive Medical, Dental, Vision & RX Coverage
Paid Time Off, Volunteer Time & Holidays
401K with Company Match
Company-Paid Life Insurance, Short-Term Disability & Long-Term Disability
Tuition Reimbursement
Parental Leave
R1 RCM Inc. (“the Company”) is dedicated to the fundamentals of equal employment opportunity. The Company’s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person’s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.
If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.
CA PRIVACY NOTICE: California resident job applicants can learn more about their privacy rights California Consent",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2003,Unknown / Non-Applicable
"Meta
3.9",3.9,"Menlo Park, CA",Data Center Network Engineer,"The scale of the network and its continuous expansion presents an opportunity to work on and solve interesting engineering challenges in the datacenter network domain. We constantly push the boundaries of what is possible. We create new and innovative ways of designing and operating our global datacenter networks and do it at scale with efficiency. We imagine what our tomorrow is going to be and make it a reality.Data Center Network Engineers at Meta are hybrid software and network engineers who design, build, and operate our worldwide Data Center network. This team owns the complete lifecycle of the Data Center network, which includes areas of planning, design, product definition, QA, deployment, and monitoring. Simple, elegant, and scalable network design, automation, and data analytics are the keys to meeting our demands. In this role, you will be part of a team that is responsible for conceiving design solutions, developing and deploying network software, systems, and tools that keep the Data Center network operating at maximum reliability, scalability, and efficiency.


Data Center Network Engineer Responsibilities:
Design network topologies and configuration for the DC Fabric networks
Develop IP addressing and routing policy intent in the DC
Create deployment packages and maintain as-built documentation for installed network gear
Establish and implement global best practices and contribute to the design of new scalable network solutions
Define and partner with network hardware, software, and vendor teams on the development of network platforms (switch and optics)
Partner with the in-house SWE, Tooling, Planning, Simulation, and Delivery teams to codify the network designs
Participate in an on-call rotation to support the global datacenter network infrastructure 24x7
10% of travel required



Minimum Qualifications:
5+ years of work experience responsible for designing, deploying and operating large-scale networks
Experience configuring and troubleshooting routing and switching protocols (BGP, IS-IS, OSPF, MPLS, RSVP-TE)
Working knowledge of network protocols (TCP/UDP, DHCP, DNS) and experience with IPv4 and IPv6
Experience working in a multi-vendor environment with hands-on experience with networking hardware
Experience in at least one programming language like Python, Go, C/C++ for developing automation software or tooling
Working knowledge of physical infrastructure design including structured cabling and fiber-optic cabling
Experience managing multiple projects simultaneously and deliver against deadlines
Experience working in global team environments and solve problems
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.



Preferred Qualifications:
Working knowledge of 40/100/400G Ethernet and CWDM, DWDM and optical transport network technologies
Understanding of different Optics and internals of a switch ASIC
Familiarity with the Linux based systems
Technical leadership experience



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$173,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Providence
3.6",3.6,Washington State,Senior Software Engineer - Data,"Description
Senior Software Engineer, Data - Enterprise Information Services - Location: WA or OR *hybrid
How would you like to pursue your passion for healthcare, social causes, and software development in a job that stimulates your brain and tugs at your heart? Our team at Providence is looking for a senior software engineer who can help us do data right to allow us to move quickly to accelerate our modern data architecture ambition. We have software engineers from Microsoft, Amazon, and other tech companies who work with the singular purpose of fulfilling our vision of Health for a Better World. Our work is not easy - healthcare is not easy, but we are having fun and are committed to our mission. If you think you have what it takes to have an impact on real lives, we want to talk to you.
The Senior Software Engineer builds modern data-centric solutions to support HR and operational processes across all parts of the healthcare system. Builds data pipelines and transformations, data enrichment processes and data visualizations to meet the requirements of key initiatives. Enjoys fast pace and has a focus on regular delivery. Uses emerging methods & tools to find data-driven solutions for complex problems and contributes to research and development of new technologies. Be an active participant in code reviews, support the code base, and help establish standard processes and frameworks.
Required qualifications:
Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
5 years related experience.
Extensive experience with object-oriented programming in C#, Java, Python or equivalent.
Experience with source code control systems such as Git.
SQL integration development experience with SQL/NoSQL.
Experience with Agile software development methodologies and tools such as Azure Devops, TFS, and Jira.
Proven track record of working both independently and collaboratively as part of a multi-disciplined team.
Experience designing and successfully implementing a large project.
Preferred qualifications:
Strong skill in understanding database architecture, data models and writing complex SQL queries/code.
Hands on experience in Azure Cloud components such as Azure Databricks, Azure Data Factory, Azure Logic apps and Azure Devops.
Experience with database query and analysis languages (e.g. SQL, R, SAS, Python).
Experience in data visualization tools (e.g. Power bi,Tableau) and ability to transform raw data into relevant insights.
Ability to work with large volume of data sets in performing data ingestion, loading, transformation and aggregation.
Data Analytics experience in a healthcare environment.
Salary Range by location: *hourly listed – position is salaried
WA Puget Sound Oregon (Portland) Alaska (Anchorage) Min: $52.84, Max: $89.98
Oregon (Hood River, Medford, Seaside) Min: $49.26, Max: $83.88
Eastern Washington (Richland, Spokane, Walla Walla) Min: $47.02, Max: $80.06
Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities.
About Providence
At Providence, our strength lies in Our Promise of “Know me, care for me, ease my way.” Working at our family of organizations means that regardless of your role, we’ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable.
The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.
Check out our benefits page for more information about our Benefits and Rewards.
About the Team
Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.
We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment.
We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business.
We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment.
Requsition ID: 220342
Company: Providence Jobs
Job Category: Development/Engineering
Job Function: Information Technology
Job Schedule: Full time
Job Shift: Day
Career Track: Business Professional
Department: 4011 SS IS AT DATA PROCSNG
Address: WA Redmond 17425 NE Union Hill Rd
Work Location: Redmond Junction At Bear Creek
Pay Range: $see posting - $see posting
The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.
Check out our benefits page for more information about our Benefits and Rewards.
Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",#N/A,10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1855,$100 to $500 million (USD)
"Hermitage Infotech
3.5",3.5,New Jersey,Sr. Data Engineer,"Hi,

Given below is the urgent req for my client.. If you are comfortable with it, available and looking for a project please send me your profile immediately in word document along with your expected hourly salary on CTC/1099 or yearly salary on W2. Please mention your work authorization and your availability to start the project.
Looking for candidates regarding the following:

POSITION

Sr Data Engineer

LOCATION

Remote

DURATION

4 Months

PAY RATE

Please mention your minimum expected salary on our W2.

INTERVIEW TYPE

Video

VISA RESTRICTIONS

USC/GC/EAD Only

REQUIRED SKILLS

3+ years of data engineering experience
Snowflake database experience
Postgres
ETL-specifically DBT for transformation workflow
Python, Tableau




Regards
Varma
732-338-7524",#N/A,1 to 50 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,$1 to $5 million (USD)
"Procter & Gamble
4.1",4.1,"Phoenix, AZ",Data Analytics Engineer,"Job Location
Cincinnati
Job Description
If data is in your blood, then we have the job to get your heart pumping!
From day 1, you'll be a key member of the engineering team driving end-to-end data and analytical solutions supporting the development, learning, and operational insights for our critical new engineering led initiatives in equipment, process, packaging, customization and supply chain.
As a Data Analysis Engineer, you will:
Work across important Data & Analytics Community of Excellence capability areas of: Data Science, Dana Engineering, Data Wrangling, Edge Programming, SME Analyst/Business Intelligence, Visualization/Citizen Scientist Ux.
Engage project teams to understand project needs/requirements and provide technical expertise with data and analytical tools.
Collaborate with data leaders and multi-discipline teams to design, develop and ensure critical data systems infrastructures and integration offer critical data model availability and scalability.
Ensure relevant data and analytics are available to meet initiatives and technical readiness needs by continuously addressing the data models, wrangling and cleansing data, and improving data solutions and platforms.
Explore emerging capabilities and Artificial Intelligence/Machine Learning for flawless integration and application between data scientist, functional specialists and their key user cases.
We believe the following skills will help you be successful:
Technical Mastery: Strategic, systems problem solver who will automate existing manual decision support and data workflows to drive key innovation and business performance improvement.
Builds Diverse and Collaborative Relationships: We seek an independent, collaborator who sees the interaction in our enterprise and systems while understanding the role that data and intelligence play in dramatically improving the user cases for the subject matter systems.
Leadership: Have the ability to set technical direction by applying and building mastery in our Product Supply Engineering innovation and delivery efforts, while demonstrating diverse data, analytics and visualization skills. Seeking immediate impact to accelerate our engineering processes, improve technical readiness of initiatives and enhance product and service execution in our manufacturing sites and supply network.
We offer you:
Dynamic and respectful work environment. At P&G our employees are at the core, we value every individual and encourage initiatives, promoting agility and work/life balance.
Continuous coaching. You will work with passionate people and receive ongoing coaching and mentoring from your line manager and other colleagues. Corporate and functional training will enable you to succeed and develop from day one.
Benefits. You will receive a competitive salary as well as other great benefits including a competitive pension, share ownership scheme and private healthcare.
Are you ready to join our Engineering team?
Job Qualifications
REQUIRED:
BS/MS in a quantitative field (Engineering, Data Science, Operations Research, Applied Math, Statistics, Analytics)
These positions are entry-level with up to 4 years work experience
PREFERRED EXPERIENCE:
Data management, ingesting new data, transforming/harmonizing data
Data analytics insights and work processes for learning and decision
support
Strong leadership, business problem definition, and priority setting skills
Prior Innovation Development, or Supply Chain, or IoT or related experience
An aptitude for communicating insights and collaborating across teams/organizations
Skills in data visualization (Tableau, Power BI, or similar) and script program languages (SQL, Python/Scala, R, JAVA, C+)
Data analytics and insight environments (Apache Hadoop, Spark, Hive, SQL Server, SAP Bus, WH)
Passion to learn/develop and bring in emerging trends/technology that drive further insight value
Proven success of applied analytics through related full-time or internship experience
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Job Schedule
Full time
Job Number
R000084077
Job Segmentation
Recent Grads/Entry Level (Job Segmentation)
Starting Pay / Salary Range
$85,000.00 - $115,000.00 / year","$100,000 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1837,$10+ billion (USD)
"M&T Bank
3.7",3.7,"Buffalo, NY",Senior Network Engineer (Data Center),"This role offers a hybrid work schedule; offering the flexibility to work remotely two days a week, while providing the opportunity for in-person collaboration at our Buffalo, NY Tech Hub.
Overview:
As a Data Center Engineer at M&T Bank, you will play a pivotal role in the maintenance, optimization, and expansion of our data center infrastructure. You will be responsible for ensuring the reliability, performance, and security of our data center operations, with a focus on Arista and Cisco networking technologies.
Primary Responsibilities:
Network Infrastructure Management: Configure, monitor, and maintain Arista and Cisco network devices to ensure high availability and performance within the data center.
Data Center Operations: Perform routine data center tasks such as equipment installations, cabling, and hardware replacements while adhering to industry best practices.
Network Security: Implement and maintain security measures to protect data center assets and ensure compliance with security policies.
Troubleshooting: Identify and resolve network and system-related issues promptly to minimize downtime and disruptions.
Capacity Planning: Collaborate with cross-functional teams to assess data center capacity requirements and plan for future expansion.
Documentation: Maintain accurate records and documentation of network configurations, changes, and procedures.
Team Player: Collaborate with peers and cross-functional colleagues to deliver results for both large and small projects.
Education and Experience Required:
Combined minimum of 8 years’ higher education and/or work experience in systems design, management and/or architecture
Strong understanding of the system development and infrastructure lifecycle and architecture, vendor best practices, IT Service Management, and systems design
Education and Experience Preferred:
Bachelor’s Degree in Computer Science or Computer Engineering
Minimum of 8 years’ professional experience in a technical engineering position involving infrastructure design technologies, data management and interchange, system design and/or development for complex applications
#LI-KB1
M&T Bank is committed to fair, competitive, and market-informed pay for our employees. The pay range for this position is $107,412.63 - $179,021.06 Annual (USD). The successful candidate’s particular combination of knowledge, skills, and experience will inform their specific compensation.
Location:
Buffalo, New York, United States of America",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1856,$5 to $10 billion (USD)
"Oracle
3.9",3.9,United States,Principal Data Center Engineer,"You are the builder here. You will be part of a team of really smart, motivated, and diverse people and given the autonomy and support to do your best work. It is a dynamic and flexible workplace where you’ll belong and be encouraged.
As a Principle Data Center Engineer you will contribute to multi-disciplinary projects using your engineering expertise. This includes identifying risks and serviceability issues related to physical hardware design, participating in the full hardware development lifecycle and using data and business intelligence to drive improvements to efficiency and quality of Oracle and OCIs physical infrastructure.

In this role you will join an exciting and highly motivated team at Oracle. We are at the forefront of innovating the data center industry, and as a key member of our engineering team, you will play a pivotal role in creating and implementing Digital Twin models of Data Centers. Using advanced techniques like Computational Fluid Dynamics (CFD), you will collaborate closely with our data center design and construction teams as well as internal and external stakeholders, helping to design and efficiently operate OCI and Oracle data centers.
Key Responsibilities
Digital Twin Creation & Implementation: Design and create Digital Twin models of Oracle Data Centers, leveraging the latest tools and technologies to ensure accurate simulations and predictions.
Computational Fluid Dynamics (CFD) Analysis: Utilize CFD to analyze airflow, temperature, and environmental conditions within the data center environment, providing recommendations for optimal performance and efficiency.
Customer Collaboration: Work closely with customer facing internal stakeholders to understand their specific needs and challenges, translating those requirements into actionable data center designs and solutions.
Continuous Improvement: Stay updated with the latest advancements in data center technology and methodologies, ensuring our offerings remain cutting-edge.
Team Collaboration: Collaborate with cross-functional teams including sales, product management, and other engineering teams to deliver cohesive solutions.
Problem-Solving: Troubleshoot and resolve any issues related to data center design, implementation, and operation.
Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. Leading contributor individually and as a team member, providing direction and mentoring to others. BS or MS degree or equivalent experience relevant to functional area. 6-10 years of engineering or related experience.

Digital Twin Creation & Implementation: Design and create Digital Twin models of Data Centers, leveraging the latest tools and technologies to ensure accurate simulations and predictions.
Computational Fluid Dynamics (CFD) Analysis: Utilize CFD to analyze airflow, temperature, and environmental conditions within the data center environment, providing recommendations for optimal performance and efficiency.
Customer Collaboration: Work closely with customer facing internal stakeholders to understand their specific needs and challenges, translating those requirements into actionable data center designs and solutions.
Continuous Improvement: Stay updated with the latest advancements in data center technology and methodologies, ensuring our offerings remain cutting-edge.
Team Collaboration: Collaborate with cross-functional teams including sales, product management, and other engineering teams to deliver cohesive solutions.
Problem-Solving: Troubleshoot and resolve any issues related to data center design, implementation, and operation.",#N/A,10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1977,$10+ billion (USD)
"Nike
4.2",4.2,"Beaverton, OR",Principal Data Engineer,"Become a Part of the NIKE, Inc. Team

\r

\r

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

Principal Data Engineer-Nike, Inc., Beaverton, OR. Provide cross-domain data engineering expertise that empowers and accelerates Nike's digital transformation. Provide expert-level guidance on the most complex coding, configuration and implementation efforts. Provide leadership, guidance and mentorship to other data engineers. Define the technical design and implementation roadmap across multiple solutions and work with engineering leadership. Design and implement innovative product features in collaboration with business and technology partners. Collaborate with and across data engineering teams on designs and implementation details for distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Research, evaluate, and utilize new technologies, tools, and frameworks centered around high-volume data processing. Innovate to address both current and future customer needs. Inform and influence both technical and business partners on technical strategies and approaches using clear, concise, fact- and experience-based information. Define, design, and build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Create strategies for building or improvement of continuous integration, test-driven development and production deployment frameworks. Define and establish standard methodologies. Anticipate, identify, and solve issues concerning data management to improve data quality. Address operational and performance issues and technical bottlenecks as needed. Solve high-risk issues and perform root cause analysis.

Applicant must have a Master's degree in Computer Science, Engineering, or Computer Engineering and 2 years of experience in the job offered or a computer-related occupation. Experience must include:
Spark;
Kafka;
Web services;
Rest;
Splunk;
Jenkins;
AWS;
Airflow;
Python;
RDS; and
NoSql Database.

#LI-DNI

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

How We Hire

At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.

This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.

Benefits

Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$145,632 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Dallas, TX",Data Engineer,"3+ years of data engineering experience
Experience with data modeling, warehousing and building ETL pipelines
Experience with SQL
Are you passionate about data and code? Does the prospect of dealing with massive volumes of data excite you? Do you want to build data engineering solutions that process billions of records? Do you want to create the next-generation of product for self-service data transformation? If so, Amazon Finance Technology (FinTech) is for you!

Amazon's Finance Technology team is seeking a Data Engineer to join the team that is shaping the future of the finance data platform. The technology solutions and services we build enable Amazon’s rapidly growing and dynamic business, and have an immediate influence on day-to-day decision making through automation, compliance with law and analysis of our financial data. We aim to provide Amazon competitive advantage for running its business and insights for our customers using state of the art technologies. This is an opportunity to work on building one of the largest finance data platforms in the world. If you are passionate about building petabytes scale data solution on AWS using modern techniques in big data space at scale to drive innovation in the finance space, this is the team for you.

As a Data Engineer, you should be an expert with data warehousing technical components (e.g. Data Modeling, ETL and Reporting), infrastructure (e.g. hardware and software) and their integration. You should have deep understanding of the architecture for enterprise level data warehouse solutions using multiple platforms (RDBMS, Columnar, Cloud). You should be an expert in the design, creation, management, and business use of large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. The candidate is expected to be able to build efficient, flexible, extensible, and scalable ETL and reporting solutions. You should be enthusiastic about learning new technologies and be able to implement solutions using them to provide new functionality to the users or to scale the existing platform. Excellent written and verbal communication skills are required as the person will work very closely with diverse teams. Having strong analytical skills is a plus. Above all, you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.

Our ideal candidate thrives in a fast-paced environment, relishes working with large transactional volumes and big data, enjoys the challenge of highly complex business contexts (that are typically being defined in real-time), and, above all, is a passionate about data and analytics. In this role you will be part of a team of engineers to create world's largest financial data warehouses and BI tools for Amazon's expanding global footprint.

Key job responsibilities
Design, implement, and support a platform providing secured access to large datasets.
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.
Tune application and query performance using profiling tools and SQL.
Analyze and solve problems at their root, stepping back to understand the broader context.
Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.
Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.
Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.
Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.
We are open to hiring candidates to work out of one of the following locations:

Dallas, TX, USA

Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","$110,777 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
Reality Defender,#N/A,"New York, NY",Data Engineer (Datasets) - Remote,"** Must have at least a BS in Computer Science and at least 3 years of work experience after graduation from university.
** No firms - we can not work with firms due to regulatory reasons.
** Please do not apply for this role if you do not fit these requirements.

Reality Defender seeks a data engineer to join the R&D team. You’d work on large foundation datasets for foundation models in vision, audio or NL.

[Large Language Model (LLM) Ethics] RD does not allow the use of Large Language Models or online chatbots such as ChatGPT in any part of the interview process - video calls, take-homes, etc.
Responsibilities
Build very large-scale multimodal datasets and high-quality benchmarks working closely with R&D.
Automate data augmentation, quality control and content moderation.
Qualifications
Proficient in software development, esp. Python
Interest in data exploration, visualization, cleaning, and analytics for real-world data modeling
Familiarity with audio and video file formats, and codecs
Smart, driven, and passionate about helping Reality Defender change the world
Team player with a positive attitude, sincerity, and good communication skills","$150,000 /yr (est.)",Unknown,Company - Private,Information Technology,Software Development,#N/A,Unknown / Non-Applicable
"Included Health
3.8",3.8,Remote,"Senior Software Engineer, Data Services","Our Team:

Think about the best products you’ve built as an engineer. Were they powered by APIs that did what you needed so you could focus on solving your user problem? Did these APIs just make sense and work as expected? If so, you already know what we’re trying to do. Building production software is hard. Making it so simple to use that it disappears into the background is harder. Doing that for healthcare data, which can be messy, is so hard that nobody has really done it.

Data Services owns the core domains underpinning how we get our members to the right care at the right time. The Coverage team is responsible for answering critical questions that enable a member to get the right care: What are the right health benefits to show a member when they come to us? And at what cost?

This team could be right for you if:
You thrive on high-impact work that is foundational to the operation of the business
You know that a big part of solving a complex business problem is getting the domain model right
Where others see intimidating complexity, you see simpler subproblems and solutions that can be built back up to solve the broader problem
Desired Outcomes — What does success look like?
Achieve team and business impact through high personal output
Prioritize and scope engineering effort according to expected business value, effectively communicating with teammates and stakeholders
Lead project execution by managing epics/stories/tasks, providing clarity to the business on delivery timing, and acting as an owner of overall project success
Design, implement, test, and operate systems with exemplary engineering fundamentals that make appropriate tradeoffs
Engage in cross-team and cross-functional efforts to ensure timely, successful delivery against team OKRs
Mentor engineers, improving their technical and non-technical skills to maximize their impact
Competencies:
Stellar engineering leadership by example — regardless of your language of choice, you separate concerns and define well-abstracted interfaces, leading to functioning, performant, well-tested, maintainable code and systems
Thinking and communicating in first principles — you are able to explain your points of view from foundational concepts rather than by associative thinking
Critical thinking with influence — you systematically evaluate the tradeoffs associated with each potential solution to a problem, make an informed decision, and articulate these things well to influence others, driving impact
Technologies:
Here are some of the technologies we use now or may use in the future; you probably care somewhat if you’re an engineer. Familiarity with these things is nice to have, but not a requirement.
Go, Python, Ruby, Scala, Java
Django
GraphQL
HL7 FHIR, Redox
gRPC/Protocol Buffers, Thrift, Avro
Bazel
OAuth
MySQL, PostgreSQL
Kafka
Redis
Elasticsearch
Docker
Kubernetes
Terraform
AWS
About Included Health

Included Health is a new kind of healthcare company, delivering integrated virtual care and navigation. We’re on a mission to raise the standard of healthcare for everyone. We break down barriers to provide high-quality care for every person in every community — no matter where they are in their health journey or what type of care they need, from acute to chronic, behavioral to physical. We offer our members care guidance, advocacy, and access to personalized virtual and in-person care for everyday and urgent care, primary care, behavioral health, and specialty care. It’s all included. Learn more at includedhealth.com.
-
Included Health is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. Included Health considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.",#N/A,1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2011,Unknown / Non-Applicable
"Linktree
3.2",3.2,"Los Angeles, CA",Staff Data Engineer,"The Role

Linktree’s Data Platform team is at the forefront of transforming the way Linktree leverages data, working closely with the insights, analytics engineering, product and marketing teams to become truly data driven.

As a Staff Data Engineer at Linktree, you will be the driving force behind scaling how data is consumed at Linktree. Not only will you be modelling some of our most important data sets to gain insights, such as the data that helps us understand the driving factors behind the success of our product or our revenue, we take self-service one step further. You will also build the platform that can be used by Data Analysts, Marketers, Engineers and anyone else who is interested to model their own data to fit their specific needs and not be dependent on a data team.

This is your opportunity to make an impact at Linktree and push the boundaries of what is possible with data self-service!

Location Expectations: Hybrid. We're growing our team in LA and the Bay Area, and plan to have offices in both locations. We expect team members to come into their respective office 2x/week.

What You Will Do
Develop and implement the strategy for the Data Platform in close collaboration with other data and engineering leaders.
Continue leading the transformation to make data a first-class citizen in software development at Linktree. This includes providing other teams with the self-service capabilities to ingest, transform, consume and integrate data with other systems for both production and analytics use-cases.
You will be building and improving data-driven systems including, but not limited to, instrumentation at the source, event ingestion, event brokers, data warehouses, pipelines and integration systems used to activate data in third parties, such as an experimentation platform, product analytics and marketing tooling.
Ensure our data platform continues to scale with our rapidly growing user base and ever-evolving product. Linktree’s growth constantly creates new challenges like needing to master data governance and discoverability with many different teams producing data, or hitting the scalability limits of cloud providers.

What We Are Looking For
A platform mindset. Our Data Platform team does not do repetitive data transformation and integration jobs for others. The team builds the infrastructure and tools that allows Linktree to perform these tasks at scale by enabling all teams to perform data-related jobs themselves.
- Data as well as a software engineering background. Our data platform spans from the SDKs that our teams use to emit and consume data in front- and back-end applications to the integration with various third-party systems, including everything in between (data ingestion, event brokers, data persistence, etc.). To be successful in your role you’ll need to be proficient in both. Having worked with distributed, event-driven systems is a plus.
Experience operating at scale. You have worked on data systems that power a product that serves hundreds of millions of active users.

Linktree is committed to providing a competitive compensation package. Our cash compensation amount for this role is targeted at $175,000-$225,000 in the San Francisco Bay or Los Angeles area. Final offer amounts are determined by multiple factors including candidate expertise, the scope of role and level, and may vary from the amounts listed above.
P.S. If you don’t tick every box in this ad, please don’t rule yourself out. We take pride in inclusion and hiring incredible human beings with great potential over ticking boxes – so if this role resonates with you, hit that apply button!

Where and How We Work
We are a global and diverse group offering a truly flexible and family friendly work environment. Kids, pets, and the occasional delivery person are all actively encouraged to appear on our Zoom screens. All of us at Linktree work either fully remote or a hybrid ""remote, but in-office sometimes"" approach.

We currently have offices in Melbourne, Sydney and LA, but our team is spread across Australia, United States, and New Zealand. As our team approaches 200 people, our company will be 10x the size we were in 2020.

We offer autonomy and flexibility in how you structure your days and weeks. There will be the need for some collaboration outside of a ""normal"" 9-5 being a global company, but we aim to work asynchronously where possible.

Our Culture and Benefits
Linktree's company culture and values are based around collaboration, diversity, inclusion, and flexibility. Those are all nice words but to give you some more specific examples:

We recognize that our teammates are individually unique and have designed our benefits with this in mind. Each employee has an annual allowance to use on things like (but not limited to) fitness memberships, development courses, childcare, travel, charitable donations, pet insurance, home office set up - the choice is yours!
We provide top-flight medical, dental, vision, disability and life insurance - we cover 100% of your monthly premiums (and 80% for your dependents).
401k matching up to 6%.
Employee Stock Option Program - we want each and every employee to share in the company’s success as we go further together.
To learn more about our benefits, including our parental leave program, volunteering leave, DE&I initiatives, and more, click here!

Our Story
We're on a mission to empower anyone to curate and grow their digital universe. We created the ""link in bio"" category and are trusted by some of the world's biggest brands and celebrities including TikTok, The UN Environmental Program, The White House, F1, Manchester United, Selena Gomez, Alicia Keys, and Dwayne “The Rock” Johnson. With a flexible work environment and a team spread across multiple time zones, we offer autonomy and flexibility. Join us in empowering people to control their online presence!

At Linktree, we celebrate and support everyone’s perspective and background, and we’re proud to be an equal opportunity workplace. We aim to foster a diverse and inclusive environment where all team members have a sense of belonging, because we believe in going further together. Linktree welcomes all people regardless of sex, gender identity, race, ethnicity, disability, pregnancy, age, or other lived experience. If you require accommodations to fully participate in our opportunities, please don't hesitate to reach us at recruiting@linktr.ee – your needs are important to us.","$170,366 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Fidelity Investments
4.3",4.3,"Westlake, TX",Principal Data Engineer,"Job Description:
Position Description:
Crafts secure, scalable, resilient Cloud-based services using data warehousing, visualization, and integration methodologies. Reviews the implementation of relational database technologies - Oracle SQL and PL/SQL -within Snowflake, Amazon Web Services (AWS), or MS Azure. Manages data movement technologies Extract, Transform, and Load and Extract, Load, and Transform (ETL/ELT) processes and schedulers. Delivers and supports Cloud strategies - migrating legacy products and implementing Software as a Service (SaaS) integrations. Manages multi-functional enterprise data, navigating between business analytic needs and data. Executes on product roadmaps to enable new insights with data. Crafts and implements operational data stores and data lakes in production environments.
Primary Responsibilities:
Manages project functionality, using DevOps, Continuous Integration and Continuous Delivery methodologies and tools.
Develops and deploys pipelines within a Cloud native infrastructure.
Performs data analysis on database platforms using SQL.
Develops ELT/ETL pipelines to move data to and from Microsoft Common Data Service (CDS), using Azure Data Factory and Power Automate Flows.
Implements data modelling techniques and standard methodologies.
Designs and develops data services.
Sets the technical direction for the team.
Develops and improves data architecture, database design, and performance optimization.
Sets up reliable infrastructure
- hardware, scalable data management systems, and frameworks to perform data-related tasks.
Simplifies and communicates technical challenges, solutions options, and recommendations to business partners and technology leadership.
Provides technical leadership and support in data and solutioning to team members.
Produces scalable, resilient, Cloud-based systems design.
Analyzes information to determine, recommend, and plan installation of a new system or modification of an existing system.
Confers with systems analysts, engineers, programmers, and others to design systems and to obtain information on project limitations and capabilities, coordinating installation of software system.
Determines system performance standards.
Education and Experience:
Bachelor’s degree (or foreign education equivalent) in Computer Science, Engineering, Information Technology, Information Systems, Mathematics, Physics, or a closely related field and five (5) years of experience in the job offered or five (5) years of experience developing applications to support legal, compliance, risk, security, and audit functions within a financial services environment.
Or, alternatively, Master’s degree (or foreign education equivalent) in Computer Science, Engineering, Information Technology, Information Systems, Mathematics, Physics, or a closely related field and three (3) years of experience in the job offered or three (3) years of experience developing applications to support legal, compliance, risk, security, and audit functions within a financial services environment.
Skills and Knowledge:
Candidate must also possess:
Demonstrated Expertise (“DE”) performing data movement processes (migration, ingestion, and sync-up) for legal, compliance, risk, and security applications using Power Automate, Azure Blob, and Azure Data Factory pipelines.
DE implementing Dataverse tables, forms, business rules, relationships, and flows for legal, compliance, risk, and security applications on a Microsoft Power Platform, using Dataverse, custom connectors, and Power BI reports.
DE implementing data components (databases, tables, views, types, stored procedures, functions, roles, and queries) for legal, compliance, risk, and security applications on relational databases (DB2, Oracle) using SQL and PL/SQL queries.
DE implementing Control–M jobs and compliance aggregate reports for legal, compliance, risk, and security applications on a customer identification program.
Certifications:
Company Overview
Fidelity Investments is a privately held company with a mission to strengthen the financial well-being of our clients. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients' money.

Join Us
At Fidelity, you'll find endless opportunities to build a meaningful career that positively impacts peoples' lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees' Choice Award, we have been recognized by our employees as a Best Place to Work in 2023. And you don't need a finance background to succeed at Fidelity—we offer a range of opportunities for learning so you can build the career you've always imagined.
At Fidelity, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we’re calling “Dynamic Working”. Most associates will have a hybrid schedule with a requirement to work onsite at a Fidelity work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change.
We invite you to Find Your Fidelity at fidelitycareers.com.

Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.
Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team by sending an email to accommodations @fmr.com, or by calling 800-835-5099, prompt 2, option 3.
At Fidelity, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry. Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Fidelity offer will need to go through a background investigation and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, Fidelity will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine.","$128,003 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Investment & Asset Management,1946,$10+ billion (USD)
"Indium Software
4.1",4.1,"Sacramento, CA",Senior Data Engineer,"Job Information
RSD NO
7502
Industry
IT Services
Min Experience
4
Max Experience
8
City
Sacramento
State/Province
California
Country
United States
Zip/Postal Code
94203
Job Description
Title: Senior Data Engineer
Education Qualification: Bachelor's degree in Computer Science, Information Technology, or a related field.
Experience: 4-8 Years
Work Location: California
Work Mode: Work from Office

Required Skills :
Extensive experience providing practical direction within azure native services , implementing data migration and data processing using Azure services: ADLS, Azure Data Factory, Synapse/DW /Azure SQL DB, Fabric.
Proven experience with SQL, namely schema design and dimensional data modelling
Solid knowledge of data warehouse best practices, development standards and methodologies
Strong experience with Azure Cloud on data integration with Databricks
Be an independent self-learner with the “let’s get this done” approach and ability to work in Fast paced and Dynamic environment

Nice-to-Have Skills:
Basic understanding on ML Studio, AI/ML, MLOps etc.
Good to have Event Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service, Cosmo Db knowledge.
Good to have SAP Hana knowledge
Intermediate knowledge on Power BI
Good to have knowledge in DevOps and CI/CD deployments, Cloud migration methodologies and processes.","$127,709 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,1999,$25 to $100 million (USD)
"CLEAR - Corporate
3.1",3.1,"New York, NY","Principal Software Engineer, Data","As a Principal Engineer for our Data Platform team, you will be responsible for modernizing our data platform and practice. You will play a critical role in selecting and implementing technology, which we will use across CLEAR to make data-driven decisions, build a best-in-class product, and enable future ML/AI use cases. You will work cross-functionally with multiple engineering teams, providing leadership and advice and helping teams integrate with the data platform. Additionally, you will be a crucial partner to various teams across CLEAR, including Business Intelligence, Product Management, Security, and more.
What you'll do:
Build partnerships with teams across CLEAR to ensure data solutions solve current and future use cases
Drive the migration to a modern data stack in which Analysts and Engineers can self-service changes in an automated, tested, and high-quality manner
Build data governance solutions into every part of the platform
Evangelize data and its use across CLEAR to make our decisions and products smarter
What you're great at:
10+ years of professional experience as a Data Engineer, focusing on building scalable data solutions
Experience with a modern programming language, such as Python
Building a modern datastack, using tools such as dbt, Dagster, Airflow, Snowflake, et cetera
Experienced with RDBMS, NoSQL, and real-time streaming systems like Kafka or Pulsar
Excellent communication skills, able to explain technical topics to non-technical audiences, manage up, down, and across
Have worked with or built a data governance program
How You'll be Rewarded:
At CLEAR we help YOU move forward - because when you're at your best, we're at our best. You'll work with talented team members who are motivated by our mission of making experiences safer and easier. Our hybrid work environment provides flexibility. In our offices, you'll enjoy benefits like meals and snacks. We invest in your well-being and learning & development with our stipend and reimbursement programs.
We offer holistic total rewards, including comprehensive healthcare plans, family building benefits (fertility and adoption/surrogacy support), flexible time off, free OneMedical memberships for you and your dependents, and a 401(k) retirement plan with employer match. The base salary range for this role is $225,000 - $260,000, depending on levels of skills and experience.
The base salary range represents the low and high end of CLEAR's salary range for this position. Salaries will vary depending on various factors which include, but are not limited to location, education, skills, experience and performance. The range listed is just one component of CLEAR's total compensation package for employees and other rewards may include annual bonuses, commission, Restricted Stock Units
About CLEAR
Have you ever had that green-light feeling? When you hit every green light and the day just feels like magic. CLEAR's mission is to create frictionless experiences where every day has that feeling. With more than 15+ million passionate members and hundreds of partners around the world, CLEAR's identity platform is transforming the way people live, work, and travel. Whether it's at the airport, stadium, or right on your phone, CLEAR connects you to the things that make you, you - unlocking easier, more secure, and more seamless experiences - making them all feel like magic.
CLEAR provides reasonable accommodation to qualified individuals with disabilities or protected needs. Please let us know if you require a reasonable accommodation to apply for a job or perform your job. Examples of reasonable accommodation include, but are not limited to, time off, extra breaks, making a change to the application process or work procedures, policy exceptions, providing documents in an alternative format, live captioning or using a sign language interpreter, or using specialized equipment.","$242,500 /yr (est.)",1001 to 5000 Employees,Company - Public,Management & Consulting,Security & Protective,2010,Unknown / Non-Applicable
"SailPoint
4.4",4.4,United States,"Senior Software Engineer, Data Platform","SailPoint is the leader in identity security for the cloud enterprise. Our identity security solutions secure and enable thousands of companies worldwide, giving our customers unmatched visibility into the entirety of their digital workforce, ensuring workers have the right access to do their job – no more, no less.
As a Senior Software Engineer on our Data Platform team you will help build our SailPoint Data Platform. We are looking for a well-rounded software engineer who is passionate about building a large-scale data infrastructure. You will work closely with Data Engineers, Warehouse Engineers, other software engineers and Data Scientists.
You will bring software engineering expertise to our Data Platform team. We are looking for someone with strong Python, Java, SQL, Snowflake and DBT experience.
Responsibilities
Collaborate with peers on designs, code reviews, and testing
Produce unit and end-to-end tests to improve code quality and maximize code coverage for new and existing features
Maintain and support current architecture (ETL) and evolve to newer architecture (ELT)
Deliver efficient, maintainable, robust Java based microservices.
Utilize a Data Platform to build and deliver data models via Java services.
Produce designs and rough estimates, and implement features based on product requirements.
Collaborate with peers on designs, code reviews, and testing.
Use telemetry to demonstrate the effectiveness of deployed services.
Work independently and deliver quality code on time
Requirements
5+ years of professional software development experience
At least 5 years of experience addressing and solving intricate data engineering challenges
A demonstrated eagerness to acquire new technical skills and adapt to evolving data landscapes
Strong programming skills, particularly in Python and Java, complemented by advanced SQL knowledge
Experience with Airflow DAGs, DBT models, Snowflake, Spark
Extensive hands-on experience building solutions for large-scale data infrastructure
Hands-on experience or deep understanding of data ingestion processes, data management best practices, and data warehousing principles.
Proficient experience with object-oriented analysis and design skills
Proficient understanding of Restful API’s
Strong experience testing code completeness and using telemetry to measure health and efficiency of services
Experience documenting requirements, proposed implementations, progress, challenges, and explanations of finished work
BS in Computer Science, or equivalent experience
Preferred
Experience with AWS
Experience working on a Big Data/Machine Learning product
Experience instrumenting code for gathering production performance metrics
SailPoint is an equal opportunity employer and we welcome everyone to our team. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2005,$100 to $500 million (USD)
"Labelbox
3.7",3.7,Remote,"Senior Backend Engineer, Data Platform","Labelbox is the leading data-centric AI platform for building intelligent applications. Teams looking to capitalize on the latest advances in generative AI and LLMs use the Labelbox platform to inject these systems with the right degree of human supervision and automation. Whether they are building AI products by using LLMs that require human fine-tuning, or applying AI to reduce the time associated with manually-intensive tasks like data labeling or finding business insights, Labelbox enables teams to do so effectively and quickly.
Current Labelbox customers are transforming industries within insurance, retail, manufacturing/robotics, healthcare, and beyond. Our platform is used by Fortune 500 enterprises including Walmart, Procter & Gamble, Genentech, and Adobe, as well as hundreds of leading AI teams. We are backed by leading investors including SoftBank, Andreessen Horowitz, B Capital, Gradient Ventures (Google's AI-focused fund), Databricks Ventures, Snowpoint Ventures and Kleiner Perkins.
About the Role
As a Senior Software Engineer on our Data Platform team you will be building highly available storage platforms that are operationally simple, scale to billions of objects, and have predictable read and write performance.
Our Data Platform team maintains backend infrastructure that does data curation of large data sets in order to search, visualize, explore, and analyze all labeled and unlabeled data, metadata, and model inferences.
Your Day to Day
Design, build, deliver and maintain complex backend systems and integrations that store billions of records, offer consistent query performance, and reasonable transactional guarantees at hundreds of thousands of queries per second.
Take the lead on critical escalations, drive them to resolution, and see them as opportunities to improve.
Empower other engineering and product teams to identify their data needs and deliver APIs for them to efficiently access it.
About You
8+ years of experience as a either a full-stack or backend software engineer
You have experience in a modern programming language (Typescript, Python)
You have expertise in multiple storage systems (Relational Databases, Key-Value Stores, Cloud Buckets, etc.)
You are Experienced with Google Cloud or AWS
You are familiar with DevOps technologies (ArgoCD, CodeFresh, Kubernetes, etc.)
Nice to Have
Experience with integrations with Databricks
ETL mechanisms
Google Spanner
Kotlin
Messaging systems (e.g. Kafka and Google pub/sub)
Microservices

Labelbox strives to ensure pay parity across the organization and discuss compensation transparently. The expected annual base salary range for United States-based candidates is $170,000 - $215,000. This range is not inclusive of any potential equity packages or additional benefits. Exact compensation varies based on a variety of factors, including skills and competencies, experience, and geographical location.
Excel in a Hub-centric Remote Model.
We’re committed to excellence and understand the importance of bringing our talented people together. While we continue to embrace remote work, we’ve transitioned to a Hub-Centric Remote Model with a focus on nurturing collaboration and connection within our dedicated hubs in the San Francisco Bay Area, New York City Metropolitan Area, Miami-Fort Lauderdale Area, and Warsaw, Poland. We encourage asynchronous communication, autonomy, and ownership of your tasks, with the added convenience of hub-based gatherings.
Your Personal Data Privacy: Any personal information you provide Labelbox as a part of your application will be processed in accordance with Labelbox’s Job Applicant Privacy notice.
#LI-Remote","$192,500 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2018,Unknown / Non-Applicable
"Curinos
3.4",3.4,"New York, NY",Senior Data Backend Engineer,"Company Description

Curinos is the leading provider of data, technologies and insights that enable financial institutions to make better, and more profitable, data-driven decisions faster. Born out of the combination of two familiar industry powerhouses, Novantas and Informa’s FBX business, Curinos brings to market a new level of industry expertise across deposits, lending and digital experience solutions and technologies.

Job Description

We are looking for a Senior Data Backend Engineer to work on the Amplero platform. Amplero’s patented technology dynamically identifies the right tone, message components, and channel preferences to improve marketing performance.
Our Data Backend Engineers are part of a cross-functional engineering team that build and maintain:
big data ETL pipelines. This entails developing pipeline components, orchestration of those components, incoming client data ingestion, and outbound client data export.
our core marketing decisioning engine.
our third-party marketing cloud connectors
The salary range for this role is 135k to 150K

Qualifications

Candidates should have the following background, skills, and qualities:
Programming languages
One of Java or Scala
Python strong nice to have
SQL
Competency with shell scripting in a Linux environment nice to have
Exposure to contemporary big data stacks and technologies. Typical examples include things such as Yarn, HDFS, Spark, Hadoop and Databricks, but this is not an exclusive list.
Some experience with real-time processing nice to have
Solid understanding of data structures and algorithms
3+ years of experience is preferred
Some experience with production support
Experience with 3rd party marking clouds (such as Salesforce) nice to have
Self–discipline and willingness to learn
Solid verbal and written communication skills
Team player and ability to work well with others in an intellectually challenging environment.

Additional Information

Why work at Curinos?
Competitive benefits, including a range of Financial, Health and Lifestyle benefits to choose from
Flexible working options, including home working, flexible hours and part time options, depending on the role requirements – please ask!
Competitive annual leave, floating holidays, volunteering days and a day off for your birthday!
Learning and development tools to assist with your career development
Work with industry leading Subject Matter Experts and specialist products
Regular social events and networking opportunities
Collaborative, supportive culture, including an active DE&I program
Employee Assistance Program which provides expert third-party advice on wellbeing, relationships, legal and financial matters, as well as access to counselling services
Applying:
We know that sometimes the 'perfect candidate' doesn't exist, and that people can be put off applying for a job if they don't meet all the requirements. If you're excited about working for us and have relevant skills or experience, please go ahead and apply. You could be just what we need!
If you need any adjustments to support your application, such as information in alternative formats, special requirements to access our buildings or adjusted interview formats please contact us at careers@curinos.com and we’ll do everything we can to help.
Inclusivity at Curinos:
We believe strongly in the value of diversity and creating supportive, inclusive environments where our colleagues can succeed. As such, Curinos is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, color, ancestry, national origin, religion, or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other protected characteristics","$142,500 /yr (est.)",201 to 500 Employees,Company - Private,Management & Consulting,Research & Development,2021,Unknown / Non-Applicable
"First American Financial Corporation
3.8",3.8,"Santa Ana, CA",Senior Data Engineer (Hybrid),"Who We Are
Join a team that puts its People First! Since 1889, First American (NYSE: FAF) has held an unwavering belief in its people. They are passionate about what they do, and we are equally passionate about fostering an environment where all feel welcome, supported, and empowered to be innovative and reach their full potential. Our inclusive, people-first culture has earned our company numerous accolades, including being named to the Fortune 100 Best Companies to Work For® list for eight consecutive years. We have also earned awards as a best place to work for women, diversity and LGBTQ+ employees, and have been included on more than 50 regional best places to work lists. First American will always strive to be a great place to work, for all. For more information, please visit www.careers.firstam.com.
What We Do
The Underwriting Innovation Team is looking for promising new Senior Data Engineer to help accelerate our digital transformation. We want diverse thinkers who know how to bring innovation to life by facilitating the design and development of simple, intuitive, and user-centered software solutions. You’ll help senior department leadership drive the transformation of a traditionally paper-based business by re-imagining underwriting as a digital experience, thinking through both the underwriter’s and customer’s lenses. The Data Engineer is a data expert and plays a key role in the development and deployment of innovative big data platforms for advanced analytics and data processing. Supports building scalable and effective solutions using modern technology stack to grow and leverage the company’s vast data assets. Works with functional teams and supports software developers, database architects, data analysts, and data scientists on data initiatives and ensures that optimal data delivery architecture is consistent throughout ongoing projects.
***Candidates will need to be local to Southern California and will get to work out of First American's Corporate HQ's in Santa Ana, CA for 2-3 days a week!
What You'll Do:
Viewed as a data expert; drives innovation and plays a key role in the department. Participates in highly visible initiatives that have broad impact.
Identify, design, and implement internal process improvements: automate manual processes, optimize data delivery, re-design infrastructure for greater scalability.
Design, develop, code, test, and document architectures and applications.
Work closely with team members and cross-functional teams to ensure design/architecture/deliverables support business requirements and align with best-practices.
Troubleshoot and resolve a wide range of data issues.
Makes innovative recommendations to improve data reliability, efficiency and quality.
Required to perform duties outside of normal work hours based on business needs.
What You'll Bring:
Strong database development skills
Strong knowledge of SQL and NoSQL databases
Strong experience with ETL processes to ingest large amounts of data at regular intervals
Strong knowledge of database performance optimization techniques, such as clustered, non-clustered, spatial, full-text indexing, etc.
Geospatial data knowledge preferred
Experience working in Agile SDLC methodology
Proficient with SQL and T-SQL programming skills
Working experience building data/ETL pipeline and data warehouse
Demonstrated expertise in data modeling, database maintenance, monitoring and performance tuning on SQL Server, MongoDB or other NoSQL databases
Exceptional analytical skills analyzing large and complex data sets
Perform thorough testing and data validation to ensure the accuracy of data transformations
Strong written and verbal communication skills, with precise documentation
Self-driven team player with ability to work independently and multi-task
Analytical, creative thinker and innovative problem solver
Working knowledge/proficient in modern cloud computing technology
Bachelor's degree in Computer Science/related field or equivalent combination of education and experience
5-8 years of directly related experience
Salary Range: $87,900.00 - $182,700 Annually
This hiring range is a reasonable estimate of the base pay range for this position at the time of posting. Pay is based on a number of factors which may include job-related knowledge, skills, experience, business requirements and geographic location.
#techreferral
#LI-NM1
What We Offer
By choice, we don’t simply accept individuality – we embrace it, we support it, and we thrive on it! Our People First Culture celebrates diversity, equity and inclusion not simply because it’s the right thing to do, but also because it’s the key to our success. We are proud to foster an authentic and inclusive workplace For All. You are free and encouraged to bring your entire, unique self to work. First American is an equal opportunity employer in every sense of the term.
Based on eligibility, First American offers a comprehensive benefits package including medical, dental, vision, 401k, PTO/paid sick leave and other great benefits like an employee stock purchase plan.","$135,300 /yr (est.)",10000+ Employees,Company - Public,Insurance,Insurance Carriers,1889,$5 to $10 billion (USD)
"Lovelytics
4.4",4.4,Remote,Data Engineer (Senior Consultant),"Lovelytics is seeking a data engineer with experience delivering strategic Databricks client engagements to join our Data & AI practice!
This consultant will primarily focus on participating in engagements with clients related to data warehousing, ETL development, data integrations, and data modeling. In addition to the technical capabilities for this role, we are looking for someone who wants to work in a collaborative, dynamic, and inclusive environment and has a passion for bringing meaning to data.
Role Location: Arlington, VA, or Remote in the US and Ontario, Canada
Primary Responsibilities:
Utilize consulting and technical skills to be able to work in a client-facing project environment
Be responsible for the execution of client engagements as assigned and under the supervision of the engagement lead
Collaborate with other team members to successfully deliver on projects
Work effectively and directly with both internal and client and/or partner teams
Support data integration efforts using cloud services.
Deliver ETL/ELT pipelines for small-scale projects independently.
Actively contributed to data warehousing initiatives.
Apply your skills with Databricks, using Python, and big data streaming to pioneer client technologies and data.
Our Ideal Candidate's Skills and Experiences:
B.S. in Computer Science or equivalent
2-3 yrs' experience in data engineering and big data. At least 1 year working directly with clients and external stakeholders.
Extensive knowledge of data warehousing concepts and hands-on experience deploying pipelines using Databricks and/or Spark
Proficiency in programming languages: Writing and debugging Python, SQL, and possibly Scala code.
Basic data modeling and database design skills and knowledge of version control
Excellent verbal and written communication skills
What We Promise You:
Exciting projects with great clients in varying departments and verticals across the world
The ability to work closely with experienced data engineers and quickly grow and expand your skillset
The ability to work closely with all sizes of companies, ranging from Fortune 100 to small local businesses
A workplace where you are encouraged to challenge the status quo and develop new technologies, methodologies, and processes
A diverse team consisting of data gurus, experience seekers, and entrepreneurial minds that are always pushing to be better
Lovelytics is an Equal Opportunity Employer. This means you don’t have to worry about whether your application process will be fair. We consider all applicants without regard to race, color, religion, age, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, veteran status, or disability.
YLkmri8OO6",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $25 million (USD)
"Blueprint Technologies
3.5",3.5,Remote,Principal Data Engineer,"Principal Date Engineer Remote
Who is Blueprint?
We are a technology solutions firm headquartered in Bellevue, Washington, with a strong presence across the United States. Unified by a shared passion for solving complicated problems, our people are our greatest asset. We use technology as a tool to bridge the gap between strategy and execution, powered by the knowledge, skills, and the expertise of our teams, who all have unique perspectives and years of experience across multiple industries. We're bold, smart, agile, and fun.
What does Blueprint do?
Blueprint helps organizations unlock value from existing assets by leveraging cutting-edge technology to create additional revenue streams and new lines of business. We connect strategy, business solutions, products, and services to transform and grow companies.
Why Blueprint?
At Blueprint, we believe in the power of possibility and are passionate about bringing it to life. Whether you join our bustling product division, our multifaceted services team or you want to grow your career in human resources, your ability to make an impact is amplified when you join one of our teams. You'll focus on solving unique business problems while gaining hands-on experience with the world's best technology. We believe in unique perspectives and build teams of people with diverse skillsets and backgrounds. At Blueprint, you'll have the opportunity to work with multiple clients and teams, such as data science and product development, all while learning, growing, and developing new solutions. We guarantee you won't find a better place to work and thrive than at Blueprint.
What will I be doing?
Blueprint is looking for a Principal Data Engineer to join us as we build cutting-edge technology solutions! The ideal candidate will have a solid background in consulting, with demonstrated experience leading clients through the process of building modern data estates. As a Principal Data Engineer, you will spend a majority of your time working directly with clients to develop their advanced modern data estates, warehouses, and analytical environments. You will also be responsible for overseeing and mentoring junior developers within the organization.
Responsibilities:
Develop and implement effective data architecture solutions using Databricks and Lakehouse
Optimize and tune data pipelines for performance and scalability
Monitor and troubleshoot data pipelines to ensure data availability and reliability
Collaborate with data scientists, analysts, and other stakeholders to understand their data needs and build solutions that enable them to extract insights from data
Implement best practices for data governance, data security, and data quality to ensure data integrity across all data sources
Create and maintain documentation related to data architecture, data pipelines, and data models
Stay up to date with emerging technologies and best practices in data engineering and big data processing
Mentor and train other data engineers on best practices for data engineering and Databricks usage
Provide thought leadership in the Databricks and Lakehouse space, both within the organization and externally
Qualifications:
Bachelor's or Master's degree in Computer Science, Computer Engineering, or a related field
8+ years of experience in data engineering
3+ years of experience working with Databricks and PySpark
6-8+ years of experience with SQL
Appreciation for the Lakehouse medallion data architecture – bronze, silver, gold – and how those data stages are used
Working knowledge of DLT(Delta Live Tables) and Unity Catalog a plus
Strong understanding of ETL and ELT data ingestion, acquisition, and data processing patterns
Experience with cloud-based data warehousing platforms such as Synapse, AWS Redshift, Google BigQuery, or Snowflake
Strong understanding of data engineering, data warehousing, data modeling, data governance, and data security best practices
Excellent problem-solving and troubleshooting skills
Strong communication and collaboration skills, with the ability to work effectively in a team environment
Experience mentoring and training other data engineers
Salary Range
Pay ranges vary based on multiple factors including, without limitation, skill sets, education, responsibilities, experience, and geographical market. The pay range for this position reflects geographic based ranges for Washington state: $127,000 to $211,600 USD/annually. The salary/wage and job title for this opening will be based on the selected candidate's qualifications and experience and may be outside this range.

Equal Opportunity Employer
Blueprint Technologies, LLC is an equal employment opportunity employer. Qualified applicants are considered without regard to race, color, age, disability, sex, gender identity or expression, orientation, veteran/military status, religion, national origin, ancestry, marital, or familial status, genetic information, citizenship, or any other status protected by law.
If you need assistance or a reasonable accommodation to complete the application process, please reach out to: recruiting@bpcs.com
Blueprint believe in the importance of a healthy and happy team, which is why our comprehensive benefits package includes:
Medical, dental, and vision coverage
Flexible Spending Account
401k program
Competitive PTO offerings
Parental Leave
Opportunities for professional growth and development
Location: Remote","$169,300 /yr (est.)",501 to 1000 Employees,Company - Private,Management & Consulting,Business Consulting,2013,Unknown / Non-Applicable
"Mitchell Martin
4.2",4.2,"New York, NY",Senior Data Engineer,"Our client, violoncello is a bowed string instrument of the violin family, is seeking a Senior Data Engineer

Location: NYC ideal, Fully Remote
Position Type: Full Time

Job Description:
Developing cutting-edge data systems and analytics tools leveraging latest data science and engineering concepts applied to the U.S. Housing and Mortgage Markets.

Leadership Requirements:
A knack for understanding and breaking down complex business logic
Strong listening and communication skills to effectively liaise among stakeholders
Experience designing and implementing complete data systems

Education Requirements:
Bachelor's degree or higher in Computer Science, Data Science, Engineering, Mathematics, or Physics
Minimum GPA 3.5

Technical Requirements:
5 years of experience in Apache Spark, Scala, Delta Lake data pipeline development
Strong knowledge of SQL and Python programing languages
Familiarity with Columnar database, No-SQL and in-memory databases
Familiarity with Apache Airflow

Optional:
Knowledge of Fixed Income and particularly Mortgage Markets

Compensation: $190k - $210k base + bonus/equity

M","$200,000 /yr (est.)",501 to 1000 Employees,Private Practice / Firm,Human Resources & Staffing,HR Consulting,1984,$100 to $500 million (USD)
"Meta
3.9",3.9,"Seattle, WA",Software Engineer - Data Center Networking,"The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!


Software Engineer - Data Center Networking Responsibilities:
Design and implement drivers (and/or Firmware) for (network) ethernet adapter functions, Transport stack for RDMA, control functions with the host/accelerators.
Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).
Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI
Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
4+ years of experience in C/C++ and Python
4+ years experience in Systems programming, TCP/IP, HTTP/HTTPS, SPDY, DNS, and load balancers
Experience with network devices (routers, switches, load balancers) and an understanding of network routing protocols
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment



Preferred Qualifications:
Experience with Linux Kernel, especially drivers and network stack
Working knowledge of transport stack particularly RDMA (RoCEv2)
Experience with Qemu, FPGA Emulation environment is a plus
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$173,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Bounteous
3.9",3.9,United States,CDP Data Engineer (Contract),"A CDP Data Engineer (Adobe RTCDP) helps clients get value out of their investment into Customer Data Platforms like Adobe Real - Time CDP (RTCDP) by extracting, transforming and loading the data into the platform to build the unified customer profile. You will be working with a multidisciplinary team of Consultants, Solution Architects, Data Scientist and Digital Marketers.
Role and Responsibilities
Be a platform expert in Adobe Experience Platform Real-Time CDP
Provide deep domain expertise in our client’s business, technology stack and data infrastructure, along with a broad knowledge base in data engineering
Extract, transform and load marketing and customer data into the platform in an automated and scalable manner
Design, build/configure and test the necessary Adobe Experience Platform source and destination connections, data sets, XDM schemas and identity namespaces
Build the unified customer profile
Identify and write necessary queries needed for segmentation, reporting, analysis and ML models in query service

Preferred Qualifications
College degree in Computer Science, Data Science, Analytics or related field
Must have hands-on experience configuring Adobe Experience Platform RTCDP, including schema creation, ingesting data from a variety of sources, configuring identity resolution, and connecting destinations for activation
At least 5 years of experience architecting and building data pipelines
At least 3 years of experience working in an agency environment and strong consulting skills working closely with clients
Strong understanding and application of SQL
Strong understanding of working with APIs
Strong understanding of customer data platforms and the modern data infrastructure
Experience working with cloud technologies such as AWS, Google Cloud, Azure or similar
Experience working with data warehouse solutions like Amazon Redshift, Google BigQuery, Snowflake or similar
Experience with data visualization tools like Tableau, PowerBI or similar is a plus

#BI-Remote
#LI-Remote

We invite you to subscribe to our monthly and quarterly newsletters to stay up to date with the latest job openings as well as resources and tips for job seekers here.

Research shows that women and other underrepresented groups apply only if they meet 100% of the criteria of a job posting. If you have passion and intelligence, and possess a technical knack (even if you’re missing some of the above), we encourage you to apply.

Bounteous is focused on promoting an inclusive environment and is proud to be an equal opportunity employer. We celebrate the different viewpoints and experiences our diverse group of team members bring to Bounteous. Bounteous does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, physical or mental disability, national origin, veteran status, or any other status protected under federal, state, or local law.

In addition, you have the opportunity to participate in several Team Member Networks, sometimes referred to as employee resource groups (ERGs), that host space with individuals with shared identities, interests, and passions. Our Team Member Networks celebrate communities of color, life as a working parent or caregiver, the 2SLGBTQIA+ community, wellbeing, and more. Regardless of your respective identity, there are various avenues we involve team members in the Bounteous community.

Bounteous is willing to sponsor eligible candidates for employment visas.",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2003,Unknown / Non-Applicable
"JPMorgan Chase & Co
4.0",4.0,"Columbus, OH",Software Engineer - AWS Big Data,"JOB DESCRIPTION

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.
As a Software Engineer III at JPMorgan Chase within the Employee Experience & Corporate Technology, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.
Job responsibilities
Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems.
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems.
Produces architecture and design artifacts for complex applications while being accountable for ensuring design constraints are met by software code development.
Gathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems.
Proactively identifies hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.
Contributes to software engineering communities of practice and events that explore new and emerging technologies.
Adds to team culture of diversity, equity, inclusion, and respect.
Required qualifications, capabilities, and skills
Formal training or certification on software engineering concepts and 3+ years applied experience.
Experience with AWS EMR, Apache Spark - Scala, Python and Java and Infrastructure as Code (IaC) tools like Terraform.
Knowledge on AWS Lake Formation, AWS Glue Data Catalog and fine-grained access control.
Hands-on practical experience in system design, application development, testing, and operational stability.
Proficient in coding in one or more languages.
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages.
Overall knowledge of the Software Development Life Cycle.
Solid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security.
Demonstrated knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)
Preferred qualifications, capabilities, and skills
Familiarity with modern front-end technologies.
Exposure to cloud technologies.
AWS & Terraform Certification.
Data Mesh Architecture.
ABOUT US
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We recognize that our people are our strength and the diverse talents and perspectives that they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs. (If you are a US or Canadian applicant with a disability and wish to request an accommodation to complete the application process, please contact us by calling the Accessibility Line (US and Canada Only) 1-866-777-4690 and indicate the specifics of the assistance needed.)
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.
JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans



ABOUT THE TEAM

Our Corporate Technology team relies on smart, driven people like you to develop applications and provide tech support for all our corporate functions across our network. Your efforts will touch lives all over the financial spectrum and across all our divisions: Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and within the Corporate Administrative Office. You’ll be part of a team specifically built to meet and exceed our evolving technology needs, as well as our technology controls agenda.","$102,811 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Octo
4.2",4.2,"Reston, VA",Senior Data Engineer,"Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes.
Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region’s best places to work multiple times, Octo is an employer of choice!
You…

As a Senior Data Engineer at Octo, you will drive interactions with government stakeholders and teaming partners to gather requirements and propose analytic solutions.You will work with Octo business analysts and data analysts, as well as government stakeholders, to understand requirements and compile structured and unstructured data, ensuring its quality, accuracy, and reasonableness. You are comfortable leading technical teams comprised of individuals with varying skillsets and levels of experience. You have a passion for detail and are an excellent communicator. You are agile and curious and not afraid to identify what we are doing wrong so we can fix it, and what we are doing right so we can improve on it.

Us…

We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client’s missions.

Program Mission…

You will be working on a high-profile data analytics program for the Department of Homeland of Security (DHS) maintaining and transforming mission critical applications. This program is the reporting system of record for a wide variety of agency and component data, including financial, human capital, and government assets.In addition to geospatial tools, this program relies on business intelligence and data analytics tools.
Octo is an Equal Opportunity/Affirmative Action employer. All qualified candidates will receive consideration for employment without regard to disability, protected veteran status, race, color, religious creed, national origin, citizenship, marital status, sex, sexual orientation/gender identity, age, or genetic information. Selected applicant will be subject to a background investigation.
Octo is an IBM subsidiary which has been acquired by IBM and will be integrated into the IBM organization. Octo will be the hiring entity. By proceeding with this application, you understand that Octo will share your personal information with other IBM affiliates involved in your recruitment process, wherever these are located. More Information on how IBM protects your personal information, including the safeguards in case of cross-border data transfer, are available here: https://www.ibm.com/careers/us-en/privacy-policy/”.

Requirements:
Designs and builds strategic solutions to move data from operational and external environments to the business intelligence environment using a variety of tools including Oracle,Informatica, Python, ArcGIS pro, ArcGIS Online, Tableau and PowerBI.
Designs and develops extract, transform and load (ETL) processes, and has experience with full lifecycle implementation of the technical components of a business intelligence solution.
Applies data governance policies and standards and incorporates these into data transformation logic in ETL processes to enforce data standards and quality rules.
Can drive conversations input to strategic program-level initiatives and roadmaps;
Experience ingesting large datasets so that they can accurately report findings to internal and external customers.
Experience creating complex data pipelines using Python, Python Jupyter notebook, Azure Data Factory and Azure Synapse Analytics.
Identifies database structural necessities by evaluating client operations, applications, and programming.
Possesses strong problem-solving and analytical skills.
Possesses excellent written and verbal communication skills, including presentation skills.
Proven ability to lead teams to collaboratively deliver work within time constraints.
Possesses effective organizational, teamwork, and interpersonal skills.
Parse the data in delimited files, XML and Json and process them into data warehouse and dashboards.
Interested in learning and has an ability to understand new technology concepts quickly and apply them accurately through an evolving, dynamic environment.
Actively participates in Agile ceremonies such as stand ups, backlog refinement, sprint planning and sprint review, retrospectives, and demos.
Has a passion and ability to make a difference.
Desired Skills:
Experience working with Oracle & Informatica
Experience in Cloud Architecture, Azure Cloud services, Azure Data Factory, Azure Synapse
Experience working with SQL Queries and Power Apps
Experience with Dashboard creation in ArcGIS, PowerBI, and Tableau
Experience with JIRAand Confluence
Years of Experience: 7+ years of experience in design, development, testing, and execution of ETL processes.
Education: Bachelor’s or Master’s in computer science, or a related field (preferred)
Location: Remote
Clearance: U.S. Citizenship required, ability to receive a DHS EOD","$133,490 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,2006,$100 to $500 million (USD)
"Apple
4.2",4.2,"Cupertino, CA",ML and Data Infrastructure Engineer - SPG,"Summary
Posted: Dec 13, 2022
Role Number:200425055
As an engineer in the Special Projects Group, you will be part of a team building infrastructure and tools for exciting new technologies that will shape the future. You will work in a startup-like environment where products are still being defined and developed, giving you the chance to influence some of the core tools used by the project. You will be part of every stage of development from concept to deployment. We are looking for an senior engineer to architect, build and scale a robust ecosystem for data processing and distributed computation. Specifically you will develop solutions that will orchestrate and support the seamless transitioning of petabytes of data through various stages like ingestion, indexing/mining, transformation, machine learning and algorithm validation.
Key Qualifications
You have hands-on experience in building distributed systems, including real-time streaming and batch data processing
You are proficient in multiple programming languages relevant for such systems (e.g. Python, C++, Go, Java)
You know what it takes to deploy and operate high availability production systems in the cloud
You have experience designing service-oriented architectures and leveraging various data stores technologies (blob, NoSQL, and relational)
You have experience with cloud computing platform like AWS, GCP and Azure
Description
• Develop and scale a data processing platform using the latest open-source technologies • Develop platforms that enable researchers and developers to run machine learning jobs in the cloud easily • Define a consistent continuous integration/deployment model that will encourage cross-functional development teams to self-service application unit testing, deployment and operations • Influence and lead cross-functional initiatives that will align the team towards commonly used technologies and methodologies
Education & Experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Magellan Health
3.6",3.6,United States,Principal Data and Integration Engineer - Remote,"Proficient in Microsoft SQL Server (using SSMS – Advanced TSQL, Stored Procedures, best practices in RDBMS)
Knowledge/experience in Oracle (PLSQL using TOAD)
SSIS
SSRS
Optional skills
SnapLogic
Tableau
Tableau Bridge
Salesforce
This position will Lead agile software development efforts as a Technical Leader. This role will respond to audits and contribute to the RFP process. Ensure data governance and best practice is embraced. Responsible for understanding business and IT strategy to align with outcomes. Will be a hands-on Data and Integration Engineer who can write quality code, assist with problem solving, root cause analysis, trouble shooting and coaching. Must understand big picture from a business standpoint within the context of the application. Will define improvements to increase system reliability, security and performance. Perform rich data visualizations and presentations to senior management on value adds. May manage a team.
Participate in defining strategic IT objectives and leading subordinates toward that strategic vision for their products.
Acts as the primary focal point for both internal and external customers for software development tasks. This includes estimates of feasibility, time and effort of tasks.
Provide updates to both the user community and the programmers.
Monitor projects, determines potential problems and guides them to a successful completion.
Ensure that all work is getting accomplished by making assignments and monitoring tasks. This includes balancing work between programmers, analysts, project managers, supervisors, and managers, and ensuring that the proper policies and procedures are being followed.
Assists with budget preparation and management.
Mentor and evaluate staff performance. - Continues to work hands-on doing programming and analysis work themselves.
Tracks all project requests in functional area and updates status of projects on a regular basis.
Assists in estimating work effort associated with new project requests.
Assists in planning for the development and support of a functional systems area.
Reviews and evaluates work of subordinate staff and prepares performance reports.
Participates in planning and budgeting.
Other Job Requirements
Responsibilities
7+ years related experience including a minimum of 3-4 years of designing, building and maintaining high quality, secure software in IT.
Critical thinker.
Demonstrated problem solving techniques.
Strong verbal and written communication skills.
ServiceNow training.
General Job Information
Title
Principal Data and Integration Engineer - Remote
Grade
30
Work Experience - Required
IT
Work Experience - Preferred
Education - Required
Education - Preferred
Bachelors - Computer and Information Science
License and Certifications - Required
License and Certifications - Preferred
Salary Range
Salary Minimum:
$105,230
Salary Maximum:
$178,890
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Actual pay will be adjusted based on an individual's skills, experience, education, and other job-related factors permitted by law.
This position may be eligible for short-term incentives as well as a comprehensive benefits package. Magellan offers a broad range of health, life, voluntary and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing.
Magellan Health, Inc. is proud to be an Equal Opportunity Employer and a Tobacco-free workplace. EOE/M/F/Vet/Disabled.
Every employee must understand, comply with and attest to the security responsibilities and security controls unique to their position; and comply with all applicable legal, regulatory, and contractual requirements and internal policies and procedures.","$105,230 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1969,$5 to $10 billion (USD)
"Providence
3.6",3.6,Oregon,Senior Software Engineer - Data,"Description
Senior Software Engineer, Data - Enterprise Information Services - Location: WA or OR *hybrid
How would you like to pursue your passion for healthcare, social causes, and software development in a job that stimulates your brain and tugs at your heart? Our team at Providence is looking for a senior software engineer who can help us do data right to allow us to move quickly to accelerate our modern data architecture ambition. We have software engineers from Microsoft, Amazon, and other tech companies who work with the singular purpose of fulfilling our vision of Health for a Better World. Our work is not easy - healthcare is not easy, but we are having fun and are committed to our mission. If you think you have what it takes to have an impact on real lives, we want to talk to you.
The Senior Software Engineer builds modern data-centric solutions to support HR and operational processes across all parts of the healthcare system. Builds data pipelines and transformations, data enrichment processes and data visualizations to meet the requirements of key initiatives. Enjoys fast pace and has a focus on regular delivery. Uses emerging methods & tools to find data-driven solutions for complex problems and contributes to research and development of new technologies. Be an active participant in code reviews, support the code base, and help establish standard processes and frameworks.
Required qualifications:
Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
5 years related experience.
Extensive experience with object-oriented programming in C#, Java, Python or equivalent.
Experience with source code control systems such as Git.
SQL integration development experience with SQL/NoSQL.
Experience with Agile software development methodologies and tools such as Azure Devops, TFS, and Jira.
Proven track record of working both independently and collaboratively as part of a multi-disciplined team.
Experience designing and successfully implementing a large project.
Preferred qualifications:
Strong skill in understanding database architecture, data models and writing complex SQL queries/code.
Hands on experience in Azure Cloud components such as Azure Databricks, Azure Data Factory, Azure Logic apps and Azure Devops.
Experience with database query and analysis languages (e.g. SQL, R, SAS, Python).
Experience in data visualization tools (e.g. Power bi,Tableau) and ability to transform raw data into relevant insights.
Ability to work with large volume of data sets in performing data ingestion, loading, transformation and aggregation.
Data Analytics experience in a healthcare environment.
Salary Range by location: *hourly listed – position is salaried
WA Puget Sound Oregon (Portland) Alaska (Anchorage) Min: $52.84, Max: $89.98
Oregon (Hood River, Medford, Seaside) Min: $49.26, Max: $83.88
Eastern Washington (Richland, Spokane, Walla Walla) Min: $47.02, Max: $80.06
Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities.
About Providence
At Providence, our strength lies in Our Promise of “Know me, care for me, ease my way.” Working at our family of organizations means that regardless of your role, we’ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable.
The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.
Check out our benefits page for more information about our Benefits and Rewards.
About the Team
Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.
We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment.
We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business.
We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment.
Requsition ID: 220342
Company: Providence Jobs
Job Category: Development/Engineering
Job Function: Information Technology
Job Schedule: Full time
Job Shift: Day
Career Track: Business Professional
Department: 4011 SS IS AT DATA PROCSNG
Address: WA Redmond 17425 NE Union Hill Rd
Work Location: Redmond Junction At Bear Creek
Pay Range: $see posting - $see posting
The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.
Check out our benefits page for more information about our Benefits and Rewards.
Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",#N/A,10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1855,$100 to $500 million (USD)
"Proofpoint
4.1",4.1,Massachusetts,Senior Software Engineer - ML and Data Pipeline,"It's fun to work in a company where people truly BELIEVE in what they're doing!
We're committed to bringing passion and customer focus to the business.
Are you fascinated by the limitless potential of machine learning and data engineering? At Proofpoint, we're pioneering the integration of scalable machine learning pipelines and cutting-edge LLM models to revolutionize Security industry. We're looking for a talented Software Engineer who is as passionate as we are about crafting the next generation of intelligent solutions. If you thrive on innovation, complexity, and a high-impact role, this position offers a rare opportunity to contribute to transformative projects that are shaping the future. Come build extraordinary things with us!
Responsibilities:
Design, develop, and maintain scalable data pipelines, using tools such as Apache Kafka, Apache Spark, AWS Glue, or similar technologies.
Implement highly available, scalable machine learning models by working closely with Data Scientists and ML Engineers.
Analyze large datasets to identify trends, patterns, and insights, and use this data to inform model improvements.
Write clean, maintainable code that is easy to read and well-documented.
Monitor pipeline performance and troubleshoot bottlenecks or failures, ensuring high data quality and availability.
Engage in code reviews, design discussions, and contribute to the architectural decisions of the engineering team.
Keep abreast of the latest trends and technologies in machine learning and data engineering to continuously drive innovation within the team.
Requirements:
BS/MS in Computer Science, Engineering, or a related field.
4+ years of software engineering experience.
2+ years of hands-on experience in building data pipelines using big data technologies (e.g., Hadoop, Spark, Flink).
Proven experience in implementing machine learning models into production environments.
Strong proficiency in programming languages such as Nodejs, Python, Java, Scala, or Go.
Familiarity with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn.
Experience with cloud platforms like AWS, Azure, or GCP is a plus.
Strong problem-solving skills and the ability to work in a collaborative team environment.
Excellent written and verbal communication skills.
#LI-PH1
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
Consistent with Proofpoint values and applicable law, we provide the following information to promote pay transparency and equity. Our compensation reflects the cost of labor across several U.S. geographic markets, and we pay differently based on those defined markets as set out below. Pay within these ranges varies and depends on job-related knowledge, skills, and experience. The actual offer will be based on the individual candidate. The range provided may represent a candidate range and may not reflect the full range for an individual tenured employee. This role may be eligible for variable pay and/or equity. We offer a competitive benefits package that includes flexible time off, a robust well-being program that provides for 4 global wellbeing days per year, and a 3-week work from anywhere option.
Base Pay Ranges:
SF Bay Area, New York City Metro Area:
Base Pay Range: 157,650.00 - 231,220.00 USD
California (excludes SF Bay Area), Colorado, Connecticut, Illinois, Washington DC Metro, Maryland, Massachusetts, New Jersey, Texas, Washington, Virginia, and Alaska:
Base Pay Range: 129,000.00 - 189,200.00 USD
All other cities and states excluding those listed above:
Base Pay Range: 117,600.00 - 172,480.00 USD","$145,040 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2002,$100 to $500 million (USD)
"Emergent Holdings
3.5",3.5,United States,IT Data Engineer III,"The IT Data Engineer III is responsible for designing, developing, and supporting the end-to-end data ecosystem to support the organization. This position is responsible for supporting data-driven capabilities throughout the organization, including areas such as business intelligence, reporting, data science, and data analytics. The IT Data Engineer III will work with the business and internal teams to prepare complex data analyses that help solve client problems and deliver significant measurable impact.
RESPONSIBILITIES/TASKS:
Hands on development of frameworks and applications for data processing.
Analyze and evaluate data in relational databases and unstructured forms of data.
Develop interactive dashboards, reports, and analysis templates.
Implement and support a platform that can provide ad-hoc access to large datasets.
Responsible for providing innovative operational solutions and best practices.
Collaborate with teams/partners to improve the overall operational maturity of the data ecosystem.
Troubleshoot and resolve daily operational issues.
Design and implement an Enterprise Data Store consisting of a Landing Zone, and subject specific Staging and Mart databases using Replication, SSIS, T-SQL and Stored Procedures.
Design, code, test, and aggregate results from SQL queries to provide information to business users.
Work with Project Manager in developing and executing project plans within the assigned schedule and timeline utilizting SAFe Agile best practices.
Determine Business Intelligence and Data Warehousing solutions to meet business needs.
Manage the company’s Enterprise Data Store including:
Validating automated data feeds into the database.
Maintain validation processes to meet auditing requirements.
Ensure mapping tables and stored procedures are accurate and up to date.
Ensure outputs from the database are complete and accurate and meet the needs of the reporting team
Ensure calculations performed within the SQL database are accurate.
Ensure accurate documentation and models are being maintained.
Consistently improve, optimize, and maintain semantic models to achieve peak performance across the entire analytics platform.
Work closely with business units to gather requirements, draft prototypes, and document changes until a final version is accepted and signed off on.
Lead data mapping and analysis efforts to build a better view of our internal data assets and make recommendations on how and where to reduce redundancy.
Work closely with strategic projects as well as coaches development teams on defined standards and methods for data usage and propagation.
Identify and resolve data reporting issues in a timely fashion.
This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.
EMPLOYMENT QUALIFICATIONS:
EDUCATION :
Bachelor’s degree in computer science, mathematics, analytics, or equivalent discipline. Continuous learning, as defined by the Company’s learning philosophy, is required. Certification or progress toward certification is highly preferred and encouraged.
EXPERIENCE:
Seven years in a Data Warehousing environment is required, including three years of SQL (T-SQL), SQL Server, SSIS, ETL, and data integration experience required. Experience with Snowflake, BI tools, and reporting platforms (e.g. PowerBI or Tableau) preferred. Experience using Cloud (AWS or Azure) or Snowflake and insurance industry experience is a plus.
SKILLS/KNOWLEDGE/ABILITIES (SKA) REQUIRED:
Knowledge of data warehouse concepts, dimensional data modeling, and complex interdependent SQL processes.
Knowledge of SAFe Agile development practices.
Skilled in information delivery concept, design, and development using modern reporting tools.
Experience working in a large data warehouse environment with complex data models.
Strong proficiency in SQL, Power BI, and SSRS.
Excellent oral and written communication skills required, with demonstrated ability to lead a collaborative conversation with IT and business leaders in a technical and non-technical context.
Ability to analyze and model normalized and dimensional data structures.
Excellent problem solving, and critical thinking skills.
Ability to work independently and collaboratively with cross-functional teams.
Ability to manage multiple and competing projects/priorities.
Outstanding communication skills.
Cross group collaboration and interpersonal skills.",#N/A,1001 to 5000 Employees,Subsidiary or Business Segment,Insurance,Insurance Carriers,#N/A,$100 to $500 million (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"BlueOwl
4.6",4.6,Remote,Senior Data Engineer [Remote],"To help keep everyone safe, we encourage all applicants to pay close attention to protect themselves during their job search. When applying for a position online you are at risk of being targeted by malicious actors looking for personal data. Please be aware we will only reach out via email using the domain BlueOwl.xyz or HiRoad.com. Anything that does not match those domains should be ignored and considered a security risk.
About Us
BlueOwl is a separate company in the State Farm® family of companies and the solutions provider for HiRoad Insurance, an InsurTech brand that recognizes and rewards good choices. Operating independently with the backing of the #1 auto insurer in the country, we blend the best aspects of a tech startup and an industry leader. To see what we've helped build so far, check out HiRoad.com.
Our Vision
At BlueOwl, we envision a world where data driven behavior fuels better lives. We started with the reinvention of insurance and a bold mission to create a data science powered platform that actually helps people become better drivers. We aspire to be the best in the business at identifying low-risk drivers by harnessing the power of data with an innovative technology stack.
It's a big goal, and that's where you come in. We're growing a world class team of data science, engineering, design, product, marketing and mobile technologists because we know that the key to success isn't just about nailing the technology—it's hiring the talented people who will help us make a quantifiable impact.
The Role
We're looking for an accomplished and well-rounded Senior Data Engineer who is comfortable navigating streaming data pipelines, data science services, and data warehouses. Over the course of your time with Blue Owl you will have the opportunity to develop streaming data pipelines that bring together data from multiple sources to evaluate insured risk, develop APIs that package data science models, and develop our organizational data warehouse to promote data driven decision processes.
Your day-to-day
Collaborate with cross-functional teams to understand data requirements and design optimal data models and schemas.
Work with technologies such as SQS, Kafka and rest services to expand BlueOwl's stream data processing pipelines.
Develop and implement data pipelines, integrating diverse data sources into Snowflake using appropriate ETL/ELT tools and techniques.
Implement data quality checks and data governance processes to maintain data accuracy, consistency, and compliance.'
Participate in building a highly usable, performant and secure data warehouse.
Document technical specifications, data flows, and system configurations for collaborative design and future reference.
About you
Bachelor's degree in Computer Science, Information Systems, or a related field.
8+ years experience in software development
3+ years experience in data warehouse development
Experience with Snowflake and DBT with ELT data pipelines
Experience with scheduling tools such as Airflow and building extensive data integrations
Deep background in data modeling techniques
Knowledge and experience with data governance practices
Extensive experience with SQL and databases such as Postgres
Experience working with rest services and APIs
Strong testing and data quality background
Strong software testing knowledge
Understanding of data science modeling processes and technologies such as pandas and scikit learn.
Strong communication and collaboration skills
Experience with streaming data ingestion and processing using tools like Kafka or AWS Kinesis.
Deep understanding of Python
Experience with AWS
Experience building scalable and resilient systems
Bonus Points
Extensive CI/CD experience
Strong familiarity with Kubernetes and Terraform
Salary: $200,000 to $300,000*
Important note: all offered salaries are based on many factors, including experience in a similar role and geographic location of the candidate.
Additional Details:
Benefits: We provide a wide variety of health, wellness and other benefits.These include medical, dental, vision, life insurance and supplemental income plans for you and your dependents, a Headspace app subscription, monthly wellness allowance and a 401(k) Plan with a company match.
Work from Home Equipment: Given our virtual environment— in order to set you up for success at home, a one-time payment of $2K will be provided to cover the purchase of in-home office equipment and furniture at your discretion. Also, our teams work with MacBook Pros, which we will deliver to you fully provisioned prior to your first day.
Paid Time Off: All employees accrue four weeks of PTO in their first year of employment. New parents receive twelve weeks of fully paid parental leave which may be taken within one year after the birth and/or adoption of a child. The twelve weeks is applicable to both birthing and non-birthing parent.
Personal and Professional Development: We're committed to investing in and helping our people grow personally and professionally. All employees receive up to $5000 each year for professional learning, continuing education and career development. All team members also receive Udemy subscriptions and access to multiple different coaching opportunities through BetterUp.
Location: We are a remote-first company for most positions so you may work from anywhere you like in the U.S, excluding U.S. territories. Occasional travel may be required for team meetings or company gatherings. Employees based in the San Francisco Bay Area or in Providence, Rhode Island may commute to one of our local offices as desired.
Hours: We maintain core meeting hours from 9AM - 3PM Pacific time for collaborating with team members across all time zones.
BlueOwl, LLC is an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
If you are a San Francisco resident, please read the City and County of San Francisco's Fair Chance Ordinance notice. https://sfgov.org/olse/sites/default/files/FCO%20poster2020.pdf
This role is employed by BlueOwl, LLC. BlueOwl, LLC is a separate company in the State Farm family of companies and is the solutions provider for the HiRoad Assurance Company.",#N/A,51 to 200 Employees,Company - Private,Insurance,Insurance Carriers,2016,Unknown / Non-Applicable
"Booz Allen Hamilton
4.2",4.2,"McLean, VA",Data Engineer,"Job Description
Location:
McLean,VA,US
Remote Work:
No
Job Number:
R0180224

Data Engineer
The Opportunity:
There’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need an experienced data engineer like you to help our clients find answers in their big data to impact intelligence community missions and plans.

As a big data engineer at Booz Allen, you’ll implement data engineering activities on some of the most mission-driven projects in the intelligence community. You’ll deploy and develop pipelines and platforms that organize and make disparate data meaningful.
Here, you’ll work with and guide a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll use your experience in analytical exploration and data examination while you manage the assessment, design, building, and maintenance of scalable platforms for your clients.
Work with us to use big data for good.
Join us. The world can’t wait.
You Have:
5+ years of experience designing and developing databases and applications within the intelligence community
Knowledge of available IC cloud systems and services
Ability to develop custom scripts, procedures, queries, and user interfaces for SQL databases
Ability to utilize large scale data flow and conditioning technologies to build production datasets for analytics purposes
Ability to develop entity relationship diagrams, data schemas, and data systems architecture
Ability to develop and maintain interfaces between data resources and analytics software applications
Ability to build scalable ETL/ELT workflows for reporting and analytics
Ability to create solutions within a collaborative, cross-functional team environment
TS/SCI clearance with a polygraph
Bachelor’s degree
Nice If You Have:
Experience with Python, SQL, Scala, or Java
Experience measuring performance against intelligence priorities
Experience designing, testing, and managing software tools to support assessment and metrics production on large, aggregated datasets
Experience with distributed data or computing tools, including Spark, Databricks, Hadoop, Hive, AWS EMR, or Kafka
Experience with data warehousing using AWS Redshift, MySQL, or Snowflake
Experience with Agile engineering practices
Clearance:
Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required.
Create Your Career:
Grow With Us
Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.
A Place Where You Belong
Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.
Support Your Well-Being
Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.
Your Candidate Journey
At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.
Compensation
At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.
Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.
Work Model
Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.
If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.
EEO Commitment
We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.","$119,550 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1914,$5 to $10 billion (USD)
"The Travelers Companies, Inc.
4.1",4.1,"Hartford, CT",Data Engineer I (SQL/ETL/AWS),"Who Are We?
Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it.
Job Category
Technology
Compensation Overview
The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards.
Salary Range
$102,600.00 - $169,200.00
Target Openings
1
What Is the Opportunity?
What Will You Do?
Build and operationalize complex data solutions, correct problems, apply transformations, and recommend data cleansing/quality solutions.
Design data solutions.
Analyze sources to determine value and recommend data to include in analytical processes.
Incorporate core data management competencies including data governance, data security and data quality.
Collaborate within and across teams to support delivery and educate end users on data products/analytic environment.
Perform data and system analysis, assessment and resolution for defects and incidents of moderate complexity and correct as appropriate.
Test data movement, transformation code, and data components.
Perform other duties as assigned.
What Will Our Ideal Candidate Have?
Bachelor’s Degree in STEM related field or equivalent
Six years of related experience
Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of software engineering practices.
The ability to deliver work at a steady, predictable pace to achieve commitments, decompose work assignments into small batch releases, and contribute to tradeoff and negotiation discussions.
Demonstrated track record of domain expertise including the ability to understand technical concepts and possess in-depth knowledge of immediate systems worked on.
Proven problem solving skills including debugging skills, allowing you to determine source of issues in unfamiliar code or systems and the ability to recognize and solve repetitive problems.
Strong verbal and written communication skills with the ability to interact with team members and business partners.
Leadership - Intermediate leadership skills with a proven track record of self-motivation in identifying personal growth opportunities.
What is a Must Have?
Bachelor’s degree or equivalent training with data tools, techniques, and manipulation.
Four years of data engineering or equivalent experience.
What Is in It for You?
Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment.
Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers.
Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays.
Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist.
Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice.
Employment Practices
Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results.

If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an
email
so we may assist you.

Travelers reserves the right to fill this position at a level above or below the level included in this posting.
To learn more about our comprehensive benefit programs please visit
http://careers.travelers.com/life-at-travelers/benefits/
.","$135,900 /yr (est.)",10000+ Employees,Company - Public,Insurance,Insurance Carriers,1853,$10+ billion (USD)
"R1 RCM, Inc.
3.4",3.4,Remote,Data Engineer III,"We are seeking a Sr. Data Engineer to join our Data Platform team. This role will report to the director of data platform and be involved in the planning, design, and implementation of our centralized data lake solution supporting analytics, products and applications across the company.
Qualifications:
To be successful in this role the candidate needs to have the following qualifications:
Deep knowledge of Scala and Spark
Experience with Databricks is preferred.
Deep knowledge of modern orchestration frameworks such as Apache airflow
Experience working with SQL and NoSQL database systems.
Experience with cloud environments (Azure Preferred)
Experience with acquiring and preparing data from primary and secondary disparate data sources.
Experience with agile project management methodology
Healthcare industry experience preferred, including exposure to different EMR systems, revenue cycle management.
Knowledge of healthcare data standards such as HL7, FHIR, EDI X12 is a plus but is not required.
Responsibilities:
Be part of an engineering team in building data adaptors to expedite the data onboarding process from various health systems.
Work with product management and business analysts on design reusable and configurable data orchestration pipelines.
Work with data specialist in develop and design data transformation to standardize the data model and support data enrichment activities.
As a subject matter expert, hosts information sharing session with teams within data platform or larger R1 organization.
Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests.

Our associates are given valuable opportunities to contribute, to innovate and create meaningful work that makes an impact in the communities we serve around the world. We also offer a culture of excellence that drives customer success and improves patient care. We believe in giving back to the community and offer a competitive benefits package including:
Comprehensive Medical, Dental, Vision & RX Coverage
Paid Time Off, Volunteer Time & Holidays
401K with Company Match
Company-Paid Life Insurance, Short-Term Disability & Long-Term Disability
Tuition Reimbursement
Parental Leave
R1 RCM Inc. (“the Company”) is dedicated to the fundamentals of equal employment opportunity. The Company’s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person’s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.
If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.
CA PRIVACY NOTICE: California resident job applicants can learn more about their privacy rights California Consent",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2003,Unknown / Non-Applicable
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Procter & Gamble
4.1",4.1,"Cincinnati, OH",Data Engineer – Retail Analytics,"Job Location
Cincinnati
Job Description
IT at P&G:
Information Technology at Procter & Gamble is where business, innovation and technology integrate to create a competitive advantage for P&G. Our mission is clear - we deliver IT to help P&G win with consumers. As a P&G IT professional your expertise will be applied to diverse business problems delivering innovative, business models and capabilities built with technology. Whether your role is to create an IT innovation strategy for a business, protect our critical information systems and assets, or build a completely new way of operating, your technical knowledge will be recognized and rewarded. Your career in IT at P&G will build you through growing your technical, leadership, and influence skills; expand your perspective via experiences across multiple businesses; and cultivate depth of expertise in areas like Engineering, Analytics, Product Management, Security, etc.,

What we offer is an exciting and diverse set of opportunities to solve problems that come with being one of the largest consumer goods companies in the world. You have many interests, and our scale enables you to explore these interests and apply your problem-solving skills.

Visit http://www.pg.com to learn more.

We are currently looking for a Data Engineer to join our industry leading Data & Analytics team. Do you have what it takes to join our technical team and bring data to life? Are you able to take abstract business needs and turn those into actionable data pipelines and analytics platforms to answer business questions?
In this role, you would assemble large, complex data sets which meets functional and non-functional business requirements. Data Engineers partners with data asset managers and architects to ensure technical solution provides data which is fit for use and in line with architecture blueprints.
Responsibilities:
Designs, develops, and implements data and analytics cloud-based analytics platforms (DAP) and pipelines which acquire, cleanse, transform and publish data.
Leverages coding standards and best practices to ensure efficient and re-usable services and components
Develop and support data pipelines, warehouses, data models, and reporting systems to tackle business opportunities
Partner with business stakeholders, upstream infrastructure platform teams, and downstream data consumers to understand and translate business requirements into technical design
Build & operate efficient solutions in the Azure Stack
Lead and continuously improve end-to-end service delivery including strategic vendor management, operations, and product innovation.
Job Qualifications
Hands-on experience with the Azure Stack including computing services and data warehouses (Azure Data Factory, Azure Databricks)
Familiarity or experience with ETL in SQL and NoSQL data stores
Familiarity or experience in coding languages like R and Python
Familiarity or experience leading IT products through the full product lifecycle from design to development to operations
Familiarity or experience in one or more modern application development framework methods and tools (e.g. Disciplined Agile, Scrum).
Familiarity or experience with a range of data engineering best practices for development including query optimization, version control, code reviews, and documentation
Familiarity with end-user visualization tools like Power BI
The ability to build relationships and work in diverse, multidisciplinary teams
Excellent communication skills with business intuition and ability to understand business systems, versatility, and willingness to learn new technologies on the job
Pay Range: $85-$115K
Compensation for roles at P&G varies depending on a wide array of non-discriminatory factors including but not limited to the specific office location, role, degree/credentials, relevant skill set, and level of relevant experience. At P&G compensation decisions are dependent on the facts and circumstances of each case. Total Rewards at P&G include salary + bonus (if applicable) + benefits. Your recruiter may be able to share more about our total rewards offerings and the specific salary range for the relevant location(s) during the hiring process.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Job Schedule
Full time
Job Number
R000080323
Job Segmentation
Experienced Professionals (Job Segmentation)
Starting Pay / Salary Range
$100,000.00 - $132,000.00 / year","$116,000 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1837,$10+ billion (USD)
"AF Group
4.2",4.2,United States,IT Data Engineer III,"The IT Data Engineer III is responsible for designing, developing, and supporting the end-to-end data ecosystem to support the organization. This position is responsible for supporting data-driven capabilities throughout the organization, including areas such as business intelligence, reporting, data science, and data analytics. The IT Data Engineer III will work with the business and internal teams to prepare complex data analyses that help solve client problems and deliver significant measurable impact.
RESPONSIBILITIES/TASKS:
Hands on development of frameworks and applications for data processing.
Analyze and evaluate data in relational databases and unstructured forms of data.
Develop interactive dashboards, reports, and analysis templates.
Implement and support a platform that can provide ad-hoc access to large datasets.
Responsible for providing innovative operational solutions and best practices.
Collaborate with teams/partners to improve the overall operational maturity of the data ecosystem.
Troubleshoot and resolve daily operational issues.
Design and implement an Enterprise Data Store consisting of a Landing Zone, and subject specific Staging and Mart databases using Replication, SSIS, T-SQL and Stored Procedures.
Design, code, test, and aggregate results from SQL queries to provide information to business users.
Work with Project Manager in developing and executing project plans within the assigned schedule and timeline utilizting SAFe Agile best practices.
Determine Business Intelligence and Data Warehousing solutions to meet business needs.
Manage the company’s Enterprise Data Store including:
Validating automated data feeds into the database.
Maintain validation processes to meet auditing requirements.
Ensure mapping tables and stored procedures are accurate and up to date.
Ensure outputs from the database are complete and accurate and meet the needs of the reporting team
Ensure calculations performed within the SQL database are accurate.
Ensure accurate documentation and models are being maintained.
Consistently improve, optimize, and maintain semantic models to achieve peak performance across the entire analytics platform.
Work closely with business units to gather requirements, draft prototypes, and document changes until a final version is accepted and signed off on.
Lead data mapping and analysis efforts to build a better view of our internal data assets and make recommendations on how and where to reduce redundancy.
Work closely with strategic projects as well as coaches development teams on defined standards and methods for data usage and propagation.
Identify and resolve data reporting issues in a timely fashion.
This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.
EMPLOYMENT QUALIFICATIONS:
EDUCATION :
Bachelor’s degree in computer science, mathematics, analytics, or equivalent discipline. Continuous learning, as defined by the Company’s learning philosophy, is required. Certification or progress toward certification is highly preferred and encouraged.
EXPERIENCE:
Seven years in a Data Warehousing environment is required, including three years of SQL (T-SQL), SQL Server, SSIS, ETL, and data integration experience required. Experience with Snowflake, BI tools, and reporting platforms (e.g. PowerBI or Tableau) preferred. Experience using Cloud (AWS or Azure) or Snowflake and insurance industry experience is a plus.
SKILLS/KNOWLEDGE/ABILITIES (SKA) REQUIRED:
Knowledge of data warehouse concepts, dimensional data modeling, and complex interdependent SQL processes.
Knowledge of SAFe Agile development practices.
Skilled in information delivery concept, design, and development using modern reporting tools.
Experience working in a large data warehouse environment with complex data models.
Strong proficiency in SQL, Power BI, and SSRS.
Excellent oral and written communication skills required, with demonstrated ability to lead a collaborative conversation with IT and business leaders in a technical and non-technical context.
Ability to analyze and model normalized and dimensional data structures.
Excellent problem solving, and critical thinking skills.
Ability to work independently and collaboratively with cross-functional teams.
Ability to manage multiple and competing projects/priorities.
Outstanding communication skills.
Cross group collaboration and interpersonal skills.",#N/A,1001 to 5000 Employees,Company - Private,Insurance,Insurance Carriers,1912,Unknown / Non-Applicable
"Coveros, Inc.
3.4",3.4,"Fairfax, VA",Data Engineer,"A Great Place to Share Your Passion and Make a Difference
Coveros helps organizations modernize their software development process by embracing agility, while integrating application security and software quality into the software lifecycle. We provide consulting, coaching, and learning opportunities in Agile, DevOps, AppSec, and Test Automation to enterprises, teams, and individuals. We aim to be Trusted Advisors to our clients who are undergoing change.
Culture at Coveros
As a remote-first company, we provide a stimulating, friendly, and casual work environment, where we live our core values of Client Focused Delivery, Openness, Shared Success, and Building Strong Relationships. In an atmosphere of continuous growth and learning, we invite employee input and employ active mentoring.
Coveros is an equal opportunity employer, dedicated to a policy of non-discrimination in employment on any basis including age, sex, color, race, creed, national origin, religion, marital status, sexual orientation, political belief, or disability.
The Opportunity
Coveros employees share a passion for helping organizations advance and accelerate their software development and security processes. We celebrate great work and teammates who consistently give their best. Our remote team of collaborative experts is expanding and adding an experienced, quality-obsessed Data Engineer as its newest member.
As an exceptional data engineer, you will fulfill a core position on our consulting team. Through your dedication and knowledge, you will help clients replace time-consuming, manual processes in order to make informed, real-time, intelligent decisions.
For a skilled and dedicated data nerd who abhors mediocrity, this opportunity positions you to lead the team in discovering truth and finding meaning in data. An ideal addition to our team is a hands-on engineer who is proficient in data management and governance standards. Equally important, we seek someone with strong interpersonal skills who is comfortable working cross-functionally across internal teams as well as directly with end users and client platform SMEs.
A curious and eager problem solver will thrive in our environment where we value the delivery of high-quality data solutions. You shine when figuring out complex problems and providing smart, simple solutions to them. And always, while multiple answers to a problem may exist, you capably lead the team through constructive dialogue to implement the best path forward.
Qualifications
US Citizenship is required – Due to the nature of this role supporting U.S. government organizations, individuals who are not U.S. Citizens will not be considered.
Required
Bachelor's degree in Computer Science, Mathematics or related technical field
3-5 years of experience in programmatically transforming data
RDBMS experience
Advanced SQL programming experience
Python programming experience
Knowledge and use of Apache Spark
Proficient use of common data formats such as CSV, XML, and JSON
Strong analytical ability and attention to detail
Ability to work independently with little supervision
A drive to create sustainable solutions that solve hard problems
Nice-to-Have
Experience using Amazon Web Services
Experience with OpenSearch
Experience automating ETL pipelines
Hands-on knowledge working with large amounts (multiple terabytes) of data
Experience in (or exposure to) the nuances of a startup or other entrepreneurial environment
Any specific experience in MLOps is a plus!
Responsibilities
Define and lead the data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage.
Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository.
Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison, and classification.
Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts.
Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency.
Work across functional teams to understand advanced statistical, machine learning, and text processing models and incorporate them into the existing data engineering infrastructure.
Actively collaborate with the DevOps team to automate processes where possible.
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures and, using non-technical language, articulate techniques and results.
We firmly believe that past performance is the best indicator of future performance. If you thrive in a fast-paced environment, have a bias toward action, and care about solving technical problems in the national security domain, apply today for consideration.
Coveros is a melting pot of seasoned IT and business professionals from Fortune 500 and leading consulting companies who deliver high value on challenging client engagements. We hire great people and provide room and support for employees' professional growth. For talented computer scientists and software engineers who share our passion for software, joining Coveros provides an opportunity to work alongside and to learn from brilliant, technical software engineers.
We believe that employees are our greatest asset. Our business model and benefits package reflect that belief.
Competitive base salaries
Company-wide profit sharing plan
401K with matching percentage
Comprehensive health benefits, including dental and vision
Generous paid time off and holidays plan
Basic Life & Personal Accident Insurance and Disability Insurance
Voluntary Life and Personal Accident Insurance
Tuition Reimbursement, plus comprehensive competency-based online skill development training programs
Adoption Assistance
Apply today and move toward a Coveros career where management values you and actively looks to help you advance your skills.
By submitting your application, you are also agreeing to receive future company news, offers, and product communications from Coveros/TechWell. You may unsubscribe at anytime.","$94,726 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Software Development,2008,Unknown / Non-Applicable
"S&P Global
4.1",4.1,"Clinton, MS",Data Engineer - AI/ML (Virtual),"Job Description
This is a software development role to work with the stakeholders to develop AI models that will help the business to take smarter decisions. The role is for a software developer for AI/ML initiative. This role will support to an existing corporate finance IT team including cloud solutions, and digital platforms. This role also requires excellent decision-making, interpersonal, and communication skills.

Duties and Responsibilities
Implement machine learning algorithms
Collect and clean data
Evaluate the performance of AI/ML models
Work closely with the stakeholders to understand the business needs and develop solutions around these needs
Develop and deploy the AI models
Daily scrum update
Work closely with QA team to fix bugs
Basic understanding of automation

The ideal candidate possesses:
Bachelor’s degree from an accredited college or university, with major course work in computer science, information technology, or related field.
Master’s or advanced education is preferred.
3-5 years of experience in software development and testing
Experience with programming languages such as Python or Java is a plus.
Strong problem-solving skills.
Ability to work independently and as part of a team.
Basic understanding of machine learning
Passionate about learning emerging technologies

S&P Global states that the anticipated base salary range for this position is $60,000 - $90,000 USD. Base salary ranges may vary by geographic location.

This role is eligible to receive additional S&P Global benefits. For more information on the benefits we provide to our employees, visit https://spgbenefits.com/ .

Flexible Working
We pride ourselves on our agility and diversity, and we welcome requests to work flexibly. For most roles, flexible hours and/or an element of remote working are usually possible. Please talk to us at interview about the type of arrangement that is best for you. We will always try to be adaptable wherever we can.

Return to Work
Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative (link to career site page when available), we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace.

Grade/Level ( relevant for internal applicants only ): 9

About Company Statement: S&P Global delivers essential intelligence that powers decision-making. We provide the world's leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, you'll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.

EEO Statement:
S&P Global is an equal opportunity employer committed to making all employment decisions without regard to race/ethnicity, gender, pregnancy, gender identity or expression, color, creed, religion, national origin, age, disability, marital status (including domestic partnerships and civil unions), sexual orientation, military veteran status, unemployment status, or any other basis prohibited by federal, state or local law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

-----------------------------------------------------------

Equal Opportunity Employer
S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to: EEO.Compliance@spglobal.com and your request will be forwarded to the appropriate person.

US Candidates Only: The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf describes discrimination protections under federal law.

----------------------------------------------------------- IFTECH202.1 - Middle Professional Tier I (EEO Job Group)

Job ID: 289943
Posted On: 2023-09-18
Location: Virtual, New Jersey, United States","$75,000 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Research & Development,1860,$10+ billion (USD)
"Nuro
4.0",4.0,"Mountain View, CA","Software Engineer, ML Data Tools and Pipeline","Who We Are
Nuro exists to better everyday life through robotics. The company's custom electric autonomous vehicles are designed to bring the things you need—from produce to prescriptions—right to your home. Nuro's autonomous, goods-focused solution can give you valuable time back and more freedom to do what you love. This convenient, eco-friendly alternative to driving has the potential to make streets safer and cities more livable.
About the Role

Nuro takes a machine-learning-first approach to autonomous driving technology. In an ML-first system, the overall system performance depends heavily on the quantity and diversity of its training and evaluation data.
The ML Data Tools and Pipeline team develops dataset management and annotation software. We are responsible for developing manual labeling tools and automated labeling pipelines to annotate a variety of sensor data wih excellent quality and low cost.
The end result is a scalable suite of tools that enables every ML researcher at Nuro — across every discipline from computer vision to reinforcement learning — to generate exactly the right dataset to improve their models.
About the Work
Architect fully automated labeling pipelines that leverage the intelligence of ML models, including both in-house and large-scale pretrained models
Develop manual and ML-assisted labeling tools to annotate image, lidar, audio, text, and other training data with low cost and great accuracy
Engineer annotation processing pipelines that handle petabytes of data with excellent performance and fault tolerance.
Design backend APIs to enable ML developers to perform rich queries and experimentation on their datasets of interest
Collaborate with operations teams (both in-house and outsourced) to understand operation specialists' needs and deliver easy-to-use products.
Collaborate with ML engineers from mapping, perception, prediction, and planning teams to understand the onboard system architecture and how training data fits in.
About You

You have 2+ years of software development experience in a language such as C, C++, Rust or Go
You're deeply technical with a scrappy mindset. You can jump into any system, quickly understand what's going on, and make changes to keep the project moving.
You are customer-obsessed: passionate about delivering a great product that solves problems for client teams.
You bring up those around you through mentorship and feedback. You're always on the lookout for ways to improve our team's products, people, and processes.
You collaborate effectively with colleagues from a wide range of disciplines and backgrounds. You feel comfortable navigating situations with many stakeholders and requirements to consider.
Bonus Points

Past experience developing internal tools for autonomous driving, robotics, data annotation, crowdsourcing, content moderation, trust & safety, computer-aided design, and/or geospatial information.
Past experience with large scale data pipelines or data migration.

At Nuro, your base pay is one part of your total compensation package. For this position, the reasonably expected pay range is between $138,225 and $207,575/year for the level at which this job has been scoped. Your base pay will depend on several factors, including your experience, qualifications, education, location, and skills. In the event that you are considered for a different level, a higher or lower pay range would apply. This position is also eligible for an annual performance bonus, equity, and a competitive benefits package.
At Nuro, we celebrate differences and are committed to a diverse workplace that fosters inclusion and psychological safety for all employees. Nuro is proud to be an equal opportunity employer and expressly prohibits any form of workplace discrimination based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, veteran status, or any other legally protected characteristics.","$172,900 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Computer Hardware Development,2016,Unknown / Non-Applicable
"Swirlds Labs
4.0",4.0,"Dallas, TX",Senior Software Engineer - Platform Data,"Are you bored with traditional software performance standards that don't require any creativity to achieve? Are you ready to put your knowledge of data structures, databases, and algorithms to the test in a extreme performance environment where microseconds matter? Join the Platform Data team at Swirlds Labs and see how far you can push the limits.
Role Description
As a member of the Platform Data team, you will work directly with the custom database designed for extreme performance that backs Hedera Hashgraph. You will be responsible optimizing consensus node data storage techniques for both scalability and performance. Day to day activities include:
Designing and implementing in-memory and on-disk data structures
Analyzing and improving data flow and back pressure mechanisms
Identifying and eliminating bottlenecks
Innovating, designing, implementing, and testing new approaches to improve speed and scalability
Required Skills/Experience
Java concurrency
Data structures & algorithms
Database internal design
Java memory management
Data IO
Strong problem solving skills
Desired Skills/Experience
Merkle Trees
Experience building a database from scratch
On disk data structures
Java garbage collectors (ZGC, Shenandoah, etc.)
Performance optimization
JMH / Custom profilers","$130,000 /yr (est.)",Unknown,Company - Public,Information Technology,Software Development,#N/A,Unknown / Non-Applicable
"UNITED PARCEL SERVICE
3.5",3.5,"Atlanta, GA",FP&A – Data Modeling & Analytics Engineer – 20E,"Before you apply to a job, select your language preference from the options available at the top right of this page.
Explore your next opportunity at a Fortune Global 500 organization. Envision innovative possibilities, experience our rewarding culture, and work with talented teams that help you become better every day. We know what it takes to lead UPS into tomorrow—people with a unique combination of skill + passion. If you have the qualities and drive to lead yourself or teams, there are roles ready to cultivate your skills and take you to the next level.
Job Description:
Job Description:
This position develops and maintains costing applications and related data for the Finance Planning & Analytics (FP&A) Decision Support Department. He/She researches and resolves SQL code and data issues relating to UPS’s internal accounting systems and provides technical documentation of accounting system components. This position tests data values to provide solutions for incorrect database values and processes. He/She creates scripts for data values to ensure proper design, maintenance, and functionality of database values. This position updates UPS’s tracking systems to document database changes.
Responsibilities:
Analyzes issue logs against existing code to resolve current coding issues.
Analyzes and summarizes data to offer insight to upper-level management.
Research scope of coding issues to determine root causes.
Documents coding solutions to ensure correct implementation of the coding process.
Writes Standard Query Language (SQL) scripts to implement data changes to tracking log.
Analyzes SQL database objects to maintain optimum functionality of the databases.
Solves system problems by identifying and applying resolutions to ensure proper system operations.
Analyzes system issues to suggest new system processes.
Executes system tests to ensure system issues are resolved.
Designs new ETL/ELT processes to transform data for managerial reporting purposes
Management and coordination of offshore team members

Qualifications:
Bachelor’s Degree or International equivalent - Required
Bachelor’s Degree or International equivalent in Management Information Systems, Data Analytics, Industrial Engineering, Computer Science, Finance, or a related field - Preferred
Proficiency in SQL and experience with relational database management systems (e.g., GCP BigQuery, Oracle, SQL Server)
Strong understanding of database design principles and best practices
Experience with ETL/ELT processes and data integration
Experience demonstrating basic knowledge of database design principles
Intermediate understanding of Microsoft Excel functions
Quick learner with a strong attention to details
Basic finance and accounting comprehension – Preferred
Foundational knowledge of data visualization tools (e.g., Microsoft Power BI, Tableau, Looker) – Preferred
Experience with Python - Encouraged
Employee Type:
Permanent
UPS is committed to providing a workplace free of discrimination, harassment, and retaliation.
Other Criteria:
Employer will sponsor visas for specific positions. UPS is an equal opportunity employer. UPS does not discriminate on the basis of race/color/religion/sex/national origin/veteran/disability/age/sexual orientation/gender identity or any other characteristic protected by law.
Basic Qualifications:
Must be a U.S. Citizen or National of the U.S., an alien lawfully admitted for permanent residence, or an alien authorized to work in the U.S. for this employer.","$119,985 /yr (est.)",10000+ Employees,Company - Public,Transportation & Logistics,Shipping & Trucking,1907,$10+ billion (USD)
"ASK Consulting
3.5",3.5,United States,Data Engineer V - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 20 October 2023
Referral: 231789@accuick.com
""All candidates must be directly contracted by ASK Consulting on their payroll and cannot be subcontracted. We are unable to provide sponsorship at this moment"".
Job Description:
Duties: The Enterprise Data Platform team is looking for a Senior Data Engineer who has experience with building a Data Platform on top of a Cloud Data Warehouse. You will be working closely with Privacy and Security teams to improve the security and privacy of Data in Snowflake.
In this role, you will also advise other Data Analysts and Data Engineers from the Business teams on the best practices for handling data and deriving insights using Snowflake. You will gradually become the Subject Matter Expert on Snowflake and also help build out the Modern Data Stack.
What you'll do:
Build Scripts in Python to Implement privacy and security requirements on Snowflake
Build Airflow operators in Python to ingest data and trigger transformations on Snowflake
Define and advocate the best practices for storing and analyzing data inside Snowflake
Become a Subject Matter Expert and advocate for Enterprise Data Platform
Skills:
Strong skills in Python, SQL & Snowflake.
Experience with Building scripts in Python for managing Data Warehouse
Experience with any Cloud Data Warehouse either as an Administrator or a Developer
Experience working on privacy and security requirements of a Cloud Data Warehouse
About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With 5 nationwide offices, two global delivery centers, and employees in 42 states-ASK Consulting connects people with amazing opportunities
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.",#N/A,501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Microsoft
4.3",4.3,United States,Senior Data Software Engineer,"Microsoft Cloud Operations + Innovation (CO+I) is the team behind building the Microsoft cloud. Within CO+I, the Datacenter Planning & Execution Engineering (DPXE) team is responsible for delivering datacenter capacity for Microsoft’s cloud business. We have a portfolio of complex, multi-disciplinary, multi-million, multi-year datacenter construction and lease projects with specific safety, quality, schedule, and cost goals.
The DPX Engineering team is responsible for architecting, designing, and building the next generation of connected systems and tools using microservices architecture or ERP platforms to help manage and support critical business functions such as Supply Chain, Cost, Schedule, Networking, Commissioning, Safety, Planning etc. in a real time manner. The team has a charter to deliver building robust automation for these functions through well engineered systems and at the same time design and build the next gen, ML based, recommendation engine to enable cost and schedule modeling, supply planning, execution planning etc. while integrating with the bigger CO+I ecosystem.
Our Systems Engineering team delivers innovative solutions to address the automation needs to scale our delivery capabilities. We are looking for a Senior Data Software Engineer to deliver automation capabilities that power the long-range execution planning efforts, drive workflow improvements, and build solutions to assist in the delivery of large-scale data centers through efficient management of cost and schedule.
Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.
In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.
Responsibilities
Perform End to end Software development life cycle activities (Requirement gathering, fit-gap analysis, system configuration & customization, cutover, Go-live, etc.)
Resolve complex system integration challenges working with other members of the team and external teams.
Collaborate with stakeholders and demonstrate features developed in an Agile environment.
Share learnings and code assets developed with the CO+I engineering team.
Design and build robust and scalable big data infrastructure to support our data needs.
Optimize and tune data pipelines for performance and reliability.
Develop and implement data quality and validation processes to ensure accuracy and completeness of data.
Build and maintain data visualization and reporting tools to enable data-driven decision making.
Stay up to date with the latest big data technologies and trends and evaluate their applicability to our organization.
Qualifications
Required/Minimum Qualifications
Bachelor's Degree in Computer Science, or related technical discipline AND 4+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR equivalent experience.
1+ years experience with technical implementation knowledge in Azure Synapse, Azure Data Factory, Azure Data Catalog/Purview, Azure Analysis Service, SQL Datawarehouse, Kusto, Data Analysis, Azure Data lake, Azure Databricks, Power BI.
1+ years experience building and shipping production grade software or services.
1+ years experience building and operating online services and fault-tolerant distributed systems.
Other Requirements
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to, the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.
Additional or Preferred Qualifications
Bachelor's Degree in Computer Science or related technical field AND 8+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR Master's Degree in Computer Science or related technical field AND 6+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python
OR equivalent experience.
Technical implementation knowledge in Azure Synapse, Azure Data Factory, Azure Data Catalog/Purview, Azure Analysis Service, SQL Datawarehouse, Kusto, Data Analysis, Azure Data lake, Azure Databricks, Power BI.
Experience working through the full product cycle from initial design to rapid production deployment.
Experience working in construction/capital projects and integration of supply chain activities into Engineering, Procurement and Construction
Experience creating and shipping V1 products using modern development practices.
Experience using agile methodologies and/or test-driven development (TDD).
Experience with shipping software products across multiple platforms/devices.
Ability to incorporate and understand the needs of our diverse customer base, including customers using assistive technology.

Software Engineering IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.

Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

#COICareers
#COIEngCareers
#COIE_DPXEcareers
Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.","$165,200 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1975,$10+ billion (USD)
"Zscaler
4.0",4.0,"San Jose, CA",Sr. Data Scientist / ML Engineer,"Company Description

Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The Zscaler Zero Trust Exchange is the company’s cloud-native platform that protects thousands of customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.
With more than 10 years of experience developing, operating, and scaling the cloud, Zscaler serves thousands of enterprise customers around the world, including 450 of the Forbes Global 2000 organizations. In addition to protecting customers from damaging threats, such as ransomware and data exfiltration, it helps them slash costs, reduce complexity, and improve the user experience by eliminating stacks of latency-creating gateway appliances.
Zscaler was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. Zscaler’s purpose-built security platform puts a company’s defenses and controls where the connections occur—the internet—so that every connection is fast and secure, no matter how or where users connect or where their applications and workloads reside.

Job Description

Our team’s use cases include but are not limited to threat detection, policy recommendation, LLM-powered applications, malware detection, content classification, anomaly detection, and AIOps (advanced networking diagnosis). These various use cases give you the opportunity and challenges to experience multiple machine learning algorithms and tools.
You will design and create machine learning models to provide faster and more effective ways to address cloud security, cloud operations, and cloud intelligence use cases.
You might not be an expert in every stage of a Machine Learning project, but you should have interests and curiosity in various parts ranging from the data to the model’s business impact.

Qualifications
4+ years of experience as a Machine Learning Engineer or Data Scientist
Experience with Python (pandas, sklearn, pytorch) and SQL
Experience with feature engineering, model evaluation and model error analysis
Experience with Large Language Models (LLMs)
Master's Degree in Computer Science/Engineering required, data science concentration is a plus; PhD is preferred
Passion for leveraging ML/AI to solve real-world business problems (better security and better business results)
Excellent interpersonal, technical, and communication skills
Good business sense and customer obsession
Ability to learn, evaluate, and adopt new technologies fast
Ability to lead and execute projects from start to finish
Solid computer science foundation
Additional Preferred Skills
Prompt engineering and fine tuning Large Language Models (LLMs)
Graph Neural Networks/Knowledge Graphs
Experience with unsupervised learning (clustering), and evaluating unsupervised models
Experience with active/few-shot learning
Experience with logs analysis/logs mining
Research Experience/Publications
Experience with various public cloud services (such as AWS, Google, Azure) and ML automation platforms (such as Kubeflow).
Experience with various program languages such as (Py)Spark.
Good understanding of operating systems and distributed systems.
Familiarity with networking and networking security .

Additional Information

All your information will be kept confidential according to EEO guidelines.
The base salary range for this full-time position is $130,00 to $160,000 + bonus + equity + benefits.
Zscaler’s salary ranges are benchmarked and are determined by role and level. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations and could be higher or lower based on a multitude of factors, including job-related skills, experience, and relevant education or training.
What You Can Expect From Us:
An environment where you will be working on cutting edge technologies and architectures
A fun, passionate and collaborative workplace
Competitive salary and benefits, including equity
Why Zscaler?

People who excel at Zscaler are smart, motivated and share our values. Ask yourself: Do you want to team with the best talent in the industry? Do you want to work on disruptive technology? Do you thrive in a fluid work environment? Do you appreciate a company culture that enables individual and group success and celebrates achievement? If you said yes, we’d love to talk to you about joining our award-winning team.

Additional information about Zscaler (NASDAQ: ZS ) is available at https://www.zscaler.com.
Zscaler is proud to be an equal opportunity and affirmative action employer. We celebrate diversity and are committed to creating an inclusive environment for all of our employees. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex (including pregnancy or related medical conditions), age, national origin, sexual orientation, gender identity or expression, genetic information, disability status, protected veteran status or any other characteristics protected by federal, state, or local laws.
Zscaler is committed to providing reasonable support (called accommodations or adjustments) in our recruiting processes for candidates who are differently abled, have long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support. If you need support, please contact us by sending an email to accommodations@zscaler.com. This email address is used specifically for accommodation requests only, and resumes, CV's, or questions other than accommodations will not be replied to or accepted.","$135,570 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2008,Unknown / Non-Applicable
"Vanguard
3.7",3.7,"Charlotte, NC","Data Engineer, Senior Associate","In this role, the Application Engineer will be part of identity and access management data management program. This program includes implementing technical enhancements within various groups in IAM and building a data lake, ingesting data from various sources and turning data insights into products with actionable outcomes. They will work in a fast-paced agile environment and deliver quality code under the guidance of technical lead. The application engineer will be involved in various aspects of application implementation and will work with the team on a daily basis. The team comes together daily and will share what they did, what they plan to do and any blockers.
The Application Engineer:
1. Provides entry level system analysis, design, development, and implementation of applications and databases.
2. Translates technical specifications into code for new or enhancement projects for internal clients. Writes programs, develops code, tests artifacts, and produces reports. Employs software development techniques to implement tests that support automation.
3. Elevates code into the development, test, and production environments on schedule. Provides follow up production support.
4. Learns and follows software development methodology. Learns and follows development architecture standards.
5. Participates in design, code, and test inspections throughout the life cycle to identify issues. Participates in systems analysis activities.
6. Learns client business functions and technology needs. Learns Vanguard's tools, technologies, and applications/databases, including those that interface with business area and systems.
7. Learns and complies with Information Technology and Information Security policies and procedures.
8. Participates in special projects and performs other duties as assigned.
Skills
Python and SQL experience
Knowledge of AWS Services like Postgres, Data Migration Services, Athena, Lambda, SNS, SQS, S3, CloudFormation, CloudWatch etc
What it takes
Minimum of two years related work experience, with at least one year of development experience.
Undergraduate degree or equivalent combination of training and experience.
Special Factors
Sponsorship
Vanguard is offering visa sponsorship for this position.
About Vanguard
We are Vanguard. Together, we’re changing the way the world invests.
For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.
We want to make success accessible to everyone. This is our opportunity. Let’s make it count.
Inclusion Statement
Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”
We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.
When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose.
Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.
How We Work
Vanguard has implemented a hybrid working model for the majority of our crew members, designed to capture the benefits of enhanced flexibility while enabling in-person learning, collaboration, and connection. We believe our mission-driven and highly collaborative culture is a critical enabler to support long-term client outcomes and enrich the employee experience.","$95,598 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Investment & Asset Management,1975,Unknown / Non-Applicable
"Deloitte
4.0",4.0,"Rosslyn, VA",Data Engineer,"Data Engineer

Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client's most complex business problems. Join our team and play a key role in helping to design our clients' roadmap to the future and help transform the Federal marketplace.

Work you'll do

The Data Analytics Architect will have overall responsibility of planning how work within different teams will integrate into one solution. The Data Analytics Architect will also have overall responsibility of being the primary representative on all architecture matters and the leading member of the Architecture Team. The Architect will:
Work closely with various software development team(s) to migrate and architect data to meet client needs
Work directly with clients to validate migrated data
Work with Agile development teams to understand changes and their impacts towards data migration efforts
Leading developers, managing database administrators' workload and activities, among other tasks.
Create and manage schedules for data management (e.g. migration, integration, etc.) efforts
Build processes and scripts required to transform and stage data necessary to develop products and analyses


The team

Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, & local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.

The GPS Analytics and Cognitive (A&C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.

Qualifications

Required:

Must have an active Top Secret clearance

2+ years of hands-on experience with ETL/data pipeline development experience, leveraging industry-standard tools, ideally Informatica

2+ years of experience working with relational databases and data lakes, with an emphasis on data warehousing, performance tuning, and analytics use cases
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.


Preferred:

Experience integrating them into custom web applications

Data modeling and solution design experience

Familiarity programming in languages commonly used for data management and data science/statistics, such as Python

A general interest in relevant emerging technologies such as cloud-native services, and a constant thirst to further your own technical abilities

Experience working in an Agile development environment

Hands-on experience with full suite of software lifecycle tools (Confluence, Jira, Stash, Jenkins, Artifactory, etc.)","$103,922 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,1850,$10+ billion (USD)
#N/A,#N/A,"Atlanta, GA",#N/A,#N/A,"$123,449 /yr (est.)",1001 to 5000 Employees,Company - Private,Insurance,Insurance Agencies & Brokerages,2000,Unknown / Non-Applicable
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Novo Nordisk
4.3",4.3,"Lexington, MA",Senior Engineer I - Real World Data - Artificial Intelligence/Machine Learning (AI/ML),"About the Department
The AI and Analytics Team is part of Novo Nordisk’s Data Science division, where we apply sophisticated algorithms and machine learning techniques to some of the hardest problems in the discovery and development of new healthcare solutions. By leveraging a blend of scientific, problem-solving, and quantitative skills, we provide superior data insights that empower Novo Nordisk to further develop and deliver life-changing treatments. We work in multidisciplinary teams with strong collaboration across all areas of the organization and engage in external collaborations to ensure access to cutting edge research and technology.

We believe in the value of a diverse and inclusive culture. Together, we build and grow talent to ensure the development of new solutions. The team is comprised of collaborative, diverse and passionate people who have a true sense of pride in their work. We are committed to helping each other grow, and we are driven by the opportunity to make a difference in the lives of people living with chronic disease.

The Position
As a technical expert in their specialty within Novo Nordisk, the Senior Engineer will contribute to the research team’s effort towards exploring and creating new technology and being a world leader in the Data Engineering role. The Data Solutions Engineer will bring elements of appropriate data architecture and engineering, together with the infrastructure teams to translate data science solutions into highly available, scalable, reusable, consistent, secure and enterprise enabled systems and platforms, specifically in the applications of AI and Machine Learning (ML) applications. Moreover, the Sr. Data Engineer will contribute to the development, validation, and deployment of Artificial Intelligence/Machine Learning (AI/ML) algorithms and models, and work closely with other engineers to build AI/ML-fueled products.

Relationships
The Senior Solutions Engineer will report to the head of the related research area. Internal partners include data scientists, specialists, ML Ops engineers, software developers, system engineers, designers, IT professionals, technology scouts & partnership developers, and other functions across US and Denmark.

Essential Functions
Generates and matures relevant ideas, concepts, and products that bring value to patients and the future Novo Nordisk business.
Lead engineering efforts across multiple projects of varying complexities
Work with various data science, ML, AI, imaging, bioinformatics, real-world evidence, and other research teams to build modern data-driven enterprise-ready solutions
Interface with business partners to lead architecture and development of enterprise cloud-based data solutions and pipelines that feed into data science solutions
Work with the data engineering, data science and data ownership teams to collect relevant data elements and implement data pipelines (data acquisition, preparation, cleaning, and consolidation) as an integral part of data science activity
Work closely with various stakeholders to provide end-to-end support in data ETL and consumption
Actively participates in cross-functional teams to develop AI and ML solutions
Actively participates in virtual global team meetings regularly
Collaborate with Data Scientists, engineers and/or scientists from other disciplines to build robust and sustainable enterprise data solutions that deliver AI/ML models
Collaborate with data scientists to design, code, train, test, deploy data models and pipelines that feed machine learning systems
Prepare and present written and oral reports and proposals to peers and management

Physical Requirements
Up to 10% overnight travel required.

Qualifications
Bachelor’s degree required, Master’s degree, or PhD is preferred. Degree within subject matter expertise preferred
Bachelor’s degree with 5+ years’ relevant experience, or Master’s Degree with 3+ years’ relevant experience, or PhD with 0 years of experience can be considered
Relevant experience includes:
Experience ensuring the quality of the data in coordination with data analysts, data scientists and business partners (peer validation)
Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions
Working knowledge of scripting languages (Python, R, Scala, Julia a plus)
Familiarity with visualization tools (PowerBI, Tableau) and project management tools (JIRA, Confluence) a plus
Demonstrated ability to proactively maintain up-to-date knowledge of the company's standards, industry-leading practices, and emerging technologies through self-driven initiatives.
Preferred experience includes:
AWS Certified Developer preferred
Experience working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements
Experience working in life sciences/pharmaceutical industry
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Experience working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements
Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes.
Experience with SQL, DynamoDB, RedShift, EFS, EMR, EBS, ElastiCache and other relational/non-relational database technologies/concepts
Experience with AWS data-related services such as Storage Gateway, CloudWatch, Glue, Athena, S3, Lambda, Data Pipeline, Data Migration, Step functions.
Experience with CI/CD, basic ETL practices such profiling, cleansing, transforming, developing and documenting data structures, schemas and dictionaries.
Proficiency in version control in git, GitHub, BitBucket, or similar tools.
Demonstrated ability to work independently and in teams
Detail oriented with excellent written and oral communication skills

We commit to an inclusive recruitment process and equality of opportunity for all our job applicants.

At Novo Nordisk we recognize that it is no longer good enough to aspire to be the best company in the world. We need to aspire to be the best company for the world and we know that this is only possible with talented employees with diverse perspectives, backgrounds and cultures. We are therefore committed to creating an inclusive culture that celebrates the diversity of our employees, the patients we serve and communities we operate in. Together, we’re life changing.

Novo Nordisk is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, gender identity, sexual orientation, national origin, disability, protected veteran status or any other characteristic protected by local, state or federal laws, rules or regulations.

If you are interested in applying to Novo Nordisk and need special assistance or an accommodation to apply, please call us at 1-855-411-5290. This contact is for accommodation requests only and cannot be used to inquire about the status of applications.","$102,911 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1923,$10+ billion (USD)
"NVIDIA
4.6",4.6,"Santa Clara, CA",Senior Data Center Computational Fluid Dynamics Engineer,"For two decades, NVIDIA has pioneered visual computing. With NVIDIA’s invention of the GPU ‐ the engine of modern visual computing ‐ Visual Computing has expanded to encompass video games, movie production, product design, medical diagnosis, deep learning and scientific research. Today, visual computing is central to how people interact with technology, and there has never been a more exciting time to join the NVIDIA team. NVIDIA is widely considered one of the world’s most desirable employers. We have some of the most forward-thinking and versatile people on the planet working for us. If you have the drive, experience, and passion to help NVIDIA take visual computing to the next level, we want to hear from you!
NVIDIA is looking for a world-class Senior Computational Fluid Dynamics (CFD) Engineer for its data center modeling team to perform detailed analyses hybrid-cooled (air and liquid) at the server, rack, and row level for data centers deploying NVIDIA’s accelerated computing server products. As a member of NVIDIA, you will be an integral member of a collaborative team that defines and develops advanced computing solutions.
What you'll be doing:
Conduct detailed airflow/liquid flow and thermal performance simulations for hybrid air/liquid cooled servers, racks, and data center rows.
Stay well-abreast of the rapidly evolving power and thermal specifications for all critical components used in NVIDIA’s servers and racks, including but not limited to GPUs, CPUs, memory, switches, transceivers, power supplies, and rack PDUs.
Work in lockstep with NVIDIA’s hardware architecture team to iterate on server and rack designs, and to stay well-abreast of the rapidly changing server/rack hardware specifications, designs, and roadmaps.
Provide detailed input on server and rack designs/layouts based upon the results of the simulations and develop strategies to reduce energy consumption and improve PUE (Power Usage Effectiveness) by optimizing the cooling system.
Conduct detailed simulations and develop airflow/liquid flow specifications for customer data centers in support of customer requests. Assist hardware architecture team to reflect customer input in the design of NVIDIA’s servers and racks.
Work closely with NVIDIA’s Data Center Engineering team to update them on the evolving air- and liquid-cooling requirements for NVIDIA’s servers, racks, and data center rows.
What we need to see:
B.Sc. or M.Sc. in Mechanical Engineering or a closely a related field (or equivalent experience).
12+ years’ experience with CFD simulations of data center environments.
Expert with CFD software such as Ansys Fluent, Ansys IcePak, and 6SigmaRoom.
Proficient with CAD software such as Creo.
Excellent problem-solving skills and attention to detail.
Strong written and verbal communication skills, in addition to strong collaboration abilities.
Ability to work in a fast-moving and dynamic environment.
Ways to stand out from the crowd:
Detailed understanding of cooling technologies and airflow management in data centers.
Demonstrate a good understanding of how coolant distribution units (CDUs), in-row coolers, and liquid-to-air cooled side cars function and interact with hybrid-cooled servers, racks, and data center rows.
NVIDIA offers highly competitive salaries and a comprehensive benefits package. We have some of the most brilliant and talented people in the world working for us and, due to unprecedented growth, our world-class engineering teams are growing fast. If you're a creative and autonomous engineer with real passion for technology, we want to hear from you!
The base salary range is $180,000 - $339,250. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.","$259,625 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1993,$5 to $10 billion (USD)
"Crown Equipment Corporation
3.9",3.9,"New Bremen, OH",ETL Data Engineer - Data Integration (SSIS) (Remote Ohio),"Company Description:

Crown Equipment Corporation is a leading innovator in world-class forklift and material handling equipment and technology. Crown brings the benefits of technology to material handling by connecting lift trucks, operators and facilities and collecting accurate, real-time information for better decision-making.

Job Responsibilities:

The Data Engineer is a critical role in the development of InfoLink, Crown’s global fleet management software solution.

Programming - Design, build and optimize scalable SSIS ETL data pipelines and stores. Clean, prepare and optimize data for consumption in applications and analytics platforms. Participate in peer code reviews to uphold internal standards.
Testing - Ensure procedures are thoroughly tested before release. Write unit tests and record test results. Detect, define, and debug programs whenever problems arise. Assist with system testing.
Documentation and Training - Provide training to users and knowledge transfer to support personnel and other staff members as required. Prepare system and programming documentation in accordance with internal standards.
System Analysis - Interface with users to extract functional needs and determine requirements. Conduct detailed systems analysis to define scope and objectives and design solutions. Create documentation per internal standards. Work with Business Analyst to help develop and write system requirements.
Project Leadership - Establish project plans and schedules and monitor progress providing status reports as required. Perform other duties as assigned.

Related Terms: Big Data Developer, Data Integration Engineer, Data Warehouse Developer, Data Warehouse Engineer, Data Warehouse Technical Analyst, ETL Developer, Senior Data Engineer, Software Developer, Software Engineer

Learn more about Crown InfoLink® Operator and Fleet Management System

Remote Work: Crown offers hybrid remote work for this position. A reasonable commute is necessary since some onsite work is required.

Location: This position is based in our New Bremen, Ohio global headquarters with possible option to work from the Troy, Ohio office. These locations are reasonably close to Dayton, Columbus, Cincinnati, Fort Wayne, Indianapolis, Toledo, and Cleveland.

Minimum Qualifications:

Bachelor’s degree in Computer Science, Software/Computer Engineering, Information Systems, or related field
2 years of related experience, including SQL Server, NoSQL, ETL, and Data Integration
Good written, verbal, analytical and interpersonal skills
Ability to occasionally travel with overnight stays (0-5%)
Reliable transportation to travel locally between company locations during scheduled workday

Preferred Qualifications:

Data-related experience with, or similar to:

AWS Technologies (RDS, SQS, S3, EC2, etc.)
C#, .NET
SSIS ETL Development
SQL (query language), basic understanding of transactional and reporting databases, strong problem-solving skills and ability to work independently.
Python, GitHub, PowerBI
Familiarity with Kanban/Agile practices, test driven development
Aurora/MySQL (SQL)
DynamoDB (NoSQL)
Kibana (log files)

Work Authorization:

Crown will only employ those who are legally authorized to work in the United States. This is not a position for which sponsorship will be provided. Individuals with temporary visas or who need sponsorship for work authorization now or in the future, are not eligible for hire.

No agency calls please.

Compensation and Benefits:

Crown offers an excellent wage and benefits package for full-time employees including Health/Dental/Vision/Prescription Drug Plan, Flexible Benefits Plan, 401K Retirement Savings Plan, Life and Disability Benefits, Paid Holidays, Paid Vacation, Tuition Reimbursement, and much more.
EO/AA Employer Minorities/Females/Protected Veterans/Disabled","$77,646 /yr (est.)",10000+ Employees,Company - Private,Manufacturing,Machinery Manufacturing,1945,$1 to $5 billion (USD)
"Jack Henry and Associates, Inc.
3.8",3.8,"Allen, TX",Systems Engineer III : VMware \ Data Protection,"At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you’ll join us. We can’t do it without you.

As part of the Infrastructure Engineering team the Systems Engineer III will design, document, implement, and maintain virtual infrastructure systems in an enterprise VMware vSphere environment. Perform capacity and performance analysis and provide recommendations for optimization. Complete lifecycle and other project-based work efforts as part of a larger interdisciplinary team. Drive continuous improvement by providing guidance on system automation, monitoring, configuration, and delivery to improve uptime and increase efficiency.

The salary range for this position is: $90,000- $115,000 based on location and experience.

This position will be filled to work Remotely within the United States.

What you’ll be responsible for:
Design, document, implement and maintain virtual infrastructure systems in a high availability, 24x7x365 enterprise environment.
Participate in high visibility projects for top corporate priorities.
Develop and maintain standard operating procedures.
Monitor alerting systems and servers.
Perform troubleshooting, and problem analysis and resolution.
Review issues, logs, and capacity reports to identify trends and solutions that should be implemented enterprise wide.
Develop custom reports to meet the business needs.
Drive continual service improvement.
Assist with disaster recovery initiatives and Implement solutions to streamline disaster recovery.
May perform other job duties as assigned.

What you’ll need to have:
Minimum of 5 years of experience in a systems engineer role designing and implementing VMware vSphere solutions in an enterprise environment.
Proficiency with VMware vCenter Server and ESXi 7.0 and 8.0.
Experience deploying and maintaining VMware virtual infrastructure.
Strong verbal and written communication skills.
Ability to work an on-call rotation including nights and weekends based on business needs.
Ability to travel up to 5% to attend meetings, trainings, and/or professional conferences.

What would be nice for you to have:
VMware Certified Professional - Data Center Virtualization (VCP - DVC) certification.
Strong knowledge of disaster recovery using Commvault, VMware Site Recovery Manager and/or Zerto.
Scripting and Infrastructure as Code tools and methodologies such as PowerShell, Python, Ansible and Terraform.
Experience working with other VMware products: VMware Cloud Director, NSX, Aria Operations (vRealize Operations), Aria Operations for Networks (vRealize Network Insights), and Horizon.
Change Management process experience.
Able to multi-task and use independent judgment to plan, prioritize and organize a diversified workload.

If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry’s mission and can contribute to our company in a variety of ways.

Why Jack Henry?

At Jack Henry, we pride ourselves through our motto of, ""Do the right thing, do whatever it takes, and have fun."" We recognize the value of our associates and believe much of our company’s strength and success depends on their well-being.

We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.

Culture of Commitment

Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.

Equal Employment Opportunity

At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business—and our society—stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.

No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.

Requests for full corporate job description may be requested through the interview process at any time.","$102,500 /yr (est.)",5001 to 10000 Employees,Company - Public,Financial Services,Banking & Lending,1976,$1 to $5 billion (USD)
"California Institute of Technology
4.4",4.4,"Pasadena, CA",Senior Data Engineer,"Senior Data Engineer

Caltech
Job Category: Fulltime Regular
Exempt Overtime Eligible: Exempt
Benefits Eligible: Benefit Based

Caltech is a world-renowned science and engineering institute that marshals some of the world's brightest minds and most innovative tools to address fundamental scientific questions. We thrive on finding and cultivating talented people who are passionate about what they do. Join us and be a part of the diverse Caltech community.

Job Summary

We seek a highly motivated and dependable individual to join the Van Valen lab as a Senior Data Engineer. This individual will collaborate with graduate students, postdoctoral scholars, and staff to create annotated image datasets for deep-learning algorithms for cellular image analysis.

Essential Job Duties
Lead efforts in the reviewing and correcting of biological image annotations.
Analyze and identify critical datasets for annotation.
Create annotation protocols for novel tissue types.
Extract relevant images and videos from scientific publications.
Coordinate with crowdsourcing companies to make clear and concise annotation instructions.
Provide feedback on data quality and software performance to develop annotation workflows.
Provide biological insights to machine learning team.
Update and maintain image databases.
Communicate efficiently with the manager, team members, researchers, and other support groups.

Basic Qualifications
Bachelor's degree with at least 5 years of relevant experience.
Experience with histology samples.
Demonstrated proficiency with computers.
Ability to perform repetitive tasks while paying close attention to detail.
Ability to extract relevant metadata from scientific publications.
Strong organizational skills.
Ability to work independently and in team settings.

Preferred Qualifications
Ph.D. with biologic imaging experience.
Experience with biological image annotation.
Experience working in a team-oriented environment.
Experience interpreting microscopy images to identify microstructures, staining patterns, and cellular boundaries.
Experience with Matlab, Python, or other programming languages.
Experience with version control software (i.e. git).

Required Documents
Resume



To be considered for this position please visit our web site and apply on line at the following link: https://hr.caltech.edu/work/job_openings

We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.

jeid-fad964b846f3fd42992d7717563b5fce","$139,449 /yr (est.)",1001 to 5000 Employees,College / University,Education,Colleges & Universities,1891,$100 to $500 million (USD)
"RVO Health
3.9",3.9,"Atlanta, GA","Senior Data Engineer, Talent Analytics","AT A GLANCE
RVO Health is looking to grow our Talent Analytics team by adding a Senior Data Engineer. In this role, you'll be challenged to help shape our Talent Analytics strategy while working on high-priority data efforts – all in line with our broader mission of attracting diverse talent and giving them an experience that will bring out their very best. You will be responsible for scoping, executing, and delivering technical projects to stakeholders across the Human Capital organization, and producing data engineering & analytical solutions that connect them to the data they need.
What You'll Do
Develop/maintain data pipelines from various data sources (ADP WFN, Greenhouse Recruiting/Onboarding, CultureAmp, Docebo, etc) to a target data warehouse using batch data load strategies utilizing cutting edge cloud technologies.
Conduct hands-on, advanced data engineering & analytics using multiple data sources originating from different applications and systems.
Collaborate with the data science team to identify new opportunities for deep analytics within the Human Capital organization.
Provide input into strategies as they drive the team forward with delivery of business value and technical acumen.
Execute on proof of concepts, where appropriate, to help improve our technical processes.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
What We're Looking For
5+ years of Data Engineering experience
3+ years of writing SQL experience against complex databases for data extraction using AWS Athena (Presto), Databricks Delta Lake along with Data Modeling & Data warehousing experience.
3+ years of experience working on Spark (RDDs / Data Frames / Dataset API) using Scala/Python to build and maintain complex ETL pipelines and experience data processing using Parquet and Avro
3+ years of Python coding experience, familiar with utilizing packages such as pandas, boto3, requests, json, csv, os
3+ years of experience working on AWS services including Glue, Athena, Lambda, S3, SNS, SQS, Cloud formation, Step Functions, Serverless architecture.
Experience with GitHub, Code check-in, versioning, Git commands
Introduce and drive adoption of CI/CD framework within the team and build/deploy CI/CD Pipelines using Terraform or AWS Cloud Formation
Experience with visualization tools such as Tableau, Looker or PowerBI to build dynamic/scalable dashboards and reports.
Strong analytical and interpersonal skills
Knowledge or experience within Talent/People analytics is a plus
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.
Starting Salary: $100,000 - $170,000
Note actual salary is based on geographic location, qualifications and experience
Access to a Free Udemy for Business subscription—thousands of hours of learning content on hundreds of different subjects at your fingertips
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
This position may occasionally require travel for training and other work-related duties.
Who We Are:
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group's Optum Health. Together we're focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.

We do not provide visa sponsorship at this time.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy","$135,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Hospitals & Health Clinics,2022,Unknown / Non-Applicable
"Optum
3.7",3.7,"Indianapolis, IN",Sr Data Engineer - Remote (Indiana),"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start Caring. Connecting. Growing together.

If you are living in Indiana, you will have the flexibility to work remotely* as you take on some tough challenges.

Primary Responsibilities:
Developing ETL solutions and supporting data strategy leveraging acquired subject matter expertise to identify/inform opportunities and risks
Creating physical and logical data models supporting new data warehouse development and architecture
Developing/leading complex dashboards, scorecards, reports, and data analysis
Performing peer-reviews and providing technical support/guidance to the project team
Leading the creating/maintaining of Teradata database, ETL, reporting architecture/environment, processes/procedures, coding standards, and data management/security activities
Supporting the project manager and leadership in project planning and executing activities, including presentations, risks/issues, and status reporting
Demonstrating deliverables to the team or the customers for approvals and gain buy-in to implement solutions or adapt to new products/services/programs
Working with the DBAs, data modelers, and application/system admins to support maintaining the Teradata and application server hardware and software (including patches, fixes, and upgrades) and leading industry level standards or best practices

You’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.
Required Qualifications:
7+ years of ETL and enterprise data warehouse technical development
7+ years of experience gathering requirements, exploring data, SQL/DB development
7+ years of experience in reporting, analysis, and/or data management/governance
4+ years of Informatica PowerCenter, Informatica B2B, Informatica Data Quality (IDQ), Address Doctor
4+ years of Teradata experience including Teradata Utilities
3 + years of experience working with Medicaid data
2 + years of experience working with Python
2 + years of experience working with Federal datasets (T-MSIS)

Preferred Qualifications:
Bachelor’s degree or higher in engineering, related field
Degree in Technology/Engineering
Certified Business Intelligence Professional (CBIP)
4+ years of experience leading a team as a technical lead or similar capacity
2 + years of data modelling
Experience in Medicaid/Managed Care/health insurance industry
Experience with visualization tools (Power B.I., Tableau, SAS, etc.)
Experience using Snowflake
Experience in scripting language experience ( R,T-SQL, etc.)
Familiarity with A.I. and machine learning
Demonstrated experience working with high-performing remote teams and delivering to external customer
Proven advanced skills in Microsoft Office (Excel, Word, PowerPoint, etc.) with solid communication skills

All employees working remotely will be required to adhere to UnitedHealth Group’s Telecommuter Policy
At UnitedHealth Group, our mission is to help people live healthier lives and make the health system work better for everyone. We believe everyone–of every race, gender, sexuality, age, location and income–deserves the opportunity to live their healthiest life. Today, however, there are still far too many barriers to good health which are disproportionately experienced by people of color, historically marginalized groups and those with lower incomes. We are committed to mitigating our impact on the environment and enabling and delivering equitable care that addresses health disparities and improves health outcomes — an enterprise priority reflected in our mission.

Diversity creates a healthier atmosphere: UnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employers and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment","$91,667 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,#N/A,$10+ billion (USD)
"Madhive
3.7",3.7,Remote,Senior Backend Engineer - Data,"Madhive is the leading tech company engineered for modern TV advertising. Advertisers seamlessly customize and automate the OTT buying process into an operating system with our self-service platform. Powered by our industry-leading bidder and device graph that processes 260 billion available ad opportunities per day, we deliver precise, brand-safe, audience connections efficiently at scale.
We are seeking a Senior Software Engineer specializing in data pipelining and modeling, you will play a crucial role in designing, developing, and maintaining our data infrastructure. You will work closely with cross-functional teams to build robust, scalable, and efficient data pipelines, ensuring high data quality and reliability. Your expertise in ETL processes, Airflow, Streaming, Warehousing, and database technologies will drive our data initiatives forward
What you'll do:
Design and implement data pipelines for ingesting, processing, and transforming large volumes of data.
Develop and maintain data models to support analytical and reporting needs.
Optimize data pipelines for performance, scalability, and reliability.
Implement real-time data streaming solutions using streaming technologies.
Create and manage ETL processes to extract, transform, and load data from various sources into data stores.
Monitor and troubleshoot data pipeline and ETL issues.
Evaluate, select, and implement columnar and store databases that best-fit project requirements.
Understand the tradeoffs between different database technologies and make informed decisions.
Perform database optimization and tuning for efficient data retrieval and storage.
Collaborate closely with data scientists, analysts, and other engineering teams to understand data requirements and deliver solutions.
Document data pipelines, models, and ETL processes for knowledge sharing and troubleshooting.
Promote and enforce best practices in data engineering and data governance.
Who you are:
Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
Minimum of 5+ years of experience in software engineering with a focus on data engineering.
Strong proficiency in data pipelining and modeling, including experience with tools like Apache Airflow.
In-depth knowledge of data streaming technologies, especially Apache Kafka.
Expertise in designing and implementing ETL processes.
Proficiency in SQL and NoSQL databases, understanding the tradeoffs between different types.
Experience with columnar and store databases.
Strong problem-solving and debugging skills.
Excellent communication and teamwork abilities.
Familiarity with cloud platforms like AWS, GCP, or Azure is a plus.
Examples of systems our teams build:
We deal with massive amounts of data here at Madhive. To use it, we need the ability to move it around, aggregate, maintain, and turn it into usable information that powers our platform.
External & internal APIs that enable frictionless integration within our platform, ranging from custom reporting for ad-hoc analysis to platform APIs for programmatic activation of programmatic ad campaigns, and much more!
Our stack lives in the warm embrace of GCP. Our engineers are language agnostic, but core technologies for our backend include Golang, gRPC, BigQuery, Postgres, Airflow, Bigtable, Docker, Spanner, Firebase, Kubernetes, and Terraform.


The approximate compensation range is $200,000 to $250,000 The actual offer, reflecting the total compensation package and benefits, will be determined by a number of factors including the applicant's experience, knowledge, skills, and abilities, as well as internal equity among our team.
Madhive is a dynamic, diverse, innovative, and friendly place to work. We embrace our differences and believe they fuel our creativity. We come from varied backgrounds and think that's important. But whether it's taking ideas from previous lives and applying them in different ways or creating something completely new, we are all trail-blazing team players who think big and want to make an impact.
Here are just some of the many benefits of becoming a Madhive employee:
Health, Dental & Vision Insurance: Your health is number 1, so we offer 100% company-paid health, dental, and vision insurance starting on day 1 for yourself and any dependents.
Family Forming Benefits: Madhive offers inclusive fertility and family-forming benefits that cover all paths to parenthood — whether it is adoption, surrogacy, fertility treatments, pregnancy, or anything related through a partnership with Carrot Fertility. The benefit includes free access to Carrot membership services and employer-sponsored funds of up to $10,000 to help pay for your care.
401(K) Matching: Madhive's generous 401(K) plan offers a contribution equal to 100% of eligible employee contributions up to 5% annually. There is no vesting period, and all full-time employees can participate immediately upon their hire date.
Unlimited Vacation: We offer Unlimited PTO plus additional paid company holidays.
Parental Leave: We believe that family comes first, so we provide parental leave to all new parents.
Food All Day: Fully stocked refrigerator and lunch are provided every day that you're in the office!","$225,000 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2017,Unknown / Non-Applicable
"Salesforce
4.1",4.1,California,"Customer Centric Engineer, Heroku Data","To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.
Job Category
Software Engineering
Job Details
About Salesforce
We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.
Heroku is looking for an experienced customer-centric engineer to join the Heroku Data Services team. Our team is dedicated to pushing the boundaries of innovation through the development of cutting-edge managed data services, while focusing on our customer needs.

In this role, you will collaborate with fellow Heroku Customer Engineers and our Heroku Data engineering teams to address technical support escalations. This opportunity will enable you to engage directly with our customers and remain closely connected to engineering and product decisions, allowing you to make a significant impact. You should have a passion for problem-solving and a commitment to ensuring customer success.

Responsibilities:
Use your analytic and problem solving skills to resolve customer cases raised to our engineering team from Support. You will work on cases related to our Heroku Postgres, Heroku Data for Redis®*, Apache Kafka on Heroku, and Heroku Connect products.
Work closely with our engineering team to identify and report bugs and propose and design fixes and improvements.
Assist, train and mentor the Heroku Support team, helping them upskill and learn about our products, to improve customer satisfaction. Our Heroku Customer Engineering team is the interface between Support and Engineering.
Partner with our engineers, product managers and technical writers on ongoing projects to provide your expertise and customer-centric insight.
Collaborate in cross-team projects to resolve high-impact customer issues.
Compassion for your team members and awareness of overall team health.
Required skills:
Experience in a technical customer-facing or support role
A strong customer-centric mentality and attention to detail
Excellent written communication skills
Ability to communicate async-first as part of a globally distributed team.
Excellent troubleshooting and problem-solving skills
Experience with one or more of the database technologies that we support:
PostgreSQL
Redis
Apache Kafka
Experience with Ruby, Python and/or Go, as you will often be digging into code
Preferred skills:
Experience with AWS (EC2, S3, VPC, etc.)
Experience debugging or operating/developing distributed systems


*Redis is a registered trademark of Redis Ltd. Any rights therein are reserved to Redis Ltd. Any use by Heroku is for referential purposes only and does not indicate any sponsorship, endorsement or affiliation between Redis and Heroku
Accommodations
If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .
Posting Statement
At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .
Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce .
Salesforce welcomes all.
Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.
For New York-based roles, the base salary hiring range for this position is $122,600 to $220,000.
For Colorado-based roles, the base salary hiring range for this position is $111,400 to $183,400.
For Washington-based roles, the base salary hiring range for this position is $111,400 to $201,700.
For California-based roles, the base salary hiring range for this position is $122,600 to $220,000.
Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.","$147,400 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1999,$10+ billion (USD)
"SAP
4.4",4.4,"Palo Alto, CA",Senior Data Engineer - Generative AI and Knowledge Graphs,"We help the world run better
Our company culture is focused on helping our employees enable innovation by building breakthroughs together. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from. Apply now!

Summary:
At SAP, we integrate AI technology with extensive industry-specific data and deep process knowledge to create innovative AI capabilities for all SAP applications. Large Language Models (LLMs) hold immense potential to change the way we work and develop products. They are reshaping the landscape of Machine Learning across various domains. However, their limited ability to leverage tabular data leaves a considerable share of enterprise data untapped. It is SAP's mission to overcome this challenge within the realm of Business AI. Our goal is to adapt Foundation Models to SAP data, enabling our clients to solve their business processes more effectively.
Meet your team:
SAP's AI organization is dedicated to seamlessly infusing AI into all enterprise applications, enabling customers, partners, and developers to enhance business processes and generate remarkable business value. Join our international AI team where innovation thrives, opportunities for personal development abound, and exceptional colleagues collaborate globally
The Role:
Unique opportunity to contribute to the development of a Foundation Model on structured business data using Knowledge Graphs in a diverse business context.
Design, develop and manage the construction of large-scale knowledge graphs using structured business data.
Lead the integration of knowledge graphs into the foundation model, enabling more efficient and accurate data interpretation.
Collaborate closely with AI/ML teams to understand their data requirements and ensure the delivery of high-quality data
Make critical design decisions regarding the selection and implementation of underlying technologies.
Extract, clean, and analyze data from various sources to ensure quality and accuracy
Contribute to thought leadership in an entirely new data modality for Foundation Models and Generative AI.
What you bring:
PhD or Master’s degree in Computer Science, Artificial Intelligence, or other relevant disciplines.
Deep background in Data Engineering, Knowledge Graphs, and their application in a business context. Background in Machine Learning is a plus.
Proficiency in Python.
Advanced knowledge of data modeling, schema design, and related technologies
Proven expertise in designing and implementing data extraction and structuring strategies for complex business data.
Ideally, professional experience with Machine Learning on structured data such as in the ERP or CRM domain.
5+ years of professional experience. Strong communication and collaboration skills, with the ability to work effectively in cross-cultural teams.
#SAPAI

We build breakthroughs together

SAP innovations help more than 400,000 customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with 200 million users and more than 100,000 employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, we build breakthroughs, together.
We win with inclusion
SAP’s culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone – regardless of background – feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.
SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com.
For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.
EOE AA M/F/Vet/Disability
Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, ethnicity, age, gender (including pregnancy, childbirth, et al), sexual orientation, gender identity or expression, protected veteran status, or disability.
Compensation Range Transparency: SAP believes the value of pay transparency contributes towards an honest and supportive culture and is a significant step toward demonstrating SAP’s commitment to pay equity. SAP provides the annualized compensation range inclusive of base salary and variable incentive target for the career level applicable to the posted role. The targeted combined range for this position is 132,300 - 275,200 USD. The actual amount to be offered to the successful candidate will be within that range, dependent upon the key aspects of each case which may include education, skills, experience, scope of the role, location, etc. as determined through the selection process. Any SAP variable incentive includes a targeted dollar amount and any actual payout amount is dependent on company and personal performance. Please reference this link for a summary of SAP benefits and eligibility requirements: SAP North America Benefits.
Requisition ID: 378785 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | Additional Locations: #LI-Hybrid","$135,663 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1972,$10+ billion (USD)
"SolTech Inc.
3.7",3.7,United States,Data Scraping Engineer,"Overview:
Do you have 'hustle' DNA and an eagerness for fast growing environments?

Our client is looking for an experienced Data Scraping Engineer to join their team and heavily support upcoming AI initiatives. This is a fully remote position and a great opportunity to join a well funded startup in the healthcare space.

Apply Today!
Responsibilities:
Utilize Axios, Puppeteer, and Playwright to scrape data from websites, web applications, and other online sources.
Develop and implement data extraction scripts and algorithms to collect structured and unstructured data.
Process and clean scraped data to ensure its quality and consistency - including data validation, normalization, and transformation.
Apply advanced data parsing techniques to dissect and interpret complex datasets, extracting specific information, and organizing it into structured formats.
Design, document, and maintain automated scraping and parsing processes.
Monitor scraping and parsing processes for performance, stability, and data integrity.
Collaborate with cross-functional teams to understand data requirements and provide timely and accurate data solutions, including insights gained through data parsing.
Qualifications:
Bachelor's degree in Computer Science, Data Science, or a related field (preferred).
Proven professional experience as a Data Scraping Engineer with expertise in Axios, Puppeteer, Playwright, and advanced data parsing techniques.
Ability and experience leading Data Scraping initiatives.
Proficiency in programming languages such as JavaScript, Python, and/or other relevant scripting languages.
Expert level SQL experience
Strong data parsing skills, including the ability to dissect and interpret complex datasets.
Excellent problem-solving skills and attention to detail.
Strong communication and documentation skills.

This position is fully remote, but qualified candidates must be comfortable working in various time zones on an as needed basis.
About SOLTECH:
SOLTECH is a leading national technology company based in Atlanta. Driven by a steadfast commitment to integrity, strong company values, and customer centricity, SOLTECH has achieved national recognition and success.

For more than 25 years, SOLTECH has been part of the thriving technology community, and has been recognized by The Atlanta Journal-Constitution as a Top Workplace, as well as one of the Best & Brightest Companies To Work For In The Nation. With a team of exceptional engineers, designers, and strategists, SOLTECH has consistently delivered cutting-edge custom software applications, technology consulting services, and IT staffing solutions that address complex business challenges.

Join us on our quest to make the world a better place by bringing to life innovative software solutions that make our lives easier, safer, healthier, and more productive.

If you are an IT professional searching for your next career opportunity, we look forward to matching your expertise and interests with a position where you can thrive. Learn more about SOLTECH careers at https://soltech.net/working-for-soltech/",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,1998,$5 to $25 million (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Intuit
4.5",4.5,"Mountain View, CA",Senior Software Engineer - Big Data,"Overview
Come join Intuit as a Senior Software Engineer!
What you'll bring
BS in Computer Science or equivalent work experience
Strong CS fundamentals including data structures, algorithms and distributed systems.
Strong database fundamentals including SQL, performance and schema design.
Strong programming skills in Java, Scala, Python, or similar.
Experience with Git
6+ years of hands-on software engineering experience.
6+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.
Experience with Spark, Hive, Hadoop, Kafka, Columnar Databases and Graph Databases.
Experience with various offerings from AWS, including S3, EMR, DynamoDB, EC2 and Athena
1+ years DevOps experience including configuration, optimization, backup, high reliability, monitoring and systems version control.
Track record working with data from multiple sources – willingness to dig-in and understand the data and to leverage creative thinking and problem-solving.
Excellent interpersonal and communication skills, including business writing and presentations. Ability to communicate objectives, plans, status and results clearly, focusing on critical few key points.
Demonstrated ability to work in a matrix environment, ability to influence at all levels, and build strong relationships.
Knowledge of enacting service level agreements and the appropriate escalation and communication plans to maintain them
How you will lead
BS in Computer Science or equivalent work experience
Strong CS fundamentals including data structures, algorithms and distributed systems.
Strong database fundamentals including SQL, performance and schema design.
Strong programming skills in Java, Scala, Python, or similar.
Experience with Git
6+ years of hands-on software engineering experience.
6+ years of experience integrating technical processes and business outcomes – specifically: data and process analysis, data quality metrics/monitoring, data architecture, developing policies/standards & supporting processes.
Experience with Spark, Hive, Hadoop, Kafka, Columnar Databases and Graph Databases.
Experience with various offerings from AWS, including S3, EMR, DynamoDB, EC2 and Athena
1+ years DevOps experience including configuration, optimization, backup, high reliability, monitoring and systems version control.
Track record working with data from multiple sources – willingness to dig-in and understand the data and to leverage creative thinking and problem-solving.
Excellent interpersonal and communication skills, including business writing and presentations. Ability to communicate objectives, plans, status and results clearly, focusing on critical few key points. Demonstrated ability to work in a matrix environment, ability to influence at all levels, and build strong relationships.
Knowledge of enacting service level agreements and the appropriate escalation and communication plans to maintain them","$160,456 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Software Development,1983,$10+ billion (USD)
"Providence
3.6",3.6,Oregon,Senior Software Engineer - Data,"Description
Senior Software Engineer, Data - Enterprise Information Services - Location: WA or OR *hybrid
How would you like to pursue your passion for healthcare, social causes, and software development in a job that stimulates your brain and tugs at your heart? Our team at Providence is looking for a senior software engineer who can help us do data right to allow us to move quickly to accelerate our modern data architecture ambition. We have software engineers from Microsoft, Amazon, and other tech companies who work with the singular purpose of fulfilling our vision of Health for a Better World. Our work is not easy - healthcare is not easy, but we are having fun and are committed to our mission. If you think you have what it takes to have an impact on real lives, we want to talk to you.
The Senior Software Engineer builds modern data-centric solutions to support HR and operational processes across all parts of the healthcare system. Builds data pipelines and transformations, data enrichment processes and data visualizations to meet the requirements of key initiatives. Enjoys fast pace and has a focus on regular delivery. Uses emerging methods & tools to find data-driven solutions for complex problems and contributes to research and development of new technologies. Be an active participant in code reviews, support the code base, and help establish standard processes and frameworks.
Required qualifications:
Bachelor's Degree in Computer Engineering, Computer Science, Mathematics, Engineering or equivalent education/experience.
5 years related experience.
Extensive experience with object-oriented programming in C#, Java, Python or equivalent.
Experience with source code control systems such as Git.
SQL integration development experience with SQL/NoSQL.
Experience with Agile software development methodologies and tools such as Azure Devops, TFS, and Jira.
Proven track record of working both independently and collaboratively as part of a multi-disciplined team.
Experience designing and successfully implementing a large project.
Preferred qualifications:
Strong skill in understanding database architecture, data models and writing complex SQL queries/code.
Hands on experience in Azure Cloud components such as Azure Databricks, Azure Data Factory, Azure Logic apps and Azure Devops.
Experience with database query and analysis languages (e.g. SQL, R, SAS, Python).
Experience in data visualization tools (e.g. Power bi,Tableau) and ability to transform raw data into relevant insights.
Ability to work with large volume of data sets in performing data ingestion, loading, transformation and aggregation.
Data Analytics experience in a healthcare environment.
Salary Range by location: *hourly listed – position is salaried
WA Puget Sound Oregon (Portland) Alaska (Anchorage) Min: $52.84, Max: $89.98
Oregon (Hood River, Medford, Seaside) Min: $49.26, Max: $83.88
Eastern Washington (Richland, Spokane, Walla Walla) Min: $47.02, Max: $80.06
Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities.
About Providence
At Providence, our strength lies in Our Promise of “Know me, care for me, ease my way.” Working at our family of organizations means that regardless of your role, we’ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable.
The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.
Check out our benefits page for more information about our Benefits and Rewards.
About the Team
Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.
We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment.
We are committed to cultural diversity and equal employment for all individuals. It is our policy to recruit, hire, promote, compensate, transfer, train, retain, terminate, and make all other employment-related decisions without regard to race, color, religious creed (including religious dress and grooming practices), national origin (including certain language use restrictions), ancestry, disability (mental and physical including HIV and AIDS), medical condition (including cancer and genetic characteristics), genetic information, marital status, age, sex (which includes pregnancy, childbirth, breastfeeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, genetic information, and military and veteran status or any other applicable legally protected status. We will also provide reasonable accommodation to known physical or mental limitations of an otherwise qualified caregiver or applicant for employment, unless the accommodation would impose undue hardship on the operation of our business.
We are a community where all people, regardless of differences, are welcome, secure, and valued. We value respect, appreciation, collaboration, diversity, and a shared commitment to serving our communities. We expect that all workforce members in our community will act in ways which reflect a commitment to and accountability for, racial and social justice and equality in the workplace. As such, we will maintain a workplace free of discrimination and harassment based on any applicable legally protected status. We also expect that all workforce members will maintain a positive workplace free from any unacceptable conduct which creates an intimidating, hostile, or offensive work environment.
Requsition ID: 220342
Company: Providence Jobs
Job Category: Development/Engineering
Job Function: Information Technology
Job Schedule: Full time
Job Shift: Day
Career Track: Business Professional
Department: 4011 SS IS AT DATA PROCSNG
Address: WA Redmond 17425 NE Union Hill Rd
Work Location: Redmond Junction At Bear Creek
Pay Range: $see posting - $see posting
The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.
Check out our benefits page for more information about our Benefits and Rewards.
Providence is proud to be an Equal Opportunity Employer. Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law.",#N/A,10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1855,$100 to $500 million (USD)
Foothill Ventures,#N/A,"Santa Clara, CA",Senior Software Engineer - Big Data,"Company Description

Foothill Ventures is a technology-focused venture fund based in Los Altos, California. We make pre-seed, seed (preferred), and A-round investments in startups across software, life science, and deep tech. We grew out of the TEEC Angel Fund, which made seed-stage, highly successful bets on companies like Zoom Communications, Quanergy, Iterable, Carta, Plus.ai, Opentrons, WeRide.ai and Ginkgo Bioworks, all subsequent Unicorns.
We provide support to our portfolio companies in various areas, including recruiting and talent acquisition. This role is posted on our website for our portfolio companies.

Job Description

One of our portfolio companies is looking for an experienced Big Data Engineer to design, develop, and optimize our large-scale data infrastructure. You will work with petabyte-scale datasets and build complex data pipelines that collect, transform, and organize big data for analytics and machine learning models.
Responsibilities:
Analyze and improve the performance and efficiency of the ETL pipelines by identifying bottlenecks, finding out root causes, applying best practices like incremental computation and parallel computation, and dogfooding Bluesky products.
Develop high-performance and scalable ETL pipelines, leveraging a powerful stack of modern tools and frameworks for data integration, transformation, and orchestration.
Effectively configure, monitor, and scale production environment involving Snowflake (similar DataWarehouse), dbt, Airbyte, and Prefect (any modern data frameworks/tools), ensuring seamless operation and optimal performance.
Build batch and real-time data processing pipelines for cleansing, transforming, and enriching data, and optimize data pipeline performance for speed, scalability, and cost efficiency
Monitor data pipelines end-to-end and troubleshoot issues proactively

Qualifications

Requirements:
Bachelor’s degree in a technical field or equivalent
5+ years of experience in big data engineering at a senior level
Expert knowledge of distributed data systems and architecture patterns
Proficiency in Scala, Python, Java, SQL, and Linux shell scripting
Experience with Spark, Hadoop, Hive, Kafka, Elasticsearch and NoSQL databases
Ability to optimize complex queries and ETL workflows
Strong problem-solving, communication and collaboration skills
Nice to Have:
1+ years of experience with Snowflake
1+ years of experience with dbt
Experience with other big data platforms: Databricks, BigQuery, Redshift, Spark, Presto
Experience in data modeling, data warehousing, and building enterprise data lakes

Additional Information

Foothill Ventures is an equal opportunity employer. All aspects of employment including the decision to hire, promote, discipline, or discharge, will be based on merit, competence, performance, and business needs. We do not discriminate on the basis of race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law.","$159,247 /yr (est.)",1 to 50 Employees,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"SOSi
3.6",3.6,"Vienna, VA",Software Engineer – Data Scraping,"Overview
At Exovera you will be responsible for collecting, organizing, and extracting data from various online sources. Your work will directly impact our decision-making processes and contribute to the success of our projects. This is an excellent opportunity to work with cutting-edge technologies and contribute to a fast-growing company.
Responsibilities
Use web scraping tools and techniques to extract data from websites and online databases.
Clean and preprocess data to ensure accuracy and consistency.
Develop and maintain data scraping scripts and automation tools.
Collaborate with the data analysis team to deliver high-quality datasets for analysis.
Monitor data sources for updates and changes and adjust scraping methods accordingly.
Stay up-to-date with the latest web scraping technologies and best practices.
Qualifications
Proven experience with web scraping techniques and tools (e.g., BeautifulSoup, Scrapy, Selenium).
Strong proficiency in programming languages like Python.
Solid understanding of data storage and database management.
Attention to detail and a commitment to delivering high-quality data.
Excellent problem-solving and troubleshooting skills.
Ability to work independently and as part of a collaborative team.
Strong communication skills, both written and verbal.
Secret Clearance
Preferred Qualifications
Bachelor's degree in a related field (Computer Science, Data Science, etc.) or equivalent work experience.
Experience with data visualization tools (e.g., Tableau, Power BI).
Knowledge of machine learning and data analysis techniques.
Familiarity with data privacy and web scraping regulations.
Top Secret Clearance
Working Conditions
Exovera offers a competitive salary and benefits package, as well as a dynamic and fast-paced work environment. If you are passionate about data engineering and want to be part of a team that is driving innovation and growth, we want to hear from you.
Full remote flexibility","$106,207 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1989,$100 to $500 million (USD)
"CVS Health
3.1",3.1,"Irving, TX",Data Software Engineer,"Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
CVS Health is seeking a highly skilled and experienced Software Engineer to join our dynamic team. The ideal candidate will have profound technical knowledge, aptitude for logical reasoning and problem-solving skills. As a software engineer on our team, you will be responsible for designing and developing high-quality software that meets business needs. You will build highly scalable microservices, event driven systems and real time streaming pipelines. You must be comfortable working in a fast-paced and dynamic environment with a deep understanding of software engineering principles.
Software engineering: Candidate should have basic knowledge Object oriented concepts. Knowledge about UI technologies like ReactJS, RESTful APIs (FASTAPI preferred), AKS, Microservices would be a plus
Programming: Candidate should have a basic knowledge of programming using Python (preferred) or Java and in the Linux environment. Knowledge in SQL and Data Engineering concepts will be helpful otherwise candidate will need to ramp-up on these skills.
Cloud: Should have basic understanding of working with Cloud platforms (Azure/GCP preferred). Should have basic understanding of integration methodologies (APIs/Connectors/Microservices etc.) as well as using CI/CD pipelines. Any hands-on experience will certainly be added advantage
Communication: Ability to effectively communicate and explain technical solutions to peers, leaders and partners. Also, ability to ask questions to get clarity on goals and technical requirements
Agile & Pro-active: Work and collaborate with a cross-functional POD in an agile/nimble fashion to drive assigned data-engineering tasks.
Problem-solving: Analyze business problems and come up with innovative solutions to help analytical partners enable data science and analytical solutions to solve the business problem.
Attitude: Candidate should be an enthusiast to learn new technologies and contribute quickly as project demands

Location: Dallas Area in Texas or Woonsocket RI or Boston Area in MA or NYC, NY or Hartford CT

Required Qualifications
1+ years of progressively complex related experience
Experience with bash shell scripts, UNIX utilities & UNIX Commands
Experience with ReactJS
Python f/w for Backend – preferably FAST API
Kubernetes/Docker (preferably AKS)
Strong Hands-on experience (this is not a project management role at onsite)
Experience on –
o Handling large volumes of data on web pages (preferably from any OLAP Data stores in the backend)
o Performance Optimization
o Deployment strategies (like hosting multiple applications under same platform)
o Data Integrity
o Caching Strategies
o Authentication and Authorization modules; Security aspects related to developing applications.

Preferred Qualifications
Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources
Ability to understand complex systems and solve challenging analytical problems
Strong problem-solving skills and critical thinking ability
Strong collaboration and communication skills within and across teams
Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar
Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment
Python f/w for Backend – preferably FAST API
Experience building data transformation and processing solutions
Strong knowledge of large-scale search applications and building high volume data pipelines

Education
Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline
Pay Range
The typical pay range for this role is:
$70,000.00 - $170,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health colleagues can initiate a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through myHR (1-888-694-7287, or through myLeave at myHR). If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.","$120,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1963,$10+ billion (USD)
"Nike
4.2",4.2,"Beaverton, OR",Sr. Data Engineer,"Become a Part of the NIKE, Inc. Team

\r

\r

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

Sr. Data Engineer-NIKE, Inc., Beaverton, OR. Design and build reusable components, frameworks and libraries at scale to support analytics products; design and implement product features in collaboration with business and Technology stakeholders; identify and solve issues concerning data management to improve data quality; clean, prepare and optimize data for ingestion and consumption; collaborate on the implementation of new data management projects and re-structure of the current data architecture; implement automated workflows and routines using workflow scheduling tools; build continuous integration, test-driven development and production deployment frameworks; review design, code, test plans and dataset implementation performed by other data engineers in support of maintaining data engineering standards; analyze and profile data for designing scalable solutions; troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues; develop architecture and design patterns to process and store high volume data sets; and participate in an Agile / Scrum methodology to deliver high - quality software releases through Sprints. Telecommuting is available from anywhere in the U.S., except from AK, AL, AR, DE, HI, IA, ID, IN, KS, KY, LA, MT, ND, NE, NH, NM, NV, OH, OK, RI, SD, VT, WV, and WY.

Employer will accept a Master's Degree in Computer Science, Engineering, Computer Information Systems, Electronics and Communications, or Technology and two (2) years of experience in the job offered or a data engineering related occupation.

Experience must include:
Programming languages such as Python, Java, and Scala;
Big Data Frameworks such as Hadoop, Hive, Spark, and Databricks;
ETL Tools such as Informatica and PL/SQL;
Scripting such as Unix, and PowerShell;
Databases, such as Oracle, MYSQL, SQL Server, Teradata, and Snowflake;
AWS tools such as EMR, S3, and Kinesis;
Analytics Tools, such as Tableau and Cognos;
Streaming Frameworks such as Kafka and Spark Streaming; and
Workflow orchestration tools such as Airflow and Autosys.

#LI-DNI

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

How We Hire

At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.

This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.

Benefits

Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$111,914 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"Fidelity Investments
4.3",4.3,"Boston, MA",Software Data Engineer-Oracle SQL and PL/SQL,"Job Description:
Asset Management Technologies is looking for a Software Engineer passionate about developing Data Engineering solutions to support Strategic Advisors business needs. The Software Engineer is responsible for data analysis, database development, testing, and deploying code to various environments. This position is available in Boston, Merrimack, Raleigh, Smithfield, and Westlake.
The Expertise You Have
Three or more years of industry experience as an Oracle Database engineer and developer
B.S. degree in Computer Science or equivalent technical/engineering discipline
Hands on working experience in Oracle SQL and PL/SQL
Proven experience in data analysis and database design
Familiarity with Data warehousing concepts and ETL tools such as Informatica, Talend
Exposure to Linux shell scripts, and Autosys would be a plus
Exposure to GIT Stash, Jenkins, Jira, and uDeploy
Experience working on Snowflake and Python would be a plus
Exposure to native AWS services such as EC2 and lambda functions
Experience working in agile methodology, and providing L3 support
Knowledgeable about Data APIs, data streaming, and messaging technologies
The Skills You Bring
You have excellent oral and written communication skills
You have curiosity and passion about data, visualization and solving problems
You have willingness to take initiative on continuous improvement
You are eager to learn and deliver in a fast-paced environment and thrill the users
You are a self-starter, highly motivated, and an innovative thinker
The Value You Deliver
Working closely with technology and business partners to understand the business problems and to design technology solutions
Designing, developing, and supporting quality solutions that aligns with the technology blueprint and standard methodologies to solve business problems
Actively participating in activities like innovation days, code, and design reviews, exploring emerging technologies etc.
The Team
The Software Engineer will be part of a global database development team that focuses on building scalable and optimized data solutions to satisfy Strategic Advisers business needs. This team has a deep understanding of the Strategic Advisors’ data needs, their products, and applications.
Certifications:
Company Overview
Fidelity Investments is a privately held company with a mission to strengthen the financial well-being of our clients. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients' money.

Join Us
At Fidelity, you'll find endless opportunities to build a meaningful career that positively impacts peoples' lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees' Choice Award, we have been recognized by our employees as a Best Place to Work in 2023. And you don't need a finance background to succeed at Fidelity—we offer a range of opportunities for learning so you can build the career you've always imagined.
At Fidelity, our goal is for most people to work flexibly in a way that balances both personal and business needs with time onsite and offsite through what we’re calling “Dynamic Working”. Most associates will have a hybrid schedule with a requirement to work onsite at a Fidelity work location for at least one week, 5 consecutive days, every four weeks. These requirements are subject to change.
We invite you to Find Your Fidelity at fidelitycareers.com.

Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.
Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team by sending an email to accommodations @fmr.com, or by calling 800-835-5099, prompt 2, option 3.
At Fidelity, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry. Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Fidelity offer will need to go through a background investigation and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, Fidelity will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine.","$107,438 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Investment & Asset Management,1946,$10+ billion (USD)
"Lumen
3.5",3.5,Remote,Senior Data Engineer,"About Lumen
Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.
The Role
Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen’s reputation as a technology leader?

In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence.
The Main Responsibilities
You are a great fit for this position if you:
Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions.
Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments.
Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in.
Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations.
What We Look For in a Candidate
Qualifications:
Experience building data models and performing complex queries using SQL
Experience performance tuning large datasets
Experience building large data pipelines and/or web services
Strong programming skills with Python and other scripting languages
4+ years of Business Intelligence or software development experience using industry technologies
3+ years of experience in building integration with upstream and downstream systems with REST APIs
Excellent problem solving, critical thinking, and communication skills
Ability to communicate effectively with technical and business teams, drive issues to closure
Strong understanding of data engineering and data stewardship roles in an organization
Strong time management and organization skills. Ability to work on multiple projects concurrently.
BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science

Other Qualifications:
Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable
Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable
Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies
Combined IT and Marketing background
Machine Learning, Data Science, and statistical modeling experience are highly valued
Azure experience.
Requisition #: 329671
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
72540
Salary Max :
161520
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.","$117,030 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1968,$10+ billion (USD)
"Blue Cross Blue Shield of Louisiana
3.9",3.9,"Baton Rouge, LA",Lead Data Engineer (Remote),"We take great strides to ensure our employees have the resources to live well, be healthy, continue learning, develop skills, grow professionally and serve our local communities. We invite you to apply for a career with Blue Cross.
Please note that effective Jan. 4, 2022, Blue Cross and Blue Shield of Louisiana implemented a policy requiring any employee who enters any of our offices or who interacts in person with anyone for company business purposes to be fully vaccinated for COVID 19, unless legally entitled to a reasonable accommodation related to religious or medical exemptions. At this time, that policy is suspended and vaccination is not required to enter our facilities. Please note this is subject to change at any point in time to ensure compliance with company policy or government mandates and certain client facing roles may have separate protocols.
Residency in or relocation to Louisiana is preferred for all positions.
We will consider remote work in the following states: LA, AL, AR, DE, FL, GA, ID, IN, IA, KS, KY, MS, MO, NE, NH, NC, OK, PA (limited counties), SC, SD, TN, TX, UT, VA, WV, WI.
POSITION PURPOSE
This position develops data integration solutions using data integration tools or other means with some direction provided by the manager as well as more senior team members such as the Principal Data Engineer. Accountable for complying with all laws and regulations associated with duties and responsibilities.
NATURE AND SCOPE
This role does not manage people
Necessary Contacts: INSIDE RELATIONSHIPS:
Make presentations to EIM management.
Must be able to understand the requirements of multiple agile teams, identify and negotiate trade-offs to gain management agreement with proposed recommendations.
Meets regularly with program management, product data management, and EIM management to resolve product and project problems and issues.
OUTSIDE RELATIONSHIPS:
Attends technical meetings and conferences with the intent of improving the processes and procedures of the Enterprise Data Warehouse and/or Data Lake
May participate in vendor negotiations.
Meets with business owners and stakeholders to refine technical requiremen
QUALIFICATIONS
Education
Bachelor's in computer science or related field is required
Four years of related experience can be used in lieu of a Bachelor’s degree.
Work Experience
Must have a minimum of seven years of professional information technology experience to include a minimum of three years’ experience with deployment and support of ETL, software applications, or web services solutions.
Requires knowledge in such areas as data mart data warehouse, data lake development, SSISETL/ELT data integration patterns, web and cloud-oriented systems integration and communication-based systems, languages such as C#, Python or Java. Additional training for integration tools used will be supplied.
Experience in one of the following areas is required: Support of a data warehousing, data mart, data lake, and/or business intelligence environment; Strong ETL development background with Informatica PowerCenter, DataStage, or SSIS; Strong development experience with TeraData, Oracle, SQL Server, Data Lake, or Sybase repositories; Other programming language such as C#, Python, PL/SQL, T-SQL, SparkSQL, NoSQL; Shared API for web or cloud applications development background; Big Data technologies such as Hadoop, Spark, Artificial Intelligence (AI), Machine Learning (ML), Natural Language Processing (NLP); Strong background in software development for applications
Massively Parallel Processing (MPP) DBMS preferred
Visualization, Business Intelligence tools or reporting experience with tools such as Tableau, Power BI, SSRS, SSAS, Cognos or BOE preferred
Project management experience preferred
Healthcare Payer Software Development experience preferred
Experience working in an agile development methodology preferred
DevOps experience (automation of code or workflow through release pipeline) preferred
Data warehousing development lifecycle preferred
Skills and Abilities
Ability to independently design, develop and debug ETL/ELT, software, or API solutions based on business requirements.
Ability to independently evaluate the test results of others
Self-sufficient in ETL/ELT software development with the ability to become self-sufficient in integration tool within one month of completing the training
Ability to independently create complex integrations to build dimensional databases, data marts, data lake, and cubes
Ability to create design patterns
Strong analytical, problem-solving and decision-making skills along with the ability to react quickly to changing requirements due to product limitation or driven by enterprise need
Ability to independently develop Unit Test Plans and Test Data
Ability to independently diagnose and resolve the issues found in workflows, mappings, stored procedures, and data pipelines
Provide guidance to fellow team members in the data analysis effort necessary in following all data integration standards and architecture
Provide guidance to team members in performing root cause analysis and resolving issues related to data/workflows
Provide guidance to team members in the development of system and integration test plans
Provide guidance to team members for executing test plans and documenting the results and discrepancies
Licenses and Certifications
None Required
ACCOUNTABILITIES AND ESSENTIAL FUNCTIONS
Independently analyzes the team’s data integration requirements and creates integration solutions that support the application development efforts.
Works with senior team members such as the Principal Data Engineers to refine the information architectures and complex data models needed for the team’s work. In addition, guides others on the modification and implementation of database integration solutions built around these models to support business requirements.
Responsible for the data integration metadata, lineage, and catalog through configuration and parameterization.
Independently develops, executes and evaluates data quality test plans such that the results and quality of the data assure compliance with corporate expectations. Guides and reviews the work of other team members in this process to ensure accuracy.
Provides guidance and training to junior team members on data warehousing processes and procedures to junior team members.
Follows the software development life-cycle as required to ensure that the company meets regulatory requirements.
Additional Accountabilities and Essential Functions
The Physical Demands described here are representative of those that must be met by an employee to successfully perform the Accountabilities and Essential Functions of the job. Reasonable accommodations may be made to enable an individual with disabilities to perform the essential functions
Perform other job-related duties as assigned, within your scope of responsibilities.
Job duties are performed in a normal and clean office environment with normal noise levels.
Work is predominately done while standing or sitting.
The ability to comprehend, document, calculate, visualize, and analyze are required.
\#LI_DB1
\#LI-Remote
An Equal Opportunity Employer
All BCBSLA EMPLOYEES please apply through Workday Careers.
PLEASE USE A WEB BROWSER OTHER THAN INTERNET EXPLORER IF YOU ENCOUNTER ISSUES (CHROME, FIREFOX, SAFARI)
Additional Information
Please be sure to monitor your email frequently for communications you may receive during the recruiting process. Due to the high volume of applications we receive, only those most qualified will be contacted. To monitor the status of your application, please visit the ""My Applications"" section in the Candidate Home section of your Workday account.
If you are an individual with a disability and require a reasonable accommodation to complete an application, please contact recruiting@bcbsla.com for assistance.
In support of our mission to improve the health and lives of Louisianians, Blue Cross encourages the good health of its employees and visitors. We want to ensure that our employees have a work environment that will optimize personal health and well-being. Due to the acknowledged hazards from exposure to environmental tobacco smoke, and in order to promote good health, our company properties are smoke and tobacco free.
Blue Cross and Blue Shield of Louisiana performs background and pre-employment drug screening after an offer has been extended and prior to hire for all positions. As part of this process records may be verified and information checked with agencies including but not limited to the Social Security Administration, criminal courts, federal, state, and county repositories of criminal records, Department of Motor Vehicles and credit bureaus. Pursuant with sec 1033 of the Violent Crime Control and Law Enforcement Act of 1994, individuals who have been convicted of a felony crime involving dishonesty or breach of trust are prohibited from working in the insurance industry unless they obtain written consent from their state insurance commissioner.
Additionally, Blue Cross and Blue Shield of Louisiana is a Drug Free Workplace. A pre-employment drug screen will be required and any offer is contingent upon satisfactory drug testing results.
JOB CATEGORY: Data Analytics/Warehousing, & Business Intelligence","$78,576 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Insurance,Insurance Carriers,1934,$25 to $100 million (USD)
"ReUp Education
3.8",3.8,Remote,Senior Data Engineer,"The Role
We are looking for an experienced data engineer to help manage, utilize, and build upon ReUp’s data infrastructure. This role will be a key member of the team creating and delivering against a data engineering strategy that will support ReUp’s tech-enabled service as we continue to grow. If you are a curious engineer strong in Python, SQL, AWS, and business acumen, then we want to hear from you!
As a Data Engineer, you’ll maintain critical data architecture, process large volumes of student data, and work collaboratively to create useful reports, dashboards, and data products that support internal teams and university partners. Data is at the heart of everything we do, so we’re always looking to improve these systems to better address a variety of open-ended questions related to student success. Along the way, you’ll help improve inefficiencies, ensure we follow best practices around data, and work on interesting data science projects in areas like predictive analytics and natural language processing. Through this critical role in our data operations, you will better equip us to support our students all the way to graduation.
What we do
Founded in 2015, ReUp Education is the only organization that focuses exclusively on helping colleges and universities engage and re-enroll the more than 40% of US students who have “stopped out” and support them until graduation, through our technology-enabled service. To date, we have re-enrolled nearly 22,500 students, assisted over 8,000 to graduate, and recaptured over $85 million in tuition for our university partners.
What you’ll do
Develop, construct, test and maintain data architectures and pipelines
Build and refine Data Integration Products (such as APIs, integrations, and other data tools)
Leverage (and expand) Python codebase to launch university partnerships, ingest student lists, process partner data, and perform validation
Support data security, compliance, and governance initiatives
Manage (and expand) daily monitoring automation for key systems/processes
Partner with stakeholders (marketing, product, coaching, partner success, finance, etc.) to optimize our systems and develop novel solutions
Contribute to our data strategy to ensure it is aligned with company goals
Manage and setup new ETLs, automated jobs, and workflows
Troubleshoot and resolve issue escalations pertaining to data infrastructure
Protect end users from risk of faulty or inaccurate data
Identify ways to improve data reliability, efficiency, and quality
Collaborate with data scientists to prepare data for machine learning applications (predictive analytics, natural language processing, etc.)
Collaborate with data analysts to create business intelligence assets (analytics reports, dashboards, KPIs, research etc.)
Qualifications
Research shows that women and people from underrepresented groups only apply to jobs if they meet all of the qualifications. However, no one ever meets 100% of the qualifications. ReUp encourages you to break that statistic and to apply. We look forward to your application.
10+ years of related work experience in data engineering required
Experience building and maintaining APIs required
Strong Python and SQL skills required
Experience building within Amazon Web Services (certification a plus)
Experience with Airflow and other workflow management tools
Experience with large scale production environments
Experience with modern development processes and practices
Experience with machine learning technologies
Tableau / Mode Analytics / BI experience a plus
Salesforce CRM experience a plus
Certification in CISA, CISSP or similar data security credential a plus
Higher ed, ed tech, and/or startup experience a plus
Bachelor’s or Master’s degree in Engineering, Computer Science, Data Science, or other quantitative focused field of study a plus
You believe in ReUp’s mission and are committed to helping us create new opportunities for millions of stopout students
Additional
You are a first-principle thinker and creative problem solver
Your attention to detail leaves no stone unturned
You are able to communicate complex ideas effectively
You proactively look for ways to automate and optimize tasks
You enjoy learning in a fast-paced environment
You are collaborative and open to feedback
You have a passion to support data driven decisions while recognizing the humans behind the numbers
Compensation & Benefits
Compensation: $130,000-160,000 annual salary commensurate with experience
Medical, dental, and vision insurance for employees
We pay 100% of the employee's premium and 50% of any dependents' premiums
FSA or HSA available
Company paid short term disability, long term disability, and life insurance for employee
Flexible time off and remote work opportunity
15 paid holidays per year (including Juneteenth and the last week of the calendar year)
Company wellness days (2 per year)
Day of Service (Paid day for volunteering)
401(k) plan
Paid parental leave (12 weeks primary parental leave, 6 weeks secondary parental leave)
A diverse team that fosters a high level of collaboration despite being highly distributed
We provide your choice of a Mac or PC laptop

Location
ReUp is a remote organization with a geographically distributed team. This position will be based remotely in one of the states listed:AL, AZ, CA, FL, GA, IL, MA, MI, MO, NC, NH, NY, OH, OR, PA, SC, TN, TX, VA, WA and WI.
Company Culture
TEAMWORK * RESULTS * CONSTANT LEARNING * AGENCY * DIVERSITY, EQUITY & INCLUSION * JOY

ReUp employees share a passion for improving outcomes for stopout students. We support students to get Results as they embark on finishing what they started. We believe in the power of human potential and that supporting an individual’s Agency acts as a catalyst for positive change and resiliency. We support Diversity, Equity & Inclusion, for both the students we work with and in our hiring practices. We value Teamwork and strive to create a safe and supportive environment where trust, communication, creativity, and humility are valued as highly as technical skills. We tackle hard problems with curiosity and take action towards continuous improvement and Constant Learning. Approaching our work with open hearts, open minds, and seeking collective success creates Joy. If that sounds like your dream work environment, we look forward to hearing from you.

ReUp Education is an equal opportunity employer. Our company values diversity and believes diverse teams make innovation possible. We encourage all qualified applicants from any race, color, religion, sex, gender identity, sexual orientation, national origin, disability status, protected veteran status, or other characteristics to apply.

BByyc1JY4Q","$145,000 /yr (est.)",Unknown,Company - Private,Management & Consulting,Building & Personnel Services,#N/A,Unknown / Non-Applicable
"DISH
3.0",3.0,"Littleton, CO",Staff Data Engineer,"Department Summary:
DISH is a Fortune 200 company that continues to redefine the communications industry.
Our legacy is innovation and a willingness to challenge the status quo, including
reinventing ourselves. We disrupted the pay-TV industry in the mid-90s with the launch
of the DISH satellite TV service, taking on some of the largest U.S. corporations in the
process, and grew to be the fourth-largest pay-TV provider. We are doing it again with
the first live, internet-delivered TV service – Sling TV – that bucks traditional pay-TV
norms and gives consumers a truly new way to access and watch television.

Now we have our sights set on upending the wireless industry and unseating the
entrenched incumbent carriers.

We are driven by curiosity, pride, adventure, and a desire to win – it’s in our DNA. We’re
looking for people with boundless energy, intelligence, and an overwhelming need to
achieve to join our team as we embark on the next chapter of our story.

Opportunity is here. We are DISH.
Job Duties and Responsibilities:

DISH is seeking a Data Analytics Engineer who will be responsible for building the DISH Wireless Commercial data integrations and implementing the fully-automated analytics modules catering to DISH business team needs and the analytics product offerings in the marketplace for Commercial customers. The engineer will focus on building the data pipelines, insights, KPIs, and metrics using the DISH Wireless data from BSS, OSS, NSS, or external sources to business/partners/customers. This individual will play an active role in the delivery and ensure alignment with the end-state architecture.

Key responsibilities:
Provide technical expertise in Wireless Analytics.
Understand business needs and analytics product offerings to design and build data and analytics solutions.
Analyze business and technical requirements.
Quickly build prototypes to test out proofs-of-concept.
Address technical concerns, ideas, and suggestions.
Assist in solving technical problems when they arise.
Monitor systems to ensure they meet the partner, user, and business goals.
Deliver solutions, and features using agile delivery methodologies.
Skills, Experience and Requirements:

Education: Bachelor's degree or equivalent work experience.

Experience:
6+ years as a Data Analytics engineer in the wireless and/or telecom space esp., in Sales, Marketing, Retention, Product, Revenue, Partner Management, etc.
8+ years of hands-on experience with the development and delivery of secure, reliable, and scalable big data solutions using agile methodologies.
Skills and qualifications:
Experience in building highly performant SQL-based solutions delivered using file feeds, Data-as-a-Service APIs, streaming data analytics, or BI tools like Tableau.
Experience in data management and engineering capabilities.
Experience in cloud technologies (like AWS) and data analytics platforms.
Experience in delivering self-service analytics, insights, KPIs, and metrics.
Experience building and maintaining a data catalog with a dictionary.
Experience with scheduling tools like Control-M or Airflow.
Ensure compliance on all deliverables by performing data audits and analysis.
Work attire: Business casual.

Working hours: This is a full-time position: 40 hours/week. Days and hours of work are typically Monday through Friday; 8:00 a.m. to 5:00 p.m. or 9:00 a.m. to 6:00 p.m
Benefits:

We also offer versatile health perks, including flexible spending accounts, HSA, a 401(k) Plan with company match, ESPP, career opportunities, and a flexible time away plan; all benefits can be viewed here: DISH Benefits.

The base pay range shown is a guideline. Individual total compensation will vary based on factors such as qualifications, skill level, and competencies; compensation is based on the role's location and is subject to change based on work location. Candidates need to successfully complete a pre-employment screen, which may include a drug test and DMV check.
Salary Range: USD $100100.00 - $145000.00 / Year","$122,550 /yr (est.)",10000+ Employees,Company - Public,Telecommunications,"Cable, Internet & Telephone Providers",1980,$10+ billion (USD)
"Florida Cancer Specialists & Research Institute
3.3",3.3,United States,Informatics Data Integration Engineer,"Date Posted:
2023-09-18
Country:
United States of America
Location:
Florida - Remote
WHY JOIN FCS
At Florida Cancer Specialists & Research Institute, we believe our people are our strength and we invest in them. In addition to having a positive impact on the people and communities we serve, associates benefit from significant professional opportunities, career advancement, training and competitive wages.
Offering competitive salaries and comprehensive benefits packages to include tuition reimbursement, 401-K match, pet and legal insurance.
A LITTLE BIT ABOUT FCS
Since 1984, Florida Cancer Specialists & Research Institute & Research Institute (FCS) has built a national reputation for excellence. With over 250 physicians, 220 nurse practitioners and physician assistants and nearly 100 locations in our network. Utilizing innovative clinical research, cutting-edge technologies, and advanced treatments, we are committed to providing world-class cancer care. We are recognized by the American Society of Clinical Oncology (ASCO) with a national Clinical Trials Participation Award, FCS offers patients access to more clinical trials than any private oncology practice in Florida. Our patients have access to ground-breaking therapies, in a community setting, and may participate in national clinical research studies of drugs and treatment protocols. In the past five years, the majority of new cancer drugs approved for use in the U.S. were studied in clinical trials with FCS participation prior to approval.
Through our partnership with Sarah Cannon, we are one of the largest clinical research organizations in the United States. Often, FCS leads the nation in initiating research studies and offering ground-breaking new therapies to patients.
Come join us today!
Summary:
Under the direction of the Director of Informatics, the Data Integration Engineer (DIE) will be transformational in bringing Data as a Service (Daas) and true self-service reporting to Florida Cancer Specialists.
RESPONSIBILITIES
The DIE will collaborate with our Data Integration Analysts to help transform clinical- and associated practice management, pharmacy and other data, focusing on optimized data workflow and data quality for FCS internal and DaaS customers.
The DIE will use knowledge of healthcare data requirements to influence the implementation and governance of our DaaS data architecture.
Healthcare data interoperability and data quality domain experience is paramount to the DIE role to help the Informatics team understand use cases, (non)functional and data governance requirements.
As a Data Integration Engineer, you will be responsible for delivering high-quality, low-defect SQL and extract, load, transform (ELT) code on schedule, while assisting with data quality initiatives and database administration tasks.
You will use your knowledge of database engineering to provide recommendations, promote database best practices amongst your sprint team, as well as assist with database issue remediation.
The ideal Data Integration Engineer has a blend of healthcare data integration and technical experience developing database solutions that support scalable solutions.
As a DIE must be passionate about data quality, test-driven development and genuinely enjoy working in an agile DevOps team environment that continuously promotes knowledge growth to bring robustness, provenance and long-term maintainability of our data platform.
QUALIFICATIONS
Education: - Bachelor’s degree in engineer, computer science, technology or another related field. In lieu of degree, 15+ years of experience is required or the equivalent combination for education and experience.
Certifications/Licenses: - Valid state Driver’s License for travel to satellite offices and offsite meetings. Compliance with the company Driver Safety Operations and Motor Vehicle Records Check Policy is required.
Microsoft Azure Certification(s) preferred
Previous Experience
Professional clinical experience within clinical oncology preferred -
10+ years in an active healthcare big-data integration experience with multiple heterogenous data sources with data cleansing and reference/master data management on an enterprise data warehouse to create a centralized ‘trusted data’ set for data analysis.
Technical competencies (T-)SQL to create/maintain DB objects, data modeling, SSMS, SSIS, SSRS, SSAS, NoSQL, Team Foundational System (TFS), microservices, query/load required data using data governance and data visualization tools.
Environment competencies with on prem, data centers and Microsoft Azure cloud system tools with appropriations for disaster recovery development and production systems.
Domain competencies with electronic health record (EHR) (e.g. OncoEMR), practice management (e.g. Centricity), next-generation sequencing (NGS), clinical trial management (CTM), pharmacy specific to antineoplastic medications, laboratory and other healthcare ancillary systems.
EEOC
Florida Cancer Specialists & Research Institute (FCS) is committed to helping individuals with disabilities to participate in the workforce and ensure equal opportunity to compete for jobs. If you require an accommodation to submit a resume for positions at FCS, please email FCS Recruitment (
Recruiter@FLCancer.com
) for further assistance. Please note this email address is intended to request an accommodation as part of the application process. Any other correspondence will not receive a response.
FCS is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status.
SCREENINGS – Background, drug, and nicotine screens
Safeguarding our patients and each other is an important part of how we deliver the best care possible to the communities we serve. All offers of employment at Florida Cancer Specialists & Research Institute are contingent upon clear results of a thorough background screening. Additionally, as a condition of employment, FCS requires all new hires to receive various vaccinations, including the influenza and COVID-19 vaccines, barring an approved exemption. In addition, FCS is a drug-free workplace, and all new hires will be subject to drug/ nicotine testing.",#N/A,1001 to 5000 Employees,Company - Private,Healthcare,Hospitals & Health Clinics,1984,Unknown / Non-Applicable
"MasterControl
4.1",4.1,"Salt Lake City, UT",Senior Data Engineer,"Summary
At MasterControl we are building our next generation data platform that will leverage AI/ML techniques to help redefine how our customers bring life-saving and life-changing products to market. To enable this, we are looking for a Senior Data Engineer to support our Data Science and Machine Learning teams.

Key Qualifications
Expertise working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, Flink, Kafka, etc.) for building efficient & large-scale data pipelines.
Software Engineering proficiency in at least one high-level programming language (Java, Scala, Python or equivalent).
Experience building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.
Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models.
Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimizations like bucketing,aggregating, sharding.
Expertise in one or more NoSQL database (Neo4J, Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.).
Personal Qualities
You are tenacious, relentless, & determined.
You are curious: always learning new technologies, rapidly synthesizing new information, and understanding ""the why"" before ""the what.""
You are self-directed and capable of operating amid ambiguity.
You are poised and display excellent judgment in prioritizing across difficult tradeoffs.
You are pragmatic: not letting ""the perfect"" be the enemy of ""the good.""
You are humble, continually growing in self-awareness and possessing a growth mindset
Education and Experience Qualifications
7+ years in a Data Engineering role
CS Bachelor's degree +
The US base salary range for this full-time position is $180,000-$220,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.","$122,520 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Computer Hardware Development,1993,$25 to $100 million (USD)
"TekBank
4.0",4.0,"Herndon, VA",Sr. Software Data Engineer,"(Master’s or equiv. deg. w/1 yr. exp. OR other suitable qualifications) – Herndon, VA. Req.
Work Experience: Design, Develop, Test & Implement Data Warehouse; & work/w: Oracle, SQL Server, DB2, ETL, Data Marts, Informatica, Business Objects, & Teradata.
Relocation & travel to various locations possible.
Send resumes: HR, TekBank Consultants Inc, 459 Herndon Parkway, Ste 13, Herndon, VA 20170","$100,524 /yr (est.)",Unknown,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"ServiceNow
4.4",4.4,"Kirkland, WA",Sr Staff Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
As a Senior Staff Data Platform Software Engineer, you will have the opportunity to become a key member of the Data Scale team in the Platform Persistence group. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work. Depending on the nature of the data, the storage systems include both relational databases and non-relational database such as columnar database.
What you’ll do and need to know:
You’ll work toward managing our explosive data growth and ensuring our systems remain available and highly responsive.
Delivering complex project on time
Having aptitude for learning new technologies quickly.
Developing platform technologies at scale.
Experience with troubleshooting difficult production issues e.g., memory leaks, concurrency issues, locking issues, network problems, intermittent failures etc. across the stack
Relational Database Experience: Developing on, troubleshooting, and optimizing performance.
Nice to have:
Passionate database technologies
Experience with Unix shell
Experience working with JDBC drivers.
Experience working in a DevOps environment.
Experience working in a customer focused environment.

Qualifications
10+ years of software development experience
Expert level with core Java development
Advanced-Expert level of backend platform development
Expert level understanding of best practices for object-oriented and modularized software. Emphasis on Java
Knowledge and/or experience with relational databases: PostgreSQL, Oracle, MySQL, MariaDB, MS SQLServer, etc.
WJ23
For positions in the Seattle metro/Kirkland areas, we offer a base pay of $184,700 - $323,300, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location.

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$254,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Fourth Technologies, Inc.
3.9",3.9,"Austin, TX",Sr. Data Engineer (W2 Only),"DATA Engineer requirement:
· Bachelor's degree in Statistics, Computer Science, Data Science, or related quantitative field 3-5+ years of experience in business intelligence related roles and at least 2+ years spent as a BI Engineer Proficient with business intelligence platforms,
· Understand business requirements and translate them into consumable and governed solutions Capture data to design KPIs and visualization for different audiences across the enterprise.
· In-depth knowledge of Power BI, including data modeling, DAX expressions, and Power Query.
· Experience in designing and implementing data visualizations, such as charts, graphs, and maps, to present complex data in a user-friendly manner Familiarity with data warehousing concepts and best practices.
· Proficiency in writing complex SQL queries, preferably in Snowflake, for data extraction, manipulation, and optimization.
· Collaborate with key stakeholders to deliver on their data and analytics needs by producing live dashboards and/or reporting with a focus on Self-Service Enablement Maintain access controls to BI and Analytics Platforms, Reports, and Dashboards to ensure sensitive information is restricted.
· Power BI Experience working with stakeholders to gather requirements Expert in SQL and experience with databases such as Snowflake Proficient in concepts and implementation in developing reports, Dashboard, self-service BI, and visualizations AI/ML experience within Power BI
· Previous experience with Tableau is nice to have related to BI and Analytics Financial industry is a plus.
· Build the North Star metrics and models that orient the overall business and our product pods.
· Build and maintain automated forecasting models from the bottom up, including diff to actuals and explanatory models.
· Build anomaly detection routines that detect risks to growth at all margins.
· Proven experience as a Power BI Developer, with a strong background in developing interactive dashboards and reports.
· Strong analytical and problem-solving skills with a keen attention to detail
· Excellent communication and collaboration abilities to work effectively with stakeholders of various technical backgrounds.
· Ability to work independently and manage multiple priorities in a fast-paced environment.
· you will work with big data sets to build forecasts, attribution models, content and engagement value models, user journeys, retention/churn models, and more.
· Come up with quick hypotheses to diagnose and explain trends in our growth.
· Propose strategic initiatives and goals, and perform ad-hoc analysis, to help our functional partners to achieve their goals and drive growth.
· Effectively communicate with people in all disciplines and levels, including the C-suite
· Deep understanding of time series, predictive / statistical modeling, ML, and probabilistic models
Job Type: Contract
Salary: $50.00 - $70.00 per hour
Compensation package:
Performance bonus
Experience level:
5 years
Schedule:
8 hour shift
Ability to commute/relocate:
Austin, TX 78701: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 5 years (Preferred)
SQL: 5 years (Preferred)
Data warehouse: 5 years (Preferred)
Business intelligence: 3 years (Required)
Power BI: 3 years (Required)
Data Modelling: 4 years (Required)
Work Location: In person",$60.00 /hr (est.),51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,1987,$5 to $25 million (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Grace Hopper 2023 : Data Engineer II,"Chewy is looking for Data Engineers to join our Data Engineering Team based in Bellevue, WA. The ideal candidate will be a well-rounded technologist with a passion for building innovative business solutions with big data technologies. Experience delivering big data solutions – from system setup to development to business solution delivery – is critical. Programming experience is also paramount. Big data technologies are constantly evolving. The Data Engineer should be keeping up with the latest developments and should be able to connect technical capability with business need.
What you'll do:
Design analytical solutions for business users that provide the data needed to operate the business.
Design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics platform.
Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes.
Participate in technical decisions and collaborate with talented peers.
Review code, implementations and give meaningful feedback that helps others build better solutions.
Monitor and troubleshoot data mart issues and perform regular backups and disaster recovery procedures.
Write documentation on design, architecture and solutions.
What you'll need:
Experience in data warehouse design and data integration methodologies.
5+ years of SQL expertise and the ability to work with many different database types. Snowflake, Postgres, SQL Server, and others as required.
5+ years of detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools
3+ years of hands-on experience with Snowflake and AWS cloud technologies, including AWS Redshift, AWS Glue, AWS Lambda, and AWS S3, EC2, ECS, Kenisis, DynamoDB, etc
3+ years of experience Integrating data between operational databases using data integration tools like Informatica, CloverDX, Datastage, Talend, Pentaho Data Integrator, or SSIS.
Data modeling experience in large Data warehousing, data lake environment
Proficient in programming languages such as Python, Java, or Scala.
Able to work in a fast-paced environment and be comfortable being accountable for work products.
Experience performing analytics to solve complex business problems.
BS or Master’s in Computer Science, Mathematics, Engineering, or Information Technology.
Position may require travel.
Bonus:
Snowflake certification.
HR data and systems knowledge.
Experience with business intelligence platforms (e.g. Tableau, etc.).
Background incommerce.
Agile experience is a plus.
Experience with statistical methods and data science.
Experience with Terraform.
Hands-on experience designing and developing scalable, high performing and fault-tolerant applications for large enterprises.
Knowledge of data integration and familiarity with common data integration challenges like converting data types, handling errors, and translating between different technology stacks.
Hand on experience delivering high performance distributed systems in public cloud environments.
Compensation & Benefits:
Our salary range for a Data Engineer II position is $115,500.00 - $183,500.00. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.
Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.","$87,595 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Capital One
4.1",4.1,"Richmond, VA",Senior Data Engineer,"West Creek 7 (12077), United States of America, Richmond, Virginia
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies.

Team Info:
As a Global Workplace Solutions Data engineering team, we work with huge quantities of data and have multiple centralized datasets to store our internal and external data sources related to the GWS (Global Workplace Solutions) business team. We have completely automated the ETL process by integrating data pipelines with containerization & serverless tools. We do continuous testing & monitoring of our data pipelines, and always provide cost effective and highly reliable solutions to our business partners. As a Data Engineer on our team, you’ll have the opportunity to be on the forefront of driving major data transformations by working with exciting tech such as AWS, Python, Snowflake, SQL, and Spark, as well as DevOps tools such as Jenkins and Docker!
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance
Create data pipelines to transform data according to business needs

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
2+ years of experience with containerization or container orchestration tools (Docker, Kubernetes)
2+ years of experience utilizing Continuous Integration and Deployment tools (Jenkins, GitLab, ArgoCD, CircleCI, Artifactory)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ years experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"DIRECTV
3.5",3.5,California,Principal-Big Data Engineer,"Interpret the requirements of various Big Data Analytic Use Cases and Scenarios. Drive the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and company data assets. Develop the necessary enablers and data platform in the Big Data Lake Environment and maintain its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment. Support standardization, customization, and ad-hoc data analysis. Develop the mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources. Support Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value by applying rigorous iterative data analytics. Work with Big Data Policy, Security and Legal teams to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods, and techniques. Serve as an advisor on technical knowledge and company technologies. Create architecture diagrams including conceptual/logical data models, data dictionaries, data flow diagrams and data discovery. Analyze business requirements to create technical solutions for data. Define data requirements, gathering and mining large scale of structured and unstructured data. Validate data by running various data tools in the Big Data Environment. Apply experience in Logical and Physical database design using data modeling tools to build innovative solutions for application transition and development of data products. Partner with business analysts, enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Serve as a thought leader to improve design, development and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to business via a defined data architecture. Use cloud-based data warehousing, streaming, batch processing.

REQUIREMENTS: Requires a Bachelor’s degree, or foreign equivalent degree, in Computer Science or Information Technology and 5 Years of progressive, post-baccalaureate experience in the job offered or 5 Years of progressive, post-baccalaureate experience in a related occupation creating architecture diagrams including conceptual/logical data models, data dictionaries, data flow diagrams and data discovery; analyzing business requirements to create technical solutions for data; defining data requirements, gathering and mining large scale of structured and unstructured data; validating data by running various data tools in the Big Data Environment; applying working knowledge of delivering insight projects to business via a defined data architecture; and designing enterprise datawarehousing systems on cloud native real-time streaming and batch data management platforms.

Principal-Big Data Engineers earn between $175,000 to $222,200 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$198,600 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Five9
4.3",4.3,"San Ramon, CA",Software Engineer II – Data Platform,"Five9 provides businesses reliable, scalable, and secure cloud contact center software designed to create exceptional customer experiences, increase agent productivity, and deliver tangible business results.
We are driven by a passion to transform contact centers into customer engagement centers of excellence. Since 2001, Five9 has led the cloud revolution in contact centers, helping organizations transition from legacy premise-based solutions to the cloud.
To complement our rapid growth, we are actively looking for a Software Engineer – Data Platform with experience working on Google Cloud Platform, to join our team. Five9 delivers market-leading up-time for its Contact Center application while constantly delivering new features and capabilities to highly demanding enterprise customers. This requires that Five9 continually enhances, updates and modernizes the Platform Services that the Contact Center Application runs on. This position requires excellent understanding of cloud software: how it's built, deployed, tested and managed. This a hybrid role and the person will need to come into our San Ramon office 3 days per week (Monday, Wednesday, Thursday).
Key Responsibilities:
Contribute to the next generation of Five9's modern SaaS platform and applications, providing businesses the ability to improve customer service through the power of AI in the Contact Center.
You will play a critical role in developing a highly-available, highly-scalable and reliable infrastructure for microservices.
You will apply your expertise of cloud computing stack, broad software technologies, and open source tools to resolve what are often considered seemingly unsolvable cloud technology platform challenges for our customers.
Gain deep application-level knowledge of existing systems as well as contributing to their overall design.
Dive deep into the software stack to troubleshoot and provide production support as needed.
Work with a team of peers, share a passion for what they're creating and pull your own weight.
Key Qualifications:
2+ years of software development experience as part of a Java development team using Spring Boot.
1+ years with Cloud Platform (AWS, Azure, GCP as plus) and Spring Cloud.
Experience with designing and building highly available and scalable applications in GCP.
Experience and hands on skills with GCP Products such as Google Big Query, Cloud Storage, Cloud Functions, Pub/Sub, App Engine, Cloud SQL.
Experience and hands on skills with Docker, Kubernetes.
Hands on experience working as part of a Continuous Delivery team who continuously develop, test, deploy and manage production applications on Google Cloud Platform.
Good understanding of private and public cloud design considerations and limitations in the areas of virtualization and global infrastructure, distributed systems, load balancing and networking, event processing, massive data storage and security.
Bachelor's degree in an engineering field.
An advanced degree in an engineering or a business discipline is highly desirable.
#LI-RN1
#LI-Hybrid

As part of our commitment to diversity, equity, and inclusion, Five9 supports pay transparency during the entire recruitment process. Actual compensation packages are based on several factors that are unique to each candidate including, but not limited to: skill set, depth of experience, certifications, and specific work location. The range displayed reflects the minimum and maximum target for new hire salaries for the job across the United States. Your recruiter can share more about the specific compensation package during your hiring process.

Additionally, the total compensation package for this position may also include an annual performance bonus, stock, and/or other applicable incentive compensation plans.

Our total reward package also includes:
Health, dental, and vision coverage, beginning on the first day of employment. Five9 covers 100% of the employee portion of the health, dental and vision coverage and shares a high portion of the dependent cost. We also offer Short & Long-Term Disability, Basic Life Insurance, and a 401k saving plan with employer matching.
Generous employee stock purchase plan.
Paid Time Off, Company paid holidays and 12 weeks paid parental leave.
All compensation and benefits are subject to the requirements and restrictions set forth in the applicable plan documents and any written agreements between the parties.
The US base salary range for this role is below.
$100,000—$177,200 USD
Five9 embraces diversity and is committed to building a team that represents a variety of backgrounds, perspectives, and skills. The more inclusive we are, the better we are. Five9 is an equal opportunity employer.
View our privacy policy https://www.five9.com/pt-pt/legal.
California residents, view our Privacy Notice here: https://www.five9.com/legal/candidatenoticeca.

-
Our headquarters are located in the San Francisco Bay Area with global hubs in the United Kingdom, Germany, Philippines, Portugal, and Australia.","$140,755 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2001,$100 to $500 million (USD)
"CSAA Insurance Group
3.6",3.6,"Glendale, AZ",Data Engineer - Remote,"Opening Statement: CSAA Insurance Group (CSAA IG), a AAA insurer, is one of the top personal lines property and casualty insurance groups in the U.S. Our employees proudly live our core beliefs and fulfill our enduring purpose to help members prevent, prepare for and recover from life's uncertainties, and we're proud of the culture we create together. As we commit to progress over perfection, we recognize that every day is an opportunity to be innovative and adaptable. At CSAA IG, we hire good people for a brighter tomorrow. We are actively hiring for an Data Engineer. Join us and support CSAA IG in achieving our goals.
Your Role:
The Data Engineer is responsible for providing technical support for Data Pipeline implementation, monitoring and administration. It is extremely important to the company that data processing from multiple source systems into the Cloud data warehouse offer the highest reliability and performance possible. The admin is challenged to work with architecture, application development and other infrastructure teams to help achieve a state-of-the-art platform that meets current and future business objectives.
The Data Engineer will work with all the data environments across the enterprise, maintain and upgrade the systems as needed. The role will work with the development teams and tune the code for performance improvement. Additionally, this induvial will provide input and suggestions for any Infrastructure changes, while participating and documenting disaster recovery process, and procedures and maintain a living document.
Your work: (Essential responsibilities)
Manage and maintain the application platforms to support the uptime and availability in both Production and Test environments
Validate the data pipeline executions to ensure that they are completed within the SLA’s.
Troubleshoot issues related to data pipelines, data integrations, bug fixes, performance bottlenecks
Working with multiple cross functional teams like DBA, Unix Server Administrator, Vendor Support to resolve any incidents / problems
Support development teams as needed acting as Subject Matter Expert
Upkeep of the systems by implementing security features like certificate, vulnerability, user access and service account management
Migrate the legacy platforms to the next gen cloud platforms using AWS EMR, EC2 and Snowflake Cloud DataWarehouse
Identify the areas of improvement by automating day to day activities
Analyze and organize raw data to extract patterns for KPIs and Metrics to publish dashboards
Work with Data Scientist / Business Analyst community to support the AI / ML Model development environments and operationalization of the models
Be able to support Master Data Management Reltio , API Hub
What would make us excited about you?
BS in Computer science or equivalent experience skill sets required
Prior experience as a data engineer or in a similar role
5 + years of ETL Tool Administration / management experience eg Informatica
2 + years of experience in Streamsets
2 + years of experience in Cloud technologies like AWS
3 + years of experience on Database technologies like Oracle, SQL and Snowflake
Hands on experience using SQL queries
Hands on experience supporting Reltio platform
Hands on experience supporting API Hub
Knowledge of programming languages (eg Java and/or Python)
A can do attitude to think big and fail fast
Confidence can sometimes hold us back from applying for a job. But we’ll let you in on a secret: there’s no such thing as a ‘perfect’ candidate. CSAA IG is a place where everyone can grow. So, however you identify and whatever background you bring with you, please apply if you meet most of the requirements (not all) and this is a role that would make you excited to come to work every day.
CSAA IG Careers
At CSAA IG, we’re proudly devoted to protecting our customers, our employees, our communities, and the world at large. We are on a climate journey to continue to do better for our people, our business, and our planet. Taking bold action and leading by example. We are citizens for a changing world, and we continually change to meet it.
Join us if you…
BELIEVE in a mission focused on building a community of service, rooted in inclusion and belonging.
COMMIT to being there for our customers and employees.
CREATE a sense of purpose that serves the greater good through innovation.
Recognition: We offer a total compensation package, performance bonus, 401(k) with a company match, and so much more! Read more about what we offer and what it is like to be a part of our dynamic team at: Benefits
In most cases, you will have the opportunity to choose your preferred working location from the following options when you join CSAA IG: remote, hybrid, or in-person. Submit your application to be considered. We communicate via email, so check your inbox and/or your spam folder to ensure you don’t miss important updates from us. If a reasonable accommodation is needed to participate in the job application or interview process, please contact TalentAcquisition@csaa.com.
As part of our values, we are committed to supporting inclusion and diversity at CSAA IG. We actively celebrate colleagues’ different abilities, sexual orientation, ethnicity, and gender. Everyone is welcome and supported in their development at all stages in their journey with us.
We are always recruiting, retaining, and promoting a diverse mix of colleagues who are representative of the U.S. workforce. The diversity of our team fosters a broad range of ideas and enables us to design and deliver a wide array of products to meet customers’ evolving needs.
CSAA Insurance Group is an equal opportunity employer.
The national average salary range for this position is $119,520-$132,500. However, we have a location-based compensation structure. Our salary ranges vary and are calculated based on county of residence. The full [salary range] [hourly rate range] for this position across all the states we hire in is $107,280-$159,200. This role also includes an opportunity for a company-wide annual discretionary bonus, through our Annual Incentive Plan (AIP), of up to 10% of eligible pay.
If you apply and are selected to continue in the recruiting process, we will schedule a preliminary call with you to discuss the role and will disclose during that call the available salary/hourly rate range based on your location. Factors used to determine the actual salary offered may include location, experience, or education.
Please note we are hiring for this role remote anywhere in the United States with the exception of California, Hawaii and Alaska.
#HP_RX
#Dice_RX
#Expand
#LI-JM1",#N/A,1001 to 5000 Employees,Company - Private,Insurance,Insurance Carriers,1914,Unknown / Non-Applicable
"Autodesk
4.3",4.3,California,"Senior Software Engineer, Real Time Streaming Data Platform","Job Requisition ID #
23WD72478
Position Overview
Are you excited by solving technical challenges that come with building a scalable, available, performant platform used by millions of users worldwide? Come join us at Autodesk! Autodesk's Analytics Real Time Data Platform group is seeking a passionate Senior software engineer to join a team of diverse and driven engineers who will build a large-scale streaming platform to support near-realtime ingestion of product data at Autodesk.
This engineer will collaborate within a Scrum team where the code, infrastructure, and services you develop will have a direct, positive impact on millions of users of our products. This experience is key to our business and one of our top initiatives around customer experience.
Location: Preference to Pacific Time Zone, United States. Hybrid or Remote United States.
Responsibilities
Experience delivering highly available, scalable, distributed systems and microservices in a production setting
Experience developing scalable and resilient data ingestion and processing pipelines, monitoring and self-healing systems, real time data platform.
You will ownership of the implementation of individual software components, with a high emphasis on quality, test-driven development, and sound software engineering practices
Participate in software design reviews, you conduct peer code reviews and provide input and feedback to other members of the development team
Write unit, functional, regression tests for the code you create, and you contribute to the test automation, continuous integration, and deployment processes together with everyone else in the development team
Collaborate as a member of an agile team to get products and components developed and completed with software development
Low tolerance for inefficiency and the burning desire to automate anything that can be automated
Creative, collaborative, and product-focused
Experience making simple and scalable platforms used by other engineering teams
Work with architects and technical product managers to translate overall system architecture and product requirements into well-designed and implemented software components
Minimum Qualifications
BS or MS in Computer Science or related technical field
5+ years of software engineering experience
Experience writing performant code in Java or Python
Experience with streaming technologies, Kafka, Flint, AWS Kinesis Firehose, and Infrastructure
Hands-on experience with AWS, cloud architectures, and Terraform
Experience working with container frameworks (Docker) or CD frameworks (Eg. Spinnaker)
Experience with microservices, RESTful web services, SDK
Experience with development and deployment of system features and QA frameworks
Debugging and testing experience
Quick learning curve
Team Oriented
Experience with Jenkins, GitHub, and Artifactory
Preferred Qualifications
Experience working in an Agile/Scrum environment
Experience working with Data Lake or Warehouses, ETLs
#LI-JK1
At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.
Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact
Autodesk Careers
.",#N/A,10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1982,$5 to $10 billion (USD)
"NVIDIA
4.6",4.6,"Santa Clara, CA",Principal Offensive Security Engineer – Data Center Systems,"NVIDIA is searching for a highly motivated, creative engineer with experience in system software and background in security to join the Server Platform Software team. You will focus on offensive security efforts for our Data Center Systems, such as NVIDIA HGX, DGX, and MGX.
What you’ll be doing:
Identify vulnerabilities in our Data Center Systems, build proof of concepts, and work with development teams to remediate
Perform security reviews of software and hardware designs and assist others to ensure quality and robustness of our products
Evangelize and drive adoption of new or improved tools, practices, and plans to increase product robustness and reliability
What we need to see:
BS or MS degree in Computer Engineering, Computer Science, or related degree (or equivalent experience)
12+ years of meaningful software engineering experience
Demonstrate security experience in either a forensic or an offensive security focused role
Excellent C programming and low-level driver experience
Experience with software development lifecycle best practices, e.g. threat modeling, unit testing, incident response, code audit, etc.
Experience with secure code quality practices and tooling to support quick engagements and rapid analysis - static analysis tools (Coverity, Checkmarx, or similar), dynamic scanning (Rapid 7, AppSider, or similar), Fuzzing (AFL, Peach, or similar) and code coverage (Bullseye, LDRA, etc)
Experience with modern server architectures
Effective written and verbal communication regardless of audience or issue complexity. Ability to work collaboratively and remotely with others to accomplish complex goals
Ways to stand out from the crowd:
Experience with System reversing and exploitation. Experience with penetration techniques and tools
Experience and familiarity with GPU accelerated computing systems
You are an asset if you have familiarity with computer system architecture, microprocessor, and microcontroller fundamentals (caches, buses, memory controllers, DMA, etc.)
NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. If you're creative, passionate and self-motivated, we want to hear from you! NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services.
The base salary range is $268,000 - $414,000. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and
benefits
.
NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.","$341,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1993,$5 to $10 billion (USD)
"Voloridge Investment Management
4.7",4.7,"Jupiter, FL",Sr Data Engineer,"At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.
Summary of Job Functions
Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues
Minimum Requirements
10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office
Preferred Skills and Previous Experience
Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines
Compensation and Benefits
Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K
Additional Information
Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.
Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.","$124,974 /yr (est.)",51 to 200 Employees,Company - Private,Financial Services,Investment & Asset Management,2009,Unknown / Non-Applicable
"Amazon Development Center U.S., Inc.
3.7",3.7,"East Palo Alto, CA","Software Engineer, Data Lake Formation","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
Be part of a team which is passionate about solving real world data management and governance challenges. Come build large scale distributed systems that are central to the next generation of analytics in the cloud.

AWS Lake Formation is a service that helps build and secure data lakes in a simple, scalable, server-less architecture. We are looking for software engineers to join our growing team!

As a Software Engineer in Lake formation you will:
Solve unique and first-order problems in areas of Big Data, Distributed Systems, and Server-less data processing
Influence and build products that will leverage scale of resources to orchestrate data management and governance
Be catalyst to deliver a truly disruptive product while still early enough to have impact and influence
Key job responsibilities
Translate functional and technical requirements into detailed architecture, design and extensible code
Be an advocate of industry best-practices to produce reliable, fault-torrent and dependable code
Code and test complex system modules; develop and leverage frameworks to be effective and efficient
Participate in architecture, design and code reviews to maintain our high development standards
Mentor other engineers, defining our challenging technical culture, and helping to build a fast-growing team
Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.

About the team
We are builders and data people that are obsessed with our customers and take-on big challenges. We support each other and encourage different views. We also like to have a bit of fun along the way.

We are open to hiring candidates to work out of one of the following locations:

East Palo Alto, CA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Apple
4.2",4.2,"San Diego, CA",Senior Software Engineer - Data Cloud,"Summary
Posted: Sep 19, 2023
Role Number:200503418
Ready to work with large scale data systems that generate invaluable insights to teams that develop Apple's operating systems? The systems required to efficiently build and manage that software produces billions of events per day and provides a unique opportunity to invaluable insights. Join an early stage team that is building a modern analytics platform using an innovative approach to software engineering, ML, and cloud data management! We believe that every engineer brings unique skills and perspectives to the table. Far more than any specific experience or skill set, we are looking for engineers who are driven to build robust and reliable software, eager to learn and hone their skills, and enthusiastic about facilitating growth and knowledge sharing among team members.
Key Qualifications
5+ years experience designing scalable data systems or cloud services using modern tools and languages.
Proficient in SQL with at least 2 years of experience using cloud data analytics platforms such as Snowflake, Redshift, or BigQuery.
Demonstrated ability to define and implement team standards in operational and development processes, from initial launch to maintenance, incorporating CI/CD and automated testing.
History of creating maintainable and well-documented tools in shared, open-source or internal codebases, showcased through examples or references.
Description
The Data Cloud team is building an analytics platform that create invaluable insights to Apple’s development teams and their leadership. You’ll work on all aspects of the system including infrastructure as code, data pipelines, data modeling, documentation, and other tools and services. Work directly with customers to understand their requirements and develop architectural solutions that prioritize performance, maintenance, and security. IN YOUR ROLE AS A SENIOR ENGINEER YOU WILL: - Create scalable solutions that enable other teams to be more productive with their data. - Define operational mechanisms that allow our team to scale efficiently. - Design and implement data modeling and governance strategies in Snowflake. - Automate testing, data verification, and deployments using Pulumi, DBT, and other technologies. - Create tools, services, docs, and frameworks that can be leveraged by multiple teams to simplify data ingestion. - Develop high-performance data pipelines and services on AWS and internal cloud systems. - Champion the refinement and adoption of standards for internal open source initiatives. - Provide technical mentorship and contribute to hiring. - Present technical designs and strategies to your team, customers, and leadership. Here you’ll find that we are committed to excellence in software development, working alongside a team of highly skilled colleagues who are open to collaboration and knowledge sharing. We offer a relaxed work environment that promotes personal and professional growth. As our team is in the early stages of formation, you will have the opportunity to take the lead on several new initiatives.
Education & Experience
BS in Computer Engineering, Electrical Engineering, Computer Science, Math, or equivalent experience.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $189,800 and $284,900, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Encore Technologies
4.5",4.5,Remote,Data Center Network Engineer,"Encore Technologies is seeking a Data Center (ACI/Nexus) Network Engineer/Architect for its client in Louisville, KY. This is a fulltime position and can be remote with some travel.
**Not a C2C role
Data Center (ACI/Nexus) Network Engineer/Architect. Focus is on route/switch/network management in a large enterprise data center environment.
Responsibilities:
· Perform design and deployments for the Cisco data switching technology including Nexus/ACI with Nexus Dashboard
· Troubleshoot and resolve tier2/3 data center network issues
· Address and resolve escalated issues for routing/switching in a large data center environment.
· Assist in the design/deployment of new locations and new solutions.
· Design/deploy solutions that scale and adhere to data security standards
· Manage project tasks
· On-call one week every 2 months
Qualifications:
· Experience with Aruba 3810/5412/6200/6300 switches, Cisco 5K,7K,9Ks, ASR platforms and the associated management platforms (IOS, NXOS, ArubaOS, Aruba CX)
· Strong understanding of routing/switching protocols
· Experience with Aruba ClearPass as a NAC solution would be valuable in this role
· Data center experience with load-balancing and firewalls would be a plus
· Must be a self-starter, able to manage project tasks on your own.
Encore Technologies is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce.
Job Type: Full-time
Pay: $140,000.00 - $150,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Education:
Bachelor's (Required)
Experience:
Network infrastructure: 7 years (Required)
Nexus: 7 years (Required)
Willingness to travel:
25% (Required)
Work Location: Remote","$145,000 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2014,$100 to $500 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer - Data Collections, Prime Air","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
Knowledge of professional software engineering & best practices for full software development life cycle, including coding standards, software architectures, code reviews, source control management, continuous deployments, testing, and operational excellence
Experience programming with at least one modern language such as Java, C++, or C# including object-oriented design
3+ years of big data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza experience
Experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems
Experience developing applications that tightly-integrate to Linux-based host systems and custom hardware.
Here at Amazon, we embrace our differences. We are committed to furthering our culture of diversity and inclusion of our teams within the organization.

How do you get items to customers quickly, cost-effectively, and—most importantly—safely, in less than an hour? And how do you do it in a way that can scale? Our teams of hundreds of scientists, engineers, aerospace professionals, and futurists have been working hard to do just that! We are delivering to customers, and are excited for what’s to come. Check out more information about Prime Air on the About Amazon blog (https://www.aboutamazon.com/news/transportation/amazon-prime-air-delivery-drone-reveal-photos).

If you are seeking an iterative environment where you can drive innovation, apply state-of-the-art technologies to solve real world delivery challenges, and provide benefits to customers, Prime Air is the place for you.

Come work on the Amazon Prime Air Team!

Prime Air is seeking an experienced Software Development Engineer to support software-related technical aspects of our solutions; you will translate requirements and architectures into sustainable aerial tools and will work across the Prime Air program to define, develop and solve unique challenges.

The ideal candidate is a creative technical contributor with superior analytical skills. Additionally, they will have experience with sensor data collection and associated post-processing pipelines. They will understand underlying cloud and automation technologies required to create and sustain post-processing pipelines that are robust and well-instrumented. Additionally, they will have an interest in the collection software/hardware (SW/HW) systems that push data into the post-processing pipeline. Knowledge of the full SW/HW development lifecycle is key for success.

To be successful in this role, you must be able to collaborate effectively within a small team, accurately prioritize projects, make sound judgments, deliver quality on-time, continually work to improve system performance, and create systems that are as easy to maintain as they are a joy to use.

Key job responsibilities
Export Control License: This position may require a deemed export control license for compliance with applicable laws and regulations. Placement is contingent on Amazon’s ability to apply for and obtain an export control license on your behalf.

We are open to hiring candidates to work out of one of the following locations:

Seattle, USA | Seattle, WA, USA

Experience in machine learning, data mining, information retrieval, statistics or natural language processing
Experience prototyping new technologies/frameworks, establishing well-instrumented systems that provide appropriate performance metrics, and testing/debugging new/prototype systems.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","ADSP Bidder Data Pipeline - Software Dev Engineer, ADSP Cornerstone Corridor","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
Do you want to solve business challenges through innovative technology? Do you enjoy working on cutting-edge, scalable services technology in a team environment? Do you like working on industry-defining projects that move the needle?

At Amazon, we hire the best minds in technology to innovate and build on behalf of our customers. The focus we have on our customers is why we are one of the world’s most beloved brands – customer obsession is part of our company DNA. Our Software Development Engineers (SDEs) use cutting-edge technology to solve complex problems and get to see the impact of their work first-hand.

The challenges SDEs solve for at Amazon are big and influence millions of customers, sellers, and products around the world. We are looking for individuals who are passionate about creating new products, features, and services from scratch while managing ambiguity and the pace of a company where development cycles are measured in weeks, not years. If this sounds interesting to you, apply and come chart your own path at Amazon.

While the majority of our SDE roles are based in the greater Seattle/Bellevue, WA area, by applying to this position your application will be considered for all locations we hire in the United States. This includes, but is not limited to Nashville, TN; Austin, TX; Greater Bay Area, CA; DC Metro Area; Denver, CO; Detroit, MI; Greater Boston Area, MA; Greater Denver Area, CO; Greater Los Angeles Area, CA; Greater New York Area; Irvine, CA; Madison, WI; Minneapolis, MN; Phoenix, AZ; Portland, OR; San Diego, CA. To qualify, applicants should have earned a Bachelor’s or Master’s degree within the last six months or be on track to earn their Bachelor’s or Master’s degree prior to the role start date.

Key job responsibilities
Collaborate with experienced cross-disciplinary Amazonians to conceive, design, and bring innovative products and services to market.
Design and build innovative technologies in a large distributed computing environment and help lead fundamental changes in the industry.
Create solutions to run predictions on distributed systems with exposure to innovative technologies at incredible scale and speed.
Build distributed storage, index, and query systems that are scalable, fault-tolerant, low cost, and easy to manage/use.
Design and code the right solutions starting with broadly defined problems.
Work in an agile environment to deliver high-quality software.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Palo Alto Networks
4.2",4.2,"Santa Clara, CA",Sr Principal UI Engineer (Data Visualization),"Company Description

Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
FLEXWORK is an employee-centric reimagining of how we work. We built FLEXWORK based on employee feedback – it is about flexibility, trust, and choice whenever possible. It’s been a journey of disruption that has yielded the best of our values. We offer as much flexibility as possible, and choices that enable you to be most productive, including benefits that meet your needs and learning opportunities that you feel passionate about.
Our Approach to Work
At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!

Job Description

Your Career
Our NetSec UI Engineering team is set out to build best-in-class, novel data visualization experiences that are custom to the cybersecurity use cases, for all the product teams across Network Security vertical at Palo Alto Networks. As a Data Visualization Engineer at Palo Alto Networks, your work will directly reach, and empower our products that are revolutionizing the cybersecurity industry.
Your Impact
Collaborate cross functionally with designers, data visualization experts, and engineers on the NetSec UI team to implement and support the reusable, and customizable data visualization components
Implement an architecture for the data visualization library that is scalable to multiple JS frameworks, and in the future Web Components
Write quality, and meaningful tests, and documentation to ensure easy adoption of the data visualization library
Create a playground GUI with a custom settings bar that users can play around with to tweak the different properties of the visualization

Qualifications

Your Experience
Bachelor’s degree or higher in Computer Science, Information Technology, Engineering, or equivalent experience or equivalent military experience required
10+ years professional experience as a data visualization /front-end engineer
Portfolio showcasing data visualization development proficiency
Great team player, willing to take on new challenging tasks
Self-driven with ability to work both independently and within a team environment to accomplish goals and objectives
Expertise in JavaScript, D3, WebGL, and/or Shader language GL/SL, HTML, CSS
Experience massaging large raw datasets to work well with simple and intuitive data visualization
Familiarity with client-side modern build processes & tools - Webpack/Rollup
Comfortable with maintaining, and contributing to code repositories using git, GitHub/GitLab or other version control
Ability to create quick prototypes for data visualization projects with D3js
Bonus Points
Strong in frontend web development technologies, including ReactJS, TypeScript, with bonus points for experience with animation
Familiarity or willingness to learn data visualization technologies like VegaJS, ThreeJS, Observable Plot or new cutting edge libraries
Passion for building performant, interactive and accessible data visualization components

Additional Information

The Team
The NetSec UI team is responsible for delivering solutions to our customers at Palo Alto Networks. Our team has a unique position in driving efforts to create accessible, performant, and cutting edge UI and data visualization components/modules.
We foster a culture of innovation, authenticity, and collaboration. Our people make this possible. It’s in our everyday interactions, how we work together and treat each other, that sets Palo Alto Networks apart from other organizations.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $170,000/yr to $275,000/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.","$222,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
"Walmart
3.4",3.4,"Dallas, TX",Data Engineer III,"Position Summary...

What you'll do...

As a Data Engineer III, you will play a pivotal role, developing, and maintaining our data infrastructure. You will collaborate with cross-functional teams including Data Scientists, Data Analysts, and Business Intelligence experts to deliver high-quality, well-structured, and performant data solutions. Your expertise in SQL, data pipelines, ETL processes, and data visualization tools will be crucial to enabling data-driven decision-making throughout the organization.

About Team:

What you'll do:
Consolidate and standardize all connections to external systems and programmatic exchanges. (WPA,DFP/GAM, ANX, TTD, LiveIntent, Adobe, Pinterest, LiveRamp etc)
Provide a unified create/read/update/delete API for operations across all of the third-party systems
Provide a normalized view of campaigns and metrics from these different sources for other systems to use.
Generate insights and reports for advertiser campaigns in both real-time and batch mode
Collect and aggregate ad delivery metrics (real-time impression, viewability etc.).
Partner with DS to build and enhance sales lift methodologies, including synthetic control, ghost ads etc.
Build and operate a data warehouse for analytics and business operations
Expose all reports via reporting APIs and data tables
Collaborate with engineering and infra teams to build a ML and experimentation platform
Ownership of ML models for audience targeting. Build and improve relevance and ranking models for ad serving
Ownership of lift measurement methodology, and support enhancement of attribution models and buyer analytics

What you'll bring:
4+ years of experience in software development, focusing on distributed systems
Big data development experience including Hadoop.
Experience in GCP/Azure cloud platforms
Experience building streaming pipeline using spark streaming or kafka or similar.
Experience with workflow management tools such as Jenkins, Airflow, Oozie or similar.
Experience working with SQL or RDBMS databases such SQL server, mySQL, DB2, etc.
Experience working with No-SQL databases such as Cassandra, Bigquery, Cosmos DB etc.,
Experience building enterprise DWH using Teradata or Hadoop/Hive or Bigquery or Azure Synapse
Experience running spark/hadoop workloads using Dataproc, Dataflow, Cloud composer, EMR, HD Insights or similar.
Proven working expertise with Big Data Technologies Spark, PySpark, hive, and SQL.
Demonstrates up-to-date expertise in Data Engineering, complex data pipeline development
Architect, Design, develop, implement, and tune distributed data processing pipelines that process large volume of data; focusing on scalability, low -latency, and fault-tolerance in every system built.
Exposure to Data Governance ( Data Quality, Metadata Management, Security, etc.)
Experience with Java, Scala and/or Python to write data pipelines and data processing layers
Demonstrates expertise in writing complex, highly optimized queries across large data sets
Knowledge and experience in Kafka, Storm, Druid and Presto
Good Knowledge on object-oriented programming & build tools such as maven, sbt or similar.
Some exposure to machine learning and data science
Experience in AdTech and advertising measurement
Experience with data visualization tools such as Looker, Tableau


About Walmart General/Not Function Specific
Sam Walton opened the first Sam's Club in 1983 to meet a growing need among customers who wanted to buy merchandise in bulk. Since then, Sam's Club has grown rapidly, opening more than 600 clubs in the U.S. and 100 clubs internationally. By offering affordable, wholesale merchandise to members, Sam's Club helps make saving simple for families and small business owners. Sam's Club employs about 110,000 associates in the U.S. The average club is 134,000 square feet and offers bulk groceries and general merchandise. Most clubs also have specialty services, such as a pharmacy, an optical department, a photo center, or a tire and battery center.

Future Ways of Working:
Our company's success can be attributed to our employees. While technology has allowed us to be effective while working remotely, there is no substitute for being in the office together; it helps to shape our culture, collaborate, innovate, build relationships, and move more quickly. We strive to provide flexibility in order to promote a healthy work-life balance but recognize that in-person interactions are important to our culture and shared success. We'll meet in person on a regular and purposeful basis.

Benefits:
Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.

Equal Opportunity Employer:
Sam's Club is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.

Minimum Qualifications...

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.

Option 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 2 years' experience in software engineering or related area.Option 2: 4 years' experience in software engineering or related area.

Preferred Qualifications...

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.

Customer Service

Masters: Computer Science

Primary Location...
603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America","$132,138 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,General Merchandise & Superstores,1962,$10+ billion (USD)
"Nike
4.2",4.2,"Beaverton, OR",Data Engineer,"Become a Part of the NIKE, Inc. Team

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

NIKE is a technology company. From our flagship website and five-star mobile apps to developing products, managing big data and providing leading edge engineering and systems support, our teams at NIKE Global Technology exist to revolutionize the future at the confluence of tech and sport. We invest and develop advances in technology and employ the most creative people in the world, and then give them the support to constantly innovate, iterate and serve consumers more directly and personally. Our teams are innovative, diverse, multidisciplinary and collaborative, taking technology into the future and bringing the world with it.

Data Engineer -NIKE, Inc., Beaverton, OR. Develop, mentor, design and implement features in collaboration with team engineers, product owners, data analysts, and business partners using Agile and Scrum methodology. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Build utilities, user defined functions, and frameworks to better enable data flow patterns. Research, evaluate and utilize new technologies, tools, frameworks centered around high-volume data processing. Define and apply appropriate data acquisition and consumption strategies for given technical scenarios. Build, incorporate, and drive teams to write automated unit tests and integration scripts using the Python test unit framework. Ensure quality solutions are implemented and engineering standard methodologies are defined and adhered to. Implement security around sensitive data.

Employer will accept a Master's degree in Engineering Management, Computer Engineering, Computer Information Systems or Data Discipline 2 years of experience in the job offered or in an engineering-related position.
ETL;
AWS Services;
PySpark;
Python;
Snowflake;
SQL;
APIs;
Data modeling;
Agile/Scrum;
SignalFX;
Meerkat;
GitHub;
Jira; and
Jenkins.

#LI-DNI

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

How We Hire

At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.

This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.

Benefits

Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$100,364 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"Meta
3.9",3.9,"Mesa, AZ",SiteOps Data Center Infrastructure Services Engineer,"The Site Operations team is responsible for the delivery of data center compute and storage at Meta, enabling our family of apps and services to support a growing global community. We are seeking a forward thinking technologist skilled across multiple disciplines to lead global initiatives on this team. The Infrastructure Services Engineer works across multiple teams and disciplines to identify and take on multifaceted technical, business, and operational problems, delivering effective and impactful solutions while working and communicating with stakeholders. This position requires working collaboratively with cross-functional partners to bring initiatives from concept through solution in data centers around the globe. The ideal candidate should thrive in a matrixed organizational structure that is complex, highly technical and requires innovative design, planning, execution, and communication to succeed.


SiteOps Data Center Infrastructure Services Engineer Responsibilities:
Represent Site Operations in leading work to define and architect new solutions on global initiatives, by working with key partner teams across multiple disciplines.
Understand and assess risks and challenges associated with emerging new hardware, data center, and software technologies, and define plans for how to address and mitigate these.
Effectively bridge between the logical and physical world, ensuring a holistic understanding of the full infrastructure stack.
Serve as a communication and advisory point of contact for the design, implementation and delivery of projects that affect our global data center and server fleet, and facilitate resolution of issues drawing on local expertise and global support partners.
Address issues that often are ambiguous and of global nature, requiring leadership and collaboration across time zones, teams, and technical domains.
Leverage data-driven methodologies to identify and understand a problem at the onset, defining a plan, and being able to measure progress throughout a project. Provide data supplied narratives and ensure a strong focus on continuous improvement.
Build and support strong cross-functional connections with teams across the globe and serve as an advocate for the Site Operations Team with key partners, influencing policies and procedures to improve global data center operations.
Ability to travel 20-30% required.



Minimum Qualifications:
BS or BA in technical field or commensurate experience
10+ years of technical and/or operational experience in a large-scale data center or IT Infrastructure environment.
Experience building and operating globally scalable solutions and translating global strategic initiatives into local executable projects.
Knowledge of the interdependencies of data center functions and technologies including electrical, cooling, structured cabling, security, network, server, and storage systems.
Experience communicating the results of analysis and insights to cross functional teams and influencing the strategy of these teams.
Experience working in a highly distributed environment, across teams/department boundaries.



Preferred Qualifications:
Six Sigma certification, with a preference for Green Belt or higher levels of certification.
Proven track record of championing and supporting innovation, including the successful adoption of new technologies, piloting new designs and delivery methods, and promoting best practices on both local and global levels.
Extensive experience as a continuous improvement agent, applying industry-leading operations and business reviews to gain deep visibility into business health and facilitating data-driven decision-making processes.
Demonstrated expertise in strategic thinking methodology, with a strong experience to develop and execute strategies for complex cross-functional site and global initiatives.
Strong background in driving data analytics and metrics in a complex environment, adept at identifying inefficiencies, opportunities, exceptions, correlations, and proactively responding to potential impacts on the business.
Proven experience to challenge and collaborate with world-class technical operations teams, delivering operational performance and providing valuable engineering insights and tools to effectively manage a hyperscale infrastructure.
Demonstrated experience assembling and leading cross-functional teams to tackle operational challenges, showcasing a broad understanding of Meta’s overall infrastructure.



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$156,999 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Procter & Gamble
4.1",4.1,"Phoenix, AZ",Data Analytics Engineer,"Job Location
Cincinnati
Job Description
If data is in your blood, then we have the job to get your heart pumping!
From day 1, you'll be a key member of the engineering team driving end-to-end data and analytical solutions supporting the development, learning, and operational insights for our critical new engineering led initiatives in equipment, process, packaging, customization and supply chain.
As a Data Analysis Engineer, you will:
Work across important Data & Analytics Community of Excellence capability areas of: Data Science, Dana Engineering, Data Wrangling, Edge Programming, SME Analyst/Business Intelligence, Visualization/Citizen Scientist Ux.
Engage project teams to understand project needs/requirements and provide technical expertise with data and analytical tools.
Collaborate with data leaders and multi-discipline teams to design, develop and ensure critical data systems infrastructures and integration offer critical data model availability and scalability.
Ensure relevant data and analytics are available to meet initiatives and technical readiness needs by continuously addressing the data models, wrangling and cleansing data, and improving data solutions and platforms.
Explore emerging capabilities and Artificial Intelligence/Machine Learning for flawless integration and application between data scientist, functional specialists and their key user cases.
We believe the following skills will help you be successful:
Technical Mastery: Strategic, systems problem solver who will automate existing manual decision support and data workflows to drive key innovation and business performance improvement.
Builds Diverse and Collaborative Relationships: We seek an independent, collaborator who sees the interaction in our enterprise and systems while understanding the role that data and intelligence play in dramatically improving the user cases for the subject matter systems.
Leadership: Have the ability to set technical direction by applying and building mastery in our Product Supply Engineering innovation and delivery efforts, while demonstrating diverse data, analytics and visualization skills. Seeking immediate impact to accelerate our engineering processes, improve technical readiness of initiatives and enhance product and service execution in our manufacturing sites and supply network.
We offer you:
Dynamic and respectful work environment. At P&G our employees are at the core, we value every individual and encourage initiatives, promoting agility and work/life balance.
Continuous coaching. You will work with passionate people and receive ongoing coaching and mentoring from your line manager and other colleagues. Corporate and functional training will enable you to succeed and develop from day one.
Benefits. You will receive a competitive salary as well as other great benefits including a competitive pension, share ownership scheme and private healthcare.
Are you ready to join our Engineering team?
Job Qualifications
REQUIRED:
BS/MS in a quantitative field (Engineering, Data Science, Operations Research, Applied Math, Statistics, Analytics)
These positions are entry-level with up to 4 years work experience
PREFERRED EXPERIENCE:
Data management, ingesting new data, transforming/harmonizing data
Data analytics insights and work processes for learning and decision
support
Strong leadership, business problem definition, and priority setting skills
Prior Innovation Development, or Supply Chain, or IoT or related experience
An aptitude for communicating insights and collaborating across teams/organizations
Skills in data visualization (Tableau, Power BI, or similar) and script program languages (SQL, Python/Scala, R, JAVA, C+)
Data analytics and insight environments (Apache Hadoop, Spark, Hive, SQL Server, SAP Bus, WH)
Passion to learn/develop and bring in emerging trends/technology that drive further insight value
Proven success of applied analytics through related full-time or internship experience
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.

Immigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.

Procter & Gamble participates in e-verify as required by law.

Qualified individuals will not be disadvantaged based on being unemployed.
Job Schedule
Full time
Job Number
R000084077
Job Segmentation
Recent Grads/Entry Level (Job Segmentation)
Starting Pay / Salary Range
$85,000.00 - $115,000.00 / year","$100,000 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1837,$10+ billion (USD)
"R1 RCM, Inc.
3.4",3.4,Remote,Data Engineer III,"We are seeking a Sr. Data Engineer to join our Data Platform team. This role will report to the director of data platform and be involved in the planning, design, and implementation of our centralized data lake solution supporting analytics, products and applications across the company.
Qualifications:
To be successful in this role the candidate needs to have the following qualifications:
Deep knowledge of Scala and Spark
Experience with Databricks is preferred.
Deep knowledge of modern orchestration frameworks such as Apache airflow
Experience working with SQL and NoSQL database systems.
Experience with cloud environments (Azure Preferred)
Experience with acquiring and preparing data from primary and secondary disparate data sources.
Experience with agile project management methodology
Healthcare industry experience preferred, including exposure to different EMR systems, revenue cycle management.
Knowledge of healthcare data standards such as HL7, FHIR, EDI X12 is a plus but is not required.
Responsibilities:
Be part of an engineering team in building data adaptors to expedite the data onboarding process from various health systems.
Work with product management and business analysts on design reusable and configurable data orchestration pipelines.
Work with data specialist in develop and design data transformation to standardize the data model and support data enrichment activities.
As a subject matter expert, hosts information sharing session with teams within data platform or larger R1 organization.
Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests.

Our associates are given valuable opportunities to contribute, to innovate and create meaningful work that makes an impact in the communities we serve around the world. We also offer a culture of excellence that drives customer success and improves patient care. We believe in giving back to the community and offer a competitive benefits package including:
Comprehensive Medical, Dental, Vision & RX Coverage
Paid Time Off, Volunteer Time & Holidays
401K with Company Match
Company-Paid Life Insurance, Short-Term Disability & Long-Term Disability
Tuition Reimbursement
Parental Leave
R1 RCM Inc. (“the Company”) is dedicated to the fundamentals of equal employment opportunity. The Company’s employment practices , including those regarding recruitment, hiring, assignment, promotion, compensation, benefits, training, discipline, and termination shall not be based on any person’s age, color, national origin, citizenship status, physical or mental disability, medical condition, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status or any other characteristic protected by federal, state or local law. Furthermore, the Company is dedicated to providing a workplace free from harassment based on any of the foregoing protected categories.
If you have a disability and require a reasonable accommodation to complete any part of the job application process, please contact us at 312-496-7709 for assistance.
CA PRIVACY NOTICE: California resident job applicants can learn more about their privacy rights California Consent",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2003,Unknown / Non-Applicable
"INEOS Energy
3.5",3.5,"Denver, CO",Data Engineer II,"Company:
INEOS Energy
Interested in joining a winning team? A team whose employees are empowered to make a difference?
Do you have a desire to make a real impact in the Energy industry? Do you thrive on a challenge? If so, then INEOS Energy want to hear from you!
At INEOS Energy we produce and trade oil, gas, power, liquefied natural gas (LNG) and carbon credits. This is supported by our investments in low carbon technologies, which will help sustain our business through the energy transition. Direct examples of these areas are ‘Project Greensand’, our pioneering carbon storage project in the Danish North Sea and our investment in HydrogenOne Capital.
Our top priority is the health and safety of our staff both on and offshore. We foster a work environment founded on trust, respect, and teamwork. Hard work and the belief that nothing is impossible is at the core of the INEOS values, we believe this is what sets us apart from the rest.
Join us on our exciting journey as we shape the future with innovative field development projects, energy transition, new energy investments as well as the safe and reliable production of energy for our customers.
We currently have the following exciting opportunities within Denver-based US Oil & Gas team:
Job Title: Data Engineer II Department: Information Technology
Summary of Position
We are seeking a Data Engineer to be responsible for designing, developing, and optimizing our data pipelines and data warehouse solutions. The ideal candidate will have hands-on experience with Snowflake and Azure, as well as a strong understanding of data modeling, ETL processes, and cloud-based data solutions. They will collaborate closely with cross-functional teams to ensure the availability, reliability, and performance of our data infrastructure.
Responsibilities
Design and develop scalable, efficient, and reliable data pipelines using Snowflake, Azure, and other cloud-based technologies.
Collaborate with stakeholders to understand data requirements and translate them into technical specifications.
Develop and implement data integration and ETL processes from various sources into our data warehouse.
Optimize data pipelines and ETL processes for improved performance, scalability, and data quality.
Design and implement data models and schemas in Snowflake, ensuring data integrity and optimization for analytics and reporting.
Enable data consumption via visualization tools or APIs.
Develop and maintain documentation for data engineering processes, standards, and best practices.
Monitor and troubleshoot data pipeline issues, ensuring data availability and reliability.
Stay up to date with industry trends and advancements in data engineering, Snowflake, and Azure technologies.
Qualifications
Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
5+ years proven experience as a Data Engineer, preferably in a cloud-based environment.
Strong proficiency in Snowflake and Azure, with 5+ years of hands-on experience in data modeling, SQL, and performance tuning.
Experience with designing and building scalable data pipelines using tools like Apache Spark, Azure Data Factory, or similar technologies.
Proficient in scripting languages (Python, PowerShell, etc.) for data processing and automation tasks.
Familiarity with oil and gas data models and upstream processes is a plus.
Solid understanding of data warehousing concepts, ETL processes, and data integration techniques.
Strong problem-solving and troubleshooting skills.
Excellent communication and collaboration skills, with the ability to work effectively in cross-functional teams.
Ability to adapt to changing priorities and manage multiple projects simultaneously.
Demonstrated commitment to safety regulations and guidelines.
Relocation:
Preferential treatment will be granted to candidates residing in the Denver, Colorado metropolitan area.
Work Authorization:
INEOS USA Oil & Gas LLC is not currently sponsoring employment visas for this position.
Compensation & Benefits
Please note that the compensation information that follows is a good faith estimate for this position only and is provided pursuant to the Colorado Equal Pay for Equal Work Act (EPEWA) and Equal Pay Transparency Rules. It is estimated based on what a successful Colorado applicant might be paid. It assumes that the successful candidate will be in Colorado or perform the position from Colorado. Similar positions located outside of Colorado will not necessarily receive the same compensation.
Compensation:
The annual rate for this position generally ranges between $92,000 - $138,000 with an opportunity for a company-wide annual discretionary bonus, of up to 24% of eligible pay. This role may also be elgibiel to participate in a Long Term Incentive Plan with an annual target between 8-16%. These ranges are estimates, based on potential employee qualifications, operational needs, business performance to metrics, and other considerations permitted by law. The range may vary above and below the stated amounts, as permitted by Colorado Equal Pay Transparency Rule 4.1.2.
Benefits:
Benefits package includes healthcare, dental, and vision insurance for employees and eligible dependents. INEOS also offers several other wellness, financial, and work/lifestyle-specific benefits. 401(k) retirement has both an automatic 3% company contribution and a match of up to an additional 6% of eligible compensation. We offer generous paid time off that includes both sick and vacation which is based on and increases, with industry experience.
Our culture is one of honesty and integrity with an emphasis on safety, health and environmental performance.On our team, people are acknowledged for embracing new practices that help create real value for customers.

Job Details
Location Denver, CO, United States
Discipline IT
Type Full-time
Business INEOS Energy
Posted 16 September 2023
Requisition ID REQ-1521","$105,430 /yr (est.)",10000+ Employees,Company - Private,Manufacturing,Chemical Manufacturing,1998,$10+ billion (USD)
"Coveros
3.4",3.4,United States,Data Engineer,"A Great Place to Share Your Passion and Make a Difference
Coveros helps organizations modernize their software development process by embracing agility, while integrating application security and software quality into the software lifecycle. We provide consulting, coaching, and learning opportunities in Agile, DevOps, AppSec, and Test Automation to enterprises, teams, and individuals. We aim to be Trusted Advisors to our clients who are undergoing change.
Culture at Coveros
As a remote-first company, we provide a stimulating, friendly, and casual work environment, where we live our core values of Client Focused Delivery, Openness, Shared Success, and Building Strong Relationships. In an atmosphere of continuous growth and learning, we invite employee input and employ active mentoring.
Coveros is an equal opportunity employer, dedicated to a policy of non-discrimination in employment on any basis including age, sex, color, race, creed, national origin, religion, marital status, sexual orientation, political belief, or disability.
The Opportunity
Coveros employees share a passion for helping organizations advance and accelerate their software development and security processes. We celebrate great work and teammates who consistently give their best. Our remote team of collaborative experts is expanding and adding an experienced, quality-obsessed Data Engineer as its newest member.
As an exceptional data engineer, you will fulfill a core position on our consulting team. Through your dedication and knowledge, you will help clients replace time-consuming, manual processes in order to make informed, real-time, intelligent decisions.
For a skilled and dedicated data nerd who abhors mediocrity, this opportunity positions you to lead the team in discovering truth and finding meaning in data. An ideal addition to our team is a hands-on engineer who is proficient in data management and governance standards. Equally important, we seek someone with strong interpersonal skills who is comfortable working cross-functionally across internal teams as well as directly with end users and client platform SMEs.
A curious and eager problem solver will thrive in our environment where we value the delivery of high-quality data solutions. You shine when figuring out complex problems and providing smart, simple solutions to them. And always, while multiple answers to a problem may exist, you capably lead the team through constructive dialogue to implement the best path forward.
Qualifications
US Citizenship is required – Due to the nature of this role supporting U.S. government organizations, individuals who are not U.S. Citizens will not be considered.
Required
Bachelor's degree in Computer Science, Mathematics or related technical field
3-5 years of experience in programmatically transforming data
RDBMS experience
Advanced SQL programming experience
Python programming experience
Knowledge and use of Apache Spark
Proficient use of common data formats such as CSV, XML, and JSON
Strong analytical ability and attention to detail
Ability to work independently with little supervision
A drive to create sustainable solutions that solve hard problems
Nice-to-Have
Experience using Amazon Web Services
Experience with OpenSearch
Experience automating ETL pipelines
Hands-on knowledge working with large amounts (multiple terabytes) of data
Experience in (or exposure to) the nuances of a startup or other entrepreneurial environment
Any specific experience in MLOps is a plus!
Responsibilities
Define and lead the data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage.
Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository.
Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison, and classification.
Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts.
Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency.
Work across functional teams to understand advanced statistical, machine learning, and text processing models and incorporate them into the existing data engineering infrastructure.
Actively collaborate with the DevOps team to automate processes where possible.
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures and, using non-technical language, articulate techniques and results.
We firmly believe that past performance is the best indicator of future performance. If you thrive in a fast-paced environment, have a bias toward action, and care about solving technical problems in the national security domain, apply today for consideration.
Coveros is a melting pot of seasoned IT and business professionals from Fortune 500 and leading consulting companies who deliver high value on challenging client engagements. We hire great people and provide room and support for employees’ professional growth. For talented computer scientists and software engineers who share our passion for software, joining Coveros provides an opportunity to work alongside and to learn from brilliant, technical software engineers.
We believe that employees are our greatest asset. Our business model and benefits package reflect that belief.
Competitive base salaries
Company-wide profit sharing plan
401K with matching percentage
Comprehensive health benefits, including dental and vision
Generous paid time off and holidays plan
Basic Life & Personal Accident Insurance and Disability Insurance
Voluntary Life and Personal Accident Insurance
Tuition Reimbursement, plus comprehensive competency-based online skill development training programs
Adoption Assistance
Apply today and move toward a Coveros career where management values you and actively looks to help you advance your skills.
By submitting your application, you are also agreeing to receive future company news, offers, and product communications from Coveros/TechWell. You may unsubscribe at anytime.",#N/A,1 to 50 Employees,Company - Private,Information Technology,Software Development,2008,Unknown / Non-Applicable
"Truist Bank
3.5",3.5,"Raleigh, NC",Lead Data Systems Engineer,"The position is described below. If you want to apply, click the Apply Now button at the top or bottom of this page. After you click Apply Now and complete your application, you'll be invited to create a profile, which will let you see your application status and any communications. If you already have a profile with us, you can log in to check status.
Need Help?
If you have a disability and need assistance with the application, you can request a reasonable accommodation. Send an email to Accessibility (accommodation requests only; other inquiries won't receive a response).
Regular or Temporary:
Regular
Language Fluency: English (Required)
Work Shift:
1st shift (United States of America)
Please review the following job description:
Provide consultation and technical direction on translating business requirements and functional specifications into logical program designs.
Facilitate the implementation and maintenance of complex business and enterprise software solutions to ensure successful deployment of released applications.
Serve as a technical expert for project teams throughout the implementation and maintenance of business and enterprise software solutions. In addition, this role personally develops and delivers code modules, stable application systems, and integrated enterprise software solutions within various computing environments.
Resolve complex problems spanning multiple applications to drive improvements across portfolios; lead projects with significant business implications, participates in planning and priority estimates, and advises Software Engineers; executes with limited guidance.
Lead development of integrated business and/or enterprise application solutions to ensure specifications are flexible, scalable, and maintainable and meet architectural standards.
Educate others on current architectural standards and guidelines to drive efficiency when leading the design efforts of complex business and enterprise software solutions.
Support systems integration testing (SIT) and user acceptance testing (UAT) for large, complex, cross-functional application initiatives by providing insight to testing teams in order to ensure the appropriate depth of test coverage.
Mentor and advise others in all software development lifecycle phases by applying and sharing an in-depth understanding of company and industry methodologies, policies, standards, and controls.
Communicate changes in software architecture and coaches others to apply this understanding to software solutions; resolve escalated issues.
Lead efforts to improve engineering, test, and operational excellence best practices.
Solve complex cross-functional architecture/design and business problems; solutions are extensible; work to simplify, optimize, remove bottlenecks, etc.
Mentor and advise others, sharing an in-depth understanding of company and industry methodologies, policies, standards, and controls.
Requirements
Must have a Bachelor’s degree in Computer Science, Computer Engineering, Electrical/Electronics Engineering, or related technical field.
Must have 5 years of progressive experience in software development or IT infrastructure positions performing the following:
MuleSoft Platform support
API Development and Support
Working on project(s) involving the implementation of solutions applying development life cycles (SLDC)
Designing and automating regular maintenance activities using Python and other scripting languages;
Writing technical documentation in a software development environment
Working with Continuous Integration/ Continuous Deployment tools
Working with source code control systems
Ensuring infrastructure changes adhered to Information Technology Infrastructure library (ITIL), and Change Management, security access procedures and policies
Assessing and testing infrastructure changes (service requests, automated incidents, and change management) to evaluate business risk from a server, storage, network, and API perspective using Service Now.
Utilizing experience with: SOAP & REST services; MuleSoft, MuleSoft Any Point API, and Mule ESB; and RAML & Rest-based APIs.
Position may be eligible to work remotely but is based out of and reports to Truist offices in Raleigh, NC. Must be available to travel to Raleigh, NC regularly for meetings and reviews with manager and project teams within 24-hours’ notice.
General Description of Available Benefits for Eligible Employees of Truist Financial Corporation: All regular teammates (not temporary or contingent workers) working 20 hours or more per week are eligible for benefits, though eligibility for specific benefits may be determined by the division of Truist offering the position. Truist offers medical, dental, vision, life insurance, disability, accidental death and dismemberment, tax-preferred savings accounts, and a 401k plan to teammates. Teammates also receive no less than 10 days of vacation (prorated based on date of hire and by full-time or part-time status) during their first year of employment, along with 10 sick days (also prorated), and paid holidays. For more details on Truist’s generous benefit plans, please visit our Benefits site. Depending on the position and division, this job may also be eligible for Truist’s defined benefit pension plan, restricted stock units, and/or a deferred compensation plan. As you advance through the hiring process, you will also learn more about the specific benefits available for any non-temporary position for which you apply, based on full-time or part-time status, position, and division of work.
Truist supports a diverse workforce and is an Equal Opportunity Employer that does not discriminate against individuals on the basis of race, gender, color, religion, citizenship or national origin, age, sexual orientation, gender identity, disability, veteran status or other classification protected by law. Truist is a Drug Free Workplace.
EEO is the Law Pay Transparency Nondiscrimination Provision E-Verify","$107,161 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,2019,$5 to $10 billion (USD)
"CVS Health
3.1",3.1,"Austin, TX","Principal DevOps Engineer ( Data Platform , Cloud ) - Remote","Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
CVS Health, a healthcare innovation company, is committed to providing Individuals, Employers, Healthcare professionals, producers, and others with innovative benefits, products, and services. The industry is evolving and the opportunities to drive real change and improve the health of millions are endless. If you are passionate about making a difference in the work you do, being recognized for your talent and expertise in solving complex and challenging clinical data problems while contributing to the success of key strategic initiatives, consider growing your career with a Fortune 6 healthcare leader!

The Principal DevOps Engineer will be a Technical Subject Matter Expert / Individual Contributor accountable for leading the organizational transformation in developing devops tooling, practices, and culture. You will contribute to enterprise wide requirements and ensure adoption of same, including observability, scalability, availability, security, cost performance.

The Principal DevOps Engineer will:
Lead DevOps strategy covering design, development of tools, practices and culture.
Establish and enforce DevOps best practices, including version control, code review, automated testing, and deployment strategies.
Architect and manage infrastructure as code, utilizing tools like Terraform, Ansible, or similar, to provision and manage resources across cloud environments.
Implement and manage CI/CD pipelines using tools like Jenkins, CircleCI or like ensuring rapid and reliable application deployment.
Collaborate with security and compliance teams to ensure teams are adhering to industry best practices and regulatory requirements.
Monitor and analyze DevOps pipelines and practices, identifying areas for improvement, optimization, and automation to enhance launch/failback consistency and accuracy.
Keep up-to-date with emerging data technologies, trends, and best practices, and make recommendations for their adoption within the organization's DevOps ecosystem.
Mentor and provide technical guidance to junior team members, fostering a culture of knowledge sharing and continuous learning.

If you are excited about the opportunity to work as a Technical Senior IC leading Devops development / transformation and meet the qualifications mentioned above, we encourage you to apply.

Full-time Remote will be considered for this role.
Required Qualifications:
Proven track record with at least 10 years of experience in DevOps data platform development, preferably in a senior or lead capacity.
Experience working in public cloud environments, GCP (preferred) / Azure / AWS and containerization technologies (e.g., Docker, Kubernetes).
Proficiency in infrastructure as code concepts and tools (e.g., Terraform, Ansible) for automating resource provisioning and configuration.
Hands-on experience with CI/CD pipeline tools (e.g., Jenkins, CircleCI) and version control systems (e.g., Git).
Solid scripting skills in languages such as Python, Bash, or similar.
Strong problem-solving and analytical skills, with the ability to troubleshoot complex DevOps platform issues and provide effective solutions.
Excellent communication and collaboration skills, with the ability to work effectively with cross-functional teams and stakeholders.

Preferred Qualifications:
Familiarity with monitoring and logging tools (e.g., Prometheus, Grafana, Splunk, Cloud Logging Solutions) to ensure application performance and system health.
Knowledge of security best practices in DevOps, including experience with vulnerability scanning, compliance frameworks, and secure deployment practices.
Leadership experience, including mentoring and guiding junior engineers, is a plus.
Education:
Bachelor's or Master's degree in Computer Science, Data Science, or a related field. Master's degree preferred.
Pay Range
The typical pay range for this role is:
$140,000.00 - $280,000.00

This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. This position also includes an award target in the company’s equity award program.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health colleagues can initiate a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through myHR (1-888-694-7287, or through myLeave at myHR). If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.","$210,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1963,$10+ billion (USD)
"Disney Media & Entertainment Distribution
3.9",3.9,"San Francisco, CA",Lead Data Engineer,"Job Overview
Our Data and Analytics team for Disney Streaming Services (DSS), a segment under the Disney Entertainment & ESPN Technology (DE&ET) is looking for a Lead Data Engineer. Data is essential for all our decision-making needs whether it’s related to product design, measuring advertising effectiveness, helping users discover new content or building new businesses in emerging markets.
This data is deeply valuable and gives us insights into how we can continue improving our service for our users, advertisers and our content partners. Our Engagement and Retention Data Engineering team is seeking a highly motivated Data Engineer with a strong technical background and passionate about diving deeper into Big Data to develop state of the art Data Solutions.
What You'll Do
Contribute to the design and growth of our Data Products and Data Warehouses around Engagement and Retention Analytics and Data Science
Design and develop scalable data warehousing solutions, building ETL pipelines in Big Data environments (cloud, on-prem, hybrid)
Our tech stack includes Hadoop, AWS, Snowflake, Spark and Airflow and languages include Python, Scala
Help architect data solutions/frameworks and define data models for the underlying data warehouse and data marts
Collaborate with Data Product Managers, Data Architects and Data Engineers to design, implement, and deliver successful data solutions
Maintain detailed documentation of your work and changes to support data quality and data governance
Ensure high operational efficiency and quality of your solutions to meet SLAs and support commitment to our customers (Data Science, Data Analytics teams)
Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team
Key Qualifications
At least 7 years of data engineering experience developing large data pipelines
Strong SQL skills and ability to create queries to extract data and build performant datasets
Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data
Strong programming skills in Python, Java/Scala
Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query)
Solid experience with data integration toolsets (i.e Airflow) and writing and maintaining Data Pipelines
Strong in Data Modeling techniques and Data Warehousing standard methodologies and practices
Familiar with Scrum and Agile methodologies
You are a problem solver with strong attention to detail and excellent analytical and communication skills
Nice to have experience with Cloud technologies like AWS (S3, EMR, EC2)
Required Education
Bachelor’s or Master’s Degree in Computer Science, Information Systems or related field

The hiring range for this position in California is $149,240 - $200,200 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$174,720 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Indium Software
4.1",4.1,"Pittsburgh, PA",Senior Data Engineer,"Job Information
RSD NO
7473
Industry
IT Services
Min Experience
5 Years
Max Experience
10 Years
City
Pittsburgh
State/Province
Pennsylvania
Country
United States
Zip/Postal Code
15201
Job Description
Title: Senior Data Engineer
Education Qualification: Bachelor's degree in Computer Science, Information Technology, or a related field.
Experience: 5-10 years
Location: Pittsburgh
Work Mode: Work from Office

Required Skills:
Snowflake engineers with strong SQL skills

Snowflake Architecture and Design.
SQL and Data Modeling.
ETL and Data Integration.
Performance Tuning and Optimization.
Cloud Computing (AWS, GCP)Data Warehousing Concepts.
Data Security and Compliance.
Data Migration and Replication.
Azure
Snowflake engineers with strong SQL skills","$113,744 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,1999,$25 to $100 million (USD)
"NCR
3.6",3.6,"Atlanta, GA",Lead Data Engineer - Cloud Platforms,"About NCR
NCR Corporation (NYSE: NCR) is a leader in transforming, connecting and running technology platforms for self-directed banking, stores and restaurants. NCR is headquartered in Atlanta, Ga., with 38,000 employees globally. NCR is a trademark of NCR Corporation in the United States and other countries.
The digital banking’s Cloud Engineering mission is to take a proactive approach to maintain the integrity of our Digital First banking platform. As a member of the Cloud Platform team, you will accomplish this by implementing and enforcing standards and practices that promote security, availability, and performance. You will provide guidance, tooling, and best practices to our development teams so that they can develop reliable, performant, scalable applications in the cloud.
As a senior engineer in the organization, you will provide mentoring within our own team as well as to our peer teams so that we can continue to grow skill and expertise across our core initiatives.
Responsibilities:
Partner with cloud architects to build, test and revise proposed architectures and solutions
Assist in building various tools/automation to streamline existing processes
Work with Development, Security and Business Unit teams to deliver a world class cloud platform
Build automation scripts and frameworks to improve operational processes and procedures.
Learn, deploy and document newer technologies for the potential deployment of services following a development and release life cycle
Support production escalations as needed.
Driving ongoing improvements and efficiencies in operational practices, tools & processes.
Required Skills/Experience:
Experience with GKE
Experience with GCP and AWS
Experience with Java
BS in Computer Science or related field, or equivalent experience.
Must have high initiative and be a clear communicator.
Must be good at setting up and troubleshooting environments
Extensive experience with Splunk or other log aggregation tools.
Strong knowledge/experience with Application and Infrastructure Delivery automation, orchestration and configuration management.
Experience operating and troubleshooting VMs in a virtual environment.
Experience operating within cloud environments
Experience with physical and virtual Networking; Cisco firewalls a plus.
Continued establishment of best in class DevOps development, automation and deployment practices, policies and standards.
Desired Skill Set:
Container build/management
Cloud migrations (Google/AWS)
Scripting – Python
Version control – Perforce, GIT
Build/Release - Jenkins, Maven, GCC, Make
Networking – Infoblox, F5, vCNS
Offers of employment are conditional upon passage of screening criteria applicable to the job.
Full time employee benefits include:
Medical Insurance
Dental Insurance
Life Insurance
Vision Insurance
Short/Long Term Disability
Paid Vacation
401k
EEO Statement
Integrated into our shared values is NCR's commitment to diversity and equal employment opportunity. All qualified applicants will receive consideration for employment without regard to sex, age, race, color, creed, religion, national origin, disability, sexual orientation, gender identity, veteran status, military service, genetic information, or any other characteristic or conduct protected by law. NCR is committed to being a globally inclusive company where all people are treated fairly, recognized for their individuality, promoted based on performance and encouraged to strive to reach their full potential. We believe in understanding and respecting differences among all people. Every individual at NCR has an ongoing responsibility to respect and support a globally diverse environment.

Statement to Third Party Agencies
To ALL recruitment agencies: NCR only accepts resumes from agencies on the NCR preferred supplier list. Please do not forward resumes to our applicant tracking system, NCR employees, or any NCR facility. NCR is not responsible for any fees or charges associated with unsolicited resumes.","$132,444 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1884,$5 to $10 billion (USD)
"Jack Henry and Associates, Inc.
3.8",3.8,"Monett, MO",Systems Engineer III : VMware \ Data Protection,"At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you’ll join us. We can’t do it without you.

As part of the Infrastructure Engineering team the Systems Engineer III will design, document, implement, and maintain virtual infrastructure systems in an enterprise VMware vSphere environment. Perform capacity and performance analysis and provide recommendations for optimization. Complete lifecycle and other project-based work efforts as part of a larger interdisciplinary team. Drive continuous improvement by providing guidance on system automation, monitoring, configuration, and delivery to improve uptime and increase efficiency.

The salary range for this position is: $90,000- $115,000 based on location and experience.

This position will be filled to work Remotely within the United States.

What you’ll be responsible for:
Design, document, implement and maintain virtual infrastructure systems in a high availability, 24x7x365 enterprise environment.
Participate in high visibility projects for top corporate priorities.
Develop and maintain standard operating procedures.
Monitor alerting systems and servers.
Perform troubleshooting, and problem analysis and resolution.
Review issues, logs, and capacity reports to identify trends and solutions that should be implemented enterprise wide.
Develop custom reports to meet the business needs.
Drive continual service improvement.
Assist with disaster recovery initiatives and Implement solutions to streamline disaster recovery.
May perform other job duties as assigned.

What you’ll need to have:
Minimum of 5 years of experience in a systems engineer role designing and implementing VMware vSphere solutions in an enterprise environment.
Proficiency with VMware vCenter Server and ESXi 7.0 and 8.0.
Experience deploying and maintaining VMware virtual infrastructure.
Strong verbal and written communication skills.
Ability to work an on-call rotation including nights and weekends based on business needs.
Ability to travel up to 5% to attend meetings, trainings, and/or professional conferences.

What would be nice for you to have:
VMware Certified Professional - Data Center Virtualization (VCP - DVC) certification.
Strong knowledge of disaster recovery using Commvault, VMware Site Recovery Manager and/or Zerto.
Scripting and Infrastructure as Code tools and methodologies such as PowerShell, Python, Ansible and Terraform.
Experience working with other VMware products: VMware Cloud Director, NSX, Aria Operations (vRealize Operations), Aria Operations for Networks (vRealize Network Insights), and Horizon.
Change Management process experience.
Able to multi-task and use independent judgment to plan, prioritize and organize a diversified workload.

If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry’s mission and can contribute to our company in a variety of ways.

Why Jack Henry?

At Jack Henry, we pride ourselves through our motto of, ""Do the right thing, do whatever it takes, and have fun."" We recognize the value of our associates and believe much of our company’s strength and success depends on their well-being.

We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.

Culture of Commitment

Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.

Equal Employment Opportunity

At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business—and our society—stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.

No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.

Requests for full corporate job description may be requested through the interview process at any time.","$102,500 /yr (est.)",5001 to 10000 Employees,Company - Public,Financial Services,Banking & Lending,1976,$1 to $5 billion (USD)
"HelioCampus
3.6",3.6,"Philadelphia, PA",Data Center Engineer,"Who We Are:
Born out of higher education, HelioCampus works with institutions throughout North America to optimize financial decision-making and assessment/accreditation processes, and provide a more integrated approach to strategic planning and institutional effectiveness. HelioCampus is backed by professionals passionate about the impact of innovation on the mission of higher education.
What We Do:
HelioCampus helps colleges and universities measure and evaluate their effectiveness in fulfilling their mission by connecting investments with financial, operational, and student learning outcomes. We help our partners see the pathway to institutional sustainability.
How We Do It:
HelioCampus turns institutional data into a highly effective asset by combining powerful technology platforms with best practices from the field. Our solutions present data in ways that allow higher ed stakeholders to take informed actions and mitigate risk. We couple unmatched institutional expertise with proven data models, insightful workflows and innovative software.
How You’ll Help:
You will work on a combination of exciting new projects and initiatives while also working to improve and maintain HelioCampus’ existing solutions (using AWS cloud and Colocation). You will become an integral part of a fast-growing Networking and infrastructure team dedicated to the success of higher education.
What You’ll Do:
Design, configure, deploy, maintain, and administer network connectivity supporting our data center, inclusive of VMware, network software, hardware, and tools
Implement and support Data Center Network distribution, routing, switching, firewalls, VPNs and Storage @ Colocation & AWS Cloud
Troubleshoot, diagnose, and resolve hardware, software, and other network and system problems
Create, review, update, and vet technical functional specification, low-level network solutions design documentation and operations guides/runbooks, ensuring those are complete, correct and kept current
Activities may include data quality engineering, metadata consolidation and integration, metamodel development and maintenance, repository management, data warehouse design and mining, data security administration, and formulation of enterprise-specific data metrics
You’ll Be a Good Fit For This Role If You Have:
3+ years experience supporting large, enterprise class data center network environments
Hands on skills on VMWare Vsphere clustered environment
Prior experience analyzing requirements for implementing, supporting, and troubleshooting network devices/functions/tools/processes in a large enterprise environment
Supported automation with network infrastructure using network automation tools
Created accurate network diagrams and documentation for design and planning network communication systems
Experience working with cloud connectivity such as AWS and Azure
Ability to implement, administer, and troubleshoot network infrastructure devices
Drive to expand technical knowledge and emerging technologies and tools
Discipline to work independently with minimal supervision while solving complex problems
Nice To Haves Include:
Bachelor's degree in Engineering or a related technical field with 3+ years of professional experience
Certifications such as, AWS Certified Solutions Architect Associate level, Cisco CCNA or CCNP, security certifications (CISSP/CEH)
Understanding of and practical knowledge of approaches to network security including packet filtering, access lists, firewalls, WAF, IDS, DDoS mitigation techniques
Experience with scripting languages/toolchain automation products such as Python
Location:
You must reside within a 1-hour driving distance to our network center located in Philadelphia, PA.

Compensation and Benefits:
Flexible work schedule, 18 PTO days plus 15 paid holidays, medical/dental/vision coverage, parental leave, 401K with match, company events, referral bonus, professional development opportunities, home office perks, and three office locations.

What We Believe:
HelioCampus is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.","$64,812 /yr (est.)",51 to 200 Employees,Company - Private,Education,Colleges & Universities,2016,Unknown / Non-Applicable
"Regeneron
3.9",3.9,"Tarrytown, NY",INFORMATICS DATA ENGINEER,"JOB DESCRIPTION
The Informatics Data Engineer will be responsible for developing and maintaining highly scalable and reliable data management pipelines, tools, and centralized databases for conducting analyses involving clinical and phenotypic data with an overarching goal of improving clinical phenotyping. You will design, implement, automate, and maintain the ETL pipelines that facilitate approaches for extracting and analyzing large-scale phenotypic datasets, including de-identified EHR data from external collaborators, targeted clinical datasets in selected cohorts, and internal datasets from clinical trials and other human subject research. The engineer will work with analysts, clinical scientists, software developers, and programmers to provide the best data management technology solutions to store, standardize, structure and mine the clinical and phenotypic data sets.
As a Clinical Informatics Engineer, a typical day may include:
Develop tools and pipelines, and optimize internal data processes for extraction, curation, processing, and storage of clinical data.
Develop code and automate production data ETL and quality assurance pipelines.
Develop, update, and maintain standards and procedures for data and databases access, storage, versioning, and maintenance.
Use a customer-focused approach to provide data extraction and storage solutions driven by scientific use cases.
Function as a ""super user"" of data reporting, analysis, and management processes and tools.
Build and maintain data standardization and optimization solutions to support the use of AI/ML for advanced phenotyping.
Basic data analysis including mining and curating of phenotypic datasets to facilitate downstream genomic analysis and workflows pertaining to reporting/ dashboarding.
Maintain close collaboration and coordination with external health system collaborators and informatics teams mining EHR and phenotypic data sets. Work with these collaborators to structure data and develop algorithms, rules engines, and querying tools to access and curate phenotypic datasets.
This role might be for you if:
You are a data steward.
You are interested in data management, mining, clinical databases, and hospital health informatics databases.
You are proficient in developing python-based data processing pipelines, and are familiar with ETL tools such as AWS Glue.
Understanding of AI/ ML concepts and architecture to the extent of being able to support activities of the clinical informatics ML team.
You can multitask and manage simultaneous projects to meet deadlines with strong attention to detail.
Possess the ability to interpret and communicate analytical information clearly and concisely.
You have exceptional analytical, organizational, and quantitative problem-solving skills and a willingness to learn and acquire new skills.
You excel at managing relationships and projects involving diverse partners.
You communicate findings clearly and document work for training and replication purposes.
To be considered for this role, you must have a bachelors or master’s (preferred) degree in Computer Science, Information Science, informatics, or other relevant data engineering field, and a minimum of 3 years of working experience in data engineering and management, ETL pipelines development, automation, and management. Healthcare and EHR data management experience is preferred. Familiarity with data mining, clinical databases, and hospital health informatics databases, including EHR data structures. Familiarity with clinical data standards such as ICD, SNOMED, LOINC, and OMOP, database architecture and administration. Proven experience with Hadoop. Demonstrated understanding of relational database concepts and querying tools. Experience with CI/CD framework, data flow orchestration. Working knowledge of programming languages such as Python and R. Experience with cloud computing services such as AWS and GCP. Experience with agile methods (Scrum, Kanban) and tools such as Atlassian JIRA and Microsoft teams foundation server. Experience with Machine Learning is not necessary but certainly a plus. However, general understanding of AI/ ML concepts to support deployment, orchestration of datasets as part of a pipeline is expected. The level is commensurate with education and experience.

Does this sound like you?to take your first steps toward living the Regeneron Way! We have an inclusive and diverse culture that provides comprehensive benefits including health and wellness programs, fitness centers and equity awards, annual bonuses, and paid time off for eligible employees at all levels!
Regeneron is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion or belief (or lack thereof), sex, nationality, national or ethnic origin, civil status, age, citizenship status, membership of the Traveler community, sexual orientation, disability, genetic information, familial status, marital or registered civil partnership status, pregnancy or parental status, gender identity, gender reassignment, military or veteran status, or any other protected characteristic in accordance with applicable laws and regulations. We will ensure that individuals with disabilities are provided reasonable accommodations to participate in the job application process. Please contact us to discuss any accommodations you think you may need.
The salary ranges provided are shown in accordance with U.S. law and apply to U.S. based positions, where the hired candidate will be located in the U.S. If you are outside the U.S, please speak with your recruiter about salaries and benefits in your location.

Salary Range (annually)
$121,200.00 - $197,800.00",#N/A,10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1988,$5 to $10 billion (USD)
"Shell
4.2",4.2,"Houston, TX",Subsurface Data Engineer,"Subsurface Data Management is helping Shell execute a strategy of moving from Epicure to OSDU. At the same time Shell has unleashed multiple digitalization efforts that require large volumes of SSW data.
You’ll will be responsible for finding new ways to help Subsurface Data Management execute upon the strategic movement of SSW data to a new platform (Point C), providing opportunities to unlock value from data now (Point B), and post Point C (once OSDU is deployed).
Your success in this role will flow not only from your technical abilities, but your capacity to manage leaders across natural teams and convince them of the business value to your approaches.
Where you fit in
The Integration team is part of the Integration and Seismic Data management team under the GM Subsurface Data Management & WF in the Upstream Subsurface Digital and Data VP-ship.
The Integration Team works with the business and IT to improve the data landscape with ambitious and realistic plans and have a track record integrating on-premise and cloud systems in a way that delivers business value in the Point B and C timelines.
You will help the business find fast and lower-cost ways to deliver the data required to optimize digital solutions, accelerate global scaling and value replication, and enable innovative ways of working.
What is the role
As a member of this team, you will have the following key responsibilities:
Assist program and project teams (e.g. X-Digi/Data, (O)SDU and Subsurface Data Management) virtualize and integrate their data in order to deliver upon the tactical and strategic goals from those programs and projects.
Utilize your knowledge of source systems and project needs to become a liaison between the business and Shell IT.
Utilize your knowledge of cloud tooling to negotiate with Shell Architects on the positioning of new technology in SSW data flows. This is convincing IT Stakeholders of the validity of our technical solutions.
Convey to management, programs and projects the business value of our approach to integration. This is convincing the business of the value of our solutions.
Work scope requires business domain knowledge and technical TIDM knowledge with demonstrable passion for identifying, developing, and deploying new ideas and ways of working. Within this role there will be significant interaction with leaders of programs, projects, IT and Subsurface Data Management, your ability to convey your technical knowledge and how it enables business value will be key to your success.
What we need from you
You will bring an open and external mindset with a sense of urgency to drive strategic SSW data integration improvements. You will collaborate and work across organizational boundaries and help develop a collaborative natural team with the business stakeholders.
Requirements:
Must have legal authorization to work in the US on a full-time basis
You have:
6+ years in a Technical Data Management Role Or proven experience leading projects within Technical Data Management programs. Or proven experience in a relevant data engineering or data science program of project.
An appetite to discover new technology solutions to improve our technical data workflows that transform our ways of working.
Experience with AWS services, or Azure equivalents.
Programming skills utilized in the data science domain (e.g. Python).
Self-starting and self-managed. You will need to move from requirements to a decomposed set of work (user stories) and deliver that work in 2-week increments (sprints).
Be able to convey to Product Owners, Program Managers, Chief Data Officers, and Architects the “why” and “how” of your approach to delivering work.
Be able to convey the business value of proposed solutions to Product Owners, Program Managers, CDOs and Architects when proposing solutions to work, or responding to challenges.
Knowledge, or experience with, data virtualization tools, especially Denodo would be beneficial.
Company description
Shell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world’s growing need for more and cleaner energy solutions in ways that are economically, environmentally, and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals.
As a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity, and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork, and professionalism, as well as pride in what we do and how we conduct business.
Building on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.
An innovative place to work
There’s never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change.
Join us and you’ll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy, or developing technology that helps the world to use energy more efficiently.
An inclusive place to work
To power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we’re nurturing an inclusive environment – one where you can express your ideas, extend your skills, and reach your potential.
We’re creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply, and we’ll take it from there.
We’re closing the gender gap – whether that’s through action on equal pay or by enabling more women to reach senior roles in engineering and technology.
We’re striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity.
We consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application.
A rewarding place to work
Combine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice.
We’re huge advocates for career development. We’ll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible.","$116,263 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1907,$10+ billion (USD)
"Bill & Melinda Gates Foundation
4.0",4.0,"Seattle, WA","Senior Data Engineer, IT Enterprise Data Solutions","The Foundation
We are the largest nonprofit fighting poverty, disease, and inequity around the world. Founded on a simple premise: people everywhere, regardless of identity or circumstances, should have the chance to live healthy, productive lives. We believe our employees should reflect the rich diversity of the global populations we aim to serve. We provide an exceptional benefits package to employees and their families which include comprehensive medical, dental, and vision coverage with no premiums, generous paid time off, paid family leave, foundation-paid retirement contribution, regional holidays, and opportunities to engage in several employee communities. As a workplace, we’re committed to creating an environment for you to thrive both personally and professionally.
The Team
As part of the IT Enterprise Data Solutions (EDS) department, the Data Platform team’s mission is to lead on data technology and utilization, enabling informed decision-making and strategic insights across the foundation. We are committed to providing a robust, secure, and scalable data platform that empowers data-driven initiatives and cultivate collaboration.

Working with our business operations and foundation strategy program partners, the team supports the management of the EDW, data engineering and integration, shared data exchange, data platform operations and data architecture support.
Your Role
You will be the primary domain expert for the data platforms and Systems for the team.
The role will develop and support the data engineering needs of the Enterprise Data solution team to improve the quality and availability of information to drive better search and reporting capabilities. The hire will be responsible for growing and optimizing our data and data repository as well as optimizing data flow and collection for multi-functional teams. The ideal candidate is an expert data wrangler and builder on the cloud data platform who enjoys optimizing data systems and building them from the ground up. The Senior Data Engineer will work with a team consisting of business partners, business and data analysts, solution architects, data architect, data engineers, quality engineers and other technical roles in an agile delivery environment.
What You’ll Do
Lead and develop data pipelines and transformations to extract, transform, and load (ETL) data from source systems into data platforms for further processing and analysis.
Identify, design, and implement process improvements including designing data quality reports, infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Work with customers including data, design, product teams and assist with data-related issues.
Work with knowledge management and Analytics and Insights functional teams to optimize data for search, reporting and insight capabilities.
Ensure data accuracy, integrity, privacy, security, and compliance through quality control procedures.
Designing and implementing data integration solutions to ingest and process data from various semi-structured and structured data sources such as JSON, XML, CSV, excel, foundation systems or relational databases.
Configuring and optimizing Storage to efficiently store and handle the ingested data. This includes defining containers and access controls. Partner with Architects to craft the data duplication strategy for durability and availability.
Implementing data normalization techniques to eliminate data duplication and ensure data integrity within normalized databases.
Collaborating with data architects, business systems analysts, and customers to understand data requirements and support the design of efficient data models that align with business needs.
Implementing dimensional databases using techniques such as star or snowflake schemas to support analytical reporting and data analysis.
Monitoring and optimizing data pipelines, storage, and databases for performance, scalability, and reliability.
Implementing security measures and standard processes to protect critical data throughout the data integration and storage processes, ensuring compliance with data protection regulations and internal security requirements.
Your Experience
Bachelor’s or master’s degree in computer science, Data Engineering, or related field.
5+ years of experience in data engineering or related roles, with a focus on designing and maintaining data platforms.
Strong proficiency in data processing tools, ETL frameworks, programming languages (Python, SQL), and both SQL and NoSQL databases.
Experience working with Azure cloud data services and Snowflake, including designing, developing, and optimizing of data integration within these platforms.
Deep understanding of data security practices, access controls, encryption, and compliance.
Experience in implementing Continuous Integration and Continuous Deployment (CI/CD) solutions for data pipelines, ensuring automated testing, deployment, and monitoring processes.
Demonstrable ability to quickly respond to incidents by assessing the situation, lead incident triage, solve issues, and providing immediate short-term solutions. Capable of formulating and implementing medium and long-term strategies to prevent similar incidents in the future.
Experience with Agile, Scrum, and Jira required.
Experience supporting and working with multi-functional teams in a dynamic environment.
Excellent leadership, communication, and collaboration skills.
A dedication to diversity, equality, and inclusion, proven through past experiences or initiatives.
Experience with analytics tools, data modeling, and visualization platforms (e.g., Power BI) is a plus.
Must be able to legally work in the country where this position is located without visa sponsorship.
The typical salary range for this role is $101,100 to $188,100 USD. The exact offer will be determined by a variety of factors such as the candidate’s individual skills, qualifications, and experience relative to the requirements of the role.
#L1-SL1
Hiring Requirements
As part of our standard hiring process for new employees, employment will be contingent upon successful completion of a background check.
Candidate Accommodations
If you require assistance due to a disability in the application or recruitment process, please submit a request here.
Inclusion Statement
We are dedicated to the belief that all lives have equal value. We strive for a global and cultural workplace that supports ever greater diversity, equity, and inclusion — of voices, ideas, and approaches — and we support this diversity through all our employment practices.
All applicants and employees who are drawn to serve our mission will enjoy equality of opportunity and fair treatment without regard to race, color, age, religion, pregnancy, sex, sexual orientation, disability, gender identity, gender expression, national origin, genetic information, veteran status, marital status, and prior protected activity.","$144,600 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Nonprofit & NGO,Grantmaking & Charitable Foundations,2000,Less than $1 million (USD)
"Savion
4.4",4.4,Remote,GIS Data Engineer,"Savion, a Shell Group portfolio company operating on a stand-alone basis, is one of the largest, most technologically advanced utility-scale solar and energy storage project development companies in the United States. With a growing portfolio of more than 36.5 GW, Savion’s diverse team provides comprehensive services at each phase of renewable energy project development, from conception through construction. As part of this full-service model, Savion manages all aspects of development for customers, partners, and project host communities. Savion is committed to helping decarbonize the energy grid by replacing electric power generation with renewable sources and delivering cost-competitive electricity to the marketplace.
Our workplace culture attracts competitive, smart, and fun people. We are committed to the health, fitness, and work-life balance of our employees. Our employees are highly motivated, technically proficient, team-oriented, and committed to renewable energy. We recognize our employees are our most valuable asset and offer highly competitive pay as well as exceptional above-market employee benefits. Balancing work and play is met with generous PTO allowances and 14.5 paid holidays per year.
Position Details
Savion is seeking a qualified candidate to join an existing team of high-performing analysts within the Commercial Strategy & Renewable Origination group. This candidate will join Savion’s industry-leading siting and market strategy department. This team ensures that the development pipeline is continually fed with commercially viable opportunities to sustain the development pipeline and is ultimately aligned with our strategy to own operating renewable projects throughout the continental U.S.
The candidate will be responsible for supporting Savion’s siting team by developing and maintaining the automation tools. This candidate will work closely with many departments across the business to inform and continually refine Savion’s siting processes and automation while facilitating critical coordination with Savion’s GIS, IT, Development, Engineering, Environmental & Permitting, Meteorology, Transmission, Real Estate teams to improve databases based on feedback from subject matter experts across the business. This position will be a key part of the Siting team and will report directly to the Portfolio Siting Manager. Preference for this position to operate from our Kansas City office, but accommodations for hybrid or remote work can be made.
Key Roles and Responsibilities:
Maintain automated processes supporting all siting related processes including the following: GIS portals, scripts, Process Improvement, Competition, Transmission, Market Analysis and Site Selection tools.
Database optimization to ensure the efficiency of the extraction, transfer and loading (ETL) of transmission data for continental U.S. transmission and energy pricing.
Monitor data integrity across all siting databases, in addition to working closely with our GIS and IT partners on change requests, communication, and coordination of implementations.
Coordinate with IT and GIS Development on GIS design and troubleshooting discussions for updates, support, and maintenance for Esri ArcGIS and Microsoft solutions.
Utilize Atlassian for clear and extensive process improvement tasks, documentation, training materials, and business requirements for siting team initiatives.
Develop new tools and methodologies for advancing Savion’s site selection process.
Collaborate with subject matter experts across the business to understand the data provided and incorporate it into the siting process.
Job Requirements
Bachelor’s or master’s degree in computer science of Geography/GIS
Minimum 5 years of experience preferably in a similar role and an understanding of renewable energy development.
Familiarity with Esri ArcGIS desktop software, ArcGIS Online, ArcPro, and ArcGIS Collector
Experience with ESRI Model Builder and Python scripting
Experience with transmission modeling software related to load flow analysis
Hands-on experience with Geographic Information Systems (GIS), or at a minimum, a solid foundational knowledge of the capabilities of GIS.
Programming experience with R, Python, or SQL
Strong strategic mindset and the ability to quickly read, review, analyze, and summarize large amounts of information
Able to learn new concepts quickly and work independently while often working on multiple initiatives at once
Very motivated self-starter with strong organizational and time-management skills
Must have excellent communication skills and work effectively in a team-based environment
Compensation & Benefits
Title and compensation commensurate with experience
Vacation & Holidays: Paid Time Off plus 14 paid company holidays
Benefits: Medical/Dental/Vision insurance; short-term and long-term disability; life insurance; 401(k)
Savion offers a culture that embraces a “flex-time” schedule to maximize both productivity and work-life balance
Contact Information
Please send a resume and cover letter to: jobs@savionenergy.com
Job Type: Full-time
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Life insurance
Paid time off
Vision insurance
Compensation package:
Bonus opportunities
Schedule:
Monday to Friday
Education:
Bachelor's (Required)
Experience:
renewable energy development: 5 years (Required)
GIS Data Engineer: 5 years (Required)
Work Location: Remote",#N/A,Unknown,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"E-INFOSOL LLC
5.0",5.0,"Washington, DC",Senior Data Engineer,"E-INFOSOL LLC is seeking a highly motivated Senior Data Engineer to be Full-time employee in Washington, DC. Come join a team that collaborates across the entire organization to bring the right solution to our customers and drive innovation.


Job Description:
The Senior Data Engineer will collaborate with customers, often engaging directly with non-technical personnel, to understand their data science related needs, suggest solutions, and complete work in a timely manner. This position performs activities associated with implementation, integration, and support of computer systems in mission-critical response operations environment.


Responsibilities:
Responsible for micro servicing development utilizing Java.
Ability to program in Java supporting workflow orchestration.
Work in data warehouse environment, which includes data design, database architecture, metadata, and repository creation.
Perform Extract, Transform, Load tasks.
Translate business needs into long-term architecture solutions.
Develop data warehousing blueprints, evaluating hardware and software platforms, and integrating systems.
Evaluate reusability of current data for additional analyses.
Review object and data models and the metadata repository to structure the data for better management and quicker access.


Required Experience:
4+ of work experience with JEE or other Java frameworks (e.g., Spring)
4+ years of work experience using Java development tools (e.g., Eclipse, JUnit, Git)
4+ years of work experience with relational or other database platforms, SQL, or other query languages
AWS/Cloud experience
Working knowledge of full lifecycle engineering projects.
Excellent interpersonal communication skills and ability to present technical capabilities.
Strong analytical and problem-solving skills.
Experience working in cross-functional teams.
Micro-service & containerization experience
Expertise in developing in a Micro services environment.
Working knowledge of Agile Scrum methodology.


Clearance:
Must be US Citizen with Active Top-Secret Clearance

About E-INFOSOL:
E-INFOSOL is a Service Disabled and Veteran Owned Small Business (SDVOSB) located in the Washington, D.C. metropolitan area. We are a premiere IT Security, Cloud and Virtualization provider servicing both federal and state government, and private sector customers. Through strategic partnerships with top industry players such as Amazon Web Services (AWS), VMware, Microsoft and Nutanix, we can provide an array of IT products and solutions, combining them with our expertise.
Why E-INFOSOL:
E-INFOSOL has 10 years in the digital world, expanding with new clientele and jobs rapidly. E-INFOSOL is constantly aware of technical changes within IT and wants to ensure future candidates can make a difference with contributing their different skills and knowledge. We offer an array of architectural, engineering, and information technological jobs to a diverse group of candidates. Come join the E-INFOSOL family and be a part of the vast growing culture that contributes to the world.
Equal Employment Opportunity Policy
E-INFOSOL LLC provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.
This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.


PID: 23-0812001","$129,060 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2010,$1 to $5 million (USD)
"ACI Federal Inc
3.5",3.5,"Washington, DC",Senior Data Analyst/Engineer,"We are seeking a skilled Senior Data Analyst/Engineer to join our leading company!
*** US citizenship required - No C2C, no sponsorships, etc. ***
*** This is a REMOTE position ***
Description:
Hands on developer who could help ingest data into the Data Platform and help analyze/model for visualization purposes.","$101,852 /yr (est.)",501 to 1000 Employees,Company - Private,Government & Public Administration,National Agencies,2014,Unknown / Non-Applicable
"Klaviyo
3.9",3.9,"Boston, MA",Senior Software Engineer Data Exchange,"At Klaviyo, we value the unique backgrounds, experiences and perspectives each Klaviyo (we call ourselves Klaviyos) brings to our workplace each and every day. We believe everyone deserves a fair shot at success and appreciate the experiences each person brings beyond the traditional job requirements. If you're a close but not exact match with the description, we hope you'll still consider applying. Want to learn more about life at Klaviyo? Visit careers.klaviyo.com to see how we empower creators to own their own destiny.
Klaviyo operates a real-time data analytics platform coded primarily in Python that is built for massive scale and hosted on Amazon Web Services (AWS). Engineers come to Klaviyo with experience in a variety of languages and from a number of disciplines.
The Data Exchange team is responsible for designing and building software that enables data transmission in and out of the Klaviyo platform through a variety of protocols and delivery mechanisms. The team collaborates closely with internal stakeholders and has substantial exposure to Klaviyo's customers, including businesses, partners, and third-party developers. Data Exchange operates at the intersection of distributed systems, data pipelining, software architecture, scalability, and reliability.
At Klaviyo, we love tackling tough engineering problems and look for employees who specialize in certain areas but are passionate about building, owning & scaling features end to end from scratch and breaking through any obstacle or technical challenge in their way. We push each other to move out of our comfort zone, learn new technologies, and work hard to ensure each day is better than the last. Klaviyo is growing fast and we have openings for all skill levels across all of our teams. Learn more about our engineering culture at https://klaviyo.tech.
How you'll make an impact
This team is a key contributor to the evolution of Klaviyo into a data platform, enabling hundreds of thousands of Klaviyo customers to effectively leverage and activate their data. Critical components of the data platform include data collection and data distribution, which must be both reliable and scalable as Klaviyo continues to expand its support for various methods of data import and export. As a Senior Software Engineer, you will define and own the core components, tools, and customer-facing features for data collection and distribution. You will contribute to the advancement of our data movement framework and play a key role in enabling our customers and partners to move their data in and out of Klaviyo. You will be contributing to the vision, mission, and strategy of our product area and will work with a team of talented and experienced software engineers who are eager to grow fast and make an impact on the company.
What you'll do
Take ownership of project segments and lead the delivery of new features, including their design, development, and deployment.
Perform independent research, work with domain experts, collect, question, and improve requirements and drill down to core problems for larger features and projects
Take charge of a significant segment within your product domain, becoming its subject matter expert, and overseeing its development and evolution.
Work closely with Product and tech leads to contribute to the roadmap that align with company worldwide growth
Contribute to the technical/architectural evolution of your product area; identify and advocate for scalability, reliability, and maintainability needs
Established expertise in some Klaviyo and industry practices, patterns, tools, languages, and processes; share new insights and contribute beyond the team.
Who you are
Passionate about building software effectively and for the long-term. Have experience building products that matter. Have proven expertise in applying relevant design patterns to implementing highly-scalable multi-tenant systems.
Like working on small, autonomous agile teams. Enjoy shipping code early and often in an agile fashion, pairing with product management, business stakeholders, and other engineers to craft better software.
Have knowledge and experience working with distributed architectures and data processing systems. Have basic understanding of domain-driven design and data management patterns.
Motivated by having ownership, excited about taking the initiative to solve tasks in collaboration with others.
Enjoy mentoring fellow engineers, ensuring their skill development aligns with organizational growth.
Love digging into performance, scalability, and reliability issues to drive breakthrough solutions. You recognize all problems can be solved and are capable of rallying others to address business needs.
Tech Stack
We are looking for a backend-focused engineer, experience with frontend development is preferred but not mandatory. Previous experience with big data stack is desirable. The tech stack you'll be working with:
Python, Django, FastAPI
Apache Kafka, Apache Pulsar, RabbitMQ, and other tech from the big data stack
MySQL, Redis
Graphite, statsd, Grafana
AWS, Terraform, Docker, Kubernetes, Jenkins, and other modern DevOps tools
Get to Know Klaviyo
We're Klaviyo (pronounced clay-vee-oh). We empower creators to own their destiny by making first-party data accessible and actionable like never before. We see limitless potential for the technology we're developing to nurture personalized experiences in ecommerce and beyond. To reach our goals, we need our own crew of remarkable creators—ambitious and collaborative teammates who stay focused on our north star: delighting our customers. If you're ready to do the best work of your career, where you'll be welcomed as your whole self from day one and supported with generous benefits, we hope you'll join us.
Upon request, you can receive additional information about the compensation and benefits for this role. Requests can be submitted here. Additional information regarding benefits can be found at klaviyorewards.com.
Klaviyo is committed to a policy of equal opportunity and non-discrimination. We do not discriminate on the basis of race, ethnicity, citizenship, national origin, color, religion or religious creed, age, sex (including pregnancy), gender identity, sexual orientation, physical or mental disability, veteran or active military status, marital status, criminal record, genetics, retaliation, sexual harassment or any other characteristic protected by applicable law.
You can find our Job Applicant Privacy Notice here.","$134,269 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2012,Unknown / Non-Applicable
"Southwest Airlines
4.1",4.1,"Dallas, TX",Associate Data Engineer,"Department: Technology

Our Company Promise

We are committed to provide our Employees a stable work environment with equal opportunity for learning and personal growth. Creativity and innovation are encouraged for improving the effectiveness of Southwest Airlines. Above all, Employees will be provided the same concern, respect, and caring attitude within the organization that they are expected to share externally with every Southwest Customer.

Job Description:
Job Profile
Tech Platforms
Integrated Data Foundation (IDF) Business Data Delivery: We are experts in data analytics focused on the Customer and Commercial space, where we design powerful dashboards and reports that empower business leaders. Our commitment to modernization maintains our competitive edge in the ever-changing business world. We also engage in various project initiatives and collaborate seamlessly with cross-functional teams, enabling data analysis across different departments within Southwest Business Teams to drive closed-loop revenue enhancement.
Job Summary
Provide technical support with supervision for design and deployment of a data engineering solution. Play a role in the building of analytical solutions and updating systems to accommodate changes.

Additional details
This role is offered as a remote workplace position, which may require travel for training, meetings, conferences, etc. Outside of those required visits, the majority of your working time may be spent in a remote location, away from our Corporate Campus. Please note, while this is a remote position, there is a limited group of states or localities ineligible for Employees to regularly perform their work. Those ineligible locations are: Alaska, California, Colorado, Delaware, Illinois, Iowa, Maryland, Massachusetts, Montana, New Hampshire, New Jersey, New York, North Dakota, Oregon, Pennsylvania, South Dakota, Vermont, West Virginia, Washington and Wyoming.
U.S. citizenship or current authorization to work in the U.S. is required, and no current or future work authorization sponsorship available.

Southwest Airlines is an Equal Opportunity Employer. We continue to look for opportunities to reflect the communities we serve, and welcome applicants with diverse thoughts, backgrounds, and experiences.

Responsibilities
Monitor and maintain the components of our data engineering pipeline, and various container-based services configured through UIs, SQL, PL/SQL, Python, and Shell, with code managed in GitHub, deployed through Jenkins
Work as a part of our production support team to ensure the highest standards of product configuration that meet client requirements
Test and troubleshoot data pipeline using sample and live client data, utilizing Jenkins, Python, and Java to automate these tests. Must be able to parse logs to determine next actions
Utilize dashboards for Kubernetes/OpenShift to diagnose high level issues and ensure services are healthy
Support Implementation immediately after go live and work with implementation team to transition support
Work with data providers to clarify requirements and remove roadblocks
Drive automation into everyday activities
May perform other job duties as directed by Employee's Leaders
Knowledge, Skills and Abilities
Knowledge of the practical application of engineering science and technology, including applying principles, techniques, procedures, and equipment to the design and production of various goods and services
Knowledge of design techniques, tools, and principles involved in production of precision technical plans, blueprints, drawings, and models
Ability to use logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions or approaches to problems
Ability to understand new information for both current and future problem-solving and decision-making
Skilled in identifying complex problems and reviewing related information to develop and evaluate options and implement solutions
Ability to tell when something is wrong or is likely to go wrong. It does not involve solving the problem, only recognizing there is a problem
Ability to combine pieces of information to form general rules or conclusions (includes finding a relationship among seemingly unrelated events)
Ability to shift back and forth between two or more activities or sources of information (such as speech, sounds, touch, or other sources)
Ability to arrange things or actions in a certain order or pattern according to a specific rule or set of rules (e.g., patterns of numbers, letters, words, pictures, mathematical operations)
Ability to identify or detect a known pattern (a figure, object, word, or sound) that is hidden in other distracting material
Education
Required: High School Diploma or GED
Required: Bachelor's Degree in Business, Engineering, Computer Science, Information Systems, Cybersecurity, or related field; or equivalent formal training
Experience
Required: Entry level experience, developing skills and knowledge in:
Cloud infrastructure, DataLake, AbInitio
ETL experience ensuring source to target data integrity.
Various file types (Delimited Text, Fixed Width, XML, JSON, Parque)
Unit Testing, Code Quality tools, CI/CD Technologies, Security and Container Technologies
Agile development experience and Agile ceremonies and practices
Preferred: Knowledge or exposure to SQL and Data Analysis
Physical Abilities
Ability to perform work duties from [limited space work station/desk/office area] for extended periods of time
Ability to communicate and interact with others in the English language to meet the demands of the job
Ability to use a computer and other office productivity tools with sufficient speed and accuracy to meet the demands of the job
Other Qualifications
Must maintain a well-groomed appearance per Company appearance standards as described in established guidelines
Must be a U.S. citizen or have authorization to work in the United States as defined by the Immigration Reform Act of 1986
Must be at least 18 years of age
Must be able to comply with Company attendance standards as described in established guidelines

Pay and Benefits:
Competitive market salary from $84,350.00 per year to $93,700.00per year* depending on qualifications and experience. For eligible Leadership and individual contributor roles, additional bonus opportunities are available and awarded at the discretion of the company.

Benefits you’ll love:
Fly for free, as a privilege, on any open seat on all Southwest flights (your eligible dependents too)
Up to a 9.3% 401(k) Company match, dollar for dollar, per paycheck *
Potential for annual ProfitSharing contribution toward retirement – when Southwest profits, you profit**
Explore more Benefits you’ll love: https://careers.southwestair.com/benefits
Pay amount does not guarantee employment for any particular period of time.
**401(k) match contributions are subject to the plan’s vesting schedule and applicable IRS limits
***ProfitSharing contributions are subject to plan’s vesting schedule and are made at the discretion of the Company.

Southwest Airlines is an Equal Opportunity Employer.
Please print/save this job description because it won't be available after you apply.","$84,350 /yr (est.)",10000+ Employees,Company - Public,Transportation & Logistics,"Airlines, Airports & Air Transportation",1967,$10+ billion (USD)
"RSI
2.9",2.9,Remote,Senior Data Engineer,"Description:
As a Data Engineer at RSI, you will be responsible for building our revX data migration best practices, for both new customers and upgrades from RSI legacy products to revX (our new SaaS based product). This individual will work with other engineers and teams to curate data conversion tooling, checklists and playbooks. Additional responsibilities will include understanding cloud-based data containers and related ETL best practices, assisting with the creation of data profiles and sample datasets, as well as collaborating with other team members to assist with interface, reports, and notices efforts.
Internally, this position is titled Engineer, Principal.
Requirements:
5+ years of relevant software development experience
Strong working experience with of relational databases, preferably SQL Server
Experience in SQL scripting, preferably T-SQL
Strong understanding of Object Oriented Design and design patterns
C# development experience, preferably Core 3.1 and/or .NET 5+
Proven ability to design and implement low to medium complexity software features from user stories or use cases.
Work experience with a structured SLDC, preferably using Agile methodologies
Previous team-oriented development experience
Strong analytical problem-solving skills
Excellent verbal and written communication skills
Outgoing and enthusiastic personality
Professional business demeanor
BS in Computer Science, related field or equivalent experience
Immediate authorization to work in the US
Desired/Preferred Qualifications:
5-7 years data analysis / mapping / ETL experience
Knowledge of DevOps concepts
Entity Framework Core
NuGet package development and delivery
Experience with large-scale public sector IT projects, especially for Revenue or Finance agencies
Physical Requirements:
Prolonged periods sitting at a desk and working on a computer.
Must be able to lift up to 15 pounds at times.
EEO Statement: RSI is committed to providing equal opportunity in employment to all employees and applicants for employment.? Discrimination of employees or applicants on the basis of race, religion, color, sex, age, national origin, veteran status, disability, sexual orientation and gender identity, marital status, genetic information, or any other protected category, is strictly prohibited.
Immigration Notice: Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.
RSI determines pay range based upon numerous compensation factors, including experience, skill set, and geographic location. A current and reasonable estimated range for this position is $104,000 - $151,000. However, it’s possible for an individual to be hired at a salary outside of this range.
About Us
RSI streamlines government operations and improves citizen services through the delivery of transformative technologies. Since 1996, we have established our position as a technology leader as we continue to bridge our legacy with the future through continual innovation. Technology continues to evolve and so too does RSI. The next chapter of RSI is lined with growth opportunities as we engage all members of our highly skilled teams in advancing our culture, recruiting top talent, and making progress together.
Culture and Values
The RSI employee experience is guided by our values of integrity, customer commitment, caring about people, innovation, inclusion, and responsibility. The most fundamental reason we exist as a company is our teams’ unparalleled passion for innovation. We believe that each individual, and every team, at RSI is central to our success. RSI is committed to creating an agile environment that inspires our people through professional development, cross-collaborative opportunities, and access to cutting-edge learning resources.",#N/A,201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,1996,Unknown / Non-Applicable
"Fulton Bank
3.2",3.2,"Lancaster, PA",IT Sr Data Engineer Delivery,"Value Proposition:
Our values define us and our culture inspires us to change lives for the better. Our employees are the heart and soul of our company, and every success we experience begins with them. Together we are committed to making a positive impact in our local communities. We champion a culture of continuous learning, work-life integration, and inclusion. We promote a digitally enabled work environment to continuously enhance the experience of our employees and customers.
Overview (Text Only): Collaborates within the business and operations units of the Corporation to design, develop, test, deliver and maintain data engineering solutions that support the Corporation's business. Engage in the entire database development process, from inception through delivery. Participate in the design and implementation of database development standards and procedures. Mentor and guide fellow data engineers. Responsibilities:
Design, develop, test and implement database solutions related to optimal data pipeline architecture and infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Oracle and Big Data technologies, in accordance with established standards. Develop and implement controls to ensure data integrity and regulatory compliance. Participate in peer reviews of solution designs and related code. Package and support deployment of releases. Work with business requestors, BAs and Business Relationship Manager to refine the business requirements and ensure that sufficient detail is provided to guide design, development and testing.
Drive innovation within the group in areas including development efficiencies, database component development and integration, database management and administration, and leading edge industry concepts and developments. Contribute to and implement standards and changes to database administration and development processes. Contribute to the development and implementation of key performance indicators and service level agreements that serve to maximize our value to the business.
Responsible for maintaining the integrity and performance of company databases and guarantee that data is stored securely and optimally. Monitor the production schedule and provide support to remediate job failures. Leverage technology to automate routine processes. Monitor key performance indicators and recovery time objectives to meet service level agreements and maximize value to the business. Provide production support to business users. Monitor and tune databases for which we are responsible and direct the work of vendors where they are responsible for the Database Administrator function. Support enterprise wide compliance with enterprise standards, processes and policies.
Qualifications:
Education
Bachelor Degree or the equivalent experience. Specialty: Computer Science, Computer Information Science. (Required)
Required Experience
5 or more years Database Administrator, Database developer, Data Engineer
1 or more years of Azure experience
: This role may perform other job duties as assigned by the manager. Each employee of the Organization, regardless of position, is accountable for reading, understanding and acting on the contents of all Company-assigned and/or job related Compliance Programs, regulations and policies and procedures, as well as ensure that all Compliance Training assignments are completed by established due dates. This includes but is not limited to, understanding and identifying compliance risks impacting their department(s), ensuring compliance with applicable laws or regulations, and escalating compliance risks to the appropriate level of management. Sponsorship Statement : As a condition of employment, individuals must be authorized to work in the United States without sponsorship for a work visa by Fulton Bank currently or in the future. EEO Statement : Fulton Bank (“Fulton”) is an equal opportunity employer and is committed to providing equal employment opportunity for all qualified persons. Fulton will recruit, hire, train and promote persons in all job titles, and ensure that all other personnel actions are administered, without regard to race, color, religion, creed, sexual orientation, national origin, citizenship, gender, gender identity, age, genetic information, marital status, disability, covered veteran status, or any other legally protected status.","$83,476 /yr (est.)",1001 to 5000 Employees,Company - Public,Financial Services,Banking & Lending,1882,$10+ billion (USD)
"Mayor's Office of Contract Services
3.3",3.3,Manhattan,Data Engineer,"DEPT OF PARKS & RECREATION
Full-Time
Location
MANHATTAN
No Exam Required
Department
Asst Comm For Inn & Per Mgmt
Salary Range:
$75,504.00 – $94,761.00
Job Description
NYC Parks is an award-winning city agency that designs, builds, and preserves public spaces for New Yorkers. NYC Parks cares for 14% of the land in New York City, diverse array of structures sits on these public spaces including recreation centers, sporting facilities, historic houses, pool facilities, nature centers, marinas, and public restrooms.

Data Engineers act as a liaison between the Information Technology & Telecommunications (ITT) and Innovation & Performance Management (IPM) departments, working collaboratively with both teams to provide support for Parks’ data-centric needs, including updating and improving data flow, data infrastructure, and overall data management.

Major Responsibilities
Maintain, improve, clean and manipulate data in agency operational and analytics databases.
Analyze complex data elements and systems, data flows, dependencies and relationships to contribute to logical data models.
Lead efforts to standardize data documentation and metadata; identify, promote and enforce best practices across data types, systems and uses.
Troubleshoot and resolve data quality issues.
Define and help build data pipelines that will enable faster, better, data-informed decision-making within the agency.
Ensure proper data governance across the Agency.
Proactively analyze and evaluate the agency’s data infrastructure to identify and recommend improvements and optimization.
Design and develop scalable Extract-Transform-Load (ETL) processes.
Perform thorough testing and validation to support the accuracy of data transformations and data verification used in analyses.
Play a collaborative role with ITT and IPM to help automate database maintenance, monitoring and performance tuning. Find ways to deploy new solutions and cutting edge technology practices while ensuring interoperability with existing legacy systems.
Keep up with industry trends and best practices, advising senior management on new and improved data engineering strategies that will drive departmental performance, reduce data and knowledge silos, ultimately improving overall agency performance.

Minimum Qualifications

1. For Assignment Level I (only physical, biological and environmental sciences and public health) A master's degree from an accredited college or university with a specialization in an appropriate field of physical, biological or environmental science or in public health.
To be appointed to Assignment Level II and above, candidates must have:
1. A doctorate degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and one year of full-time experience in a responsible supervisory, administrative or research capacity in the appropriate field of specialization; or
2. A master's degree from an accredited college or university with specialization in an appropriate field of physical, biological, environmental or social science and three years of responsible full-time research experience in the appropriate field of specialization; or
3. Education and/or experience which is equivalent to ""1"" or ""2"" above. However, all candidates must have at least a master's degree in an appropriate field of specialization and at least two years of experience described in ""2"" above. Two years as a City Research Scientist Level I can be substituted for the experience required in ""1"" and ""2"" above.

NOTE:
Probationary Period
Appointments to this position are subject to a minimum probationary period of one year.

Preferred Skills

1. Outstanding analytical skills across traditional knowledge domains, paired with a well-developed sense of management priorities. Previous team leader/management experience. 2. Demonstrated project management, technology implementation, supervisory, writing, administrative and interpersonal skills. 3. Track record of fostering innovation, prioritizing initiatives, and coordinating the deployment of complex projects across departments and different groups of stakeholders. 4. Strong communication skills to inspire and motivate staff at all levels and develop and maintain effective working relationships with diverse sets of partners within the technology and user community. 5. Experience analyzing and identifying appropriate business solutions to meet operational needs extensive project management experience, helping develop and implement operations projects from start to finish. 6. At least four years of relevant experience. 7. Demonstrated leadership in government innovation. Prior experience working in government and with the operations sector preferred.
Public Service Loan Forgiveness

As a prospective employee of the City of New York, you may be eligible for federal loan forgiveness programs and state repayment assistance programs. For more information, please visit the U.S. Department of Education’s website at https://studentaid.gov/pslf/
Residency Requirement

Residency in New York City, Nassau, Orange, Rockland, Suffolk, Putnam, or Westchester counties required for employees with over two years of city service. New York City residency required within 90 days of hire for all other candidates.
Additional Information

The City of New York is an inclusive equal opportunity employer committed to recruiting and retaining a diverse workforce and providing a work environment that is free from discrimination and harassment based upon any legally protected status or protected characteristic, including but not limited to an individual's sex, race, color, ethnicity, national origin, age, religion, disability, sexual orientation, veteran status, gender identity, or pregnancy.

Job ID
584079
Title code
21744
Civil service title
CITY RESEARCH SCIENTIST
Title classification
Non-Competitive-5
Business title
Data Engineer
Experience Level:
Experienced (Non-Manager)
Number of positions
1
Work location
Arsenal 830 Fifth Ave, New Yor
Category:
Technology, Data & Innovation","$85,133 /yr (est.)",Unknown,Government,Government & Public Administration,Municipal Agencies,#N/A,Unknown / Non-Applicable
"PatientPoint
3.4",3.4,"Chicago, IL",Senior Data Engineer,"It is an exciting time to be part of the PatientPoint team! As the clear leader in the point-of-care industry, we offer an ideal, people-focused place to innovate, positively impact patient education and doctor-patient connections, and be inspired to build a great career.

Location: Chicago

Hybrid Schedule: 1-3 days in Office Weekly

Travel Requirements: 4-5 weeks per year

Job Summary
We are a small team in a rapidly developing space, our culture is hugely important to us, and is an area where you can make a great impact . Our success is driven by collaboration - we solve problems together, and our openness helps each individual grow, too. We're looking for people who bring innovative approaches to their work, excitement for looking at things from new angles and a spirit of continuous improvement contributing fresh insights and the tenacity required to deliver value, and of course, who love to have fun!

You will report to the Director of Data and Analytics Engineering. As a Senior Data Engineer, you will be expected to be hands-on using your in-depth knowledge of data pipelines, DAGs, monitoring and testing to design, develop, and support our data pipeline . You will be responsible for ensuring that design and implementation adhere to DnA engineering standards, are secure, resilient and reliable, enabling our DnA team to deliver rapid impactful benefits with our data product to our business partners. .

What You'll Do
As a Senior Data Engineer, you will be responsible for the design, orchestration, monitoring, quality, accuracy, and security of data throughout its lifecycle, including data ingestion, collection, storage, processing, and analysis primarily using Snowflake, Fivetran and Astronomer.
Work closely with senior management, product owners, DnA Architects and Engineers, experienced data scientists, software developers and analysts to understand their data requirements and help build robust and efficient data pipelines to support their work.
Lead design, development, prototyping, operations and implementation of data pipelines
Educate, mentor and support DnA team members new to integrating the modern stack.
Build PatientPoint data expertise and own data quality for the pipelines you create.
Testing and release process of data pipelines using best practices for frequent releases.
Participate in Code Reviews
Partner to deliver a modern data engineering model that follows Dev/Ops principles and standards for continuous integration/ continuous delivery (CI/CD) processes.
Develop and maintain data documentation, including data dictionaries, data lineage, and data flow diagrams, to provide clear visibility into the data ecosystem.
Analyze the impact of changes to downstream systems/products and recommend alternatives to minimize the impact.
Drive the migration to a modern data stack in which Analysts and Engineers can self-service changes in an automated, tested, and high-quality manner.
Stay up-to-date with emerging trends and technologies in data engineering and recommend improvements to existing systems.

What We Need
5+ years of experience working on cloud data warehouses and data pipelines with a focus on data engineering, building scalable and secure data platforms and systems powering intelligent applications.
Bachelor's Degree in Computer Science or a related field
Competency with Python, Airflow, GitHub and DAG construction
Advanced SQL query and procedure writing experience
Experience with unstructured datasets and ability to handle Avro, Parquet, JSON and XML file formats
Strong understanding of CI/CD principles, DevOps practices, software testing and quality
Experience working with cloud-based data engineering and storage technologies such as AWS and orchestration tools such as Apache Airflow Astronomer.

Desired Qualifications
Experience working with large data sets and streaming data
Experience with Snowflake
Excellent problem-solving skills and attention to detail
Experience protecting PPI or PHI data during the ELT process, data security and data access controls and design
Streaming data; high volume IoT data ingest
Experience with various patterns of data ingestion, processing, and curation along with various streaming data concepts, such as Kafka.
Exposure to industry standard BI tools like Power BI and Tableau
Experience implementing data quality initiatives such as test harnesses, monitoring, and auditing features on data
Healthcare / Medical Devices domain experience

What You'll Need to Succeed
Effective Communication Skills both written and verbal within all levels of the organization
Solid work ethicwith the ability to work productively with a distributed team.
Self-driven execution capabilities; self-motivated to independently research latest technologies, needs minimal guidance to deliver on commitments .
Creative, Innovative and Solution-oriented mindset along with a positive attitude
Comfort presenting complex, technical topics in an actionable manner to technical and non-technical team members within our organization
Ability to learn quickly and pick up new skills/concepts.
Comfortable with delivering in an ever-changing environment.
Strategic thinking and passion for business strategy and business processes
Seeking a team member who embraces our core values of Integrity, Customer Focus, Innovation, Teamwork, and Coachability.
Collaborative, communicative, respectful, you help others meet their goals, cultivate trust, lead with respect, and practice self-awareness.
Proven experience delivering within a distributed team.
Willingness to participate in daily scrum meetings; collaborate with other agile squads and work in a matrix environment.
Drive Results: pushes self and others to exceed goals and achieve breakthrough results. Demonstrates persistence in removing barriers to achieving results and encourages others to do the same.

#LI-Hybrid

What We Offer We know you bring your whole self to work every day. That is why we are committed to providing modernized benefits and cultural perks to our teammates. We offer competitive compensation, comprehensive and affordable benefits, flex time off to rest and charge, where applicable, a hybrid work model, mental & emotional wellness resources and coaching, 401K and more.

About PatientPoint PatientPoint ® is the patient engagement platform for every point of care. Our innovative, tech-enabled solutions create more effective doctor-patient interactions and deliver high value for patients, providers and healthcare sponsors. Through our nearly 140k unique healthcare provider relationships, PatientPoint's solutions impact roughly 750 million patient visits each year, further advancing our mission of making every doctor-patient engagement better ® . Learn more at patientpoint.com.

PatientPoint recognizes that privacy is important to you. Please read the PatientPoint privacy policy, we want you to be familiar with how we may collect, use, and disclose your information. Employer is EOE/M/F/D/V","$127,937 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,1987,$100 to $500 million (USD)
"Ansys
4.1",4.1,"San Jose, CA",Application Engineer II- Data Management- Remote/Hybrid,"When visionary companies need to know how their world-changing ideas will perform, they close the gap between design and reality with Ansys simulation. For more than 50 years, Ansys software has enabled innovators across industries to push boundaries by using the predictive power of simulation. From sustainable transportation to advanced semiconductors, from satellite systems to life-saving medical devices, the next great leaps in human advancement will be powered by Ansys.

Take a leap of certainty … with Ansys.

Summary / Role Purpose
Join the Ansys Customer Excellence team to partner with our customers to engineer what''s ahead, solve their real-world engineering problems, deploy Ansys software in their design workflows, and grow Ansys’ business. As a hands-on expert in Ansys products, you will use advanced-level engineering knowledge to provide technical pre-sales support, perform professional services, and help translate customer requirements into exciting new product features. You will be working within multi-disciplinary teams to advance your knowledge, experience and business impact.

Key Duties and Responsibilities
Lead/Assist in coordinating and executing all technical activities throughout the sales opportunity lifecycle such as technical discovery, product presentations, demonstrations and evaluations
As a product expert with one or more Ansys products, interact with customers to understand their product design needs and engineering design workflows; analyze how to address customers’ requirements using Ansys products and platform; articulate Ansys’ value proposition
Collaborate with the Ansys product development teams to translate customer requirements into exciting new product features; test new releases of Ansys products on industrial problems
Support Ansys field and digital marketing
Contribute to consulting services, conduct introductory and/or intermediate training classes

Minimum Education/Certification Requirements and Experience
Required education and degree type: MS in Mechanical/Chemical/Aerospace/Electrical Engineering or related field
Required minimum years of professional experience in an engineering software environment: MS+0
Demonstrated use of relevant Ansys software or knowledge of other commercial CAE, CAD, EDA, PLM software packages
Logical problem-solving, strong interpersonal and communication skills, fluent in writing and speaking English. Must effectively communicate complex technical concepts to non-technical stakeholders.
Strong organizational and time management skills, possesses a sense of urgency
Projects a professional image and demonstrates business acumen, driven to succeed
Ability to travel domestically up to 25% of time
Provide 4-6 skills that are absolutely required to perform the duties of the advertised position
Data Management Knowledge: An understanding of data management concepts, including data modeling, database design, data warehousing, ETL (Extract, Transform, Load) processes, and data integration.
Customer Focus: Customer-centric mindset, empathy, and the ability to understand client needs, managing expectations, and ensuring client satisfaction.
Product Development Process Knowledge: An understanding of how products are made from concept through delivery. Familiarity with how data management influences product design.Technical Proficiency: A solid understanding of relevant technologies, databases, and data integration tools. (ie: Python, SQL, Apache, Oracle, etc..) Ability to evaluate and recommend the right solutions based on experience.

Preferred Qualifications and Skills
Preferred education and years of professional experience in an engineering software environment: MS+3, or PhD+0
Ability to travel domestically up to 50% of time
Additional preferred requirements for the specific position being advertisedBusiness Analysis: The ability to analyze an organization''s business processes, workflows, and data requirements. The candidate will be asked to identify areas where improved data management can drive business value and efficiency.
Change Management: Implementing new data management practices often requires organizational change. The application engineer should be skilled in change management techniques to facilitate the adoption of new processes and tools among client employees
Continuous Learning: Commitment to ongoing learning to stay up-to-date with industry trends and emerging technologies.
Domain Knowledge: Expertise in a specific industry or domain. Understands the unique data challenges, compliance requirements, and industry standards for tailoring data management solutions to the client''s needs.

At Ansys, we know that changing the world takes vision, skill, and each other. We fuel new ideas, build relationships, and help each other realize our greatest potential in the knowledge that every day is an opportunity to observe, teach, inspire, and be inspired. Together as One Ansys, we are powering innovation that drives human advancement.

Our Commitments:
Amaze with innovative products and solutions
Make our customers incredibly successful
Act with integrity
Ensure employees thrive and shareholders prosper
Our Values:
Adaptability: Be open, welcome what’s next
Courage: Be courageous, move forward passionately
Generosity: Be generous, share, listen, serve
Authenticity: Be you, make us stronger

Our Actions:
We commit to audacious goals
We work seamlessly as a team
We demonstrate mastery
We deliver outstanding results

OUR ONE ANSYS CULTURE HAS INCLUSION AT ITS CORE
We believe diverse thinking leads to better outcomes. We are committed to creating and nurturing a workplace that fuels this by welcoming people, no matter their background, identity, or experience, to a workplace where they are valued and where diversity, inclusion, equity, and belonging thrive.

TAKE A LEAP OF CERTAINTY IN YOUR CAREER AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary leaders across the globe. Collectively we strive to change the world with innovative technology and transformational solutions. With a prestigious reputation in working with well-known, world-class companies, standards at Ansys are high - met by those willing to rise to the occasion and meet those challenges head on. Our team is passionate about pushing the limits of world-class simulation technology, empowering our customers to turn their design concepts into successful, innovative products faster and at a lower cost.

At Ansys, it’s about the learning, the discovery, and the collaboration. It’s about the “what’s next” as much as the “mission accomplished.” And it’s about the melding of disciplined intellect with strategic direction and results that have, can, and do impact real people in real ways. All this is forged within a working environment built on respect, autonomy, and ethics.

CREATING A PLACE WE’RE PROUD TO BE
Ansys is an S&P 500 company and a member of the NASDAQ-100. We are proud to have been recognized for the following more recent awards, although our list goes on: America’s Most Loved Workplaces, Gold Stevie Award Winner, America’s Most Responsible Companies, Fast Company World Changing Ideas, Great Place to Work Certified (China, Greece, France, India, Japan, Korea, Spain, Sweden, Taiwan, U.K.).


For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity.

#LI-Remote",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Computer Hardware Development,1970,$1 to $5 billion (USD)
Caden,#N/A,"New York, NY","Sales Engineer, Data Science","Sales Engineer, Data Science

Job Summary:
Caden’s mission is to create an equitable and fair data economy online by giving users ownership of their personal data, the ability to securely control it, and various ways to put it to work to create value with brands they trust, while always preserving their privacy. We’re a real web3 company, focused on semantics, ownership, control, and user reward, leveraging the blockchain in useful ways.
We’re led by industry veterans, backed by powerhouse investors, and crewed by the brightest minds in the game. We exist to make the internet a better place for all.
We are seeking a dynamic and technically skilled Sales Engineer to join our team. If you are passionate about technology, have excellent communication skills, and enjoy bridging the gap between technical solutions and customer needs, we encourage you to apply.

The position will report the Director - Alternative Data and also work closely with the VP, Data and Technology. As a Sales Engineer at Caden, you will play a crucial role in driving our sales efforts by providing technical expertise, solution demonstrations, and personalized consultations to our clients. You will work closely with our sales team to understand customer requirements, tailor product offerings, and ensure smooth technical transitions during the sales process. Your ability to explain complex concepts in a simple and relatable manner will be essential in building customer trust and closing deals.

What You'll Do

Collaborate with the sales team to understand customer needs, pain points, and objectives.
Experience working with financial services clients, specifically within the buy side: quantitative and fundamental hedge funds.
Experience with selling SaaS to financial services.
Comprehensive understanding of the investment process and how alternative data can be used and implemented
Strong communicator who can interpret needs /requirements and communicate internally to deliver solutions.
Conduct in-depth technical discussions with prospects to identify the best-fit solutions and demonstrate the value of Caden’s Alt-Data products and solutions.
Articulate complex technical concepts to both technical and non-technical audiences, tailoring your communication to suit the recipient's level of understanding.
Develop and deliver compelling product presentations, demos, and proofs of concept (PoCs) that showcase the benefits and features of our offerings.
Act as the technical liaison between the customer and internal teams, ensuring a smooth handoff from sales to implementation.
Provide detailed technical documentation, including solution architectures, technical specifications, and integration guides.
Collaborate with product management and engineering teams to gather customer feedback and contribute insights for product improvement.
Assist in the preparation of RFPs (Request for Proposals) and RFIs (Request for Information), offering technical insights to support the sales proposal process.
Stay up-to-date with industry trends, emerging technologies, and competitors' offerings to maintain a competitive edge in the marketplace.
Address technical inquiries from (existing) customers, troubleshoot issues, and provide effective solutions to challenges. (post -sales)
Collaborate with the sales team to develop sales strategies, forecasts, and targets based on technical insights.

What You’ve Done
Required:
Bachelor's degree in Engineering, Computer Science, or a related field; advanced degree is a plus.
Proven experience (3-5 years) as a Sales Engineer, Solutions Consultant, or a similar role.
Strong technical background with the ability to understand and explain complex technical concepts.
An understanding of the manipulation of data sets, both structured and unstructured, with natural curiosity for exploring data and uncovering new insights
An understanding of statistics, modeling and machine learning techniques and hands-on experience building analytic processes and solutions for financial services,, adtech and/or marketing use cases.
Excellent interpersonal and communication skills, with the ability to build rapport and trust with customers.
Proficiency in delivering technical presentations and product demonstrations.
Experience with sales and CRM tools for tracking leads, opportunities, and customer interactions.
Strong problem-solving skills and the ability to think on your feet during customer interactions.
Ability to work collaboratively in a cross-functional environment and manage multiple projects simultaneously.
Hands-on expertise with SQL and SQL analytics
Experience using Tableau and/or Databricks and/or Snowflake.
Willingness to travel for customer visits, presentations, and conferences as required.
Preferred:
Familiarity with the following programming languages: SAS, Python and R
Business Development, Sales and/or Marketing experience is a big plus - Experience selling to financial services, adtech and/or martech clients

Why Caden
Join a forward-thinking company that is at the forefront of innovation in data intelligence.
Opportunity to make a significant impact on our sales strategy and customer engagement.
Collaborative and inclusive work environment that encourages innovation and artistic growth.
Competitive compensation package with performance-based incentives.
Professional development opportunities, workshops, and conferences to enhance your skills.
Health & Commuter Benefits.
Hybrid work arrangements

Salary: $110,000 - $150,000 base. Salary may vary based on experience.
If you are a technically adept professional with strong communication skills and a passion for driving sales through technical expertise, consider joining Caden as a Sales Engineer. Help us create meaningful connections between our solutions and our customers' needs.
Caden is an equal opportunity employer. We encourage applications from candidates of all backgrounds and experiences.

** There is currently no relocation and/or visa (immigration) assistance provided for this position.
QOsLrM6pvz","$130,000 /yr (est.)",Unknown,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Hardinge Inc
2.9",2.9,"Elmira, NY",Data Systems Engineer,"Location: Elmira NY (On-Site Position)

Sponsorship: This position does not include sponsorship.

Position Overview:
We are seeking a highly skilled and motivated Data Systems Engineer to join our team. This individual will play a crucial role in ensuring accurate and real-time reporting of manufacturing metrics by scrubbing existing data systems and designing/implementing real time display dashboards and reporting. The ideal candidate should have a strong background in SQL, data systems, live metric reporting, and experience with JDE, Power BI, Microsoft Access, Excel, ERP, and MRP systems. Additionally, the candidate should be adept at collaborating with various departments to address reporting and ERP process issues.

Responsibilities:
Analyze existing data systems and databases to identify discrepancies and inconsistencies.
Develop and implement strategies to clean and organize data, ensuring data accuracy and integrity.
Create and maintain real-time reporting mechanisms for manufacturing metrics using appropriate technologies and tools.
Collaborate with cross-functional teams to gather requirements, design, and develop display dashboards for real-time data monitoring.
Integrate data sources from various systems, including JDE, Kronos, Power BI, Microsoft Access, and Excel to ensure seamless data flow.
Design and implement data visualizations and reports that provide insights into manufacturing performance, process efficiency, and financial correlations.
Work closely with finance teams to ensure that manufacturing metrics and financial records are aligned and accurate.
Identify and troubleshoot data-related issues, implementing solutions to enhance reporting accuracy and efficiency.
Collaborate with departments across the organization to identify and resolve reporting and ERP process issues.
Stay updated with industry trends and emerging technologies to suggest continuous improvements in data reporting systems.

Qualifications:
Bachelor's degree in Computer Science, Information Systems, Engineering, or a related field. Master's degree is a plus.
Proven experience (7+ years) working with SQL, data systems, and real-time reporting.
Strong proficiency in JDE, Oracle, Power BI, Microsoft Access, and Excel for data analysis and visualization.
Familiarity with ERP and MRP systems, with the ability to extract, transform, and load (ETL) data from these systems.
Experience in designing and implementing display dashboards and real-time reporting solutions.
Excellent problem-solving skills and attention to detail, with the ability to identify data inconsistencies and discrepancies.
Strong understanding of data integrity, validation, and cleansing techniques.
Effective communication skills and the ability to collaborate with teams from various departments.
Solid project management skills, with the ability to prioritize tasks and manage deadlines.
Self-motivated, proactive, and able to work both independently and as part of a team.
Familiarity with financial data and the ability to link manufacturing metrics to financial records.

Benefits:
Competitive salary and benefits package.
Opportunity to work in a dynamic and collaborative environment.
Chance to make a significant impact on manufacturing processes and data reporting.
Professional growth opportunities through ongoing learning and development.
Access to cutting-edge technologies and tools.
If you are passionate about data systems, real-time reporting, and driving process improvements, we encourage you to apply. Join our team and play a key role in shaping our data-driven manufacturing success.

Pay Range: $80,000-$100,000","$90,000 /yr (est.)",1001 to 5000 Employees,Company - Public,Manufacturing,Machinery Manufacturing,1890,$100 to $500 million (USD)
"Tesla
3.6",3.6,"Fremont, CA",Vibration Test & Data Analysis Engineer,"What to Expect
This position will work as a member of Tesla’s reliability and test team to develop and execute vibration and durability validation tasks for Tesla products.
What You’ll Do
Process public roads, proving ground durability data and develop accelerated random vibration profiles for MAST/ED shakers
Develop constant amplitude durability test profiles based on raw data collected from proving ground or field data
Conduct vibration testing on various vehicle sub-systems on electrodynamic shaker tables
Development, improvement of vibration durability methodologies (simulation and testing)
Do hands-on test setup (mounting unit on and off the shaker table) and instrumentation (accelerometers etc.)
Design test fixtures in CATIA for mounting sub-systems on electrodynamic and other shaker tables
Conduct part inspections, root cause and report failures
Post process test data and make test reports
Be involved with general test equipment maintenance and lab expansions
Work in close collaboration with other technicians, instrumentation and design teams
Maintain a clean and organized work environment
What You’ll Bring
BS and/or MS degree in mechanical, automotive or mechatronics engineering or equivalent
Strong mechanical engineering, vibration, and durability (damage theory) fundamentals
1+ years of experience with automotive systems or competitive projects like Formula SAE etc.
Data processing and analysis using nCode Glyphworks, MATLAB, Python etc.
Well versed with the instrumentation, usage, and data consumption from accelerometers, strain gages, load transducers and other road load data acquisition sensors.
Experience with modal testing
Experience with 3D CAD software for fixture design (CATIA or 3D Experience preferred)
Able to work well under pressure while managing competing demands and tight deadlines
Excellent written & verbal communication skills
Strong organization skills with meticulous attention to detail","$128,812 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Jacobs
4.0",4.0,"Sandusky, OH",Data Engineer,"Challenging Today. Reinventing Tomorrow.
We're invested in you and your success. Everything we do is more than just a project. It's our challenge as human beings, too. That's why we bring a thoughtful and collaborative approach to every one of our partnerships.
At Jacobs, we challenge the status quo and redefine how to solve the world's greatest challenges, transforming big ideas into intelligent solutions for a more connected, sustainable world.
Design your career with a company that inspires and empowers you to deliver your best work so you can evolve, grow and succeed – today and into tomorrow

Your Impact:
Overview
The Test Facilities Operations, Maintenance, and Engineering (TFOME) contract at the NASA Glenn Research Center, Neil A. Armstrong Test Facility in Sandusky, OH is searching for a Data Engineer to support the integrity of the overall data acquisition process and work closely with the test customers, electrical and instrumentation engineers, and computer programmers to ensure that high quality data is being collected. The Data Engineer will provide engineering support and leadership in the planning, design, and technical execution of mechanical engineering and technical tasks for an assigned test or facility project at a test facility.
Responsibilities
Serves as a system manager for various facility systems at assigned test facilities.
Provides technical expertise to the users of the ground test facilities in planning test projects to ensure proper match of facility requirements with capabilities, balance of resources, and integration of schedules.
Works with the test customer to understand data requirements, measurement needs including accuracies, instrumentation requirements, and performance calculations.
Acts as a liaison between the test customer, electrical/instrumentation engineers, and the data acquisition system programmer.
Works with the test customer in the development of requirements for the data acquisition and analysis software then with the programmer to implement the requirements into the data collection and analysis software.
Works directly with electrical test engineers and technicians to ensure that the data systems are properly configured, and that all instrumentation is functioning properly.
Develops and supports development of code for data acquisition and analysis of test data. Develops on-line data displays (graphical and tabular displays) for use in data analysis and troubleshooting during testing.
Provides project management support for an assigned test project including developing detailed project plans and project schedules with a task list, durations and assignment of resources relevant to data acquisition, programming and instrumentation needs.
Works with the electrical engineers and programmers to develop the schedule input, and with the project lead for integration of the overall project schedule.
Supports large and small scale aerospace ground testing projects, including involvement of system and hardware installation, measurement and data requirements, data analysis, instrumentation specifications, and final report generation.
Prepares documentation supporting facility development efforts.
Prepares specifications and purchase requisitions for facility hardware.
Provides support for training of other engineers and technicians.
Develops presentations, and presents at design reviews, safety reviews, and other technical presentations.
Provides periodic status reports on each assigned task to contractor and customer management.
Conducts design of experiments and experimental error analyses.
Coordinates calibration activities for assigned systems.
Here’s What You’ll Need:
Qualifications
Requires a Bachelor of Science degree in Aerospace, Electrical, Electronic, Computer Engineering, Computer Science, or similar, and a minimum of three (3) years relevant experience.
General knowledge and understanding of aerospace testing, facility operations, and concepts being tested, such as aircraft performance, air-breathing engine performance, fluid dynamics, etc.
Understanding of mechanical test systems involving hydraulics, high vacuum, pneumatics, fluid mechanics, fluid dynamics, aerodynamics, and mechanical design.
General understanding of electronic test systems involving data acquisition, sensors, and signal conditioning.
Proficient in inspecting, editing, navigating, and performing basic file system and configuration tasks using the Command Line Interface (CLI) on systems running Microsoft Windows and Linux operating systems.
Proficient in using common command line tools such as PuTTy, Rsync, SSH, Cygwin, etc. to securely transfer data to and from ATF systems and system components.
Proficient with:
Data Acquisition Control (DAC) systems that use the Experimental Physics and Industrial Control System (EPICS) software toolkit.
An Infrastructure-As-Code approach to Software Configuration Management using Ansible.
Python Programming Language.
Auto Cad (for 2D drawings).
SQL/MySQL Database Theory and Application.
EMI/EMC Theory and Application.
Database Theory and Application.","$78,287 /yr (est.)",10000+ Employees,Company - Public,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1947,$10+ billion (USD)
"Gridiron IT
4.6",4.6,Remote,Software/Data Engineer,"_Gridiron IT is seeking a Software and Data Engineer to support a federal program in Washington, DC.
_
Role Description:
We are implementing a data and analytics solution built on Snowflake and Power BI. The primary source of the data is Microsoft Dataverse via Azure Data Lake Storage Gen2. We are seeking a Software and Data Engineer to work as part of a small team that will be designing and implementing the end-to-end functionality needed, primarily focused on the non-visual (i.e., Power BI presentation) requirements. You’ll be working in a collaborative environment with a constantly changing understanding of requirements. You should be prepared to pick-up whatever needs to be done and approach it with a sense of urgency while delivering quality production-ready solutions.
Core Tasks:
Design, implementation, and testing of data transformation code using SQL.
Develop process and scripts using a language such as Python or PowerShell to support data and file operations.
Create and maintain a security model to secure access to a database.
Implement build and release pipelines to automate instantiation of cloud services, run schema/DDL, etc.
Technical Skills (Order of Importance):
SQL Development
Python or PowerShell Development
Creation and execution of unit tests for SQL code
Data model and data warehousing concepts
Snowflake
Git source control (clone, branch, commit, push, etc.)
Build and release pipeline development using Azure DevOps or GitHub Enterprise
Power BI (or similar tool such as Tableau) is helpful
Job Type: Full-time
Pay: $70.00 - $80.00 per hour
Benefits:
401(k) matching
Dental insurance
Health insurance
Vision insurance
Experience level:
7 years
8 years
9 years
Schedule:
Monday to Friday
Application Question(s):
This project is in support of a federal client; and therefore you will be processed for a federal public trust. This requires US Citizenship and a clean criminal and credit history. Do you meet these requirements?
Experience:
SQL: 7 years (Required)
Python scripting: 5 years (Required)
Work Location: Remote",$75.00 /hr (est.),51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,Unknown / Non-Applicable
"Meta
3.9",3.9,"Seattle, WA",Software Engineer - Data Center Networking,"The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!


Software Engineer - Data Center Networking Responsibilities:
Design and implement drivers (and/or Firmware) for (network) ethernet adapter functions, Transport stack for RDMA, control functions with the host/accelerators.
Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).
Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI
Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
5+ years of experience in C/C++ and Python
5+ years experience in Systems programming, TCP/IP, HTTP/HTTPS, SPDY, DNS, and load balancers
Experience with network devices (routers, switches, load balancers) and an understanding of network routing protocols



Preferred Qualifications:
Experience with Linux Kernel, especially drivers and network stack
Working knowledge of transport stack particularly RDMA (RoCEv2)
Experience with Qemu, FPGA Emulation environment is a plus
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL
Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$206,997 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Nike
4.2",4.2,"Beaverton, OR",Data Engineer,"Become a Part of the NIKE, Inc. Team

\r

\r

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

Data Engineer-NIKE, Inc., Beaverton, OR. Design and implement data products and features in collaboration with product owners, data analysts, and business partners. Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes. Contribute to evaluation of new technologies/tools/frameworks centered around high-volume data processing. Translate product backlog items into logical units of work in engineering. Implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem. Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns. Work with engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and followed. Build and incorporate automated unit tests and participate in integration testing efforts. Utilize and advance continuous integration and deployment frameworks. Troubleshoot data issues and perform root cause analysis. Work across teams to resolve operational & performance issues. Telecommuting is available from anywhere in the U.S., except from AK, AL, AR, DE, HI, IA, ID, IN, KS, KY, LA, MT, ND, NE, NH, NM, NV, OH, OK, RI, SD, VT, WV, and WY.

Employer will accept a Master's degree in Computer Information Systems, Electronics Engineering or Engineering and 2 years of experience in the job offered or in a computer-related position.

Experience must include:
Programming languages such as Python, SQL, Java and Scala;
Big Data cloud computing technologies and services such as AWS and Azure;
Data pipeline orchestration tools such as Airflow, and Autosys;
Streaming processing systems like Kafka, Nifi, and AWS Lambda;
Databases such as Oracle, DynamoDB, and Snowflake;
Scripting language such as Unix and PowerShell;
Big Data technologies like Hadoop, Hive, Spark, and MapReduce;
CI/CD tools such as Jenkins;
Postman, RESTful API's;
Data architecture; and
Data modelling.

#LI-DNI

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

How We Hire

At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.

This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.

Benefits

Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$107,308 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"Jack Henry and Associates, Inc.
3.8",3.8,Remote,Systems Engineer III : VMware \ Data Protection,"At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you’ll join us. We can’t do it without you.

As part of the Infrastructure Engineering team the Systems Engineer III will design, document, implement, and maintain virtual infrastructure systems in an enterprise VMware vSphere environment. Perform capacity and performance analysis and provide recommendations for optimization. Complete lifecycle and other project-based work efforts as part of a larger interdisciplinary team. Drive continuous improvement by providing guidance on system automation, monitoring, configuration, and delivery to improve uptime and increase efficiency.

The salary range for this position is: $90,000- $115,000 based on location and experience.

This position will be filled to work Remotely within the United States.

What you’ll be responsible for:
Design, document, implement and maintain virtual infrastructure systems in a high availability, 24x7x365 enterprise environment.
Participate in high visibility projects for top corporate priorities.
Develop and maintain standard operating procedures.
Monitor alerting systems and servers.
Perform troubleshooting, and problem analysis and resolution.
Review issues, logs, and capacity reports to identify trends and solutions that should be implemented enterprise wide.
Develop custom reports to meet the business needs.
Drive continual service improvement.
Assist with disaster recovery initiatives and Implement solutions to streamline disaster recovery.
May perform other job duties as assigned.

What you’ll need to have:
Minimum of 5 years of experience in a systems engineer role designing and implementing VMware vSphere solutions in an enterprise environment.
Proficiency with VMware vCenter Server and ESXi 7.0 and 8.0.
Experience deploying and maintaining VMware virtual infrastructure.
Strong verbal and written communication skills.
Ability to work an on-call rotation including nights and weekends based on business needs.
Ability to travel up to 5% to attend meetings, trainings, and/or professional conferences.

What would be nice for you to have:
VMware Certified Professional - Data Center Virtualization (VCP - DVC) certification.
Strong knowledge of disaster recovery using Commvault, VMware Site Recovery Manager and/or Zerto.
Scripting and Infrastructure as Code tools and methodologies such as PowerShell, Python, Ansible and Terraform.
Experience working with other VMware products: VMware Cloud Director, NSX, Aria Operations (vRealize Operations), Aria Operations for Networks (vRealize Network Insights), and Horizon.
Change Management process experience.
Able to multi-task and use independent judgment to plan, prioritize and organize a diversified workload.

If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry’s mission and can contribute to our company in a variety of ways.

Why Jack Henry?

At Jack Henry, we pride ourselves through our motto of, ""Do the right thing, do whatever it takes, and have fun."" We recognize the value of our associates and believe much of our company’s strength and success depends on their well-being.

We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.

Culture of Commitment

Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.

Equal Employment Opportunity

At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business—and our society—stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.

No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.

Requests for full corporate job description may be requested through the interview process at any time.","$102,500 /yr (est.)",5001 to 10000 Employees,Company - Public,Financial Services,Banking & Lending,1976,$1 to $5 billion (USD)
"Personio
3.7",3.7,"New York, NY","Lead Engineer, Data Platform","The Role
At Personio, your work transforms the way millions of people experience work every day. Join our Product & Technology team that drives our customer's outcomes by designing, developing and delivering innovative and high quality products. Be empowered to take ownership of your areas and make an impact on your team, our product, and our customers. Personio is the all-in-one HR solution for small and medium-sized enterprises. With offices in New York, Munich, Madrid, London, Dublin, Amsterdam, Barcelona and Berlin, Personio is on a mission to make people processes as transparent and efficient as possible, so HR can focus on what matters most - people and strategy.
Our Product Platform domain is fulfilling this purpose by building out the platform strategy for Personio’s product. We are a rapidly growing, enablement-focused domain that strives to create secure, reusable, and extensible systems that accelerate the ability of our internal teams to create customer value, at scale.
Furthermore, Product Platform plays a pivotal role in delivering the tooling, components, templates and standards that establish the foundations of a common Personio design platform; ultimately providing our customers with a consistent, accessible and delightful experience.
To support our mission, we are looking for a Lead Software Engineer with expertise in data capture, event-driven architecture and tooling, effective data governance, as well as continuously enhancing system reliability and operational excellence. You’ll partner with product and engineering peers across the organization to build a reliable, resilient, scalable and future-proof Personio data platform.

Role & Responsibilities:
You will research, engineer and experiment with new ways to improve the developer experience and DevOps practices to provide product teams with the capability to deploy on demand while also limiting any risk to the stability of production.
Your scope will include everything from how software components are built, tested, deployed, released and monitored across all environments, from the local machine straight through to our production clusters.
You will foster relationships and work closely with product teams to support them through platform specific migrations. Learn from and understand the challenges they face so that you can translate them into result-oriented solutions that help improve the reliability of the platform.
You will also spend time teaching engineers (especially new joiners) how to use our tools, whether by giving internal talks, organizing internal onboarding workshops or writing documentation and tutorials.
You will conceptualize and own technical solutions end-to-end. Organizing effective groups of engineers to brainstorm, design and deliver impactful work.
You will help your team manage technical debt, refactor existing solutions, and introduce and improve the team’s approach to principles and processes such as system architecture, design patterns, coding principles and code review.
You will use your existing experience to help drive the platform forward with new ideas and strategies that help maintain the quality, reliability, security, performance and cost effectiveness of the product and platform.
You will partner with your engineering manager, keeping them up to date and informed with technical details across multiple projects. Helping to ensure the team is delivering results in an iterative fashion that is driven by impact and promotes a culture of experimentation and learning.
What you need to succeed
8+ years of software engineering experience building and designing scalable applications, tools or distributed systems. You understand the needs of software engineers working in product teams, you’ve been in their shoes, and can empathize with them. You want to help your fellow engineers to achieve maximum efficiency.
Proficiency in Kafka operations or building platform tools that utilize Kafka.
Experience in both constructing and managing a schema registry, contributing to effective data governance.
Preferably experience in DevOps or Site Reliability Engineering (SRE) roles, enhancing our commitment to system reliability and operational excellence.
Preferably hands-on experience with various database technologies, Debezium and data capture.
You have a deep understanding and an interest for DevOps tools and technologies such as: Kubernetes, AWS (CDK, ECS, Fargate etc.), Gitlab, DataDog, Sentry, Projen, Backstage, Docker and in particular progress delivery automation (CI/CD pipelines, feature flags, canary deployments, service mesh).
You’re comfortable designing, building, documenting and distributing robust and delightful solutions in the form of services, CLI tools, scripts & plugins for developers.
You’re interested in development processes and practices (merge requests, approvals, trunk-based vs branch-based development, etc), and are eager to optimize and automate them.
Experience acting as a mentor or role model to other engineers is a plus. Ideally leading pair and mob programming sessions, as well as setting up and running technical brainstorming and solution design sessions.
You strike a balance between a strategic and tactical mindset. You are capable of working with your engineering manager to translate the platform's strategic vision into tactical, achievable objectives for the team.
You want to work with a very technical team on developer-facing tools and services, and you like writing great technical documentation and useful tutorials.
You are data-driven and are passionate about using metrics to define your engineering design decisions as well as measuring the impact of your work.
You have excellent written and spoken English (level C1/C2 on the CEFR scale)
We are experiencing rapid growth and are “building our plane while flying it” so bring your agile mindset to the table.
You embrace feedback - no one is perfect, and neither are we. So let’s make this an opportunity to praise and learn from each other.
Finally, you have a good sense of humor. Have fun with us, learn with us from our mistakes and bring your good vibes!

What motivation and mindset you should bring:
Driven by impact - We work hard and take action to achieve great results for our customers and Personio
Speed of execution - We are moving fast and are relying on you to elevate the team delivery
Embrace feedback - no one is perfect, and neither are we. So let’s make this an opportunity to praise and learn from each other
Tech branding - tell others about the things you like, either through blogging or tech events
Humor - have fun, learn and bring your good vibes
Why Personio
Our Benefits:

Medical insurance
Vision insurance
Dental insurance
401(k)
20 days of paid vacation, plus another additional day after 2 and 4 years (because we love what we do, but we also love vacation!)
2 Impact Days you can use to have an impact on the environment and society – one for an individual project of your choice and one for a company-wide initiative! #SocialResponsibility
Annual personal development budget for you to invest in your development via professional memberships, external certifications, conferences, and more
High-impact working environment with flat hierarchies and short decision-making processes
Receive family leave, child support, and sabbatical opportunities with PersonioCares
$185,000/year to $205,000/year + equity + benefits
Please note the national salary range listed in the job posting reflects the new hire salary range across levels and U.S. locations that would be applicable to the position. Final salary will be commensurate with the candidate’s final level and final location. Also, this range represents base salary only and does not include equity, or benefits, if applicable.

Please note that the information provided in this job posting is for general informational purposes only. The job posting is provided 'as is' without any representations or warranties, express or implied. Personio makes no representations or warranties in relation to the accuracy, completeness, or suitability of the information contained in this job posting. By applying to this position, applicants acknowledge that they have read and understood this disclaimer and that Personio shall not be held liable for any reliance on the information contained herein.

Personio is an equal opportunities employer, committed to building an integrative culture where everyone feels welcomed and supported. We #EmbraceUniqueness and understand that our diverse, values-driven culture makes us stronger. We are proud to have an inclusive workplace environment that will foster your development no matter your gender, civil status, family status, sexual orientation, religion, age, disability, education level, or race.
About us
Bring your best. Make your mark. We’re using technology to revolutionize the way HR operates so that we can transform the way millions of people experience work every day. We move fast, challenge the status quo, and support our people as they shape their careers.

With over 10,000 customers and a team of 1,800 in seven offices across Europe, now is the perfect time to join! We believe in hiring driven people who want to make an impact. So bring your best, and let’s build the future of HR technology together.

Personio is an equal opportunities employer, committed to building an integrative culture where everyone feels welcomed and supported. We #EmbraceUniqueness and understand that our diverse, values-driven culture makes us stronger. We are proud to have an inclusive workplace environment that will foster your development no matter your gender, civil status, family status, sexual orientation, religion, age, disability, education level, or race.","$195,000 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Software Development,2015,Unknown / Non-Applicable
"RVO Health
3.9",3.9,"Minneapolis, MN","Senior Data Engineer, Talent Analytics","AT A GLANCE
RVO Health is looking to grow our Talent Analytics team by adding a Senior Data Engineer. In this role, you'll be challenged to help shape our Talent Analytics strategy while working on high-priority data efforts – all in line with our broader mission of attracting diverse talent and giving them an experience that will bring out their very best. You will be responsible for scoping, executing, and delivering technical projects to stakeholders across the Human Capital organization, and producing data engineering & analytical solutions that connect them to the data they need.
What You'll Do
Develop/maintain data pipelines from various data sources (ADP WFN, Greenhouse Recruiting/Onboarding, CultureAmp, Docebo, etc) to a target data warehouse using batch data load strategies utilizing cutting edge cloud technologies.
Conduct hands-on, advanced data engineering & analytics using multiple data sources originating from different applications and systems.
Collaborate with the data science team to identify new opportunities for deep analytics within the Human Capital organization.
Provide input into strategies as they drive the team forward with delivery of business value and technical acumen.
Execute on proof of concepts, where appropriate, to help improve our technical processes.
Documenting database designs that include data models, metadata, ETL specifications and process flows for business data project integrations.
What We're Looking For
5+ years of Data Engineering experience
3+ years of writing SQL experience against complex databases for data extraction using AWS Athena (Presto), Databricks Delta Lake along with Data Modeling & Data warehousing experience.
3+ years of experience working on Spark (RDDs / Data Frames / Dataset API) using Scala/Python to build and maintain complex ETL pipelines and experience data processing using Parquet and Avro
3+ years of Python coding experience, familiar with utilizing packages such as pandas, boto3, requests, json, csv, os
3+ years of experience working on AWS services including Glue, Athena, Lambda, S3, SNS, SQS, Cloud formation, Step Functions, Serverless architecture.
Experience with GitHub, Code check-in, versioning, Git commands
Introduce and drive adoption of CI/CD framework within the team and build/deploy CI/CD Pipelines using Terraform or AWS Cloud Formation
Experience with visualization tools such as Tableau, Looker or PowerBI to build dynamic/scalable dashboards and reports.
Strong analytical and interpersonal skills
Knowledge or experience within Talent/People analytics is a plus
Enthusiastic, highly motivated and ability to learn quickly.
Able to work through ambiguity in a fast-paced, dynamically changing business environment.
Ability to manage multiple tasks at the same time with minimal supervision.
Pursuant to various state Fair Pay Acts, below is a summary of compensation elements for this role at the company. The following benefits are provided by RVO Health, subject to eligibility requirements.
Starting Salary: $100,000 - $170,000
Note actual salary is based on geographic location, qualifications and experience
Access to a Free Udemy for Business subscription—thousands of hours of learning content on hundreds of different subjects at your fingertips
Health Insurance Coverage (medical, dental, and vision)
Life Insurance
Short and Long-Term Disability Insurance
Flexible Spending Accounts
Paid Time Off
Holiday Pay
401(k) with match
Employee Assistance Program
Paid Parental Bonding Benefit Program
This position may occasionally require travel for training and other work-related duties.
Who We Are:
Founded in 2022, RVO Health is a new healthcare platform of digital media brands, services and technologies focused on building relationships with people throughout their health & wellness journey. We meet people where they are in their personal health journeys and connect them with both the information and the care they need. RVO Health was created by joining teams from both Red Ventures and UnitedHealth Group's Optum Health. Together we're focused on delivering on our vision of a stronger and healthier world.
RVO Health is comprised of Healthline Media (Healthline, Medical News Today, Psych Central, Greatist and Bezzy), Healthgrades, FindCare and PlateJoy; Optum Perks, Optum Store and the virtual coaching platforms Real Appeal, Wellness Coaching, and QuitForLife.
We offer competitive salaries and a comprehensive benefits program for full-time employees, including medical, dental and vision coverage, paid time off, life insurance, disability coverage, employee assistance program, 401(k) plan and a paid parental leave program.
RVO Health is an equal opportunity employer that does not discriminate against any employee or applicant because of race, creed, color, religion, gender, sexual orientation, gender identity/expression, national origin, disability, age, genetic information, veteran status, marital status, pregnancy or any other basis protected by law. Employment at RVO Health is based solely on a person's merit and qualifications.
We are committed to providing equal employment opportunities to qualified individuals with disabilities. This includes providing reasonable accommodation where appropriate. Should you require a reasonable accommodation to apply or participate in the job application or interview process, please contact accommodations@rvohealth.com.
We do not provide visa sponsorship at this time.
RVO Health Privacy Policy: https://rvohealth.com/legal/privacy","$135,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Hospitals & Health Clinics,2022,Unknown / Non-Applicable
"Equinix
4.2",4.2,"Carteret, NJ",Data Center Critical Facilities Engineer,"Data Center Critical Facilities Engineer
Equinix is the world’s digital infrastructure company, operating 240+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, complex infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.

We are a fast-growing global company with 20 years of continuous growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of 10,000+ companies, including 2,100 networks and 3,000+ cloud and IT service providers in 32 countries spanning six continents.

Joining our operations team means that you will be at the forefront of all we do, maintaining critical facilities infrastructure as part of a close-knit team delivering best-in-class service to our data center customers. We embrace diversity in thought and contribution and are committed to providing an equitable work environment. that is foundational to our core values as a company and is vital to our success.
Job Summary
Data Centers are considered Critical Facilities. This means that we support hospitals, laboratories, public safety centers. Simply put - We cannot go dark. In this crucial role, you will complete repairs, corrective maintenance, and routine installations of Critical Facility infrastructure.
Responsibilities
Perform site inspections and supervise the building and Data Center alarms
Perform preventative maintenance of on-site infrastructure (e.g. maintenance of primary infrastructures), and lead vendors in maintenance activities
Undertake repairs and corrective maintenance of critical infrastructure i.e. UPS, generator, BMS, chillers, life safety systems
Complete site logs and data gathering issuing for basic permits, such as MOPs and scripts
Respond to all on-site incidents and act as the need arises
Completes routine work requests and circuit installations
Provide assistance during critical maintenance activities
Collaborate within the department and provide recommendations to peers for general maintenance activities
Carry out basic infrastructure projects
Work any assigned shift, off-schedule, fill in for workmate, respond to emergencies, etc

Qualifications
3 or more years’ experience with facilities electrical, HVAC and/or mechanical
Experience working in a critical facility
Strong system level mechanical or electrical proficiency
You are capable of lifting up to 50 lbs. and are agile in manual dexterity (climb, stoop, et.) with or without an accommodation
High School Diploma or equivalent
The targeted pay range for this position in the following location is / locations are:
California (Non-SF/Bay Area), Connecticut, Maryland, New York, New Jersey, Washington state: $63,000 to $98,000

Our pay ranges reflect the minimum and maximum target for new hire pay for the full-time position determined by role, level, and location. Individual pay is based on additional factors including job-related skills, experience, and relevant education and/or training.

This position may be offered in other locations. Your recruiter can share more about the specific pay range for your preferred location during the hiring process.

The targeted pay range listed reflects the base pay only and does not include bonus, equity, or benefits. Employees are eligible for bonus, and equity may be offered depending on the position.

More details about our company benefits can be found at the following link:
https://equinixbenefits.us.newsweaver.com/icfiles/201/1002910/1057118/1171391/921bc962bf0e0352cb2d6c93/equinix%202023%20oe%20ebook_rev122022%20-%20final.pdf
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.
Equinix is an Equal Employment Opportunity and, in the U.S., an Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to unlawful consideration of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy / childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political / organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law.
Equinix is committed to ensuring that our employment process is open to all individuals, including those with a disability. If you are a qualified candidate and need assistance or an accommodation, please let us know by completing this form.",#N/A,10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1998,$1 to $5 billion (USD)
"Hilton
4.0",4.0,"McLean, VA",Senior Lead Data Science Engineer,"Senior Lead Data Science Engineer
***This role is based at one of our corporate offices in McLean, VA, or Remote***
This is your chance to be a part of an in-house Technology team that's creating consumer-facing, modern technologies revolutionizing the hospitality industry around the world! As a Senior Lead Data Science Engineer, you will bring your technical skills to a hospitality company with an award-winning culture. On the Enterprise Architecture and Data organization reporting to Director, Data Science Engineering, you will support projects including Pricing Solutions and Customer Insights.
HOW WE WILL SUPPORT YOU
Hilton is proud to support the mental and physical wellbeing of all Team Members so they can Thrive personally and professionally in a diverse and inclusive environment, thanks to programs and benefits such as:
Go Hilton travel program: 100 nights of discounted travel with room rates as low as $40/night
Hilton Shares: Our employee stock purchase program (ESPP) - you can purchase Hilton shares at a 15 percent discount
Paid parental leave for eligible Team Members, including partners and adoptive parents
Mental health resources including free counseling through our Employee Assistance Program
Paid Time Off (PTO)
Learn more about the rest of our
At Hilton, we believe every Team Member is a leader. We are committed to offering leadership development opportunities through every step of a Team Member's career journey and at every level, both in our hotels and across corporate. Hilton's leadership development framework focuses on developing skills and business insight through a range of programs and approaches to meet varying learning needs and preferences.
**Available benefits may vary depending upon terms and conditions of employment and are subject to the terms and conditions of the plans.
HOW YOU WILL MAKE AN IMPACT
Your role is important and below are some of the fundamental job duties that make your work unique.
What your day-to-day will be like:
Hands-on coding using Python and PySpark to build data pipelines, implement Pricing Models and Customer Insights Models.
Attend team daily meetings to update the progress.
Find ways to improve performance of Machine Leaning pipelines. Find opportunities to automate routine tasks.
Understand Hilton processes, architecture and find opportunities for continuous improvement.
How you will collaborate with others:
Collaborate with Data Science, Cloud Engineering, Global Information Security and Operations teams to build well architected solutions.
Create detailed documents using Atlassian tools to describe the solution and build architecture diagrams that adhere to Hilton standards to socialize the solution to leadership.
Work with Business Architecture team to understand requirements, refine them to meet the business expectations.
Work with Delivery Team to build solutions using Agile methodologies.
What projects you will take ownership of:
Build Data Engineering solutions to run models at scale in Pricing, Customer insights domains.
WHY YOU'LL BE A GREAT FIT
You have these minimum qualifications:
Seven (7) years of professional experience within Technology or a related field
Two (2) years of experience with data technologies and platforms such as AWS and Spark
Two (2) years of experience working with relational databases or AWS Redshift
Two (2) years of experience in Python programming
Experience analyzing customer data and preparing customer data for modeling
Ability to travel up to 15%
It would be useful if you have:
Bachelor's Degree, or Associate's Degree plus 6+ years of Technology related experience, or High School Degree/GED plus 12+ years of Technology related experience
Ten(10) + years of professional experience within Technology or a related field
Experience building models for Customer Analytics and Customer Insights
Experience with AWS Technologies such as EMR, Step Functions, AWS Lambdas
Unix Shell scripting experience
AWS Certifications
WHAT IT IS LIKE WORKING FOR HILTON
The future of hospitality is bright at Hilton: a leading global hospitality company with a diverse portfolio of. Dedicated to filling the earth with the light and warmth of hospitality, we have welcomed more than 3 billion guests in our more-than 100-year history. Hilton is proud to have an award-winning workplace culture and we are consistently named among one of the World's Best Workplaces. Check out the and to learn more about what it's like to be on Team Hilton!
It is the policy of Hilton to employ qualified persons without regard to color, race, creed, religion, national origin, ancestry, citizenship status, age, sex or gender (including pregnancy, childbirth and related medication conditions), gender identity or gender expression, sexual orientation, marital status, military service, status as a protected veteran, disability, protected medical condition as defined by applicable law, genetic information, or any other protected group status as defined by and subject to applicable federal, state and local laws. Hilton's commitment to equal employment opportunity supports the attraction and retention of a diverse workforce that will enhance our effectiveness in attracting Team Members, customers, corporate partners, and owners.
We provide reasonable accommodations to qualified persons with disabilities to perform the essential functions of the position and provide other benefits and privileges of employment in accordance with applicable law. Please if you require an accommodation during the application process.
Hilton offers its eligible team members a comprehensive benefits package including medical and prescription drug coverage, dental coverage, vision coverage, life insurance, short-and long-term disability insurance, access to our employee stock purchase plan (ESPP) where you can purchase Hilton shares at a 15 percent discount, a 401(k) savings plan, 20 days of paid time off accruing over your first year of employment and increasing up to 25 days after completing one year of full employment, up to 12 weeks of paid leave for birth parents and 4 weeks for non-birth parents, 10 paid holidays and 2 floating holidays throughout the year, up to 5 bereavement days, flexible spending accounts, a health savings account, an employee assistance program, access to a care coordination program (""Wellthy""), a legal services program, an educational assistance program, adoption assistance, a backup childcare program, pre-tax commuter benefit and our travel discount. The annual salary range for this role is $120,000-$165,000 and is determined based on applicable and specialized experience and location. Subject to plan terms and conditions, you will be eligible to participate in the Hilton Annual Incentive (Bonus) Plan, consistent with other team members at the same level and/or position within the Company. #LI-REMOTE","$142,500 /yr (est.)",10000+ Employees,Company - Public,Hotels & Travel Accommodation,Hotels & Resorts,1919,$10+ billion (USD)
"ACI Federal Inc
3.5",3.5,"Washington, DC",Senior Cloud Data Engineer,"We are seeking a skilled Senior Cloud Data Engineer to join our leading company!
*** US citizenship required - No C2C, no sponsorships, etc. ***
*** This is a REMOTE position ***
Description:
Hands on Cloud Engineer who could provision/administer the Azure cloud services.","$121,196 /yr (est.)",501 to 1000 Employees,Company - Private,Government & Public Administration,National Agencies,2014,Unknown / Non-Applicable
"TTEC Digital
3.6",3.6,Remote,Senior Data Engineer - Remote U.S.,"At TTEC Digital, we coach clients to ensure their employees feel valued, and fully supported, because an amazing customer experience is an employee first process. Our vision is the same, a place where employees know they can thrive.

Looking to work with cutting edge technology and expand your skill set? Have a passion for data and analytics? You’ll be instrumental in building data products and big data solutions, that turn data into actionable insights, for our clients in automotive, healthcare, retail, and travel industry. Bring your curiosity to solve interesting engineering puzzles and develop tech-enabled analytics solutions that delivers personalization at-scale. Along the way, you’ll partner with the internal consulting, data science, and technology teams to provide feedback to improve the platform.

You’ll make an impact by building actionable solutions for our clients based on your analysis and subject matter expertise in data engineering discipline.
During a Typical Day, You’ll
Partner with leadership, engineers, data scientists, and strategic data consultants to refine data requirements and drive technical solutions
Be responsible for the end-to-end implementation of the technology stack from data collection to reporting, with a focus on data infrastructure and technical processes
Design, build and launch efficient and reliable data pipelines to move, ingest and process data from disparate applications including databases, APIs, message brokers and big data stores
Contribute to conceptualization, design and maintenance of data infrastructure and architecture
Implement and monitor quality control processes to ensure accuracy of data and reports
Proactively identify internal and external dependencies, issues, scope changes and progress against project plan
Stay on top of data trends; evaluate new solutions, technologies to evolve our data platform as new needs emerge
Effectively communicate and share your knowledge with global teams through mentoring, code reviews, pair programming and presentations
Develop and expand our knowledge-base and best practices for delivering data products
Provide technical support to assist clients during pre and post implementation
Initiate and foster partnerships with current clients, potential clients, and senior business executives
What You Bring to the Role
Bachelor's in Computer Science, Engineering, or other STEM fields required (Masters preferred)
3+ years professional experience building and supporting data and analytics solutions
Mastery of SQL, Python, PySpark
Experience with Scala, NoSQL, stream processing, SQL performance tuning, build/deploy automation and E2E process optimization
Skilled at designing & building APIs
Experience designing and building solutions on any public cloud environments and associated services (e.g., Data Factory, Airflow, Databricks, Serverless Functions, mlFlow, API gateways, load balancers, DevOps)
Knowledge of data structures, data validation, algorithms, and implications of architecture on software performance
Familiarity with automated testing frameworks and concepts
Exceptional problem-solving skills: demonstrated ability to understand business challenges, structure complex problems, develop solutions
Understanding of Agile Software Development Lifecycle and project planning/execution skills
Experience organizing large projects into manageable action items and communicating next steps to stakeholders
What you can expect
The anticipated range for individuals expressing interest in this position is $120,000 - $140,000 USD. Actual compensation offers to a candidate may vary based upon geographic location, work experience, education and/or skill levels. This position is eligible to participate in an incentive program.

Benefits available to eligible employees include
Medical, dental, and vision
Tax-advantaged healthcare accounts
Financial and income protection benefits
Paid time off (PTO) and wellness time o
#LI-MS3

About Us
TTEC Digital, and our 1,700+ employees, pioneer engagement and growth solutions that fuel the exceptional customer experience (CX). TTEC Engage is a 60,000+ employee service company, with customers in more than 80 countries. Together, we utilize a holistic approach, applying solutions from two centers of excellence, Engage and Digital.
TTEC is a proud equal opportunity employer where all qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, disability. TTEC has fully embraced and is committed to expanding our diverse and inclusive workforce. We strive to reflect the communities we serve while delivering amazing service and technology centered around humanity.
Rarely do applicants meet all desired job qualifications, so if you feel you would succeed in the role above, please take a moment and share your qualifications.

#LI-RemoteUS",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Information Technology Support Services,2011,Unknown / Non-Applicable
Alpine School District Technology Department,#N/A,"American Fork, UT",Software Engineer/Data Analyst,"Candidates must apply on alpineschools.org to be considered
Position Information
1 position available on Alpine School District’s Professional Salary Schedule; 8 hours per day; 250 days per year; Benefits and Retirement Plan included. This position will work with teams to develop a Data Dashboard based on district goals and objectives.
Job Summary
Alpine School District has purchased a data dashboarding tool for viewing and analyzing student achievement and performance data. It is an interactive tool that allows educators to track, analyze, and view KPIs and metrics.
Job Requirements
Applicants will be expected to have the skills needed below to create, maintain, and troubleshoot Alpine’s dashboarding tool. This position will require and use a data analysis skill set to combine historical and real-time data from multiple sources by providing data preparation, chart creation, and analysis. This position will work closely with both technical and educational departments to create specifications for new dashboard requirements then implement them through best programming practices. This position will also test results for accuracy through the use of State and District supported tools and direct SQL queries. This person may work with employees to maintain clean student data through training and data clean up. This position may also be involved with other various department projects. This position will also be involved in programming projects as needed within the department.
Skills needed:
Analytical Skills - Understand, design and troubleshoot in a complex technical environment. Ability to problem solve data and logic issues that arise within database, middleware, and front end.
Technical Skills - Basic understanding of relational transactional and analytical, databases, data warehouses, data relationships, DB schemas, and the ETL processes used to populate these databases. Ability to understand and create complex queries using SQL. Ability to create graphical elements/charts from SQL queries. Understanding of traditional software development and some experience in traditional programming.
Numerical Skills - Ability to understand and implement statistical models in a graphical environment.
Ability to gain a thorough understanding of student data systems in order to present that data to the end user. Ability to read and make judgments on student information and work with groups to understand, create and implement reporting requirements.
Great people and communication skills.
Ability to proactively work with and train individuals and groups.
Desired Experience:
Thorough understand of database architecture, design and theory
Experience with advanced SQL queries
Experience in creating visualizations from SQL queries.
Quality Assurance experience by validating and analyzing results/reports through raw SQL queries.
Understanding of student educational systems and academic educational models
Understanding statistical analysis and creating statistical visualizations based on those concepts.
Experience in Power BI or other business analytics dashboarding tool, python, Javascript.
Job Type: Full-time
Pay: $80,000.00 - $120,000.00 per year
Benefits:
401(k)
401(k) matching
AD&D insurance
Dental insurance
Dependent health insurance coverage
Disability insurance
Family leave
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid holidays
Paid sick time
Prescription drug insurance
Retirement plan
Vision insurance
Experience level:
5 years
Schedule:
8 hour shift
Ability to commute/relocate:
American Fork, UT 84003: Reliably commute or planning to relocate before starting work (Required)
Experience:
SQL: 5 years (Preferred)
Work Location: In person","$100,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Google
4.4",4.4,"San Francisco, CA","Staff Software Engineer, Front End, Google Cloud Data Management","Note: Google’s hybrid workplace includes remote and in-office roles. By applying to this position you will have an opportunity to share your preferred working location from the following:

In-office locations: San Francisco, CA, USA; Santa Cruz, CA, USA.
Remote location(s): California, USA; United States.
Minimum qualifications:
Bachelor's degree or equivalent practical experience.
8 years of experience in software development, and with data structures/algorithms.
5 years of experience testing, and launching software products, and 3 years of experience with software design and architecture.
5 years of experience with front-end frameworks, full-stack development, and/or API development.

Preferred qualifications:
Master’s degree or PhD in Engineering, Computer Science, or a related technical field.
3 years of experience in a technical leadership role leading project teams and setting technical direction.
3 years of experience working in a complex, matrixed organization involving cross-functional, and/or cross-business projects.
About the job
Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.

With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.
Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.
The US base salary range for this full-time position is $185,000-$283,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.

Responsibilities
Provide technical leadership on high-impact projects.
Influence and coach a distributed team of engineers.
Facilitate alignment and clarity across teams on goals, outcomes, and timelines.
Manage project priorities, deadlines, and deliverables.
Design, develop, test, deploy, maintain, and enhance large scale software solutions.
Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.",#N/A,10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1998,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"East Palo Alto, CA","Senior Software Engineer, Data Lake Formation","5+ years of non-internship professional software development experience
5+ years of programming with at least one software programming language experience
5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience as a mentor, tech lead or leading an engineering team
Be part of a team which is passionate about solving real world data management and governance challenges. Come build large scale distributed systems that are central to the next generation of analytics in the cloud.

AWS Lake Formation is a service that helps build and secure data lakes in a simple, scalable, server-less architecture. We are looking for software engineers to join our growing team!

As a Software Engineer in Lake formation you will:
Solve unique and first-order problems in areas of Big Data, Distributed Systems, and Server-less data processing
Influence and build products that will leverage scale of resources to orchestrate data management and governance
Be catalyst to deliver a truly disruptive product while still early enough to have impact and influence
Key job responsibilities
Translate functional and technical requirements into detailed architecture, design and extensible code
Be an advocate of industry best-practices to produce reliable, fault-torrent and dependable code
Code and test complex system modules; develop and leverage frameworks to be effective and efficient
Participate in architecture, design and code reviews to maintain our high development standards
Mentor other engineers, defining our challenging technical culture, and helping to build a fast-growing team
Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.

About the team
We are builders and data people that are obsessed with our customers and take-on big challenges. We support each other and encourage different views. We also like to have a bit of fun along the way.

We are open to hiring candidates to work out of one of the following locations:

East Palo Alto, CA, USA

5+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $134,500/year in our lowest geographic market up to $261,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$134,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"University of Maryland
4.2",4.2,"College Park, MD",Natural Language Processing and Data Science Engineer,"Posting Details
Posting Details
Position Number:
128386

Title:
Faculty Specialist

Functional Title:
Natural Language Processing and Data Science Engineer

Category Status:
15-Fac.Non-Tenured,Continuing Con

Applicant Search Category:
Faculty

University Authorized FTE:
100

Unit:
VPR-Applied Research Lab for Intelligence & Security

Campus/College Information:
Founded in 1856, University of Maryland, College Park is the state’s flagship institution. Our 1,250-acre College Park campus is just minutes away from Washington, D.C., and the nexus of the nation’s legislative, executive, and judicial centers of power. This unique proximity to business and technology leaders, federal departments and agencies, and a myriad of research entities, embassies, think tanks, cultural centers, and non-profit organizations is simply unparalleled. Synergistic opportunities for our faculty and students abound and are virtually limitless in the nation’s capital and surrounding areas. The University is committed to attracting and retaining outstanding and diverse faculty and staff that will enhance our stature of preeminence in our three missions of teaching, scholarship, and full engagement in our community, the state of Maryland, and in the world.

Background Checks
Offers of employment are contingent on completion of a background check. Information reported by the background check will not automatically disqualify you from employment.

Position Summary/Purpose of Position:
The Applied Research Laboratory for Intelligence & Security (ARLIS) – a University Affiliated Research Center (UARC) under the UMD Vice President of Research (VPR). seeks to hire a Natural Language Processing (NLP) and Data Science Engineer to support the Acquisition and Industrial Security (A&IS) Mission Area. We seek talented professionals who can work with a team to support the research, construction, implementation, test, documentation, and maintenance of socio-technical solutions that provide highly impactful capabilities for the special operations and intelligence community. Specifically, much of our work focuses on policy and implementation relating to manufacturing, data and knowledge engineering, model-based systems engineering, digital supply chains, and library science.
The Natural Language Processing and Data Science Engineer’s responsibilities include:
Designing complex information systems to support stakeholder needs and requirements related to the use of natural language-based information to impact the operational environment.
Implementing prototype solutions to support testing, evaluation, and demonstration.
Developing written reports and briefings for stakeholders and customers.

Benefits Summary
Top Benefits and Perks:
Faculty Benefits Summary

Minimum Qualifications:
Education:
Bachelor’s degree (or higher) in data science, computer science, statistics, or related fields

Knowledge, Skills, and Abilities:
Basic understanding of theory and detail of machine-learning (ML) methods and familiarity with ML libraries and frameworks (e.g., torch, pytorch, scikit, scipy).
Programming skills to implement ML solutions for a variety of different types of structured and unstructured data.
Strong communications, presentation, and writing skills.


Conditions of Employment:
Must be able to obtain a U.S. security clearance. If selected, you must meet the requirements for access to classified information and will be subject to a government security clearance investigation that includes criminal and credit history checks, as well as verification of U.S. citizenship, birth, education, employment, and military history.

Preferences:
Preferences:
Documented research experience specific to NLP, ML, deep learning, or artificial intelligence either as part of academic activities (e.g., dissertation) or professional experience.
2+ years of experience designing and writing production-level code for NLP applications.
Experience with agile workflow and continuous integration and delivery (CI/CD).
Experience with project and/or program management.
Active security clearance.

Additional Certifications:

Additional Information:

Posting Date:
05/16/2023

Closing Date:

Open Until Filled
Yes

Best Consideration Date
06/16/2023

Physical Demands
Sedentary work performed in an office environment; exerts up to 10 pounds of force occasionally and/or negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Ability to attend meetings and events both on and off campus. Spending long hours in front of a computer screen.

Diversity Statement:
The University of Maryland, College Park, an equal opportunity/affirmative action employer, complies with all applicable federal and state laws and regulations regarding nondiscrimination and affirmative action; all qualified applicants will receive consideration for employment. The University is committed to a policy of equal opportunity for all persons and does not discriminate on the basis of race, color, religion, sex, national origin, physical or mental disability, protected veteran status, age, gender identity or expression, sexual orientation, creed, marital status, political affiliation, personal appearance, or on the basis of rights secured by the First Amendment, in all aspects of employment, educational programs and activities, and admissions.","$86,984 /yr (est.)",10000+ Employees,College / University,Education,Colleges & Universities,1856,$1 to $5 billion (USD)
"Modus Closing
4.7",4.7,Colorado,Senior Data Infrastructure Engineer,"At Compass, our mission is to help everyone find their place in the world. Founded in 2012, we’re revolutionizing the real estate industry with our end-to-end platform that empowers residential real estate agents to deliver exceptional service to seller and buyer clients.
The Data Platform team at Compass is responsible for building and operating a unified, secure and scalable data platform, making high-quality data available for business intelligence, financial reporting, and data science use cases.
As a Senior Engineer of the Data Platform team, you will play a crucial role in building and operating the data infrastructure that serves the entire company. Your responsibilities will include delivering high-quality results to ensure the security, compliance, optimization, and automation of the data infrastructure. Additionally, you will take ownership and actively contribute to the architectural innovations while maintaining a high standard for quality.
To thrive in this role, effective collaboration with engineers and stakeholders across the company is essential. A strong sense of ownership for the product you work on is important to you. You have a genuine passion for learning and find joy in sharing your knowledge with others. You try to understand others before seeking to be understood. Every day you wake up excited about the new things you’ll learn and the people you can inspire.
Responsibilities:
Data architecture: Evaluate data platform architecture. Build and optimize data services to improve compliance, security, reliability, performance, and resource utilization.
Compliance: Build process and tools to ensure that the data platform is compliant with SOX (Sarbanes-Oxley Act), GLBA (Gramm-Leach-Bliley Act ), and CCPA (California Consumer Privacy Act).
Security: Identify infrastructure security-relevant actions, tests, and key performance indicators. Enhances the security posture of the Compass data platform, ensuring the protection of data, systems, and assets.
Infrastructure automation: Increases reliability, enhances employee productivity, reduces security attack surfaces, and eliminates human errors through standardization of process and Infrastructure as Code.
Data infrastructure monitoring. Monitor the platform health, reliability, cost, and usage.
Best practices and guardrails: Champion the best practices and guardrails for using the data platform. Identify cost-saving opportunities and optimize the data platform for all stakeholders.
Operational support: Support the platform users for troubleshooting, configuration, version updates, and feature adoptions.
Qualifications:
8 years of development experience with a focus on architecting cloud data platforms, setting up, managing and automating the infrastructure of cloud data platforms, including Airflow, Databricks, Spark, and Kafka
5 years of developer experience using Infrastructure as Code (IaC) technologies, such as AWS Cloud Formation and Terraform
3 years of experience with data compliance and governance. Demonstration of collaboration with the internal compliance team and external auditors in planning and execution of all phases of SOX compliance including risk assessment & scoping, documentation of process walkthroughs, identifying controls and key reports, testing, and reporting results. Implement customer data deletion requests that are required by CCPA. Standardize and automate the compliance process.
5 years of experience maintaining and improving OE of data platforms - service alerting, monitoring,and automation.
8 years of experience and proficient programming skills in Python or Java/C#. 3 years of programming experience in SQL.
B.S., M.S., or PhD. in Computer Science or equivalent
Desirable to Have:
Subject matter expert (SME) in architecting cloud data platforms using Databricks, Snowflake, AWS Lake Formation or other relevant technologies.
SME in big data technologies including Spark, Presto, Airflow, Kafka
Work in a startup-like environment building agile products and services
Create clear and concise documentation, including diagrams, service descriptions, decisions, and runbooks.
Deep knowledge of cloud platform such as AWS, GCP, Azure
Proven records of improving services in your domain throughout their lifecycle. Identify and remove bottlenecks to address inefficiencies in the developer experience.
Check out Compass’s
Engineering blog
!
Perks that You Need to Know About:
Participation in our incentive programs (which may include where eligible cash, equity, or commissions). Plus paid vacation, holidays, sick time, parental leave, marriage leave, and recharge leave; medical, tele-health, dental and vision benefits; 401(k) plan; flexible spending accounts (FSAs); commuter program; life and disability insurance; Maven (a support system for new parents); Carrot (fertility benefits); UrbanSitter (caregiver referral network); Employee Assistance Program; and pet insurance.

Do your best work, be your authentic self.
At Compass, we believe that everyone deserves to find their place in the world — a place where they feel like they belong, where they can be their authentic selves, where they can thrive. Our collaborative, energetic culture is grounded in our Compass Entrepreneurship Principles and our commitment to
diversity, equity, inclusion,
growth and mobility. As an equal opportunity employer, we offer competitive compensation packages, robust benefits and professional growth opportunities aimed at helping to improve our employees' lives and careers.",#N/A,1 to 50 Employees,Company - Private,Real Estate,Real Estate,2018,Unknown / Non-Applicable
"Amazon Web Services, Inc.
3.8",3.8,"Dallas, TX","Sr. Software Dev Engineer, SMGS Ops - DP&I - Data Platform","5+ years of non-internship professional software development experience
5+ years of programming with at least one software programming language experience
5+ years of leading design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience as a mentor, tech lead or leading an engineering team
Are you passionate about helping customers quickly make sense of massive amounts of data? Are you interested in building and operating a highly scalable data platform that is extremely simple to use? Do real-time streaming, data discoverability, data quality, data security, data governance, data profiling excite you?

We, the AWS Sales, Marketing, & Global Services (SMGS) Data Platform Team, are in the business of helping our customers securely, conveniently, and quickly manage and gain insights into the organization’s Sales and Marketing data at scale. We are looking for a Senior Software Development Engineer to join us in our exciting data journey.

You will work closely with partner, product, and security teams to understand requirements and business cases, and distill them into an engineering vision that will be a foundational capability of the platform. You will use this understanding and knowledge to guide and influence multiple teams of software and data engineers to build scalable mechanisms, tools, and products that empower our customers to manage and gain insights into their data. You will help establish technical standards and drive the overall technical architecture and engineering practices. You will think globally when designing and building the software, ensuring the software is evolving in the right long term direction while bringing value to customers iteratively.

The ideal candidate will be motivated, have strong attention to detail, and will model Amazon Leadership Principles. A familiarity with Amazon Web Service technologies including EC2, S3, SQS, Elastic Map Reduce, Hadoop, RDS as well as no-SQL solutions which form the foundation of these systems is an asset.

Key job responsibilities
High level responsibilities for this position include but are not limited to:
Own the overall platform architecture.
Work closely with the engineers to architect and develop the best technical design and approach.
Ensure that technical decisions are made with a balance between strategic and tactical perspectives.
Mentor engineering team members.
A day in the life
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

About the team
We, the AWS SMGS Data Platform Team, are in the business of helping our customers securely, conveniently, and quickly manage and gain insights into the organization’s Sales and Marketing data at scale. We place a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren’t focused on how many hours you spend at work or online. Instead, we’re happy to offer a flexible schedule so you can have a more productive and well-balanced life, both in and outside of work.

We are open to hiring candidates to work out of one of the following locations:

Dallas, TX, USA | Seattle, WA, USA

4+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Master's degree in computer science or equivalent
Experience building complex software systems that have been successfully delivered to customers
Strong practical understanding of Computer Science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $134,500/year in our lowest geographic market up to $261,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$134,500 /yr (est.)",Unknown,Subsidiary or Business Segment,Information Technology,Information Technology Support Services,2006,$10+ billion (USD)
"GENERAL LAND OFFICE
3.4",3.4,"Austin, TX",GLO - Senior Data Engineer (Data Analyst V),"GLO - Senior Data Engineer (Data Analyst V) (00036219)
Organization: GENERAL LAND OFFICE
Primary Location: Texas-Austin
Work Locations: Austin GLO Main FL7 1700 N Congress Ave Austin 78701

Job: Computer and Mathematical
Employee Status: Regular
Schedule: Full-time
Standard Hours Per Week: 40.00
Travel: Yes, 5 % of the Time
State Job Code: 0654
Salary Admin Plan: B
Grade: 26
Salary (Pay Basis): 8,750.00 - 9,750.00 (Monthly)
Number of Openings: 1
Overtime Status: Exempt
Job Posting: Sep 20, 2023, 4:03:21 PM
Closing Date: Oct 4, 2023, 11:59:00 PM
Description
The Texas General Land Office primarily serves the schoolchildren, veterans, and the environment of Texas. The agency does so by preserving our history, maximizing state revenue through innovative administration, and through the prudent stewardship of state lands and natural resources. This position is with our Information Technology Services area of the agency. To be successful the candidate must model the GLO's competencies of Integrity, Open Communications, Teamwork, Innovation and Proficiency. The successful candidate will be an integral part of the GLO's Information Technology Services team.
Performs highly complex (senior-level) data analysis and data research work or the Saas Development team in Information Technology Services. Work involves conducting detailed analysis of and extensive research on data, providing results, and monitoring and implementing data quality. May supervise the work of others. Works under limited supervision, with moderate latitude for the use of initiative and independent judgment

Military Crosswalk information can be accessed at:
https://hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_PlanningResearchandStatistics.pdf
In order to receive Veteran's preference, a copy of the DD #214 is required at the time of interview.

Benefits
Free Parking
Defined Retirement Benefit Plan
Optional 401(k) and 457 accounts
- Medical Insurance - State pays 100% of the health plan premium for eligible full-time employees and 50% of the
premium for their eligible dependents. State pays 50% of the eligible part-time employee’s premium and 25% for eligible dependents.
Optional Benefits such as dental, vision, and life insurance
Minimum of 96+ Hours of Annual Leave a year **Annual leave increases with length of service.

Essential Job Elements:

Performs coding tasks in various programming languages and related technologies in the business intelligence domain while adhering to GLO established architecture, software design, development, and coding standards.

Leads and contributes on business intelligence and development activities to ensure tasks and projects are completed within established time frames.

Leads and contributes to the design, implementation, and maintenance of systems used to collect and analyze business intelligence data.

Defines, develops, and implements data standards. Develops data quality measures, analyzes data quality results, and implements necessary changes to ensure data quality improvement

Leads and contributes to the development of reports, dashboards, databases, and other business intelligence assets that allow for efficient collection, processing, and presentation of data.

Compiles and queries data. Identifies data gaps, errors, anomalies, inconsistencies, and redundancies by analyzing the content, structure, and relationships within data. Identifies and interprets data patterns and trends and assesses data quality.

Manages, tracks and documents all work in the respective work management system based on the type of work being performed.

Produces and reviews technical specification documents, support documentation and diagrams as required by standard team practices.

Qualifications
Minimum Qualifications
10 years of professional experience working in information technology or similar industry. Full-time experience in data analysis, research, compilation, and/or reporting work.
Preferred Qualifications
Graduation from an accredited four-year college or university with major coursework in information systems, accounting, public administration, business, or closely related field.

8 years or more experience working in data analytics, big data, statistics, business intelligence or reporting strategies

Technical experience with data collection, data processing, data modeling, reporting and visualization development. Experience with data, reporting, analytics, and business intelligence strategies

Excellent time management and prioritization skills.
Experience with big data, data architecture and pipelining
Experience with data management, protection, policy, and classification
Experiencing with data modeling, transformation and integration technologies and patterns
Experience with R, Dax, Python, and other advanced data processing technologies
Experience in OLTP, OLAP, structured and unstructured data systems
Experience with distributed system patterns, data distribution and integration patterns
Advanced experience with big data, reporting, analytics and dashboarding technology like Tableau, Power Bi, SSRS, MongoDB, SQL Server, SQL Server Analytics,
Advanced experience with designing data organization, data warehousing, data modeling, and data lake architecture
Experience with the following technologies, tools, and platforms:
Microsoft Azure, Amazon Web Services, or other cloud computing services
Azure Data Lake or storage services
Microsoft SQL Server or relative RDBMS technology
Microsoft SQL Server Integration Services (SSIS), MuleSoft, or other integration tools and platforms.
Microsoft Power BI, Microsoft SQL Server Reporting Services (SSRS), Tableau, or other reporting tools and platforms.

Knowledge, Skills, and Abilities
Knowledge of statistics and analyzing data sets; of running queries, report writing, and presenting findings; of data models, database design development, data mining, and segmentation techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data; business administration principles and practices; project management and of research and budgeting process.
Skill in the use of a computer and applicable software, including advanced Microsoft Excel skills; in analyzing problems and devising effective solutions, in conducting data searches, in evaluating and translating large amounts of data, and in critical thinking; problem solving, critical thinking and attention to detail; report writing and budget development; grant preparation, development, evaluation, and monitoring.
Ability to compile, review, and analyze data; to prepare reports; to maintain accuracy and attention to detail; and to communicate effectively; interpret guidelines, policies, procedures, and regulations; evaluate fiscal data for reasonableness, necessity, and conformity with grant requirement; communicate effectively and to train others.
Skill analyzing operational issues and approach troubleshooting in a methodical and analytical manner to ensure appropriate resolution.
Skill in exercising sound judgment and effective decision making
Excellent organizational, problem-solving, and work management skills
Ability to communicate effectively both verbally and in writing to any level of the organization in a clear and concise manner
Ability to work under pressure and successfully manage multiple overlapping deadlines
Ability to lead technical requirement gathering sessions and building solutions from those requirements
Ability to receive and respond positively to constructive feedback
Physical Requirements
This position requires the employee to primarily perform sedentary office work; however, mobility (moving around the work-site) is routinely required to carry out some duties. This position requires extensive computer, telephone and client/ customer contact and communication. It requires the ability to move and position oneself as needed for filing and similar routine office duties. The job also requires normal cognitive abilities requiring the ability to learn, recall, and apply certain practices and policies. It requires the stamina to maintain attention to detail despite interruptions. Ability to read printed materials and computer screens. The individual must be able to move and transport records, documents, boxes, and all related information and materials, weighing up to 20 pounds when required.","$9,250 /mo (est.)",501 to 1000 Employees,Company - Private,Media & Communication,Advertising & Public Relations,1836,Unknown / Non-Applicable
"Publicis Sapient
3.7",3.7,"New York, NY",Manager Data Engineer-Databricks,"Manager Data Engineer-Databricks
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across truly value
Job Description
Publicis Sapient is looking for a Data Architect to join our team of bright thinkers and doers. You’ll use your problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients’ most complex and challenging problems across different industries. We are on a mission to transform the world, and you will be instrumental in shaping how we do it with your ideas, thoughts, and solutions.
Your Daily Duties and Impact:
Work closely with our clients providing evaluation and recommendations of design patterns and solutions for data platforms with a focus on ETL, ELT, ALT, lambda, and kappa architectures
Define SLAs, SLIs, and SLOs with inputs from clients, product owners, and engineers to deliver data-driven interactive experiences
Provide expertise, proof-of-concept, prototype, and reference implementations of architectural solutions for cloud, on-prem, hybrid, and edge-based data platforms
Provide technical inputs to agile processes, such as epic, story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements
Creation and maintenance of infrastructure-as-code for cloud, on-prem, and hybrid environments using tools such as Terraform, CloudFormation, Azure Resource Manager, Helm, and Google Cloud Deployment Manager
Mentor, support and manage team members
Qualifications
Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines
Hands-on experience in using Databricks
Hands-on experience with at least one of the leading public cloud data platforms (Amazon Web Services, Azure or Google Cloud)
Experience with column-oriented database technologies (e.g., Big Query, Redshift, Vertica), NoSQL database technologies (e.g., DynamoDB, BigTable, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)
Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Glue ETL, Lambda, Google Cloud DataFlow, Azure Data Factory, Spark, Spark Streaming, etc.
Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, DataHub, Alation, AWS Glue Catalog, Google Data Catalog.
Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks
Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes
Data processing programming using SQL, DBT, Python, and similar tools
Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala
Cloud-native data platform design with a focus on streaming and event-driven architectures
Participate in integrated validation and analysis sessions of components and subsystems on production servers
Data ingest, validation, and enrichment pipeline design and implementation
SDLC optimization across workstreams within a solution
Bachelor’s degree in Computer Science, Engineering, or related field

Set Yourself Apart With:
Certifications for any of the cloud services like AWS, GCP or Azure
Experience working with code repositories and continuous integration
Understanding of development and project methodologies
Additional Information
Pay Range:$108,000 -$210,000
Benefits of Working Here:
Flexible vacation policy; time is not limited, allocated, or accrued
16 paid holidays throughout the year
Generous parental leave and new parent transition program
Tuition reimbursement
Corporate gift matching program
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200.","$159,000 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1990,Unknown / Non-Applicable
"DataChat
4.5",4.5,"Madison, WI",Senior Software Engineer - Data Services,"We are currently seeking a proactive and highly skilled Senior Engineer to join our dynamic team. In this role, you will assume responsibility for various aspects of our data platform, with a primary focus on the technology stack that interfaces with our backend database systems.

Responsibilities:
Expand the product with scalable and robust data processing methods.
Build mechanisms for parallel data/task processing.
Maintain and enhance existing code and infrastructure.
Develop mechanisms for serverless execution.
Improve our deployment and CI/CD process.

Requirements:
At least a B.S. in Computer Science with a 3.5 or higher GPA. M.S. in Computer Science preferred.
3+ years experience in database systems, including experience with SQL, materialized views, and correlated queries.
Strong Python skills.
Good grasp of broader systems-related skills, including distributed systems and micro-services.
Experience with cloud technologies, e.g. AWS, Azure, GCP, Docker, or Kubernetes.
Strong demonstration of commitment to Software Development Principles, and test-driven software development.
Prior experience with working in an Agile development environment.","$97,623 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,2017,Less than $1 million (USD)
"Waters Corporation
3.8",3.8,"Milford, MA",Senior Data Engineer,"The Strategy & Operational Excellence team is on a mission to improve both our customer and employee experience by transforming how we plan, buy, make, and distribute products in Waters Global Operations. Our four pillars of focus include Strategy, Processes and Systems, Continuous Improvement, and Insights. As a Senior Data Engineer, you will be working on a multi-disciplinary team within Global Operations focused on driving process improvements, developing technology and analytical solutions, and enabling data driven decisions at all leadership levels. This will require you to collaborate with colleagues from both operations and IT backgrounds to identify and prioritize opportunities, make the changes, provide training, and monitor adherence and adoption.
This role will report to a Director, GO Transformation Lead. Location: Milford, MA
Responsibilities:
Work collaboratively within a multi-disciplinary team and with functional leaders across multiple domains to develop a good understanding of current processes and systems used
Develop apps and reports that enable data-driven decision making and actions to be taken
Build data processing pipelines that enable data extraction and transformation from a variety of source systems (with SAP tables being a key data source)
Monitor, maintain, and optimize data processes focusing on data reliability and quality
Derive insights through data, provide context for findings, highlight confounding variables, and provide awareness into exceptions.
Engineer dataflows for broad analytics use
Keep abreast of developments in data engineering, act as a thought leader by engaging colleagues in active dialogue regarding industry trends and recommendations, and implement best practices
Qualifications:
BS/BSc in Computer Science, Software Engineering, or related field, Masters preferred
3+ years’ experience in a software development or data engineering role
Experience writing code in at least one OOP language (preferred language is Python)
Experience working with large and small data sets from multiple sources and formats
Working knowledge of machine learning methods in regression and classification
Experience developing complex visualizations within Power BI or similar environment
Understanding of relational and non-relational databases
Ability to derive insights using variable and categorical datasets
Able to translate technical concepts for non-technical audiences in both written and oral forms
Results oriented mindset, operate with high sense of urgency
Experience with the following environments a plus: SAP DP/SNP/MM/PPDS/GATP, Ariba, Celonis, Azure, Kinaxis, Siemens OpsCenter
Experience working within a Scrum team a plus
Proven track record of solving problems, breaking down barriers and delivering results
Job Type: Full-time
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Health savings account
Paid time off
Parental leave
Professional development assistance
Retirement plan
Tuition reimbursement
Vision insurance
Compensation package:
Performance bonus
Stock options
Yearly pay
Experience level:
3 years
4 years
5 years
6 years
Schedule:
8 hour shift
Monday to Friday
No weekends
Ability to commute/relocate:
Milford, MA 01757: Reliably commute or planning to relocate before starting work (Required)
Experience:
Celonis: 3 years (Required)
SAP: 3 years (Required)
Kinaxis: 3 years (Required)
Work Location: In person","$104,977 /yr (est.)",5001 to 10000 Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1958,$1 to $5 billion (USD)
VXForward,#N/A,Remote,Cloud Data Engineer,"VXForward has a great opportunity for a Cloud Data Engineer - 100% Remote with one of our clients.

Roles and Responsibilities
Design and develop Azure solutions
Implement automated unit and integration testing
Collaborate with architecture and lead engineers to ensure consistent development practices
Participate in retrospective reviews
Participate in the estimation process for new work and releases
Collaborate with other engineers to solve and bring new perspectives to complex problems
Drive improvements in data engineering practices, procedures, and ways of working
Embrace new technologies and an ever-changing environment
Requirements
5+ years proven ability of professional Data Development experience
3+ years of proven ability to develop with Azure or HDFS and SQL
2+ years of experience in Azure Data Factory and/or Azure Databricks
Experience in working with large-scale data sets and distributed systems
Full understanding of ETL concepts and Data Warehousing concepts
Exposure to version control software (Git, GitHub SaaS)
Strong understanding of Agile Principles (Scrum)
Must Have Skills:
5+ years proven ability of professional Data Development experience
3+ years of proven ability to develop with Azure or HDFS and SQL
2+ years of experience in Azure Data Factory and/or Azure Databricks

This is a remote position.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
RX USA LLC,#N/A,"Souderton, PA",MES Data Engineer,"TITLE: MES Data Engineer
TYPE: Direct Hire
LOCATION: Souderton, PA
ONSITE/REMOTE/HYBRID: Onsite
START DATE: October 2023
SHIFT: Day Shift
VACCINATION REQUIREMENT: None
We are looking for a MES Data Engineer to join our team.
MAIN RESPONSIBILITIES
Ability to read data correctly and then use that data to integrate the information properly across multiple platforms in a manufacturing environment.
Lead the design, implementation, and maintenance of software systems with upper-level manufacturing and business data systems and lower-level control systems used for manufacturing.
Maintain systems so the data is reliable for decision-making for production, engineering, and other support roles with real-time and historical data analytics.
Communicate to the proper personnel project status and issues to ensure the achievement of project milestones.
Advocate self-development and prepare high-level troubleshooting capabilities and strategic support for manufacturing and supply chain teams.
Keeps immediate supervisor well-informed of activities and recommends corrective actions.
QUALIFICATIONS
Bachelor's degree in IT or Electrical Engineering. from an accredited institution.
10 plus years of experience in Systems Engineering or similar experience.
Manufacturing Plant Data Analysis is needed.
Want to develop SMART Manufacturing, Data Automation, and approaches to contribute to the digital transformation.
Efficient database skills.
Experience with MES (Manufacturing Execution System) integration and knowledge of PLCs, SCADA environments, Ethernet network communication, and Windows operating systems.
Working experience in IT systems integration; manufacturing IT systems' web and mobile application development.
Knowledge of deployment aspects of upper-level manufacturing and business data systems (Oracle EBS, legacy, and other enterprise systems).
Experience with the Rockwell or Siemens automation and data acquisition platforms.
Excellent verbal and written communication skills and the ability to influence and demonstrate confidence in project stakeholders.
Ability to understand and translate business requirements into data and technical requirements.
Team player who can successfully meet project milestones in a matrix environment.
A readiness and eagerness to learn other technologies as needed.
EOE STATEMENT
We are an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law.
Job Type: Full-time
Experience level:
10 years
Schedule:
Day shift
Work Location: In person",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Zions Bancorporation
3.6",3.6,"Midvale, UT",Software Engineer - Data Governance,"Zions Bancorporation’s Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. With a commitment to technology and innovation, we have been providing our community, clients and colleagues the best experience possible for over 150 years. Help us transform our workforce of the future, today.

We have an amazing opportunity available for a Software Engineer within the Data Governance Innovation & Engineering team. We are currently looking for a passionate and experienced Software Engineer that will play a key role in establishing foundation for self-service governance capabilities (e.g Data Catalog, Adaptive Governance).

The ideal candidate will have:
Full Stack engineering experience with knowledge Data engineering and architecture.
Experience with JAVA or Python programming, developing microservice architecture and Rest API’s.
Knowledge of CI\CD and containerized deployment on Kubernetes.
Understanding data governance technologies would be the icing on the cake!

The Software Engineer will:
Design, build and integrate internal and external APIs. Develop
Collaborate with Product Management and business partners to iteratively build solutions that meet customers’ needs.
Adhere to internal development best practices/lifecycle (e.g., Testing, Code Reviews, CI/CD, Documentation).
Gather business requirements and propose robust and scalable solutions.
Document and showcase feature designs/workflows.
Be a team player, stay up to date on industry latest industry trends and design patterns and loves to innovate.

Qualifications:
Bachelor’s degree in computer science, Computer Engineering or related field.
4+ years of Full stack engineering experience building API’s & Microservices, utilizing JAVA, Spring Boot (and/or) Python. A combination of education and experience may meet qualifications.
Knowledge of UI/UX design and development, knowledge of frameworks and libraries using Angular and REACT.JS.
Experience building applications on Docker and Kubernetes
Understand Data architecture and with knowledge of SQL, NO SQL databases and Big Data ecosystem.
Experience building CI/CD pipelines (e.g. Azure Pipelines, Jenkins)

Nice to have:
Cloud experience (e.g. Google, Azure)
Conceptual understanding of data governance capabilities (e.g. data catalog, classification, profiling, data sharing)

Location:
This position has a hybrid work from home schedule with a minimum of three days per week in the office at the new Zions Technology Center in Midvale, UT.

The Zions Technology Center is a 400,000-square-foot technology campus in Midvale, Utah. Located on the former Sharon Steel Mill superfund site, the sustainably built campus will be the company’s primary technology and operations center. This modern and environmentally friendly technology center will enable Zions to continue to compete for the best technology talent in the state while providing team members with an exceptional work environment with features such as:

Electric vehicle charging stations and close proximity to Historic Gardner Village UTA TRAX station.
At least 75% of the building is powered by on-site renewable solar energy.
Access to outdoor recreation, parks, trails, shareable bikes and locker rooms.
Large modern cafe with a healthy and diverse menu.
Healthy indoor environment with ample natural light and fresh air.
LEED-certified sustainable building that features include the use of low VOC-emitting construction materials.

Benefits:
Medical, Dental and Vision Insurance - START DAY ONE!
Life and Disability Insurance, Paid Parental Leave and Adoption Assistance
Health Savings (HSA), Flexible Spending (FSA) and dependent care accounts
Paid Training, Paid Time Off (PTO) and 11 Paid Federal Holidays
401(k) plan with company match, Profit Sharing, competitive compensation in line with work experience
Mental health benefits including coaching and therapy sessions
Tuition Reimbursement for qualifying employees
Employee Ambassador preferred banking products

Apply now if you have a passion for impactful outcomes, enjoy working collaboratively with co-workers, and want to make a difference for the clients and communities we serve.","$102,732 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1955,$1 to $5 billion (USD)
"Real Time Consulting, LLC
4.5",4.5,"Phoenix, AZ",Systems Engineer - Aircraft Data Network,"REAL TIME CONSULTING (An RTCo Company)—POSITION DESCRIPTION
JOB TITLE: Systems Engineer – Aircraft Data Network

ABOUT THE JOB:
Be part of a team that designs, develops, and integrates the Next Generation Avionics Platform. The successful candidate will be responsible for validating the Aircraft Data Network (ADN) solution and completing the network design, integration, and verification activities including robustness testing.

REQUIRED SKILLS:
Bachelor Science degree in Electrical/Computer Engineering or Computer Science
System development lifecycle knowledge
Ethernet networks experience
Integrated Modular Avionics (IMA) experience
System verification and lab testing experience
Agile development processes experience
Lab equipment experience (oscilloscopes, signal generators, power supplies, and network data analysis test software)
Experience coordinating with cross-functional design teams including Systems, Software, Hardware, and Test
Strong technical writing skills
Effective communicator
Strong analytical skills
Diverse and global teaming and collaboration
Self-motivated and able to work with little supervision, consistently take the initiative to get things done, do things before being asked by others or forced to by events

PREFERRED SKILLS:
Familiarity with system development lifecycle in accordance with ARP-4754A
Experience with ARINC 664 and SAE AS6802 (Time-Triggered Ethernet) protocols
Experience with system test automation strategies
Experience with IBM Rational DOORS Next Generation requirements management tool
Experience with IBM Rational Quality Manager for test planning, test construction, and test artifact management

ABOUT THE COMPANY:
Real Time Consulting (RTC) exists to partner outstanding engineering talent to support our clients’ success. Unsurpassed service is delivered to our clients by upholding responsibility, teamwork and quality. Our primary commitment is to help our clients. Since 1997, RTC has been protecting and enhancing lives with safe, reliable, innovative solutions, providing full life-cycle design, development and testing of EMBEDDED ENGINEERING SYSTEMS and SOFTWARE SOLUTIONS with Program Management and Consulting Services. Our employees average 20+ years of versatile and accomplished expertise to our clients, driving continuous innovation forward. Employee’s innovative and analytical ideas are cultivated while maintaining the big picture vision in a fast-paced, changing environment. Our corporate values are to Uphold Responsibility, Support People, Promote Teamwork and Deliver Quality!

This position may require exposure to software, source code or technology that is subject to US export control laws and regulations (i.e., International Traffic in Arms Regulations or the Export Administration Regulations). To comply with these requirements, you must be a U.S. citizen, lawful permanent resident of the U.S., protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Departments of State or Commerce, as applicable.

RTCo is an Equal Opportunity Employer; employment with RTCo is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.

To qualify for all positions with Real Time Companies, applicants must be legally authorized to work in the United States and should not require now, or in the future, sponsorship for employment visa status. Please be aware that Real Time Companies does not sponsor employment-based visas. Additionally, certain positions with Real Time Companies that involve work with government entities may have more restrictive employment status requirements, such as U.S. citizenship, based on security clearance requirements or other governmental requirements. Real Time Companies is an Equal Opportunity Employer M/F/D/V.","$101,592 /yr (est.)",1 to 50 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1997,$5 to $25 million (USD)
"Publicis Sapient
3.7",3.7,"New York, NY",Senior/Lead GCP Data Engineer,"Senior/Lead GCP Data Engineer
Full-time
Company Description
Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across truly value
Job Description
Senior/Lead Data Engineering Google Cloud Platform (GCP) is responsible to develop and deliver effective cloud solutions for clients. This position requires in-depth knowledge and expertise in GCP services, architecture, and best practices. They will collaborate with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions. He will also be responsible for driving innovation and staying up-to-date with the latest GCP technologies and trends to provide industry-leading solutions.
Your Impact:
Collaborate with clients to understand their business requirements and design GCP architecture to meet their needs.
Develop and implement cloud strategies, best practices, and standards to ensure efficient and effective cloud utilization.
Work with cross-functional teams to design, implement, and manage scalable and reliable cloud solutions on GCP.
Provide technical guidance and mentorship to the team to develop their skills and expertise in GCP.
Stay up-to-date with the latest GCP technologies, trends, and best practices and assess their applicability to client solutions.
Qualifications
Must have good implementation experience on various GCP’s Data Storage and Processing services such as BigQuery, Dataflow, Bigtable, Dataform, Data fusion, cloud spanner, Cloud SQL
Must have programmatic experience with tools like Javascript, Python, Apache Spark.
What sets you apart:
Experience in complex migrations from legacy data warehousing solutions or on-prem datalakes to GCP
Experience in building real-time ingestion and processing frameworks on GCP.
Adaptability to learn new technologies and products as the job demands.
Multi-cloud & hybrid cloud experience
Any cloud certification
Additional Information
Gender-Neutral Policy
Access to Medical Plan
Employee engagement activities and events
Remote work
Additional Information
Base Salary Range for the Role: 110000- 140000 (varies depending on experience)
The range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. Actual range for this position may differ, depending on location and specific skillset required for the work itself.
Learn more about us at www.publicissapient.com or explore other career opportunities careers.publicissapient.com.
As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at h[email protected] or you may call us at +1-617-621-0200.","$125,000 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1990,Unknown / Non-Applicable
"Resolution Life
3.2",3.2,"Sydney, FL",Data Engineer,"At Resolution Life, we’re proud to have evolved into a global business under the Resolution Life name. For customers, advisers, companies and the industry. We’re making an impact worldwide
Resolution Life Group is a global life insurance group focusing on the acquisition and management of in-force life insurance policies. With assets of $31 billion and 1.5 million customers, Resolution Life are providing existing customers with life insurance, super and investments.

Why us?
Our platform vision is to be the leading in-force specialist life-insurer in Australasia by 2024, by being customer-obsessed and data-driven.
We are one of the first life insurers globally to operate in an entirely Enterprise Agile environment. The strategic priorities of the platform are focused on ensuring the business is future-fit and sustainable, and to grow through bolt-on acquisition of in-force portfolios. We are guided by core behaviours that inform the way Resolution Life team members show up each day and interact with others.
The Opportunity
The individual will play a hands-on role and work closely with business and technology stakeholders to deliver an enterprise-wide data solution in our data platform to grow and retain data domain expertise to support our data driven vision and reduce our ongoing operating costs and technical debit.
Your Story
Align Architecture, Solution Design with business requirements.
Design, Build and Maintain Physical data model in data platform layers
Map business glossary, data definition and data sets to physical data model
Build ETL that collects, manage, and convert raw data into consumable tables applying technical logic based on business rules
Responsible to defining and building job orchestration
Build of database objects by applying application best practices
Build of reusable components and frameworks based on application best practices
Build a robust codebase to improve data reliability, efficiency, latency, and quality
Build code and maintain version control by following Software development lifecycle
Responsible for unit testing and system testing and system integration testing
Build a test-driven development approach to identify data anomalies and data quality issues
Support SIT, UAT and Performance Testing
Support Code deployment and Code stabilisation in UAT, Pre-Prod and Prod environments
Present details technical design at DnA design forum and obtain approval.
Strong Data Modelling skills required.
Have key technical skills across data platforms technologies including ETL, Snowflake , SQL Server, Informatica Cloud, advanced SQL, as well as nice to haves such as Power BI and Azure / AWS Cloud
Critical Skills
At Resolution Life, we have identified the following critical skills which are key to success in our culture:
Customer Focused: Passionate drive to delight our customers and offer unique solutions that deliver on their expectations.
Critical Thinking: Thoughtful process of analysing data and problem-solving data to reach a well-reasoned solution.
Team Mentality: Partnering effectively to drive our culture and execute on our common goals.
Business Acumen: Appreciation and understanding of the financial services industry in order to make sound business decisions.
Learning Agility: Openness to new ways of thinking and acquiring new skills to retain a competitive advantage.
What Will We Do For You:
Our culture underpins our values and guides our decision making. It's also what makes Resolution Life a great place to work.
Resolution Life Australasia supports virtual working, and our enduring primary place of work continues to be “virtual” with the physical office and home office used interchangeably. We recognise that our workers can contribute and connect equally regardless of where they are located, and we have seen and experienced the wellbeing and benefits that come from working at home. This means some of us work at home most of the time, in the office most of the time or a balanced mix.
Every day is an opportunity to grow – and we hope to offer our people a career, not just a job.
The learning and development opportunities we offer include supporting the completion of executive-level short courses, access to leading online learning tools, on the job training, and mentoring by highly experienced business leaders.
Join us
Before commencing employment in this role you will need to provide two references, full working rights and complete police and credit checks through an online provider.
As an equal opportunity employer strongly committed to working in a diverse and inclusive workforce you will be provided with any support or accessibility requirements throughout your interview process. Please feel free to contact our Talent Team directly at talent@resolutionlife.com.au.
Privacy Policy
Please refer to our
Privacy Policy
to learn about how we use the information you give us, alternatively you can view the same information by navigating to the page
https://www.resolutionlife.com.au/privacy
.","$91,413 /yr (est.)",201 to 500 Employees,Company - Private,Insurance,Insurance Carriers,2003,Unknown / Non-Applicable
"Arivo Acceptance LLC
3.2",3.2,"Salt Lake City, UT",(Utah Residents Only) Senior Data Engineer,"Senior Data Engineer
M-F/Full Time/On Site
Salary: 150-170k/year
Arivo is a tech-driven lending framework with a focus on disrupting and recreating the auto lending experience for dealerships and customers alike. Arivo is a rapidly growing start up company, focused on excellence, transparency, and innovation.
At Arivo, we believe in rewarding hard work, with benefits like
Competitive compensation package and 401k.
Paid Holidays
160 Hours Accrued PTO
Medical, dental, vision, disability insurance, AD&D and Life Insurance
Flex Spending, EAP, Wellness Plans, and Maternity Leave Stipend
Company Match Year-End Savings Program
A company culture that places a premium on the employee experience including ongoing training, development and advancement opportunities.
WHAT YOU'LL DO AS A SENIOR DATA ENGINEER:
Architect and build onto our in-house SaaS loan origination and servicing platform
Develop and manage custom integrations with 3rd party APIs and handle ETLs to move and transform data
Orchestrate end-to-end data pipelines that are fault-tolerant, observable, and scalable, using advanced serverless technologies
Collaborate closely with our executive team, product engineers, and data scientists to make key business data reliable and highly available
WHAT WE’RE LOOKING FOR:
Minimum of 5 years of experience as a Data Engineer or Analytics Engineer, deploying high-quality production code at scale
Excellent SQL skills with dbt experience
Experience working with modern data warehouses i.e., Snowflake (Snowpipe, Dynamic Tables, External Functions, Snowpark)
Hands-on experience with AWS (IaC, Glue, DMS, Kinesis, MSK, Lambda, SQS)
Proven knowledge of APIs & Webhooks, OAuth/Tokens, and handling rate limits
Extensive experience with DevOps practices, including deployment using tools like git, AWS TypeScript CDK, Cloud Formation, GitLab pipelines
Proficient in Python and Node.js programming
A strong focus on code quality. You write code that is readable, extensible, and testable
Experience with various testing methodologies including unit testing and integration testing
Proven ability in conducting code reviews, both submitting your own code for review and reviewing others' work preferred
Experience in the Modern Data Stack including tools such as Fivetran, dbt, Airflow, Docker, etc. preferred
Previous back-end application development preferred
Experience working with streaming data, message queues, and Spark is a big plus
WHY YOU’LL LOVE WORKING HERE:
Arivo is just getting started, but as part of its early success and its commitment to its employees, Arivo has invested in a cutting-edge workplace, with standard-issue sit/stand motorized desks with programmable settings and stand reminders, multiple collaboration areas, and a full service Café. With a blazing WiFi system that enables work from the café, dedicated collaboration spaces, and comfortable breakout rooms, Arivo appreciates the importance of empowering its employees with an amazing workspace.
In addition to our top-of-the-line facilities, Arivo cherishes top-down communication, meaning you won’t ever be left in the dark about what is going on in the company. Open communication between all employees and executives proves that we are here to support each other and work
Please see our website: arivo.com/careers to learn more about Arivo and be enlightened by our employee experiences shown there
NOTE:
This is not necessarily an exhaustive list of responsibilities, skills, duties, requirements, efforts or working conditions associated with this job. While this list is intended to be an accurate reflection of the current job, the Company reserves the right to revise the functions and duties of the job and to require that additional or different tasks be performed as circumstances dictate.
Company Description
Arivo is a rapidly growing auto finance company who wanted to make getting an auto loan effortless for everyone involved. We built an organization that is constantly looking for ways to make the lending process simpler and improve service to customers, applicants, and dealers. Today, Arivo helps car buyers find and finance cars that match their needs and budgets - without the usual stress and uncertainty. With Arivo, customers can begin the process by filling out a simple online application or walking into a participating dealership. Either way, we work to understand each of our customers' needs and approve a loan tailored specifically to them. Then, we work with our extensive network of auto dealers to match customers with reliable, affordable cars that meet their needs. This unique approach makes it easy for Arivo customers to find and buy the right car with confidence. Every Arivo loan is designed to be simple, transparent, and fair - with terms that are easy to understand without hidden fees or conditions.
Arivo Acceptance, LLC
Arivo is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce.
Job Type: Full-time
Pay: $150,000.00 - $170,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Employee assistance program
Flexible spending account
Health insurance
Health savings account
Life insurance
Paid time off
Parental leave
Referral program
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Salt Lake City, UT 84118: Reliably commute or planning to relocate before starting work (Required)
Work Location: In person","$160,000 /yr (est.)",51 to 200 Employees,Company - Private,Financial Services,Banking & Lending,#N/A,$5 to $25 million (USD)
"G Associates LLC
4.0",4.0,Remote,Sr. Data Engineer,"Title: Sr Data Engineer
Location: Remote
Length: Contract-To-Hire
WHAT YOU'LL NEED:
Bachelor’s degree in computer science, Management information systems (MIS) or related degree / experience commensurate to a degree preferred
5+ years of hands-on experience implementing, maintaining, and supporting data management solutions including program/project delivery
7+ years of experience with SQL & T-SQL code development - experience with Snowflake preferred
5+ years of experience with Python – A MUST HAVE!
4+ years of experience with Databricks
4+ years of experience designing, building and deploying solutions with Azure Data Factory – A MUST HAVE !
4+ years of experience with logical modeling for visualization tools (Tableau, Power BI, Sigma)
4+ years of Experience with Data lake technologies including ADLS Gen. 2, AWS S3, AWS Glue preferred
Need to differentiate between a Senior Data Engineer versus a Data Analyst (e.g., BI) … don’t want an Analyst
Needs to be heavy Python (libraries include Pandas) and have worked with very large data sets; Understands OOP (Object-Oriented Programming language).
Candidates need to own the entire process creation (business requirements through production). Also need to be comfortable wearing multiple hats (ie., jumping off the Innnovation team to help with something on the Run team (production/maintenance).
Must be able and comfortable with mentoring other Data Engineers
Senior enough to know how to deal with ambiguity … they are creating a totally new data warehousing environment, moving to Azure Data Lake. Be able to jump in and build pipelines …
Job Type: Full-time
Pay: $83,602.86 - $140,684.14 per year
Experience level:
10 years
Schedule:
8 hour shift
Experience:
Python: 8 years (Required)
SQL: 10 years (Required)
Databricks: 7 years (Required)
Azure Data Lake: 7 years (Required)
Azure: 7 years (Required)
Pandas: 6 years (Required)
Data warehouse: 7 years (Required)
Work Location: Remote","$112,144 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,2003,$25 to $100 million (USD)
"GENERAL LAND OFFICE
3.4",3.4,"Austin, TX",GLO - Senior Data Engineer (Programmer V),"GLO - Senior Data Engineer (Programmer V) (00036216)
Organization: GENERAL LAND OFFICE
Primary Location: Texas-Austin
Work Locations: Austin GLO Main FL9 1700 N Congress Ave Austin 78701

Job: Business and Financial Operations
Employee Status: Regular
Schedule: Full-time
Standard Hours Per Week: 40.00
Travel: Yes, 5 % of the Time
State Job Code: 0245
Salary Admin Plan: B
Grade: 28
Salary (Pay Basis): 8,750.00 - 9,750.00 (Monthly)
Number of Openings: 2
Overtime Status: Exempt
Job Posting: Sep 20, 2023, 3:56:19 PM
Closing Date: Oct 4, 2023, 11:59:00 PM
Description
The Texas General Land Office primarily serves the schoolchildren, veterans, and the environment of Texas. The agency does so by preserving our history, maximizing state revenue through innovative administration, and through the prudent stewardship of state lands and natural resources. This position is with our Information Technology Services area of the agency. To be successful the candidate must model the GLO's competencies of Integrity, Open Communications, Teamwork, Innovation and Proficiency. The successful candidate will be an integral part of the GLO's Information Technology Services team.

Performs highly advanced (senior-level) computer programming work for the SaaS Development team in Information Technology Services. Work involves overseeing programming projects; analyzing proposed applications; and designing software solutions. May supervise the work of others. Works under minimal supervision, with considerable latitude for the use of initiative and independent judgment.

Military Crosswalk information can be accessed at:


http://www.hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_InformationTechnology.pdf
In order to receive Veterans' preference, a copy of Form DD#214 is required at time of interview.

Benefits
Free Parking
Defined Retirement Benefit Plan
Optional 401(k) and 457 accounts
Medical Insurance - State pays 100% of the health plan premium for eligible full-time employees and 50% of the premium for their eligible dependents. State pays 50% of the eligible part-time employee’s premium and 25% for eligible dependents.
Optional Benefits such as dental, vision, and life insurance
Minimum of 96+ Hours of Annual Leave a year **Annual leave increases with length of service

Essential Job Elements:

Performs highly advanced (senior-level) coding tasks in various programming languages and related technologies while adhering to GLO established architecture, software design, development, and coding standards.

Oversees and/or performs work on programming projects including those that are highly complex in nature and/or large in scale. Contributes on and/or leads development activities to ensure tasks and projects are completed within established time frames.

Oversees and/or evaluates business requests and leads the design of solutions aligned with project goals and objectives which leverage commercial products, and software-as-a-service offerings first over custom development as needed.

Oversees and/or performs software application testing activities such as: unit, integration, and performance testing.

Oversees and/or performs research and analysis required for project proposals, software and systems modifications, and collaborates with peers and leadership regarding the technologies, products, services, and strategies needed to successfully align technology with agency business needs.

Oversees and/or evaluates proposals and work products of third-party vendors to determine the quality, accuracy, and completeness.

Manages, tracks and documents all work in the respective work management system based on the type of work being performed.

Produces and reviews technical specification documents, support documentation and diagrams as required by standard team practices.

Qualifications
Minimum Qualifications:
10 years of professional experience working in information technology or similar industry.
Full-time experience in software development, data integration, reporting, or business intelligence.

Preferred Qualifications:
Graduation from an accredited four-year college or university with major coursework in information systems, accounting, public administration, business, or closely related field.

8 years or more experience working as a software developer or data integration developer.

Experience working with or leading teams that follow an Agile delivery methodology
Experience working with MuleSoft Anypoint Platform, SSIS, Azure Dev Ops, Git, Bitbucket, Visual Studio, Eclipse, REST API services and/or other similar tools and technologies to design, develop, test, troubleshoot, and support enterprise-class web applications.
Experience coding in Java, Python, Microsoft SQL Server, SQL Server Integration Services, and SQL Server Reporting Services.
Experience in designing, developing, and implementing ETL processes
Experience in working with data engineering teams
Experience developing in the Salesforce platform including Apex, Lightning Components, Visualforce, Workflows, Triggers.
Experience using AWS SDK to develop secure and scalable cloud applications.

One or more of the following certifications:

MuleSoft Certified Developer - Level 1
MuleSoft Certified Developer - Level 2
MuleSoft Certified Integration Architect - Level 1
Salesforce Platform App Builder Certification
Salesforce Platform Developer I Certification

Knowledge, Skills, and Abilities (KSAs):
Knowledge of the principles, practices, and techniques of software development and the full software development life cycle (SDLC)
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including agile methodologies, coding standards, code reviews, source control management, build processes, and testing.
Knowledge of database development, relational database design, and database protocols.
Knowledge of computer Science fundamentals in object-oriented design, data structures, algorithms design, and problem solving.
Knowledge of application CI/CD pipelines: infrastructure as code, integration testing, automated deployment, and rollback.

Skill analyzing software applications, defects, and business problems to draw evidence-based conclusions and devise innovative solutions.
Skill in exercising sound judgment and effective decision making
Skill in writing complex SQL queries in designing tables, stored procedures, views and functions for development, analysis, and performance tuning.

Ability to communicate effectively both verbally and in writing to any level of the organization in a clear and concise manner.
Ability to create and validate test classes and move code and other components into Production environment.
Ability to work under pressure and successfully manage multiple overlapping deadlines.
Ability to lead technical requirement gathering sessions and building solutions from those requirements.
Ability to receive and respond positively to constructive feedback.
Physical Requirements
This position requires the employee to primarily perform sedentary office work; however, mobility (moving around the work-site) is routinely required to carry out some duties. This position requires extensive computer, telephone and client/ customer contact and communication. It requires the ability to move and position oneself as needed for filing and similar routine office duties. The job also requires normal cognitive abilities requiring the ability to learn, recall, and apply certain practices and policies. It requires the stamina to maintain attention to detail despite interruptions. Ability to read printed materials and computer screens. The individual must be able to move and transport records, documents, boxes, and all related information and materials, weighing up to 20 pounds when required.","$9,250 /mo (est.)",501 to 1000 Employees,Company - Private,Media & Communication,Advertising & Public Relations,1836,Unknown / Non-Applicable
"Abarca Health
3.2",3.2,"San Juan, PR",Data Engineer,"What you'll do
In a few words…
Abarca is igniting a revolution in healthcare. We built our company on the belief that with smarter technology we are redefining pharmacy benefits, but this is just the beginning…
Our Data Engineering team handles all incoming and outgoing data as well as our data warehouse with scrutiny and security in mind. Within this team, we work on everything data related from analyzing data warehousing requirements, designing pipelines, and developing, testing, and deploying EDI solutions.
As Data Engineer you'll design and implement enterprise-level data solutions that serve a dynamic community of internal and external clients. You will work with product owners, software engineers, quality assurance teams and technology leaders to provide design guidelines that offer technical solutions and support complex decision making. You will be part of our EDI and Data Warehouse transformation designing and developing new solutions using cloud native technologies.
The fundamentals for the job..
Provide technical coaching, guidance and support in the development and deployment of complex backend processes and APIs.
Collaborate with Software Engineers and end users to understand business and client needs; then, create optimal software / technology solutions to address those needs.
Define product requirements for creating high-level architectural specifications, ensuring feasibility, functionality, and integration with existing systems and services.
Lead the way within classifying and documenting development of best practices, processes, and methodologies.
Develop scalable and maintainable designs supports loosely-coupled enterprise components and fosters reuse of software.
Make high-level design choices and instruct on technical standards, including software coding, tools, and platforms.
Develop and define frameworks for new applications.
Lead data engineers from existing to future software architectures.
Cultivate and disseminate knowledge of application development best practices, as well as take an active role in cross‐departmental projects when needed.
What we expect of you
The bold requirements…
Bachelor's or Master's Degree in Computer Engineering, Computer Science, or related field. (In lieu of a degree, equivalent relevant experience may be considered.)
3+ years of work experience as a Programmer, Technical or Systems Analyst, or in roles emphasizing Programming, Relational Database Programming or Relational Database Administration.
Experience working with Microsoft's .NET Framework, Java, Angular, Object-Oriented languages, and Design Patterns.
Experience with any major database (MS SQL Server, Oracle, MySQL, Postgres, etc.), Database Design, Database Optimization.
Excellent oral and written communication skills.
We are proud to offer a flexible hybrid work model which will require certain on-site workdays (Puerto Rico Location Only
Nice to have…
Microsoft Certified Application or Professional Developer.
Experience with X12, NCPDP, and/or EDI standards.
Physical requirements…
Must be able to access and navigate each department at the organization's facilities.
Sedentary work that primarily involves sitting/standing.
At Abarca we value and celebrate diversity. Diversity, equity, inclusion, and belonging are guiding principles of Abarca and ensure Abarca's workforce reflects the communities it serves. We are proud to provide equal employment opportunities to all employees and applicants for employment and prohibit discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, medical condition, genetic information, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.
Abarca Health LLC is an equal employment opportunity employer and participates in E-Verify. ""Applicant must be a United States' citizen. Abarca Health LLC does not sponsor employment visas at this time""
The above description is not intended to limit the scope of the job or to exclude other duties not mentioned. It is not a final set of specifications for the position. It's simply meant to give readers an idea of what the role entails.
#LI-AMBT #LI-HYBRID","$73,140 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2005,Unknown / Non-Applicable
"Lumen
3.5",3.5,Remote,Sr. Data Engineer,"About Lumen
Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.
The Role
Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen’s reputation as a technology leader?

In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence.
The Main Responsibilities
You are a great fit for this position if you:
Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions.
Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments.
Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in.
Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations.
What We Look For in a Candidate
Qualifications:
Experience building data models and performing complex queries using SQL
Experience performance tuning large datasets
Experience building large data pipelines and/or web services
Strong programming skills with Python and other scripting languages
4+ years of Business Intelligence or software development experience using industry technologies
3+ years of experience in building integration with upstream and downstream systems with REST APIs
Excellent problem solving, critical thinking, and communication skills
Ability to communicate effectively with technical and business teams, drive issues to closure
Strong understanding of data engineering and data stewardship roles in an organization
Strong time management and organization skills. Ability to work on multiple projects concurrently.
BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science

Other Qualifications:
Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable
Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable
Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies
Combined IT and Marketing background
Machine Learning, Data Science, and statistical modeling experience are highly valued
Azure experience.
Requisition #: 329671
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
72540
Salary Max :
161520
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.","$117,030 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1968,$10+ billion (USD)
"CVS Health
3.1",3.1,"Irving, TX",Associate Data Engineer,"Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
CVS Health has a rich set of healthcare data for more than 150 million individuals and provides the best foundation for any ambitious data engineer to:

Solve the complex business problems using all the modern tools and technologies
Securely store, process, transform and enrich terabyte to petabyte scale of highly confidential healthcare data that helps in taking data driven business decisions
Provide best-in-class environment where everyone brings their heart to work to build technical solutions to support customers.
Training and development will be a part of your role.

As an Associate Data Engineer you will:

Manage and support production platform to ensure the quality, performance, and availability of the services that meets business requirements for various CVS Lines of Business
Identify, design, and implement engineering process improvements through automating manual processes, optimizing data pipelines, re-designing services for greater scalability.
Required to support an on call 24 x 7 cloud Production Environment supporting and administering products & Services involving platform technologies like GCP, Azure, etc.
Work hands-on with customers to develop, migrate, and debug services issues.
Ensure server/process documentation is up to date and appropriate or create documentation where none may exist.
Tier 2 triage, troubleshooting, remediation, and escalation of tickets tied to the product support function.
Build data pipelines using Azure/GCP platform.

Required Qualifications
6 months of related work experience (can include internships/course work) including:

Experience in Azure/GCP (Big Query, GCS, Pub/Sub, DataProc, Airflow/Composer, Snowflake, Azure Cloud Services etc.)
Experience in Unix/Shell Scripting
Experience in Python
Experience in SQL

Preferred Qualifications
Experience in Service Now ticketing system
Hands on experience in designing and building data engineering solutions in cloud environments (preferably Azure/GCP).
Hands-on experience with languages like Python, PySpark, SQL, UNIX/Linux scripting to access, extract, manipulate and summarize data.
Strong understanding of query optimization, data structures, transformation, metadata, dependency, and workload management
Experience with CI/CD pipeline, and other DevOps principles/best practices
Experience with Cloud based tech stack and Cloud components including cluster management, Kubernetes, or other containerized services, storage, and workspace management.
Experience working in multi-developer environment, using version control (i.e. Git).
Certified Cloud Engineer in Data engineering track: Azure/GCP preferred
Good articulation in communicating complex technical subjects to non-technical audience
Working experience with automation and orchestration tools
Experience with modern API and microservice patterns
Knowledge and working experience in agile frameworks like Scrum. Kanban etc.
Familiarity in Retail / Healthcare / Insurance industry

Education
Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline

Master’s degree or PhD preferred
Pay Range
The typical pay range for this role is:
$60,000.00 - $144,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health colleagues can initiate a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through myHR (1-888-694-7287, or through myLeave at myHR). If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.","$102,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1963,$10+ billion (USD)
"PRI
3.7",3.7,Remote,Senior Data Engineer (US Remote),"PRI Talent is hiring a Senior Data Engineer on behalf of our client. This role is a full-time, 1099 contract staff augmentation position working with a company that is a leader in reducing electronic waste and finding value in gently used electronics. Our client has seen staggering growth and extraordinary impact on protecting the planet, all while providing a work culture unlike any other.
As a Senior Data Engineer, you can transform the business by gathering, modeling, and sharing actionable information via data-based applications, automated pipelines, and data integrations. This high-impact role will combine your best software engineering and data management practices with many unique and challenging problems. You will work with a small but passionate team to design and develop elegant software and scalable data frameworks with engaged stakeholders. Our Clients seek individuals with a proven track record of on-time product delivery and take pride in high-quality releases. To succeed in this role, you will need excellent technical knowledge, the ability to help gather requirements, and clear verbal and written communication skills to stay aligned with our client's national teammates.
Experience
5-7+ years of professional experience as an active participant in an Agile Development Team.
Expert level fluency in Python and major libraries associated with data and API integrations (Pandas, requests, numpy, etc.)
Expert knowledge of SQL and ease of working in common database and data warehouse applications (SQL Server, Redshift, Snowflake, MySQL, Oracle, etc.)
Advanced knowledge of the design and development of flexible, easy-to-use data models
Track record delivering rock-solid ELT pipelines and data orchestrations
Advanced ability to work with technical API documentation and technical contacts to quickly and reliably integrate with third-party systems
Intermediate experience working with high-level libraries for visualization and UI development in data-centric applications (matplotlib, seaborn, streamlit, etc.)
Comfort and respect working with sensitive information and handling it securely
History of work on complex enterprise systems or successful delivery of a greenfield product
Ability to understand business requirements and translate them into technical requirements
Knowledge, Skills, and Abilities
Familiarity with no-code/low-code tools (Microsoft PowerApps, Retool, etc.) to accelerate development
Experience working with containers, Docker, Kubernetes, or other orchestration services
Experience with Supply Chain and Inventory Management
Skill mastery based on extensive practical experience
Frequently mentors others in this skill
Experience with cloud-based data tools such as FiveTran, DBT, and Dagster is a plus
You're passionate about software development and elegant architectures. It's not just your career; it's your hobby, too!
You're constantly striving to learn new things and improve.
You follow industry news, regularly tinker with innovative technologies, and read books and blogs to keep your skills current.
Skill Level Definitions
Advanced: Demonstrated expertise built from repeated and diverse practical experience. Able to mentor others in this skill.
Intermediate: Good relevant practical experience and can credibly discuss/offer perspective.
Foundational: Understanding of fundamentals but limited/no practical experience.


Please note we will not accept applications that do not include a cover letter and work examples.",#N/A,51 to 200 Employees,Nonprofit Organization,Management & Consulting,Research & Development,2006,$5 to $25 million (USD)
Welcome to Clearway,#N/A,"Scottsdale, AZ",Data Analytics Engineer,"What The Role Is
The Data Analytics Engineer is responsible for analyzing the performance of renewable energy assets within Clearway's wind, solar, and battery storage fleets. The individual in this roll will identify, quantify, and communicate generation upside opportunities. This role will also perform analysis on an as needed basis for key stakeholders to support refinancing, divestitures, and lookback analyses on projects. The Data Analytics Engineer will work cross-functionally within the organization to collect data for internal stakeholders and analysis/Visualizations.
What You'll Be Doing
Knowledge of code and programming concepts
Ability to build and analyze dashboards and reports
Ability to summarize complex issues and identify opportunities and enhancements
Ability to manage simultaneous projects/tasks, set priorities and exercise independent judgment
Assess the performance for our Distributed Generation (DG) solar fleet
Identify process improvement opportunities to increase accuracy of DG metrics
Perform ad-hoc analyses to solve for DG issues and performance requests
QA/QC data pipeline for new projects added to Clearway's portfolio
Development of code for automation of reporting functions
Data collection and dissemination for internal stakeholders (periodic & reoccurring)
Feedback into Development Engineering for instrumentation strategy
Development of standards for data acquisition requirements on projects
What You'll Bring
Bachelor's degree in Engineering, Meteorology, Statistics, Physics, Applied Mathematics, or quantitative field
Minimum of 2 years of experience in data analytics required
SQL query experience required
Strong programming language experience required (Python, R, Matlab, etc.)
What Would Be Nice
Renewable energy experience preferred
Experience building dashboards using PowerBI, Spotfire or other BI software preferred
Certification in Lean/Six Sigma a plus
Clearway will not sponsor nonimmigrant visas for this position (H-1B, TN, E-3, etc.).
The pay rate for the successful candidate will depend on geographic location, skills, relevant and demonstrated experience, education, training and certifications, and other factors permitted by law. This role is eligible to earn an annual cash bonus, subject to personal and company performance goals.
Salary Range Across all U.S. Locations
$89,000—$123,000 USD
Clearway Energy Group is leading the transition to a world powered by clean energy. Along with our public affiliate Clearway Energy, Inc., we own and manage more than 9.6 gigawatts of renewable and conventional energy assets across the country. As we develop a nationwide pipeline of new renewable energy projects for the future, Clearway's 7 gigawatts of operating wind, solar, and energy storage assets offset the equivalent of more than 9 million metric tons of carbon emissions for our customers today. Clearway Energy Group is headquartered in San Francisco with offices in Carlsbad, Calif.; Scottsdale, Ariz.; Houston; and Princeton, N.J. For more information, visit clearwayenergygroup.com.
Our Commitment to Diversity, Equity, & Inclusion
At Clearway, we create a community that isn't about being the same – it's about building a team of unique individuals, with different backgrounds & skill sets, coming together to build something big & make a difference in the world. Clearway's team is dedicated to a clean energy future across a wide spectrum of roles & responsibilities. Embodying our company values and operating principles, unique individuals come together over a common mission. We embrace opportunities to do challenging work that can change the world. We aspire to bring out the best in everyone. We share setbacks, celebrate successes, & act with integrity & accountability to get the job done.

Working at Clearway, Hybrid Together
Here at Clearway, we're committed to balancing flexibility while fostering strong relationships with our teammates. We do this by prioritizing new hires based near one of our offices in San Francisco, Carlsbad, Scottsdale, Houston, & Princeton. Our office-based employees typically work together from fabulous spaces on Tuesdays & Thursdays to collaborate & learn, build community, get to know one another, & enjoy company-provided meals & events.

Clearway Energy is an equal opportunity employer that values a broad diversity of talent, knowledge, experience & expertise. We intentionally foster a culture of inclusion that empowers our employees to deliver superior performance to the communities we serve. We encourage minorities, women, individuals with disabilities & protected veterans to join the team. Clearway is a proud promoter of employment opportunities to our Military & Veterans.

What We Provide
Clearway offers all eligible employees working 20+ hours per week a comprehensive menu of benefits: generous PTO, medical, dental & vision care, HSAs with company contributions, health FSAs, dependent daycare FSAs, commuter benefits, relocation, & a 401(k) plan with employer match, a variety of life & accident insurances, fertility programs, adoption assistance, generous parental leave, tuition reimbursement, & benefits for employees in same-sex marriages, civil unions & domestic partnerships. For more on Clearway benefits, visit our Benefits Website.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"TD Bank
3.9",3.9,"Falmouth, ME",Data Engineer III (US) (Business Data Analyst),"Data Engineer III (US) (Business Data Analyst)
420108BR
Job Category - Primary
Technology Solutions
Work Location
11325 North Community House Road, Suite 575, 70 Gray Road West Falmouth Crossing, Mt Laurel - Technology Center - 17000 Horizon Way
Employment Type
Regular
City
Charlotte, Falmouth, Mount Laurel
Time Type
Full Time
State
Maine, North Carolina, New Jersey
Hours
40
Pay Range
$83,720 - $136,240 annually
Department Overview
Building a World-Class Technology Team at TD
The Business Data Analyst family provides data-oriented professionals who work as agents focused on ensuring technology and processes align within the business. They are SMEs in the products/systems/assets they analyze/support and are a perfect blend of Business Analyst and Data Analyst. They work closely with the System Data Analysts, technology partners, and business partners to ensure the products are audit compliant with regulatory requirements and meet the business needs.
Job Details
Depth & Scope:
Expert knowledge of data engineering frameworks, technologies, tools, processes, patterns, and procedures, including how they impact and integrate with other technology areas such as Architecture or Infrastructure
Performs highly complex technical tasks independently
Expert knowledge of TD applications, systems, networks, innovation, design activities, business, organization, best practices, and standards
Designs and develops to meet business and technical requirements; analyzes, adapts, integrates, codes, tests, debugs, and executes
Uses and evolves established patterns to solve complex problems; leads the development of new patterns where necessary
Recognized as primary subject matter expert in multiple areas directly and indirectly related to key accountabilities
Consults with peers and partners across multiple teams on all aspects of research, analysis, design, and support
Job Requirements
Customer Accountabilities:
Performs data analysis and assesses data management requirements for a specific Platform or Journey, including complex analysis involving multiple pods or products
Maintains expert knowledge of upstream data, including knowledge provided through data profiling, data quality reporting, and via the production of metadata
Supports the acquisition and ingestion of data
Articulates complex, large scale, and high impact technical design and development details to non-technical business partners
Elicits, analyzes, and understands business and data requirements to develop complete business solutions, including data models (entity relationship diagrams, dimensional data models), ETL and business rules, data life-cycle management, governance, lineage, and metadata
Ensures data is maintained in compliance with enterprise data standards, policies, and guidelines
Develops and maintains complex data models using industry standard modeling tools
Develops and maintains complex ETL jobs and frameworks using the Bank's standard tools
Provides support to the development and testing teams to resolve data issues, including escalation support on complex issues
Supports partners and stakeholders in interpreting and analyzing data
Builds effective working relationships within own pod and across partner teams to encourage collaboration on all pod deliverables
Shareholder Accountabilities:
Coordinates with technology work teams such as ITS, ARE, Architecture, Enterprise Protect etc. to ensure overall delivery success
Supports the QA team with data analysis/investigations of complex issues/ test cases as part of SIT/UAT/PAT testing
Provides oversight on post implementation activities during the warranty period
Executes & approves code check-in/ check-out into source code repository as part of source code management
Works closely with ITS/ ARE teams to support code packaging & deployment (CI & CD) into higher environments
Is the lead participant in the design & architecture reviews or the application
Raises service-now requests and works with the change management team to support release management activities
Leads data engineering initiatives and capabilities, data governance principles and how they apply across the organization
Ensures metadata and data lineage is captured and compatible with enterprise metadata and data management tools and processes
Adheres & contributes towards standard security coding practices to ensure application is free of most common coding vulnerabilities
Ensures technical decisions, technical risks and lessons learned are identified, clearly documented and enhancements are accordingly implemented
Protects the interests of the organization – identifies and manages risks, and escalates non-standard, high-risk activities as necessary
Employee/Team Accountabilities:
Participates fully as a member of the team, supports a positive work environment that promotes service to the business, quality, innovation and teamwork and ensures timely communication of issues/ points of interest
Provides thought leadership and/ or industry knowledge for Data engineering best practices and participates in knowledge transfer within the team and business unit
Keeps current on emerging trends/ developments and grows knowledge of the business, related tools and techniques
Participates in personal performance management and development activities, including cross training within own team
Keeps others informed and up-to-date about the status / progress of projects and / or all relevant or useful information related to day-to-day activities
Actively mentors and enables team members by sharing knowledge and leveraging engineering best practices
Leads, motivates and develops relationships with internal and external business partners / stakeholders to develop productive working relationships
Must be eligible for employment under regulatory standards applicable to the position.
Qualifications
Preferred Qualifications - Here are the preferred qualifications for this role:
Banking
Risk and Regulatory knowledge
SQL
Company Overview
About TD Bank, America's Most Convenient Bank®
TD Bank, America's Most Convenient Bank, is one of the 10 largest banks in the U.S., providing over 9.8 million customers with a full range of retail, small business and commercial banking products and services at more than 1,100 convenient locations throughout the Northeast, Mid-Atlantic, Metro D.C., the Carolinas and Florida. In addition, TD Auto Finance, a division of TD Bank, N.A., offers vehicle financing and dealer commercial services. TD Bank and its subsidiaries also offer customized private banking and wealth management services through TD Wealth®. TD Bank is headquartered in Cherry Hill, N.J.
We offer a competitive salary and benefit program, including: comprehensive, affordable health care through medical, dental, and vision coverage; financial security with life and disability insurance; opportunities to save using health savings and flexible spending accounts; retirement benefits to help prepare for the future; paid time off and work/life benefits to maintain a good balance.
Inclusiveness
At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live in and serve, and creating an environment where every employee has the opportunity to reach their potential.
If you are a candidate with a disability and need an accommodation to complete the application process, email the TD Bank US Workplace Accommodations Program at USWAPTDO@td.com . Include your full name, best way to reach you, and the accommodation needed to assist you with the application process.
EOE/Minorities/Females/Veterans/Individuals with Disabilities/Sexual Orientation/Gender Identity.
Business Line
TD Bank AMCB
Job Category(s)
Technology Solutions
Country
United States
State (Primary)
North Carolina
City (Primary)
Charlotte
State #2
New Jersey
City #2
Mount Laurel
State #3
Maine
City #3
Falmouth
Job Expires
22-Sep-2023","$109,980 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1855,$10+ billion (USD)
"FullSpeed Automotive
2.4",2.4,"Greenwood Village, CO",Data Engineer Manager,"Applicants must be authorized to work for any employer in the US. We are unable to sponsor or take over sponsorship of an employment visa at this time.
Job description
Collaborate cross-functionally with senior leadership and BI Analysts, to understand data requirements and ensure the availability of reliable data. Build scalable and high-performance data ingestion, transformation, and storage solutions in Azure Synapse Analytics (formerly SQL Data Warehouse).Design, develop, and implement data pipelines and workflows using Microsoft Azure Data Factory (ADF) and related services. Optimize data pipelines and workflows for performance, reliability, and scalability. Develop and maintain data models, schemas, and data dictionaries to support business intelligence and reporting needs. Implement data quality and data governance processes to ensure the accuracy, completeness, and integrity of the data. Monitor and troubleshoot data pipelines to identify and resolve issues proactively. Collaborate with IT Manager to ensure the availability, security, and compliance of data systems.Stay up to date with emerging technologies and industry trends related to data engineering and Azure cloud services.Required experience:Proven experience as a Data Engineer, specifically working with the Microsoft Azure Tech Stack.Strong proficiency in Microsoft Azure Data Factory (ADF) for data integration and orchestration.Hands-on experience with Azure Synapse Analytics (formerly SQL Data Warehouse) for scalable data storage and analytics.In-depth knowledge of SQL and database technologies, including data modeling, query optimization, and performance tuning.Familiarity with big data processing frameworks such as Apache Spark.Experience with data integration techniques and technologies, including ETL/ELT processes.Proficiency in scripting languages such as Python or PowerShell for automation and data manipulation.Solid understanding of cloud computing concepts and working knowledge of Azure services like Azure Storage, Azure Databricks, and Azure Data Lake.Strong analytical and problem-solving skills with a keen attention to detail.Excellent communication and collaboration skills to work effectively in a cross-functional team environment.Preferred Qualifications:Relevant certifications in Microsoft Azure, such as Azure Data Engineer Associate or Azure Solutions Architect.Experience with other Azure services like Azure Event Hubs, Azure Stream Analytics, or Azure Machine Learning.Familiarity with data warehousing concepts and methodologies.Knowledge of data governance and compliance frameworks, such as GDPR or CCPA.Required education: Bachelor's or Master's degree in Computer Science, Engineering, or a related field.
Job Type: Full-time
Pay: $115,000.00 - $135,000.00 per year
Benefits:
401(k)
Dental insurance
Flexible schedule
Health insurance
Paid time off
Vision insurance
Compensation package:
Bonus opportunities
Experience level:
5 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Greenwood Village, CO 80111: Reliably commute or planning to relocate before starting work (Preferred)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person","$125,000 /yr (est.)",1001 to 5000 Employees,Company - Private,"Construction, Repair & Maintenance Services",Vehicle Repair & Maintenance,#N/A,Unknown / Non-Applicable
"Capital One
4.1",4.1,"McLean, VA","Distinguished Engineer, Enterprise Data Platforms - Data Creation","Center 1 (19052), United States of America, McLean, Virginia
Distinguished Engineer, Enterprise Data Platforms - Data Creation
Come join my teams in Enterprise Data & Machine Learning group to build a highly scalable, well governed, data ecosystem that scales across 1000’s of AWS accounts, tens of thousands of database instances and millions of files stored across enterprise. You will also have the opportunity to shape the future of the platform that exchanges terabytes of data daily between Capital One and partners.
Distinguished Engineers are individual contributors who strive to be diverse in thought so we visualize the problem space. At Capital One, we believe diversity of thought strengthens our ability to influence, collaborate and provide the most innovative solutions across organizational boundaries. Distinguished Engineers will significantly impact our trajectory and devise clear roadmaps to deliver next generation technology solutions.
Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices
Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates
Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community
Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities
Responsibilities:
Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in
Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team
Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible
Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization
Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner
Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent
Basic Qualifications:
Bachelor’s Degree
At least 7 years of Software Architecture or Enterprise Architecture experience
At least 5 years of experience in software architecture and design patterns
At least 5 years of AWS cloud experience
Preferred Qualifications:
Masters’ Degree
Experience with developing strategy and implementing target architectures
AWS Solution Architect - Professional or AWS Certified Data Analytics - Specialty certified
8+ years of data governance, data access, data lineage, data monitoring, and security controls experience
7+ years of experience developing in Python, Java, Scala or Node
3+ years of rich experience in modern database technology evaluation and data modeling
3+ years of experience building data products and enterprise level data governance
3+ years of experience in building highly resilient distributed data systems
3+ years in data engineering including experience in distributed data pipelines and test data engineering
3+ years of experience dealing with large number of cross AWS account communications
3+ years of experience in Agile practices
Capital One will consider sponsoring a new qualified applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
San Francisco, California (Hybrid On-Site): $285,400 - $325,700 for Distinguished Engineer
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Capgemini
3.7",3.7,New Jersey,Sr. Data Engineer,"Title: Sr. Data Engineer
Location: New Jersey, NJ
Responsibilities:
Document existing processes workflows, reporting models, etc.
Translate business requirements into the technical specifications
Design, deploy, and build the BI solutions - such as the reporting tools
Maintain and support data analytics platforms such as the MicroStrategy
Create the tools to store data e.g. OLAP cubes
Conduct some unit testing along with troubleshooting
Evaluate and improve existing BI systems
Collaborate with teams to integrate systems
Develop and execute the database queries along with conducting analyses
Create of the visualizations or the reports for required projects
Develop and update the technical documentation
Life at Capgemini:
Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:
Flexible work
Healthcare including dental, vision, mental health, and well-being programs
Financial well-being programs such as 401(k) and Employee Share Ownership Plan
Paid time off and paid holidays
Paid parental leave
Family building benefits like adoption assistance, surrogacy, and cryopreservation
Social well-being benefits like subsidized back-up child/elder care and tutoring
Mentoring, coaching and learning programs
Employee Resource Groups
Disaster Relief
About Capgemini:
Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.
Get The Future You Want | www.capgemini.com
Disclaimer:
Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.
Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law",#N/A,10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"Blue Shield of California
3.9",3.9,"Oakland, CA","Data Engineer, Senior","JOB DESCRIPTION
Your Role
The Data Engineering development team Is responsible for design, development, test and deployment of large enterprise data warehouse/BI data solutions using both on-prem and cloud technologies . The Data Engineer (Senior) will report to the Manager, Data Engineering Development. In this role you will be responsible for design, development, and implementation of data integration, data warehouse and data mart (ELT/ETL) solutions using on-prem as well as Cloud technologies.
Your Work
In this role, you will:
Building data pipelines: Create, maintain, and optimize workloads from development to production for specific use cases.
Responsible for using innovative and modern tools, techniques and architectures listed below to drive automate of most-common, repeatable data preparation and integration tasks with goal of minimizing reducing defects and improving productivity.
Develop and follow data integration and data quality standards across all development initiatives according to the organization’s Enterprise information services policies as well as best practices.
Assist in renovating our data management infrastructure with quality of data preparation, integration and AI-enabled metadata management tools and techniques.
Tracking data consumption patterns most used and valued to our customers by performing intelligent sampling and monitoring.
Triage data issues, analyzing end to end data pipelines and in working with business users in troubleshooting/resolving data pipeline issues.
Perform the analysis and remediation of root causes, including deficiencies in technology, process, or resource capabilities.
Work in agile/DevSecOps pod model alongside solution leads, data modelers, analysts, business partners and other developers in delivery of data

QUALIFICATIONS
Your Knowledge and Experience
Requires a bachelor's degree or equivalent experience
Requires at least 10 years of prior relevant experience
Hands on experience with programming languages including SQL, PL/SQL on cloud data platforms like Snowflake, Oracle, SQL Server and Netezza
Strong technical understanding of data modeling (data vault 2.0), data mining, master data management, data integration, data architecture, data virtualization, data warehousing and data quality techniques with hands on experience using data management technologies like Informatica PowerCenter/IICS, Collibra, Master Data Management, DBT Cloud, Denodo and Golden Gate.
Working knowledge of Git repositories (bitbucket, GitHub), CI/CD (Jenkins, Azure DevOps)and software development tools, including incident tracking, version control, release management, subversion change management(Atlassian toolset – Jira/Confluence), testing tools and systems and scheduling software (Tidal, Control-m)
Experience working with popular data discovery, analytics and BI software tools like Tableau, Qlik, PowerBI and others for semantic-layer-based data discovery.
Experienced in popular open-source and commercial data science platforms such as Python, R, KNIME, Alteryx, others is a strong plus but not required/compulsory.
Basic experience in working with data governance and data security and specifically information stewards and privacy and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification.
Adept in agile methodologies and capable of applying DevOps and increasingly Data Operations principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization.
Pay Range:
The pay range for this role is: $ 96800.00 to $ 145200.00 for California.
Note:
Please note that this range represents the pay range for this and many other positions at Blue Shield that fall into this pay grade. Blue Shield salaries are based on a variety of factors, including the candidate's experience, location (California, Bay area, or outside California), and current employee salaries for similar roles.

ABOUT US
At Blue Shield of California we are parents, leader, students, visionaries, heroes, and providers. Everyday we come together striving to fulfill our mission, to ensure all Californians have access to high-quality health care at a sustainably affordable price. For more than 80 years, Blue Shield of California has been dedicated to transforming health care by making it more accessible, cost-effective, and customer-centric. We are a not-for-profit, independent member of the Blue Cross Blue Shield Association with 6,800 employees, more than $20 billion in annual revenue and 4.3 million members. The company has contributed more than $500 million to Blue Shield of California Foundation since 2002 to have a positive impact on California communities. Blue Shield of California is headquartered in Oakland, California with 18 additional locations including Sacramento, Los Angeles, and San Diego. We're excited to share Blue Shield of California has received awards and recognition for LGBT diversity, quality improvement, most influential women in corporate America, Bay Area's top companies in volunteering & giving, and one of the world's most ethical companies. Here at Blue Shield of California, we're striving to make a positive change across our industry and the communities we live in , Join us!
ABOUT THE TEAM
Blue Shield of California’s mission is to ensure all Californians have access to high-quality health care at a sustainably affordable price. We are transforming health care in a way that truly serves our nonprofit mission by lowering costs, improving quality, and enhancing the member and physician experience.
To fulfill our mission, we must ensure a diverse, equitable, and inclusive environment where all employees can be their authentic selves and fully contribute to meet the needs of the multifaceted communities we serve. Our comprehensive approach to diversity, equity, and inclusion combines a focus on our people, processes, and systems with a deep commitment to promoting social justice and health equity through our products, business practices, and presence as a corporate citizen.
Blue Shield has received awards and recognition for being a certified Great Place to Work, best place to work for LGBTQ equality, leading disability employer, one of the best companies for women to advance, Bay Area’s top companies in volunteering & giving, and one of the world’s most ethical companies. Here at Blue Shield of California, we are striving to make a positive change across our industry and the communities we live in – join us!
Our Values:
Honest . We hold ourselves to the highest ethical and integrity standards. We build trust by doing what we say we're going to do and by acknowledging and correcting where we fall short.
Human . We strive to be our authentic selves, listening and communicating effectively, and showing empathy towards others by walking in their shoes.
Courageous . We stand up for what we believe in and are committed to the hard work necessary to achieve our ambitious goals.
Our Workplace Model:
Blue Shield of California is dedicated to making work-life balance a reality. Whether you prefer to work in an office or from home, we understand flexibility is more important than ever. That’s why Blue Shield is a hybrid company, offering you the opportunity to decide where you can do your best and most meaningful work.
Two ways of working: Hybrid (our default) and office
Hybrid – In a business unit approved office a few times per year to 3 days per week, on average
Office – In a business unit approved office 4+ days a week, on average. If the role you’re applying for is deemed an “Essential Role,” the company has determined that the role can only be performed in a Blue Shield office or in the field and would require your to meet the office worker classification.
Physical Requirements:
Office Environment - roles involving part to full time schedule in Office Environment. Due to the current public health emergency in California, Blue Shield employees are almost all working remotely. Based in our physical offices and work from home office/deskwork - Activity level: Sedentary, frequency most of work day.

Equal Employment Opportunity:
External hires must pass a background check/drug screen. Qualified applicants with arrest records and/or conviction records will be considered for employment in a manner consistent with Federal, State and local laws, including but not limited to the San Francisco Fair Chance Ordinance. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, national origin, sexual orientation, gender identity, protected veteran status or disability status and any other classification protected by Federal, State and local laws.","$121,000 /yr (est.)",5001 to 10000 Employees,Nonprofit Organization,Insurance,Insurance Carriers,1939,$10+ billion (USD)
"Indium Software
4.1",4.1,"Sacramento, CA",Senior Data Engineer,"Job Information
RSD NO
7502
Industry
IT Services
Min Experience
4
Max Experience
8
City
Sacramento
State/Province
California
Country
United States
Zip/Postal Code
94203
Job Description
Title: Senior Data Engineer
Education Qualification: Bachelor's degree in Computer Science, Information Technology, or a related field.
Experience: 4-8 Years
Work Location: California
Work Mode: Work from Office

Required Skills :
Extensive experience providing practical direction within azure native services , implementing data migration and data processing using Azure services: ADLS, Azure Data Factory, Synapse/DW /Azure SQL DB, Fabric.
Proven experience with SQL, namely schema design and dimensional data modelling
Solid knowledge of data warehouse best practices, development standards and methodologies
Strong experience with Azure Cloud on data integration with Databricks
Be an independent self-learner with the “let’s get this done” approach and ability to work in Fast paced and Dynamic environment

Nice-to-Have Skills:
Basic understanding on ML Studio, AI/ML, MLOps etc.
Good to have Event Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service, Cosmo Db knowledge.
Good to have SAP Hana knowledge
Intermediate knowledge on Power BI
Good to have knowledge in DevOps and CI/CD deployments, Cloud migration methodologies and processes.","$127,709 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,1999,$25 to $100 million (USD)
"Tarrant County, TX
3.7",3.7,"Tarrant, TX",LEAD NETWORK ENGINEER (Data) - Information Technology,"Summary
This position will design, install, and manage the Access, Distribution, and Core layers of the Tarrant County Network infrastructure. Design fault tolerance and high availability into the County network. Engineer Quality of Service (QoS) policies into the County’s converged network of voice, video, and data. This position will manage the connectivity for the Wide Area Network (WAN). The position will design, install, and manage connections between the County’s network and partner agencies. The position will manage the County’s connections to the Internet. The position will implement, configure, maintain, troubleshoot, secure, and monitor, the network environment within the County.

POSTING MAY CLOSE AT ANY TIME
AFTER A SUFFICIENT NUMBER OF APPLICATIONS ARE RECEIVED
This position is with the award-winning Information Technology Department.
Tarrant County Information Technology Department

Tarrant County employees enjoy superior health, retirement, and insurance benefits.
For more information, please click on the link below:
http://www.tarrantcounty.com/en/human-resources/employee-benefits.html
Essential Duties and Responsibilities
Install, configure and maintain Access layer Ethernet switches for the Local Area Networks (LANs) in the downtown campus and remote locations. Designs and implements fault-tolerant star topologies for the LANs. Use Virtual LAN (VLAN) technologies to make the most efficient use of available network ports.
Install, configure, and maintain all Distribution and Core layer routers/switches at multiple County buildings and offices.
Manages route advertisement between all County routers via EIGRP and OSPF protocol.
Manages the leased Ethernet and fiber connectivity for the County Wide Area Network (WAN). The position will also manage the licensed microwave links that exist in the Tarrant County WAN.
Design, implement, and manages all County WiFi networks (802.11x).
Install, configure and manage the County network layer firewalls.
Install, configure, and manages remote access into the County network using Virtual Private Network (VPN) technologies.
Install, configure, and manages the authentication software (RADIUS) for VPN and WiFi networks.
Manage and maintain the VIOP switches that control all VoIP phones on the County network.
Install, configure and maintain network management software to proactively monitor all layer two (2) and layer three (3) network devices.
When requested, assist other County IT personnel in trouble-shooting application performance issues and errors. This is usually done by performing a packet trace and analyzing the output.
Provides research and development of new products related to improving network availability, performance and mobility. Test new technologies and develop County standards for network equipment and protocols. Seeks approval, of these proposed standards from the Tarrant County IT Technical Committee.
Performs all other related duties involved in the operation of the IT Department as assigned or required.
Minimum Requirements
NOTE: You must fill out the work history and education sections of application to show you have years of experience/education as required by hiring department or be disqualified.

Bachelor’s degree majoring in Information Technology related field plus four (4) full-time years' experience in Layer 2 or Layer 3 Network Infrastructure.
~OR~
Associate’s degree majoring in Information Technology related field plus six (6) full-time years' experience in Layer 2 or Layer 3 Network Infrastructure.
~OR~
High School or GED plus eight (8) full-time years' experience in Layer 2 or Layer 3 Network Infrastructure.

Hands on advanced working knowledge of the information technology tools and environments currently in use and/or planned for use in the near future for support of County networks.
Work independently or as part of a team.
Cisco Certified Network Associate (CCNA) certification or higher professional certificate required, Information Technology Infrastructure Library (ITIL) certification plus Security+ required or obtained within one (1) year of accepting position.
Cisco Certified Network Professional (CCNP) certification preferred.
Advanced oral/written communications skills, strong analytical and organization skills, ability to solve problems accurately, completely and quickly if necessary, ability to coordinate various activities simultaneously, make decisions and work without direct supervision, participate in and/or manage multiple projects concurrently without loss of quality on any project.
Driving may be required. Must have a valid and current driver’s license.
If hired, must provide proof of educational attainment at new hire processing.
Tarrant County will conduct background checks on new hires that will include a criminal background check related to convictions and deferred adjudications since the age of seventeen (17) and may include credit reports, motor vehicle records, employment records, and educational attainment. A conviction or deferred adjudication is not an automatic bar to employment. Each case is considered individually. Incumbent must hold a valid Driver’s License or State Issued ID card.
Physical Demands and Work Environment & Other Requirements
While performing the duties of this position, the incumbent is regularly required to sit, stand, walk, bend, stoop, climb, lift, push and pull.","$99,696 /yr (est.)",1001 to 5000 Employees,Government,Government & Public Administration,Municipal Agencies,#N/A,Less than $1 million (USD)
"Lyft
3.6",3.6,"Seattle, WA","Software Engineer, Data Platform","At Lyft, our mission is to improve people's lives with the world's best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.
The Data Orchestration team within Data Platform is responsible for managing orchestration engines including Airflow and Flyte, which power and accelerate data pipelines and machine learning processes at the scale required by Lyft products. These components support a variety of use cases, including but not limited to Core Dataset, Financial Infra, Pricing, Estimated Time of Arrivals (ETA), and Mapping. The team's clusters host and serve thousands of workflows and over 100,000 executions on a daily basis.
As a Software Engineer, with your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance the platform offerings. Your work will have a major impact on several areas of the business.
We are looking for candidates who are self starters and have a proven track record of delivering software solutions that can solve critical business needs. The candidate should be able to dive deep into any problems with lots of ambiguity and build a technical solution to solve it. They should be willing to take ownership of a project or a feature and be able to drive it from design to implementation.
Responsibilities:
Design, develop, deploy, monitor, operate and maintain existing or new elements of our platform
Help establish roadmap and architecture based on technology and our needs
Write well-crafted, well-tested, readable, maintainable code
Analyze our internal systems and processes and locate areas for improvement/automation
Collaborate with product org stakeholders to address and prioritize custom edge cases
Help lead large projects from inception to positive execution
Unblock, support and communicate with internal partners to achieve results
Experience:
3+ years of software engineering industry experience and with data structures/algorithms
2+ years of experience building and developing large-scale infrastructure, distributed systems or networks, and/or experience with data infrastructure
Experience working with kubernetes and container technologies (e.g. Docker, cri-o, etc)
Familiar with a cloud-based environments such as AWS/GCP/Azure
Benefits:
Great medical, dental, and vision insurance options
Mental health benefits
Family building benefits
In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off
401(k) plan to help save for your future
18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible
Pre-tax commuter benefits
Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program
Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law.
Starting in September 2023, this role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.
Candidates for this role must be based in the Seattle metro area.
The expected range of pay for this position in the Seattle area is $103,785 - $165,600. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.","$144,140 /yr (est.)",5001 to 10000 Employees,Company - Public,Information Technology,Computer Hardware Development,2012,Unknown / Non-Applicable
"C.H. Robinson
3.6",3.6,"Eden Prairie, MN",Principal Data Engineer,"Are you passionate about shaping the future of logistics through data-driven insights and cutting-edge cloud technologies? Join our Fortune 500 Global Logistics Company on our NAST Data Estate Team as a Principal Data Engineer and play a crucial role in transforming our data ecosystem into a modern, scalable, and high-performance cloud-based infrastructure. As part of our dynamic data engineering team, you will have the opportunity to collaborate with leadership and other professionals, leverage state-of-the-art cloud tools, and drive innovation that shapes the logistics industry worldwide.
This role may be located in Minneapolis-Saint Paul, Kansas City, Seattle, or Chicago.
Responsibilities:
Collaborative Teamwork: Collaborate with other senior level engineers/architects, business stakeholders, and analytics teams to help shape and influence our modern data strategy leveraging cloud-first technologies by eliciting requirements and delivering results
Cloud Data Architecture: Design, architect, and with partnership among your team develop data architectures to support our business needs and objectives. Using modern cloud data warehouses and supporting technologies to enable efficient costs and value driven products
Data Engineering: Create ELT/ETL pipelines that allow us to retrieve valuable data from both internal and external platforms, transform it into a value-added product, and make it available for consumers. Establish and implement best practices to ensure data quality, reliability, and cost responsibility
Data Modeling and Optimization: Design and implement data models that align with business requirements and enhance data accessibility for reporting and analytics. Optimize data structures and queries to improve system performance and reduce latency.
Continuous Improvement: Proactively identify technologies or solutions that differ from current technology stack or represent innovative uses of existing technologies. Construct and deliver proposed solution strategies for potential new technologies
Mentoring: Provide technical guidance and mentorship to engineering teams through technical POCs, shared frameworks, and desired best practices and patterns for software development, delivery, and management
Required Qualifications:
8+ years of experience in data engineering (4+ years cloud), utilizing modern platforms (AWS, Azure, Google Cloud Platform)
2+ years of experience with cloud data warehouses (Snowflake, Redshift, BigQuery)
Experience building and modeling data in relational and non-relational data storage technologies including schema design, stored procedure development, and performance optimization
Proficiency in SQL and Python and hands on experience with big data frameworks (Spark, Hadoop), NoSQL technologies (ElasticSearch, MongoDB), and streaming technologies (Kafka, Azure Event Hub)
Experience with cloud data replication and integration tools (Matillion, Fivetran, dbt, Airflow/Astronomer, LookML)
Bachelor’s degree from an accredited college or university in Computer Science, Software Engineering, IS, MIS, or other technology degree or minimum 4 years of equivalent work experience and high school diploma/GED
Preferred Qualifications:
Proven record of strong decision-making, analytical skills, conflict resolution, follow through, and building technical relationships with senior executives and business stakeholders
Experience with containerization and orchestration tools (Docker, Kubernetes)
Experience establishing testing patterns, acceptance testing criteria, and reviewing others' automated tests
Familiarity with data governance principles, data security, and compliance with global data protection regulations (ALTR, Alation, Collibra, Atlan)
Experience with Business Intelligence tools (PowerBI, Sigma, Tableau, Alteryx, Thoughtspot)
Questioning if you meet the mark? Studies have shown that women and people of color may be less likely to apply unless they match the job description exactly. Here at C.H. Robinson, we’re building a diverse and inclusive workplace where all employees feel they belong. If this position excites you, we welcome you to apply whether you check all the preferred qualifications or just a few. You may just be our next great fit!
Equal Opportunity and Affirmative Action Employer
C.H. Robinson is proud to be an Equal Opportunity and Affirmative Action employer. We believe in equality for all and celebrate the diversity of our employees, customers and communities. We believe this increases creativity and innovation, drives business growth and enables engaged and thriving teams. We’re committed to providing an inclusive environment, free from harassment and discrimination, where all employees feel welcomed, valued and respected.
Affirmative Action Employer/EOE/M/F/Disabled/Veteran
Benefits
Your Health, Wealth and Self
Your total wellbeing is the foundation of our business, and our benefits support your financial, family and personal goals. We provide the top-tier benefits that matter to you most, including:
Two medical plans (including a High Deductible Health Plan)
Prescription drug coverage
Enhanced Fertility benefits
Flexible Spending Accounts
Health Savings Account (including employer contribution)
Dental and Vision
Basic and Supplemental Life Insurance
Short-Term and Long-Term Disability
Paid and floating holidays
Paid time off (PTO)
Paid parental leave
Paid time off to volunteer in your community
Charitable Giving Match Program
401(k) with 6% company matching
Employee Stock Purchase Plan
Plus a broad range of career development, networking, and team-building opportunities
Dig in to our full list of benefits on OUR CULTURE page.

Why Do You Belong at C.H. Robinson?


Standing out among the world’s largest logistics platforms, C.H. Robinson solves logistics problems for companies across the globe and across industries, from the simple to the most complex. For 100+ years, our global suite of services has innovated trade to seamlessly deliver the products and goods that drive the world’s economy. With 20 million shipments annually for 100,000 customers, and millions of dollars contributed to support causes that matter to us, our people and technology literally move the world.
As a FORTUNE 200 company, FORTUNE has also named C.H. Robinson one of the World’s Most Admired Companies 2022. Headquartered in Eden Prairie, Minnesota, we are proud to be recognized as one of LinkedIn’s Top Companies in Minneapolis-St. Paul 2021. And we’re not stopping there… Join us as we collaborate, innovate, and work as one global team to make life better and more sustainable for our customers, communities, and world.","$107,091 /yr (est.)",10000+ Employees,Company - Public,Transportation & Logistics,Shipping & Trucking,1905,$10+ billion (USD)
"American Red Cross
3.4",3.4,"Raleigh, NC",Lead Data Warehouse Engineer (work from home),"Please use Google Chrome or Mozilla Firefox when accessing Candidate Home.
By joining the American Red Cross you will touch millions of lives every year and experience the greatness of the human spirit at its best. Are you ready to be part of the world's largest humanitarian network?
Join us—Where your Career is a Force for Good!
Job Description:
WHY CHOOSE US?
As one of the nation’s premier humanitarian organizations, the American Red Cross is dedicated to helping people in need throughout the United States and, in association with other Red Cross networks, throughout the world. When you join our team, you have a direct impact on a meaningful mission, and you can help save lives every day. If you share our passion for helping people, join us in this excellent career opportunity. Work where your career is a force for good.
We are committed to the diversity of our workforce and to delivering our programs and services in a culturally competent manner reflecting the communities we serve. Our work environment is collaborative, respectful, and inclusive with a focus on building allyship and a culture of belonging that empowers all team members. Come to learn, grow, and succeed while sharing your passion for making a difference.
The Red Cross supports a variety of cultural and community resource groups for employees and volunteers. From the Ability Network, our Asian American & Pacific Islander Resource Group, the Latino Resource Group, and Red Cross PRIDE, to the Umoja African American Resource Group, our Veterans+ Resource Group, and the Women’s Resource Group, these networks provide connections, mentoring and help give voice to important concerns and opinions.
At the American Red Cross, your uniqueness can shine!

WHAT YOU NEED TO KNOW ABOUT THE JOB:
The Enterprise Data & Analytics Team is building out a team of Data Warehouse Engineers to support mission-transforming work through data at the American Red Cross. As a result, we are hiring for a Lead Data Warehouse Engineers to help do this exciting work!
As a Lead Data Warehouse Engineer for the American Red Cross, you will be part of a Data Management team that is modernizing and transforming our data and reporting capabilities across multiple verticals by implementing a new modernized data architecture.
The Lead Data Warehouse Engineer will help develop, maintain and support an enterprise data warehouse system and corresponding data and will be responsible for database design and implementation of agreed upon standards. This position requires an innovative engineer who is passionate about data & data quality. The ideal candidate will possess strong data warehousing experience and the ability to develop scalable data pipelines that make data management and analytics/reporting faster, more insightful, and more efficient.
The work location is 100% virtual from a home office with occasional in-person meetings as necessary. Preference for candidate to be in the Mid-Atlantic states (NC, SC, VA) &/or to start the workday at 8am East coast to work with off-shore resources.

WHERE YOUR CAREER IS A FORCE FOR GOOD (Key Responsibilities):
Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Build and implement scalable solutions that align to our data governance standards and architectural roadmap for data integrations, data storage, reporting, and analytic solutions.
Design and develop data integrations and a data quality framework. Write unit/integration/functional tests and document work.
Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues.
Serve as tech lead by mentoring less experienced members of the team through code reviews, pair programming and similar hands-on interactions.

PAY INFORMATION: The annual salary range for this position is $135K - $140K. We do not offer an annual bonus for this role. Note that American Red Cross salaries are aligned to the specific geographic location in which the work is primarily performed. Other factors that may be used to determine your actual salary may include your specific skills, how many years of experience you have and comparison to other employees already in this role. **We will review specific salary information at the time of phone screening based upon your location & experience.**

Scope: Individual contributor that works under limited supervision. Apply subject matter knowledge. Capacity to understand specific needs or requirements to apply skills/knowledge.
Qualified candidates must be authorized to work in the United States. The American Red Cross does not sponsor employment visas.

WHAT YOU NEED TO SUCCEED (required/minimum qualifications):
Education*: 4-year college degree or equivalent combination of education and experience. Prefer academic backgrounds in Computer Science, Mathematics, Statistics, or related technical field.
7+ years of relevant work experience in data engineering, business intelligence or related field.
Experience with a variety of database technologies and data warehouse schema design patterns (snowflake and star in particular).
Experience with cloud-based databases, specifically AWS technologies (e.g., Redshift, RDS, S3, EMR, EC2, Kinesis)
Proficient in Informatica (Power Center, IDMC, IDQ, MFT) required
Experience using SQL queries as well as writing and optimizing SQL queries in a business environment with large-scale, complex datasets.
Experience creating ETL and/or ELT jobs.
Experience with Agile software development methodologies.
Excellent problem solving and troubleshooting skills.
Process oriented with great documentation skills.
Proficient in object-oriented programming (Python in particular).
Experience with DevOps methodologies and tools (e.g., Git, Artifactory, etc.).
Experience developing in a Linux environment.
Experience developing integrations across multiple systems and APIs is a plus.
Experience with Big Data tools like Spark, Hadoop, Kafka, etc. is a plus.
Combination of candidate’s education and general experience satisfies requirements so long as the total years equate to description’s minimum education and general experience years combined (Management experience cannot be substituted).
BENEFITS FOR YOU:
We take care of you, while you take care of others. As a mission-based organization, we believe our team needs great support to do great work. Our comprehensive benefits help you in balancing home and work, retirement, getting healthy and more. With our resources and perks, you have amazing possibilities at the American Red Cross to advance and learn.
Medical, Dental, & Vision Plans
Health Spending Accounts & Flexible Spending Accounts
PTO + Holidays
401K with up to 5% Match
Paid Family Leave
Employee Assistance Programs
Disability and Insurance: Short + Long Term
Service Awards and Recognition
LI-EH1
IND123

LI-EH1
IND123
Apply now! Joining our team will provide you with the opportunity to make a difference every day.
The American Red Cross is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.
Interested in Volunteering?
Life’s emergencies don’t stop, and neither do American Red Cross volunteers, who represent more than 90 percent of our workforce to help prevent and alleviate human suffering. You can make a difference by volunteering in a position that appeals to you and allows you to use your unique skills and talents. The Red Cross relies on generous volunteers who give their time and talent to help fulfill our lifesaving mission.
Visit
redcross.org/volunteertoday
to learn more, including our most-needed volunteer positions.
To view the EEOC Summary of Rights, click here:
Summary of Rights",#N/A,10000+ Employees,Nonprofit Organization,Nonprofit & NGO,Civic & Social Services,1881,$1 to $5 billion (USD)
"MultiPlan Inc.
3.7",3.7,"Boston, MA",Sr. Data Engineer,"Imagine a workplace that encourages you to interpret, innovate and inspire. Our employees do just that by helping healthcare payers manage the cost of care, improve competitiveness and inspire positive change. You can be part of an established company with a 40-year legacy that helps our customers thrive by interpreting our client's needs and tailoring innovative healthcare cost management solutions.
Our commitment to diversity, inclusion and belonging are part of the fabric of our company. We strive to create a workplace that fosters mutual respect and collaboration, where every talent individual can participate and perform their best work. We are MultiPlan and we are where bright people come to shine!
JOB SUMMARY:
This role will be part of the team responsible for developing and deploying Engineering and Integration solutions. Primary responsibility will be to work closely with the Data Architects and Machine Learning Team to implement data solutions for the organization using, as well as creating technical specification documents and test plans.
JOB ROLES AND RESPONSIBILITIES:
Understand business processes and how they are modeled in various systems
Work with business users, technology teams, and executives to understand their data needs to create innovative solutions to fulfil them
Design, organize, and implement data structures, workflows, and integrations between enterprise platforms to ensure the accurate and timely execution of business processes.
Develop and maintain scalable data pipelines and build out new API integrations to support continuing increases in data volume and complexity.
Define or redefine big data stack and revamp the data processing infrastructure and platform when necessary
Architect and rearchitect multi-tenant databases to meet the needs of our rapidly growing customer base
Streamline and automate the ETL process, dealing with thousands of data source
Improve data validation and data quality monitoring
Optimize and tune the databases to improve performance and reduce cost
Enhance and monitor data privacy and security to ensure HIPAA compliance
Collaborate with the operation team to improve and maintain our existing ETL pipeline
Guiding decisions and establishing best practices on data integration/engineering, as well as the future of our data infrastructure
Managing and improving the performance of our database, queries, tools, and solutions
Writing complex and efficient queries to transform raw data sources into easily accessible models for our teams and reporting platforms
Prepare data for predictive and prescriptive modeling
Identify and analyze data patterns
Identify ways to improve data reliability, efficiency and quality
Work with analytics, data science, and wider engineering teams to help with automating data analysis and visualization needs, advise on transformation processes to populate data models, and explore ways to design and develop data infrastructure
Document high and low level technical design
Draw performance reports and strategic proposals from analyses results for senior data science leadership
Collaborate, coordinate, and communicate across disciplines and departments.
Ensure compliance with HIPAA regulations and requirements.
Demonstrate Company’s Core Competencies and values held within.
Please note due to the exposure of PHI sensitive data – this role is considered to be a High Risk and privileged role.
The position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary.

JOB SCOPE:
The incumbent works independently and relies on judgment and experience to complete job responsibilities. The incumbent possesses an extensive range of knowledge of practices and procedures within the field and acts a resource for less experienced team members. Work is varied and complex.

JOB REQUIREMENTS (Education, Experience, and Training):
Bachelors’ degree in computer science, information technology or a similarly relevant field is highly preferred.
Minimum 5-7+ years experience building large scale, cost effective and robust data processing platforms
Required licensures, professional certifications, and/or Board certifications as applicable
Demonstrable experience creating multi tenant databases and ETL pipelines
Strong experience in database schema design, analytics data modeling
Strong SQL programming and query optimization
Experience with Spark, EMR, Presto, Hive, Scala, Redshift, Pentaho, SQL, etc.
Experience with Linux, Shell Script and Python
Experience with AWS and/or Azure cloud
Good understanding of data security and encryption
Healthcare Insurance Domain experience strongly preferred
Excellent communication skills (verbal, listening and written)
Extensive experience in triaging data issues, analyzing end-to-end data pipelines and working with business users in resolving issues.
Experience in working with data governance/data quality and data security teams and specifically data stewards and security officers in moving data pipelines into production with appropriate data quality, governance and security standards and certification.
Experience building infrastructure required for optimal extraction, transformation, and loading of data from diverse data resources
Adept in agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines.
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata and workload management.
Strong attention to detail when identifying data relationships, trends, and anomalies.
Thinking through long-term impacts of key design decisions and handling failure scenarios.
Ability to work with both IT and business in integrating analytics and data science output into business processes and workflows.
An agile learner who brings strong problem-solving skills and enjoys working as part of a technical, cross functional team to solve complex data problems
A thought leader when approaching technical challenges
Ability to provide mentoring to a team of data engineers
Ability to prioritize and manage multiple projects and requests at any one time
Ability to effectively share technical information, communicate technical issues and solutions to all levels of business
Ability to meet strict deadlines, work on multiple tasks and work well under pressure
Individual in this position must be able to work in a standard office environment which requires sitting and viewing monitor(s) for extended periods of time, operating standard office equipment such as, but not limited to, a keyboard, copier and telephone
COMPENSATION
The salary range for this position is [$120K to $145K]. Specific offers take into account a candidate’s education, experience and skills, as well as the candidate’s work location and internal equity. This position is also eligible for health insurance, 401k and bonus opportunity.

BENEFITS
We realize that our employees are instrumental to our success, and we reward them accordingly with very competitive compensation and benefits packages, an incentive bonus program, as well as recognition and awards programs. Our work environment is friendly and supportive, and we offer flexible schedules whenever possible, as well as a wide range of live and web-based professional development and educational programs to prepare you for advancement opportunities.

Your benefits will include:
Medical, dental and vision coverage with low deductible & copay
Life insurance
Short and long-term disability
401(k) + match
Generous Paid Time Off
Paid company holidays
Tuition reimbursement
Flexible Spending Account
Employee Assistance Program
Summer Hours

EEO STATEMENT
MultiPlan is an Equal Opportunity Employer and complies with all applicable laws and regulations. Qualified applicants will receive consideration for employment without regard to age, race, color, religion, gender, sexual orientation, gender identity, national origin, disability or protected veteran status. If you would like more information on your EEO rights under the law, please click here.","$112,479 /yr (est.)",1001 to 5000 Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1980,Unknown / Non-Applicable
"AE Business Solutions
4.2",4.2,"Milwaukee, WI",Senior Data Engineer,"AE Business Solutions is seeking a Senior Data Engineer that can deliver high-quality, maintainable, and scalable data solutions. The Senior Data Engineer will work with Solution Architects and other data engineers to develop an enterprise analytics data platform through new and updated data pipelines leveraging shared components and aligning to standards and best practices. This role is focused on collecting data from internal and external sources and transforming it into usable information for the business including data scientists and data analysts. If you have strong experience in AWS services and leveraging data pipelines, this role has a lot to offer.

This position is a 6-month contract to hire position that requires 3 days onsite in Milwaukee. Benefits including PTO and health insurance can be provided throughout the contract duration.
How will you make an impact?
Deliver high quality data assets to be used by the business to transform business processes and to enable leaders to make data-driven decisions
Continuously improve data solutions to increase quality, speed of delivery and trust of data engineering team’s deliverables to enable business outcomes
Reduce total cost of ownership of solutions by developing shared components and implementing best practices and coding standards
What are we looking for?
Ability to translate data engineering designs into working code
Data analysis and data engineering pipeline experience including design, development, and support
Experience with AWS services including S3, Lambda, EMR, RDS, Glue, Data Pipeline, Redshift and/or other big data technologies.
Experience with coding in Python, PySpark, and Terraform
Experience with DevOps practices including Continuous Integration, Continuous Delivery, and Infrastructure as Code to deliver end-to-end automation of data delivery.
Ability to train and mentor junior data engineers.
Experience with Agile engineering practices including the scrum framework
You might be a good fit if you like to:
Leverage technology to deliver data solutions to drive business outcomes
Drive for continuous improvement of processes and solutions
Bring energy and commitment to excellence to drive delivery of high-quality solutions
Share knowledge and mentor team members on technologies and solutions
What you can learn on the job:
Gain experience and expertise using AWS cloud technologies through hands-on solution execution alongside solution architects and data engineers
Grow practical understanding of agile work practices through application of the scrum framework to deliver work products
Partner with others to deliver solutions and build knowledge around other data functions including Information Governance, Information Architecture, and Data Science
What does success look like?
First 30 days:
Understand the existing analytics data platform and technologies
Understand team’s work management processes
First 6 months:
Develop data solutions for the business including shared components and specific data sets
Learn business processes and develop necessary contacts throughout the organization
First year:
Continue to develop data solutions for the business
Become expert on the team for other data engineers to go to for mentoring in completing their work
Partner with solution architects and lead data engineers to advance capabilities of the platform","$96,796 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,1949,$25 to $100 million (USD)
"Dollar General
2.7",2.7,"Goodlettsville, TN",LEAD DATA SCIENCE ENGINEER,"Company Overview:
As a Lead Data Scientist-Model development with Dollar General, you'll develop models and algorithms for our retail business. You'll be engaged in Sales Forecasting space to build and optimize new Models as well as work closely with stakeholders in other domains to continuously learn more about our business and develop an understanding of the various business processes.

You will partner with ML Engineers within our IT team and mentoring Data Scientist and Decision Science analyst on our Decision Science teams to build solutions for business needs including development, deployment, and maintenance of algorithms and models at scale!

You will oversee the creation and development of key models which allow us to evaluate and guide Dollar General’s Sales forecasting data at every node of the multi echelon supply chain network
Job Details:
Perform analytical tasks that include data gathering, analysis, visualization, and data-driven storytelling as a basis of project justification and innovation.
Perform statistical/machine learning projects as necessary for given business needs. These projects may consist of – large scale/rapid hypothesis testing, classification, prediction, and recommender systems.
Develop dynamic, productionized, and scalable customer-level models that generate ROI for both DG and their customers. These models may include predictive propensity models and customer segmentations.
Serve as a leader on the team providing direction, sharing knowledge, offering analytical expertise, and mentoring junior team members as appropriate
Qualifications:
MS in Data Science, Statistics, Economics, Computer Science, Mathematics, or related applied quantitative field preferred.
8+ years hands-on industry (non-academic) experience in Data Science (or equivalent quantitative job title). Strong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries
3-4 years of leading /developing statistical models","$118,124 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,Other Retail Stores,1939,$10+ billion (USD)
"JobNimbus
3.7",3.7,"Lehi, UT",Senior Data Engineer,"We are obsessed with the hero's journey at JobNimbus. Every person has a hero's journey. Hermione Granger, James T. Kirk, Frodo Baggins, Anna & Elsa, Nacho Libre, and even YOU! This is our “call to adventure” to come check out JobNimbus. What do you have to lose? You might make a few new friends, learn about a sick new company doing some amazing things, and maybe you’ll even land a new job!
Mission:
Contribute to the design and building out of JobNimbus data architecture and pipelines.

What you’ll be doing:
Be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.
Support our software developers, architects, data analysts and BI team on data initiatives to ensure an optimal data delivery architecture that is consistent throughout ongoing projects.
Must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.
The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

What makes you the hero for this job:
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
5+ years in a Data Engineer role with a primary focus on building and scaling data pipelines in AWS.
Experience with big data tools: Athena, Glue, Kafka, etc.
Experience with relational SQL and NoSQL databases: Couchbase, PostgreSQL, MySQL
Experience with data pipeline and workflow management tools
Experience with AWS cloud services: S3, Glue, Athena, RDS, etc
Experience with stream-processing systems: Kafka, etc.
Experience with data related programming language with a preference towards Python.
Bachelor degree in CS, IT, IS or equivalent experience.

Superpowers:
Ownership. We need someone who embodies this value and can figure things out and move quickly. If you need direction and someone to hold your hand, this job is not for you.
Customer Obsessed. Our software is ever changing, and you'll need to stay on top of the latest and greatest adjustments. It's kind of like being obsessed with Oprah's book club and that feeling that you have to read the next one as soon as it comes out.
Mentor (Hit us up to get more information)
Nick Cook - Specialist in hiring amazing people, lover of all things outdoors, computer nerd, and lead substitute on his friends hockey team.
JobNimbus is proud to be an equal opportunity / affirmative action employer. We are committed to equal opportunity regardless of race, color, religion, sex, national origin, sexual orientation, gender identity, age, disability, Veteran status, or other legally protected characteristics. This position may require the successful completion of a criminal background check and/or drug screen. If you have a disability or special need that requires accommodation, please let us know in the application.
If you have any questions regarding this job post, please email jobs@jobnimbus.com.
bdCdRAoCk6","$132,934 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Computer Hardware Development,2013,Unknown / Non-Applicable
"The Hartford
3.9",3.9,"Hartford, CT",Senior Staff Data Engineer,"You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.
The Hartford's Enterprise Data Organization is seeking a Sr. Data Engineer/Tech Lead in our Hartford, CT office. We are seeking a talented professional with a proven track record of engineering and operationalizing a next generation analytics solution suite using Cloud (AWS) and Big Data Technologies. Our ideal candidate will leverage deep technical expertise and strong communication skills to deliver both invest and maintenance projects within the Personal Lines portfolio. Responsibilities include but are not limited to: • Design and develop high quality, scalable software modules for next generation analytics solution suite • Prototype high impact innovations, catering to changing business needs, by leveraging new technologies (AWS – Cloud and Big Data) • Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of highest technical complexity • Consults with functional management in the analysis of short and long-range business requirements and recommends innovations which anticipate the future impact of changing business needs • Works closely with client management to identify and specify the complex business requirements and processes for diverse development platforms, computing environments (e.g., Cloud, host based, distributed systems, client server), software, hardware, technologies and tools • Provides highly technical consulting and leadership in identifying and implementing new uses of information technologies that assist the functional business units in meeting their strategic objectives • Reviews the disaster recovery plan to ensure that new systems promote uninterrupted systems operation • Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.) • Researches and evaluates alternative solutions and recommends the most efficient and cost effective solution for the systems design • Formulates logical statements of business problems and devises, tests and implements efficient, cost effective application program solutions (e.g., codes and/or reuses existing code through the use of program development software alternatives and/or integrates purchased solutions) • Prepares charts, tables and diagrams to assist in analyzing problems, utilizing various business, scientific, engineering and mathematical techniques. Analyzes existing system and programming logic to provide more efficient machine operations or to identify difficulties, and revises the logic and procedures involved as necessary • Primary technical point of contact for interaction with other cross-functional units and teams. • Assign personnel to the various projects or application components, and direct their activities • Review, evaluate and prepare periodic activity and progress reports for the team Qualifications • Bachelor’s degree in Computer Science or a related discipline and 7 or more years’ experience in IT systems analysis and application program development, or an equivalent combination of education and work experience • 7+ years ETL / Data Integration / Big Data / Cloud (AWS) Technologies experience • 4+ years Big Data / Cloud (AWS) Technologies experience • AWS / Big Data Technologies certification preferred • Knowledge of Oracle, Talend, Unix/Linux Shell scripting, Autosys scheduling tool, Sub Version, version control Tools • Strong data warehouse applications knowledge in financial/insurance domain • Knowledge of ErWin modeling, Big Data Distributed Processing (HDFS, Hive, Spark, PySpark), AWS, Data Analytical languages R, Python preferred • Good programming skills in Java
Compensation
The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
$129,200 - $193,800
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",#N/A,10000+ Employees,Company - Public,Insurance,Insurance Carriers,1810,$10+ billion (USD)
"Texas Comptroller of Public Accounts
3.5",3.5,"Austin, TX",GLO - Senior Data Engineer (Programmer V),"GLO - Senior Data Engineer (Programmer V) (00036216)
Organization: GENERAL LAND OFFICE
Primary Location: Texas-Austin
Work Locations: Austin GLO Main FL9 1700 N Congress Ave Austin 78701

Job: Business and Financial Operations
Employee Status: Regular
Schedule: Full-time
Standard Hours Per Week: 40.00
Travel: Yes, 5 % of the Time
State Job Code: 0245
Salary Admin Plan: B
Grade: 28
Salary (Pay Basis): 8,750.00 - 9,750.00 (Monthly)
Number of Openings: 2
Overtime Status: Exempt
Job Posting: Sep 20, 2023, 3:56:19 PM
Closing Date: Oct 4, 2023, 11:59:00 PM
Description
The Texas General Land Office primarily serves the schoolchildren, veterans, and the environment of Texas. The agency does so by preserving our history, maximizing state revenue through innovative administration, and through the prudent stewardship of state lands and natural resources. This position is with our Information Technology Services area of the agency. To be successful the candidate must model the GLO's competencies of Integrity, Open Communications, Teamwork, Innovation and Proficiency. The successful candidate will be an integral part of the GLO's Information Technology Services team.

Performs highly advanced (senior-level) computer programming work for the SaaS Development team in Information Technology Services. Work involves overseeing programming projects; analyzing proposed applications; and designing software solutions. May supervise the work of others. Works under minimal supervision, with considerable latitude for the use of initiative and independent judgment.

Military Crosswalk information can be accessed at:


http://www.hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_InformationTechnology.pdf
In order to receive Veterans' preference, a copy of Form DD#214 is required at time of interview.

Benefits
Free Parking
Defined Retirement Benefit Plan
Optional 401(k) and 457 accounts
Medical Insurance - State pays 100% of the health plan premium for eligible full-time employees and 50% of the premium for their eligible dependents. State pays 50% of the eligible part-time employee’s premium and 25% for eligible dependents.
Optional Benefits such as dental, vision, and life insurance
Minimum of 96+ Hours of Annual Leave a year **Annual leave increases with length of service

Essential Job Elements:

Performs highly advanced (senior-level) coding tasks in various programming languages and related technologies while adhering to GLO established architecture, software design, development, and coding standards.

Oversees and/or performs work on programming projects including those that are highly complex in nature and/or large in scale. Contributes on and/or leads development activities to ensure tasks and projects are completed within established time frames.

Oversees and/or evaluates business requests and leads the design of solutions aligned with project goals and objectives which leverage commercial products, and software-as-a-service offerings first over custom development as needed.

Oversees and/or performs software application testing activities such as: unit, integration, and performance testing.

Oversees and/or performs research and analysis required for project proposals, software and systems modifications, and collaborates with peers and leadership regarding the technologies, products, services, and strategies needed to successfully align technology with agency business needs.

Oversees and/or evaluates proposals and work products of third-party vendors to determine the quality, accuracy, and completeness.

Manages, tracks and documents all work in the respective work management system based on the type of work being performed.

Produces and reviews technical specification documents, support documentation and diagrams as required by standard team practices.

Qualifications
Minimum Qualifications:
10 years of professional experience working in information technology or similar industry.
Full-time experience in software development, data integration, reporting, or business intelligence.

Preferred Qualifications:
Graduation from an accredited four-year college or university with major coursework in information systems, accounting, public administration, business, or closely related field.

8 years or more experience working as a software developer or data integration developer.

Experience working with or leading teams that follow an Agile delivery methodology
Experience working with MuleSoft Anypoint Platform, SSIS, Azure Dev Ops, Git, Bitbucket, Visual Studio, Eclipse, REST API services and/or other similar tools and technologies to design, develop, test, troubleshoot, and support enterprise-class web applications.
Experience coding in Java, Python, Microsoft SQL Server, SQL Server Integration Services, and SQL Server Reporting Services.
Experience in designing, developing, and implementing ETL processes
Experience in working with data engineering teams
Experience developing in the Salesforce platform including Apex, Lightning Components, Visualforce, Workflows, Triggers.
Experience using AWS SDK to develop secure and scalable cloud applications.

One or more of the following certifications:

MuleSoft Certified Developer - Level 1
MuleSoft Certified Developer - Level 2
MuleSoft Certified Integration Architect - Level 1
Salesforce Platform App Builder Certification
Salesforce Platform Developer I Certification

Knowledge, Skills, and Abilities (KSAs):
Knowledge of the principles, practices, and techniques of software development and the full software development life cycle (SDLC)
Knowledge of professional software engineering practices & best practices for the full software development life cycle, including agile methodologies, coding standards, code reviews, source control management, build processes, and testing.
Knowledge of database development, relational database design, and database protocols.
Knowledge of computer Science fundamentals in object-oriented design, data structures, algorithms design, and problem solving.
Knowledge of application CI/CD pipelines: infrastructure as code, integration testing, automated deployment, and rollback.

Skill analyzing software applications, defects, and business problems to draw evidence-based conclusions and devise innovative solutions.
Skill in exercising sound judgment and effective decision making
Skill in writing complex SQL queries in designing tables, stored procedures, views and functions for development, analysis, and performance tuning.

Ability to communicate effectively both verbally and in writing to any level of the organization in a clear and concise manner.
Ability to create and validate test classes and move code and other components into Production environment.
Ability to work under pressure and successfully manage multiple overlapping deadlines.
Ability to lead technical requirement gathering sessions and building solutions from those requirements.
Ability to receive and respond positively to constructive feedback.
Physical Requirements
This position requires the employee to primarily perform sedentary office work; however, mobility (moving around the work-site) is routinely required to carry out some duties. This position requires extensive computer, telephone and client/ customer contact and communication. It requires the ability to move and position oneself as needed for filing and similar routine office duties. The job also requires normal cognitive abilities requiring the ability to learn, recall, and apply certain practices and policies. It requires the stamina to maintain attention to detail despite interruptions. Ability to read printed materials and computer screens. The individual must be able to move and transport records, documents, boxes, and all related information and materials, weighing up to 20 pounds when required.","$9,250 /mo (est.)",1001 to 5000 Employees,Government,Government & Public Administration,State & Regional Agencies,1835,Unknown / Non-Applicable
"Definitive Logic
4.2",4.2,"Arlington, VA",Data Engineer IV - REMOTE,"Definitive Logic is seeking a motivated Senior Data Engineer IV to join our team supporting the US Air Force in enhancing their network security posture through the implementation of microsegmentation.
The professional will be a full-time, remote employee that is part of an agile team that is responsible for analysis of existing application servers using data and tools from many sources.
This is an exciting opportunity to be part of a dynamic team in a highly rewarding work environment that presents numerous training and professional growth opportunities.
This position is contingent upon award.
Roles and Responsibilities:
Help our customers enhance the security posture of their network and enhance reporting of applications
Operate as a trusted advisor that helps the Technology and Data Solutions (TDS) Practice and its customers achieve their goals
Researches and integrates design strategies, product specifications, development schedules, for client applications
Participate in data engineering of existing client applications to facilitate the insertion of a new application allowing microsegmentation
Develops technical designs and specifications for complex data pipelines/data flows for customer/customers.
Identifies data quality issues and potential remediations for consideration by PM and/or customer stakeholders
Identifies data gaps and potential remediation or integration activity for consideration by PM and/or customer
Understands Department of Defense (DoD) data standards and management requirements
Leads and influences team on project deliverables
Drives quality assurance program for project deliverables
Creates quality deliverables for customers
Drives full life-cycle of services/solution delivery for project(s)
Provides technical leadership to lower-level engineer
Required Qualifications
8+ years of Relevant Experience
Experience with the DoD
Bachelor’s Degree, preferably in Engineering, Mathematics, or Business
DoD Secret Clearance or ability to obtain
Information Assurance(IA) Certification (“8570 Certification”) - Security + or higher
Desired Qualifications
Experience with projects that include cloud solutions implemented in Air Force Cloud One
Experience with projects that include software insertion
Experience with projects that include network microsegmentation
About Definitive Logic
Definitive Logic (DL) is a management and technology consulting firm known for delivering outcomes and ROI for agencies’ most complex business challenges. DL delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We’re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.
Definitive Logic is ultimately a team of problem solvers — thought leaders, domain experts, coders, data enthusiasts, and technophiles. Our exciting projects and learning and sharing culture have consistently resulted in validation as a Great Place to Work: 2023 Washington Post Top Workplaces (8-time winner) \u007C 2023 Virginia Best Places to Work (10 years running, #1 midsize in 2019).

Definitive Logic is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.

If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable, or limited in your ability, to use or access our Careers page: https://www.definitivelogic.com/careers/open-opportunities/ as a result of your disability. You can request a reasonable accommodation by sending an e-mail to Recruiting@DefinitiveLogic.com or via phone: 703-955-4186. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your e-mail subject line.

DL Benefits
Health
Dental
Vision
Life/AD&D: Company paid
STD/LTD:Company paid
Supplemental Plans: TriCare Supplement, Pet Insurance through Nationwide, Legal Resources and hospital/accidental indemnity plans and Wellness initiatives.
Compensation Benefits:
Competitive Base Salary
Annual performance based bonus
401(k) & Roth option: You are fully (100%) vested on day 1 and DL matches up to 5%
Spot Bonuses
Referral Bonuses
Additional Benefits:
Flexible Time Off (FTO): Under our FTO plan, there is no cap in the amount of leave you choose to take, with proper coordination and prior approval.
Volunteer Hours: DL allocates up to 8 hours for you to use every year to volunteer for a 501c3 organization of your choice and DL will donate to that charity based on how many hours you volunteer.
Cell Phone Reimbursement: $80/month
Location Specific Metro/Parking
Tuition Reimbursement
Training & Certifications","$123,218 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,1999,$25 to $100 million (USD)
"Mastronardi Produce
3.1",3.1,"Livonia, MI",Data Lake Engineer,"Mastronardi Produce pioneered the commercial greenhouse industry in North America, and we’re now the leading greenhouse vegetable company on the continent. Our award-winning, flavorful produce is packed under the SUNSET® brand and is available at leading grocery retailers across North America. Family owned for over 65 years, we pride ourselves on having the most flavorful products and the best people in the industry. We are constantly pushing boundaries to be a leader in fresh produce innovation. We seek individuals that demonstrate our PRIDE values (Passion, Respect, Innovation, Drive, Excellence) to help us fulfill our mission to inspire healthy living through WOW flavor experiences.

Our Corporate office in Livonia, Michigan is currently seeking a Data Lake Engineer to join our Information Technology team! As a Data Lake Engineer, you will be responsible for the design, implementation, and maintenance of the data lake infrastructure within an organization. You will work closely with data engineers, data scientists, and other stakeholders to ensure the data lake meets the requirements for data storage, processing, and analytics. This role requires a deep understanding of data lake technologies, data integration, and data governance principles.

Values:
To perform the job successfully, the incumbent’s behavior must be consistent with the PRIDE values expected of all Mastronardi Produce employees: be Passionate; have Respect; be Innovative; be Driven and strive for Excellence.

Primary Responsibilities:
Design and build scalable and reliable data lake architectures to support data storage and processing needs.
Collaborate with cross-functional teams to gather data requirements and understand data sources.
Develop data ingestion pipelines to efficiently extract, transform, and load data into the data lake.
Implement data governance policies and procedures to ensure data quality, security, and compliance.
Perform data profiling, cleansing, and validation activities to maintain the integrity of the data.
Optimize data storage and retrieval processes to improve performance and efficiency.
Monitor data lake performance and troubleshoot issues to ensure uninterrupted data availability.
Implement data partitioning and indexing strategies to enhance query performance.
Develop and maintain data catalog and metadata management processes.
Collaborate with data scientists to provide them with access to relevant data sets and tools.
Implement data security measures, including encryption and access controls, to protect sensitive data.
Collaborate with data engineers to develop and maintain data pipelines for data extraction and transformation.
Evaluate and implement new data lake technologies and tools to enhance data lake capabilities.
Work with stakeholders to define data retention and archival policies for the data lake.
Ensure compliance with data privacy regulations and industry best practices.
Develop and maintain documentation for data lake architecture, processes, and workflows.
Provide technical guidance and support to other team members on data lake-related issues.
Collaborate with infrastructure teams to ensure proper hardware and software provisioning for the data lake.
Implement disaster recovery and backup strategies for the data lake.
Stay up to date with emerging trends and advancements in data lake technologies and practices.

Qualifications & Experience:
Bachelor's degree in computer science, information systems, or a related field.
Proven experience as a data engineer or a similar role.
In-depth understanding of data lake architectures, concepts, and best practices.
Strong knowledge of big data technologies, such as Hadoop, Spark, and Hive.
Experience with cloud-based data lake platforms, such as Amazon S3, Azure Data Lake Storage, or Google Cloud Storage.
Proficiency in programming languages commonly used in data engineering, such as Python, Java, or Scala.
Solid understanding of SQL and experience with SQL-based query engines.
Experience with data integration and ETL (Extract, Transform, Load) processes.
Familiarity with data modeling and database design principles.
Knowledge of data governance frameworks and data quality management.
Understanding of data security and privacy principles.
Experience with data catalog and metadata management tools.
Proficient in using data manipulation and analysis tools, such as Apache Spark or Apache Hudi.
Strong analytical and problem-solving skills.
Excellent communication and collaboration abilities to work effectively with cross-functional teams.
Detail-oriented with a focus on delivering high-quality results.
Ability to work in a fast-paced and dynamic environment.
Knowledge of agile software development methodologies.
Experience with version control systems, such as Git.
Certifications in relevant technologies (e.g., AWS Certified Big Data Specialty) are a plus.
Experience with real-time data processing frameworks (e.g., Apache Flink, Kafka Streams) is a plus.

Please note: Mastronardi Produce has accommodation processes and policies in place and provides accommodation for employees with disabilities. If you require a specific accommodation because of a disability or documented medical need, please contact the Human Resource office so that arrangements can be made for the appropriate accommodation to be put in place.","$75,046 /yr (est.)",1001 to 5000 Employees,Company - Private,Agriculture,Crop Production,1954,Unknown / Non-Applicable
"Labcorp
3.7",3.7,"Durham, NC",Senior Data Engineer,"Labcorp is recruiting a Data Engineer/Analyst for a dynamic team in either Burlington or Durham, NC.
Get ready to redefine what’s possible and discover your extraordinary potential at Labcorp. Here, you’ll have the opportunity to personally advance healthcare and make a difference in peoples’ lives with your bold ideas and unique point of view. With the support of exceptional people from across the globe and an energized purpose, you’ll be empowered to own your career journey with mentoring, training and personalized development planning.
At Labcorp we believe in the power of science to change lives. We are a leading global life sciences company that delivers answers for crucial health questions because we know that knowledge has the potential to make life better for all. Through our unparalleled diagnostics and drug development capabilities, we provide insights and accelerate discoveries that not only empower patients and providers but help medical, biotech and pharmaceutical companies transform ideas into innovations.
Overview:
Reviews, evaluates, and maintains data for computer processing. Analyzes data for system performance and functionality. Works directly with users to resolve data conflicts. Recommends methods, tools, or software to maximize performance.
Position Responsibilities and Expected Outcomes:
Work on complex data initiatives with broad impact and act as key participant in large scale software planning for the Technology area
Perform data analysis and modelling tasks within a data warehouse environment.
Experience on mainframe to analyze current code base and document the process
Perform SQL queries to analyze and troubleshoot issues.
Discover problems in data and applications and design solutions with engineering and product leadership.
Strategically collaborate and consult with internal partners to resolve highly risky data engineering challenges
Demonstrated ability to solve complex data engineering problems; end to end problem resolution and continuous improvement mindset.
In-depth knowledge and experience with Data Engineering essentials such as scripting languages, source control, workflow scheduling, relational and non-relational SQL, and development of complex data solutions
Required Qualifications:
5+ years of Data Engineering experience, or equivalent demonstrated
5+ years of relevant Python development experience
4+ years’ experience on mainframe COBOL JCL, Easytrive
Experience with Databricks , Spark, Hive, AWS EMR/S3, Data Stage or similar systems for performance.
Experience with AWS technologies like Lambda, S3
Familiarity with modern build pipelines, tools, CI/CD concepts
Experience in data modelling within a data warehouse environment
Desired qualifications:
ETL (Software agnostic) Experience
Databricks, Hive, Datastage and Oracle SQL Experience
Experience in query and/or SQL tuning
CI/CD Tool Experience
Experience working in an Agile Team
Understanding of SDLC Requirements
Knowledge on mainframe
License/Certification/Education:
Normally requires a B.S. Degree in Computer Science or related discipline, w/ 5 years of relevant experience.
Labcorp is proud to be an Equal Opportunity Employer:
As an EOE/AA employer, Labcorp strives for diversity and inclusion in the workforce and does not tolerate harassment or discrimination of any kind. We make employment decisions based on the needs of our business and the qualifications of the individual and do not discriminate based upon race, religion, color, national origin, gender (including pregnancy or other medical conditions/needs), family or parental status, marital, civil union or domestic partnership status, sexual orientation, gender identity, gender expression, personal appearance, age, veteran status, disability, genetic information, or any other legally protected characteristic. We encourage all to apply.
For more information about how we collect and store your personal data, please see our Privacy Statement.","$123,292 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1978,$10+ billion (USD)
"Amazon Web Services, Inc.
3.8",3.8,"Seattle, WA","Sr. Data Engineer, WWFE - Analytics, Reporting, Operations and Governance","7+ years of data engineering experience
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
Experience with SQL
Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
Experience mentoring team members on best practices
Knowledge of professional software engineering & best practices for full software development life cycle, including coding standards, software architectures, code reviews, source control management, continuous deployments, testing, and operational excellence
Amazon Web Services (AWS) is obsessed with ensuring the success of our customers. To this end, AWS is building the industry’s best-trained sales force. As the number of AWS sellers and cloud services continues to expand rapidly, AWS is re-investing how to train and enable its sellers. AWS’s Worldwide Field Enablement (WWFE) organization is driving this transition by pioneering highly innovative, multi-modal enablement that is able to support our field’s diverse learning styles.
WWFE is looking for a results-oriented Sr. Data Engineer to help AWS build our next generation enablement data management solution. WWFE's data solutions helps us to understand 1/ what training each of AWS’s >20K sellers consume every day and 2/ how this training impacts their business results and productivity.

Key job responsibilities

The Senior Data Engineer will:
Collaborate with WWFE's business leaders and economists to identify data engineering requirements
Lead the technical design of WWFE's reporting, analysis and data management solutions
Collaborate with AWS’s Business Technology & Solutions team to leverage best practices and partner on solution designs
Lead and coach junior data engineers on the best practices
Build robust and scalable data integration (ETL) pipelines using SQL/EMR/Python
Work with other AWS Region Services Business Intelligence Teams to integrate into existing data warehouses and plan for scaling into data lake solutions
Design, develop and maintain scaled, automated, user-friendly systems that supports Business Intelligence Engineers to build reports and dashboards
Improve overall data architecture using innovative approaches and new processes from AWS stack or open source
Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation

A day in the life
Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

About the team
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.
We are dedicated to supporting our new team members. Our team has a broad mix of experience levels and Amazon tenures, and we’re building an environment that celebrates knowledge sharing and mentorship.
Our team also puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren’t focused on how many hours you spend at work or online. Instead, we’re happy to offer a flexible schedule so you can have a more productive and well-balanced life—both in and outside of work.

We are open to hiring candidates to work out of one of the following locations:

Arlington, VA, USA | Seattle, WA, USA

Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
Experience operating large data warehouses
6+ years of data engineering, database engineering, business intelligence or business analytics experience
Experience providing technical leadership and mentoring other engineers for best practices on data engineering
Experience with MPP databases such as Amazon Redshift
Experience leading large-scale data warehousing and analytics projects leveraging AWS technologies including Redshift, S3, Glue, EMR, EC2, Data-pipeline and other big data technologies
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $123,700/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$123,700 /yr (est.)",Unknown,Subsidiary or Business Segment,Information Technology,Information Technology Support Services,2006,$10+ billion (USD)
"PODS
3.5",3.5,"Clearwater, FL",IT Data Engineer III (Lead),"The successful candidate will demonstrate:
Expertise in DW concepts, think Bill Inmon & Ralph Kimball
Strong analytical abilities and creative problem solving
Work with data stakeholders (technical as well as end users) to understand business requirements and implement database solutions for diverse problems. We do not leverage a Business Analyst as a go between
Ability to work independently with general direction and flexibility in a fast-paced environment
Good organization and excellent communication skills across cultures in English
Integrity and a positive attitude, especially while handling stressful situations
Research viable technical and/or non-technical solutions, evaluate new technology and advocate, influence, and build consensus for innovations that satisfy business needs
Required Qualifications:
BS/BA degree, preferably in computer science or related field; or business administration, or mathematics
10+ years IT experience, including 5+ years in DW Development. Advanced background in Ansi SQL on Snowflake, Teradata or Redshift or equivalent
Experience in data analysis and database architecture, maintenance, and support
Expertise in cloud data warehouse platforms such as Snowflake
Experience in Python pulling data from APIs; or experience in other integration frameworks pulling data from SaaS applications in the cloud
Hands-on implementation experience building a Data Warehouse
Experience in all aspects of Agile SDLC, and end to end participation in a project lifecycle, especially delivering modular system change with a high degree of testing, change management, automation and cutover
Experience with Tableau or Power BI is beneficial
Experience working with resources over Microsoft Teams or similar technology to collaborate","$103,447 /yr (est.)",1001 to 5000 Employees,Company - Private,Personal Consumer Services,Consumer Product Rental,1998,$1 to $5 billion (USD)
"Bank of America
4.0",4.0,"Pennington, NJ",Assistant Vice President; Data Engineer II,"Job Description:
At Bank of America, we are guided by a common purpose to help make financial lives better through the power of every connection. Responsible Growth is how we run our company and how we deliver for our clients, teammates, communities and shareholders every day.
One of the keys to driving Responsible Growth is being a great place to work for our teammates around the world. We’re devoted to being a diverse and inclusive workplace for everyone. We hire individuals with a broad range of backgrounds and experiences and invest heavily in our teammates and their families by offering competitive benefits to support their physical, emotional, and financial well-being.
Bank of America believes both in the importance of working together and offering flexibility to our employees. We use a multi-faceted approach for flexibility, depending on the various roles in our organization.
Working at Bank of America will give you a great career with opportunities to learn, grow and make an impact, along with the power to make a difference. Join us!
RESPONSIBILITIES:
Participate in design, development, and implementation of architectural deliverables, to include components of the assessment and optimization of system design and review of user requirements.
Contribute to the determination of technical and operational feasibility of solutions.
Develop prototypes of the system design and working with database, operations, technical support, and other IT areas as appropriate throughout development processes.
Serve as a fully seasoned/proficient technical resource; providing tech knowledge and capabilities.
Analyze the risk and impact on existing financial solutions, enforcing security guidelines on business solutions.
Review legacy code using languages such as Perl and Python, to enhance processes, provide upgrades and deploy new features for Network File System based application.
Employ RHEL servers to manage, configure, and troubleshoot operating system issues.
Utilize Agile development processes and tools, such as GIT, Horizon, Jira and Confluence to support prioritization, development and testing of new features and capabilities.
Use tools such as Alteryx tool for large scale data integration.
Use Oracle SQL and Splunk knowledge to analyze, document data issues and data enhancements related to capacity concern or client configuration irregularities.
Use backend metadata databases such as PostgesDB for Vendor supported/managed applications.
REQUIREMENTS:
Bachelor's degree or equivalent in Computer Science, Computer Information Systems, Management Information Systems, Engineering (any), Information Management or related; and
5 years of progressively responsible experience in the job offered or a related IT occupation.
Must have 5 years of experience in each of the following:
Reviewing legacy code using languages such as Perl and Python, to enhance processes, provide upgrades and deploy new features for Network File System based application;
Employing RHEL servers to manage, configure, and troubleshoot operating system issues;
Utilizing Agile development processes and tools, such as GIT, Horizon, Jira and Confluence to support prioritization, development and testing of new features and capabilities;
Using tools such as Alteryx tool for large scale data integration;
Using Oracle SQL and Splunk knowledge to analyze, document data issues and data enhancements related to capacity concern or client configuration irregularities; and,
Using backend metadata databases such as PostgesDB for Vendor supported/managed applications.
If interested apply online at www.bankofamerica.com/careers or email your resume to bofajobs@bofa.com and reference the job title of the role and requisition number.
EMPLOYER: Bank of America N.A.
Shift:
1st shift (United States of America)
Hours Per Week:
40","$98,539 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1904,$10+ billion (USD)
"KBS Solutions LLC
4.5",4.5,Remote,Sr. Data Scientist/Machine Learning Engineer - Generative AI,"Role: Senior Data Scientist- Generative AI
Location: 100% Remote
Client Office Location: Irving TX - Remote
Duration: 12+ months contract
Responsibilities
Build and deploy Gen AI-enabled applications using our tech stack
Fine-tune open source models and/or build telecom specific Generative AI models
Evaluate and make recommendations to use services provided by different vendors to speed time to market
Actively involve in ongoing AI training and refinement
Collaborate with cross-disciplinary teams - developers, other data scientist, data analysts, business
Monitor and correlate inputs and outputs, establish meaningful metrics
Lead and act as a technical liaison between business, executives and data science teams to deliver POC’s / pilot on need basis.
Keep up to date with technological developments and make recommendations for improvements
Requirements:
6+ years of experience in data science , with a focus on generative AI technology/data science
5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python)
Telecommunication domain experience is a plus
Strong analytical and problem-solving skills
Excellent verbal and written communication skills
Ability to work independently and as part of a team in a fast-paced environment
Hands on fine tuning AI models (SBERT, ScaNN, PaLM, ChatGPT, LLM)
Strong background in Natural Language Processing, including experience with text representation, language modelling, sequence-to-sequence architectures, and semantic understanding
Technical skills : Data science, Python, Javascript, MongoDB, AWS/GCP, API Programming
Job Type: Contract
Pay: $359,008.11 - $1,613,467.19 per year
Experience level:
11+ years
8 years
Schedule:
8 hour shift
Experience:
Python: 7 years (Preferred)
Genrative AI: 2 years (Required)
Work Location: Remote",#N/A,51 to 200 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Fusion Health
4.1",4.1,"Woodbridge, NJ",Data & Analytics Engineer,"Fusion Health is seeking a bright, motivated, and outgoing Data & Analytics Engineer to join our Engineering team at our Woodbridge, NJ office location! This candidate will participate in dynamic and challenging projects to change how the company organizes, consumes, and delivers data in all forms. We are looking for an ambitious team player who is target driven and passionate about achieving results.

About Us:

Fusion Health was founded in 2006 and provides HealthTech solutions that proactively manage the quality of life for underserved patients managed by government agencies such as Public Health, Rehabilitation & Corrections. Our mission is to deliver impactful solutions that drive efficiency for clinicians in movement-restricted communities.

Fusion Health has been recognized by INC as one of the fastest-growing private companies in the United States for four consecutive years, #38 in the NY Tri-State area, and #8 in New Jersey. Fusion has also been recognized by Deloitte on its Fast 500 list of fastest-growing technology companies in the United States.

Building a quality team takes a lot of work. Our founder and CEO, Bryan Jakovcic (EY Entrepreneur of the Year) works hand in hand with our Human Resources team and we are searching the globe for the Fusionite of tomorrow. Our team is among some of the brightest and most inspiring in the industry. To boot, they love working at Fusion so much that we have been certified as a Great Place to Work by Fortune!

We pride ourselves on our modern company culture as a vibrant and diverse group. Guided by our shared values, we thrive in an environment where collaboration and openness are valued. Our headquarters is located in Woodbridge, New Jersey, just minutes from several major train stations. Lovingly known as HQ4, it features high-tech open working spaces, multiple meeting areas, café, a gym, and an arcade! Our satellite office locations are also equipped with state-of-the-art technologies and similar amenities.

A positive culture is a core fundamental at Fusion. While we are looking for the brightest minds around, ideal Fusionites should be strong problem solvers, be able to work independently, have great communication skills, and have a fun/energetic personality.

To date, Fusion has phenomenal retention of our team members. Our fundamental belief is that employee satisfaction is critical to achieving our mission/vision, so we provide competitive compensation, professional development, career advancement opportunities, and a supportive team-based atmosphere. We also provide a full range of health-related benefits, including medical, dental, vision, life insurance, and 401K.

We also offer numerous work-life enhancements such as:
Work From Anywhere (WFA) program (up to 100 days WFA per year)
20 PTO Days to start, with an additional PTO day per year for each year you are a Fusionite (up to 30 PTO days max/year)
Business casual dress code
Easy-going corporate structure. We hate red tape.
Accessible leadership.
A REALLY COOL OFFICE (Click for Photos)

This role looks like...

The Engineering team is vital to our organization’s mission and growth. This role will provide assistance with a multitude of projects that will enhance the Engineering team’s success, such as:

Define relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies
Created a wide variety of reports and dashboards all suiting different purposes
Convert legacy reports from SSRS to modern BI solution
Design, develop, maintain data warehouse structure with data views
Create scalable data pipelines from a variety of sources and a variety of formats
Working with stakeholders including data, design, product, and executive teams and assisting them with data-related issues
Assist development engineers with embedded reporting solution
Monitor and evaluate the performance of data models and algorithms, implementing improvements as necessary
Assist in the development of test cases, test scripts and solutions to test and validate the results of the ETL processes to ensure that all business and performance requirements are met
Writes database documentation, including data standards, procedures, and definitions for the data dictionary
Very strong background in a disciplined software development life cycle (SDLC) process with excellent analytical, programming, and problem-solving skills.

You could be a great fit if...

We believe in harnessing diverse talents and perspectives, and if you believe you have what it takes to excel in this role, we want to hear from you. We look forward to reviewing your application if you have the following qualifications and experience:
Bachelor’s degree in data science or equivalent experience
5+ years of IT experience in data analytics and database engineering
Experience with reporting/analytic tools (e.g. SSRS, Crystal Reports, PowerBI, Tableau, Qlik)
Familiarity with business analytics/intelligence from both database (STAR/SNOWFLAKE) and structures (OLAP/OLTP)
Experience with ETL/ELT tools (e.g. SSIS, Talend, Azure Data Factory)
3+ years' work experience with systems development methodologies
Experience with transactional AND data warehouse structures
Experience with Agile processes and tools (e.g. Jira)
Experience with embedded analytics in applications
Familiarity with development tools (e.g. Visual Studio) and languages (e.g. C#)

Additional Details:

This is an on-site (hybrid), full-time, salaried position at our Woodbridge, NJ office location. Our normal hours of operation are Monday – Friday, 8:00 AM – 4:00 PM.
Salary is DOE, please provide your salary expectations in the application
This position description is not intended to be exhaustive, and other duties may be assigned as they arise.
It is not expected that applicants have any familiarity with Fusion’s proprietary applications, Healthcare software, or Corrections/Public Health business processes. Qualified candidates will be able to demonstrate related experience and transferable skills that will work well with the Fusion team.
At this time, this position is not eligible for employment sponsorship.
Fusion is an equal employment opportunity employer.


For Internal Use only: In reference to our Employee Referral Program, this opening is ‘Level 4’.","$95,067 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,#N/A,Unknown / Non-Applicable
"Intone Networks
4.3",4.3,Remote,Snowflake Data Engineer,"Notes • This Person will sit with research and development team for an Investment company • Must also have background/knowledge in finance. o Has to be familiar with lingo from perspective of financial data • Looking for engineer who understand Snowflake and SQL yet has ability to do enhancements. • Someone that knows Python and can write SQL. • 5 years of hands-on experience working with Big Storage Data Bases in a professional environment • Design and implement novel query optimization or distributed data processing algorithms. • Develop and optimize ETL processes to extract, transform, and load data into Snowflake moving to SQL. • Certifications in Snowflake or related technologies would be a plus.",#N/A,201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,$5 to $25 million (USD)
"Johnson & Johnson
4.2",4.2,"New Brunswick, NJ",IT Lead Data and Analytics Engineer,"Johnson & Johnson Technology (JJT) is currently recruiting for IT Lead, Corporate Business Technology Data Analytics & Integration position primarily located in New Brunswick, NJ.
Caring for the world, one person at a time has inspired and united the people of Johnson & Johnson for over 125 years. We embrace research and science - bringing innovative ideas, products and services to advance the health and well-being of people. Employees of the Johnson & Johnson Family of Companies work with partners in health care to touch the lives of over a billion people every day, throughout the world.
Johnson & Johnson is the world's most comprehensive and broadly-based manufacturer of health care products, as well as a provider of related services, for the consumer, pharmaceutical, and medical devices markets. There are more than 265 Johnson & Johnson operating companies employing approximately 132,200 people and with products touching the lives of over a billion people every day, throughout the world. If you have the talent and desire to touch the world, Johnson & Johnson has the career opportunities to help make it happen.
Thriving on a diverse company culture, celebrating the uniqueness of our employees and committed to inclusion. Proud to be an equal opportunity employer.
Do you seek big, complex, ambiguous problems? Are you passionate about having a meaningful impact on the experience, effectiveness, and efficiency of your colleagues through innovative technology solutions? Do you want to be a part of a 133-year-old startup?
The Data Platform Lead Engineer is responsible for overseeing the technical development, management, and strategic direction of the organization's data platform. This role involves collaborating with cross-functional teams, product leaders, and stakeholders to ensure the data platform aligns with business objectives and supports data-driven initiatives. The Data Platform Lead Engineer plays a key role in driving the product roadmap, enhancing technical capabilities, and fostering strong business relationships.
Responsibilities
Collaborate closely with business and stakeholders to understand their data requirements, challenges, and opportunities.
Drive the technical development and evolution of the data platform's product roadmap.
Collaborate with cross-functional teams, product leaders, and stakeholders to ensure the data platform aligns with business objectives and supports data-driven initiatives.
Lead the design, architecture, implementation, and maintenance of the data platform.
Provide technical expertise and guidance to a team of data engineers, ensuring high-quality development and best practices.
Prioritize technical features, enhancements, and projects based on technical impact and alignment with business needs.
Evaluate and recommend tools, technologies, and services that enhance the data platform's technical capabilities.
Ensure efficient data processing, storage, and retrieval while maintaining data quality and accuracy.
Stay informed about industry trends, emerging technologies, and best practices in data engineering and platform development.
Identify opportunities for technical innovation and improvements to the data platform.
Utilize Agile methodology to work with business partners to define and translate business needs into user stories, prioritize product backlog, and define sprint plans.
Cultivate collaborative, healthy, inclusive, and credo-based culture of highly engaged, high performing teams by modeling credo values and valuing diverse perspectives.
Qualifications
A minimum of a Bachelor’s degree is required, preferably in technology or engineering discipline. A master’s degree is preferred.
5+ years in IT space specializing in Data Management, Analytics and Insights generation
Proven experience in data platform engineering, data architecture, or related technical leadership roles.
Proficiency in programming languages (e.g., Python, Java, Scala) and data engineering frameworks
Experience with Data Platform Technologies such as AWS RDS/Redshift, Databricks, and Snowflakes.
Excellent communication and collaboration skills to work effectively with technical and non-technical stakeholders.
AWS Associate Developer / Architect certification is a plus
Practical experience using Agile development methodology is preferred.
Experience collaborating cross-functionally within a matrixed IT organization is required.
Demonstrated track record of delivering successful data and analytics products and solutions is required.
Excellent verbal and written communication skills are required.
The ability to work with minimal supervision and achieve results in a fast-paced environment is required.
At Johnson & Johnson, we’re on a mission to change the trajectory of health for humanity. That starts by creating the world’s healthiest workforce. Through cutting-edge programs and policies, we empower the physical, mental, emotional, and financial health of our employees and the ones they love. As such, candidates offered employment must show proof of COVID-19 vaccination or secure an approved accommodation prior to the commencement of employment to support the well-being of our employees, their families and the communities in which we live and work. For more information on how we support the whole health of our employees throughout their wellness, career and life journey, please visit www.careers.jnj.com .
Salary
For US based candidates, the base pay range for this position is $101,500 USD to $163,300 USD. Some U.S. states have recently instituted certain pay transparency disclosure requirements. This means that for jobs posted by J&J corporate legal entities in Colorado, Connecticut, Nevada, New Jersey, and New York (collectively the “Enumerated States”). If the job can be performed in one of these identified states or the job can be performed remotely, the posting must include the anticipated pay range for the position in question, and in certain circumstances, benefits information.
Bonus
The Company maintains highly competitive, performance-based compensation programs. Under current guidelines, this position is eligible for an annual performance bonus in accordance with the terms of the applicable plan. The annual performance bonus is a cash bonus intended to provide an incentive to achieve annual targeted results by rewarding individual and the corporation’s performance over a calendar/ performance year. Bonuses are awarded at the Company’s discretion on an individual basis.
Benefits
Employees may be eligible to participate in Company employee benefit programs such as health insurance, savings plan, pension plan, disability plan, vacation pay, sick time, holiday pay, and work, personal and family time off in accordance with the terms of the applicable plans. For additional general information on company benefits, please go to:
https://www.careers.jnj.com/employee-benefits
Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.","$132,400 /yr (est.)",10000+ Employees,Company - Public,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,1887,$10+ billion (USD)
"Coveros, Inc.
3.4",3.4,"Fairfax, VA",Data Engineer,"A Great Place to Share Your Passion and Make a Difference
Coveros helps organizations modernize their software development process by embracing agility, while integrating application security and software quality into the software lifecycle. We provide consulting, coaching, and learning opportunities in Agile, DevOps, AppSec, and Test Automation to enterprises, teams, and individuals. We aim to be Trusted Advisors to our clients who are undergoing change.
Culture at Coveros
As a remote-first company, we provide a stimulating, friendly, and casual work environment, where we live our core values of Client Focused Delivery, Openness, Shared Success, and Building Strong Relationships. In an atmosphere of continuous growth and learning, we invite employee input and employ active mentoring.
Coveros is an equal opportunity employer, dedicated to a policy of non-discrimination in employment on any basis including age, sex, color, race, creed, national origin, religion, marital status, sexual orientation, political belief, or disability.
The Opportunity
Coveros employees share a passion for helping organizations advance and accelerate their software development and security processes. We celebrate great work and teammates who consistently give their best. Our remote team of collaborative experts is expanding and adding an experienced, quality-obsessed Data Engineer as its newest member.
As an exceptional data engineer, you will fulfill a core position on our consulting team. Through your dedication and knowledge, you will help clients replace time-consuming, manual processes in order to make informed, real-time, intelligent decisions.
For a skilled and dedicated data nerd who abhors mediocrity, this opportunity positions you to lead the team in discovering truth and finding meaning in data. An ideal addition to our team is a hands-on engineer who is proficient in data management and governance standards. Equally important, we seek someone with strong interpersonal skills who is comfortable working cross-functionally across internal teams as well as directly with end users and client platform SMEs.
A curious and eager problem solver will thrive in our environment where we value the delivery of high-quality data solutions. You shine when figuring out complex problems and providing smart, simple solutions to them. And always, while multiple answers to a problem may exist, you capably lead the team through constructive dialogue to implement the best path forward.
Qualifications
US Citizenship is required – Due to the nature of this role supporting U.S. government organizations, individuals who are not U.S. Citizens will not be considered.
Required
Bachelor's degree in Computer Science, Mathematics or related technical field
3-5 years of experience in programmatically transforming data
RDBMS experience
Advanced SQL programming experience
Python programming experience
Knowledge and use of Apache Spark
Proficient use of common data formats such as CSV, XML, and JSON
Strong analytical ability and attention to detail
Ability to work independently with little supervision
A drive to create sustainable solutions that solve hard problems
Nice-to-Have
Experience using Amazon Web Services
Experience with OpenSearch
Experience automating ETL pipelines
Hands-on knowledge working with large amounts (multiple terabytes) of data
Experience in (or exposure to) the nuances of a startup or other entrepreneurial environment
Any specific experience in MLOps is a plus!
Responsibilities
Define and lead the data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage.
Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository.
Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison, and classification.
Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts.
Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency.
Work across functional teams to understand advanced statistical, machine learning, and text processing models and incorporate them into the existing data engineering infrastructure.
Actively collaborate with the DevOps team to automate processes where possible.
Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.
Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures and, using non-technical language, articulate techniques and results.
We firmly believe that past performance is the best indicator of future performance. If you thrive in a fast-paced environment, have a bias toward action, and care about solving technical problems in the national security domain, apply today for consideration.
Coveros is a melting pot of seasoned IT and business professionals from Fortune 500 and leading consulting companies who deliver high value on challenging client engagements. We hire great people and provide room and support for employees' professional growth. For talented computer scientists and software engineers who share our passion for software, joining Coveros provides an opportunity to work alongside and to learn from brilliant, technical software engineers.
We believe that employees are our greatest asset. Our business model and benefits package reflect that belief.
Competitive base salaries
Company-wide profit sharing plan
401K with matching percentage
Comprehensive health benefits, including dental and vision
Generous paid time off and holidays plan
Basic Life & Personal Accident Insurance and Disability Insurance
Voluntary Life and Personal Accident Insurance
Tuition Reimbursement, plus comprehensive competency-based online skill development training programs
Adoption Assistance
Apply today and move toward a Coveros career where management values you and actively looks to help you advance your skills.
By submitting your application, you are also agreeing to receive future company news, offers, and product communications from Coveros/TechWell. You may unsubscribe at anytime.","$94,726 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Software Development,2008,Unknown / Non-Applicable
"Linktree
3.2",3.2,"San Francisco, CA",Staff Data Engineer,"The Role

Linktree’s Data Engineering team is at the forefront of transforming the way Linktree leverages data, working closely with the insights, data platform product and marketing teams to become truly data driven.

As a Staff Data Engineer at Linktree, you will be the driving force behind scaling how data is consumed at Linktree. Not only will you be modelling some of our most important data sets to gain insights, such as the data that helps us understand the driving factors behind the success of our product or our revenue, we take self-service one step further. You will also build the platform that can be used by Data Analysts, Marketers, Engineers and anyone else who is interested to model their own data to fit their specific needs and not be dependent on a data team.

This is your opportunity to make an impact at Linktree and push the boundaries of what is possible with data self-service!

Location Expectations: Hybrid. We're growing our team in LA and the Bay Area, and plan to have offices in both locations. We expect team members to come into their respective office 2x/week.

What You Will Do
Build the platform that allows data analysts, product managers, marketers and other heavy data users to model their own data as well as making that data available in tools of their choosing, such as product analytics tools, BI tools, an experimentation platform or our CRM system.
Continue leading the transformation to make data a first-class citizen in software development at Linktree. This includes defining standards and providing guidance to product teams who emit the vast majority of our data.
Build and maintaining robust, efficient and integrated data models. We don’t believe that Analytics Engineers should be painfully cleaning up after others and deal with bad data all day long, if you are faced with a “garbage in, garbage out” situation, you will work with the engineers in our product teams to come up with a better way to emit the raw data.
You will also provide support to other data users including peer-reviews, training and acting as a data modelling/SQL/dbt SME across various business initiatives.

What We Are Looking For
A platform mindset. Data teams main focus is not to do repetitive data transformation and integration jobs for others. The team builds the infrastructure and tools that allows Linktree to perform these tasks at scale by enabling all teams to perform data-related jobs themselves.
You understand data-driven product development and have experience with the typical tools used by high-performing product teams, such product analytics, experimentation, but also general purpose BI tools.
Experience in data modelling with the ability to translate business requirements to fit for purpose data products for critical use-cases (reporting to the board, understanding key drivers of product success).
Experience operating at scale. You have worked on data systems that power a product that serves hundreds of millions of active users.
Proficient in SQL and experience with working on cloud-based warehouses (experience in Snowflake is a bonus), as well as working with DBT.

Linktree is committed to providing a competitive compensation package. Our cash compensation amount for this role is targeted at $175,000-$225,000 in the San Francisco Bay or Los Angeles area. Final offer amounts are determined by multiple factors including candidate expertise, the scope of role and level, and may vary from the amounts listed above.
P.S. If you don’t tick every box in this ad, please don’t rule yourself out. We take pride in inclusion and hiring incredible human beings with great potential over ticking boxes – so if this role resonates with you, hit that apply button!

Where and How We Work
We are a global and diverse group offering a truly flexible and family friendly work environment. Kids, pets, and the occasional delivery person are all actively encouraged to appear on our Zoom screens. All of us at Linktree work either fully remote or a hybrid ""remote, but in-office sometimes"" approach.

We currently have offices in Melbourne, Sydney and LA, but our team is spread across Australia, United States, and New Zealand. As our team approaches 200 people, our company will be 10x the size we were in 2020.

We offer autonomy and flexibility in how you structure your days and weeks. There will be the need for some collaboration outside of a ""normal"" 9-5 being a global company, but we aim to work asynchronously where possible.

Our Culture and Benefits
Linktree's company culture and values are based around collaboration, diversity, inclusion, and flexibility. Those are all nice words but to give you some more specific examples:

We recognize that our teammates are individually unique and have designed our benefits with this in mind. Each employee has an annual allowance to use on things like (but not limited to) fitness memberships, development courses, childcare, travel, charitable donations, pet insurance, home office set up - the choice is yours!
We provide top-flight medical, dental, vision, disability and life insurance - we cover 100% of your monthly premiums (and 80% for your dependents).
401k matching up to 6%.
Employee Stock Option Program - we want each and every employee to share in the company’s success as we go further together.
To learn more about our benefits, including our parental leave program, volunteering leave, DE&I initiatives, and more, click here!

Our Story
We're on a mission to empower anyone to curate and grow their digital universe. We created the ""link in bio"" category and are trusted by some of the world's biggest brands and celebrities including TikTok, The UN Environmental Program, The White House, F1, Manchester United, Selena Gomez, Alicia Keys, and Dwayne “The Rock” Johnson. With a flexible work environment and a team spread across multiple time zones, we offer autonomy and flexibility. Join us in empowering people to control their online presence!

At Linktree, we celebrate and support everyone’s perspective and background, and we’re proud to be an equal opportunity workplace. We aim to foster a diverse and inclusive environment where all team members have a sense of belonging, because we believe in going further together. Linktree welcomes all people regardless of sex, gender identity, race, ethnicity, disability, pregnancy, age, or other lived experience. If you require accommodations to fully participate in our opportunities, please don't hesitate to reach us at recruiting@linktr.ee – your needs are important to us.","$171,881 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Department of Financial Protection and Innovation
3.3",3.3,"Sacramento, CA",Information Technology Specialist II (Senior Data Engineer),"About the DFPI
The Department of Financial Protection and Innovation (DFPI) protects consumers and oversees financial service providers and products. The DFPI supervises the operations of state-licensed financial institutions, including banks, credit unions and money transmitters. Additionally, the DFPI licenses and regulates a variety of financial service providers, including securities brokers and dealers, investment advisers, payday lenders and other consumer finance lenders. The DFPI offers benefit packages, competitive salary, a robust training program and opportunities for advancement.
Position Details
Job Code #:
JC-392093
Position #(s):
410-113-1414-XXX
Working Title:
Senior Data Engineer
Classification:
INFORMATION TECHNOLOGY SPECIALIST II
$7,893.00 - $10,894.00
# of Positions:
1
Work Location:
Sacramento or San Francisco
Job Type:
Permanent, Full Time
Job Description And Duties
The Department of Financial Protection and Innovation is recruiting for one, permanent, full-time Information Technology Specialist II (ITS II), Senior Data Engineer position within the Division of Information Technology, Planning and Portfolio Management Office. This position will be located in either San Francisco or in the Sacramento office. This recruitment may be used to fill subsequent vacancies within the next 180 days.
Under the general direction of the Director of Enterprise Architecture, the ITS II will serve as a Senior Data Engineer and perform a wide variety of tasks requiring subject matter expertise in data interchange, cleaning, and integration. Moreover, the candidate will be expected to support all aspects of the department’s business intelligence infrastructure.
TELEWORK
This position is eligible for full-time telework under Government Code 14200 for eligible applicants residing in California. Remote-centered telework employees may be required to report in person to their assigned office (Either Sacramento or San Francisco) and/or offsite events or locations, as determined by management, and will be required to utilize a shared workspace or “hotel” when working in the office.
Final Filing Date: 10/4/2023
Examination Information
Applicants will need to take and pass the online Information Technology Specialist II exam/assessment to be eligible to apply for Information Technology Specialist II positions. Please visit: https://www.calcareers.ca.gov/JOBSGEN/2PBBS.PDF
Consider a rewarding and challenging career with the DFPI!
DFPI Website: www.dfpi.ca.gov
Job Types: Full-time, Permanent
Pay: $7,893.00 - $10,894.00 per month
Benefits:
Dental insurance
Health insurance
Paid time off
Vision insurance
Experience level:
5 years
Schedule:
Monday to Friday
Work Location: Hybrid remote in Sacramento, CA 95834","$9,394 /mo (est.)",1 to 50 Employees,Government,Government & Public Administration,State & Regional Agencies,#N/A,Unknown / Non-Applicable
"Moen
4.1",4.1,"North Olmsted, OH",Data Operations Engineer,"Company Description

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here.

Job Description

We are seeking a talented Data Integration Engineer to join our newly established Data and Analytics organization within the Data Engineering team under Data Platforms. As a key member of our dynamic team, you will play a crucial role in advancing our data transformation and integration initiatives across a variety of ERPs, including SAP, Oracle E-Business Suite (EBS), Oracle JD Edwards (JDE), SQL Server, and others. If you're passionate about solving complex technical challenges, collaborating with cross-functional teams, and contributing to cutting-edge data solutions, this role is perfect for you.

Enjoy remote work with the option to engage at our North Olmsted office. This role offers career growth and leadership opportunities.

RESPONSIBLIITIES:

What you will be doing
Drive Innovative Data Integration: Collaborate within a small yet diverse team to lead the migration of data from multiple ERPs and SQL Server, utilizing Extract and Load tools. Leverage your technical expertise to ensure seamless data movement and integration.
Maintain and Enhance Legacy Systems: Utilize your expertise to work with existing legacy systems and reports. Engage in reverse engineering to understand and improve these systems incrementally, applying your technical acumen to patch, optimize functionality, and migrate data pipelines to the Modern Data Platform (MDP).
Clean Programming, Self-Documenting Code, Version Control, and CI/CD: Adhere to clean programming skills and self-documenting code practices, while utilizing GIT version control for codebase management and contributing to automation through CI/CD pipelines for streamlined deployments.
Cross-functional Collaboration, Problem-Solving, and Teamwork: Collaborate closely with both on-shore and offshore team members, stakeholders across the country and world, fostering teamwork, a 'we got this' mentality, and effective technical problem-solving.
Orchestrate and Enhance Processes: Contribute to the continuous improvement of data integration processes, orchestrating workflows optimal efficiency and reliability.


Hiring Pay Range: $100,000 - $154,000

Actual pay will vary based on qualifications and other factors

Qualifications

QUALIFICATIONS:

BASIC QUALIFICATIONS:


Experience: 5+ years of experience working with data integration and transformation, including a strong understanding of SQL for data querying and manipulation.
Technical Proficiency and Problem-Solving: Deep understanding of data integration tools and methods, coupled with a proven ability to troubleshoot complex technical challenges.
Communication and Agile Experience: Excellent communication skills for translating technical concepts to non-technical stakeholders, with comfort in Agile methodologies and project management tools.

PREFERRED QUALIFICATIONS:
Education: Bachelor's degree in Computer Information Systems, Computer Science, or related field.
Cloud Data Warehousing Exposure: Experience with Snowflake or comparable cloud based data systems and tools.
Source Systems: Exposure to multiple ERPs, especially SAP, Oracle EBS, Oracle JDE, and others.
SQL Expertise: Proficiency in SQL, especially in managing data systems.
Clean Programming Skills: Strong adherence to clean programming practices, producing self-documenting code using coding best practices.

Very Nice to Have:
Experience in SAP BW, ABAP programming, SAP BPC (Business Planning and Consolidation), and/or Oracle BI (Business Intelligence) for data visualization and reporting.
Proficiency in GIT version control for codebase management, coupled with experience in automation through CI/CD pipelines.
Proficiency in Python, especially in implementing and orchestrating data integrations.

Join us in this exciting role to shape the future of our data integration initiatives, improve processes, and drive impactful results. Your expertise will contribute to the success of our growing Data and Analytics organization.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.","$127,000 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"Booking.Com
4.2",4.2,"Washington, DC",Software Engineer - Data & Machine Learning Platform,"It wasn’t so long ago that booking a trip to see the Eiffel Tower, stroll down New York’s iconic Madison Avenue or feel the sand between our toes on Copacabana Beach was simply a matter of a few taps on our smartphone. In fact, that’s what we do at Booking.com. We make it easier for everyone to experience the world. And while that world may feel distant right now, we are seeing a growth in domestic travel, as well as preparing for the anticipated traveling boom that is soon to return. Across our offices worldwide, we continue to innovate. To solve for some of the most complex challenges in travel and technology, and to plan for the exciting developments that lie ahead. With strategic long-term investments into what we believe the future of travel can be, we are opening up new career opportunities that will have a strong impact on our mission. We are united in the belief that our very human desire to explore the planet’s beauty and discover more about other people and cultures will endure. The world is waiting for us. Together, we will be ready.
At Booking.com, data drives our decisions. To do it more effectively we are building a platform for data analysts and scientists. Our Data and Machine Learning Platform is behind what makes Booking able to deliver personal experiences and you will be a part of its development helping to support multiple areas of the business as they use ML to tackle some of the hardest problems that we face, from detecting fraud to recommending which properties you should check for your next stay.
This is a fantastic opportunity for a seasoned software engineer to get involved in Data/ML/AI. The team you will join develops both the way data scientists interact with the Machine Learning Platform and built-in facilities for them to monitor performance and quality of their work. You will also have the opportunity to interact with data scientists as customers and will be involved in development all the way through the data consumed and produced by ML/AI models.
What you will be Doing:
As a Software Engineer at Booking’s Data and Machine Learning Platform, you are responsible for the development, performance, and scaling of our Data Privacy Platform which includes microservices, data pipelines and ML datasets. You will work independently and will also be responsible for making technical decisions within a team.
As a Backend Engineer in Booking.com you will:
Be part of a squad-like, multi-disciplinary team.
Own and lead technical aspects of every project you are a part of.
Design, build, and monitor scalable and high-performance services to solve business needs.
Set up necessary CI/CD pipelines, adding appropriate tests for your services.
Work mainly with Java, but also with Python and Scala.
Important aspects of the job include:
Rapidly developing and improving scalable, flexible, and high-performance API service.
Build and solve issues with data and data pipelines, prioritizing based on customer impact.
Experimenting with new tools and technologies to meet business requirements regarding performance, scaling, and data quality.
Act as an intermediary for problems, with both technical and non-technical audiences.
Supplying to a high scale, complex, world renowned product and seeing real-time impact of your work on millions of travelers worldwide.
Promote and drive impactful and innovative engineering solutions.
Technical, behavioral and interpersonal competence advancement via on-the-job opportunities, experimental projects, hackathons, conferences, and active community participation.
Take initiative to address the larger technical needs of the product you work on and always keep the customer at the center of everything you do.
Advocate for best engineering practices within the team.
Contribute to the growth of Booking.com through interviewing, on-boarding, or other recruitment efforts.
Represent Booking.com values, both within the company and in the external community.
What We are Looking For:
We are looking for driven Developers who enjoy solving problems, who initiate solutions and discussions and who believe that any challenge can be scaled with the right mindset and tools.
We have found that people who match the following requirements are the ones who fit us best:
Minimum of 3 years software development experience; using 2 or more server side programming languages. Preferably Java, Python, Scala, C# or C++.
Proficiency with Git and remote debugging of applications.
Previous experience with distributed systems (e.g. microservice architectures).
Practical experience with containerized application deployment systems, particularly Kubernetes and Docker.
Demonstrable experience with Relational databases (e.g. MySQL).
Demonstrable experience with NoSQL and distributed databases (e.g. Cassandra, MongoDb, ElasticSearch etc).
Demonstrable experience with distributed event platforms and messaging systems (e.g. kafka) is a plus.
Proven experience in owning and leading technical projects.
Experience with BigData or ML systems is a significant plus (Spark, Hadoop, Flink, Airflow).
Experience working with Cloud technologies (AWS, GCP, Azure etc.)
Experience with infrastructure-as-a-code technologies (e.g. Terraform, Ansible etc.) is a plus.
Preferably a university degree in Mathematics or Software Engineering.
Excellent communication: written and spoken (with English as the main language across the organization).
What we will Offer:
Contributing to a high scale, complex, world renowned product and seeing real-time impact of your work on millions of travelers worldwide.
Working in a fast-paced and performance driven culture.
Opportunity to utilize technical expertise, leadership capabilities and entrepreneurial spirit.
Promote and drive impactful and innovative engineering solutions.
Technical, behavioral and interpersonal competence advancement via on-the-job opportunities, experimental projects, hackathons, conferences and active community participation.
Competitive compensation and benefits package.
Salary Range for this role is: $176,300 - $193,900 annually
Should you require accommodation to meet the essential functions of this job, please let us know.
Pre-Employment Screening:

If your application is successful, your personal data may be used for a pre-employment screening check by a third party as permitted by applicable law. Depending on the vacancy and applicable law, a pre-employment screening may include employment history, education and other information (such as media information) that may be necessary for determining your qualifications and suitability for the position.","$185,100 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1996,$1 to $5 billion (USD)
"Lighthouse Document Technologies Inc
4.1",4.1,Remote,Data Operations Engineer,"What is special about Lighthouse?
Lighthouse is built on a foundation of unique, compassionate, highly driven individuals. We elevate the strengths and talents of those around us while leveraging opportunities for growth. We offer the experience of solving complex problems while continuing to grow multiple facets of your career. Lighthouse is where innovation meets support and where collaboration is the key ingredient to success. We grow together and are stronger together.

What’s unique about this role?
The Data Operations Engineer role is part of the eDiscovery Custom Engineering team and focuses on creating quick-turn solutions that solve complex eDiscovery data problems utilizing modern software technologies. The team’s software solutions typically include interpreted language programs, complex scripts, SQL database queries, and light application development. This is an execution role responsible for planning, grooming, and developing the most efficient technology solution to meet internal and external client needs. The team functions as the next-level technical escalation to support the eDiscovery service delivery organization and involves quick-turn response and resolution. Solutions typically include automating and optimizing the execution of manual tasks, data manipulation tools (extract, normalize, transform, organize, query), integrating 3rd party technologies, and just-in-time custom eDiscovery client requirements. Timeframes are typically quick-turn and measured in hours, days, and weeks.

As a Data Operations Engineer, you must be a self-starter and have a talent for collecting information from many sources across the business and clients and pulling that information together to execute an efficient solution that meets the business needs.

What will this person do?
Create quick-turn eDiscovery solutions that solve client and operational needs with a primary focus on automating and optimizing complex manual tasks, data handling tools (extract, normalize, transform, organize, query), integrating 3rd party technologies, and just-in-time custom eDiscovery client requirements.
Responsible for the creation or modification of production-ready software applications and workflows from conception to completion in the most efficient and timely manner.
Solution creation includes designing, coding, debugging, and unit testing that meets internal and external client requirements.
Specify software and related workflow requirements to determine design feasibility within time and cost constraints.
Contribute to the planning and estimating software development timelines and accountable to deliver on the timelines by actively managing risks and changing requirements.
Provide execution escalation support for complex client requirements, software issues, root cause analysis, and investigation/remediation of complex technology problems.
Effective use of modern software development tools and techniques to create efficient and reliable algorithms with appropriate exception handling/fault tolerance.
Communicate and train on how to use newly developed solutions as needed.
Perform other related duties as assigned.

Bring your passion and together we will shine. It would also be great if you have the following:
Bachelor’s Degree in Computer Science or equivalent experience/certification preferred.
2+ years professional development including strong competencies or expertise in Python, SQL, C#, .NET Core, Ruby, Agile, data analysis & transformation, and other modern programming techniques preferred.
2+ years of technical eDiscovery software solution experience including techniques for complex data extraction, transformation, mapping, and large dataset query development preferred.
Experience with Relativity, Nuix, and other proprietary eDiscovery software solutions is preferred.Strong analytical, troubleshooting, problem solving, and root cause analysis skills.
Effective written and oral communication skills
Understanding of e-discovery principles and best practices.
Exceptional attention to detail and strong organizational skills.
Willingness to adapt to a rapidly changing environment and changing requirements.
Ability to work in a fast-paced environment and manage competing priorities.
Ability to work flexible hours as needed.
Adherence to processes and procedures while remaining results-oriented and “thinking outside the box”.

Work Environment and Physical Demands
Duties are performed in a typical office environment while at a desk or computer table.
Duties require the ability to use a computer, communicate over the telephone, and read printed material, in a quiet and professional setting.
Duties may require being on call periodically and working outside normal working hours (evenings and weekends).

Lighthouse celebrates and thrives on diversity and is an Equal Opportunity Employer. We hire, train, and promote regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law. We welcome any talents and contributions you can bring to the team and are deeply committed to growing an environment where everyone can feel safe, is respected, and can show up as themselves. Come as you are!

As required by applicable pay transparency laws, Lighthouse complies with compensation disclosure requirements for roles that may be hired in locations under these requirements. Factors that may be used to determine your actual salary may include a wide array of factors, including: your specific skills and experience, geographic location, or other relevant factors. The salary range for this position may be tailored to be lower or higher in different talent markets.

The expected pay for this role will range from $66,000 to $115,000 per year. This role will be eligible to participate in an annual bonus or incentive program.

Lighthouse offers a quality comprehensive benefits package including, medical, dental, vision, and a 401k with company match. Company paid benefits also include Life & AD&D, short and long-term disability, telemedicine through 98point6, and other wellness plans. We offer a generous Flexible PTO program and paid volunteer days. Employees may also participate in voluntary insurance plans including accident, hospitalization, and critical illness plans as well as pet insurance.

As a trailblazer and catalyst for change, Lighthouse rises to each opportunity to help our clients and our people do what they do best—shine.","$90,500 /yr (est.)",501 to 1000 Employees,Company - Private,Legal,Legal,1995,Unknown / Non-Applicable
"Adventist HealthCare
3.3",3.3,"Gaithersburg, MD","Data Engineer IV, Day Shift, Information Technology","Support Center

Adventist HealthCare seeks to hire an experienced Data Engineer IV who will embrace our mission to extend God’s care through the ministry of physical, mental, and spiritual healing.

As a Data Engineer IV you will:

Lead the creation and supports the ETL process to facilitate the on-boarding of data into the data warehouse and distribution of data across data stores from wide variety of sources using different ETL tools and technologies.
Lead the design and develop the physical and virtual Data warehouse table schemas, database, data marts for new and existent data sources for the business’s data warehouse.
Lead the development and maintenance of informative and actionable data visualizations and reports for analysis, problem solving, and business solutions that highlights relevant business trends and opportunities for improvement.
Lead all service operational tasks including but not limited to database setup, maintenance, configuration, programming, troubleshooting, debugging, testing, fulfilling support requests, resolving incidents, and managing problems.
Lead the creation and support of routine and ad hoc data load processes through database refreshes and updates.
Optimize data integration platform to provide optimal performance under increasing data volumes.
Lead the preparation and maintenance of comprehensive understanding of data warehousing and ETL application lifecycle, technical architecture, data, configuration, and operational support requirements.
Maintains detailed charts, diagrams, and flow charts outlining systems, hardware, interfaces, and configurations related to data warehousing, ETL jobs, Data visualization, Data analytics and other similar.
Provide expertise in the design and development of best practice for big data stacking, data warehousing, data lake, ETL architecture, data federation, virtualization, data modeling procedures, data visualization, and workflows including technical documents.
Lead the analytics support to generate insights in the form of dashboards, metrics, or reports for healthcare solutions including the collection of detail business analytics requirements from stakeholders and the development of standardized functional requirement documents.
Lead the preparation of presentations and demonstrates business intelligence solutions to end users.
Lead in the training of end users on new reports and dashboards
Assist in leading the preparation of documents related to data governance, definitions, key metrics, and sample reports, ensuring alignment and consistency in reporting across the organization and standardized data analytics, visualization, and business intelligence reports.
Lead the data Integration and data warehousing application portfolio support in the timely resolution of technology incidents while adhering to SLA prioritization and success measures including 24x7 on call support.

Qualifications include:

Bachelor’s degree in computer science, information technology, or a related field.
7+ years’ experience and knowledge of coding languages, including Java, XML, and SQL to extract data from various relational databases, application systems, flat files, XML documents, and load into data warehouses.
7+ years’ experience in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDW.
7+ years’ experience as an ETL developer using.
integration tools such as Talend and SSIS.
Experience working on cloud-based environment such as AWS or Azure.
Experience working with large scale.
Data warehouses and related technologies.
7+ years working on building meaningful data analytics, reports, and visualizations in health care environment.
Snowflake experience is preferred.
Experience in metadata management and related tools.
Advanced knowledge of database security, integrity, backup and recovery, and performance monitoring standards.
3 Years Supervisory Experience.
Preferred Cloud-Data Warehouse certification or ETL Certification or Data Visualization.
Experience with business intelligence software applications such as Tableau visualization, PowerBI, SQL servicer Management studio, IBM Cognos B.
Work Schedule:
Full Time Days
Monday - Friday
At Adventist HealthCare our job is to care for you.
We do this by offering:
Work life balance through nonrotating shifts
Recognition and rewards for professional expertise
403(b) retirement plan
Free Employee parking
Benefits Eligible Positions:
Competitive, comprehensive benefit plans [including health, employer-paid disability and life insurance, PTO]
Employer retirement contribution and match after 1-year of eligible employment with 3 year vesting
Ancillary benefits such as flexible spending, legal and pet insurance to meet the needs of employees and their eligible family members
Subsidized childcare at participating childcare centers
As a faith-based organization, with over a century of caring for the communities in the Maryland area, Adventist HealthCare has earned a reputation for high-quality, compassionate care. Adventist HealthCare was the first and is the largest healthcare provider in Montgomery County.

If you want to make a difference in someone’s life every day, consider a position with a team of professionals who are doing just that, making a difference.

Join the Adventist HealthCare team today, apply now to be considered!
COVID-19 Vaccination
Adventist HealthCare requires all applicants to be fully vaccinated for COVID-19 before commencing employment. Applicants may be required to furnish proof of vaccination and, if needed, may elect to be vaccinated at any community pharmacy or location offering COVID-19 vaccinations.
Tobacco and Drug Statement
Tobacco use is a well-recognized preventable cause of death in the United States and an important public health issue. In order to promote and maintain a healthy work environment, Adventist HealthCare will not hire applicants for employment who either state that they are nicotine users or who test positive for nicotine and drug use.

While some jurisdictions, including Maryland, permit the use of marijuana for medical purposes, marijuana continues to be classified as an illegal drug under the federal Controlled Substances Act. As a result, medical marijuana use will not be accepted as a valid explanation for a positive drug test result.

Adventist HealthCare will withdraw offers of employment to applicants who test positive for Cotinine (nicotine) and marijuana. Those testing positive are given the opportunity to re-apply in 90 days, if they can truthfully attest that they have not used any nicotine products in the past ninety (90) days and successfully pass follow-up testing. (""Nicotine products"" include, but are not limited to: cigarettes, cigars, pipes, chewing tobacco, e-cigarettes, vaping products, hookah, and nicotine replacement products (e.g., nicotine gum, nicotine patches, nicotine lozenges, etc.).
Equal Employment Opportunity
Adventist HealthCare is an Equal Opportunity/Affirmative Action Employer. We are committed to attracting, engaging, and developing the best people to cultivate our mission-centric culture. Our goal is to have a welcoming, equitable, and safe place to work and grow for all employees, no matter their background. AHC does not discriminate in employment opportunities or practices on the basis of race, ethnicity, color, religion, sex, national origin, age, disability, sexual orientation, gender identity, pregnancy and related medical conditions, protected veteran status, or any other characteristic protected by law.
Adventist HealthCare will make reasonable accommodations for applicants with disabilities, in accordance with applicable law. Adventist HealthCare is a religious organization as defined under applicable law; however, it will endeavor to provide reasonable accommodations for applicants’ religious beliefs.
Applicants who wish to request accommodations for disabilities or religious belief should contact the Support Center HR Office.","$67,567 /yr (est.)",5001 to 10000 Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1907,$500 million to $1 billion (USD)
"Abile Group, Inc.
5.0",5.0,"Saint Louis, MO",Data Automation Engineer,"Overview:
Abile Group has an exciting and challenging opportunity for a Data Automation Engineer on a 10 year contract providing User Facing and Data Center Services supporting an Intelligence Community customer. All the personnel on the team will work together to support innovative design, engineering, procurement, implementation, operations, sustainment and disposal of user facing and data center information technology (IT) services on multiple networks and security domains, at multiple locations worldwide, to support the IC mission.

The right candidate will possess the below skills and qualifications and be ready to handle all responsibilities independently and professionally.
Responsibilities:
Supports the Geospatial Services and Solutions business area to provide high-quality, cost-effective solutions to the customer
Designs and implements automation solutions to enhance data capture, data refinement, and processes.Coding examples include: Interfacing with device APIs in order to collect operational metrics
Providing automated VoIP phone setup
Administering and automating data pipelines between different environments
Producez and deploys code via GitLab projects in collaboration with other team members
Utilizes best practices for source control, testing, and deployment of software changes
Works in close collaboration with other automation engineers, infrastructure administrators, and data scientists
Diagnoses, isolates, and expediently resolves complex problems pertaining to data structures
Develops methods of ensuring data incompatibilities among systems are systematically eliminated
Develops and recommends data management policies, standards, practices, and security measures to ensure effective and consistent data management operations
Participates in continuous improvement efforts to increase data availability, data quality, and speed of access
Maintains up-to-date documentation of designs/configurations, ensuring team members have continuity of recurring tasks
In office work requirement > 80%
Travel requirement 0%
Qualifications:
Clearance Required: TS/SCI with eligibility to obtain a CI poly

Degree and Years of Experience: Bachelor's Degree in Computer Science or related technical discipline, or the equivalent combination of education, technical certifications or training, and work experience
8+ years of related systems engineering experience
Required Skills:
Scripting, coding, or software development experience
Comfort with Linux/Windows command-line
Automation mindset
System administration and/or DevOps environment experience
Desired Skills:
Python experience
Shell scripting experience such as Bash or PowerShell
Experience with Database technologies such as Postgres, SQL Server, Oracle, or MySQL
Experience writing and working with SQL commands
Version control experience with Git
Experience with Gitlab and Git workflows
Familiarity with Agile Scrum methodologies
Time management skills and the drive to work with limited supervision within a small team
Bonus Skills:
Web App development experience such as Flask, Django, React, etc.
UI/UX experience
Experience with Analytics tools such as Tableau
Infrastructure as Code experience
Experience in technical operations at DoD/IC agencies
Cloud experience such as AWS, Azure, GCP, etc.

About Abile Group, Inc.:
Abile Group, Inc. was formed in July 2004 to partner with the Intelligence Community and their Contractors in the areas of Enterprise Analytics & Performance Management, IT & Systems Engineering and Program & Project Management. We have significant experience with the Federal Government and are an EDWOSB dedicated to our employees and clients. We are looking for high performing employees who enjoy providing advice and guidance along with solutions development and implementation support, crafted by combining industry best practices with the clients’ subject matter experience and Abile’s breadth of expertise.
EEO Statement:
Abile Group, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. Anyone requiring reasonable accommodations should email careers@abilegroup.com with requested details. A member of the HR team will respond to your request within 2 business days.

Please review our current job openings and apply for the positions you believe may be a fit. If you are not an immediate fit, we will also keep your resume in our database for future opportunities.","$100,929 /yr (est.)",Unknown,Company - Public,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"Medtronic
3.9",3.9,"Northridge, CA",Prin Cloud Data Engineer,"Careers that Change Lives

Our team is building the latest medical device connected cloud systems and web applications for worldwide diabetes care. To support our growing customer base, we need software engineers who can solve complex engineering problems, keep our system operating in top shape, and build the diagnostic tools we need to maintain rock-solid reliability.
As a Principal Cloud Data Engineer, you will help create data solutions that simplify care and improve clinical outcomes while working closely with software architects, local, and remote teams.
Our connectivity team connects a planet’s worth of patient health data to deliver consumer and hospital solutions that make a real difference in how people live their lives every day. Our systems are truly “the core” that powers our business’ clinical studies, data analytics and customer-facing applications.
A Day in the Life
Build and design robust distributed data processing systems architectures that are highly scalable and performant
Design, develop, and unit test applications in accordance with established standards. Participate in peer-reviews of solution designs and related code.
Develop, refine, and tune integrations between applications.
Analyze and resolve technical and application problems.
Assess opportunities for application and process improvement and prepare documentation of rationale to share with team members and other affected parties.
Adhere to high-quality development principles while delivering solutions on-time.
Generates design documents, architecture diagrams, and other technical artifacts
Write scalable, secure, maintainable code that powers our products.
Must Have: Minimum Requirements
Bachelor’s degree in engineering, sciences, or technology with 7+ years of relevant experience
or 5+ years of experience with an Advanced degree
Nice to Have
Experience with AWS technologies and Containers
Knowledge and experience in Kafka, DynamoDB, Kinesis, Elasticsearch, Spark
Experience in direct coordination and leadership with offshore development teams and multiple onsite teams.
Thorough understanding of software development and testing life cycles.
Good architecture design and distributed systems skills.
Willingness and passion to learn about new technologies, architectures, and solutions.
Expertise in Software design, architecture and prototyping
Experience in the medical device industry
About Medtronic

Together, we can change healthcare worldwide. At Medtronic, we push the limits of what technology, therapies and services can do to help alleviate pain, restore health and extend life. We challenge ourselves and each other to make tomorrow better than yesterday. It is what makes this an exciting and rewarding place to be.

We want to accelerate and advance our ability to create meaningful innovations - but we will only succeed with the right people on our team. Let’s work together to address universal healthcare needs and improve patients’ lives. Help us shape the future.

Physical Job Requirements

The physical demands described within the Responsibilities section of this job description are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. For Office Roles: While performing the duties of this job, the employee is regularly required to be independently mobile. The employee is also required to interact with a computer, and communicate with peers and co-workers. Contact your manager or local HR to understand the Work Conditions and Physical requirements that may be specific to each role. (ADA-United States of America)",#N/A,10000+ Employees,Company - Public,Manufacturing,Health Care Products Manufacturing,1949,$10+ billion (USD)
"Stripe Theory
3.4",3.4,"Atlanta, GA",Data Engineer - Marketing Analytics (FT),"About Stripe Theory:
Stripe Theory is an agency made up of a team of data-driven digital marketers, communication professionals, and analysts. We call ourselves interpreters of data because that’s just what we do - use data to inform and fuel strategies across PR, marketing, and digital.
About ACC:
Stripe is an acquisition of ACC - Acceleration Community of Companies. ACC is an integrated team of cutting-edge media, marketing, and communications companies, offering best-in-class marketing solutions where strategy, technology, and creativity converge.
About the Role:
We are seeking a Data Engineer to join our growing Analytics team. In this role, you will focus on building new data pipelines and refining existing ones that extract, transform and load marketing and social data from a wide array of sources. The data you provide will be consumed by the analytics team and a wide array of client stakeholders. This is the first true Data Engineer position on the team and will be an excellent opportunity to own and define the evolution of our data practices and workflow. At the same time, this role will require you to be a proactive problem solver, anticipating use cases and developing a deep understanding of marketing data and our data stack. You’ll report to and work closely with the Director of Analytics to understand business needs and develop solutions.
Responsibilities:
Be our go-to data expert, and develop our data warehouse and data processing layers.
Partner with data analytics and business stakeholders to obtain a holistic understanding of data needs and translate into infrastructure that enables a data-driven culture.
Incorporate automation wherever possible to improve data pipelines and analyses.
Build, refactor, and maintain data pipelines that ingest data from multiple sources.
Assist the analytics team in building Tableau dashboards and visualizations.
Tools we use right now:
We store data in PostgreSQL.
Our platform is powered using EC2.
We visualize data for clients in Tableau.
We are always looking to integrate other tools that help evolve our workflows and data stacks.
About You:
You have a demonstrated ability in database architecture, design, implementation, support and experience with PostgresSQL. Successful candidates for this role must have strong analytical and data modeling skills, a deep understanding of database technology and data use within analytics platforms, and they must have strong programming skills with SQL and/or Python. As the resident database expert, you'll need to have the ability to work with and influence all levels of our team-oriented and collaborative organization. You feel comfortable writing an API call, segmenting and aggregating the data in a Postgres environment, connecting Tableau to these tables, and helping the analytics team build bespoke dashboards in Tableau for a variety of use cases.
Qualifications:
Expert proficiency in SQL and/or Python.
Expert in database table design - able to create database structures from scratch that ingests multiple data sources and enable a variety of aggregate views.
Expert in writing API calls to pull in data - big bonus for experience doing this with social, website, and/or marketing platforms (AdTheorent, Meta, Google Ads, GA4, TradeDesk, etc).
Experience and strong knowledge in data warehousing concepts and analytics platforms.
2+ years of experience with Tableau, Lookr, PowerBI or equivalent as a visualization and reporting tool.
4+ years experience in creating and supporting databases and ETL processes.
Some experience working with cloud platforms such as AWS, Azure and GCP.
BS/MS/PhD in Computer Science, Information Systems, Applied Mathematics or a related field.
Preferred Qualifications:
Tableau expertise a BIG plus.
Agency/marketing experience a BIG plus.
Experience with social data is a plus.


About Stripe Theory:

We are a digital marketing agency focused on growing brands through data, storytelling and strategy. We started Stripe Theory on the belief that a data-first, cross-trained and discipline-agnostic approach to marketing and strategy could deliver greater client value and innovation at a lower cost. At Stripe Theory, we embrace the chaos of marketing and use data to navigate the noise. This is how we operate at the cusp of what is next.","$101,682 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Schlitterbahn Waterparks and Resorts
3.7",3.7,"Charlotte, NC",Data Engineer,"Charlotte, North Carolina
Job Category: Information Technology
Req ID19054
Overview:
Cedar Fair is seeking a Data Engineer at our corporate Charlotte office. The Data Engineer develops and supports centralized corporate data repository, to include large data sets from enterprise applications across the Cedar Fair domain. Deliver easy to consume data sets to the business analyst and aid in dashboard and reporting creation and delivery.

Responsibilities:
Develop data transformation processes.
Work with data and business analyst building consumable data sets.
Data governance and validation between source application and centralized data store.
Document and diagram all corporate data flow, ETL, and ELT processes.
Administrative i.e.. email, meetings.

Qualifications:
Bachelor's degree required in Information Technology.
Master's degree preferred in Data Engineering.
2-4 years work-related experience required.
3 or more years of data architecting (ETL & ELT) . 3+ years of SQL Server or other relational data application. Experience with cloud data lake and data delivery models. Expert in TSQL & ansi SQL. Experience in calling API’s via postman.
AWS, Qlik, and Visual Cron experience a plus. Working knowledge of dbt Cloud and python a plus.
Ability to pass a background check, if 18 years of age or older, which may include, but is not limited to, credit, criminal, DMV, previous employment, education and personal references, per Company policy, unless prohibited by federal, state, or provincial law.
Ability to work nights, weekends, and holiday periods to meet business needs.
Must possess a valid Driver's License.
#LI-CM1","$90,003 /yr (est.)",1001 to 5000 Employees,Subsidiary or Business Segment,"Arts, Entertainment & Recreation",Culture & Entertainment,1979,Unknown / Non-Applicable
"TEXAS HIGHER EDUCATION COORDINATING BOARD
2.9",2.9,"Austin, TX","THECB - Data Analyst IV, Data Engineer","THECB - Data Analyst IV, Data Engineer (00036495)
Organization: TEXAS HIGHER EDUCATION COORDINATING BOARD
Primary Location: Texas-Austin
Work Locations: TX Hghr Edu Coordinating Board 1801 Congress Ave Austin 78701

Job: Computer and Mathematical
Employee Status: Regular
Schedule: Full-time
Standard Hours Per Week: 40.00
Travel: Yes, 5 % of the Time
State Job Code: 781U
Salary Admin Plan: N/A
Grade: 00
Salary (Pay Basis): 6,597.00 - 7,431.00 (Monthly)
Number of Openings: 1
Overtime Status: Exempt
Job Posting: Sep 21, 2023, 3:59:09 PM
Closing Date: Oct 12, 2023, 11:59:00 PM
Description

THECB is observing a hybrid telecommuting schedule with employees required to be in the office at least two (2) days per week.
The agency is located at the George Herbert Walker Bush Building located in the Capitol Complex at 1801 N Congress Ave. Austin, TX 78701.

General Description:
Performs complex (journey-level) data engineering and analysis work within the Data Management and Reporting (DMR) division. Assists with the development and integration of a data analytics and business intelligence environment that aligns with the mission, vision, strategy, and goals of THECB leadership. Work involves building data pipelines; integrating, consolidating, cleansing, and structuring data for analytical applications; data modeling; and implementing and managing database systems, data warehouses, and data marts. May provide guidance to others. Works under general supervision, with moderate latitude for the use of initiative and independent judgment. This position reports directly to the Director of Data DevOps on the Data Management team.
General Duties and Responsibilities:
Analyzes data using standard statistical tools, methods, and techniques
Consults with internal and external customers to identify user needs
Compiles and queries data
Identifies data gaps, errors, anomalies, inconsistencies, and redundancies by analyzing the content, structure, and relationships within data
Interprets results to identify significant differences in data
Identifies and interprets data patterns and trends and assesses data quality
Cleans and prunes data to discard irrelevant information
Prepares concise, comprehensive technical reports to present and interpret data, identify alternatives, and make and justify recommendations on data revisions
Assists in defining, developing, and implementing data standards
Assists in developing data quality measures, analyzing data quality results, and implementing necessary changes to ensure data quality improvement
Assists in developing software applications or programming to use for statistical modeling and graphic analysis
Assists in developing and implementing databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality
May perform quality assurance and serve as a subject matter expert on data integrity, extraction, and compilation
May guide the selection of data management tools, and the development of standards, usage guidelines, and procedures for those tools
Knowledge, Skills, and Abilities:
Expertise in data pipelines and end-to-end data product lifecycle
Knowledge of industry standard project frameworks to deliver data platform and products (examples: Agile/Scrum Development & Management, Scaled Agile Framework)
Expertise in DataOps lifecycle (build, deploy, and production support)
Prior exposure to cloud infrastructure in AWS, Azure or GCP for analytic and data platform solutions spanning a range of services including storage, data movement, data lake management, and analytics
Broad understanding of data engineering and/or machine learning lifecycles and enablement, experiment and project tracking, and data version control
Prior work in a dynamic and complex solution ecosystem
Effective and engaging interpersonal skills with technical team members as well as business partners and able to distill complex ideas into straightforward language
Military Crosswalk: https://hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_PlanningResearchandStatistics.pdf

Qualifications

Required Minimum Education and Experience:
Graduation from an accredited four-year college or university with major coursework in data science, business analytics, computer science, computer information systems, or management information systems
2+ years’ experience working as a data analyst and/or modeler in a data warehouse, data lake, operational data store, or similar
Master’s degree from an accredited college or university, in a related field, may substitute for one year of required work experience for candidates
Preferred:
Experience working with Snowflake platform
3+ years of experience with advanced, end-user, data preparation and manipulation tools and languages: SAS, R, Python, Trifacta, SQL; be willing to adapt to new tools compliant with standards
Experience in technology platform architecture design, code refactoring and migration
Experience with ETL processes and skill in data transformation
Experience contributing to data transformation coding and documentation standards, code and data re-use approaches, designs and guidelines
Demonstrated experience working with supporting tooling aimed at workload management or tracking
Understanding of metadata management, data profiling and data quality rules
Work with data analysts and supporting IT teams to implement automated quality checks

Physical Requirements and/or Working Conditions:
Work is performed in a standard office environment and requires:
Regular, reliable, and punctual attendance at work;
Frequent use of personal computer, copiers, printers, and telephones;
Frequent sitting, and
Frequently working under deadlines, as a team member, and in direct contact with others.
Workforce:
Must be able to:
Demonstrate knowledge of customer service deliverables.
Show flexibility and adaptability toward changes in assignments and work schedules, working extended hours as necessary.
Adhere to the organization’s internal management policies and procedures.
Contribute to the agency’s performance measures and mission.
Travel occasionally for work assignments and training.

Application Requirements:
The Texas Higher Education Coordinating Board is an Equal Opportunity Employer. A State of Texas application is required to apply. For more information on how to apply for this position, go to the Coordinating Board’s employment opportunities website at http://www.thecb.state.tx.us/about-us/human-resources/career-opportunities/.
The Texas Higher Education Coordinating Board participates in E-Verify for each new employees’ Form I-9 to confirm work authorization. For questions, please call the HR Department at 512-427-6190. For vocal and/or hearing assistance call 7-1-1.
Notes to Applicant:
If you require any reasonable accommodation for the interview process, please inform the hiring representative who calls to schedule your interview. This position has been designated as a security sensitive position. A criminal background investigation will be conducted on the final candidate for this position.
Your job application must be completely filled out. Your application must contain dates of employment, job titles, name of employer and a description of duties performed in a way that demonstrates you meet the minimum qualifications for the position for which you are applying. Resumes do not take the place of the requirement to include this information on the application. If this information is not submitted, your application may be rejected because it is incomplete.
Veterans Information: THECB is committed to hiring Veterans. To receive Veteran’s Preference, a copy of the FORM DD214 -member #4, must be attached when submitting your application.
AN EQUAL EMPLOYMENT OPPORTUNITY EMPLOYER: THECB does not discriminate on the basis, of race, color, religion, sex, national origin, age, or disability in employment or the provision of services.
Job offer and continuation of employment with THECB is contingent upon:
Proof of education and experience listed on the application.
Eligibility/authorization to work in the U.S.
Satisfactory results from a pre-employment criminal history background check.
Compliance with the Selective Service Law for males ages 18-25. Please be advised that under Texas law, names and other information concerning applicants or nominees may be subject to disclosure upon request.
THECB does not allow dual employment with other state of Texas agencies or institutions.
Skills assessment may be conducted at time of interview
No phone calls or emails, please. Due to the high volume of applications, we do not accept telephone calls and cannot reply to all email inquiries. Only candidates selected for interview will be contacted.","$7,014 /mo (est.)",201 to 500 Employees,Government,Government & Public Administration,State & Regional Agencies,1965,Unknown / Non-Applicable
"Deloitte
4.0",4.0,"Richmond, VA",Cloud Data Engineer Manager II- Healthcare,"Position Summary
Are you an experienced, passionate pioneer in technology who wants to work in a collaborative environment? As an experienced Cloud Data Engineer - Manager - Healthcare you will have the ability to share new ideas and collaborate on projects as a consultant without the extensive demands of travel. If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery.

Work you’ll do/Responsibilities
You will determine processes and automation tools to reduce IT spend and increase efficiencies on multiple projects within the Healthcare domain.
This position includes collaborating with DevOps teams to implement CI/CD pipelines, automated deployments, and infrastructure as code (IaC) practices for AWS-based solutions. Document design, development, and deployment processes, as well as create technical specifications and user guides for developed solutions.
Your role will be to design, develop, and deploy cloud-based solutions for data processing, analytics, and integration using cloud services and big data technologies. Collaborate with architects, data engineers, and business stakeholders to understand requirements and translate them into technical solutions.
You will implement data ingestion, transformation, and storage processes using cloud services like AWS's S3, Glue, Athena, Redshift, and EMR. Implement security, data governance, and compliance measures to ensure data integrity and protection in AWS-based solutions. Develop and optimize data pipelines using Snowpark, SnowSQL, Hadoop and PySpark to extract, transform, and load data efficiently.
You will conduct performance tuning and optimization of data processing and analytics workflows to maximize efficiency and scalability. Work with cross-functional teams to troubleshoot and resolve issues related to data processing, data integration, and analytics solutions.
Communicate regularly with Engagement Managers (Directors), project team members, and representatives from various functional and / or technical teams, including escalating any matters that require additional attention and consideration from engagement management
The Team
As a part of the US Strategy & Analytics Offering Portfolio, the AI & Data Engineering offering provides managed AI, Intelligent Automation, and Data DevOps services across the advise-implement-operate spectrum.

Qualifications
Required
Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience
12+ years’ experience as a Cloud Data Engineer
12+ years’ hands on experience in Snowpark, SnowSQL, Hadoop and PySpark
12+ years’ experience in AWS services such as S3, Glue, Athena, Redshift, EMR, Lambda and Cloud Formation.
10+ years’ experience in Python with a focus on data processing and analytics
10+ years in healthcare domain
12+ years in consulting
Strong knowledge and hands-on experience in designing, developing, and deploying scalable solutions on the cloud platforms
Expertise in SQL and database technologies for data manipulation and querying
Limited immigration sponsorship may be available
Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve
Must live near or willing to relocate to Richmond, VA.
Hybrid work model. Able to commute to office 1-2 days a week as needed.
Preferred
Expertise with data modeling, data warehousing, and data integration concepts
Experience with DevOps practices, CI/CD pipelines, and infrastructure as code (IAAC) using tools like Jenkins, Git, and Terraform.
Strong analytical and problem-solving skills, with the ability to troubleshoot and resolve complex technical issues.
Familiarity with agile development methodologies and experience working in Agile teams
Analytical/ decision making responsibilities
Analytical ability to manage multiple projects and prioritize tasks into manageable work products
Can operate independently or with minimum supervision
Excellent communication skills
Ability to deliver technical demonstrations
Recruiting tips

From developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters.
Benefits

At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.
Our people and culture

Our diverse, equitable, and inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our client most complex challenges. This makes Deloitte one of the most rewarding places to work. Learn more about our inclusive culture.
Our purpose

Deloitte’s purpose is to make an impact that matters for our clients, our people, and in our communities. We are creating trust and confidence in a more equitable society. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. We are focusing our collective efforts to advance sustainability, equity, and trust that come to life through our core commitments. Learn more about Deloitte's purpose, commitments, and impact.
Professional development

From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.
As used in this posting, ""Deloitte"" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.
Requisition code: 159141","$111,153 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,1850,$10+ billion (USD)
Phoenix Cyber,#N/A,Remote,Data Protection Engineer [JOB ID 20230920],"Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States.
Requirements:
5+ years’ experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise.
5+ years’ experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise.
Experience with Regex
Description:
Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options.
Assess different DLP endpoint protection tool options and help the customer choose the best option.
Develop DLP design, design DLP integrations and assess enterprise reporting capability.
Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode.
Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options.
Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP’s), and assess enterprise reporting capability.
Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode.
Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT).
Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT).
Requirements:
Secret Clearance
Active: CySA, CEH, SSCP, or GICSP Certification
Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team.
Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status.
Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify.gov/

MeIcqDt7H3",#N/A,Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Zions Bancorporation
3.6",3.6,"Midvale, UT",Data Engineer (Credit Systems),"Zions Bancorporation’s Enterprise Technology and Operations (ETO) team is transforming what it means to work for a financial institution. With a commitment to technology and innovation, we have been providing our community, clients and colleagues the best experience possible for over 150 years. Help us transform our workforce of the future, today.

We are seeking a Data Engineer to join Zions Bancorporation on our Credit Systems Team. As a Data Engineer, you’ll provide your talents in contributing to the success of the Zions team by delivering all aspects of the software development lifecycle, including design, coding, integration testing, deployment, operations support, and documentation using Agile methodologies. Also, able to work independently, collaborate with cross-functional teams on technical understanding, handle multiple concurrent projects, with an ability to prioritize and manage projects effectively with changing priorities.

Responsibilities:
Partner with architects, engineers, information analysts, business, and technology stakeholders for developing and deploying enterprise grade platforms that enable data-driven solutions.
Demonstrate strong analytical, organizational, and problem-solving skills.
Strong focus on long-term strategy, application stability, refactoring, and re-usability.
Analyzes and designs technical solutions to address business needs.
Develops, tests, and modifies software to improve efficiency of data platforms and applications.
Identifies, investigates, and proposes solutions to technical problems.
Coordinate with data operations teams to deploy changes into production.
Serve in the goalie rotation to support Test, QA, and Production environments.
Other duties as assigned

Qualifications:
Requires a Bachelor's in Computer Science, Computer Engineering, or related field.
Experience with Data Warehousing, data technologies and ETL solutions.
4+ years of experience in ETL (IBM Datastage preferred), SQL, UNIX/Linux scripting, and Big Data distributed systems.
3+ years of experience in programming languages like Python, orchestration tools and processes.
Experience in building ETL pipelines using Python pandas
Exposure in RDD’s with Python/Scala using Spark framework.
Extensive experience in data migration, data analysis, data transformations, conversion, interface, large volume data loading (ETL techniques), database modeling, and performance SQL tuning.
Experience in leveraging database tools to develop DDL scripts, stored procedures, and functions to create and alter database objects.
Experience working with Greenplum, Oracle, SQL Server, DB2, Teradata, Hive and delimited text files would be helpful.
Enthusiasm and strong desire to learn and grow within the organization.

Preferred skills
Experience working with cloud or on-prem Big Data/MPP analytics platform like Google BigQuery, Azure Data Warehouse, or similar
Experience with designing and implementing real-time ETL pipelines
Experience with data pipeline automation and CI/CD tools like Jenkins
Hands on experiences with Git version control processes, data streaming technologies such as Kafka, and unstructured data handling preferred.

Location:

This position has a hybrid work from home schedule with a minimum of three days per week in the office at the new Zions Technology Center in Midvale, UT.

The Zions Technology Center is a 400,000-square-foot technology campus in Midvale, Utah. Located on the former Sharon Steel Mill superfund site, the sustainably built campus will be the company’s primary technology and operations center. This modern and environmentally friendly technology center will enable Zions to continue to compete for the best technology talent in the state while providing team members with an exceptional work environment with features such as:
Electric vehicle charging stations and close proximity to Historic Gardner Village UTA TRAX station.
At least 75% of the building is powered by on-site renewable solar energy.
Access to outdoor recreation, parks, trails, shareable bikes and locker rooms.
Large modern cafe with a healthy and diverse menu.
Healthy indoor environment with ample natural light and fresh air.
LEED-certified sustainable building that features include the use of low VOC-emitting construction materials.

Benefits:
Medical, Dental and Vision Insurance - START DAY ONE!
Life and Disability Insurance, Paid Parental Leave and Adoption Assistance
Health Savings (HSA), Flexible Spending (FSA) and dependent care accounts
Paid Training, Paid Time Off (PTO) and 11 Paid Federal Holidays
401(k) plan with company match, Profit Sharing, competitive compensation in line with work experience
Mental health benefits including coaching and therapy sessions
Tuition Reimbursement for qualifying employees
Employee Ambassador preferred banking products

Apply now if you have a passion for impactful outcomes, enjoy working collaboratively with co-workers, and want to make a difference for the clients and communities we serve.","$85,924 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1955,$1 to $5 billion (USD)
"LinQuest Corporation
4.0",4.0,"Washington, DC",Data Engineer / Scientist,"Position Summary
LinQuest is looking for an energetic and innovative Data Engineer/Scientist to assist in addressing gaps and discrepancies in sustainment-management reporting through the synchronization of multiple stakeholder requirements and the processing of sustainment data to develop and display operational readiness metrics. As a member of a team, the Data Engineer will streamline a current scheduling tool to improve user experience through the application of cascading filtering, refining user roles, and scheduling confidence ratings. As a Data Engineer the candidate will be adept at loading and joining data tables, integrating data from diverse static and automatic data sources, writing functions, and configuring charts and data grids. Candidates must be comfortable working with a wide range of stakeholders and functional teams that work across multiple time zones and have a passion for discovering solutions hidden in large data sets. Candidates will have the opportunity to work with unstructured and structured data, develop databases, build data pipelines, and find innovative solutions to complex data problems.
Key Responsibilities:
Loading and joining data tables, writing functions, and configuring charts and data grids
Publish charting for automated data feeds of effectiveness metrics
Provide the ability to display metrics generated from automated data sources
Research state-of-the-art data mining methods and innovative statistical models
Identify relevant data sources and sets to mine for client business needs and collect large structured and unstructured datasets and variables
Process, cleanse, and verify the integrity of data used for analysis
Clearly document and present methodology, assumptions, and findings to stakeholders

Required Skills and Experience:
Bachelor’s degree in Computer Science, Data Analytics, Software Development, Information Technology, or related discipline
3-5 years of experience in data engineering
Experience processing data in Advana
Manipulating data with SQL and Python
Developing data pipelines to support analytics
Documenting and communicating results of analysis
Experience manipulating data from spreadsheets (i.e. MS Excel)
Experience with Business Intelligence (BI) Tools (Power BI, Tableau, Qlik etc.)
Strong analytical and problem-solving skills with hands on experience driving analytic insights
Ability and motivation to self-teach in order to stay current with leading best practices in analytics
Expected to deliver in a fast-paced, team-oriented work environment
Must thrive in satisfying analytic requirements from diverse user base
Must have the knowledge and communication skills to articulate trade-offs between analytic techniques, recommend a course of action to clients, and provide effective updates on project outcome uncertainty to leadership
US citizenship and the ability to obtain a DoD Secret security clearance are required

Preferred Skills and Experience:
Text mining and unstructured data analysis techniques
Machine Learning techniques
Language/Scripting skills: Python, Databricks Spark Compute
Tools: Qlik
Extract, Transform, Load (ETL) experience
Predictive and prescriptive analysis
Optimization experience
A current/active DoD security clearance

Why LinQuest?
LinQuest Corporation has a stellar 40-year track record of providing end-to-end system-of-systems (SoS) architecture definition, engineering design, integration and test, and operations expertise to enable full lifecycle development and deployment of pre-eminent Space, Air, Land, Sea, Ground, and Cyberspace game-changing capabilities across US DOD and IC Customers’ portfolios. Unique combination of in-depth domain knowledge, lessons learned-honed best practices, and mission-specific applications of principles, tools, and techniques of Digital Engineering (DE), DE Ecosystem (DEE), and Model-Based Systems Engineering (MBSE) set LinQuest apart from the competition to consistently deliver stellar high-value results for our customers. LinQuest’s corporate vision and values place the employee at the center of utmost customer satisfaction, strategic business growth, and tactical execution excellence. Our employees’ creative and inspirational drive, sense of fulfillment of personal and professional growth, and tightknit camaraderie within and across lines of business are essential in gaining and maintaining exceptional LinQuest corporate-wide results of new business awards and renewed contracts.
Benefits:
LinQuest offers comprehensive and competitive benefit offerings to our team members to include medical, dental, vision, retirement, paid time off, tuition reimbursement, company paid life insurance, and more! For additional information please visit: https://www.linquest.com/careers/our-benefits
Education
Required
Bachelors or better
Licenses & Certifications
Required
Ability to Obtain
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$109,892 /yr (est.)",1001 to 5000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2004,$100 to $500 million (USD)
"The Aerospace Corporation
4.1",4.1,"El Segundo, CA",IC 2024 Data Platforms and Architecture Engineer,"The Aerospace Corporation is the trusted partner to the nation’s space programs, solving the hardest problems and providing unmatched technical expertise. As the operator of a federally funded research and development center (FFRDC), we are broadly engaged across all aspects of space— delivering innovative solutions that span satellite, launch, ground, and cyber systems for defense, civil and commercial customers. When you join our team, you’ll be part of a special collection of problem solvers, thought leaders, and innovators. Join us and take your place in space.
At Aerospace, we are committed to providing an inclusive and diverse workplace for all employees to share in our common passion and aspiration – to carry out a mission much bigger than ourselves.
Internship conversion position for the Data Platforms and Architecture Department.

The Data Platforms and Architectures Department develops cloud-based, scalable, and resilient data analysis pipelines, tools and platforms to enable the full exploitation of historical and streaming data sets for a variety of civil and national security space customers. Do you want to do cutting edge data engineering and do innovative work on the open-source data processing frameworks with the ability to intelligently scale? Join us as a Cloud Native Software Developer on the Data Platforms and Architectures Department team in The Aerospace Corporation!
Work Model:
This position will be a hybrid work model and offer partially remote with some onsite work required in El Segundo, CA.
What You’ll Be Doing
Supporting the National Security, United States Space Force, DoD, and commercial space enterprise customers through the identification, prototyping, assessment, and implementation of cutting-edge data engineering technologies in a cloud-native environment.
Collaborating with technical subject matter experts and interdisciplinary teams to conceive, design, and develop enterprise data analysis pipelines and applications.
Learning by doing, acquiring expertise in emerging technologies to further personal and organizational breadth of knowledge in an academic environment where self-enrichment, training, and mentorship is fundamental.
Proposing innovative research and development projects, leading research and proof-of-concept development as the principal investigator.
Duties, responsibilities, and activities may change, or new ones may be assigned as needed.
What Corporate Skills You’ll Bring
Strong written and oral communication and interpersonal skills for coordinating efforts and working with members of various internal and external organizations.
Strong reading comprehension, research, and analytical skills for understanding software documentation and source code, interpreting project requirements, and learning new technologies according to project demand.
Integrity, self-motivation, initiative, and a collaborative approach to working in a team environment and proactively communicating progress and concerns to teammates and project stakeholders.
Organizational, time management, and project management skills, including knowledge of software engineering lifecycles and familiarity with project management methodologies.
Adaptability to working in a dynamic environment where duties, responsibilities, and activities vary in response to fluctuating organizational needs.
Flexibility in completing projects with concurrent timelines, accurately estimating task duration, and working independently on execution.
Demonstration of behavior consistent with the company’s values: Dedication to Mission Success, Technical Excellence, Commitment to Our People, Objectivity and Integrity, and Innovation.
What You Need to be Successful
Minimum Requirements:
Pursuing a Bachelors degree in Computer Science or related discipline from an accredited college/university program and to be conferred within 12 months
Prior internship at The Aerospace Corporation
Minimum GPA of 3.0
Intermediate knowledge of one or more programming languages, including Python and/or Java.
Backend development project experience or course work in data structures and algorithms.
Experience developing in Unix-like environments and using source/version control (Git).
Must be able to obtain and maintain a security clearance; which is issued by the US government. U.S citizenship is required to obtain a security clearance.
Transcripts required
How You Can Stand Out
It would be impressive if you have one or more of these:
GPA of 3.5 or higher
Active security clearance
Strong leadership skills
Development of data platforms
Experience with data security and governance technologies
Microservice architectures
Knowledge of data virtualization and data access
Distributed and stream data processing
Intermediate to advanced knowledge of other programming languages i.e. Python, JavaScript, C/C++, C#, etc.
We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. The grade-based pay range for this job is listed below. Individual salaries within that range are determined through a wide variety of factors including but not limited to education, experience, knowledge and skills.
(Min - Mid - Max)
$75,000 - $85,000 - $93,000
Pay Basis: Annual
Ways We Reward Our Employees
During your interview process, our team will provide details of our industry-leading benefits.
Benefits vary and are applicable based on Job Type. A few highlights include:
Comprehensive health care and wellness plans
Paid holidays, sick time, and vacation
Standard and alternate work schedules, including telework options
401(k) Plan — Employees receive a total company-paid benefit of 8%, 10%, or 12% of eligible compensation based on years of service and matching contributions; employees are immediately eligible and vested in the plan upon hire
Flexible spending accounts
Variable pay program for exceptional contributions
Relocation assistance
Professional growth and development programs to help advance your career
Education assistance programs
An inclusive work environment built on teamwork, flexibility, and respect
We are all unique, from diverse backgrounds and all walks of life, yet one thing bonds all of us to each other—the belief that we can make a difference. This core belief empowers us to do our best work at The Aerospace Corporation.
Equal Opportunity Commitment
The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, age, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender, gender identity or expression, color, religion, genetic information, marital status, ancestry, national origin, protected veteran status, physical disability, medical condition, mental disability, or disability status and any other characteristic protected by state or federal law. If you’re an individual with a disability or a disabled veteran who needs assistance using our online job search and application tools or need reasonable accommodation to complete the job application process, please contact us by phone at 310.336.5432 or by email at
ieo.mailbox@aero.org
. You can also review
Know Your Rights
: Workplace Discrimination is Illegal
, as well as the
Pay Transparency Policy Statement
.","$93,000 /yr (est.)",1001 to 5000 Employees,Nonprofit Organization,Aerospace & Defense,Aerospace & Defense,1960,$1 to $5 billion (USD)
"Texas Comptroller of Public Accounts
3.5",3.5,"Austin, TX",GLO - Senior Data Engineer (Data Analyst V),"GLO - Senior Data Engineer (Data Analyst V) (00036219)
Organization: GENERAL LAND OFFICE
Primary Location: Texas-Austin
Work Locations: Austin GLO Main FL7 1700 N Congress Ave Austin 78701

Job: Computer and Mathematical
Employee Status: Regular
Schedule: Full-time
Standard Hours Per Week: 40.00
Travel: Yes, 5 % of the Time
State Job Code: 0654
Salary Admin Plan: B
Grade: 26
Salary (Pay Basis): 8,750.00 - 9,750.00 (Monthly)
Number of Openings: 1
Overtime Status: Exempt
Job Posting: Sep 20, 2023, 4:03:21 PM
Closing Date: Oct 4, 2023, 11:59:00 PM
Description
The Texas General Land Office primarily serves the schoolchildren, veterans, and the environment of Texas. The agency does so by preserving our history, maximizing state revenue through innovative administration, and through the prudent stewardship of state lands and natural resources. This position is with our Information Technology Services area of the agency. To be successful the candidate must model the GLO's competencies of Integrity, Open Communications, Teamwork, Innovation and Proficiency. The successful candidate will be an integral part of the GLO's Information Technology Services team.
Performs highly complex (senior-level) data analysis and data research work or the Saas Development team in Information Technology Services. Work involves conducting detailed analysis of and extensive research on data, providing results, and monitoring and implementing data quality. May supervise the work of others. Works under limited supervision, with moderate latitude for the use of initiative and independent judgment

Military Crosswalk information can be accessed at:
https://hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_PlanningResearchandStatistics.pdf
In order to receive Veteran's preference, a copy of the DD #214 is required at the time of interview.

Benefits
Free Parking
Defined Retirement Benefit Plan
Optional 401(k) and 457 accounts
- Medical Insurance - State pays 100% of the health plan premium for eligible full-time employees and 50% of the
premium for their eligible dependents. State pays 50% of the eligible part-time employee’s premium and 25% for eligible dependents.
Optional Benefits such as dental, vision, and life insurance
Minimum of 96+ Hours of Annual Leave a year **Annual leave increases with length of service.

Essential Job Elements:

Performs coding tasks in various programming languages and related technologies in the business intelligence domain while adhering to GLO established architecture, software design, development, and coding standards.

Leads and contributes on business intelligence and development activities to ensure tasks and projects are completed within established time frames.

Leads and contributes to the design, implementation, and maintenance of systems used to collect and analyze business intelligence data.

Defines, develops, and implements data standards. Develops data quality measures, analyzes data quality results, and implements necessary changes to ensure data quality improvement

Leads and contributes to the development of reports, dashboards, databases, and other business intelligence assets that allow for efficient collection, processing, and presentation of data.

Compiles and queries data. Identifies data gaps, errors, anomalies, inconsistencies, and redundancies by analyzing the content, structure, and relationships within data. Identifies and interprets data patterns and trends and assesses data quality.

Manages, tracks and documents all work in the respective work management system based on the type of work being performed.

Produces and reviews technical specification documents, support documentation and diagrams as required by standard team practices.

Qualifications
Minimum Qualifications
10 years of professional experience working in information technology or similar industry. Full-time experience in data analysis, research, compilation, and/or reporting work.
Preferred Qualifications
Graduation from an accredited four-year college or university with major coursework in information systems, accounting, public administration, business, or closely related field.

8 years or more experience working in data analytics, big data, statistics, business intelligence or reporting strategies

Technical experience with data collection, data processing, data modeling, reporting and visualization development. Experience with data, reporting, analytics, and business intelligence strategies

Excellent time management and prioritization skills.
Experience with big data, data architecture and pipelining
Experience with data management, protection, policy, and classification
Experiencing with data modeling, transformation and integration technologies and patterns
Experience with R, Dax, Python, and other advanced data processing technologies
Experience in OLTP, OLAP, structured and unstructured data systems
Experience with distributed system patterns, data distribution and integration patterns
Advanced experience with big data, reporting, analytics and dashboarding technology like Tableau, Power Bi, SSRS, MongoDB, SQL Server, SQL Server Analytics,
Advanced experience with designing data organization, data warehousing, data modeling, and data lake architecture
Experience with the following technologies, tools, and platforms:
Microsoft Azure, Amazon Web Services, or other cloud computing services
Azure Data Lake or storage services
Microsoft SQL Server or relative RDBMS technology
Microsoft SQL Server Integration Services (SSIS), MuleSoft, or other integration tools and platforms.
Microsoft Power BI, Microsoft SQL Server Reporting Services (SSRS), Tableau, or other reporting tools and platforms.

Knowledge, Skills, and Abilities
Knowledge of statistics and analyzing data sets; of running queries, report writing, and presenting findings; of data models, database design development, data mining, and segmentation techniques; and of record keeping, including security procedures for handling, protecting, and distributing confidential data; business administration principles and practices; project management and of research and budgeting process.
Skill in the use of a computer and applicable software, including advanced Microsoft Excel skills; in analyzing problems and devising effective solutions, in conducting data searches, in evaluating and translating large amounts of data, and in critical thinking; problem solving, critical thinking and attention to detail; report writing and budget development; grant preparation, development, evaluation, and monitoring.
Ability to compile, review, and analyze data; to prepare reports; to maintain accuracy and attention to detail; and to communicate effectively; interpret guidelines, policies, procedures, and regulations; evaluate fiscal data for reasonableness, necessity, and conformity with grant requirement; communicate effectively and to train others.
Skill analyzing operational issues and approach troubleshooting in a methodical and analytical manner to ensure appropriate resolution.
Skill in exercising sound judgment and effective decision making
Excellent organizational, problem-solving, and work management skills
Ability to communicate effectively both verbally and in writing to any level of the organization in a clear and concise manner
Ability to work under pressure and successfully manage multiple overlapping deadlines
Ability to lead technical requirement gathering sessions and building solutions from those requirements
Ability to receive and respond positively to constructive feedback
Physical Requirements
This position requires the employee to primarily perform sedentary office work; however, mobility (moving around the work-site) is routinely required to carry out some duties. This position requires extensive computer, telephone and client/ customer contact and communication. It requires the ability to move and position oneself as needed for filing and similar routine office duties. The job also requires normal cognitive abilities requiring the ability to learn, recall, and apply certain practices and policies. It requires the stamina to maintain attention to detail despite interruptions. Ability to read printed materials and computer screens. The individual must be able to move and transport records, documents, boxes, and all related information and materials, weighing up to 20 pounds when required.","$9,250 /mo (est.)",1001 to 5000 Employees,Government,Government & Public Administration,State & Regional Agencies,1835,Unknown / Non-Applicable
"HII
3.6",3.6,"Tampa, FL",Data Engineer 5 (Engineer Database 5),"Date: Sep 21, 2023
Location: Tampa, FL, Florida, United States
Company: HII's Mission Technologies division
Requisition Number: 16315
Required Travel: 0 - 10%
Employment Type: Full Time/Salaried/Exempt
Anticipated Salary Range: $127,273.00 - $175,000.00
Security Clearance: TS/SCI
Level of Experience: Senior

Meet HII’s Mission Technologies Division
Our team of more than 7,000 professionals worldwide delivers all-domain expertise and advanced technologies in service of mission partners across the globe. Mission Technologies is leading the next evolution of national defense – the data evolution - by accelerating a breadth of national security solutions for government and commercial customers. Our capabilities range from C5ISR, AI and Big Data, cyber operations and synthetic training environments to fleet sustainment, environmental remediation and the largest family of unmanned underwater vehicles in every class. Find the role that’s right for you. Apply today. We look forward to meeting you.
Job Description
HII Mission Technologies is seeking a Data Engineer 5 with a TS/SCI security clearance to come join our team supporting DoD customer missions in the Tampa, FL area.
This position is ON-SITE only.
Essential Job Responsibilities
Designs, develops, builds, analyzes, evaluates and installs database management systems to include database modeling and design, relational database architecture, metadata and repository creation and configuration management. Uses data mapping, data mining and data transformational analysis tools to design and develop databases. Determines data storage and optimum storage requirements. Prepares system requirements, source analysis and process analyses and design throughout the database implementation.
Minimum Qualifications
15 years relevant experience with Bachelors in related field; 13 years relevant experience with Masters in related field; 10 years relevant experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 19 years relevant experience.
Complete understanding and wide application of technical principles, theories, and concepts in the field. General knowledge of other related disciplines.
Clearance – Must possess and maintain a TS-SCI clearance
#LI-RM1
Preferred Requirements
19 years relevant experience with Bachelors in related field; 17 years relevant experience with Masters in related field.
Experience working at a major command, combatant command, or service-level headquarters required; experience with/in the USCENTCOM AOR preferred.
Strong and effective verbal and written communication skills.
Physical Requirements
May require working in an office, industrial, shipboard, or laboratory environment. Capable of climbing ladders and tolerating confined spaces and extreme temperature variances.
Why HII
We build the world’s most powerful, survivable naval ships and defense technology solutions that safeguard our seas, sky, land, space and cyber. Our diverse workforce includes skilled tradespeople; artificial intelligence, machine learning (AI/ML) experts; engineers; technologists; scientists; logistics experts; and business administration professionals.

Recognized as one of America’s top large company employers, we are a values and ethics driven organization that puts people’s safety and well-being first. Regardless of your role or where you serve, at HII, you’ll find a supportive and welcoming environment, competitive benefits, and valuable educational and training programs for continual career growth at every stage of your career.

Together we are working to ensure a future where everyone can be free and thrive.
Today’s challenges are bigger than ever, and the nation needs the best of us. It’s why we’re focused on hiring, developing and nurturing our diversity. We believe that diversity among our workforce strengthens the organization, stimulates creativity, promotes the exchange of ideas and enriches the work lives of all our employees.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, physical or mental disability, age, or veteran status or any other basis protected by federal, state, or local law.

Do You Need Assistance?
If you need a reasonable accommodation for any part of the employment process, please send an e-mail to buildyourcareer@hii-co.com and let us know the nature of your request and your contact information. Reasonable accommodations are considered on a case-by-case basis. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this email address. Additionally, you may also call 1-844-849-8463 for assistance. Press #3 for HII Technical Solutions.","$151,137 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,2011,Unknown / Non-Applicable
"Capital One
4.1",4.1,"McLean, VA","Senior Software Engineer, Full Stack (Enterprise Data)","Center 3 (19075), United States of America, McLean, Virginia
Senior Software Engineer, Full Stack (Enterprise Data)
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Full Stack Software Engineers who are passionate about marrying data with emerging technologies. As a Capital One Software Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
In this role, you will be supporting an enterprise wide data management initiative and data governance application for managing digital assets including datasets, datastores, and applications that are owned by various organizations across Capital One. The application will be the centralized repository of metadata that will facilitate the navigation, discovery, and change management of digital assets. Engineers on this team will support data use, file transfer, and data retention functionalities for the application while prioritizing data security and compliance.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Architecting and building products by utilizing programming languages like Python, Open Source RDBMS and NoSQL databases, Lambda functions, Container Orchestration services including ECS and Docker, and a variety of AWS tools and services
Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in software engineering (Internship experience does not apply)
Preferred Qualifications:
5+ years of programming experience with Python, Java, or NodeJS
3+ years of experience with AWS
3+ years of experience in open source frameworks
2+ years of experience in Agile practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Flagship Pioneering, Inc.
3.6",3.6,"Cambridge, MA",Senior Data Engineer,"About Empress
Flagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune's ""Change the World"" list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.
Founded by Flagship Pioneering in 2020, Empress Therapeutics generates good medicines, fast, by starting with chemistry inside the human body. The Empress Chemilogics™ platform uses novel insights that connect the lines of code in DNA with drug-like chemistry made in the human body to create first- or best-in-class oral medicines for a broad range of diseases quickly, predictably, and cost-effectively.
About the Position
At Empress Therapeutics, we are seeking a highly motivated, innovative, and collaborative Senior Data Engineer to join our Computational Discovery team. As a key member of the team, the successful candidate will work in close partnership with Scientists and Engineers to build a next-generation, metadata- and automation-driven data experience that enables decision making, increase productivity and reduce time spent on data processing.
Key responsibilities:
Design architecture and enable complete implementation of a data lake(s) compliant with FAIR, data privacy and corporate data security standards.
Design, implement, and maintain ETL/ELT pipelines to process and integrate multi-omics datasets from disparate sources.
Enable data validation and monitoring procedures to ensure data quality and accuracy.
Enable automation of end-to-end data flows: Faster and reliable ingestion of high throughput data in genetics, genomics and multi-omics and optimize data delivery to the lab scientists.
Evaluate commercial and open-source tools to improve our bioinformatics research pipelines; implement pipelines into our research workflows. Maintain awareness of new technologies and industry best practices, and champion innovative solutions.
Stay up to date with developments in the open-source community around data engineering, data science, and maintain awareness of industry best practices.
Navigate and work independently and report results to scientific team and management.
Key requirements:
MS/BS in Computational Biology, Bioinformatics, Computer Science, or related discipline. MS with 2+ yrs of industry or academic research experience (or BS with 5+ yrs of similar experience).
Hands on experience in data lake design, implementation, and maintenance.
Experience using Infrastructure as Code (IaC) to automate data infrastructure provisioning and management (e.g. Terraform, AWS CDK toolkit, CloudFormation).
Hands-on experience with Docker containers and container orchestration.
Programming experience in scripting languages such as Python & R, using version control (GitHub/Gitlab), and continuous integration environments.
Experience with schema design and data modeling. Data warehouse & BI Tools (Spotfire preferable).
Strong communication and presentation skills, capable of conveying technical information in a clear and thorough manner.
Ability to work independently in a multidisciplinary, fast-paced, entrepreneurial, and results-oriented environment.
Preferred requirements:
Background in life sciences, biotechnology, or biomedical engineering.
Experience working with Biotech and supporting genomic data pipelines, integrating data from data sources such as LIMS, ELN, and other 3rd party APIs.
Hands on experience with workflow management systems such as Snakemake, Airflow and Nextflow.
Knowledge of data science and AI/ML methodologies and experience building AI/ML-enabled solutions a plus
What We'll Offer You
The opportunity to learn about all aspects of our drug discovery platform and variety of new skills including working with automation.
Comprehensive, competitive healthcare and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, paid time off, 401k retirement plan, disability and life insurance, and fully covered parking/commuter benefits.
A dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team.
Opportunities to invent and discover.

Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. At Flagship, we recognize there is no perfect candidate. If you have some of the experience listed above but not all, please apply anyway. Experience comes in many forms, skills are transferable, and passion goes a long way. We are dedicated to building diverse and inclusive teams and look forward to learning more about your unique background.
Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, ""FSP"") do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering's internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.","$135,709 /yr (est.)",51 to 200 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2000,Unknown / Non-Applicable
"Iron EagleX
4.9",4.9,"Tampa, FL",Lead Data Engineer,"Overview:
Iron EagleX is a veteran owned defense contracting company based in Tampa, FL.

It is our mission to provide solutions to the most challenging technical problems facing the Department of Defense while simultaneously making a positive impact on our employees and community.
Responsibilities:
Job Description:

The Lead Data Engineer builds and maintains data systems and constructs datasets that are easy to analyze and support customer requirements. Implement methods to improve data reliability and quality. Combine raw information from different sources to create consistent and machine-readable formats. Develop and test architectures that enable data extraction and transformation for predictive or prescriptive modeling. Develop and deploy Application Programming Interfaces (API) to expose IDST maintained data to the enterprise.

Job Duties Include (but not limited to):

Acquire and assemble large, complex datasets that align with USSOCOM enterprise
Building, testing, and maintaining data infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using modern data
Develop analytics tools and transformative algorithms for data to provide actionable insights into customer processes, operational efficiency, and other key business performance metrics.
Create new data validation methods for analytics and data scientist team members that assist them in building and optimizing products to fulfill customer objectives.
Work with IDST stakeholders including USSOCOM leadership, customers, and design teams to assist with data-related technical issues and support their data infrastructure needs.
Analyze procedures for USSOCOM data separation, access, and security across users and the enterprise data architecture.
Work with IDST data and analytics experts to strive for greater functionality in our data systems and capability integration.
Create and maintain optimal data pipeline architecture and support associated process improvements for automating manual processes, data delivery, and infrastructure re-design for scalability.
Qualifications:
Required Skills & Experience

8 years’ experience as a data engineer or in a similar
Demonstrated experience employing data models, data mining, and segmentation techniques.
Demonstrated experience developing, deploying and/or maintaining enterprise level data solutions.
Experience with SQL database design
Python, SQL, NoSQL, Cypher, POSTGRES
Can write in modern coding languages; Python & JavaScript required; Experience with Flask and React preferred.
Can read and understand other coding languages; HTML/CSS, R, Java, C, C++, C#
Create respective process documentation using a web-based version control
Experience with Gitlab and Jira
Provide written and verbal communication and respective business process
Work independently and on teams and have excellent time management and work prioritization skills
Execute complex projects within government defined timelines across a geographically dispersed workforce and user base
Desired Skills

SQL Alchemy, Flask, Swagger, JavaScript, Spark, Hadoop, Kafka, Hive, R, storm, MATLAB, Neo4J, MongoDB
Data engineering certification is a plus
Education & Certifications:

Possess a minimum of a bachelor's degree in computer science, IT, or similar field.
Security Clearance:

Active TS Clearance and eligible for SCI required while TS/SCI is preferred.
Benefits:

National health, vision, and dental plans
20 days of PTO and 11 paid holidays
Life Insurance
Short- and long-term disability plans
401(K) retirement plan
Incentive and recognition programs
Relocation opportunities

Iron EagleX is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, among other things, or status as a qualified individual with disability.","$117,715 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,#N/A,Unknown / Non-Applicable
"CoxHealth
3.7",3.7,"Springfield, MO",Azure Data Engineer,"Summary

Job Summary

The Azure Data Engineer works directly with the Microsoft EDW Development team, supporting the CoxHealth System. To be successful in this position, the Engineer must have strong communication skills and the ability to collaborate with different analysts/developers across the team. This position is focused on the development of data management solutions within the Microsoft Azure Synapse environment.

Job Requirements

Education

Required: Bachelor’s Degree in Information Technology, Computer Science, or other related discipline OR 8 years' experience in IT or Computer Science

Experience

Required: 1 year experience in one of the following areas:
Experience with cloud-based technologies, preferably Azure, Data Factory, Databricks, Synapse Analytics, Azure Key Vault

Experience with Spark, preferably in a Databricks notebook-based development environment

Experience designing Data Lakes and Data Warehouses

Experience leveraging, designing, and building database schemas for analytics

Experience designing, building, and maintaining ETL/ELT data pipelines, preferably SSIS & Data Factory using multiple data source types like custom API sources, file based, RDBMs systems (SQL Server, Oracle, Snowflake, etc.)

Skills

Develop, test and configure automated deployments of data management solutions (data ingestion, transformation, modeling, interfaces, etc.)

Understand SQL query optimization, profiling, and performance monitoring tools & techniques

Excellent communication skills required with ability to effectively collaborate with members of the technical team and with business leaders in a fully-remote or hybrid capacity.

Must be very detailed oriented, with excellent organizational skills with the ability to manage/prioritize multiple tasks concurrently.

Licensure/Certification/Registration

None Required

Additional Information
Job Benefits & Perks!

Tuition reimbursement up to $1200 per year
Additional Educational Assistance programs available
Health/Dental/Vision
Retirement with employer match
20% tuition discount on most classes at Cox College
On-site Daycare with extended hours, holidays and weekends
Employee Discount at CoxHealth Fitness Centers
Pharmacy delivery to your unit
On-site Employee Health services
Opportunity to earn referral bonuses of up to $5,000 per hire for certain positions
1906 Employee Store
Cafeteria discount

If you would like more information about job benefits & perks, please feel free to email us @ hr-recruitment@coxhealth.com or visit https://www.coxhealth.com/employees/benefits/","$100,095 /yr (est.)",10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1906,Unknown / Non-Applicable
"Crackajack Solutions
3.3",3.3,"Wilmington, DE",Senior Python Data Engineer,"Senior Data Engineer With (Python /Data bricks)
Delaware, & Texas (Onsite Day 1/Hybrid)
12-24 Months
The Python Data Engineer role will be part of our client’s Data Engineering practice team and will be focused on building Data pipelines and Data processing solutions based on AWS platform for Digital Marketing domain.
The candidate will contribute to Competency development & driving innovation through various internal initiatives within the organization. Databricks Engineer should have more than 3 years of experience with broad exposure to AWS services relevant to Analytics and Data engineering.
Description
Over 10+ years’ experience as a Data Engineer including extensive experience in Databricks.
Experience in Spark, SQL performance tuning, and optimization.
Experience with architectural design and development of large-scale data platforms and data applications.
Good hands-on experience in AWS services like EC2, S3, RDS, KMS, IAM, STS, Redshift etc.
Good knowledge and experience in creating, securing, and managing Databricks clusters of Amazon Elastic Compute Cloud (Amazon EC2) instances.
Strong programming background with Java, Python and Pyspark.
Practical exposure to end-to-end design and implementation process of Near-Real-Time and Batch Data Pipelines.
Strong knowledge and understanding of Databricks Lakehouse Platform.
Knowledge of Databricks scheduling features to automate Databricks jobs.
Strong knowledge and experience in Databricks Lakehouse platform and Delta Lake.
Experience in managing, using and scheduling notebooks in Databricks.
Good experience in integrating and ingesting data from external data sources with Databricks including automating ETL using Delta Live Tables and Databricks Autoloader.
Strong SQL (Hive/Spark/Databricks) skills and experience tuning complex queries.
Good to have Databricks Lakehouse Data Engineer Associate or Data Engineer Professional certification.
Job Type: Full-time
Pay: $150,000.00 - $170,000.00 per year
Experience level:
10 years
11+ years
Schedule:
8 hour shift
Monday to Friday
Ability to commute/relocate:
Wilmington, DE 19801: Reliably commute or willing to relocate with an employer-provided relocation package (Required)
Education:
Bachelor's (Preferred)
Experience:
Databricks: 5 years (Preferred)
AWS Cloud: 5 years (Preferred)
Data Lake, Data IKU, Hadoop: 8 years (Preferred)
Python/Pyspark: 8 years (Preferred)
License/Certification:
Databricks Certified Data Engineer Professional (Preferred)
Work Location: Hybrid remote in Wilmington, DE 19801","$160,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Apple
4.2",4.2,"Cupertino, CA","AIML - Sr Machine Learning Engineer, Data & ML Innovation","Summary
Posted: May 17, 2023
Role Number:200464615
Do you want to innovate at the intersection of Machine Learning and Data to make Apple products smarter for our users? The Data and Machine Learning Innovation team is looking deeply into the end-to-end lifecycle of ML product development, and finding innovative ways to make it scalable and efficient. We are a R&D team with strong expertise in Applied Machine Learning, Data Engineering and Distributed Infrastructure. The team works broadly with Machine Learning teams across the company to advance capabilities in the data centric machine learning world. As part of our team, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional, and you will collaborate very closely with various highly skilled machine learning and software development teams developing groundbreaking solutions!
Key Qualifications
10+ years of technical leadership experience.
Excellent knowledge and experienced practical skills in major machine learning algorithms.
Extensive knowledge in design and development of large scale distributed and big data processing systems.
Mastery of one of following languages: Python, Java or C++, demonstrating strong background in algorithms and data structures.
Excellent interpersonal skills, ability to work independently as well as in a team.
Creativity and curiosity for solving highly complex problems.
Excellent data analytical skills.
Description
As a member of our fast-paced group you’ll have the unique and rewarding opportunity to shape upcoming products from Apple. Our team includes a diversity of background engineers focusing on making ML development lifecycle scalable and efficient. As such we are looking for candidates with both strong applied machine learning experiences and engineering skills.
Education & Experience
MS or Ph.D in Computer Science, Machine Learning or related field. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $242,700 and $364,100, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"OneStudyTeam
3.2",3.2,Remote,Senior Data Engineer,"At OneStudyTeam (a Reify Health company), we specialize in speeding up clinical trials and increasing the chance of new therapies being approved with the ultimate goal of improving patient outcomes. Our cloud-based platform, StudyTeam, brings research site workflows online and enables sites, sponsors, and other key stakeholders to work together more effectively. StudyTeam is trusted by the largest global biopharmaceutical companies, used in over 6,000 research sites, and is available in over 100 countries. Join us in our mission to advance clinical research and improve patient care.
One mission. One team. That's OneStudyTeam.
Our unique, rapidly growing data streams are enabling novel opportunities to manage clinical trials more efficiently and predictably. The Data Engineering team is looking for talented Senior Data Engineers to build, expand, and support a cutting-edge data architecture which is the analytical backbone of our company. If you are empathetic, business-driven, and want to use your data engineering and data architecture skills to make a tangible impact in the clinical research community then this may be the role for you.
We're looking for people who can effectively balance rapid execution and delivery with sustainable and scalable architectural initiatives to serve the business most effectively. You have strong opinions, weakly held, and while well-versed technically know when to choose the right tool, for the right job, at the right level of complexity. You will work closely with the rest of our Data Engineering team and our Data Science teams to help collect, stream, transform, and effectively manage data for integration into critical reporting, data visualizations, and ModelOps systems for emerging data science products.
What You'll Be Working On
Build reliable and robust data integrations with external partners
Supporting the development and expansion of modern, privacy-aware, data warehouse and data mesh architectures
Helping to build, manage, orchestrate, and integrate streaming data sources, data lakes, ELT processes, columnar storage systems, and distributed query execution solutions
Establishing proactive data quality/freshness dashboards, monitoring, alerting, and anomaly remediation systems
Building practical data onboarding tooling and process automation solutions
Learning to effectively understand and deftly navigate the global compliance ecosystem (HIPAA, GDPR, etc.) to ensure your work respects the rights, regulations, and consent preferences of all stakeholders, including historical underserved or underrepresented populations
Developing a deep understanding of the clinical ecosystem, our products, and our business and how they all uniquely interact to help people
What You'll Bring to OneStudyTeam
4+ years of experience successfully developing and deploying data pipelines and distributed architectures, ideally in a space similar to ours (startup, healthcare, regulated data)
Hands-on experience implementing ETL/ELT best practices at scale and demonstrated practical experience or familiarity with a good portion of our stack, including: AWS services (Redshift, MSK, Lambda, ECS, ECR, EC2, Glue, Quicksight, Spectrum, S3, etc.), Postgres, dbt, Kafka, Prefect, Docker, Terraform
Excellent programming skills in Python and deep comfort with SQL. Clojure experience is also highly appreciated
Experience or interest in developing and managing enterprise-scale data, distributed data architectures
Able to independently ship medium-to-large features and start to support or participate in architectural design
Excellent written and verbal communication skills
Strong attention to detail is key, especially when considering correctness, security, and compliance
Solid software testing, documentation, and debugging practices in the context of distributed systems
Learn more about our global benefits offerings on our careers site: https://careers.onestudyteam.com/us-benefits
We value diversity and believe the unique contributions each of us brings drives our success. We do not discriminate on the basis of race, sex, religion, color, national origin, gender identity, age, marital status, veteran status, or disability status.
Note: OneStudyTeam is unable to sponsor work visas at this time. If you are a non-U.S. resident applicant, please note that OST works with a Professional Employer Organization.
As a condition of employment, you will abide by all organizational security and privacy policies.
For a detailed overview of OneStudyTeam's candidate privacy policy, please visit https://careers.onestudyteam.com/candidate-privacy-policy. This organization participates in E-Verify (E-Verify's Right to Work guidance can be found here).",#N/A,201 to 500 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2012,Unknown / Non-Applicable
"CGI Group, Inc.
3.9",3.9,"Reston, VA",Sr. Data Engineer (Python/AWS),"Sr. Data Engineer (Python/AWS)

Position Description
CGI has an immediate need for a Sr. Data Engineer (Python/AWS) to join our financial services team in Reston, VA. This is an exciting opportunity to work in a fast-paced team environment supporting one of the largest leaders in the secondary mortgage industry. We take an innovative approach to supporting our client, working side-by-side in an agile environment using emerging technologies.
We partner with 15 of the top 20 banks globally, and our top 10 banking clients have worked with us for an average of 26 years!
We have over 73,000+ CGI Members in 40 countries and over 5k+ loyal Clients who are leveraging our end-to-end services across the globe

Description
We are seeking a Python Developer with AWS For a large financial service client.

Your future duties and responsibilities
In this role you will be focused on AWS Development and Architecture. We are looking for hands-on professionals who can build good technical solutions and then roll up their sleeves to implement the solution.

Required qualifications to be successful in this role
8+ years of IT Data Engineering experiences.
4+ years of experience with Python (must have)
Must have strong experience with SQL, Databases (Oracle, PostgreSQL, Aurora)
2+ years of experience with Data engineering (EMR, PySpark, Redshift, Glue)
Strong experience with data migration, cloud migration, and ETL.
Strong experience with AWS Lambda, Fargate, SNS, Elastic Beanstalk, ECS, and CloudWatch.
Experience with enterprise data lakes, data warehouses, data marts, and big data.
Excellent communication skills to ask questions, clarify requirements, and engage with the team and stakeholders.
Strong logic, reasoning, and critical thinking skills to solve problems as they arise.
Must be an independent problem solver who can evaluate a situation and build solution options.
Strong Python, Strong working AWS experience, Databases (Oracle, PostgreSQL, Aurora) Data engineering (EMR, PySpark, Redshift, Glue), Serverless experience (Lambda, step functions), containerization (ECS with Fargate)

Desired Skillset
SAS knowledge
DevOps knowledge (Jenkins, Bitbucket, Terraform/UCD/CloudFormation)
Testing Automation

EDUCATIONAL REQUIREMENTS
Bachelor's degree in computer science, Information Systems or related field
AWS Certification(s) desired

#LI-PK1
#DICE

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and licensure and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $67,200.00 - $146,900.00.

Insights you can act on

While technology is at the heart of our clients' digital transformation, we understand that people are at the heart of business success.

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees ""members"" because they are CGI shareholders and owners and owners who enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today - one of the world's largest independent providers of IT and business consulting services.

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where all belong and collaborate with clients in building more inclusive communities. As an equal-opportunity employer, we want to empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.

Ready to become part of our success story? Join CGI - where your ideas and actions make a difference.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, pregnancy, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will consider for employment qualified applicants with arrests and conviction records in accordance with all local regulations and ordinances.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.",#N/A,10000+ Employees,Company - Public,Management & Consulting,Business Consulting,1976,$10+ billion (USD)
"CRISP Shared Services, Inc
5.0",5.0,"Columbia, MD",Data Engineer - CRISP Insights,"Description:
Company Description
CRISP Shared Services (CSS) serves as the designated Health Information Exchange (HIE) for Maryland and Washington, D.C., with affiliates in West Virginia, Connecticut, Alaska, and Virginia. CSS facilitates the electronic transfer of clinical information between disparate information systems in order to positively impact the healthcare system through improved patient care and outcomes, reduced costs, and data-driven understanding of regional public health concerns.
Job Summary
The Data Engineer will be responsible for supporting HIT activities in the Baltimore/Washington region. The successful candidate will work to design, develop, and maintain a data analytics platform solution. CRISP is currently running an Azure Data Lake 2 / Azure Data Factory / Spark / Databricks infrastructure with approximately 300 production use cases that consolidate several streams of healthcare data. This role will primarily focus on the creation of new use cases through Databricks programming including communication, technical proficiency, collaboration, and willingness to learn new things. This role assists a senior data engineer to implement new ingestion pipelines and troubleshoot production issues.
This position will have a base salary.
This position requires the candidate to be in the Columbia office 1-2 days a week.
Requirements:
ESSENTIAL DUTIES AND RESPONSIBILITIES
Include the following. Other duties may be assigned.
Create new business data sources from the available data in the data platform:
Work with source system owners to understand integration needs.
Work with business users to understand reporting needs.
Implement Databricks and Azure Data Factory components to transform the data into business facing datasets.
Perform unit and integration testing of business facing datasets.
Document business use cases.
Maintain existing data sources in data platform pipeline:
Monitor data pipeline job status and troubleshoot issues.
Work with source system owners and business owners to incorporate business changes into data pipeline (i.e., updating metadata file to add new object, update curated layer query, etc.).
Perform automated data quality checks on data pipelines.
Perform continuous improvement.
Qualifications
To perform this job successfully, the incumbent must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Required Skills
Experience in a production Data Lake or Data Warehouse environment
Data Integration – Intermediate
Data Lake Design Patterns – Familiar
SQL – Intermediate
Agile Methodologies – Familiar
Ability to develop programming components to build complex business use cases
Ability to prioritize and manage multiple job duties, including personal time management and organization skills
Ability to diagram and understand technical workflows
Preferred Skills
SQL - Intermediate
Python - Intermediate
Cloud Infrastructure (Azure) - Foundational
Education and/or Experience
4-year college degree
2+ years of working with data integration, 1+ years with Masters degree
www.crisphealth.org
www.crispsharedservices.org","$101,385 /yr (est.)",Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Leidos
3.8",3.8,Remote,Data Center Facilities Engineer,"Description

Leidos is hiring a Data Center Facilities Engineer at Ft. Meade, MD.
POSITION SUMMARY:
The selected candidate will be part of the Defense Enclave Services (DES) team to lead data collection, design, and implementation of tasks associated with the management of: cable plant, floor space, heating and cooling, and physical data center security. This engineer will establish the key data points that are inputs to migration planning efforts, and collect the predefined information through documents, site surveys, and customer interviews. Using the data collected the engineer will create migration plans that include technical designs and a schedule of migration tasks.
CLEARANCE REQUIREMENT:
Must hold an active Secret clearance prior to start. (US Citizenship required)
PRIMARY RESPONSIBILITIES:
Evaluate, design, and deploy the central components of data center facilities, including: power, cooling, physical security, floor space management, and cable management.
Define monitoring and management requirements.
Providing professional engineering advice to facility technicians, including design, planning, specifications, and operation of electrical and mechanical equipment, HVAC systems design and operation, as well as structural and architectural considerations in field locations.
Providing guidance and recommendations to government management regarding engineering and facilities issues.
Working in close collaboration with Network Engineers, Server Engineers, Cyber Engineers, Storage Engineers, Data Experts, and other key technical resources.
Identify procurement and tracking of maintenance materials, safety supplies, and spare components.
Ensuring compliance with all applicable building codes and standards.
Maintaining the inventory of buildings and installed systems, and establishing maintenance and replacement cycles.
Performing facility condition assessments.
Developing and proposing facility upgrade and replacement projects.
Possess strong soft skills in the form of documentation and client communications.
Able to perform physical activities including heavy lifting, climbing in and out of equipment, crawling, and working outdoors in cold, dry, high elevation environments.
BASIC QUALIFICATIONS:
Bachelor’s Degree and 12+ years of prior relevant experience; additional years of experience may be substituted in lieu of a degree.
Possess professional knowledge of Architectural, structural, mechanical, electrical, and fire protection engineering concepts and principles.
Experience in asset reliability centered maintenance strategies that target preventive/predictive maintenance.
Communicate effectively, both orally and in writing, with management and staff to present, defend, negotiate, and clarify programs, decisions and recommendations.
Field construction experience including managing changes, quality control, deliverables, redlining drawings, and other activities supporting work completion.
Experience with procurement and material tracking.
Current United States Passport, and valid Driver’s License issued in the United States.
Proactively identify any unsafe conditions or hazards and communicate them effectively.
Complies with applicable safety, environment, health, and waste management policies and procedure.
PREFERRED QUALIFICATIONS:
Experience with resource loaded scheduling.
Experience with fire safety systems including fire alarm systems and suppression.
Experience with Data Center Infrastructure Management solutions.
DISADES
External Referral Eligible
Pay Range:
Pay Range $105,300.00 - $190,350.00
The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.
#Remote","$147,825 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1969,$10+ billion (USD)
"ampliFI Loyalty Solutions
4.2",4.2,Remote,Intermediate Data Engineer,"About ampliFI Loyalty Solutions
ampliFI provides fully outsourced, customized credit and debit card loyalty programs exclusively focused on banks and credit unions nationwide. For almost two decades, we have delivered compelling rewards programs, unique earn and burn opportunities and card-linked programs to leverage merchant funded offers. Here at ampliFI, we are always looking for more great people to be a part of the relentless pursuit of excellence in everything we do. Our core values are Integrity, Curiosity, and Advocacy for our clients. We are looking for a Intermediate Data Engineer (Level 2). Local candidates with a hybrid schedule are strongly preferred. However, well qualified, fully remote candidates outside the area may be considered.
Summary
As an Intermediate Data Engineer, you are familiar with the data warehousing technical components, infrastructure, and their integration. You’ll analyze large amounts of data, discover and solve real world problems. You love the idea of being able to provide insight as well as presenting those insights. You are responsible for high level design/architecture. You are comfortable fostering relationships with internal business partners and other members of the development team.
Key Responsibilities:
Design, develop, and maintain modular code base to solve “real” world problems.
Conduct regular peer code reviews to ensure code quality and compliance following best practices in the industry.
Work in cross-disciplinary teams to understand client needs and ingest rich data sources.
Research, experiment, and utilize leading Big Data technologies in AWS.
Help drive the process for pursuing innovations, target solutions, and extendable platforms for ampliFI’s products.
Participate in developing and presenting thought leadership and assist in ensuring that ampliFI’s “data source” technology stack incorporates and is optimized for using specific technologies.
Education and Experience:
3+ year of professional work experience in Data Engineering using big data methodologies with multiple programming languages and technologies.
Experience working efficiently under Unix/Linux environment.
Experience with source code management systems like GIT.
Experience and demonstrated proficiency with Python, Pandas, Spark and Java
Bachelor of Science degree from an accredited college/university in Computer Science, Information Technology, Computer Engineering, or related field (i.e. math and physics) required. Master’s degree a plus.
Competencies, Knowledge and Skills
Qualified individuals possess the ampliFI attributes of being smart, curious, committed to vision, passionate, fun/pleasant, an achiever and having a sense of urgency.
Ability to manage established relationships internally as well as with clients.
Ability to communicate complex technical concepts succinctly to non-technical colleagues, understand & manage interdependencies between all facets of a project.
Ability to interface with internal clients; Must have demonstrated advanced proficiency in complex, mature and sophisticated design & analysis technologies and solutions.
Skilled ability to rapidly ingest, transform, engineer, and visualize data, both for ad hoc and product-level (e.g., automated) data & analytics solutions.
Experience with large-scale, AWS big data methods such as EC2, S3, EMR, Kinesis, DynamoDB, Athena, AWS-Glue and Redshift.
Demonstrated strong knowledge of programming methodologies (Terraform, version control, testing, QA) and agile development methodologies.
Physical Requirements:
Frequently required to sit and stand.
Required to use hands to handle or feel objects, tools or controls.
Visual acuity and manual dexterity required to code using software and a laptop computer.
Other Duties:
Duties, responsibilities and activities are not all encompassing and may change at any time with or without notice. To perform this job successfully, an individual must be able to perform each essential job duty satisfactorily. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform essential job functions

ampliFI Loyalty Solutions embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are the better our company will be.",#N/A,Unknown,Company - Public,Financial Services,Financial Transaction Processing,#N/A,Unknown / Non-Applicable
"Meta
3.9",3.9,"Seattle, WA",Software Engineer - Data Center Networking,"The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!


Software Engineer - Data Center Networking Responsibilities:
Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).
Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI
Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.



Minimum Qualifications:
Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.
4+ years of experience in C/C++ and Python
4+ years experience in Systems programming, TCP/IP, HTTP/HTTPS, SPDY, DNS, and load balancers
Experience with network devices (routers, switches, load balancers) and an understanding of network routing protocols
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment



Preferred Qualifications:
Experience with Linux Kernel, especially drivers and network stack
Working knowledge of transport stack particularly RDMA (RoCEv2)
Experience with Qemu, FPGA Emulation environment is a plus
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL
Experience with parallel computing platforms such as CUDA, RoCM and OpenCL Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$173,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Lumen
3.5",3.5,Remote,Sr. Data Engineer,"About Lumen
Lumen is guided by our belief that humanity is at its best when technology advances the way we live and work. With 450,000 route fiber miles serving customers in more than 60 countries, we deliver the fastest, most secure global platform for applications and data to help businesses, government and communities deliver amazing experiences. Learn more about Lumen’s network, edge cloud, security and communication and collaboration solutions and our purpose to further human progress through technology at news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies and YouTube: /lumentechnologies.
The Role
Are you interested in serving as an integral part of our digital marketing team developing new tools and capabilities that will continue to advance Lumen’s reputation as a technology leader?

In this role, you will be partnering closely with marketing, operations, and data science teams to utilize terabytes of data and translate them into actionable insights to create a competitive advantage for marketing/sales initiatives to win market share. Furthermore, you will be accountable for building and operationalizing critical components and tools to ensure the data coming in and going out are of the highest data quality and integrity. In the end state, the data solutions built and operated by you would rival the absolute best in the industry in engineering, operations, and usability excellence.
The Main Responsibilities
You are a great fit for this position if you:
Have strong passion in building reliable, accurate datasets that power end-to-end user scenarios and used in business decisions.
Highly believe that data is an asset that must be accessible to and applicable by every function in a modern business to guide and assess growth investments.
Are passionate about Data Engineering and believe that it is one of a kind emerging discipline and career path that you want to grow in.
Enjoy building and operating data services at terabyte and higher scales to enable data driven organizations.
What We Look For in a Candidate
Qualifications:
Experience building data models and performing complex queries using SQL
Experience performance tuning large datasets
Experience building large data pipelines and/or web services
Strong programming skills with Python and other scripting languages
4+ years of Business Intelligence or software development experience using industry technologies
3+ years of experience in building integration with upstream and downstream systems with REST APIs
Excellent problem solving, critical thinking, and communication skills
Ability to communicate effectively with technical and business teams, drive issues to closure
Strong understanding of data engineering and data stewardship roles in an organization
Strong time management and organization skills. Ability to work on multiple projects concurrently.
BA/BS in Computer Science, Engineering or related technical field such as Statistics or Data Science

Other Qualifications:
Strong familiarity with big data and Hadoop ecosystem of tools is highly valuable
Knowledge of Lumen data, systems and processes including paid media, financial and inventory systems highly desirable
Experience with ETL and data integration development using multiple tools, including Informatica, Microsoft SSIS or other technologies
Combined IT and Marketing background
Machine Learning, Data Science, and statistical modeling experience are highly valued
Azure experience.
Requisition #: 329671
When applying for a position, you may be subject to a background screen (criminal records check, motor vehicle report, and/or drug screen), depending on the requirements for the position. More information on what’s included in these checks can be found in the Post Offer section of our FAQ page. Job-related concerns noted in the background screen may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.
EEO Statement
We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, marital status, family status, pregnancy, or other legally protected status (collectively, “protected statuses”). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.
NOTE: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
Disclaimer
The above job definition information has been designed to indicate the general nature and level of work performed by employees within this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job. Job duties and responsibilities are subject to change based on changing business needs and conditions.
Salary Range
Salary Min :
72540
Salary Max :
161520
This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.
This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.
As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.
Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.","$117,030 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1968,$10+ billion (USD)
"CVS Health
3.1",3.1,"Irving, TX",Associate Data Engineer,"Bring your heart to CVS Health Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver.

Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.
Position Summary
CVS Health has a rich set of healthcare data for more than 150 million individuals and provides the best foundation for any ambitious data engineer to:

Solve the complex business problems using all the modern tools and technologies
Securely store, process, transform and enrich terabyte to petabyte scale of highly confidential healthcare data that helps in taking data driven business decisions
Provide best-in-class environment where everyone brings their heart to work to build technical solutions to support customers.
Training and development will be a part of your role.

As an Associate Data Engineer you will:

Manage and support production platform to ensure the quality, performance, and availability of the services that meets business requirements for various CVS Lines of Business
Identify, design, and implement engineering process improvements through automating manual processes, optimizing data pipelines, re-designing services for greater scalability.
Required to support an on call 24 x 7 cloud Production Environment supporting and administering products & Services involving platform technologies like GCP, Azure, etc.
Work hands-on with customers to develop, migrate, and debug services issues.
Ensure server/process documentation is up to date and appropriate or create documentation where none may exist.
Tier 2 triage, troubleshooting, remediation, and escalation of tickets tied to the product support function.
Build data pipelines using Azure/GCP platform.

Required Qualifications
6 months of related work experience (can include internships/course work) including:

Experience in Azure/GCP (Big Query, GCS, Pub/Sub, DataProc, Airflow/Composer, Snowflake, Azure Cloud Services etc.)
Experience in Unix/Shell Scripting
Experience in Python
Experience in SQL

Preferred Qualifications
Experience in Service Now ticketing system
Hands on experience in designing and building data engineering solutions in cloud environments (preferably Azure/GCP).
Hands-on experience with languages like Python, PySpark, SQL, UNIX/Linux scripting to access, extract, manipulate and summarize data.
Strong understanding of query optimization, data structures, transformation, metadata, dependency, and workload management
Experience with CI/CD pipeline, and other DevOps principles/best practices
Experience with Cloud based tech stack and Cloud components including cluster management, Kubernetes, or other containerized services, storage, and workspace management.
Experience working in multi-developer environment, using version control (i.e. Git).
Certified Cloud Engineer in Data engineering track: Azure/GCP preferred
Good articulation in communicating complex technical subjects to non-technical audience
Working experience with automation and orchestration tools
Experience with modern API and microservice patterns
Knowledge and working experience in agile frameworks like Scrum. Kanban etc.
Familiarity in Retail / Healthcare / Insurance industry

Education
Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline

Master’s degree or PhD preferred
Pay Range
The typical pay range for this role is:
$60,000.00 - $144,000.00
This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.

In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.

For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits
CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.
You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.
CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health colleagues can initiate a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through myHR (1-888-694-7287, or through myLeave at myHR). If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.","$102,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1963,$10+ billion (USD)
"Nike
4.2",4.2,"Beaverton, OR",Sr. Data Engineer,"Become a Part of the NIKE, Inc. Team

\r

\r

NIKE, Inc. does more than outfit the world's best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it's about each person bringing skills and passion to a challenging and constantly evolving game.

Sr. Data Engineer-NIKE, Inc., Beaverton, OR. Design and build reusable components, frameworks and libraries at scale to support analytics products; design and implement product features in collaboration with business and Technology stakeholders; identify and solve issues concerning data management to improve data quality; clean, prepare and optimize data for ingestion and consumption; collaborate on the implementation of new data management projects and re-structure of the current data architecture; implement automated workflows and routines using workflow scheduling tools; build continuous integration, test-driven development and production deployment frameworks; review design, code, test plans and dataset implementation performed by other data engineers in support of maintaining data engineering standards; analyze and profile data for designing scalable solutions; troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues; develop architecture and design patterns to process and store high volume data sets; and participate in an Agile / Scrum methodology to deliver high - quality software releases through Sprints. Telecommuting is available from anywhere in the U.S., except from AK, AL, AR, DE, HI, IA, ID, IN, KS, KY, LA, MT, ND, NE, NH, NM, NV, OH, OK, RI, SD, VT, WV, and WY.

Employer will accept a Master's Degree in Computer Science, Engineering, Computer Information Systems, Electronics and Communications, or Technology and two (2) years of experience in the job offered or a data engineering related occupation.

Experience must include:
Programming languages such as Python, Java, and Scala;
Big Data Frameworks such as Hadoop, Hive, Spark, and Databricks;
ETL Tools such as Informatica and PL/SQL;
Scripting such as Unix, and PowerShell;
Databases, such as Oracle, MYSQL, SQL Server, Teradata, and Snowflake;
AWS tools such as EMR, S3, and Kinesis;
Analytics Tools, such as Tableau and Cognos;
Streaming Frameworks such as Kafka and Spark Streaming; and
Workflow orchestration tools such as Airflow and Autosys.

#LI-DNI

NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.

NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.

How We Hire

At NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best - and to do that, you need to understand how the hiring process works. Transparency is key.

This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.

Benefits

Whether it's transportation or financial health, we continually invest in our employees to help them achieve greatness - inside and outside of work. All who work here should be able to realize their full potential.","$111,914 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Consumer Product Manufacturing,1972,$10+ billion (USD)
"SSR Mining
3.4",3.4,"Denver, CO",Junior Data Engineer,"Who Are We?

SSR Mining Inc. is a leading, free cash flow focused intermediate gold company with four producing assets located in the USA, Turkey, Canada, and Argentina, combined with a global pipeline of high-quality development and exploration assets in the USA, Turkey, Mexico, Peru, and Canada.
SSR Mining is committed to delivering excellence through the contributions of our dedicated employees. With an industry-leading pipeline of projects, strong financial positioning, and talented employees, we aim to continue building on our strong foundation – we have high expectations for the future!
Job Description:
Help deploy and manage custom built applications and support these developed products. Apply the latest technologies where applicable to help solve problems within the business. Help deliver data flows and algorithms. Maintain current applications and services to maximize uptime and deliver reliable applications. Manage data pipelines that feed the company’s data hierarchy. Help create and maintain continuous integration and deployment of applications. Being a part of the growth and innovation team, there will be a customization of projects to fit the need of the business
The day to day:
The Engineer is primarily responsible for helping to develop and execute SSR’s innovation initiatives and OT standards. Including duties outlined below:
Collaborate with mine operations personnel to enhance on site relationships and maintain data integrity.
Execute the digital convergence of the technical value stream with operational tactical planning.
Help create and deploy on-premises applications developed by the data innovation team.
Assist in managing, supporting, and deploying Python, Docker, Kubernetes, Lua, C#, .NET, SQL, Angular solutions.
Monitor servers to prevent any server and application downtimes.
Assist mine operations in troubleshooting and developing their applications and calculations that drive the business.
Assist in developing computational, mathematical, mechanical, and chemical models for the process and mine operations to utilize.
Responsible for working with the sites to design and implement technical solutions.
This position is specialized in its complexity and involves independent judgment to develop and maintain the software required to aggregate all business operational data streams into a single coherent view.
Is this you?
University degree in Chemical Engineering, Geology and/or Mining Engineering with a programming background or Computer Science Engineering or equivalent practical experience.
Minimum of 1 years of technical work experience, preferably in a mining or oil and gas company with exposure to multiple mining and extraction methodologies.
Ability to problem solve through thinking systematically, experimentation, and applying innovative and disruptive solutions.
Comfortable interfacing at all levels of the company from site staff through to senior management.
Experience in the use of multiple programming languages, database types, and knowledge of the many data transfer protocols used in the mining industry.
Previous experience in virtualization and container orchestration. Kubernetes, docker, helm.
Familiarity with basic networking protocols.
Knowledge of python, SQL, .NET, Angular, Lua, Docker, Kubernetes, Helm, PHP are preferred.
Willingness to learn new technology.
Periodic domestic and international travel required.
Awareness of culture and business environment issues in Latin America and/or Turkey preferred
Experience working with technology, data science, software engineering, and industrial mathematic service providers.
For applicants residing in CO, the salary range for this role is from $75,000-$95,000.
Benefits: 401(k); medical/dental/vision insurance; employee share purchase plan, PTO, and STI.
#INDSSR
SSR Mining Inc. is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.","$85,000 /yr (est.)",501 to 1000 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Pacific Northwest National Laboratory
3.9",3.9,"Richland, WA",Early Career Data Engineer - Richland,"Overview:
Protecting U.S. residents and visitors is among our nation’s highest priorities. As adversaries gain access to sophisticated technologies and materials, the threats grow more dynamic and complex—from cyber and nuclear to chemical and biological weapons of mass effect and other forms of terrorism. The PNNL national security mission employs our researchers, tools, and technologies to play a key role in advancing the ability to identify and secure nuclear materials, detect weapons of mass effect, manage nonproliferation treaties, secure our nation's borders, and protect critical infrastructures. PNNL’s scientific discovery and capabilities—rooted in innovative theory, methods, algorithms, and tools—are enabling stronger, more resilient technologies and systems to safeguard national security. Coupled with decades of radiological and nuclear materials expertise, advanced computing and threat analysis capabilities, and a broad fundamental science base, we are identifying and countering emerging threats that have significant impact at home and around the globe.

Join a group of 90 software engineers using the latest technologies to solve the hardest problems for our nation. We are seeking early career data engineers to design, build, and deploy scalable data pipelines and analytics/machine learning solutions.

Critical Technologies
Programming & Scripting - Python, GO, Rust, Java, Scala
Compute – IoT/ICS, Linux, Fargate/EC2, ECS/Docker, EKS/Kubernetes, EMR
Development – Git/Gitlab, Agile, Atlassian, CDK, CI/CD, DevOps, IDE
Data and Storage – S3, Athena, Postgres, Elasticsearch/OpenSearch, Dynamo, Redshift, MongoDB
Pipelines – IAM, Cognito, Nifi, Airflow, Dagster, Spark, Lambda, Beats, Splunk
Analytics – Dask, Numpy & Pandas, DataBricks, SageMaker, Tensorflow/Keras, PySpark
National Interest Project Examples
Detect and prevent smuggling of drugs and contraband at ports of entry [Link]
Develop large data pipelines to thwart funding for terrorists, nuclear proliferators, drug cartels, and rogue leaders [Link]
Applying big data solutions to national security problems [Link]
Applying image classification for nuclear forensics analysis [Link]
Detect and respond to advanced cyber threats with at-edge computing [Link]
Develop capabilities for scalable geospatial analytics [Link]
Use remotely sensed imagery to identify and monitor the progression of wildfires [Link]
Analyze the resiliency of the electric power grid to prevent large-scale outages [Link]
Optimize building efficiency using IOT and ICS data with automated demand-response markets [Link]
Model climate change and impacts to civilization [Link]
Hunt for the existence of dark matter to understand the nature of the universe [Link]
Data Complexities
Volume – large, we work with terabytes and petabytes
Variety – Images, audio, text, IoT, RF, GPS, edge sensors
Velocity – Sub-second and lower frequency
How We Work
Diverse and flexible projects – Flexibility to choose and move between projects
Agile development environment – Scrum meetings, standups, demos, and retrospectives
Partners – Work with government, academic, industry, and other partners to solve problems
Locations – Seattle, WA; Richland, WA; Washington, DC
Team Sizes – Typically around 5-10 members, although projects can be more than 100 or just a few members
Team Compositions – Our teams include cloud engineers, machine learning engineers, data scientists/domain experts, UI/UX designers, front-end developers, scrums masters, product owners, and most importantly, users
A day in the life of a data engineer at PNNL might involve exploring new scientific data and creating robust datasets. You will create data pipelines to store in large databases, feed to AI/ML and create new data analysis tools to tackle national level problems. You will work with Cloud engineers to deploy to AWS and Azure, ML researchers to develop production ready models, and analysts to extract new features and derive new insights. You will hit a sprint demo to show off your biweekly progress and then call it a day. All along you will know that your deployment answered a critical national security problem, something that might have been discussed on the evening news.

Missing some of these skills or experiences? That’s okay. If you have relevant technical expertise, are highly driven, and are very motivated to learn these technologies and tackle these domain problems, let’s talk.

Rockstar Rewards:
Employees and their families are offered medical insurance, dental insurance, vision insurance, health savings account, flexible spending accounts, basic life insurance, disability insurance*, employee assistance program, business travel insurance, tuition assistance, supplemental parental bonding leave**, surrogacy and adoption assistance, and fertility support. Employees are automatically enrolled in our company funded pension plan* and may enroll in our 401k savings plan. Employees may accrue up to 120 vacation hours per year and may receive ten paid holidays per year.
Research Associates excluded.
**Once eligibility requirements are met.

Click Here For Rockstar Rewards
Responsibilities:
Responsibilities include:
Identify mission challenges and formulate engineering solutions methodically
Embrace software engineering excellence and delivering quality results at scale
Employ expertise with a high-level programming language such as Python
Apply good design and innovative problem-solving skills to solve challenging technical problems
Stay current about data management and database technology developments
Initiate personal direction and goals
Possess interest and/or experience mentoring junior scientists and engineers
Demonstrate outstanding verbal and written communication skills and the ability to work in a collaborative environment
Be passionate and self-motivated with good time management skills
Qualifications:
Minimum Qualifications:
BS/BA or higher
Preferred Qualifications:
Degree in computer science, software engineering, or related field
2+ years of experience in designing or deploying large-scale and high-performance ETL pipelines and analytics
2+ years Python or other software development experience
Strong understanding of software engineering and data management best practices
Strong cloud architecture and implementation experience
Cloud and database certifications are a plus
Familiar with machine learning algorithms with hands-on experience in machine learning pipeline development is a plus.
Active Federal Q Clearance and ability to maintain such clearance
Hazardous Working Conditions/Environment:
Not applicable.
Additional Information:
This position requires the ability to obtain and maintain a federal security clearance.
Requirements:
U.S. Citizenship
Background Investigation: Applicants selected will be subject to a Federal background investigation and must meet eligibility requirements for access to classified matter in accordance with 10 CFR 710, Appendix B.
Drug Testing: All Security Clearance positions are Testing Designated Positions, which means that the candidate selected is subject to pre-employment and random drug testing. In addition, applicants must be able to demonstrate non-use of illegal drugs, including marijuana, for the 12 consecutive months preceding completion of the requisite Questionnaire for National Security Positions (QNSP).
Note: Applicants will be considered ineligible for security clearance processing by the U.S. Department of Energy until non-use of illegal drugs, including marijuana, for 12 months can be demonstrated.
Testing Designated Position (TDP):
This position is a Testing Designated Position (TDP). The candidate selected for this position will be subject to pre-employment and random drug testing for illegal drugs, including marijuana, consistent with the Controlled Substances Act and the PNNL Workplace Substance Abuse Program.
About PNNL:
Pacific Northwest National Laboratory (PNNL) is a world-class research institution powered by a highly educated, diverse workforce committed to the values of Integrity, Creativity, Collaboration, Impact, and Courage. Every year, scores of dynamic, driven people come to PNNL to work with renowned researchers on meaningful science, innovations and outcomes for the U.S. Department of Energy and other sponsors; here is your chance to be one of them!

At PNNL, you will find an exciting research environment and excellent benefits including health insurance, flexible work schedules and telework options. PNNL is located in eastern Washington State—the dry side of Washington known for its stellar outdoor recreation and affordable cost of living. The Lab’s campus is only a 45-minute flight (or ~3-hour drive) from Seattle or Portland, and is serviced by the convenient PSC airport, connected to 8 major hubs.
Commitment to Excellence, Diversity, Equity, Inclusion, and Equal Employment Opportunity:
Our laboratory is committed to a diverse and inclusive work environment dedicated to solving critical challenges in fundamental sciences, national security, and energy resiliency. We are proud to be an Equal Employment Opportunity and Affirmative Action employer. In support of this commitment, we encourage people of all racial/ethnic identities, women, veterans, and individuals with disabilities to apply for employment.

Pacific Northwest National Laboratory considers all applicants for employment without regard to race, religion, color, sex (including pregnancy, sexual orientation, and gender identity), national origin, age, disability, genetic information (including family medical history), protected veteran status, and any other status or characteristic protected by federal, state, and/or local laws.

We are committed to providing reasonable accommodations for individuals with disabilities and disabled veterans in our job application procedures and in employment. If you need assistance or an accommodation due to a disability, contact us at careers@pnnl.gov.
Drug Free Workplace:
PNNL is committed to a drug-free workplace supported by Workplace Substance Abuse Program (WSAP) and complies with federal laws prohibiting the possession and use of illegal drugs.

If you are offered employment at PNNL, you must pass a drug test prior to commencing employment. PNNL complies with federal law regarding illegal drug use. Under federal law, marijuana remains an illegal drug. If you test positive for any illegal controlled substance, including marijuana, your offer of employment will be withdrawn.","$73,091 /yr (est.)",5001 to 10000 Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1965,$1 to $5 billion (USD)
"LinQuest Corporation
4.0",4.0,"San Antonio, TX",Data Engineer,"LinQuest is looking for an energetic and innovative Data Engineer in San Antonio Texas to assist an Air Force Major Command in the operations of the Command Data Office (CDO). US citizenship and the ability to obtain a DoD security clearance are required.
Position Summary
Ideal candidates will have experience providing technical support and managing technical programs throughout the life cycle of data operations. As a Data Engineer, the candidate will be adept at using large data sets to find opportunities for business optimization and using models to test the effectiveness of different courses of action. The Data Engineer candidate should have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using and creating algorithms and/or creating and running simulations. Candidates must have a proven ability to generate data-driven insights. Candidates must be comfortable working with a wide range of stakeholders and functional teams that work across multiple timezones, and have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. As a Data Engineer, you will have the opportunity to work with unstructured and structured data, develop databases, build data pipelines, and find innovative solutions to complex data problems. Candidates should be familiar with state-of-the-art data engineering techniques and have hands-on experience with data pipelines and should be comfortable manipulating, processing, and extracting value from large unstructured and structured datasets.

Key Responsibilities:
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries.
Research state-of-the-art data mining methods and innovative statistical models
Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables
Process, cleanse, and verify the integrity of data used for analysis
Clearly document and present methodology, assumptions, and findings to stakeholders
Required Skills and Experience:
Bachelor’s degree in Computer Science, Data Analytics, Software Development, Information Technology, or related experience
1-5 Years of experience in data engineering
Manipulating data with SQL, Python
Developing data pipelines to support Analytics
Documenting and communicating results of analysis
Experience manipulating data from spreadsheets (i.e. MS Excel)
Experience with Business Intelligence (BI) Tools (Power BI, Tableau, Qlik etc.)
Strong analytical and problem-solving skills with hands on experience with driving analytic insights
Ability and motivation to self-teach in order to stay current with leading best practices in analytics
Ability to tackle difficult problems specifically working with unstructured textual data
Data wrangling skills
Expected to deliver in a fast-paced, team-oriented work environment
Must thrive in satisfying analytic requirements from diverse user base
Expected to be able to adapt quickly to changing needs across several core areas, including data wrangling, data exploration, data analysis, and data visualization
Must have the knowledge and communication skills to articulate trade-offs between analytic techniques, recommend a course of action to clients, and provide effective updates on project outcome uncertainty to leadership
US Citizenship and ability to acquire a DoD SECRET clearance
Preferred Skills and Experience:
Text mining and unstructured data analysis techniques such as Named Entity Recognition and Text Classification
Language/Scripting skills: JavaScript, M
Tools: Sparx Enterprise Architect, Cameo
Extract, Transform, Load (ETL) experience
Predictive and Prescriptive analysis

Why LinQuest?
LinQuest Corporation has a stellar 40-year track ecord of providing end-to-end system-of-systems (SoS) architecture definition, engineering design, integration and test, and operations expertise to enable full lifecycle development and deployment of pre-eminent Space, Air, Land, Sea, Ground, and Cyberspace game-changing capabilities across US DOD and IC Customers’ portfolios. Unique combination of in-depth domain knowledge, lessons learned-honed best practices, and mission-specific applications of principles, tools, and techniques of Digital Engineering (DE), DE Ecosystem (DEE), and Model-Based Systems Engineering (MBSE) set LinQuest apart from the competition to consistently deliver stellar high-value results for our customers. LinQuest’s corporate vision and values place the employee at the center of utmost customer satisfaction, strategic business growth, and tactical execution excellence. Our employees’ creative and inspirational drive, sense of fulfillment of personal and professional growth, and tightknit camaraderie within and across lines of business are essential in gaining and maintaining exceptional LinQuest corporate-wide results of new business awards and renewed contracts.
Benefits:
LinQuest offers comprehensive and competitive benefit offerings to our team members to include medical, dental, vision, retirement, paid time off, tuition reimbursement, company paid life insurance, and more! For additional information please visit: https://www.linquest.com/careers/our-benefits
Education
Required
Bachelors or better
Licenses & Certifications
Required
Ability to Obtain
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)","$94,344 /yr (est.)",1001 to 5000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2004,$100 to $500 million (USD)
"BOEING
3.9",3.9,"Everett, WA",Lead Engineer - Air Data and Inertial Reference System (ADIRS),"At Boeing, we innovate and collaborate to make the world a better place. From the seabed to outer space, you can contribute to work that matters with a company where diversity, equity and inclusion are shared values. We’re committed to fostering an environment for every teammate that’s welcoming, respectful and inclusive, with great opportunity for professional growth. Find your future with us.
Lead a team of Avionics Design Engineers that specialize in the integration of Air Data and Inertial Reference System components on the 737, 747, 777 (legacy) and 767 model airplanes. This includes pitot, angle of attack (AOA) and total air temperature (TAT) probes as well as air data modules (ADM) and the Air Data and Inertial Reference Units (ADIRU). The Lead Engineer will define, release and manage change on production installations for 737, 747, 767 and 777 programs. Provides instructions and inputs for service bulletins to implement production changes on previously delivered systems. Provides system support and troubleshooting assistance to factory, field and airlines technicians for ADIRS equipment and functions. Interfaces with Electrical Wire Design, Equipment Installations, Electrical Subsystems, Flight Deck, EME, Vibration, ECS, IFE, Avionics and other Network Systems groups.
This position requires strong leadership skills, excellent communication skills, and extensive coordination experience both internal and external to Boeing (i.e. Customer Airlines, Suppliers, Tech Center, Certification, Service Engineering, etc.). The Lead is responsible for assisting team members with technical and process related issues while considering work statement, cost, and schedule impact. In addition, the Lead will be expected to be part of the mentorship and development of team members assigned to the group. The Lead will ensure common practices and requirements are followed within the group and are also applied to the Suppliers. Duties also include supplier interface, software development, and technical troubleshooting of airplane systems designs and production related issues. Occasional travel is required.

Boeing Commercial Airplanes in Everett, WA is seeking an Air Data and Inertial Reference System (ADIRS) Designer Engineer Senior = (level 4) to join the ADIRS team.
Position Responsibilities (Level 4)
The roles involve ensuring that product improvements, in-service issues, and regulatory mandates are comprehensively vetted, properly implemented and certified on schedule using a disciplined systems engineering approach that embodies quality from requirements validation through lab and airplane test verification.
Successful candidates will also be exposed to and contribute to the certification lifecycle of our Software Block Point development programs from cert plan inception, through test, to FAA/EASA regulatory approval that will provide an in-depth exposure to the current evolving regulatory landscape.
Work Authorization:
This position is expected to be 100% onsite or modified Hybrid.
This position must meet Export Control compliance requirements, therefore a “US Person” as defined by 22 C.F.R. § 120.15 is required. “US Person” includes US Citizen, lawful permanent resident, refugee, or asylee.

Basic Qualifications (Required Skills/Experience):
Must be over the age of 18.
Bachelor’s degree in engineering or computer science.
Experience or coursework related to cybersecurity concepts and techniques
Preferred Qualifications (Desired Skills/Experience):
Experience or coursework in Electrical Engineering, Aerospace Engineering, Mechanical Engineering, cybersecurity, security network architecture, embedded systems security, security testing and evaluation, network design, and PKI infrastructure.
Typical Education/ Experience:
Level 4
Education/experience typically acquired through advanced education (e.g. Associate) and typically 1 or more years' related work experience or an equivalent combination of education and experience (e.g. Bachelor, 3 years' related work experience, etc.).
Union:
This role is union represented.

Shift:

This position is for 1st shift
Relocation:
This position offers relocation based on candidate eligibility.
At Boeing, we strive to deliver a Total Rewards package that will attract, engage and retain the top talent. Elements of the Total Rewards package include competitive base pay and variable compensation opportunities.
The Boeing Company also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health insurance, flexible spending accounts, health savings accounts, retirement savings plans, life and disability insurance programs, and a number of programs that provide for both paid and unpaid time away from work.
The specific programs and options available to any given employee may vary depending on eligibility factors such as geographic location, date of hire, and the applicability of collective bargaining agreements.
Please note that the salary information shown below is a general guideline only. Salaries are based upon candidate experience and qualifications, as well as market and business considerations.
Salary Range:
Senior (Level 4) $128,350 - $173,650

Export Control Requirements: U.S. Government Export Control Status: This position must meet export control compliance requirements. To meet export control compliance requirements, a “U.S. Person” as defined by 22 C.F.R. §120.15 is required. “U.S. Person” includes U.S. Citizen, lawful permanent resident, refugee, or asylee.

Export Control Details: US based job, US Person required

Equal Opportunity Employer:
Boeing is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national origin, gender, sexual orientation, gender identity, age, physical or mental disability, genetic factors, military/veteran status or other characteristics protected by law.","$78,581 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1916,$10+ billion (USD)
Phoenix Cyber,#N/A,Remote,Data Protection Engineer [JOB ID 20230920],"Phoenix Cyber is looking for a Data Protection Engineer to join our client delivery team. This is a remote, work-from-home position with the possibility of minimal travel within the continental United States.
Requirements:
5+ years’ experience with defining an Endpoint data protection program (such as ForcePoint DLP) for a large enterprise.
5+ years’ experience with defining an email Data Protection program with a full lifecycle approach for a large enterprise.
Experience with Regex
Description:
Ability to assess DLP configuration, infrastructure and assess data loss prevention (DLP) options.
Assess different DLP endpoint protection tool options and help the customer choose the best option.
Develop DLP design, design DLP integrations and assess enterprise reporting capability.
Configure DLP reporting capabilities, develop Endpoint system test plans and configure Endpoint policies in monitoring mode.
Must have the ability to assess Microsoft Office 365 email configuration, infrastructure, email flow and assess data loss prevention (DLP) options.
Responsible for developing O365 email DLP design, design DLP integrations, have experience with reviewing email Standard Operating Procedures (SOP’s), and assess enterprise reporting capability.
Responsible for configuring DLP reporting capabilities, develop email system test plans and configure O365 Email DLP policies in monitoring mode.
Monitor O365 email alerts, review and categorize alerts, coordination with business process and owners to move to secure information exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT).
Monitor endpoint alerts, review and categorize alerts, coordination with business process and owners to move to secure data exchange, develop risk reduction plan, DLP policies testing and tune, and User acceptance testing (UAT).
Requirements:
Secret Clearance
Active: CySA, CEH, SSCP, or GICSP Certification
Phoenix Cyber is a national provider of cybersecurity engineering services, operations services, sustainment services and managed security services to organizations determined to strengthen their security posture and enhance the processes and technology used by their security operations team.
Phoenix Cyber is an equal opportunity employer and complies with Executive Order 11246, Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veteran's Readjustment Assistance Act (VEVRAA), all amendments to these regulations, and applicable executive orders, federal, and state regulations. Applicants are considered without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, and/or veteran status.
Phoenix Cyber participates in E-Verify to confirm the employment eligibility of all newly-hired employees. To learn more about E-Verify, including your rights and responsibilities, go to https://www.e-verify.gov/

bKiBjd1rdO",#N/A,Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Fives
3.8",3.8,"Cleveland, OH",Data Engineer,"As a Data Engineer at Fives North American Combustion, Inc., you will be crucial in raising data to enhance our engineering and manufacturing processes, improve product quality, and drive operational efficiency. You will collaborate with cross-functional teams to extract, analyze, and visualize data, providing valuable insights to guide our strategic decisions. The successful candidate will possess a combination of analytical skills, technical proficiency, and industry knowledge to thrive in this role.
Duties & Responsibilities: All duties and responsibilities are essential functions of the position. Other duties and responsibilities may be assigned.
Data Collection and Integration: Gather, clean, and integrate data from various sources, including production databases, sensor data, and external datasets.
Data Analysis: Conduct exploratory data analysis to identify patterns, trends, and anomalies.
Perform statistical analysis and hypothesis testing to drive meaningful insights.
Data Visualization: Create informative and visually appealing dashboards and reports using tools like Tableau, Power BI, or Python libraries.
Predictive Modeling: Develop predictive models to forecast manufacturing performance, quality, and operational outcomes.
Root Cause Analysis: Investigate production issues and quality concerns by analyzing data to identify root causes and recommend corrective actions.
Performance Monitoring: Establish and maintain key performance indicators (KPIs) to track manufacturing and engineering metrics. Generate regular reports to communicate performance trends to stakeholders.
Cross-functional Collaboration: Collaborate with engineering, manufacturing, and quality assurance teams to understand their data needs and provide analytical support
Continuous Improvement: Suggest process improvements and optimizations based on data analysis.
Data Security and Compliance: Ensure data security and compliance with relevant regulations, such as GDPR or industry-specific standards.
Build and maintain the infrastructure for collecting, storing, and processing data
Design, develop, and manage data pipelines, ELT processes, and data warehouses.
Work to optimize data processing and storage for both structured and unstructured data.

Profil

Proven experience as a Sr. Data Analyst and/or Data Engineer in an engineering or manufacturing environment.
Proficiency in data analysis tools and programming languages, such as Python, R, SQL, and Excel.
Strong data visualization skills with tools like Tableau or Power BI.
Excellent knowledge of statistical analysis and machine learning techniques.
Ability to communicate complex findings and insights effectively to technical and non-technical stakeholders.
Strong problem-solving skills and attention to detail.
Familiarity with manufacturing processes and quality control is a plus.
Requires experience with enterprise ERPs (SAP S4HANA, Oracle EBS), and CRMs (Salesforce, Hubspot).
*Please be aware that the compensation details provided by the website may be incorrect. To receive accurate and up-to-date information regarding the compensation package for this position, we kindly request you to reach out directly to Rachel, our HR representative, at Rachel.finnegan@fivesgroup.com.*

Take part in the Sustainability Industry! Every day in 25 countries, we (8,500 people) create the sustainable solutions the world needs by inventing the technologies of tomorrow across the entire spectrum of industry: from metallurgy to advanced logistics, from cement plants to the tech industry, from the IoT to aerospace. By Joining Fives, you'll become an entrepreneur who is involved in the design and management of the project from start to finish. Come and work with a group of passionate women and men, proud to be pioneers and above all proud to make the world move forward.","$82,686 /yr (est.)",5001 to 10000 Employees,Company - Private,Manufacturing,Machinery Manufacturing,1812,$1 to $5 billion (USD)
"Blackspoke
4.9",4.9,"Springfield, MO","Data Automation Engineer, Senior","Own your opportunity to serve as a critical component of our nation’s safety and security. Make an impact by using your expertise to protect our country from threats.
Be part of an exciting opportunity to contribute to one of the nation's most critical intelligence organizations. Your work directly impacts national security and global issues, you will have the chance to contribute to missions that are of paramount importance to the United States and its allies, know that that the environments and programs you support are making a difference on a global scale. Our customers operates at the forefront of technology, dealing with some of the most advanced defense, geospatial, and intelligence systems in the world.
As the Data Automation Engineer, you'll be exposed and contribute to the development and application of innovative technologies such as machine learning, artificial intelligence, and advanced data analytics. Our work depends on a Data Engineer joining our team to support our intelligence customer in Springfield, VA or St. Louis, MO.
What you will be working on:
Support the Geospatial Services and Solutions business area to provide high-quality, cost-effective solutions to the customer
Design and implement automation solutions to enhance data capture, data refinement, and processes. Coding examples include:
Interfacing with device APIs in order to collect operational metrics
Providing automated VoIP phone setup
Administering and automating data pipelines between different environments
Produce and deploy code via GitLab projects in collaboration with other team members
Utilize best practices for source control, testing, and deployment of software changes
Work in close collaboration with other automation engineers, infrastructure administrators, and data scientists
Diagnose, isolate, and expediently resolve complex problems pertaining to data structures
Develop methods of ensuring data incompatibilities among systems are systematically eliminated
Develop and recommend data management policies, standards, practices, and security measures to ensure effective and consistent data management operations
Participate in continuous improvement efforts to increase data availability, data quality, and speed of access
Maintain up-to-date documentation of designs/configurations, ensuring team members have continuity of recurring tasks
In office work requirement > 80%
Travel requirement 0%

What you will bring to us:
Bachelor's Degree in Computer Science or related technical discipline, or the equivalent combination of education, technical certifications or training, and work experience
8+ years of related systems engineering experience
Scripting, coding, or software development experience
Comfort with Linux/Windows command-line
Automation mindset
System administration and/or DevOps environment experience
Active TS/SCI clearance and eligibility to obtain a CI poly

Would be nice if you bring the following:
Python experience
Shell scripting experience such as Bash or PowerShell
Experience with Database technologies such as Postgres, SQL Server, Oracle, or MySQL
Experience writing and working with SQL commands
Version control experience with Git
Experience with Gitlab and Git workflows
Familiarity with Agile Scrum methodologies
Time management skills and the drive to work with limited supervision within a small team

Bonus Skills:
Web App development experience such as Flask, Django, React, etc.
UI/UX experience
Experience with Analytics tools such as Tableau
Infrastructure as Code experience
Experience in technical operations at DoD/IC agencies
Cloud experience such as AWS, Azure, GCP, etc.
Equal Opportunity Employer/Veterans/Disabled. Individuals with disabilities, including disabled veterans or veterans with service-connected disabilities, are encouraged to apply. If you need assistance applying outside of the online application, please contact recruiting@blackspoke.com for more information.","$109,600 /yr (est.)",51 to 200 Employees,Company - Private,Government & Public Administration,National Agencies,2011,$5 to $25 million (USD)
"City and County of San Francisco
3.8",3.8,"San Francisco, CA","Network and Data Center Engineer, Infrastructure - Department of Emergency Management (1042)","Company Description

Application Opening: September 18, 2023
Application Deadline: File Immediately. This announcement may close at any time after 5:00 pm on October 2, 2023
Compensation Range: $129,064 - $162,344 Annually
This is a Temporary Exempt appointment not to exceed two (2) years. This position is exempt from Civil Service Commission rules pursuant to the City and County of San Francisco, Charter Section 10.104, and incumbents are considered “at will” and serve at the discretion of the Appointing Officer. This is a full time, 40 hours per week appointment.
The San Francisco Department of Emergency Management (DEM) manages disaster preparation, mitigation, and response; 9-1-1 dispatch, and homeland security grant distribution for the City and County of San Francisco. DEM was created in 2006 by local legislation that reorganized the Emergency Communications Department and the Office of Emergency Services into a single agency. For more information on the Department of Emergency Management, please visit http://www.sfdem.org/.

Job Description

Under general direction of the IT Manager, the Network and Data Center Engineer will be responsible for the Department of Emergency Management (DEM) server systems (physical and virtual). This position will be responsible for installations, maintenance and maintenance contracts, backups, monitoring and patching on all servers, and any SLA (Service Level Agreements). The Network and Data Center Engineer is the primary technical resource for servers on the IT staff and will assist the support staff as needed with tickets escalated to this level, and also be the technical lead on server-related integrations/coordination with citywide services as well as collaborative projects with other departments.
Essential duties include but are not limited to:
Maintain and support DEM Admin network
Provide escort for other city partners and vendors to the Data Center and Telco Room
Install new network and server equipment into Data Center
Decommission old equipment
Maintain and support CAD network
Ensure the drawings are maintained and updated
Procure servers, software, and peripherals
Perform “rack-and-stack” deployments for Windows 20XX servers as needed
Monitor and reports on server health
Monitor and reports backup status
Maintain and document changes in Active Directory Group Policy and DNS records
Deploy and manage virtual servers in VMware environments
Assist in technical design of disaster recovery of servers and services
Maintain Windows update services and manages patch approvals
Configure and maintain Windows Server 20XX remote application and desktop services
Determine the proper installation parameters for software and hardware for smooth integration and efficiency in relation to the enterprise system and network
Performs other related duties as assigned.
Nature of Work: Candidate must be willing to work a 40-hour week as determined by the department. Occasional on-call and/or after-hours work is required.

Qualifications

Education:
An associate degree in computer science or a closely related field from an accredited college or university OR its equivalent in terms of total course credits/units [i.e., at least sixty (60) semester or ninety (90) quarter credits/units with a minimum of twenty (20) semester or thirty (30) quarter credits/units in computer science or a closely-related field]. AND
Experience:
One (1) year of experience analyzing, installing, configuring, enhancing, and/or maintaining the components of an enterprise network, that includes
a) Windows server administration experience consisting of installation of hardware and software, maintenance and configuration changes;
b) experience in server virtualization with VMWare, including design, installation and configuration of host server as well as the creation, development and management of virtual machines.
Substitution: Additional experience as described above may be substituted for the required degree on a year-for-year basis (up to a maximum of two (2) years). One (1) year is equivalent to thirty (30) semester units / forty-five (45) quarter units with a minimum of 10 semester / 15 quarter units in computer science or a closely related field.
Desirable Qualifications:
Microsoft certifications
VMware certifications.
Cisco certifications
Knowledge of and experience with administering NetApp Storage systems.
Demonstrated expertise in utilizing written and oral communication skills to document and share technical information.
Five (5) years of IT experience in a Windows network environment.
Experience with system auditing and various compliance configurations.
Advanced experience troubleshooting RDP and remote application services.
VERIFICATION: Verification of Education and Experience: Applicants may be required to submit verification of qualifying education and experience at any point during the recruitment and selection process. If education verification is required, information on how to verify education requirements, including verifying foreign education credits or degree equivalency, can be found at https://sfdhr.org/how-verify-education-requirements
Note: Falsifying one’s education, training, or work experience or attempted deception on the application may result in disqualification for this and future job opportunities with the City and County of San Francisco.
All work experience, education, training and other information substantiating how you meet the minimum qualifications must be included on your application by the filing deadline. Information submitted after the filing deadline will not be considered in determining whether you meet the minimum qualifications.

Additional Information

SELECTION PROCEDURE:
The selection process will include evaluation of applications in relation to minimum requirements. Applicants meeting the minimum qualifications are not guaranteed advancement to the interview. Depending on the number of applicants, the Department may establish and implement additional screening mechanisms to comparatively evaluate the qualifications of candidates. If this becomes necessary, only those applicants whose qualifications most closely meet the needs of the Department will be invited for an interview.
Notes: Applicants who meet the minimum qualifications are not guaranteed advancement through all of the steps in the selection procedure.
Additional Information Regarding Employment with the City and County of San Francisco:
Information About the Hiring Process
Conviction History
Employee Benefits Overview
Equal Employment Opportunity
Disaster Service Worker
ADA Accommodation
Veterans Preference
Right to Work
Copies of Application Documents
Diversity Statement
HOW TO APPLY
Applications for City and County of San Francisco jobs are only accepted through an online process. Visit careers.sf.gov and begin the application process.
Select the “Apply Now” button and follow instructions on the screen.
Applicants may be contacted by email about this recruitment and, therefore, it is their responsibility to ensure that their registered email address is accurate and kept up to date. Also, applicants must ensure that email from CCSF is not blocked on their computer by a spam filter. To prevent blocking, applicants should set up their email to accept CCSF mail from the following addresses (@sfgov.org, @sfdpw.org, @sfport.com, @flysfo.com, @sfwater.org, @sfdph.org, @asianart.org, @sfmta.com, @sfpl.org, @dcyf.org, @first5sf.org, @famsf.org, @ccsf.edu, @smartalerts.info, and @smartrecruiters.com).
Applicants will receive a confirmation email that their online application has been received in response to every announcement for which they file. Applicants should retain this confirmation email for their records. Failure to receive this email means that the online application was not submitted or received.
Analyst Information: If you have any questions regarding this recruitment or application process, please contact Angie Ignao at angie.ignao@sfgov.org.
The City and County of San Francisco encourages women, minorities and persons with disabilities to apply. Applicants will be considered regardless of their sex, race, age, religion, color, national origin, ancestry, physical disability, mental disability, medical condition (associated with cancer, a history of cancer, or genetic characteristics), HIV/AIDS status, genetic information, marital status, sexual orientation, gender, gender identity, gender expression, military and veteran status, or other protected category under the law.","$145,704 /yr (est.)",Unknown,Government,Government & Public Administration,State & Regional Agencies,#N/A,Unknown / Non-Applicable
"Deloitte
4.0",4.0,"Seattle, WA",Data Instrument Engineer,"Are you an experienced, passionate pioneer in technology who wants to work in a collaborative environment? As an experienced Data Instrument Engineer, you will have the ability to share new ideas and collaborate on projects as a consultant without the extensive demands of travel. If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery.

Work you'll do/Responsibilities

This is an opportunity to join a fast-paced team that plays a key role in the overall success of our client's organization through technology enablement. You'll play a critical part in driving the technology vision forward and ensuring that we execute across multiple initiatives.
Partner with product, analytics, and data engineering in interpreting business and analytics requirements and converting them into instrumentation requirements documents
Work with feature and data engineering to communicate instrumentation requirements and support development
Support data instrumentation for multiple projects concurrently
Communicate regularly with Engagement Managers (Directors), project team members, and representatives from various functional and / or technical teams, including escalating any matters that require additional attention and consideration from engagement management
Independently and collaboratively lead client engagement workstreams focused on improvement, optimization, and transformation of processes including implementing leading practice workflows, addressing deficits in quality, and driving operational outcomes

The Team

As a part of the US Strategy & Analytics Offering Portfolio, the AI & Data Operations offering provides managed AI, Intelligent Automation, and Data DevOps services across the advise-implement-operate spectrum.

Qualifications

Required
5+ years of experience in a Data Scientist or Data Analyst role with extensive experience with both client and server tagging/instrumentation concepts & frameworks
Expertise in crafting SQL friendly data structures and implementing complex SQL queries.
Exposure to data Quality Assurance, large volume data sets and Big Data technology stack such as Hadoop, Hive and Spark preferred
Familiarity with Python or, Splunk and data visualization tools such as Tableau for full-stack data analysis, insight synthesis and presentation
Experience into Data Privacy and Privacy preserved data collection and analysis
Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience
Limited immigration sponsorship may be available
Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve

Preferred
Candidates with a background in payments are highly preferred
Analytical/ Decision Making Responsibilities
Analytical ability to manage multiple projects and prioritize tasks into manageable work products
Can operate independently or with minimum supervision
Excellent Written and Communication Skills
Ability to deliver technical demonstrations

The wage range for this role takes into account the wide range of factors that are considered in making compensation decisions including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The disclosed range estimate has not been adjusted for the applicable geographic differential associated with the location at which the position may be filled. At Deloitte, it is not typical for an individual to be hired at or near the top of the range for their role and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $97,875 to $171,000
You may also be eligible to participate in a discretionary annual incentive program, subject to the rules governing the program, whereby an award, if any, depends on various factors, including, without limitation, individual and organizational performance","$109,997 /yr (est.)",10000+ Employees,Company - Private,Financial Services,Accounting & Tax,1850,$10+ billion (USD)
"Cloudera
3.9",3.9,Maryland,"Senior Staff Software Engineer, Generative AI for Data Flow Design","Business Area:
Engineering
Job Description:
At Cloudera, we empower people to transform complex data into clear and actionable insights. Powered by the relentless innovation of the open source community, Cloudera advances digital transformation for the world’s largest enterprises.
Cloudera is looking for a Software Engineer to join the Data Flow team and help drive development of Cloudera’s next-generation AI for flow design. You will be responsible for helping design, build, and deliver an AI platform that not only accelerates customer adoption of CDF from exploration to production but also enables enterprises to create & deploy data flows using foundation models with enterprise data at scale. This role requires an empathetic mindset and close collaboration with frontend / web UI engineers, data scientists, designers, and product management.
We look for ""The Startup Spark"", a desire to create new things, dive in wherever there's a need, eagerness to make an impact as an individual and the willingness to learn new things. You must be self-motivated, innovative, and proactive. The role offers significant opportunities for growth.
As a Senior Staff Software Engineer you will:
Help build the leading platform for machine learning & AI in the enterprise
Design, code, and implement elegant, scalable, enterprise-quality application services
Work to enhance developer velocity and team agility
Build strong relationships and collaborate with platform and UI engineers, quality engineers, UX designers, as well as, Product Management, Field Engineering, and other external partners
We’re excited about you if you have
Bachelor's degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field. A Master's/Ph.D. is a plus.
Proven experience as a machine learning engineer with a track record of developing and deploying machine learning models in real-world applications.
Proficiency in data preprocessing, feature engineering, and data visualization.
8+ years of experience building scalable microservices using Go, node.js, or Java
Experience with microservices development (Go, GRPC, SQL)
Experience with server-side JavaScript tooling such as Node. js, npm, webpack, babel, etc
Self-driven and motivated, with a strong sense of ownership and craftsmanship.
Strong written and verbal communication skills.
Experience with open source foundation models, prompt engineering, fine-tuning, and Retrieval-Augmented Generation (RAG)
Experience with cloud technologies (AWS, GCE, Azure)
You may also have:
Experience with data science and machine learning tools (R, Python, Tensorflow, Spark, mlflow etc.)
Experience with AI/ML orchestration software like Kubeflow, KServe, Knative, etc.
Experience building scalable, robust and secure Enterprise applications
Experience using Big Data technologies like Spark, Hive etc.
Experience using Apache NiFi or similar GUI based data flow/data integration tools
What you can expect from us:
Generous PTO Policy
Support work life balance with
Unplugged Days
Flexible WFH Policy
Mental & Physical Wellness programs
Phone/Internet Reimbursement program
Access to Continued Career Development
Comprehensive Benefits
Competitive Packages
Paid Volunteer Time
Employee Resource Groups
Cloudera is an Equal Opportunity / Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Management Level:
9 Individual Contributor",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2008,$500 million to $1 billion (USD)
"Cushman & Wakefield
3.7",3.7,"Plano, TX",Operating Engineer - Data Center-2,"Job Title
Operating Engineer - Data Center-2
Job Description Summary
Responsible to ensure the proper efficient operations and maintenance of the mechanical electrical and plumbing systems for the assigned facility. The performance of all necessary maintenance and operational tasks are developed to assure maximum life and reliability of all mechanical/ electrical/plumbing systems. May be only maintenance staff member on duty during certain shifts; may be required to work extended periods of time without relief when responding to priority/emergency situations (including overtime type assignments); requires shift work and/or on call duties.
Job Description
ESSENTIAL FUNCTIONS AND RESPONSIBILITIES
Assist with or conduct the daily operations and maintenance of the mechanical, electrical and plumbing systems and general maintenance requirements for the buildings
Supervise maintenance staff when applicable and assign, and monitor maintenance activities and projects
Perform preventive maintenance duties, including changing filters, lubricating motors, replacing lamps, ballasts and fixtures, Inspecting and adjusting belts, replacing motor bearings, aligning shafts, and other inspections and maintenance recommended by equipment manufacturers
• Recommend improvements to the preventive maintenance program on an ongoing basis•
Respond immediately to emergency situations (fire, evacuation, equipment failure, etc.) and customer concerns
Comply with all applicable codes, regulations, governmental agency, and company directives as related to building operations and practice safe work habits
Ensure management team is informed of current building operations by compiling and submitting monthly reports
Complete all required C&W Safety Training as scheduled annually.
Comply with C&W Uniform Dress Code while working and maintain a neat and clean appearance while on the property at times other than working hours
KEY COMPETENCIES
Communication Proficiency (oral and written)
Organization Skills
Technical Proficiency
Decision Making
Problem Solving/Analysis
IMPORTANT EDUCATION
High School Diploma or GED Equivalent
Graduate of apprentice program or trade school preferred
IMPORTANT EXPERIENCE
§ 5+ years of related trade experience in operating mechanical, electrical and plumbing systems in a commercial property setting. Data Center experience preferred.
ADDITIONAL ELIGIBILITY QUALIFICATIONS
Appropriate license/permit for trade as may be required, i.e. Journeyman or Master Electrician License, City Licenses, Operators License, Steam Engineers License, etc.
Basic Computing Skills in Outlook, Excel & Word
Experience in operation, maintenance and basic repair of HVAC, boilers, heaters, pumps, refrigerant systems, compressors, water systems, etc.
Knowledgeable in energy management systems, techniques and operations.
Thorough knowledge in all building systems operations, maintenance and repair
May be only maintenance staff member on duty during certain shifts; may be required to work extended periods of time without relief when responding to priority/emergency situations (including overtime type assignments); may require shift work and/or on call duties
WORK ENVIRONMENT
This job operates in a professional Data Center environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets and fax machines. Regularly required to travel outside between properties in varying weather conditions.
PHYSICAL DEMANDS
The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.
Must have ability to stoop, stand, climb, frequently lift a minimum of 50 lbs. of equipment (pumps, tools, ladders) and safely install rigging/lifting devices
Regularly required to crouch and reach to install/move equipment by bending forward at the waist or by bending legs and spine
Involves movement between departments, floors, and properties to facilitate work
Ability to speak clearly so others can understand you
Ability to read and understand information presented orally and in writing
Regularly required to utilize vision abilities, allowing reading of printed material, drawings, and schematics
AAP/EEO STATEMENT
C&W provides equal employment opportunity to all individuals regardless of their race, color, creed, religion, gender, age, sexual orientation, national origin, disability, veteran status, or any other characteristic protected by state, federal, or local law. Further, the company takes affirmative action to ensure that applicants are employed and employees during employment are treated without regard to any of these characteristics. Discrimination of any type will not be tolerated.
OTHER DUTIES
This job description is not designed to cover or contain a comprehensive list of activities, duties or responsibilities that are required of the employee. Other duties, responsibilities and activities may change or be assigned at any time with or without notice.

Cushman & Wakefield provides equal employment opportunity. Discrimination of any type will not be tolerated. Cushman & Wakefield is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other characteristic protected by state, federal, or local law.
In compliance with the Americans with Disabilities Act Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position at Cushman & Wakefield, please call the ADA line at 1-888-365-5406 or email HRServices@cushwake.com. Please refer to the job title and job location when you contact us.","$87,910 /yr (est.)",10000+ Employees,Company - Public,Real Estate,Real Estate,1917,$5 to $10 billion (USD)
"Citrine Informatics
4.7",4.7,United States,Data and Artificial Intelligence Research Engineer (DARE),"Design and build the core scientific libraries that enable our users to apply machine learning to solve the world’s most important materials science problems at an industrial scale.

About Citrine

At Citrine, we’re ushering in the next generation of sustainable, high-performing materials and chemicals.
We are the industry leader in AI for materials and chemicals. Our SaaS platform provides data management and Artificial Intelligence (AI) tools that help our customers rapidly develop higher-performing, more sustainable materials. Our users are scientists and engineers at market-leading manufacturing and materials companies, and we collaborate with professors and researchers from world-renowned institutions on cutting-edge research at the intersection of AI and the physical sciences.

This year, Citrine won the LyondellBasell Advancing Strategic Potential Forum Award for Innovation. We have also been recognized for our impact on sustainability by the Global CleanTech Group, and earned a spot on both the CB Insights AI 100 List and the Inc. 5000 list of fastest-growing private companies in the US. Citrine works with leading global organizations across chemical and materials development and manufacturing, such as: LyondellBasell, Panasonic, Michelin, Synthomer, Solvay, and more. As a team, we are ambitious with our goals, passionate about our vision, and eager to grow and learn from each other. Our team is growing fast and looking for the best to join us.

Our Platform gives product developers, researchers, and engineers access to cutting-edge, domain-specific AI, all without writing a line of code. This enables our customers to discover and deploy the next generation of sustainable, high-performing materials and chemicals up to 98% faster than traditional R&D approaches. While our headquarters are located in the San Francisco Bay Area, the Citrine team is distributed across the United States, Canada, Belgium, Germany, and Switzerland.

About the Role

Data & AI Research Engineering is a uniquely interdisciplinary team working at the intersection of materials science, applied mathematics, and software engineering. We are responsible for researching, developing, testing, implementing, and maintaining scientific methods that form the core materials-aware machine learning functionality that powers the Citrine Platform. We collaborate extensively across the company — other teams rely on us throughout the product lifecycle to translate ideas to math to code and back again.

Responsibilities include:
Writing and maintaining Scala ML code, with some additional Python
Collaborate closely with other engineers, frequently reviewing code and best practices
Mentor other developers
Design high-performance, scalable systems
Test & analyze the impact and performance of your software
Work in a multi-functional team on features from concept to delivery

Example projects:
Improve and maintain our core Scala libraries that enable our users to apply machine learning to solve the world’s most important materials science problems at an industrial scale
Collaborate with our External Research and Development (ERD) team to write and publish papers related to the work we’re doing
Improve the interpretability of machine learning models and develop tools to communicate that information to users
Develop ways to efficiently explore the complex parameter spaces that characterize real-world materials synthesis problems
Collaborate with our Product team to shape the future of our AI capabilities and support our customers’ unique use cases
Develop new methods to quantify uncertainty in machine learning predictions
Skills and Experience
6+ years of professional experience or MS/PhD in mathematics, information science, or computer science
Extensive knowledge of Scala in a production environment
Proven history of implementing AI solutions for customers, with quantifiable results
Experience solving scientific problems with computational techniques
Ability to communicate complex technical concepts and design choices to any audience
In-depth knowledge of how core ML algorithms work and their design (random forest, k-nearest neighbors, linear and logistic regression, backpropagation, etc.)
Python (Sklearn, Numpy, Pandas, Scipy, etc.)
Advanced developer-testing skills: unit, integration, property-based testing, etc.
Containers (Docker, ECS) for development, testing, and production
Nice-to-haves
Experience with and/or a degree in Materials Science
Prior projects where you took materials manufacturing data and built ML models to detect anomalies or quality defects
Extensive knowledge of statistics
Experience with LLMs such as the GPT models or BERT, etc
Bonus points if you’ve taken one of these models and created a customer-facing product with it!
Published papers that establish you as a domain expert in AI/ML, NLP, or scientific computing
Pinecone (vector database)
Relational databases (Advanced PostgreSQL is an asset)
Close integration with various AWS services (S3, RDS, SQS, etc)
Equal Opportunity

All qualified applicants will receive consideration for employment without regard to race, creed, color, or national origin.

Our Core Values

Citrine Informatics recognizes that its most valuable asset is its people. We have created our set of Core Values to encourage, support, and invest in our team as they work to innovate and support a more sustainable world. Our Core Values reflect our ongoing commitment to continuously invest in nurturing our talent and our people-first approach to conducting business.

We take pride in and recognize the successes and growth of ourselves and our colleagues. We support each other in our growth.
We prototype and collect data to make good decisions. We question that data and are constantly iterating to find the best solution.
We are all owners of Citrine and make decisions like owners. We work autonomously with personal and organizational accountability.
We commit to building a diverse and inclusive community within Citrine and actively promote equity and belonging.
We are tirelessly committed to creating value for our customers.
We exist to help our customers accelerate the development of sustainable products that are critical to the future of both our planet and our industry.

Compensation and Pay Transparency

At Citrine, we want your path to career growth to be transparent, straightforward, fair, and easily accessible - starting with your application and interview process. The annual salary range listed below reflects the level we are considering for this position (please note that there may be unique situations where you may fall outside of this range). Where you fall within the range will depend on how your experience and skills align to our internal leveling system as we learn more about you throughout the interview process.

$145,000 USD - $175,000 USD

Range(s) listed are for full-time employees based in the United States only.
**Colorado only: disclosure above meets the requirement by sb19-085(8-5-20).

Our Benefits (for exempt, full-time employees based within the United States)

401k with matching up to 4%
Medical, vision, dental insurance (we pay 100% of your premium and 75% of your dependents)
Life and Disability insurance
FSA and HSA plans
Equity options within the company
12 weeks of paid parental leave
Flexible PTO on top of our 15 paid company holidays (includes your birthday!)
Free financial counseling
$600 tech allowance
Monthly $75 phone reimbursement
$5,000 annual continuing educational allowance",#N/A,51 to 200 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2014,$1 to $5 million (USD)
"World Acceptance Corporation
3.1",3.1,"Greenville, SC",Data Engineer,"Essential Duties and Responsibilities:
Protect confidential company information.
Assist business, technology, and support partners/stakeholders to deliver secure data solutions.
Design, build, and maintain data delivery solutions in accordance with governing data architecture patterns.
Model and assemble data sets that meet functional and technical business requirements.
Implement infrastructure required to optimize ETL and ELT operations across a variety of data sources.
Process file-based data extracts using data retrieval and management tools to provide timely loading of critical business data.
Identify, design, and implement process improvements in data flows and data pipelines, focusing on automating data tasks.
Integrate external systems with internal systems to ensure proper data flow between systems.
Maintain an accurate and comprehensive inventory of data, data systems, and data storage.
Communicate with non-technical stakeholders to determine technical solutions to business problems.
Perform data load, data extraction.
Qualifications:
Must be legally authorized to work in the United States without the need for employer sponsorship (including but not limited to C2C arrangement), now or at any time in the future.
To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required:
Expertise with relational databases.
Advanced SQL proficiency.
Experience working with data warehousing systems for large enterprises with both internal and customer facing applications, preferably with near real time transactional data.
Expertise in creating and maintaining data structures in SQL.
Experience structured and non-structured data paradigms, relational databases, data lake and data warehouse technologies, data vault and dimensional data models.
Ability to define problems, collect data, establish facts, and draw valid conclusions.
Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Ability to conduct research into systems issues and products to determine integration requirements.
Ability to communicate ideas in both technical and user-friendly language.
Ability to work with IT operations to quickly come to resolution of open support requests.
Self-motivated and able to work within a project-based environment.
Possesses strong oral and written communication skills, clearly and accurately communicating complex and/or technical information to both technical and nontechnical audiences.
Python for building and redefining data pipelines is required.
Education and/or Experience:
Bachelor’s Degree in MIS, Computer Science, or related field, or equivalent professional experience.
Minimum 2 years of designing and implementing Data engineering solution.
Hands on experience with building productionized data ingestion and processing pipelines.
Design and delivery of data warehouse applications/solutions
Familiarity with business intelligence tools (such as PowerBI)
Experience with MS SQL Server, Integration Services (SSIS)
Strong TSQL scripting abilities and understanding of complex stored procedures, views, data. aggregation/manipulation through table joins/queries, database design, normalization, and de-normalization techniques.
Experience using Python.
Industry experience working with large data sets.
Experience with data modeling and building high-volume ETL/ELT pipelines tools (Matillion, Fivetran, Stich, etc) is a plus.
Experience with cloud services (Snowflake, Amazon AWS, Azure Synapse, Data Factory, Data Lake Infrastructure, Azure Databricks, etc) is a plus.
Familiarity with Azure Dev OPS or GitHub is a plus
Experience workflow orchestration (Airflow, etc) is a plus.
Experience with data transformation (DBT, etc) is a plus.
Physical Demands:
Must be able to constantly remain in a stationary position.
The person in this position needs to occasionally move about inside the office to access file cabinets, office machinery, etc.
Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine, and computer printer.
Occasionally may require light lifting to 25 pounds.
Work Environment:
Office environment.
Occasional travel may be required.
This job description reflects management’s assignment of essential functions; and nothing in this herein restricts management’s right to assign or reassign duties and responsibilities to this job at any time.
It is the policy of World Acceptance Corporation to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, World Acceptance Corporation will provide reasonable accommodations for qualified individuals with disabilities.","$88,156 /yr (est.)",1001 to 5000 Employees,Company - Public,Financial Services,Banking & Lending,1962,$500 million to $1 billion (USD)
"Global Atlantic Financial Group Opportunities
4.0",4.0,"Des Moines, IA",Azure Data Engineer,"All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com.
COMPANY OVERVIEW
Global Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.

Global Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us.
We use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling.
Position Overview:
The Finance Platform Developer role partners with the Actuary team, IT data team and primary vendor to provide data development, support, and administration for the Actuarial Modeling/Data Management Platform. This position will be accountable for managing the data lifecycle and development throughout the Actuarial Modeling process.
This position can sit in our Boston or Des Moines offices.
Key responsibilities will include the following:
New Requests/Builds
Collaborate with Actuary Model Development to support any data needs for models
Collaborate with Actuary Valuation to support model analytics and approval workflow
Define backlog items and requirements for IT Data team and other supporting IT areas
Participate in testing and verification of technical solutions
General Support
Become a subject matter expert in Actuarial Modeling Platform Data Management capabilities
Is primary administrator of Actuarial Modeling Platform and appropriately manages required administrative tasks if needed
Responsible for the regular maintenance, updates, fixes and upgrades. This could include testing after upgrade or facilitating UAT
Ensures platform is running at optimal performance and levels
Maintain application run books to ensure appropriate documentation exists
Provide training to new and existing users on current and future functionality
Production Process
Manage and facilitate all incidents from Priority 1 to Priority 4, which includes, but not limited to, providing support to users of applications, responding to user-based questions, tickets and assists with troubleshooting issues within platform.
Manage day-to-day operational and tactical aspects of multiple projects or requests
Provides on-call assistance as requested, for after-hours issues and support needs
Resolve incidents if able to, otherwise escalate as needed (provide tier-2 incident response)
SKILLS
General development skills with proven experience Azure SQL and other programming languages
Understanding of Life and Annuity insurance a plus
Demonstrates excellent interpersonal communication skills and documentation skills
Proven Data management skills with understanding of Data flows across different platforms
Experience building data pipelines
Able to manage work across a development team
Work cross-functionally within IT, with an emphasis working with a data team
Self-disciplined, able to work independently, but also able to take direction when necessary
Self-motivated to identity and resolve issues and in advancing personal knowledge
Hands on experience with GITLAB (nice to have)
QUALIFICATIONS
An undergraduate degree in an IT related field or similar combination or education and experience
Experience working on Life and Annuity products (nice to have)
2+ years' experience in Data Integration and Data Management
Experience working in cloud environments
Must have
Experience in the following technologies –Azure Data Factory and PowerBI
Experience in Data Integration and Data Management
Global Atlantic's base salary range is determined through an analysis of similar positions in the external labor market. The annual base salary range provided in this posting for this position is a nationwide market range and represents a broad range of salaries for this role across the country. Base pay is just one component of Global Atlantic's total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k), as well as a company match on your contributions), and sales incentives. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives. The base salary range for this role is $60,000 to $110,000.

#LI-AO1
#LI-Hybrid
TOTAL REWARDS STATEMENT
Global Atlantic's total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.
We are active in our communities-
New York: Red Hook Conservancy, Girls Who Invest and The Bowery Mission
Boston: Cradles to Crayons, Project Bread, Let's Get Ready, Rise Against Hunger, Salvation Army and many other local volunteer organizations in around the Boston area
Hartford: Habitat for Humanity, Foodshare, Humane Society, Hands on Hartford, Mercy Shelter and Dog Star Rescue
Indianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation
Batesville: American Cancer Society Relay for Life, Angels of Giving, Margaret Mary Health Foundation, Ripley County Community Foundation, Safe Passage, Batesville High School Sponsorships, local area youth sports and food pantries, as well as many others
Des Moines: United Way, Central Iowa Shelter & Services, Junior Achievement of Central Iowa and Make a Wish Foundation
Berwyn: Food drive and will be planning an event to help a local family over the holidays
Atlanta: Packaged Good Organization, which helps the most vulnerable community members with providing personalized care packages for people in need including the elderly, our armed forces, the homeless and hospitalized kids
Bermuda: Sponsor of a weekly feeding program operated by The Hamilton Seventh-Day Adventist Church
Social platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.
Global Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws. More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.
Employees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com.
Please click on the below links to learn more about Global Atlantic.
Global Atlantic Privacy Statement","$85,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Insurance,Insurance Carriers,2004,Unknown / Non-Applicable
"UBS
3.9",3.9,"Weehawken, NJ",Data Engineer - Reg Reporting Crew,"United States - New Jersey
Information Technology (IT)
Group Functions
Job Reference #
281704BR
City
Weehawken
Job Type
Full Time
Your role
Are you passionate about data? Do you like to be challenged, learn and grow professionally? Do you have a deep love for solving data problems and seeing the results of your work? Do you have a knack for understanding business problems and engineering data driven solutions that provide insights and help to deliver sustainable and impactful outcomes.

We’re looking for a Data Engineer, Regulatory Reporting Crew to:

transform data into valuable insights that inform business decisions, making use of our internal data platforms and applying appropriate analytical techniques
engineer reliable data pipelines for sourcing, processing, distributing, and storing data in different ways, using data platform infrastructure effectively
develop, train, and apply machine-learning models to make better predictions, automate manual processes, and solve challenging business problems
design and implement cloud-based solutions using microservices, Big Data, and elastic computing concepts
collaborate on innovative proofs-of-concept, pilots, minimum viable products, and business cases
be a part of our Agile engineering community
Your Career Comeback
We are open to applications from career returners. Find out more about our program on ubs.com/careercomeback.
Your team
We are a global organization that values diversity, collaboration, engineering & digital culture, and innovation. In our agile operating model, Crews are aligned to larger products and services fulfilling client needs and encompass multiple autonomous Pods. You’ll be working in the CDIO Group Finance team in our USA location in the Regulatory Reporting posting crew. The role of the Finance function in UBS is to help make the right decisions, execute on these decisions and tell the stories of these decisions. Our technology provides the backbone for accurate and timely financial controls and reporting across all legal entities in UBS Group. We work closely together with our product sponsors, crew product leads and colleagues to respond quickly to the needs of our Finance team, clients, regulators, and shareholders.

Diversity helps us grow, together. That’s why we are committed to fostering and advancing diversity, equity, and inclusion. It strengthens our business and brings value to our clients.
Your expertise
Bachelor’s, master’s degree or equivalent (technical school) in data science/engineering, computer science, math, or a related field
comprehensive understanding and ability to apply data engineering techniques
good understanding of Cloud and Big Data technologies (Spark/Databricks, Scala/Python, SparkSQL)
high proficiency in IaC, Yaml, PowerShell, and scripting.
ideally 8 to 10 years of technical and management skills.
proven delivery of Cloud-based solutions
experience in building data pipelines
knowledge of Terraform, Bash, Azure DevOps, and Git would be beneficial
curious to learn new technologies and practices, reuse strategic platforms and standards, evaluate options, and make decisions with long-term sustainability in mind.
passionate about what you do (and really excellent at it)
About us
UBS is the world’s largest and the only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal & Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors..

We have a presence in all major financial centers in more than 50 countries.
Join us
At UBS, we embrace flexible ways of working when the role permits. We offer different working arrangements like part-time, job-sharing and hybrid (office and home) working. Our purpose-led culture and global infrastructure help us connect, collaborate, and work together in agile ways to meet all our business needs.

From gaining new experiences in different roles to acquiring fresh knowledge and skills, we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we’re more than ourselves. Ready to be part of #teamUBS and make an impact?
Disclaimer / Policy Statements
UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce.","$115,798 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1862,$10+ billion (USD)
"Capital One
4.1",4.1,"McLean, VA","Principal Associate, Data Loss Prevention (DLP) Engineer (Symantec)","Center 3 (19075), United States of America, McLean, Virginia
Principal Associate, Data Loss Prevention (DLP) Engineer (Symantec)
Capital One is seeking a data protection subject matter expert to deliver game-changing cybersecurity solutions based on threat, data, and design thinking. At Capital One, we believe in the values of Excellence and Doing the Right Thing. We are a technology-oriented company delivering financial products to market through modern technology and constant innovation at a massive scale. Part of that innovation is leveraging technology to deliver the best cybersecurity solutions for the business.
As a candidate for this role, you will play a key role on a team of cyber technicians and engineers to create, implement, and maintain DLP Controls using SaaS and IaaS based solutions to reduce risk and enforce Capital One's Information Security Policy and Standards. You are naturally curious and stay on top of emerging trends and threats. You are not afraid to question any existing processes and solutions, yet you display a keen sense of business value proposition and focus on the right priorities. You are a clear thinker, thrive in working across teams, and are an expert in dealing with ambiguity. You believe that a core component of security’s role is to enable the business, not just to secure it, and the solutions you bring to life are aligned to the needs of our developer community and business partners. You thrive in working in a fast paced, technologically forward leaning environment and are not afraid to push the boundaries of security capabilities.

What you'll do…
Leverage data protection technology subject matter expertise to design, build, and implement tools to safeguard from cyber risks for data in use, in motion, and at rest.
Analysis of the problem space, documentation of the approach, and working with architecture to identify a target state architecture.
Execute a technical resolution program by closely partnering with cross functional teams across the organization.
Maintain close ties to various stakeholders, developers, and engineers across the company, ensuring the services we create meet their needs as products evolve.
Communicate extensively with Data Protection Product and engineering teams across the organization.
Collaborate with partners in different teams to resolve the dependencies with data loss prevention products.
Design, build, and maintain cloud-based infrastructure to meet the organization’s requirements and ensure high availability.
About You…
You are a subject matter expert in data loss prevention tools.
You have a strong understanding of the web proxy, email, and endpoint solution.
You are detail oriented and are able to articulate key details clearly both in conversation and in technical writing.
You are capable of driving complex technical initiatives to full delivery leveraging knowledge of Cyber security practices, software engineering principles, agile frameworks, and customer engagement.
You have the ability to foster collaborative, open, working relationships with technology groups and other stakeholders, including vendor relationships .
You have demonstrated clear communication skills and ability to interact effectively at multiple levels of an organization, and to influence leadership (Including translating technical information based on specific audiences).
You have experience working in and/or managing multiple high-visibility and high-impact enterprise cybersecurity projects with cross-functional teams while maintaining superior results including planning, development and management of technical requirements, design, testing and deployment of security solutions.
You have passion and expertise in one or more of the following areas: technical delivery, product security, software development practices, or platform engineering.
Hands-on knowledge and expertise in building and/or securing technology, including operating systems, databases, virtualization, cloud computing environments, and networks.
You are able to troubleshoot, investigate, configure and support the data loss prevention products.
Basic Qualifications:
High School Diploma, GED, or equivalent certification
At least 4 years of experience working in cybersecurity or information technology
At least 3 years of experience in the data protection field
At least 3 years of experience with Symantec Data Loss Prevention (DLP) infrastructure engineering

Preferred Qualifications:
Bachelor's Degree in Cybersecurity, Systems Engineering, or Computer Science
3+ years of experience in scripting and solving cyber technical challenges
3+ years of experience in the Agile delivery model
3+ years of experience in public cloud security and multi-cloud environments
2+ years experience in IT Delivery projects and technical writing
2+ years of hands-on JIRA experience
2 or more professional cybersecurity certifications: CISSP, GIAC, CISM, CCSP, CISA, or Security+
1 or more professional cloud certifications: AWS Cloud Practitioner, AWS Solution Architect - Associate, AWS Developer - Associate, AWS Security - Specialty, or AWS Solution Architect - Professional
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
New York City (Hybrid On-Site): $161,900 - $184,800 for Prin Assoc, Cyber Technical
San Francisco, California (Hybrid On-Site): $171,500 - $195,800 for Prin Assoc, Cyber Technical
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Palo Alto Networks
4.2",4.2,"Santa Clara, CA",Senior Devops/ Data Engineer - FedRAMP (Must be a US Citizen),"Company Description

To comply with U.S. federal government requirements, U.S. citizenship is required for this position
Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
FLEXWORK is an employee-centric reimagining of how we work. We built FLEXWORK based on employee feedback – it is about flexibility, trust, and choice whenever possible. It’s been a journey of disruption that has yielded the best of our values. We offer as much flexibility as possible, and choices that enable you to be most productive, including benefits that meet your needs and learning opportunities that you feel passionate about.
Our Approach to Work
At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!

Job Description

Your Career
In this role you will assume the responsibility of maintaining the data lake for our Federal Customers and be responsible for constructing data ingestion pipelines and implementing ETL processes to cater to our business requirements. Additionally, you will play a vital role in contributing to the development operations (DevOps) process by establishing and maintaining the necessary cloud infrastructure to support our global operations.
Collaboration with the Analytics team will be a key aspect of this role, as you will be working together to support the generation of various analytics outputs. These outputs will enable the business to efficiently utilize the data through interactive and insightful dashboards. Overall, this position requires a candidate who possesses strong technical skills, a keen eye for detail, and the ability to effectively collaborate with cross-functional teams to meet our organization's data and analytics objectives.
Your Impact
As a Senior Data Engineer, you will be an integral member of our Artificial Intelligence & Analytics team responsible for design and development of data pipeline
You will also have opportunity to work closely with our data science team and work on various business critical predictive use-cases
Build data profiling and ETL jobs using heterogeneous sources such Salesforce, SAP and others
Diligently teaming with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability
Accountable for Big Data and batch/real time analytical solutions leveraging Cloud (GCP) technologies
Be constantly challenged by tough data engineering and design tasks

Qualifications

Your Experience
5+ Data Engineering experience in multi cloud environments (AWS, GCP, Azure. etc..)
Strong knowledge of Python, SQL and pyspark is must
Experience in working with REST API services
Strong experience on BigQuery, Dataflow, DataProc, Data Fusion - GCP related technology
Experience in Linux/Unix and good understanding of Linux internals
Knowledge of containers and orchestration ( Docker, Kubernetes) is a plus
Ability to work in a fast-paced environment and manage multiple simultaneous priorities
Effective problem solving and analytical skills
Monitoring tools - Splunk, Prometheus, Grafanna etc. is a plus
Minimum of 5 years of related experience with a Bachelor’s degree or equivalent military experience required

Additional Information

The Team
Working at a high-tech cybersecurity company within Information Technology is a once-in-a-lifetime opportunity. You’ll join the brightest minds in technology, creating, building, and supporting tools and enabling our global teams on the front line of defense against cyberattacks.
We’re connected by one mission but driven by the impact of that mission and what it means to protect our way of life in the digital age. Join a dynamic and fast-paced team of people who feel excited by the prospect of a challenge and feel a thrill at resolving technical gaps that inhibit productivity.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.
We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.
Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $112,200/yr to $181,500/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.
Please note that we will not sponsor applicants for work visas for this position.","$146,850 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
"ICF
3.8",3.8,"Arlington, VA",Data Mining and Analytics Engineer (Senior),"Description
ICF International seeks an experienced Senior Data Mining and Analytics Engineer to support the research and development of new cyber analytic capabilities that will help the US protect and defend its networks and critical information systems. The successful cleared candidate will act as a Senior Data Mining and Analytics Engineer to support a large federal cyber security analytic program. Your work will contribute to the knowledge of how cyber-attacks work, how vulnerabilities are exploited, and the way hostile cyber actors operate. Utilize your skills to help experiment and prototype future cyber capabilities for implementation at large scale.

As the Senior Data Mining and Analytics Engineer, your exceptional skillset will create useful and actionable insight for the customer through the development of analytic solutions (hardware, analytics, tools, techniques, practices, deployment, standards, performance specifications, etc.) for analytic use cases developed during the performance of this project. You will work closely with the Analytics Research team to identify platform enhancements that support the forward-looking analytics under consideration.

The ideal candidate has extensive knowledge of a wide variety of systems and networks including high-volume/high-availability systems. You are focused on results, a self-starter, and have demonstrated success in using analytics to drive the understanding, growth, and success of the analysis. This is an opportunity to contribute to an important project from its beginning, work with the latest and emerging technologies, and all while building a great career at ICF!

This role is primarily telework-based with occasional meetings at client locations (Arlington, VA or Pensacola, FL) or ICF facilities within the National Capital Region.

What You Will Be Doing:
Perform knowledge elicitation from customer subject matter experts and convert that to build analytic solutions
Design, engineer, and optimize sustainment of large-scale distributed computation platforms and supporting environments (ecosystems) for various stakeholders, business owners, and industry partners
Manage teams of system administrators, prioritize work, identify high-risk critical problems, and dedicate appropriate resources
Oversee the transition of services from third-party vendors to the analytic environment and be responsible for ad hoc and formal end-user training
Identify applicable data to perform analytics and create solutions to acquire, transform, and load or correlate data components to and from the analytic environment
Develop custom data modeling procedures to assist with data mining, modeling, and production
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop processes and tools to monitor and analyze model performance and data accuracy
Interpret and communicate results to non-technical customers

What You Must Have:
Active high-level security clearance required as part of client contract requirements
US Citizenship required as part of client contract requirements
Bachelor’s degree with 12+ or Master’s degree with 10+ years of experience in Computer Science, Mathematics, Engineering, or related field
Practical working experience and advanced knowledge of cyber threats, tools, techniques, and processes.
Strong experience in data modeling and working with datasets of all sizes using a variety of data mining and data analysis methods/tools

Preferred Skills/Experience:
Interpersonal skills and the ability to communicate effectively with various clients in order to explain and elaborate on technical details
Experience in developing analytic tools, processes, and governance for storing, modeling, capturing, and delivering data to the client’s enterprise
Experience with computational notebook software such as Zeppelin or Jupyter
Experience with the application of visual analytics to computational analytic results
Fluency in one or more programming languages (e.g., Python, JavaScript, R, etc.)
Experience with database querying like SQL
Readiness to collaborate with engineering teams, product teams, and customers to develop prototypes and software products
Scaled Agile Framework (SAFe) experience
Amazon Web Services (AWS) Certified Cloud Practitioner or higher desired
CompTIA Security+ or higher cybersecurity certification preferred
Working at ICF
ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO & AA policy.
Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email icfcareercenter@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: Know Your Rights and Pay Transparency Statement.

Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
$85,153.00 - $144,760.00
Virginia Client Office (VA88)","$114,957 /yr (est.)",5001 to 10000 Employees,Company - Public,Management & Consulting,Business Consulting,1969,$1 to $5 billion (USD)
"Attentive Mobile
3.4",3.4,United States,"Data Engineer, Business Intelligence","UNITED STATES /
ENGINEERING /
FULL-TIME
/ REMOTE
About Attentive:
Attentive® is the leader in conversational commerce, reinventing business to consumer communication. Our SMS-first software platform helps everyone from entrepreneurs to enterprises strengthen relationships with their consumers in a new way. Through two-way, real-time, personalized communications, we drive billions in e-commerce revenue and over 8,000 leading brands like CB2, Urban Outfitters, Crocs, Jack in the Box, and Coach rely on Attentive to deliver powerful commerce experiences.

Attentive’s growth has been recognized by Deloitte’s Fast 500, Linkedin’s Top Startups and Forbes Cloud 100 all thanks to the hard work from our global employees!

Who we are
We are seeking a self-driven Data Engineer II to join our Business Intelligence Engineering team. On the BI Engineering team, you’ll help build and shape the backbone for analytics needs across the organization. You’ll work with Data Engineers and Data Analysts, as well as other internal teams to define and shape self-service analytics and a data-driven organization. You’ll also support the relationship between the BI/Analytics teams and Engineering as we build out a world-class data warehouse for our business and clients.
If you are a self-starter, excited about building a data-driven culture, and motivated by making an impact, then you may be a good fit for this role.
Why Attentive needs you:
You will work with teams across the company to define BI and analytics requirements
You will work alongside data engineers to develop data models to feed dashboards for teams across the org, as well as, client-facing analytics
You will work with data engineers and analysts to model data and build scalable data pipelines for BI
About you:
2+ years of data/software engineering experience
You are a self starter with a high desire to learn
You have experience with SQL, Python, ETL/ELT development
You are a team player with collaboration and communication skills
Nice to have:
You have proficiency or experience with Airflow
You have proficiency or experience with AWS
You have proficiency or experience with DBT
You have proficiency or experience with Snowflake or Trino.
You have familiarity with a BI visualization tool like Looker or Tableau
Our Environment:
We have access to Python, R, Snowflake, SQL, DBT for analysis
Our data visualization tool is Looker
Our product backend is Java and Python microservices coupled with Spark, Kinesis, AirFlow, Snowflake, and Postgres, all hosted on AWS
Our team supports stakeholders from client strategy, product management, sales, marketing, finance, engineering, designers and the leadership team
We believe our company will win in the long run through product innovation and data-driven decision-making
Attentive Company Values
Default to Action - Move swiftly and with purpose
Be One Unstoppable Team - Rally as each other’s champions
Champion the Customer - Our success is defined by our customers' success
Act Like an Owner - Take responsibility for Attentive’s success

Learn more about AWAKE, Attentive’s collective of employee resource groups.

If you do not meet all the requirements listed here, we still encourage you to apply! No job description is perfect, and we may also have another opportunity that closely matches your skills and experience.

At Attentive, we know that our Company's strength lies in the diversity of our employees. Attentive is an Equal Opportunity Employer and we welcome applicants from all backgrounds. Our policy is to provide equal employment opportunities for all employees, applicants and covered individuals regardless of protected characteristics. We prioritize and maintain a fair, inclusive and equitable workplace free from discrimination, harassment, and retaliation.",#N/A,1001 to 5000 Employees,Company - Private,Media & Communication,Advertising & Public Relations,2016,Unknown / Non-Applicable
"First Solar
4.0",4.0,"Perrysburg, OH",Associate Engineer (Data),"First Solar reserves the right to offer you a role most applicable to your experience and skillset.
Basic Job Functions:
This role lies in Development Engineering’s Analytics Team. It provides analytical and engineering support for large scale experiment operations to evaluate innovative ideas and boost solar cell performance in state-of-the-art R&D fabrication lines. You will identify and implement operations systems improvements that contribute to the achievement of error free experiment execution then thoughtful analysis. You will be a role model for the Development Engineering organization, demonstrating First Solar’s rigorous analytical techniques. Data driven, concise, and clear visual story telling will be your passion.
Education/Experience:
Bachelor's Degree in mathematics, computer science or engineering with minimum 2 years of technical experience or 2 years of experience as a Development Engineering Technician II at First Solar.
Master's Degree in in mathematics, computer science or engineering.
Required Skills/Competencies:
Dexterity to communicate up, down and across multi-disciplinary teams with diverse technical backgrounds.
Demonstrated ability to independently research, learn and apply knowledge to achieve success in engineering, analysis, and coding.
SQL, Python, SAS’s JMP (preferred)
Experience in structured problem solving, including data-driven (empirical) approaches.
Understanding of Inferential Statistics, T-test, DOE, fitting models and visual display of these concepts to tell a story.
Electrical knowledge, understanding current, voltage, resistance as well as PV cell operation.
Experience with Microsoft environment: Windows OS, Office 365, Teams, etc.
Essential Responsibilities:
Ensure your coworkers’ safety by adherence to all health and environmental procedures.
Develop new and improve existing software to…
standardize access to new data
create new analysis methods
optimize experiment operations and analysis workflows
validate and qualify experiment results
integrate into a broader analytical system
Perform analytical outreach by specializing in First Solar’s standardized analytical methods and demonstrating the workflows to Experimenters.
Jump into ad-hoc experiment analysis, quickly understand intent, and show results with key factors of influence.
Own analysis coordination and delivery, assuring material quality and experimental results are reviewed and summarized on time for group review.
Work with data consumers to understand their needs, point them to the right tool or make a new tool for them.
Collaborate with data and analytical system designers to assure the published tools are customer optimized.
Job description subject to change at any time.
Reporting Relationships:
Reports to Development Engineer or Development Manager
Estimated Salary Range:
$60,000 - $80,000 annually
US Physical Requirements:
Will sit, stand, or walk short distances for up to the entire duration of a shift
Will climb stairs on an occasional basis
Will lift, push, or pull up to 27 pounds on an occasional basis
Required to use hands to grasp, lift, handle, carry or feel objects on a frequent basis
20/40 vision in each eye, with or without correction, is required
Must be able to comply with all safety standards and procedures
May reach above shoulder heights and below the waist on a frequent basis
May stoop, kneel, or bend, on an occasional basis
Ability to wear personal protective equipment is required (including but not limited to; steel toed shoes, gloves, safety glasses, hearing protection, protective jacket or apron and arm guards)
All associates working on the production floor may be required to wear a respirator at any given time and thus, the ability to wear a respirator is a condition of employment and continued employment (requires little or no facial hair)
Potential candidates will meet the education and experience requirements provided on the above job description and excel in completing the listed responsibilities for this role. All candidates receiving an offer of employment must successfully complete a background check and any other tests that may be required.
Equal Opportunity Employer Statement: First Solar is an Equal Opportunity Employer that values and respects the importance of a diverse and inclusive workforce. It is the policy of the company to recruit, hire, train, and promote persons in all job titles without regard to race, color, religion, sex, age, national origin, veteran status, disability, sexual orientation, or gender identity. We recognize that diversity and inclusion is a driving force in the success of our company.","$70,000 /yr (est.)",5001 to 10000 Employees,Company - Public,Manufacturing,Electronics Manufacturing,1999,$1 to $5 billion (USD)
"Sbg Technology Solutions Inc
4.1",4.1,"Washington, DC","Senior Health Data Migration Engineer - 359.b, SBG","SBG Technology Solutions, Inc. (SBG), a DSS, Inc. company, offers IT Governance, Systems Engineering, Enterprise Modernization, Artificial Intelligence, and Cyber Security innovation to federal and commercial clients nationwide. We are looking for a Senior Health Data Migration Engineer to join our team. We are seeking highly motivated individuals looking to join our rapidly growing company. The ideal candidate for these positions are experienced individuals who are hard-working, with the ability to excel in a fast-paced government contractor environment, and who have positive energetic attitudes. The position location is 100% remote.

OVERVIEW
Support the Department of Veterans Affairs (VA) Electronic Health Record Modernization Integration Office (EHRM-IO) as a Senior Health Data Migration Engineer.
An Expert Integration Engineer must create strategies and plans for integration of multiple IT systems/subsystems into an operational unit, ensuring full functional and performance capabilities are retained. Coordinate with development and user teams to assess risks, goals and needs and ensure that all are adequately addressed. The expert integration engineer must be experienced in introducing new hardware or software into a new or existing environment while minimizing disruption and mitigating risks. The expert integration engineer must be cost conscience as well addressing goals.

Responsibilities:
Assess the current EHRM data migration requirements; maintain and update the strategy to meet the requirements.R
Review error and trace logs.
Track messages by domain and reconcile table counts with Cerner.
Review secure data message transmission logs.
Track the number of records sent per message by domain.
Monitor Queue Depth by service/process/operation.
Track retry attempts and suspended messages.
Validate and update data integration reports in support of VX130 data domains.
Review, update, and maintain Cerner to CDW, VistA, Millennium or Cloud Database data mappings for potential data migrations.
Evaluate and integrate data from multiple sources, which requires data mapping from one data source to another minimizing any data loss.
Document VistA Extraction and monitoring process and update existing documentation quarterly. Interpret Cerner’s Data model to be used for the construction of API’s, queries, and reports that will be consumed by internal or external applications.
Review Domain adds to Ensemble Production. Validate edits made to Domain record type, schema version, status, and payload size via the GUI Interface and Rule Builder.
Validate Ensemble data flows built using VX130 ClassBuilder.
Validate the load of Cache/IRIS Objects, SQL Tables or other storage structures (Historical Pulls) in all regions/districts for classes in all environments with VistA or Data Syndication data.
15+ years of professional work experience, to include experience with InterSystems IRIS in a healthcare environment
Be able to create strategies and plans for integration of multiple IT systems/subsystems into an operational unit, ensuring full functional and performance capabilities are retained.
Able to coordinate with development and user teams to assess risks, goals and needs and ensure that all are adequately addressed.
Experienced in introducing new hardware or software into a new or existing environment while minimizing disruption and mitigating risks.
Able to be cost conscience as well addressing goals.
Bachelor's degree in Computer Science, Engineering, Math, or equivalent, or an additional 8 years of relevant experience may be substituted for degree requirements
Preferred qualifications:
Experience in the VA.
Experience implementing Electronic Health Records (E H R).
Experience with VA and DoD legacy health data, and private sector health data.
Experience with Extraction, Transformation, and Loading of data between systems.
Knowledge and experience handling VistA data","$108,801 /yr (est.)",501 to 1000 Employees,Company - Private,Information Technology,Information Technology Support Services,1991,Unknown / Non-Applicable
"Applied Systems, Inc.
3.9",3.9,United States,Data Migration Engineer,"Job Description:
Applied Systems, Inc., a worldwide leader in insurance technology, is currently searching for a Data Migration Engineer to join our Data Services team and to migrate customer data from competitor/legacy systems into one of the Applied Systems products (SaaS). The Data Migration Engineer will work closely with new and existing customers to deliver high quality data projects while ensuring business continuity and satisfaction. They will perform data extractions, acquisition merges, and data cleanup/quality services to support unique customer needs.
As a strategic partner within the Data Services team, the Data Migration Engineer works under minimal supervision on assigned project work. This role will interact with other colleagues that support migration projects in Activation Services, Adoption Services, Development, Operations, Solution Services, and Support. The role requires attention to detail and the ability to follow multiple data sets through complex migration process.

What You’ll Do
Lead and participate in data conversion and data migration from legacy systems to target SaaS product, producing sample and final deliveries using SQL tools
Develop standardized and efficient data scripts for integrating data into the new systems and perform data audits to evaluate data accuracy and integrity
Act as a point of contact for internal team members and external clients during the migration process; leveraging SharePoint, Jira, and other collaboration tools.
Collaborate with stakeholders to ensure new systems satisfy the user requirements and expectations while remaining adaptable to contingency project plans when rescheduling is required
Works closely with Development for testing, follow up, and implementation of defects, enhancements, and new solutions while maintaining Data Services documentation
Ongoing research and analysis of customer data and the structure of competitor systems, with an emphasis on moving that data into Applied Systems’ products
Participates in special projects or aids in the implementation of future technology as required by Data Services Management

What You’ll Need to Succeed

We’re looking for someone who:
Can work remotely or from an Applied Systems office
Your experience should include some or all the following:
Competencies in Microsoft Office (Word, Excel, Access, etc.) and Microsoft Windows OS
Intermediate knowledge in database structure and SQL skills and capabilities
Familiar with ETL concepts
Ability to multi-task and manage several competing project timelines while remaining detail-oriented, a high level of initiative and good communication skills
Bachelor’s degree or equivalent work experience in the areas of Information Systems, Computer Science, Data Science, Software Engineering, or related disciplines. Equivalent work experience will be considered (minimum 2-year SaaS data migration / ETL experience)
We proudly support and encourage people with military experience, as well as military spouses, to apply
Additionally, you may have:
Experience with Google Cloud Platform/Storage and BigQuery
Experience with JIRA and SharePoint
Bilingual in French
What You’ll Gain
Benefits from Day One
Health insurance plans, dental, and vision
Wellness incentives
401(k) and/or RRSP retirement savings plans with employer match
Work-Life Balance
Competitive paid vacation time and a free day for your birthday
Personal/sick time
Paid holidays
Flex Time
Paid parental leave (U.S. candidates)
Volunteer time off
Empowering Career Growth and Success – We invest in talent, care about our people and are empowered by the results of our work. We grow our teams from within and give our employees opportunities to advance.

What We Value
We strive for excellence at every turn to be the best at what we do. We invest in talent, care about our people and are empowered by the results of our work. We fulfil the promise of insurance – safeguarding and protecting what matters most in people’s lives. And there is no more important job than that.
Our focus on the workforce, workplace and marketplace gives us a qualified individual in an environment in which they can be productive while we maintain our position in the industry. To help drive that change toward a vibrant, modern workplace, we have employee-driven networks with commonalities in ethnicity, gender, sexual orientation and military status.
Who We Are
For more than 35 years, Applied Systems has created innovative technology for the global insurance industry. Today, we are a rapidly growing software leader that is revolutionizing the way agencies and brokerages succeed.
We are smart and curious people in a tech-first environment that champions bold and powerful thinking. We are transforming a complex industry through digitization, automation, and innovative new partnerships. Together we are driving the industry fearlessly forward.
It’s an exciting time at Applied. You can do big things here, in an environment that supports creative thinking and bold ideas. Visit http://www.AppliedSystems.com for more information on how you can challenge what’s possible.
EEO Statement
Applied Systems is proud to be an Equal Employment Opportunity and Affirmative Action Employer. Diversity and Inclusion is a business imperative and is a part of building our brand and reputation. At Applied, we don’t discriminate, and we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sexual orientation, gender identity, disability, age, veteran status, and other protected status as required by applicable law.
#LI-Remote",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Computer Hardware Development,1983,$100 to $500 million (USD)
Starr And Associates LLC,#N/A,"Atlanta, GA",Data Engineer,"Sponsorship not available.
HELP FURTHER INDUSTRY PERFORMANCE AND INNOVATION.
WORK WITH GENUINE AND THOUGHTFUL COLLEAGUES.
HAVE FULL OWNERSHIP OF YOUR PERSONAL BRAND WHILE CONTRIBUTING TO OURS.
Starr & Associates (S&A) strives to better commerce and society by enhancing consumer delight, enterprise value, and employee satisfaction among its clientele. We love supporting and hiring individuals that can think BIG while simultaneously knowing that significant change often begins with seemingly insignificant gestures. We strive to teach large entities to behave more like smaller, more nimble versions of themselves allowing them to reduce waste, improve performance and deliver on their brand promise. Come and be a catalyst in our growth!
Why Starr & Associates? You are important and your work matters! As we continue to strive to become a brand synonymous with “excellence in service”, “transformation”, “dependability” and “effectiveness” it is imperative that the parts of the whole are motivated and contribute at an optimal level. We want you to be great so that you can help us be a greater collective!
At Starr & Associates, you’re an important part of the team. We started as a “one man band”. We understand that successful growth is dependent on culture, commitment and talent. This is a place that you can stretch as wide as you would like to stretch. As a firm, we realize the impact that a talented individual can have on not only our firm but also on our clients and their customers.
We are seeking an experienced and talented Data Engineer with data architect skills to join our team. With a minimum of 7+ years of proven experience as a data engineer or business intelligence consultant, you will be responsible for providing data management solutions to our large enterprise customers across multiple BI platforms in a consulting role.
As a Data Engineer, you will work closely with our clients, interacting directly with them to understand their requirements, consult on best practices, and design and construct innovative solutions to address their data analytic challenges. Your problem-solving and data management skills will be critical in creating, modifying, and maintaining data analysis solutions based on customer initiatives. This role requires excellent teamwork and working independently, often interfacing directly with the customer.
The ideal candidate will be highly responsive to customer needs, anticipating and proactively addressing technical and political challenges throughout the project lifecycle. Exceptional organizational skills, attention to detail, and a consultative approach to solving complex Data Management issues are essential. Proficiency in ETL tool data integration, data modeling, advanced SQL skills, and Excel efficiency for data querying and manipulation is necessary. Additionally, candidates should have a proven ability to extract valuable insights and drive improvement actions from large, complex, and messy datasets.
While the position primarily operates within a remote virtual environment, occasional travel may be required for on-site engagements. Suppose you thrive on delivering high-quality data solutions, working closely with clients, and are passionate about making a meaningful impact in data analytics. In that case, we invite you to join our dynamic team.
Duties & Responsibilities
Effectively communicate with internal and external customers to capture current data management requirements and objectives from different stakeholders that define their needs.
Define and document business intelligence policies and procedures, standards, and metrics to support a customer analytic business rules.
Perform activities to address data extraction, data validation, data cleansing, data harmonization, business logic, exception handling and required data indication.
Design and build a data inventory including field definitions, list of values (LOVs), and mappings as requested by customer and defined by requirements.
Understand key data relationships and customer’s data domains.
Collaborate with business process owners, data producers and data consumers to get an understanding of current processes and systems that has a direct impact on the quality of the enterprise data.
Work as a Data Architects to define and maintain a customer data model and Analytics solutions.
Work with stakeholders and the technical team to establish and manage match/merge that identify duplicate data across data sources and align required action such survivorship and trust rules in accordance with the organization's data governance procedures.
Assist customers with validating data integration from operational systems to future solutions.
Establish data quality processes and compliance with data standards for data domains.
Troubleshoot issues with data quality as identified by customers.
Research new statistical and mathematical techniques that are suitable and helpful for solving business related problems.
Education
Bachelor's Degree Required (STEM curriculum preferred)
Required Skills
Data Management: Proficiency in managing large-scale datasets, including data ingestion, storage, and retrieval. Strong understanding of data modeling, normalization, and data integration techniques.
Programming Languages: Expertise in a programming language such as to R, Python, Java, or Scala for data manipulation, transformation, and analysis. Familiarity with a scripting language like C#, VBScript, Ruby, Bash or PowerShell is a plus.
Database Technologies: In-depth knowledge of relational databases (e.g., Oracle, SQL Server, MySQL) and non-relational databases (e.g., MongoDB, Cassandra). Experience in designing and optimizing database schemas and SQL query optimization.
Big Data Technologies: Familiarity with distributed computing frameworks like Apache Hadoop, Apache Spark, or Apache Flink. Understanding of concepts like MapReduce and data processing in parallel.
Data Warehousing: Exposure to data warehousing technologies such as Amazon Redshift, Google BigQuery, or Azure Synapse Analytics. Proficiency in designing and implementing ETL (Extract, Transform, Load) processes is a plus.
ETL, Pipeline, and Workflow Tools: Familiarity with tools such as SSIS, Informatica, Talend, Knime, and Alteryx for building and managing ETL processes, data pipelines, and workflows, as well as understanding of Apache Airflow, Apache NiFi, or Luigi for workflow orchestration, scheduling, and managing complex data pipelines.
Data Visualization: Proficiency in data visualization tools such as Tableau, Power BI, or QlikView. Ability to create intuitive and visually appealing dashboards for data exploration and reporting.
Cloud Platforms and Data Services: Experience with a cloud platform and their respective data services, including:
Amazon Web Services (AWS): AWS EC2, S3, Redshift, Glue, Athena, EMR, etc.
Microsoft Azure: Azure VMs, Blob Storage, SQL Database, Data Factory, Databricks, etc.
Google Cloud Platform (GCP): Compute Engine, Cloud Storage, BigQuery, Dataflow, Dataproc, etc.
Data Science and Statistical Modeling: Understanding of data science principles and statistical modeling techniques. Familiarity with machine learning algorithms, predictive analytics, and statistical analysis tools such as Python libraries (e.g., scikit-learn, TensorFlow, PyTorch) and R.
Data Security and Compliance: Familiarity with cloud-based data security and compliance practices. Knowledge of encryption, access control, and data protection mechanisms provided by cloud platforms.
Data Visualization Tools: Familiar with Data Visualization Tools (Tableau, PowerBI, Qlik, etc)
Data Governance and Monitoring: Understanding of cloud-based data governance frameworks and tools for ensuring data integrity, privacy, and compliance. Proficiency in monitoring and troubleshooting data engineering pipelines in a cloud environment.
Problem Solving and Analytical Skills: Strong problem-solving abilities and analytical thinking to tackle complex data engineering challenges. Attention to detail and ability to troubleshoot and debug data-related issues.
Collaboration and Communication: Effective collaboration skills to work in cross-functional teams and interact with stakeholders. Excellent communication skills to convey complex technical concepts to non-technical audiences.
Continuous Learning: Willingness to stay updated with the latest trends, tools, and techniques in data engineering, cloud platforms, data science, and statistical modeling. A growth mindset and eagerness to learn and adapt to evolving technologies.
Required Competencies
Analytical: Synthesizes complex or diverse information; Collects and researches data; Uses intuition and experience to complement data. Ability to read, analyze, and interpret common technical journals, and documents.
Problem Solving: Identifies and resolves problems in a timely manner; Gathers and analyzes information skillfully; Develops alternative solutions; Works well in group problem solving situations; Uses reason even when dealing with emotional topics.
Interpersonal: Focuses on solving conflict, not blaming; Maintains confidentiality; Listens to others without interrupting; Keeps emotions under control; Remains open to others' ideas and tries new things.
Oral Communication: Speaks clearly and persuasively in positive or negative situations; listens and gets clarification; Responds well to questions; Demonstrates group presentation skills; Participates in meetings.
Team Work: Balances team and individual responsibilities; Ability to multi task and manage multiple projects and priorities; Exhibits objectivity and openness to others' views; Gives and welcomes feedback; Contributes to building a positive team spirit; Puts success of team above own interests; Able to build morale and group commitments to goals and objectives; Supports everyone's efforts to succeed; Recognizes accomplishments of other team members.
Attendance/Punctuality: Is consistently at work and on time; Ensures work responsibilities are covered when absent; Arrives at meetings and appointments on time.
Dependability: Follows instructions, responds to management direction; Takes responsibility for own actions; Keeps commitments; Commits to long hours of work when necessary to reach goals; Completes tasks on time or notifies appropriate person with an alternate plan.
Innovation: Displays original thinking and creativity; Meets challenges with resourcefulness; Generates suggestions for improving work; Develops innovative approaches and ideas; Presents ideas and information in a manner that gets others' attention.
Motivation: Sets and achieves challenging goals; Demonstrates persistence and overcomes obstacles; Measures self against standard of excellence; Takes calculated risks to accomplish goals.
Quality: Demonstrates accuracy and thoroughness; Looks for ways to improve and promote quality; Applies feedback to improve performance; Monitors own work to ensure quality.
Job Type: Full-time
Salary: $90,000.00 - $135,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Flexible schedule
Health insurance
Health savings account
Life insurance
Paid time off
Vision insurance
Schedule:
8 hour shift
Monday to Friday
Supplemental pay types:
Bonus pay
Education:
Bachelor's (Required)
Experience:
Management consulting: 5 years (Required)
Data management: 7 years (Required)
Work Location: Remote
Flexible work from home options available.","$112,500 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Apple
4.2",4.2,"Cupertino, CA",Cellular 4G/5G Firmware Data and Automation Engineer,"Summary
Posted: Dec 12, 2022
Role Number:200448933
Do you have a passion for invention and self-challenge? As part of a world class modem team, you’ll craft sophisticated groundbreaking embedded firmware that deliver more performance in our products than ever before! We'll work across disciplines to transform improved hardware elements into a single, coordinated design. Join us, and you’ll help us innovate new wireless systems technologies that continually outperform the previous iterations. By collaborating with other product development groups across Apple, you’ll push the industry boundaries of what wireless systems can do and improve the product experience for our customers across the world. As a Cellular 4G/5G Firmware Data and Automation Engineer, you will be at the center of the embedded 5G/4G/multimode cellular firmware effort within a silicon design group responsible crafting and productizing powerful cellular SoCs.
Key Qualifications
Minimum BS and 3+ years of relevant industry experience
Ability to think creatively and identify, build, and support solutions and roadmaps focused on automation and reduction of manual processes
Strong critical thinking and communication skills with the ability and desire to learn and evaluate new technologies
Experience in utilizing analytics and statistical methods to transform data into useful insights and actionable results
Proficient Python developer with 3+ years of experience in developing data processing & test automation pipeline or similar projects
Good understanding of AWS components including S3, Kinesis firehose, Kibana, Elasticsearch, Redshift
Experience in creating data processing & visualization pipeline over AWS.
Proven knowledge and experience with relational database (e.g Postgres), SQL and non-relational database (e.g.Mango DB) is required
Experience with Testrail is a plus
Experience with popular data visualization tools is a plus
Description
Design and develop robust and modular data processing & automation systems across hardware and software that enable engineers to be more efficient produce quality work Develop scripts for implementing firmware verification test cases Use external tools and internal tools/services from other teams within Apple We are looking for someone with a passion for technology, automation, data and an ability to iterate quickly.
Education & Experience
Minimum BS and 3+ years of relevant industry experience
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
TEKletics,#N/A,"Scottsdale, AZ",Python Data Engineer,"Azure Data Engineer
Tekletics is an information technology company focused on providing quality resources to support our customers needs. Successful candidates will work with world class organizations to deliver projects. Each candidate is required to have a strong work ethic and the ability to handle high pressure situations.
A little about this role:
As the Azure Data Engineer, you are primarily responsible for the collection and transformation of data across a multitude of data sources. This individual is also responsible for the optimization of the environment, structure, and processes associated with said data.
A day in the life:
Data Warehouse - As the Azure Data Engineer, you are responsible for the data warehouse design, development, testing, support, and configuration. You will review business requests for data warehouse data and data warehouse usage. You will also research data sources for new and better data feeds ensuring consistency and integration with existing warehouse structure.
Data Collection – You will be responsible for developing automated data pipelines and/or data integrations within the Azure Synapse environment. You will use SQL, Python scripts and Azure Functions to automate data collection from a wide variety of sources.
o API utilization – ability to leverage REST APIs as needed.
Data Transformation – You will create BI (Business Intelligence) and Data Warehousing cube design. You will create and manage ETL/ELT processes to transform and load data into data warehouse for reporting and analytics.
Data Optimization – As the Azure Data Engineer, you will create and maintain standards and policies. You will identify, design, and implement internal process improvements, including automation of manual processes and optimization of data delivery. You will continuously improve data reliability, efficiency, and quality.
Training – Identify and demonstrate techniques to optimize reporting for Data Visualization Analyst, provide and participate in internal and external training sessions, and produce documentation to support understanding and learnings around the Presence data/reporting environment.
This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Projects and responsibilities may change at any time with or without notice due to our business, industry, and/or market changes.
What we are looking for:
Previous experience using SQL, Python scripts and Azure Functions
Experienced in Azure Synapse environment
Experience designing, building, and maintaining data processing system
Dependable, extroverted, diplomatic person, able to problem-solve successfully with a wide variety of people and issues
Attention to detail and strong organizational skills, self-motivated
Ability to work independently while being a strong team player
Ability to mentor junior level developers
Passion for innovation and “can do” attitude to thrive in a fast-paced environment
Proficient in time management and adhering to deadlines
Knowledge and interest of the natural products/brands and retail landscape is a plus
Proficient computer (MS Office applications) and data-mining skills
Flexibility to successfully multi-task in a fast-paced environment with a positive attitude
Regular and predictable attendance is required
Ability to manage time and deadlines
Job Type: Full-time
Pay: $79,947.00 - $142,509.31 per year
Experience level:
3 years
Schedule:
8 hour shift
Ability to commute/relocate:
Scottsdale, AZ: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 3 years (Required)
Python: 5 years (Required)
MongoDB: 3 years (Required)
Work Location: In person","$111,228 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Infovista
3.7",3.7,United States,Data Center Engineer M/F,"Position description
Category
Development/Engineering - Information Technology Management / General IT
Job title
Data Center Engineer M/F
Contract
Indefinite term contract
Position start date
01/11/2023
Job description
Infovista helps fixed, mobile and broadband communications service providers (CSPs) and IT-intensive enterprises improve customer experience, reduce customer churn and deliver differentiated services, while increasing the capital efficiency of their infrastructure. For more information, please visit www.infovista.com

The Data center engineer is responsible for the day-to-day systems/network/environmental monitoring of our Billerica, Somerville and Cambridge, MA sites as well as our Manchester, NH CoLo site.

You are tasked with ensuring that these facilities run smoothly and efficiently, which often means monitoring and maintaining equipment, resolving issues as they arise, and planning for future growth or changes in technology.

The role will deploy and maintain Company's Data Center Server and Network Infrastructure by installing, configuring, testing, troubleshooting, and repairing hardware and server software. This role is will also participate in the management and configuration of our New England based network architecture. Data center engineer will ensure that goals, missions, and projects are successfully delivered and that they are repeatable across our global array of data centers. In this role, you will move and install equipment, and ensure Data Center quality and reliability.

Responsibilities
Monitoring and troubleshooting server, storage, and networking equipment for malfunctions or failures Data center Engineer
Installing and configuring new servers, storage devices, routers, switches, and other network components
Conducting capacity assessments of existing infrastructure to ensure that it can support future growth
Maintaining detailed documentation of all server and storage configurations and changes made to them
Performing regular backups of data to prevent loss in case of computer failure or theft
Providing technical support for applications and operating systems used in the data center
Writing scripts to automate common processes within the data center environment
Monitoring energy usage across the data center to ensure efficient operation
Maintains optimal system performance. Performs data backup, ensures system security, and manages systems capacity.
Maintains inventory and labeling of equipment and removal of decommissioned hardware. Maintains an adequate spare parts inventory of systems, subsystems, and parts used in repair work.

Requirements:
Experience with server maintenance and support (HP and Dell)
o Firmware updates, iDRAC/iLO configuration (and tracking), adding/removing/configuring hardware (NICs, memory, etc)
o Monitor and remediate system level issues (failed drives, memory, etc)
o Troubleshoot system level incidents and action/recommend action to remediate issues related to consumption, hardware performance, etc
Network Experience o TCP/IP and basic network understanding required
o Cisco experience required o Simple configuration requirements such as
Profile
Knowledge/expertise in the following areas is a plus:
IT Glue or similar documentation platform experience
o Visio or other network mapping experience for rack/network diagrams
SNMP v2 (and v3)
o Not just for hardware but for OS as well
Automated Documentation/Provisioning IMS DevOps (entry level)
Basic Linux, i.e.:
o How to perform installs
o Assist in basic troubleshooting
o Perform port mapping
System/Environmental monitoring
o PRTG, RoomAlert

Qualifications: Bachelor’s degree in any of computer science, computer systems engineering, electronic engineering and other related disciplines. Certifications from IT companies such as Microsoft and Cisco Technologies (preferable).

Location: Billerica (MA)

Why Infovista? Day after day, Infovista strengthens its position of global market leader in 5G and next-generation networks, focused on the growing network lifecycle automation requirements of our CSP and large enterprise customers. As part of our commitment to Infovista Employees we strive to create an environment offering
Flexible workplaces- adaptable work schedules, workspaces & locations • Inclusive culture- everyone’s voice matter
Sustainability- environmental, social & governance programs (ESG Group)
Innovative Environment- shape the future of next gen networks

The Infovista Values define our philosophy to serve employees, customers, and the broader community:
CARE- We work towards a sustainable future for customers, employees & society
INNOVATE- We create value through innovation
STRONGER TOGETHER- We are more than the sum of the parts
ASPIRE- We are achievers & have a strong drive for great results
OWN- We are not observers, we stand up, commit, own & deliver
Position location
Job location
America/Carribean, USA


General information
Organisation
InfoVista is an Equal Opportunity Employer. We are committed to the principles of equal opportunity and freedom from any harassment or discrimination for all candidates and employees. We adhere to these in all our hiring, promotion, employee movement practices.
Reference
2023-616",#N/A,501 to 1000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,1995,$100 to $500 million (USD)
"SailPoint
4.4",4.4,United States,"Senior Software Engineer, Data Platform","SailPoint is the leader in identity security for the cloud enterprise. Our identity security solutions secure and enable thousands of companies worldwide, giving our customers unmatched visibility into the entirety of their digital workforce, ensuring workers have the right access to do their job – no more, no less.
As a Senior Software Engineer on our Data Platform team you will help build our SailPoint Data Platform. We are looking for a well-rounded software engineer who is passionate about building a large-scale data infrastructure. You will work closely with Data Engineers, Warehouse Engineers, other software engineers and Data Scientists.
You will bring software engineering expertise to our Data Platform team. We are looking for someone with strong Python, Java, SQL, Snowflake and DBT experience.
Responsibilities
Collaborate with peers on designs, code reviews, and testing
Produce unit and end-to-end tests to improve code quality and maximize code coverage for new and existing features
Deliver efficient, maintainable, robust Java based microservices.
Utilize a Data Platform to build and deliver data models via Java services.
Produce designs and rough estimates, and implement features based on product requirements.
Collaborate with peers on designs, code reviews, and testing.
Use telemetry to demonstrate the effectiveness of deployed services.
Work independently and deliver quality code on time
Requirements
5+ years of professional software development experience
At least 5 years of experience addressing and solving intricate data engineering challenges
A demonstrated eagerness to acquire new technical skills and adapt to evolving data landscapes
Strong programming skills, particularly in Python and Java, complemented by advanced SQL knowledge
Experience with Airflow DAGs, DBT models, Snowflake, Spark
Extensive hands-on experience building solutions for large-scale data infrastructure
Hands-on experience or deep understanding of data ingestion processes, data management best practices, and data warehousing principles.
Proficient experience with object-oriented analysis and design skills
Proficient understanding of Restful API’s
Strong experience testing code completeness and using telemetry to measure health and efficiency of services
Experience documenting requirements, proposed implementations, progress, challenges, and explanations of finished work
BS in Computer Science, or equivalent experience
Preferred
Experience with AWS
Experience working on a Big Data/Machine Learning product
Experience instrumenting code for gathering production performance metrics
SailPoint is an equal opportunity employer and we welcome everyone to our team. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2005,$100 to $500 million (USD)
"SAIC
4.0",4.0,"Fort Meade, MD",Data Flow Junior Systems Engineer,"Job ID: 2312738
Location: FORT MEADE, MD, US
Date Posted: 2023-09-15
Category: Engineering and Sciences
Subcategory: Systems Engineer
Schedule: Full-time
Shift: Day Job
Travel: No
Minimum Clearance Required: TS/SCI with Poly
Clearance Level Must Be Able to Obtain: None
Potential for Remote Work: No

Description
Are you interested in joining SAIC to be part of our partnership providing high quality engineering advisory services, system planning, integration, and architecture to our government intelligence agency customer? Then consider joining the members of the Enterprise Systems Engineering and Architecture team as they aid our customer in collaborating, integrating, and standardizing the engineering approach across the customers enterprise.
We have on-going requirements for a Data Flow Junior Systems Engineer in support of our customer at their Fort Meade facility. As a Dataflow Systems Engineer on our team, you will provide support services to the Data Flow and Routing Solutions (DFRS) systems engineering team. Required support includes customer service, dataflow paths, organize dataflow implementation, identify ways to improve dataflow implementation and modernization efforts, and prioritize the customer’s needs based on larger strategic priorities.
Responsibilities include:
Identify and establish new processes and procedures (modernization efforts, process improvement…) and have excellent customer service skills.
Data tagging, data formats, data sanitization, data sharing rules/criteria, general dataflow knowledge and troubleshooting.
Provide support to manage the process of dataflow requests. This includes customer and service provider support/interaction and learning the customer need and how it fits into the larger picture.
Measure and monitor metrics, identify trends, discover areas for process improvement, document deficient resourcing, and report standings and finding to management and other stakeholders.
Provide support to technical leaders by coordinating activities pertaining to the development, documentation and maintenance associated with changes to the system.
Support also includes leading customer and service provider meetings, setting agendas, taking meeting notes, maintaining process documents, describing complex information in simple terms so people who are not experts can understand.
Research and document dataflow processes according to standards of compliance in support of the Enterprise Data Header (EDH) initiatives. Support will include research, analysis, documentation, and integration of how data can be identified, protected, tracked and handled throughout its life cycle.
Qualifications
Required
Position requires TS/SCI clearance with polygraph
A Bachelor’s degree in Computer Science, Electrical Engineering, Systems Engineering, or a related discipline and at least 2 years of systems engineering experience.
A Master’s or PhD Degree may be substituted for the two years of experience.
Note: a High School Diploma or GED plus 6 years of systems engineering experience is also acceptable.
This is a full-time position requiring 1880 hours of support per year; and work is performed at the customer site.
Desired
Experience in data tagging, data formats, data sanitization, data sharing rules/criteria, and general dataflow knowledge.
Ability to work constructively and successfully with diverse stakeholders to resolve mission and technical issues is critical.
A self-starter, have a high level of attention to detail, and possess excellent oral and written communication skills, and be proficient with Microsoft Office Tools.

Covid Policy: SAIC does not require COVID-19 vaccinations or boosters. Customer site vaccination requirements must be followed when work is performed at a customer site.","$83,952 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1969,$5 to $10 billion (USD)
#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"ICF
3.8",3.8,"Reston, VA","Data Engineer, Azure-based Health Data System (Remote)","Description
*We are open to supporting 100% remote work anywhere within the US. *

Our IT Modernization division is an information technology and management consulting department that offers integrated, strategic solutions to its public and private-sector clients. ICF has the expertise, agility, and commitment to design, build, and operate high-performance IT engines to support all aspects of our client’s business.

Job Description:
The Data Engineer will use a variety of full-stack software languages and tools to build a data processing system for health care data in a major Health & Sciences agency. The system will be built on and Azure infrastructure and will integrate data from both internal and external data sources. The Data Engineer will create new pipelines and build reusable components at scale to support reporting & analytics data products.
Based on your experiences and interests, we may ask you as a technology professional to support growth-related activities, including (but not limited to) RFI, RFP, prototypes, and oral presentations. Team members are also expected to uphold and maintain appropriate certifications necessary for their practice expertise.
You will:
Write complex queries to transform raw data sources into accessible models by coding.
Clean, prepare, transform, and optimize data at scale for integration and consumption.
Implement data management projects and restructure current web architecture.
Solve complex data issues and perform root cause analysis to proactively resolve product issues.
Own the data pipeline and support systems failures.
Requirements:
Must have previous experience working with any CDC Center, Institute, or Office or specific CDC application(s) that are in scope for modernization
3+ years of experience programming with Java and/or Kotlin
3+ years of experience working with Azure cloud native technologies
2+ years of experience building a pipeline for Public health/health care data (HL7, FHIR, vocabulary, and HHS data standards)
2+ years experience with developing ETL pipelines in Azure using tools such as Azure Data factory, Event hubs, Event grid, Azure functions,
2+ years developing data engineering pipeline with Databricks or Spark
2+ years of experience working in Agile teams
Familiar with devOps process, CI/CD, security, coding standard and SDLC cycle
Preferred:
1+ year working with technologies such as CosmoDB, AzureSQL, Redis, Synapse
1+ year working with orchestration tool such as Airflow or Oozie
Experience working with streaming and batching solutions
Experience working with csv, json, xml and complex structures
#DMX
#LI-CC1
#Indeed
Working at ICF
ICF is a global advisory and technology services provider, but we’re not your typical consultants. We combine unmatched expertise with cutting-edge technology to help clients solve their most complex challenges, navigate change, and shape the future.
We can only solve the world's toughest challenges by building an inclusive workplace that allows everyone to thrive. We are an equal opportunity employer, committed to hiring regardless of any protected characteristic, such as race, ethnicity, national origin, color, sex, gender identity/expression, sexual orientation, religion, age, disability status, or military/veteran status. Together, our employees are empowered to share their expertise and collaborate with others to achieve personal and professional goals. For more information, please read our EEO & AA policy.
Reasonable Accommodations are available, including, but not limited to, for disabled veterans, individuals with disabilities, and individuals with sincerely held religious beliefs, in all phases of the application and employment process. To request an accommodation please email icfcareercenter@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: Know Your Rights and Pay Transparency Statement.

Pay Range - There are multiple factors that are considered in determining final pay for a position, including, but not limited to, relevant work experience, skills, certifications and competencies that align to the specified role, geographic location, education and certifications as well as contract provisions regarding labor categories that are specific to the position. The pay range for this position is:
$82,673.00 - $140,544.00
Nationwide Remote Office (US99)","$111,609 /yr (est.)",5001 to 10000 Employees,Company - Public,Management & Consulting,Business Consulting,1969,$1 to $5 billion (USD)
"Tech Impact
4.2",4.2,"Wilmington, DE",Data Innovation Lab Fellowship Program - Data Engineer / Data Scientist / Front End Developer,"A Nonprofit That Leverages Technology To Advance Social Impact:


Apply To Our Data Fellowship Program.
We Are Looking For Data Scientist, Data Engineers & Front End Developers:
- Starting June, 2024 - To May, 2025 :
- 1 Year Paid Fellowship - $70,000:
Job Placement Assistance:
The Data innovation Lab at Tech Impact uses data for social good. If you are interested in using your advanced data analytics and artificial intelligence skills to improve Delaware's most pressing social challenges, then apply to our Fellowship today!:
Contribute to meaningful, complex data projects.:
Enhance your technical skillset by collaborating on initiatives across social good. domains.:
Advance professionally by building your expertise in the non-profit and civic data space to help improve communities. :
If you are interested please apply to the position or send your resume to Devie Smith our Talent Acquisition Manager at Devie@techimpact.org","$86,216 /yr (est.)",51 to 200 Employees,Nonprofit Organization,Information Technology,Information Technology Support Services,2003,$5 to $25 million (USD)
"Precision Solutions
4.2",4.2,"Springfield, VA",Data Automation Engineer,"Overview:
Data Automation Engineer
Hybrid | Springfield, VA or St. Louis, MO | 4 days a week Onsite
TS/SCI Clearance with ability to obtain CI Poly Required

Summary
Our client has been a leading enterprise Content Services Platform (CSP) to Federal, Civilian and DoD agencies since 1995. Furthermore, Knowvation® (formerly ArchivalWare™), their CSP application, has been in production since 2003. They are best known for providing knowledge management, geospatial, and declassification solutions. They also help with digitization, system integration, application installation/configuration, content loading/organization, training, staff augmentation, and ongoing support services.

Responsibilities
Our client is looking for a Data Automation Engineer to join their team!
Support the Geospatial Services and Solutions business area to provide high-quality, cost-effective solutions to the customer
Design and implement automation solutions to enhance data capture, data refinement, and processes
Coding examples include:
Interfacing with device APIs in order to collect operational metrics
Providing automated VoIP phone setup
Administering and automating data pipelines between different environments
Produce and deploy code via GitLab projects in collaboration with other team members
Utilize best practices for source control, testing, and deployment of software changes
Work in close collaboration with other automation engineers, infrastructure administrators, and data scientists
Diagnose, isolate, and expediently resolve complex problems pertaining to data structures
Develop methods of ensuring data incompatibilities among systems are systematically eliminated
Develop and recommend data management policies, standards, practices, and security measures to ensure effective and consistent data management operations
Participate in continuous improvement efforts to increase data availability, data quality, and speed of access
Maintain up-to-date documentation of designs/configurations, ensuring team members have continuity of recurring tasks
Requirements
8+ years of related systems engineering experience
Scripting, coding, or software development experience
Comfort with Linux/Windows command-line
Automation mindset
System administration and/or DevOps environment experience
Python experience
Shell scripting experience such as Bash or PowerShell
Experience with Database technologies such as Postgres, SQL Server, Oracle, or MySQL
Experience writing and working with SQL commands
Version control experience with Git
Experience with Gitlab and Git workflows
Familiarity with Agile Scrum methodologies
Time management skills and the drive to work with limited supervision within a small team
Preferred Requirements
Web App development experience such as Flask, Django, React, etc.
UI/UX experience
Experience with Analytics tools such as Tableau
Infrastructure as Code experience
Experience in technical operations at DoD/IC agencies
Cloud experience such as AWS, Azure, GCP, etc.
Education/Certification Requirements
A Bachelor’s degree in computer science or related technical discipline, or the equivalent combination of education, technical certifications or training, and work experience
Clearance Requirements
Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; an active TS/SCI clearance is required with the ability to obtain a CI Poly.
COVID-19 Vaccine Statement
This position may require candidates to disclose their COVID-19 vaccination status based on our client's requirements.
Other Duties
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.
-
About Us
Northern Virginia-based Precision Solutions is an expert in staffing solutions for companies of any size that open the door to new opportunities and seek outstanding talent. We pride ourselves on being versatile enough to tailor our relationships to the needs of each individual client, being agile in the fast-paced marketplace, and being precise in meeting the needs of any company.
Equal Opportunity Employer Statement
Precision Solutions is an equal opportunity employer. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.","$102,327 /yr (est.)",1 to 50 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,#N/A,$5 to $25 million (USD)
"PODS Enterprises, LLC
3.5",3.5,"Clearwater, FL",IT Data Engineer III (Lead),"The successful candidate will demonstrate:
Expertise in DW concepts, think Bill Inmon & Ralph Kimball
Strong analytical abilities and creative problem solving
Work with data stakeholders (technical as well as end users) to understand business requirements and implement database solutions for diverse problems. We do not leverage a Business Analyst as a go between
Ability to work independently with general direction and flexibility in a fast-paced environment
Good organization and excellent communication skills across cultures in English
Integrity and a positive attitude, especially while handling stressful situations
Research viable technical and/or non-technical solutions, evaluate new technology and advocate, influence, and build consensus for innovations that satisfy business needs
Required Qualifications:
BS/BA degree, preferably in computer science or related field; or business administration, or mathematics
10+ years IT experience, including 5+ years in DW Development. Advanced background in Ansi SQL on Snowflake, Teradata or Redshift or equivalent
Experience in data analysis and database architecture, maintenance, and support
Expertise in cloud data warehouse platforms such as Snowflake
Experience in Python pulling data from APIs; or experience in other integration frameworks pulling data from SaaS applications in the cloud
Hands-on implementation experience building a Data Warehouse
Experience in all aspects of Agile SDLC, and end to end participation in a project lifecycle, especially delivering modular system change with a high degree of testing, change management, automation and cutover
Experience with Tableau or Power BI is beneficial
Experience working with resources over Microsoft Teams or similar technology to collaborate","$103,447 /yr (est.)",1001 to 5000 Employees,Company - Private,Personal Consumer Services,Consumer Product Rental,1998,$1 to $5 billion (USD)
"Carnegie Mellon University
4.5",4.5,"Pittsburgh, PA",Senior Data Engineer - National Robotics Engineering Center,"The National Robotics Engineering Center (NREC) at Carnegie Mellon University is looking for data scientists to develop tools to support machine learning and data-intensive applications. We are people with a desire to make robust software using agile development processes. You will work on a variety of software for commercial and government organizations. You will bring together open-source, commercial, internal, and your own tools to support diverse data processing workflows. Some of our machine learning software keeps self-driving vehicles safe, automatically discovers new pharmaceuticals, and leads to less waste in agriculture. You will support programs in deep learning for agriculture, artificial intelligence for defense, and autonomous manipulation.
Your primary responsibilities include:
Collaborate with key partners, business managers, and engineers to build consensus around data solutions, define high-level and detailed requirements, establish priorities, and deliver data pipelines successfully for machine learning, computer vision, and robotic applications
Perform, review, and facilitate trade studies and team discussions to select design solutions among options, including proprietary and open source packages and APIs.
Lead and collaborate with team members in data analysis, issues resolution, change management, risk management, documentation, quality assurance, scheduling, and staffing.
Data preparation, ingestion, integration, verification
Contribute to organization-wide methods and best practices for data engineering
Participating in the software process: design, code reviews, etc.
Developing, documenting, testing, and fixing software
Supporting development and acquisition of storage and networking hardware
Database deployment and administration
Webapp deployment and maintenance
Required Qualifications:
B.S. in Computer Science, Engineering, Mathematics is required (any more is a bonus)
>=3 year relevant industry experience is required.
Demonstrated understanding and use of software engineering concepts, practices, and procedures.
Proficient development skills in Python
Proficient in data infrastructure tools (SQL DB, NoSQL DB, data version control, etc.)
Linux scripting (bash and related tools) experience
Technical communication skills
Ability to participate in a multi-disciplinary team
Demonstrated success in leading, working, and collaborating within a team
Self-motivated, curious, and failure-seeking to achieve continuous improvements and solve problems
Demonstrated ability to apply critical big picture thinking in completing tasks
Highly organized with the ability to work on multiple projects/tasks simultaneously and remain agile given changing priorities
Practices attention to detail, respect for documentation accuracy, and information sharing
We especially want to hear from you if you have experience or qualifications in ANY of the following areas:
MLOps tools (airflow, mlflow, etc.)
Deployment tools (docker, kubernetes.)
Cloud, high performance, and distributed computing
Ingestion and integration of disparate sources
Data processing (pre-processing, augmentation, post-processing)
Tools and protocols for reproducible research and data analysis
Front end (Data visualization, exploration, labeling)
Proficient C or C++ skills
Professional software development processes
Networking interfaces and applications
CMake, Valgrind, and other development tools
Computer vision, robotics, machine learning, scientific computing, simulation, or graphics
Opportunities people at NREC have seized:
As a member of NREC, you take control of your career. People in similar roles have shaped their careers to suit their interests and their needs.
Publishing in conferences and journals
Guest lecturing in university courses
Becoming an in-depth expert in a technical area
Leading projects and fostering client relationships
Receiving mentoring from principal investigators
Mentoring junior engineers
Taking courses at Carnegie Mellon
Stay connected with academic activities at Carnegie Mellon
Performing consulting during off time
Outreach to K-12 and college-level students
Why NREC?
You will have an impact in shaping the robotics revolution, collaborate with and learn from experts, and build your career in a very fast-growing field. As part of our team, you will develop solutions to solve industrial and government challenges, deploy your technology in real-world situations, work side-by-side with elite robotics experts, and develop a variety of cutting-edge technologies.
Have an Impact!
Remove waste from farming = more food (
link
)
Make industrial processes environmentally friendly (
link
)
Make hazardous jobs safer (
link
)
Improve efficiency in industry & manufacturing (
link
)
Accelerate screening of pharmaceuticals (
link
)
Take Control of Your Career!
Select the career pathway that interests you
Influence the direction of projects
Supportive of a non-standard schedule
Maintain work/life balance
Switch between part-time and full-time as life demands
NREC is at the center of the robotics ecosystem in Pittsburgh, PA. With over 100 robotics companies, Pittsburgh has become the robotics capital of the world. Geek Wire calls it
Robotics Row
; others call it
Roboburgh
. Join the leader in the most exciting time in robotics!
Join the best robotics R&D group
Join our talented team at NREC, an operating unit within the world-renowned Robotics Institute at Carnegie Mellon University.
NREC has 25+ years of experience and is globally renowned for developing and deploying robots into many applications across multiple sectors, such as agriculture, mining, defense, energy, and manufacturing. We strive to provide solutions for real world challenges where automation and robots have greater impact on productivity and improve the safety and comfort of the labor force. Our unique expertise places us at the forefront of unmanned ground vehicle design, autonomy, sensing and perception, machine learning, machine vision, operator assistance, 3D mapping and position estimation. With over 160 robotics professionals, we can solve challenges that no other organization can.
NREC also leads in educational outreach through its Robotics Academy, which builds robotics curricula and software for K-12 and college-level students.
At NREC, we value diversity, support it, and thrive on it for the benefits of our organization, our employees and our community. Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.
#NREC
Location
Pittsburgh, PA
Job Function
Engineering, Research and Project Scientists
Position Type
Staff – Regular
Full Time/Part time
Full time
Pay Basis
Salary
More Information:
Please visit “
Why Carnegie Mellon
” to learn more about becoming part of an institution inspiring innovations that change the world.
Click
here
to view a listing of employee benefits
Carnegie Mellon University is an Equal Opportunity Employer/Disability/Veteran.
Statement of Assurance","$123,092 /yr (est.)",1001 to 5000 Employees,College / University,Education,Colleges & Universities,1900,$1 to $5 billion (USD)
"JT4
3.7",3.7,"Edwards, CA",Engineer II - Data Links,"JT4, LLC provides engineering and technical support to multiple western test ranges for the U.S. Air Force, Space Force and Navy under the Joint Range Technical Services Contract, better known as J-Tech II. JT4 develops and maintains realistic, integrated test and training environments and prepares our nation's war-fighting aircraft, weapons systems, and aircrews for today's missions and tomorrow's global challenges.
JOB SUMMARY - ESSENTIAL FUNCTIONS/DUTIES
Performs as a lead on more complex engineering assignments. Performs a variety of engineering assignments in planning and overseeing research, design, development, manufacturing, testing, installation, integration, sustainment, operation, and maintenance of diverse software, electronic, and/or mechanical equipment and systems. Performs generally as a lead of a development, sustainment, or operations & maintenance team on more complex engineering assignments.
Independently performs a range of design, development, analysis, or review tasks under generally established project deadlines.
Completes design specifications, analyses, or design reviews for complex projects.
Generates complete design specifications for more complex projects.
Coordinates and works closely with other engineering, logistics, financial, and program management disciplines to define system specifications and requirements.
Verifies and complies with engineering documentation standards and test procedures.
Prepares, delivers, and submits technical papers and performs engineering studies.
Supports development of technical proposals and provides comments on the technical content and level of effort of the proposed scope of work.
Develops, maintains, and produces technical documentation and system/subsystem specifications.
Directs interface with customers at all levels from quotation to final design and test activities; acts as liaison for design reviews and technical working group meetings to comply with requirements and specifications.
Conducts site visits and experimental investigations and analyzes engineering problems, proposes solutions and alternatives, and provides recommendations.
Performs other position-related duties and assignments as directed.
RANGE POSITION DESCRIPTION
Candidate will need basic understanding of Python and basic experience is desired with operating common tactical data link radios/terminals/gateways/modems, MIDS LVT (Link 16), MIDS JTRS (Link 16), AN/ARC-210 (U/VHF), AN/PRC-117G (U/VHF). Should have some familiarity with the following data link waveforms and protocols: Link 16, Variable Message Format (VMF) and the ability to develop and analyze data link messages (J-series messages, K-series messages). Ability to read and understand common military data link standards and protocols is desired: (MIL-STD 6016 (Link 16), MIL-STD 6017 (VMF).
Familiarity with using tactical data link software is desired: (Battlefield Operations Group Support System (BOSS), Amalgamated Remote Management System (ARMS), Link 16 Environment Gateway Stimulator (LEGS), Terminal Operational Environment Simulator (TOES), IDM Workbench. Protocol Analyzer, Message Analysis and Data Reduction for the Integration of Links (MANDRIL).
Candidate will order aircraft data for a specific Data Link and Aircraft and run a software program or go through the data manually to analyze it, complete computer data transfers, and including completion of proper documentation.
Candidate will plan individually or with teammates Data Link test missions, interact with other platforms to conduct Data Link Interoperability testing. Candidate will operate Data Link Equipment during actual missions to gather data from the aircraft and send stimulus to aircraft during missions to complete test operations.
Candidate needs to have basic understanding in COMMS and Datalinks, ability to obtain/maintain the appropriate clearances, be a team player, be self-motivated to get things done on time and with high quality, and be willing to work odd hours at times, be familiar with hardware and software.
DESIRED QUALIFICATIONS
Active Secret clearance
Current CompTIA Security+ certification or must be able to obtain a CompTIA Security+ certification within six months of hire
REQUIREMENTS - EDUCATION, TECHNICAL AND WORK EXPERIENCE
The incumbent must have a Bachelor of Science in Engineering from an ABET-accredited academic institution with 2 years of related engineering experience, or have an accredited Master of Science in Engineering. The candidate must have professional knowledge of applicable engineering concepts and principles and familiarity with related engineering fields. The candidate must have practical knowledge of test methods and practices sufficient to perform routine to more complex engineering procedures and to prepare or make minor modifications of standard test procedures or test equipment work instructions. The incumbent should have a working knowledge of computer systems and computer-based engineering tools and must possess planning/organizing skills. The incumbent must possess a valid, state issued driver's license. Must be able to obtain and maintain security clearance. Must be a U.S. citizen.
SALARY
The expected salary range for this position is $67,392 to $110,157 annually.
Note: The salary range offered for this position is a good faith description of the expected salary range this role will pay. JT4, LLC considers factors such as (but not limited to) responsibilities of the position, candidate's work experience, education/training, key skills, internal peer equity, as well as, market and business considerations when extending an offer.
BENEFITS
Medical, Dental, Vision Insurance
**Benefits Active on Day 1
Life Insurance
Health Savings Accounts/FSA's
Disability Insurance
Paid Time Off
401(k) Plan Options with Employer Match
JT4 will match 50%, up to an 8% contribution
100% Immediate Vesting
Tuition Reimbursement
OTHER RESPONSIBILITIES
Each employee must read, understand, and implement the general and specific operational, safety, quality, and environmental requirements of all plans, procedures, and policies pertaining to his/her job.
WORKING CONDITIONS
This position involves work typical of an office environment with no unusual hazards. There is occasional lifting to 20 pounds, constant sitting with occasional use of computer terminal, constant use of sight abilities while reviewing documents, constant use of speech/hearing abilities for communication, and constant mental alertness. Routine travel to remote Company work locations may be required.
DISCLAIMER
The above statements are intended to describe the general nature and level of work being performed by personnel assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of persons so classified.
Tasking is in support of a Federal Government Contract that requires U.S. citizenship. Some jobs may require a candidate to be eligible for a government security clearance, state-issued driver's license or other licenses/certifications, and the inability to obtain and maintain the required clearance, license or certification may affect an employee's ability to maintain employment.
SCC: JENG17, A1412TW","$88,775 /yr (est.)",1001 to 5000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2000,$100 to $500 million (USD)
Atlas Real Estate,#N/A,"Denver, CO",Data Engineer – Business Intelligence,"Description:
Do you want to work at a fast growing, employee-owned company, recognized by leading media outlets as one of the?Best Places to Work, the?Best Property Management Company?and a?Top Company in Real Estate?
Are you ready for growth and upward mobility, a flexible schedule, and to be part of a fun, dynamic, and passionate team?
Atlas Real Estate, a Denver-based residential real estate brokerage and property management company with offices across seven states, is hiring a Data Engineer. Atlas currently manages over 8,500 units of residential real estate and the joint venture owns approximately 1,800 homes acquired in the last 24 months.?Learn more at realatlas.com
As a Data Engineer at Atlas Real Estate, you will handle designing, developing, and maintaining our database systems to ensure efficient and secure data storage and retrieval. Your primary responsibilities will include, but are not limited to:
Database Management: Design, implement, and maintain solutions built on database systems using your mastery of SQL, ensuring optimal performance, scalability, and data integrity.
ELT (Extract, Load, Transform) Development: Develop and maintain Extract, Transform, Load (ELT) processes to efficiently integrate data from various sources into our database systems.
API Experience: Design, build, and maintain solutions built on various API standards REST, GraphQL, etc.
Programming: Utilize your expertise in SQL and Python
Cloud Platform: Knowledge of Microsoft Azure and Snowflake
Collaboration: Collaborate with cross-functional teams, including software engineers, data analysts, and business stakeholders, to gather requirements and deliver database solutions that meet business needs.
Performance Optimization: Identifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Working with stakeholders including data, sales, pm, and executive teams and assisting them with data-related technical issues.
What you get:
Base Salary $95,000-145,000 year depending on skills and experience
Annual Performance Based Bonus of up to 15%
Total Rewards:
Health Insurance
Medical Insurance (with $376 monthly contribution)
Dental Insurance
Vision Insurance
Time Off
Discretionary Time Off
Nine paid federal holidays off
Birthdays off
Atlas Gives Back (volunteer events and two volunteer days off per year)
Parental Leave:
Birthing Parents/Primary Caregiver – 8 weeks paid leave (+ FML applicable)
Non-Birthing Parents/Non-primary caregiver – 2 weeks paid leave (+ FML if applicable)
Supplemental Insurance
Health Savings Account
Dependent Care Flex Savings Account
Accidental Insurance
Life Insurance
Short-term and Long-term Disability
Critical Illness
Incentives to Become a Real Estate Investor
Property Management Discount
7% management fee
$150 lease-up fee
Perks
A purpose-first driven company: We uplift humanity through real estate.
Atlas is a well-recognized Best Place to Work company
Flexible work schedules and work-from-home options
$1000 Team Member Referral Program
Pet “Discount Plan”
Compost-at-home stipend
Gym Membership stipend ($50/monthly)
Boot Camp classes to become a savvy real estate investor
Annual Holiday Party w/ giveaways
5-year Anniversary Trip:
All-inclusive Beach Vacation, OR
Plane tickets to anywhere in the world, OR
An Alaskan cruise
Referral Rewards
Referral to Property Management
$300 for Single Family Home (½ paid at closing and ½ paid after at one year)
$100 for Multi-Family Home (½ paid at closing and ½ paid after one year)If you are a motivated and skilled Data Engineer looking to join a dynamic real estate company, we invite you to apply. Please submit your resume, along with a cover letter highlighting your relevant experience and why you believe you are the ideal candidate for this position.
Note: Only shortlisted candidates will be contacted for further evaluation. Atlas Real Estate is an equal opportunity employer, and we encourage applicants from diverse backgrounds to apply.
Requirements:
Preferred Qualifications:
Experience: 3-10 years of proven experience in database management with a strong focus on SQL. Previous experience in the real estate or property management industry is a plus but not required.
Education: Bachelor's degree in computer science, information technology, or related
ELT Development: Proficiency in designing and implementing ELT processes to extract, transform, and load data from various sources. Experience with DBT is preferred.
API Experience: Strong skills in developing and maintaining APIs using industry-standard frameworks and protocols.
Programming Languages: Expertise in Python and SQL languages to develop database applications and tools.
Cloud Platform: Hands-on experience with Microsoft Azure, Azure Data Factory, and Azure Functions.
Data Transfer: Familiarity with client data transfer processes through Snowflake or similar platforms.
AI (Artificial Intelligence) Tools and Integration: Interest or familiarity with AI tools and their integration with database systems would be beneficial.
Problem Solving: Excellent problem-solving skills with a focus on identifying and resolving database-related issues.
Team Player: Strong collaboration and communication skills to work effectively within a multidisciplinary team.
Attention to Detail: Meticulous attention to detail and a commitment to delivering high-quality work.","$120,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Three Ships
3.4",3.4,"Raleigh, NC",Data Analytics Engineer,"Role Overview:
3S Health is seeking a hands-on, self-motivated Data Analytics Engineer to own our data analytics pipeline for one of our fastest growing businesses. In this role, you will be responsible for collecting and modeling data through the deployment of modern cloud tools, and turning that data into insights through the building of dashboards and reports. This role is for the data engineer that seeks to get closer to the business, or the business analyst that seeks to dive deeper into understanding where their data comes from.
What you'll Do:
Create and maintain scalable data pipeline through combination of modern SaaS applications and custom-built solutions
Create and maintain business intelligence roadmap to help enable business goals
Partner with business users to gather and understand data requirements
Extract data from sources through custom-built data integrations (typically Python) with discipline towards automation
Write SQL-based transformations to turn raw data into production-ready business models
Develop and manage business and executive team dashboards
Create and maintain data storage systems
Develop data discoverability tools and data monitoring systems

What You'll Bring:
Proficiency in SQL and Python (and/or proven ability to pick up a new language)
Proven ability to operate autonomously to achieve results.
Optional experience in Data Build Tool (DBT) or other SQL-based transformation tools
General understanding of the Marketing Technology stack, components, and best-practices. An ideal candidate will have some familiarity with common marketing tools (Google Analytics, Tag Manager, Segment (CDP), Facebook Ads, etc.)
Experience with common enterprise analytics tools with proven ability to translate data insights into action (Tableau, PowerBI, Looker Studio, Superset, etc.)
Working knowledge of software development best practices as they apply to data engineering, including: Version Control, Unit Testing, and Continuous Integration/Continuous Delivery (CI/CD)
The Package
As a full-time employee of Three Ships, you'll have access to competitive benefits, including flexible time off, health/dental/vision, 401k match, an annual Relax & Recharge Bonus, an annual Learning & Development stipend to enroll in class(es) of your choosing, and up to $75 mobile reimbursement. If you join us in person in our Raleigh or Charlotte locations, we have an office stocked with snacks, coffee, and just about every other beverage you can imagine.
How We Hire
All applicants are considered without regard to race, color, religion, sex, national origin, age, disability, veteran status, gender identity, or any other discriminatory factors. Please note that we do not provide immigration sponsorship for this role. All offers are subject to a background check.","$91,608 /yr (est.)",201 to 500 Employees,Company - Private,Media & Communication,Advertising & Public Relations,2009,Unknown / Non-Applicable
"TRILLIUM HEALTH RESOURCES
3.5",3.5,Remote,IT Applications/Report Developer (Data Engineer),"Pay Plan Title: IT Applications/Report Developer
Working Title Data Engineer
FLSA Status: Exempt
Posting Salary Range: $60,409 - $95,359
Office Location: Remote with offices available in Greenville and Wilmington NC

POSTING DETAILS:
Make an Impact
Trillium Health Resources is a local governmental agency (LME/MCO) in North Carolina that manages serious mental health, substance use, and intellectual/developmental disability services. Serving in 28 counties, we help individuals and their families strengthen well-being and build foundations for a healthy life.
Join our team as we empower others to live their best lives by providing access to quality healthcare. We offer a challenging, engaging work environment where staff take home more than a paycheck. Every day, we see the results of our dedication – in the smiles of children on our accessible playgrounds and in the pride on the face of an adult cooking a meal for the first time. Working at Trillium Health Resources is more than just a job; it is an opportunity to make a direct impact on the communities we serve.
At Trillium, we know that empowering others begins with supporting and developing our team. That’s why we offer competitive benefits and work-from-home flexibility so that our employees thrive outside of the office. We’re also committed to building a diverse, inclusive culture where all employees have the potential to grow professionally and personally.
What We’re Looking For
Trillium Health Resources is transforming public health in North Carolina by managing the health needs of many of the state’s most vulnerable populations. After successfully implementing managed care for mental health, substance use, and intellectual/developmental disabilities in the early 2010s, we’re currently implementing a groundbreaking new type of Medicaid health plan that focuses on people’s physical health needs, as well as factors like housing and food insecurity that can affect health.
We’re seeking a Data Engineer who wants to grow their IT career by helping us implement this new model. You’ll work directly with team members from all parts of our organization, on everything from Medicaid claims processing, to finance and accounting, to quality improvement and population health management.
On a typical day, you might:
Use SQL to:
Create a report that helps assess the health of our provider network
Create a report that identifies pregnant members and directs them to targeted prenatal services
Use R/R-Studio, Python, or Power BI to design an interactive COVID-19 dashboard
Help onboard a new 3rd-party reporting tool by conducting end-user testing and creating a maintenance plan
Use Azure DevOps, TFS, or other software development/project management tools to:
Respond to requests from internal partners,
Document and track your progress on outstanding work
Maintain version control for reports and other code
Develop a data dictionary for a new line of business, such as physical or pharmacy claims data
Customize a data set(commercial or open) to fit Trillium’s requirements
Plan, coordinate, and implement a new set of security measures to safeguard HIPAA-protected member data
Employee Benefits:
Trillium knows that work/life balance is important. That’s why we offer our employees competitive benefits and flexibility that is second to none. Take a look at what we have to offer:
Flexible Work Schedules. Remote work was a strong part of our culture prior to COVID-19, and currently, employees may work remotely 100% of the time, with an in-office option available for those who prefer that.
Paid Time Off (PTO) of 23 days per year, plus 10 paid holidays both in first year of employment
Health Insurance - no premium for employee coverage
NC Local Government retirement pension. This is a defined-benefit retirement plan that will pay you a monthly amount upon retirement, for the rest of your life, with as little as five years of service. For more information, go to:
https://files.nc.gov/retire/documents/files/Actives/LGERSHandbook.pdf
401k with 5% employer match & immediate vesting
Public Service Loan Forgiveness Qualifying Employer
Flexible Spending Accounts
Qualifications:
Education: High School (required certification) / Associate’s degree Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, or Human Service field. Requires Certification
Experience: High School diploma and three (3) years’ experience in any of the following areas: Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, Human Service field, healthcare claims environment, reporting development, n-tier and web-based system development or support with strong technical knowledge in the specialized areas of application system programming, including software tools such as: SQL Server 2008 R2 or above, SQL, Oracle, NoSQL, MySQL, TFS (Team Foundation Server), Microsoft IIS and Microsoft .NET framework2.0 or above , Source Control, SSRS, SSIS, SSAS, SSMS, Visual Studio BIDS, Visual Studio 2008 or above, C#. Requires certification. Applicable certification(s) may be substituted to equivalent degree and experience requirements.
OR
Associate’s degree and a minimum one (1) year experience in any of the following areas: Information Technology / MIS, Mathematics (Actuarial/ Statistics), Data Analytics, Engineering Sciences, Business, Healthcare Administration, Human Service field, healthcare claims environment, reporting development, n-tier and web-based system development or support with strong technical knowledge in the specialized areas of application system programming, including software tools such as: SQL Server 2008 R2 or above, SQL, Oracle, NoSQL, MySQL, TFS (Team Foundation Server), Microsoft IIS and Microsoft .NET framework2.0 or above , Source Control, SSRS, SSIS, SSAS, SSMS, Visual Studio BIDS, Visual Studio 2008 or above, C#. Requires certification. Applicable certification(s) may be substituted to equivalent degree and experience requirements.

OR
Equivalent combination of education/experience
Preferred Experience: (If Applicable): Recent experience with SQL database management or report development (Power BI, Analytical, R, Python, Visual Studio and /or SSRS) preferred
License/Certification: Certification required for High School and Associates degree.
Preferred Experience: (If Applicable): Applicable certification(s) including Microsoft data systems certifications CSTP, ISTQB, ASTQB, MTA, MCSA, MCSD, MCSE, ITIL v3, Power BI, as well as INFORMS, IIBA, AWS, Azure, or equivalent certifications will be accepted
Must have a valid driver’s license
Location: Remote with offices available in Greenville or Wilmington, NC
Deadline for application: Friday, September 22, 2023 at 11:59 p.m.
To be considered for employment, all candidates are required to submit an application through ADP and upload a current resume. Your resume must provide your level of education and detailed work experience, including:
Employer Name
Dates of service (month & year)
Average number of hours worked per week
Essential duties of the job as related to the position you’re applying for
Education
Degree type
Date degree was awarded
Institution
Licensure/certification, if applicable
After submitting your application through our career center in ADP, your resume will be reviewed to ensure that your skills and experience meet the essential criteria for the role you have applied for.
The diversity of the communities we serve is reflected in our employees. Trillium Health Resources is an Equal Employment Opportunity (EEO) employer.
Trillium Health Resources is a drug-free workplace. Candidates are required to pass a drug test as a condition of employment.
#Innovation #Technology #Careers #NorthCarolina #BehavioralHealth","$77,884 /yr (est.)",201 to 500 Employees,Government,Insurance,Insurance Carriers,2015,$5 to $25 million (USD)
"Northrop Grumman
4.0",4.0,"Melbourne, FL",Engineer / Principal Engineer Electromechanical - Instrumentation and Data Systems,"Requisition ID: R10123335
Category: Engineering
Location: Melbourne, Florida, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman Aeronautics Systems has an opening for a Engineer Electromechanical / Principal Engineer Electromechanical to join our team of qualified, diverse individuals within our Test and Evaluation organization. This role is located in Melbourne, FL.
**This role may be filled at the Engineer Electromechanical OR Principal Engineer Electromechanical level based on qualifications below**
As an Instrumentation and Data Systems engineer, you will be responsible for the development, design and maintenance of complex instrumentation and data system solutions for laboratory, ground and flight test activities on the program. You will maintain Flight Test Instrumentation system configurations and coordinate test activity, maintenance and communicate instrumentation issues and status across teams. In addition, support planning and flight test readiness reviews; flight test planning working groups and coordination meetings; pre and posttest briefings. Also, define data system configurations, sensor selection, installation, checkout requirements and operational procedures and define air vehicle interface, integration and logistic requirements. Knowledge of telemetry, onboard recording, Data Acquisition Systems (Teletronics) and ground stations is key. You will also provide test crews, manufacturing and/or suppliers the guidance and direction required for operation, fabrication, modifications, assembly and checkout of Instrumentation systems and associated equipment. Experience in computer operating systems and application software (AutoCAD), as well as database development for measurand and test data is important. You will prepare system specifications, Request for Quotes (RFQ’s) and Statement of Work (SOW’s) that satisfy test and system requirements plus support test activities, anomaly resolution and process improvement initiatives. Strong leadership, communication and interpersonal skills are key.
Key Responsibilities:
Applies electrical, electronic and mechanical principles to components and systems, including assembly, analysis, and documentation of results
Construction of developmental assemblies, sub-assemblies and components
Quality testing
Supports and participates in the design, test, modification, fabrication and assembly of prototype electromechanical systems.
We offer flexible work arrangements, 9/80 work schedule with every other Friday off, phenomenal learning opportunities, exposure to a wide variety of projects and customers, and a very friendly team environment. We are looking for self-motivated, proactive, and goal-oriented people to help us grow our services and become even better at what we do.
Basic Qualifications (Engineer Electromechanical):
Must have a Bachelor’s of Science degree in a STEM discipline AND 2 years of related professional/military experience OR a Master’s of Science degree in a STEM discipline AND 0 years of related professional/military experience OR a STEM Ph.D. AND 0 years of related professional/military experience
Must have an active DoD Secret or higher clearance (with a background investigation completed within the last 6 years or currently enrolled into Continuous Evaluation)
Must have the ability to obtain and maintain Special Access Program (SAP) clearance prior to the commencement of employment
Basic Qualifications (Principal Engineer Electromechanical):
Must have a Bachelor’s of Science degree in a STEM discipline AND 5 years of related professional/military experience OR a Master’s of Science degree in a STEM discipline AND 3 years of related professional/military experience OR a STEM Ph.D. AND 0 years of related professional/military experience
Must have an active DoD Secret or higher clearance (with a background investigation completed within the last 6 years or currently enrolled into Continuous Evaluation)
Must have the ability to obtain and maintain Special Access Program (SAP) clearance prior to the commencement of employment
Preferred Qualifications:
Current SAP/PAR Clearance
Top Secret clearance
Master’s degree in a STEM discipline
Salary Range: $73,400 - $110,000
Salary Range 2: $90,400 - $135,600
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$91,700 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"WillScot | Mobile Mini
3.4",3.4,"Phoenix, AZ",Data Engineer III,"At WillScot Mobile Mini (NASDAQ WSC), our 4000+ people are at the heart of everything we do. In addition to providing industry-leading pay and benefits, we provide opportunities for development and upward mobility, while investing in the communities we serve.

We are the undisputed leader in providing innovative ﬂexible workspace and portable storage solutions, serving an incredible range of customers across all industries from 240+ locations across the United States, Canada, and Mexico.

Our values are our foundation. We’re constantly striving to diversify our teams to ensure we have the best and brightest talent. We’re deeply committed to creating an inclusive and equitable workplace where each person can contribute while being their authentic self. For more about WillScot Mobile Mini and who we are, click here.

Come build your future with us!

ABOUT THE JOB:
Data Engineer
(Phoenix, AZ)
Maintain, improve and build database solutions to support business operations and analytics. Work with business and Business Intelligence team to translate business requirements into data and analytics solutions and to determine data needs of multiple teams, systems and products. Optimize data pipeline performance and troubleshoot issues. Develop and optimize SQL-based solutions on cloud platforms such as Snowflake. Assemble large, complex data sets that meet functional and non-functional business requirements. Develop and drive standards and best practices on release management technologies, including database schema compares, code check-ins, and merges. Develop new frameworks for tracking and reporting data quality and improving testing efficiency. Manage and direct training on data requirements and system interfaces.
Minimum of Master's degree in Information Technology or closely related technical field and two years experience as Data Engineer, Systems Analyst, Sr. SAP HANA Developer or related position designing, developing and implementing business intelligence and analytical applications, including SAP BW/HANA and Cloud data warehousing solutions.
Please apply to Williams Scotsman, Inc. at https://careers.willscot-mobilemini.com/.
WHAT YOU'LL BE DOING:
EDUCATION AND QUALIFICATIONS:
Disclaimer: This posting describes the general nature and level of work performed and does not represent an exhaustive list of responsibilities, duties, or skills required. Collaboration and teamwork drive our success. Team members may be required to perform duties outside normal responsibilities from time to time as needed.

WillScot Mobile Mini provides equal employment opportunities to employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

WillScot Mobile Mini embraces diversity and is committed to equal opportunity in all aspects of employment, including recruiting, hiring, promotion, termination, leaves of absence, compensation, and training. We are focused on building teams that include a variety of backgrounds, lived experiences, and skills.

The more inclusive we are, the stronger we will be!","$110,951 /yr (est.)",1001 to 5000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Commercial Equipment Services,1955,$1 to $5 billion (USD)
BUSINESS VALUE INTELLIGENCE SERVICES INC,#N/A,"Albany, NY",IFS ERP Data Migration Engineer,"Position: IFS ERP Data Migration Engineer
Location: Albany, NY( day 1 onsite)
Job Type/Duration: Contract/Long term
Experience: 10+ Years
Job Description:
End-to-end understanding of IFS processes and 10+ years of experience in handling processes on IFS/ Equivalent tools.
Collaborating with cross-functional platform and system owners to ensure the overall integrity of the IFS landscape.
Define, explore, and support the implementation of enablers to evolve solution intent, working directly with Agile teams to implement them
Plan and develop the IFS Architectural Runway in support of new business Features and Capabilities
Work with Product and Solution Management to determine the capacity allocation for enablement work
Understanding industry best practice and engage with platform providers and vendors to align capabilities and influence standard product roadmaps
Mentoring and supporting development teams to take shared code responsibility ensuring the development model supports high speed and good quality deliverables with the ability
to build faster, build in parallel and release often.
Ability to design, configure & customize FSM Screens, Scripting, Have used IFS proprietary tools for report generation and metadata manipulation for changing business logic.
Well versed in IFS FSM development framework and packages; PLSQL, RDBMS Knowledge.
Job Type: Contract
Pay: $100,000.00 - $111,360.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
10 years
Schedule:
8 hour shift
Ability to commute/relocate:
Albany, NY 12202: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person","$105,680 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Stantec
3.9",3.9,"Seattle, WA",Data Center Electrical Engineer,"Data Center Electrical Engineer - ( 230003ST )
Description
The buildings that make up the landscape of our daily lives seem like permanent fixtures, fastened to a time and place. But what if that didn’t have to be true? What if our built environment — where we live, learn, play, and conduct business — carried us forward instead?
Our Buildings practice keeps people at its heart, recognizing that our shared journey forward is shaped by the meaningful and responsive places we design. From iconic designs to monumental groundbreakings, join us to bring transformational building solutions to life. Every day we apply our expertise, creativity, and passion to propel communities into the future—join us!
Your Opportunity
You will work with close guidance and supervision on tasks and smaller projects, and as a team member of a larger project under the guidance of a Project Manager/Senior Engineer. You will assist in evaluating, selecting, specifying, and engineering certain electrical power and lighting systems or products for projects verifying compliance with applicable codes and internal engineering standards / practices. You will perform a variety of tasks which may include Revit design, calculations, and field work.
Your Key Responsibilities
Conducts basic interpretations of drawings, codes, and other similar materials.
Performs Revit and AutoCAD design for the electrical discipline using knowledge of relevant software programs.
Works with architectural, interior, and other engineering disciplines in the coordination of the project under the direction of a senior engineer/ designer.
Performs field work such as field investigation, as built and construction site observations.
Performs basic calculations to analyze and design individual building electrical system components using company standard software and proprietary manufacturer software including power systems studies such as arc flash, short circuit, and coordination studies.
Assists with engineering duties on projects of various complexity including data collection and information gathering to support design decisions.
Performs other duties as assigned by the senior engineering staff.
Qualifications
Your Capabilities and Credentials
Prior experience in Commercial, Data Center and/or Science & Technology market sectors.
Understanding of Revit and AutoCAD, and the use of it as a drafting/design tool.
Ability to participate and collaborate in a project team setting and to engage in creative and critical thought.
Basic understanding of electrical engineering concepts and the ability to effectively communicate ideas to others.
Ability to interpret sketches, drawings, building program and other similar material.
Ability to take direction, follow process and accept feedback and suggestions from senior engineers/designers.
Requires proficiency of Microsoft Office Suite, Revit, AutoCAD, SKM; Prefer experience with AGI 32, Visual Lighting Software, Newforma.
Must have a valid driver's license and good driving record.
Education and Experience
Bachelor’s degree or equivalent in Electrical Engineering or related field. Minimum of 2 years of experience preferred.
Typical office environment working with computers and remaining sedentary for long periods of time. Field work may include exposure to the elements including inclement weather.
This description is not a comprehensive listing of activities, duties or responsibilities that may be required of the employee and other duties, responsibilities and activities may be assigned or may be changed at any time with or without notice.
Stantec is a place where the best and brightest come to build on each other’s talents, do exciting work, and make an impact on the world around us. Join us and redefine your personal best. #DesignYourPlace
Pay transparency laws require employers to provide the following information for positions that may be in the following jurisdiction(s):
Salary Range(s):
$79,400 - $115,200 (CA, CO, WA locations only)
The final agreed upon compensation is based on individual education, qualifications, experience, and work location. At Stantec certain roles are bonus eligible.
Benefits Summary: Regular full-time and part-time employees have access to medical, dental, and vision plans, a wellness program, health saving accounts, flexible spending accounts, 401(k) plan, employee stock purchase program, life and accidental death & dismemberment (AD&D) insurance, short-term/long-term disability plans, emergency travel benefits, tuition reimbursement, professional membership fee coverage and paid family leave. Regular full-time and part-time employees will receive ten paid holidays in each calendar year. In addition, employees will be eligible to accrue vacation between 10 and 20 days per year and eligible for paid sick leave (and if more generous, in accordance with state and local law).
Temporary/casual employees have access to 401(k) plans, employee stock purchase program, and paid leave, in accordance with state and local law.
Washington state employees are eligible to accrue 1 hour of paid sick leave for every 40 hours worked except for Seattle employees who accrue sick leave in accordance with the city’s paid sick leave law.
The benefits information listed above may not apply to union positions because benefits for such positions are governed by applicable collective bargaining agreements.
Primary Location : United States-Washington-Seattle
Work Locations :
Seattle WA
Organization : BC-2048 Buildings-US Northwest
Employee Status : Regular
Job Level : Individual Contributor
Travel : Yes, 10 % of the Time
Schedule : Full-time
Job Posting : Sep 19, 2023, 11:41:38 AM
Req ID: 230003ST
Stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. We prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. Stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. EEO including Disability/Protected Veterans","$95,405 /yr (est.)",10000+ Employees,Company - Public,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1954,$1 to $5 billion (USD)
"GenesisCare
2.8",2.8,"Fort Myers, FL",Senior BI Data Engineer,"At GenesisCare we want to hear from people who are as passionate as we are about innovation and working together to drive better life outcomes for patients around the world.
GenesisCare USA Services, LLC, Senior BI Data Engineer, Fort Myers FL
Work closely with stakeholders and IT development teams to build modern and highly scalable cloud data platform that enables data ingestion, storage, transformations, and preparation of massive datasets for data analytics and machine learning models
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Design and develop optimal data pipeline architecture and infrastructure for data movement and data orchestration aligned with trending data pipeline design patterns in the industry and best practices
Assemble large, complex data sets that meet functional/non-functional business requirements
Perform proof of concepts for innovation and to continuously improve and enhance the capabilities of the business intelligence platform in cloud and scale them out for production use
Contribute ongoing monitoring including cloud resource capacity management, performance monitoring, troubleshooting, and resolving technical issues
Collaborate with the business and technical teams to ensure active support and resolution of risk and incidents.
JOB REQUIREMENTS:
Must have a Bachelor's degree or foreign equivalent in Computer Science, Computer Engineering, Information Technology, or a related field, and 5 years of post-bachelor’s, progressive related work experience;
OR a Master's degree or foreign equivalent in Computer Science, Computer Engineering, Information Technology, or a related field, and 3 years of related work experience.
Of the required experience, must have 3 years of experience with the following: Utilizing SQL Azure platform and Microsoft business intelligence suite; Designing and developing data movement and orchestration pipelines using Azure Data Factory, Azure Data Lake Storage, Azure Blob Storage, and Azure SQL; Managing CI/CD build, release, deploy process with Git and Docker containers; Automating Azure resources using Azure CLI, ARM templates and SQL Server PowerShell; and Writing scripts in Python.
Work Schedule: 40 hours per week, M - F (9:00am - 5:00pm)
Telecommuting permitted 5 days a week
Employer will accept any suitable combination of education, training, or experience.
Qualified Applicants: Apply online by clicking the ‘apply for this job’ button at the top of the page
#LI-CS1
GenesisCare is an Equal Opportunity Employer.","$112,710 /yr (est.)",5001 to 10000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2005,Unknown / Non-Applicable
"West Bend Mutual Insurance Company
3.8",3.8,"Madison, WI",Senior Data Engineer,"Hiring Manager Summary
West Bend Mutual's Data practice is seeking an experienced senior engineer to join their team! The ideal candidate will have experience with cloud-native data architecture, as well as coaching and mentoring junior engineers. We are a fast growing, relationships-based company who values employee engagement and culture. Future work initiatives include data engineering for warehousing and dataset curation, exposing new predictive analytics capabilities, enhancing risk pricing and ratemaking capabilities, and driving our company culture to embrace data-driven decision making.
*West Bend Mutual has office locations in Madison, West Bend, & Appleton. Flexible Hybrid schedule determined by manager based on candidates preferences and experience*
Summary of Responsibilities
The Senior Data Engineer provides technical leadership to an agile engineering team. We are looking for a flexible technical leader who is motivated to design, develop and test extensible data solutions, while mentoring junior team members. Ideal candidates possess experience with cloud-native data tooling, including programming languages such as SQL and Python, integration platforms such as Azure Data Factory and Snowpark, and data storage technology such as Snowflake, Microsoft SQL Server, and Azure Storage. All candidates should have experience with databases, data warehouses, and data lake concepts. Candidates should consider themselves to be high-level specialists who excel at solving complex issues and problems and should be skilled at adapting to new solutions in an ever-changing technical landscape.
At West Bend Mutual, we value leadership, teamwork, collaboration and incremental improvement. The ideal candidate should enjoy collaborating as part of a larger team. They will provide leadership, coaching and mentoring as part of our ongoing improvement efforts and participate as a technical leader.

Preferred Experience and Skills
Eight or more years of experience delivering data solutions
Advanced proficiency with solution design concepts in cloud-native data architectures
Advanced proficiency with SQL, Microsoft SQL Server, and SQL Stored Procedures
Experience with data modeling, data warehouse, and data lakehouse concepts
Experience with Snowflake, Azure Storage, and/or Microsoft SQL Server
Experience with Python, SnowSQL, Snowpark, Azure Data Factory, Azure Databricks, and/or Matillion
Experience with DevOps or DataOps concepts; including release engineering & observability frameworks
Can effectively communicate, influence, and challenge IT peers, architects and management
Sees a solution through to its full delivery – facilitates and leads the team, not just their individual code
Shares knowledge, mentors junior team members, advocates best practices
Experience in Property & Casualty Insurance, or Financial Services industry, is a plus

EEO Statement
West Bend provides equal employment opportunities to all associates and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.",#N/A,1001 to 5000 Employees,Company - Private,Insurance,Insurance Carriers,1894,$1 to $5 billion (USD)
"Northrop Grumman
4.0",4.0,United States,Principal Engineer Data (23-467),"Requisition ID: R10124868
Category: Research and Sciences
Location: Schriever AFB, Colorado, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Days (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman Space Systems – Launch and Missile Defense Systems has an exciting career opportunity for a Principal Engineer Data – X-Lab Data Engineer (23-467) to join our team of qualified, diverse individuals. This position will be out of Schriever Space Force Base, Colorado Springs, CO.
Position Overview:
This position is located full-time at the Missile Defense Integration and Operations Center (MDIOC) in Schriever, SFB, CO, and is not a remote work position. Will focus on the development of database tools and will contribute to other ongoing X-Lab and external stakeholder projects as needed. The team will extract value from experimental C2BMC systems by cleaning, aggregating, and visualizing the generated data, adapting to system changes, and presenting customer-quality products. The Data Engineer will apply these results to identify analysis opportunities and work to enhance C2BMC for future operations. Be comfortable with rapidly changing requirements, design challenges requiring novel solutions, fast-paced activities, and tight deadlines. The position is responsible for full lifecycle support for database development projects.
Essential Functions:
Database Implementation - Define schema and table structure, data relationships
Build ETL pipelines and implement data automation
Integrate DBMS tools Database Management: - Understand and adapt pipelines to data format changes - Integrate new data to the database and clearly explain relationships - Support customer requests for data
Experience contributing to an integrated team environment with other systems, software, and specialty engineers to develop solutions that include a background in all aspects of the analysis life cycle.
Experience designing a database, ingesting and cleaning data, automating database load, and adapting to data changes.
Demonstrated ability to interpret high-level customer needs and deliver quality data projects.
Demonstrated ability to communicate effectively and present technical approaches and findings.
Familiarity with standard office productivity tools such as the MS Office suite.
Experience with PostgreSQL
Basic Qualifications:
Please note your updated security clearance and IAT/relevant certifications on your resume, if applicable.
An active Secret clearance is required to start with the ability to obtain TS/SCI clearance.
5 years with a Bachelor’s degree in a related field; 9 years experience in lieu of a degree.
Experience in working on IRAD-type projects.
Experience with DBeaver and pgAdmin
Experience with Python, Pandas library, MATLAB, Excel, Tableau
Experience with Gitlab and Gitlab Runner
Operating systems experience with Windows & Unix/Linux.
Knowledge of physics & mechanics of missile flight and satellite orbits.
Theory and application of the Missile Defense System and Space domain.
Theory and application of Command and Control Systems.
Theory and application of track correlation algorithms.
Experience with Agile development techniques and tools.
Integration practices and methods.
Preferred Qualifications:
An active TS/SCI clearance is highly desired
Some travel may be required
Occasional off-hours work may be required
What We Can Offer You:
Northrop Grumman provides a comprehensive benefits package and a work environment that encourages your growth and supports the mutual success of our people and our company. Northrop Grumman benefits give you the flexibility and control to choose the benefits that make the most sense for you and your family. Your benefits will include the following:
Health Plan
Savings Plan
Paid Time Off
Education Assistance
Training and Development
Flexible Work Arrangements
https://benefits.northropgrumman.com/us/en2/BenefitsOverview/Pages/default.aspx
NGSpace
COSpace
NGFeaturedJobs
C2BMC
Additional Northrop Grumman Information:
Salary Range: $95,100 - $142,700
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$118,900 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
Neo tech solutions,#N/A,"Lewisville, TX",Tech Led/Lead Data Engineer,"Tech Lead/Lead Data Engineer
Lewisville, TX
Onsite
Job Functions / Responsibilities
Build and document automated data pipelines from a wide range of data sources with an emphasis on automation and scale
Develop highly available applications and APIs to support near-real-time integrations using an AWS-based technology stack
Ensure product and technical features are delivered to spec and on-time in a DevOps fashion
Contribute to overall architecture, framework, and design patterns to store and process high data volumes
Develop solutions to measure, improve, and monitor data quality based on business requirements
Design and implement reporting and analytics feature in collaboration with product owners, reporting analysts / data analysts, and business partners within an Agile / Scrum methodology
Proactively support product health by building solutions that are automated, scalable, and sustainable – be relentlessly focused on minimizing defects and technical debt
Provide post-implementation production support for data pipelines
Business Analyst experience good communication skills and has soft skills to lead the team and be a link between architects, developers, and project manager.
Requires 10% travel
Qualifications
Bachelors' degree in Computer Science, Informatics, or a related field required
Masters’ degree in Computer Science preferred
10+ years of experience in a data engineering role
Hands-on experience with ETL tools and techniques (Desirable)
Basic proficiency with a dialect of ANSI SQL, APIs, and Python
Knowledge of and experience with RDBMS platforms, such as MS SQL Server, MySQL, NoSQL, Postgres
Job Type: Full-time
Pay: $135,000.00 - $145,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
11+ years
Schedule:
8 hour shift
Ability to commute/relocate:
Lewisville, TX 75022: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person","$140,000 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Techstra Solutions
4.4",4.4,"Pittsburgh, PA",Snowflake Data Engineer,"Techstra is seeking an experienced Snowflake Data Engineer As a skilled analyst, you will provide data analysis leadership as well as conduct data analysis across different projects with diverse scope, sophisticated business and technical requirements in a multi-platform and highly coordinated data environment. This role is analysis and design centric; crafting and detailing data solutions/models, which are then handed to developers, engineers, and DBAs to implement.
From the day you join, you will hit the ground running surrounded by amazing people. Here is a look at some of the expectations and responsibilities for this position:

Responsibilities:
Lead data architecture and modeling efforts within Snowflake, AWS, and related cloud data products, including the design of data structures and the identification of business transformation logic
Analyzing and translating business requirements into conceptual and detailed logical data models
Creating logical data models based on existing applications and databases
Working with business architects, data architects, and data stewards to capture business requirements in a Logical Data Model
Expert level analysis skills in the form of research, gap analysis, data mining, and data profiling
Solid understanding of data lineage. Ability to breakdown and detail the flow of data from origination to consumption
Proven track record of solving real world problems using a design-oriented modeling approach in large data warehouses, data marts, and analytics/reporting platforms
Understanding of different database platforms (e.g. Oracle, Snowflake, Hadoop, Microsoft SQL Server) usages (OLTP Recordkeeping, ODS, MDM, Warehousing, and Data Lakes)
Understanding of modeling strategies (dimensional, relational, unstructured)
Robust SQL experience, used to design new platforms on cloud technologies/architecture including Snowflake, AWS, etc.
Proficient with ERD/Data Modeling tools (e.g. SAP Power Designer or Erwin)
Experience carrying out projects in an Agile environment
Accepts uncertainty and can combine various sources of information including personal data experimentation, research, and dialogues to formulate answers
Values pace over perfection and can show incremental progress of analysis and research through tangible artifacts
Experience with cloud native data warehousing and data lake solutions using Snowflake

Requirements:
Bachelor’s Degree or equivalent in a technology related field (e.g. Computer Science, Engineering, etc.) with a focus on data analysis, data structures, or data modeling
Strong experience in Snowflake, AWS and related cloud data products
Strong experience in Python
Working knowledge of IICS, dbt ETL/ELT technologies
Advanced SQL Skills
Outstanding interpersonal skills with experience collaborating and influencing across all levels of the organization including written, verbal, and technology illustrations
Perform autonomously on tasks but are willing and able to share knowledge with coworkers and partners
Go-getter, self-sufficient, and willing to exhaust all research avenues before seeking help or discontinuing the search for answers
Familiar with the financial industry

Location:
This position is located in Pittsburgh, Pennsylvania.

At Techstra Solutions, we help top companies and brands achieve the business value of Digital and Talent Transformation. We believe there are three components in successful business transformation: Business Strategy, Technology and Talent. It is the coming together of these three disciplines that enable companies to take full advantage of opportunities. It differentiates us. Our approach is holistic and all encompassing. We consider the full picture as we guide our clients on this journey.

We are experts in transformation, business strategy, technology, innovation, and human capital management. We deliver our expertise through client consulting, innovative staffing solutions and software development. From strategy through implementation, we are dedicated to bringing our clients world-class business and talent solutions that fit strategic requirements and most importantly, deliver results.
Equal Employment Opportunity Statement
Techstra Solutions maintains a strong policy of equal opportunity in employment. It is our objective to recruit, hire, and retain the most qualified individuals without regard to race, color, creed, religion, gender, national origin, age, pregnancy, marital status, sexual orientation, gender identity or expression, disability, veteran status, or any other characteristic or status protected by applicable federal, state, or local law. Our equal employment philosophy applies to all aspects of employment, including recruitment, compensation, benefits, training, promotions, transfers, job benefits, and terminations.
kg1J03TNqx","$89,124 /yr (est.)",1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Varo Bank
3.0",3.0,"Salt Lake City, UT","Principal Engineer, Data Engineering","Varo is an entirely new kind of bank. All digital, mission-driven, FDIC insured and designed for the way our customers live their lives. A bank for all of us.

We’re looking to hire a Principal Engineer to lead and develop our data platform capabilities. In this role you will act as the lead individual contributor, while also managing our onshore and offshore engineering talent. The Data Engineering team collaborates closely with product, data science and machine learning teams to design, build, and scale high leverage datasets that enable analytics, and experimentation. As a Data Engineering leader, you will establish and drive a vision for data architecture and data quality across multiple company verticals. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other, and want to solve interesting problems to propel the company’s growth, apply now!
What you'll be doing
Develop and execute a roadmap to build and optimize foundational datasets to ensure delivery of high-quality ergonomic data across multiple company verticals
Develop and execute a roadmap to establish data quality as a given, at scale
Oversee the design, development, and maintenance of data pipelines and ETL processes to ensure the efficient and reliable movement of data from various sources to the data warehouse or other target systems
Partner with data platform teams to identify opportunities to improve infrastructure and influence their roadmaps accordingly
Inform architectural decisions, establish best practices, develop lean scalable processes, and contribute to the overall direction of the data organization
Establish a collaborative culture that thrives on innovation and impact
You'll bring the following required experiences and skills
8+ years experience in data engineering or data architecture
8+ years of experience in developing robust data models based off of structured and unstructured sources at massive scale
2+ years experience as a manager, who successfully managed multiple individual contributors
Extensive experience with big data platforms (Apache Spark, Presto, Amazon Glue, Amazon EMR), data warehouses (Amazon Redshift, Snowflake), container management systems (Kubernetes, Amazon ECS), modern data workflows (Apache Airflow), and data visualization platforms (Tableau, Looker)
Bonus – Prior experience with AI/ML tools (Amazon Sagemaker, Azure ML Studio, Tecton) is a plus, as you will be partnering closely with the data science and ML engineering teams
Bonus – Prior experience with streaming data ingestion and analytics (Amazon Kinesis, Apache Kafka)
An ability to explain complex concepts in easy-to-understand ways and navigate environments where problems are not well-defined (and evolve quickly)
Experience leveraging your excellent communication skills to thrive in areas where problems are not well-defined and evolve quickly
Experience proactively identifying opportunities to improve ETL and dashboard performance and cost
Excellent cross-functional communication skills
Ability to thrive in a fast-paced environment
We recognize not everyone will have all of these requirements. If you meet most of the criteria above and you’re excited about the opportunity and willing to learn, we’d love to hear from you!

About Varo
Varo launched in 2017 with the vision to bring the best of fintech into the regulated banking system. We’re a new kind of bank – all-digital, mission-driven, FDIC-insured, and designed around the modern American consumer.

As the first consumer fintech to be granted a national bank charter in 2020, we make financial inclusion and opportunity for all a reality by empowering everyone with the products, insights, and support they need to get ahead. Through our core product offerings and suite of customer-first features, we aim to address a broad range of consumer needs while profitably serving underserved communities that have been historically excluded from the traditional financial system.

We are growing quickly in our hub locations of San Francisco, Salt Lake City, and Charlotte along with colleagues located across the country. We have been recognized among Fast Company’s Most Innovative Companies, Forbes’ Fintech 50, and earned the No. 7 spot on Inc. 5000’s list of fastest-growing companies across the country.

Varo. A bank for all of us.

Our Core Values
Customers First
Take Ownership
Respect
Stay Curious
Make it Better

Learn more about Varo by following us:
Facebook - https://www.facebook.com/varomoney
Instagram - www.instagram.com/varobank
LinkedIn - https://www.linkedin.com/company/varobank
Twitter - https://twitter.com/varobank
Engineering Blog - https://medium.com/engineering-varo
SoundCloud - https://soundcloud.com/varobank

Varo is an equal opportunity employer. Varo embraces diversity and we are committed to building teams that represent a variety of backgrounds, perspectives, and skills. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

Beware of fraudulent job postings!
Varo will never ask for payment to process documents, refer you to a third party to process applications or visas, or ask you to pay costs. Never send money to anyone suggesting they can provide work with Varo. If you suspect you have received a phony offer, please e-mail careers@varomoney.com with the pertinent information and contact information.

CCPA Notice at Collection for California Employees and Applicants:
https://varomoney.box.com/s/q7eockvma9nd2b0utwryruh4ze6gf8eg","$130,847 /yr (est.)",501 to 1000 Employees,Company - Private,Financial Services,Banking & Lending,2015,Unknown / Non-Applicable
"Northrop Grumman
4.0",4.0,"Roy, UT",Sentinel (GBSD) Systems Engineer- Wing Data Simulator 10361 & 10362,"Requisition ID: R10119808
Category: Engineering
Location: Roy, Utah, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 2
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Embark on a career putting innovative, reliable, and agile products and ideas into orbit, and beyond. Northrop Grumman has opportunities waiting for you that play a vital role in human space exploration, national defense, and scientific discovery, supporting multiple programs across the universe. With us, you’ll discover a culture of curiosity and collaboration that will have you Defining Possible from the day you start. Our space systems connect and protect millions of people on earth every day, now and for the future. Explore your future and launch your career today.

Northrop Grumman Space Systems is seeking to hire a Systems Engineer- Wing Data Simulator to its team of diverse and qualified individuals. These positions will be located in Roy, UT and will support the Sentinel (GBSD) program. Learn more about the Sentinel program here. Northrop Grumman supports the Air Force’s sustainment, development, production and deployment of hardware and system modifications for Intercontinental Ballistic Missile (ICBM) Ground and Airborne Launch Control Systems, Launch Facilities and associated infrastructure.
What you will get to do:
The Wing Data Simulator project is developing a complex Software/Hardware modeling and simulation capability that will be used to test the GBSD weapon system. This position will perform systems engineering in a dynamic, fast-moving environment using the Agile (Scrum) framework. The WDS project is in the early stages of development, so this position will immediately be contributing to the early stages of the systems engineering V: use case definition, architecture/design, and requirements decomposition. As the project matures, this position will have exposure to the entire development lifecycle, including integration, test, and deployment. As a systems engineer on WDS, this position will work closely with software development scrum teams to define future development requirements and architecture. Experience with software projects is useful but not required. Major tools used by the team include the Atlassian suite, DOORS, and Cameo. The Sentinel program, and WDS project specifically, heavily leverages MBSE concepts and tools - Maintain design documentation and follow configuration management requirements.
As a full-time employee of Northrop Grumman Space Systems, you are eligible for our robust benefits package including:
Medical, Dental & Vision coverage
401k
Educational Assistance
Life Insurance
Employee Assistance Programs & Work/Life Solutions
Paid Time Off
Health & Wellness Resources
Employee Discounts
https://benefits.northropgrumman.com/us/en2/BenefitsOverview/Pages/default.aspx
This positions standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.
This role may offer a competitive relocation assistance package.
#GBSDsystems
BASIC QUALIFICATIONS:
Systems Engineer: bachelor’s degree with at least 2 years of related systems engineering experience, 0 years with a master’s degree.
Active Secret clearance investigated within the last 6 years with the ability to obtain special access.
Experience with Model-Based Systems Engineering (MBSE)
Experience with requirements development and verification
PREFERRED QUALIFICATIONS:
Modeling experience using Cameo
Experience with Atlassian tool suite
Experience with requirements management using DOORS
Experience with Agile development
Experience with Scrum methodology
Experience with DevOps
One or more of SysML, DoDAF
Salary Range: $73,400 - $110,000
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$91,700 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"The Hartford
3.9",3.9,"Hartford, CT",Senior Data Engineer,"You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.
The Hartford is seeking a Sr. Data Engineer within Personal Lines Data & Analytics to design, develop, and implement modern and sustainable data assets to fuel machine learning and artificial intelligence solutions across a wide range of strategic initiatives.
Within Personal Lines Data & Analytics the Performance Analytics team is looking for a Sr. Data Engineer, you will participate in the entire software development lifecycle process in support of continuous data delivery, while growing your knowledge of emerging technologies. We use the latest data technologies, software engineering practices, MLOPs, Agile delivery frameworks, and are passionate about building well-architected and innovative solutions that drive business value. This cutting edge and forward focused organization presents the opportunity for collaboration, self-organization within the team, and visibility as we focus on continuous business data delivery.
Responsibilities:
Design and develop high quality, scalable software modules for next generation analytics solution suite
Prototype high impact innovations, catering to changing business needs, by leveraging new technologies
Consult with cross-functional stakeholders in the analysis of short and long-range business requirements and recommend innovations which anticipate the future impact of changing business needs
Formulates logical statements of business problems and devises, tests and implements efficient, cost-effective application program solutions
Identify and validate internal and external data sources for availability and quality. Work with SMEs to describe and understand data lineage and suitability for a use case
Create data assets and build data pipelines that align to modern software development principles for further analytical consumption. Perform data analysis to ensure quality of data assets.
Develop code that enables real-time modeling solutions to be ingested into front-end systems
Produce code artifacts and documentation using GitHub for reproducible results and hand-off to other data science teams
Qualifications:
5+ years of relevant experience recommended
Bachelor’s degree in Computer Science, Engineering, IT, Management Information Systems, or a related discipline
Proficiency in Python and SQL
Proficiency in ingesting data from a variety of structures including relational databases, Hadoop/Spark, cloud data sources, XML, JSON
Proficiency in ETL concerning metadata management and data validation
Proficiency in Unix and Git
Proficiency in Automation tools (Autosys, Cron, Airflow, etc.)
Experience with AWS Services (i.e. S3, EMR, etc) a plus
Experience with Cloud data warehouses, automation, and data pipelines (i.e. Snowflake, Redshift) a plus
Able to communicate effectively with both technical and non-technical teams
Able to translate complex technical topics into business solutions and strategies as well as turn business requirements into a technical solution
Experience with leading project execution and driving change to core business processes through the innovative use of quantitative techniques
Additional Details:
Must be authorized to work in the US without company sponsorship.
The Hartford is proud to offer a hybrid work location model that is designed to support flexibility.
This partial remote position requires in office presence Tuesday/Wednesday with remote work flexibility Monday, Thursday, and Friday.
Office Locations include NC: Charlotte; CT: Hartford; TX: Frisco, San Antonio; GA: Alpharetta; IL: Chicago, AZ: Scottsdale; FL: Lake Mary
Compensation
The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
$110,560 - $165,840
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",#N/A,10000+ Employees,Company - Public,Insurance,Insurance Carriers,1810,$10+ billion (USD)
"Computacenter
3.9",3.9,United States,"Senior Rack Integration Engineer, Data Center","Senior Rack Integration Engineer, Data Center
Location
Telecommuter, US

Salary Range
$130K - $145K USD

Position Overview
The Senior Rack Integration Engineer, Data Center is responsible for providing high level consultancy within the specialist area to peers and customers. Post-sales engineering and consulting design and implementation services related to hardware and software technologies; and providing presales support by assisting the development, review and validation of customer solutions.

Duties/Responsibilities
Manage and implement projects relevant to specialist area
Manages, develops and coaches team of staff and implements performance management solutions where required
Develop and motivate team to help ensure the delivery of function and business targets.
Assess situations, issues and opportunities and escalate when appropriate.
Acting as a point of escalation on complex issues and providing appropriate support to other team members
Maintain confidentiality in all business related matters.
Liaise with colleagues to ensure best practice and continual improvement in delivery of service to the business.
Establishes productive relationships and networks at Senior Management level to build and maintain customer relationships
Responsible for managing budget/ P&L to maintain spend in line with budgetary limitations
Responsible for the adoption of CC best practice and service offerings to ensure consistency of service.
Makes decisions which impact on the success of assigned projects i.e. results, deadlines and budget.
Contribute to business strategy in order to help grow and develop the business
Develop effective working relationships through influencing and advising Safety and security of facility.
Embrace and support Computacenter’s mission and core values.

Education & Experience Required
Bachelor’s degree or relevant technical experience within a large organization or IT Industry
Relevant qualifications or accreditations in one or more technology area(s)
Legally eligible to work in the United States.

Skills & Competencies
Taking ownership of queries and managing through to a prompt resolution
Demonstrate a creative and analytical approach to problem solving
Performing as a credible capable professional and an expert in the relevant field.
Broad knowledge of the business benefits that technical solutions can provide
Experience in dealing with and influencing multi -tier management
Good working knowledge of relevant functional systems
Experience of developing best practice policies and procedures for functional area
Strong written and verbal communication skills.
Excellent interpersonal and communication skills with the ability to present in a group setting.
Prefer a strong working knowledge of computer system applications (e.g.: Windows, Microsoft Office, OSX, Salesforce).

WHY COMPUTACENTER?

Computacenter is a leading independent technology partner, trusted by large corporate and public sector organizations. We help our customers to source, transform and manage their IT infrastructure to deliver digital transformation, enabling users and their business. Computacenter is a public company quoted on the London FTSE 250 (CCC.L) and employs over 15,000 people worldwide. In US we support some of the country’s best-known businesses with regional headquarters in both San Francisco & New York City and an Integration Center in Silicon Valley. www.computacenter.com/us

WE OFFER A GREAT BENEFITS PACKAGE!
There's so much more to enjoy about being at Computacenter than just having a rewarding career. In addition to offering competitive compensation plans and long-term career opportunities, Computacenter provides an attractive mix of benefit plans to contribute to its employees' good health, future financial security and peace of mind.

You must be authorized to work in the United States.

Computacenter United States Inc. is an Equal Opportunity Employer with a strong commitment to supporting and retaining a diverse and talented workforce.

No AGENCIES, please. We are not obligated to pay any fees for any individuals we decide to hire.","$137,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1981,$1 to $5 billion (USD)
"Amazon Data Services, Inc.
3.7",3.7,"Umatilla, OR",Data Center Controls Engineer,"Basic Qualifications

1. B.S. in Electrical, Mechanical or other related engineering degrees as well as 5 years Controls related experience; or Associates degree and 7 years of Controls related experience; or High School diploma with 10 years of Controls related experience.
2. Experience with industrial controls in critical environment (data center, pharmaceutical, manufacturing, oil & gas, petrochemical, laboratory, power, water etc.).

AWS Data centers have multiple components such as generators, uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc. All these components have local control systems that interact with each other via open and/or proprietary communications protocols. The building management system (BMS) is the primary method of control of all mechanical systems within a data center. The electrical power monitoring system (EPMS) is the primary method of monitoring all electrical systems within a data center.

As part of the global controls team, you will work with highly motivated experts and innovators in the data center industry. You will be responsible for innovating, deploying, optimizing, and maintaining the BMS and EPMS. Using Amazon leadership principles, you will develop new processes and standards while innovating in the controls space.

As a Controls Engineer you will:
Troubleshoot and perform Root Cause Analysis (RCA) or Corrective Action (CA) for Control Systems for AWS data centers.
Possess, understand and apply controls fundamental concepts, practices and procedures to manage scope of Building Management System (BMS) and Electrical Power Monitoring System (EPMS) in operational AWS Data Centers.
Train and assist internal customers and stakeholders with the creation, design, configuration, validation, installation, commissioning and operation of BMS and EPMS systems.
Provide technical assistance and support to internal customers during life cycle of the data center.
Complete and implement assigned work within agreed upon scope, schedule and budget to a high level of quality and safety.
Review controls sequence of operation and provide feedback for construction of AWS data centers.
Schedule and supervise Quarterly maintenances for BMS and EPMS.
Provide vendor management.
Participate in AWS global on-call schedule to provide immediate BMS and EPMS
Technical support to in-service data centers.
Attend project related meetings, coordinate with project leaders and regularly report status to Controls Management.
Review and provide feedback on mechanical, electrical, and plumbing (MEP) drawings.
Develop controls bill of material (BOM).
Develop and modify controls logic programming.
Develop and modify graphical user interface.
Grow in technical ability by learning a multitude of different automation platforms.
Develop scope of work for site improvement projects.
Manage and work under tight project timelines.
Manage multiple stakeholder deliverables, requirements and navigate difficult situations.
Financially manage BMS and EPMS service contracts.
Frequently visit (locally) assigned in-operation data centers to supervise vendor’s work to ensure compliance with the design, sequence of operations (SOO) and applicable local codes.
We are open to hiring candidates to work out of one of the following locations:

Umatilla, OR, USA

Preferred Qualifications

Master’s Degree (MS) with five years of relevant controls or data center mechanical/electrical work experience.
Knowledge computer networking and HVAC and/or electrical power distribution systems.
Proven track record for cultivating strong relationships with internal stakeholders, vendors, or customers
Excellent communication skills, teamwork, organizational and problem-solving skills.
Experience with automation controls in data centers or other critical facilities.
TCP/IP, BACnet and/or MODBUS communication protocol experience.
Why AWS?
About AWS
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud
platform. We pioneered cloud computing and never stopped innovating — that’s why customers
from the most successful startups to Global 500 companies trust our robust suite of products and
services to power their businesses.

Inclusive Team Culture
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster
a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning
experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender
diversity) conferences, inspire us to never stop embracing our uniqueness.

Work/Life Balance
We value work-life harmony. Achieving success at work should never come at the expense of
sacrifices at home, which is why flexible work hours and arrangements are part of our culture.
When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the
cloud.

Mentorship & Career Growth
We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.
That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing
resources here to help you develop into a better-rounded professional.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","$99,679 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Texas A&M AgriLife
3.8",3.8,"Houston, TX",Sr. Geospatial Data Engineer,"Job Title
Sr. Geospatial Data Engineer
Agency
Texas A&M Agrilife Extension Service
Department
Disaster Resilience & Recovery
Proposed Minimum Salary
Commensurate
Job Location
Houston, Texas
Job Type
Staff
Job Description
WHAT WE DO
Are you driven to develop data products that have tangible, positive impacts on community life and well-being? Motivated to build data products for communities and decision makers across the nation? Excited about engaging users, government, and industry to improve visualizations and applications?
For more than a decade, the planning team at TCWP (Texas Community Watershed Partners) has used interactive scenario planning technologies to advance data-driven, collaborative, and holistic approaches to community planning. These tools are designed for ordinary citizens, elected officials, and decision makers to engage in ‘what-if’ analysis of future growth, development, and hazards. An incredible array of data products is used to support these tools and sustain our organization’s mission of community outreach, education, and planning.
As a senior geospatial data engineer with TCWP, you will collaborate with a cross-functional team to build a next generation planning platform that raises people’s voices and gives them more influence about the communities they live in. As a founding member of the product team, you will have the opportunity to guide our product, culture, and overall business of our team. We look forward to partnering your passion for data with empowering community decision-making.
YOUR ROLE
We are looking for a tenacious problem solver who loves a challenge and is excited by the pace of startup located within a university setting. Candidate should be a highly motivated, extremely organized, and solutions-oriented candidate, with strong spatial, conceptual, analytical, and reasoning abilities. As an early team member, candidates should be adaptable to the growth of the team and work well in virtual teams.
To excel in this role, you will possess a solid foundation in geospatial data technologies, data visualization, and implementing scalable data management solutions. Your designs and working tools will gather, integrate, and process data from diverse sources. These data products form the backbone of our applications, and you will ensure that our data products are accurate, secure, and accessible to our end-users. Your ability to collaborate and distill technical concepts are an essential part of this role, and you will be supported with both in-house and contract support.
Essential Duties and Responsibilities
Geospatial Data Management
Designs and leads implementation of a geospatial data strategy for architecture, services, and maintenance of geospatial data pertaining to products and projects.
Defines and enforces data standards, best practices, and quality assurance processes to maintain high-quality geospatial information.
Leads the integration of planning, hazard, and natural resource related geospatial data for inclusion in the product and project data libraries.
Manages, queries, and manipulates geospatial data within databases.
Creates and maintains detailed documentation for data processes and sources.
Product Development Team Member
Is an early team member, with the opportunity to guide our product, our culture, and the overall business.
Uses passion for technology and solving users’ problems to drive product outcomes.
Is a member of the product team, collaboratively develop overall product vision, strategy, and roadmap.
Engages with end users and external stakeholders to bring forth product vision, customer insights and feedback.
Works as a member of the product team to apply insights to defining features and user stories in support of development activities.
Communicates product related data strategies and governance issues to internal and external product stakeholders.
Enhances product outcomes through efficient utilization of data resources.
Documents requirements for data compilation and storage for team members and external users.
Project and Operational Management
Drives and plans multiple projects and contracts simultaneously and communicate status to partners and stakeholders.
Leads brainstorming sessions with key stakeholders to learn about client needs and identify product solutions.
Manages expectations across stakeholders, communicates prioritization and ROI, and surfaces any issues promptly.
Develops contractor work plans as part of an overall strategic project plan; develops acceptance criteria documentation for deliverables; and receives and reviews deliverables from contractors.
Applies best practices in vendor selection, contract negotiation, and project lifecycle.
Directs and coordinates activities of project personnel to ensure project progresses on schedule and within prescribed budget.
Additional Responsibilities
Performs other duties as assigned.
Supervises assigned staff.
Qualifications
Required Education and Experience
Bachelors degree or equivalent combination of education and experience.
Nine years of related experience in geospatial data management.
Required knowledge, skills, and abilities
Strong problem-solving skills and attention to detail.
Strong understanding of geospatial data management principles, including data quality, metadata, and data governance.
Proficiency in using geospatial software and tools, both proprietary (ESRI ArcGIS) and open source (QGIS, GRASS GIS).
Experience with geospatial databases (e.g., PostGIS) and SQL.
Proficiency in python, arcpy, and other development languages.
Familiarity with cloud platforms (e.g., Azure) and their geospatial services.
Ability to work collaboratively in cross-functional teams and communicate effectively with team members and external stakeholders.
Additional desired skills
Core areas of expertise in one or more of the listed fields: Digital Transformation, SaaS, Low-Code/No-Code solutions, Emerging Technologies, Data analytics and Visualization, Information Assurance, Cloud Solutions, and Business Process Re-Engineering.
Machine Learning, Large Language Models, and/or Natural Language Processing methodologies.
Artificial intelligence and ChatGPT API(s) and use cases.
Continuous Integration (CI) and/or Continuous Delivery (CD) approach
Various programming languages: SQL, Python, Java
Other requirements
Occasional work-related overnight travel.
Salary
Anticipated hiring range is $110,000 – $130,000. Salary is commensurate with experience, education, skills, and responsibilities.
This is a grant funded position continued employment contingent on available grant funding.
Note to all Candidates:
Please submit a cover letter and resume with your application.
All positions are security-sensitive. Applicants are subject to a criminal history investigation, and employment is contingent upon the institution’s verification of credentials and/or other information required by the institution’s procedures, including the completion of the criminal history check.
Equal Opportunity/Affirmative Action/Veterans/Disability Employer.","$120,000 /yr (est.)",Unknown,Government,Education,Colleges & Universities,#N/A,Unknown / Non-Applicable
"Vortalsoft
3.4",3.4,"Richards, TX",Data Center Engineer,"We are looking for 5 self-motivated, dedicated individuals who are ready to put their technical skills to work in a fast-paced, customer-focused environment. Utilizing their technical knowledge, they will have the responsibility of responding to customer calls in a timely and efficient manner to troubleshoot, analyze and diagnose servers in a critical environment. They will provide problem resolution or refer more complex issues to a Sr. Support Engineer.
Responsibilities
Analyzes, diagnoses, and troubleshoots hardware/server issues with focus on responsiveness; provides issue resolution
Maintains inventory and documentation of activity
Creates own service tickets, updates, and closes
Communicates before and after repair work windows via ticket and email to client
Break/Fix
Qualifications
Previous experience working on on HPE, DELL, Oracle (SUN), or Lenovo Servers
Strong problem solving and self-management skills with attention to detail
Ability to prioritize tasks and effectively communicate verbally and in writing’ experience servicing hardware as specified or utilized in customer environment
Familiarity with ticket-tracking software (ServiceNow preferred)
Job Type: Full-time
Salary: $60,000.00 - $65,000.00 per year
Benefits:
Health insurance
Paid time off
Schedule:
8 hour shift
Supplemental pay types:
Bonus opportunities
Ability to commute/relocate:
Richards, TX 77873: Reliably commute or planning to relocate before starting work (Required)
Experience:
Computer networking: 1 year (Preferred)
LAN: 1 year (Preferred)
Security clearance:
Confidential (Preferred)
Work Location: In person","$62,500 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,#N/A,$5 to $25 million (USD)
"Intuites LLC
4.5",4.5,"Cupertino, CA",AIML Data Infrastructure- Data Virtualization Infrastructure Engineer,"Position Title* Software Engineer IV (AIML-Data Infrastructure-Data Virtualization Infrastructure Engineer)-REMOTE
Job Order Type * Contract
W2 Position

Position Responsibilities
Role: AIML- Data Infrastructure- Data Virtualization Infrastructure Engineer
Location: Cupertino, CA (REMOTE)

Allowed Work Authorization US Citizen, Green card Holder
Note: Local profiles only!

Job Summary:
AIML Data Infrastructure provides the foundation and core technologies all higher level abstractions run on. We strive to provide the best experience to our stakeholders. Our objective is to provide our engineers and data scientists a highly stable, reliable and performant platform to perform both analytics and data engineering activities on. Our goal is simple, provide a world class infrastructure to enable our engineers and data scientists to do their best work.

Should be passionate about automation, optimizations and tuning. Be part of the Data Infrastructure journey.

Key Qualifications:
Passionate about Data Compute and Storage Technologies (Object Storage, Caching, Optimization)
Experience configuring and troubleshooting Spark jobs when interfacing with our storage infrastructure
Experience optimizing, tuning and automating a large distributed compute environment
Experience in configuration management (Spinnaker, Helm, Terraform, Crossplanes, Puppet or similar)
Experience with alerting, monitoring and remediation automation in a large scale environment
Fluent in at least one scripting or systems programming language (Python, Java, Go, etc.)
Interest or knowledge in using public or private Kubernetes frameworks for scaling data and services infrastructure

Job Description:
You will be responsible for the data abstraction layer of our storage platform used for analytics and machine learning teams. To run our environment efficiently, we drive for proper monitoring, alerting and automation. The team’s goal is to ensure the reliability and performance at the highest level.

As a member of the AIML Data Virtualization Infrastructure Team:
You will manage one of the largest ML infrastructure supporting hundreds of millions of Apple customers.
You will diagnose, fix, improve, and automate complex issues across the entire stack to ensure maximum uptime and performance.
You will take part in designing and building out our next generation ML Data Platform and push our services to the next level.
You will advise other teams on proper integration of our platform.
You will manage the core infrastructure which powers all Machine Learning, ETL, Analytics, and Privacy Efforts within AIML Education.
BS, MS, or PhD degree in Computer Science or equivalent and 5+ years experience in data technologies.","$126,700 /yr (est.)",1 to 50 Employees,Company - Private,Media & Communication,Advertising & Public Relations,#N/A,Less than $1 million (USD)
"Northrop Grumman
4.0",4.0,"Roy, UT",Sentinel - Principal/Sr Principal Systems Engineer – Post Flight Data Processing (1327-2),"Requisition ID: R10129207
Category: Engineering
Location: Roy, Utah, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Embark on a career putting innovative, reliable, and agile products and ideas into orbit, and beyond. Northrop Grumman has opportunities waiting for you that play a vital role in human space exploration, national defense, and scientific discovery, supporting multiple programs across the universe. With us, you’ll discover a culture of curiosity and collaboration that will have you Defining Possible from the day you start. Our space systems connect and protect millions of people on earth every day, now and for the future. Explore your future and launch your career today.
Northrop Grumman Space Systems is seeking a Principal/Sr Principal Systems Engineer - Post Flight Data Processing in support of the Sentinel program. Northrop Grumman supports the Air Force’s sustainment, development, production and deployment of hardware and system modifications for Intercontinental Ballistic Missile (ICBM) Ground and Airborne Launch Control Systems, Launch Facilities, and associated infrastructure. This position is located in Roy, UT. This position may be filled at a higher level based on qualifications listed below.
What You’ll Get To Do
Flight test data processing including data quality checks and best bit selection of raw telemetry data.
Supporting development of the Test Data Management System.
Work with stakeholders to understand Software and System Metrics requirements and analyze data from different data sources.
Create data visualizations using Tableau or similar dashboard.
Real time telemetry decommutation and display (such as IADS).
Participating in technical exchange meetings, interfacing with customers (internal/external) and contributing to a broad range of program deliverables.
Interface with senior management, peers, and employees.
Position Benefits
As a full-time employee of Northrop Grumman Space Systems, you are eligible for our robust benefits package including:
Medical, Dental & Vision coverage
401k
Educational Assistance
Life Insurance
Employee Assistance Programs & Work/Life Solutions
Paid Time Off
Health & Wellness Resources
Employee Discounts
This position’s standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off. This role may offer a competitive relocation assistance package.
Basic Qualifications:
Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM) discipline from an accredited university.
Minimum 5 years of related engineering experience with a Bachelor's degree; 3 years with a Master's degree; 1 year with a PhD. (Sr Principal level requires 9 years with a Bachelor's degree; 7 years with a Master's degree; or 4 years with a PhD)
Must be a US Citizen with an active DoD Secret clearance with a reinvestigation date in the last 6 years, and the ability to obtain Special Access Program (SAP).
Experience using one or more of the following: Python, C++, MongoDB, JavaScript, React.
Preferred Qualifications:
Active Top Secret Clearance (awarded within the past 5 years).
Current SAP.
Master’s Degree in Software Engineering, Data Analytics, Systems Engineering, Aerospace Engineering, or similar.
Experience in scripting and automation.
Familiarity/knowledgeable with Web Application Development frameworks; Understanding of HTML/ CSS.
Experience with version control tools such as GitHub/GitLab/Gitbucket.
Business Intelligence and Data Visualization experience using tools like Tableau, Cognos, or Power BI.
Knowledge of data gathering, cleansing, and transformation techniques.
Understanding of Agile Software Development.
Experience with telemetry processing.
Excellent communication, mentoring, interpersonal skills.
#GBSDsystems
Salary Range: $90,400 - $135,600
Salary Range 2: $112,000 - $168,000
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$113,000 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"Chewy
3.5",3.5,"Plantation, FL",Grace Hopper 2023 : Data Engineer II,"Chewy is looking for Data Engineers to join our Data Engineering Team based in Boston, MA, Plantation, FL, or Minneapolis, MN. The ideal candidate will be a well-rounded technologist with a passion for building innovative business solutions with big data technologies. Experience delivering big data solutions – from system setup to development to business solution delivery – is critical. Programming experience is also paramount. Big data technologies are constantly evolving. The Data Engineer should be keeping up with the latest developments and should be able to connect technical capability with business need.
What you'll do:
Design analytical solutions for business users that provide the data needed to operate the business.
Design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for analytics platform.
Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes.
Participate in technical decisions and collaborate with talented peers.
Review code, implementations and give meaningful feedback that helps others build better solutions.
Monitor and troubleshoot data mart issues and perform regular backups and disaster recovery procedures.
Write documentation on design, architecture and solutions.
What you'll need:
Experience in data warehouse design and data integration methodologies.
5+ years of SQL expertise and the ability to work with many different database types. Snowflake, Postgres, SQL Server, and others as required.
5+ years of detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools
3+ years of hands-on experience with Snowflake and AWS cloud technologies, including AWS Redshift, AWS Glue, AWS Lambda, and AWS S3, EC2, ECS, Kenisis, DynamoDB, etc
3+ years of experience Integrating data between operational databases using data integration tools like Informatica, CloverDX, Datastage, Talend, Pentaho Data Integrator, or SSIS.
Data modeling experience in large Data warehousing, data lake environment
Proficient in programming languages such as Python, Java, or Scala.
Able to work in a fast-paced environment and be comfortable being accountable for work products.
Experience performing analytics to solve complex business problems.
BS or Master’s in Computer Science, Mathematics, Engineering, or Information Technology.
Position may require travel.
Bonus:
Snowflake certification.
HR data and systems knowledge.
Experience with business intelligence platforms (e.g. Tableau, etc.).
Background in e-commerce.
Agile experience is a plus.
Experience with statistical methods and data science.
Experience with Terraform.
Hands-on experience designing and developing scalable, high performing and fault-tolerant applications for large enterprises.
Knowledge of data integration and familiarity with common data integration challenges like converting data types, handling errors, and translating between different technology stacks.
Hand on experience delivering high performance distributed systems in public cloud environments.
Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.","$58,087 /yr (est.)",10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Jack Henry and Associates, Inc.
3.8",3.8,"Monett, MO",Systems Engineer III : VMware \ Data Protection,"At Jack Henry, we deliver technology solutions that are digitally transforming and empowering community banks and credit unions to provide enhanced and streamlined user experiences to their customers and members. Our best-in-class products are just the start as we lay the groundwork for the future of digital banking and payments. We hope you’ll join us. We can’t do it without you.

As part of the Infrastructure Engineering team the Systems Engineer III will design, document, implement, and maintain virtual infrastructure systems in an enterprise VMware vSphere environment. Perform capacity and performance analysis and provide recommendations for optimization. Complete lifecycle and other project-based work efforts as part of a larger interdisciplinary team. Drive continuous improvement by providing guidance on system automation, monitoring, configuration, and delivery to improve uptime and increase efficiency.

The salary range for this position is: $90,000- $115,000 based on location and experience.

This position will be filled to work Remotely within the United States.

What you’ll be responsible for:
Design, document, implement and maintain virtual infrastructure systems in a high availability, 24x7x365 enterprise environment.
Participate in high visibility projects for top corporate priorities.
Develop and maintain standard operating procedures.
Monitor alerting systems and servers.
Perform troubleshooting, and problem analysis and resolution.
Review issues, logs, and capacity reports to identify trends and solutions that should be implemented enterprise wide.
Develop custom reports to meet the business needs.
Drive continual service improvement.
Assist with disaster recovery initiatives and Implement solutions to streamline disaster recovery.
May perform other job duties as assigned.

What you’ll need to have:
Minimum of 5 years of experience in a systems engineer role designing and implementing VMware vSphere solutions in an enterprise environment.
Proficiency with VMware vCenter Server and ESXi 7.0 and 8.0.
Experience deploying and maintaining VMware virtual infrastructure.
Strong verbal and written communication skills.
Ability to work an on-call rotation including nights and weekends based on business needs.
Ability to travel up to 5% to attend meetings, trainings, and/or professional conferences.

What would be nice for you to have:
VMware Certified Professional - Data Center Virtualization (VCP - DVC) certification.
Strong knowledge of disaster recovery using Commvault, VMware Site Recovery Manager and/or Zerto.
Scripting and Infrastructure as Code tools and methodologies such as PowerShell, Python, Ansible and Terraform.
Experience working with other VMware products: VMware Cloud Director, NSX, Aria Operations (vRealize Operations), Aria Operations for Networks (vRealize Network Insights), and Horizon.
Change Management process experience.
Able to multi-task and use independent judgment to plan, prioritize and organize a diversified workload.

If you got this far, we hope you're feeling excited about this opportunity. Even if you don't feel you meet every single requirement on this posting, we still encourage you to apply. We're eager to meet motivated people who align with Jack Henry’s mission and can contribute to our company in a variety of ways.

Why Jack Henry?

At Jack Henry, we pride ourselves through our motto of, ""Do the right thing, do whatever it takes, and have fun."" We recognize the value of our associates and believe much of our company’s strength and success depends on their well-being.

We demonstrate our commitment by offering outstanding benefit programs to ensure the physical, mental & financial wellbeing of our people is always met.

Culture of Commitment

Ask our associates why they love Jack Henry, and many will tell you it is because our culture is exceptional. We do great things together. Rising to meet challenges and seeking opportunities is part of who we are as an organization. Our culture has helped us stay strong through challenging times and we credit our dedicated associates for our success. Visit our Corporate Responsibility site to learn more about our culture and commitment to our people, customers, community, environment, and shareholders.

Equal Employment Opportunity

At Jack Henry, we know we are better together. We value, respect, and protect the uniqueness each of us brings. Innovation flourishes by including all voices and makes our business—and our society—stronger. Jack Henry is an equal opportunity employer and we are committed to providing equal opportunity in all of our employment practices, including selection, hiring, performance management, promotion, transfer, compensation, benefits, education, training, social, and recreational activities to all persons regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, genetic information, pregnancy, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, and military and veteran status, or any other protected status protected by local, state or federal law.

No one will be subject to, and Jack Henry prohibits, any form of discipline, reprisal, intimidation, or retaliation for good faith reports or complaints of incidents of discrimination of any kind, pursuing any discrimination claim, or cooperating in related investigations.

Requests for full corporate job description may be requested through the interview process at any time.","$102,500 /yr (est.)",5001 to 10000 Employees,Company - Public,Financial Services,Banking & Lending,1976,$1 to $5 billion (USD)
"Northrop Grumman
4.0",4.0,"Colorado Springs, CO",Sentinel (GBSD) Wing Data Simulator Software Engineer - 10374,"Requisition ID: R10124427
Category: Engineering
Location: Colorado Springs, Colorado, United States of America | Roy, Utah, United States of America+ 1 more
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Description
Join Northrop Grumman on our continued mission to push the boundaries of possible across land, sea, air, space, and cyberspace. Enjoy a culture where your voice is valued and start contributing to our team of passionate professionals providing real-life solutions to our world’s biggest challenges. We take pride in creating purposeful work and allowing our employees to grow and achieve their goals every day by Defining Possible. With our competitive pay and comprehensive benefits, we have the right opportunities to fit your life and launch your career today.
Embark on a career putting innovative, reliable, and agile products and ideas into orbit, and beyond. Northrop Grumman has opportunities waiting for you that play a vital role in human space exploration, national defense, and scientific discovery, supporting multiple programs across the universe. With us, you’ll discover a culture of curiosity and collaboration that will have you Defining Possible from the day you start. Our space systems connect and protect millions of people on earth every day, now and for the future. Explore your future and launch your career today.
Northrop Grumman Space Systems (NGSP) is seeking a Wing Data Simulator Software Engineer. This position will be in Colorado Springs, CO or Roy, UT and will support the GBSD program. Northrop Grumman supports the Air Force’s sustainment, development, production and deployment of hardware and system modifications for Intercontinental Ballistic Missile (ICBM) Ground and Airborne Launch Control Systems, Launch Facilities, and associated infrastructure.
What You’ll Get to Do:
The Wing Data Simulator project is developing a complex Software/Hardware modeling and simulation capability that will be used to test the GBSD weapon system.
This position will develop software in a dynamic environment using the Agile (Scrum) framework using a variety of languages including C++, Javascript, and Python.
This SW engineering position will join a scrum team of 6-8 engineers to develop software capability.
Experience developing software in the early stages of a project is useful but not required.
Experience using design patterns early in projects to develop a strong foundation for the entire product lifecycle is suggested.
The project heavily leverages CI/CD and automated test concepts, so DevSecOps experience is useful.
Experience with Linux OS is required. Experience with code packaging and configuration management is very useful.
Position Benefits:
As a full-time employee of Northrop Grumman Space Systems, you are eligible for our robust benefits package including:
Medical, Dental & Vision coverage
401k
Educational Assistance
Life Insurance
Employee Assistance Programs & Work/Life Solutions
Paid Time Off
Health & Wellness Resources
Employee Discounts
This position’s standard work schedule is a 9/80. The 9/80 schedule allows employees who work a nine-hour day Monday through Thursday to take every other Friday off.
Job Qualifications:
You’ll Bring These Qualifications:
2 Years with Bachelors in Science; 0 Years with Masters; 4 additional years of experience in lieu of degree
US Citizen with Active Secret Clearance
Professional C++ development experience
Experience with Agile development
Experience with Atlassian tool suite
Experience with SW development in a Linux environment
Experience with code design documentation using UML
Familiarity with Model-Based Systems Engineering languages (SysML/UML) and concepts
These Qualifications Would be Nice to Have:
Preferred Qualifications:
Degree in Computer Science, Computer Engineering, or similar field
Experience with software development using a DevOps pipeline
Experience with Hardware/Software interface design
Experience with software and hardware certification/accreditation
Experience with embedded systems
Experience with databases (structure, design) and query languages
Experience with real-time operating systems
Experience with secure software development such as DO-178C compliant or similar
UML modeling experience using Cameo
Experience with Javascript, Python languages
#GBSDSoftware
Salary Range: $73,400 - $115,800
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$94,600 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"Northrop Grumman
4.0",4.0,"Palmdale, CA",Principal / Sr Principal Instrumentation and Data Acquisition Hardware Engineer,"Requisition ID: R10120971
Category: Engineering
Location: Palmdale, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: Any (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 7
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Northrop Grumman Aeronautics Systems has an opening for an Instrumentation and Data Acquisition Hardware Engineer to join our team of qualified, diverse individuals. This position is located in Palmdale, CA.
As an Instrumentation and Data Acquisition Engineer you’ll be part of the design, development, integration, configuration and test of a real-time, hardware in the loop (HITL), Data Acquisition Systems (DAS). Tasking will include design, development, verification and acceptance testing of data builds and real time Mission Control Room configuration files using Symvionics IADS software.
This position will require occasionally work shift work and overtime and travel.
“This requisition may be filled at a higher grade based on qualifications listed below.”
Basic Qualifications:

“This requisition may be filled at either a principal or a Sr. Principal Level)
Basic Qualifications for Principal Instrumentation Data Hardware Engineer:
Bachelor’s degree within a science, technical, engineering or mathematics (STEM) discipline with 5 years of test experience, Masters with 0 years of experience.
Basic understanding of troubleshooting systems to identify and assist in the correct the root cause.
Assist with creating, editing and executing procedures.
Assist in data acquisition and data collection.
Experience with Microsoft Window Family, AutoCAD, MatLab.
Requires active DoD Secret Clearance
Ability to obtain and maintain PAR (Program Special Access)
Basic Qualification for Sr Principal Instrumentation Data Hardware Engineer:
Bachelor’s degree within a science, technical, engineering or mathematics (STEM) discipline with 9 years of test experience, master's with 7 years of experience.
Basic understanding of troubleshooting systems to identify and assist in the correct the root cause.
Assist with creating, editing and executing procedures.
Assist in data acquisition and data collection.
Experience with Microsoft Window Family, AutoCAD, MatLab.
Requires active DoD Secret Clearance
Ability to obtain and maintain PAR (Program Special Access)
Preferred Qualifications:
Electronics, Analog and Digital Communications, Digital Signal Processes, Computer Communication Networks, Embedded Systems
Experience working in Flight Test or Lab Test environments
Experience using oscilloscopes and waveform generators.
Experience working with Strain Gages, Accelerometers, Pressure Transducers and other commonly used instrumentation sensors
Basic knowledge of data bus architecture MIL-STD-1553, IEE-1394, ARINC-429, RS232 an RS422.
Experience using Symvionics IADS software and working in a Mission Control Room
Experience post-test processing data from a IRIG-106 CH10 recording
Experience using TTCWare Application Software
Experience working Curtiss-Wright TTC Data Acquisitions Systems
Ability to write scripts GUIs or small scale applications a plus.
Degree in Electrical or a Bachelor’s of Science degree with Instrumentation data experience.
Salary Range: $95,000 - $142,000
Salary Range 2: $117,700 - $176,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$118,500 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"Allstate
3.5",3.5,"Rochelle, IL",Critical Facility Engineer (Rochelle Data Center),"The world isn’t standing still, and neither is Allstate. We’re moving quickly, looking across our businesses and brands and taking bold steps to better serve customers’ evolving needs. That’s why now is an exciting time to join our team. You’ll have opportunities to take risks, challenge the status quo and shape the future for the greater good.
You’ll do all this in an environment of excellence and the highest ethical standards – a place where values such as integrity, inclusive diversity and accountability are paramount. We empower every employee to lead, drive change and give back where they work and live. Our people are our greatest strength, and we work as one team in service of our customers and communities.
Everything we do at Allstate is driven by a shared purpose: to protect people from life’s uncertainties so they can realize their hopes and dreams. For more than 89 years we’ve thrived by staying a step ahead of whatever’s coming next – to give customers peace of mind no matter what changes they face. We acted with conviction to advocate for seat belts, air bags and graduated driving laws. We help give survivors of domestic violence a voice through financial empowerment. We’ve been an industry leader in pricing sophistication, telematics, digital photo claims and, more recently, device and identity protection. We are the Good Hands. We don’t follow the trends. We set them.
Job Summary:
The Critical Facility Engineer Senior Associate has technical skills to support building-related equipment, perform maintenance including electrical, plumbing, HVAC, UPS, and other maintenance duties.

**This position is for the 3rd shift. It is 8 10-hour days (Tuesday night at 9:00 PM and ends the following Wednesday morning at 7:30 AM). The hours are 9pm to 7:30am.**
Key Responsibilities:
Operation of most of the mechanical, electrical, plumbing, and computerized equipment
Activate all LAN connections for move requests prior to move data
Troubleshoot workstations, wiring, and data transmission equipment to minimize downtime
Apple Federal, State, and OSHA regulations and guidelines
Operation of computerized/automated systems (i.e., Johnson Control and Andover systems)
Diagnose malfunctions and perform corrective action
Install wire/cable for telephone and computers
Maintain documentation of all wiring/fiber connections, upon completion of changes
Annual S.C.B.A. Mask Fit Testing
Attend internal/external technical courses/seminars related to building engineer work
#LI-SH1

Supervisory Responsibilities:
This job does not have supervisory duties.
Education and Experience:
High school diploma or equivalent
3 or more years of related experience
Certificates, Licenses, Registrations:
None
Functional Skills:
Basic understanding of how systems are integrated, clearly understanding their dependences and performance dependencies
Working knowledge of all major mechanical and electrical equipment
Knowledge of Federal, State, and OSHA regulations and guidelines
General working knowledge of inventory control
General knowledge of material handling
General knowledge of office operating procedures
General working skill/ability regarding HVAC systems, pumps, gas engines, high and low electric voltage, UPS operation and distribution, kitchen equipment/refrigerator, test equipment operation, purchasing procedures, and principles of inventory
Notes:
The preceding description is not designed to be a complete list of all duties and responsibilities. May be required to perform other related duties as assigned. Regular, predictable attendance is an essential function of this job.
Compensation offered for this role is $37,000.00-$64,750.00 per year and is based on experience and qualifications.
The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen.
Good Work. Good Life. Good Hands®.
As a Fortune 100 company and industry leader, we provide a competitive salary – but that’s just the beginning. Our Total Rewards package also offers benefits like tuition assistance, medical and dental insurance, as well as a robust pension and 401(k). Plus, you’ll have access to a wide variety of programs to help you balance your work and personal life - including a generous paid time off policy. For a full description of Allstate’s benefits, visit allstate.jobs/benefits/
Learn more about life at Allstate. Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video.
Allstate generally does not sponsor individuals for employment-based visas for this position.
#LI-SH1

Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.

For jobs in San Francisco, please click “here” for information regarding the San Francisco Fair Chance Ordinance.
For jobs in Los Angeles, please click “here” for information regarding the Los Angeles Fair Chance Initiative for Hiring Ordinance.

To view the “EEO is the Law” poster click “here”. This poster provides information concerning the laws and procedures for filing complaints of violations of the laws with the Office of Federal Contract Compliance Programs

To view the FMLA poster, click “here”. This poster summarizing the major provisions of the Family and Medical Leave Act (FMLA) and telling employees how to file a complaint.

It is the Company’s policy to employ the best qualified individuals available for all jobs. Therefore, any discriminatory action taken on account of an employee’s ancestry, age, color, disability, genetic information, gender, gender identity, gender expression, sexual and reproductive health decision, marital status, medical condition, military or veteran status, national origin, race (include traits historically associated with race, including, but not limited to, hair texture and protective hairstyles), religion (including religious dress), sex, or sexual orientation that adversely affects an employee's terms or conditions of employment is prohibited. This policy applies to all aspects of the employment relationship, including, but not limited to, hiring, training, salary administration, promotion, job assignment, benefits, discipline, and separation of employment.","$50,875 /yr (est.)",10000+ Employees,Company - Public,Insurance,Insurance Agencies & Brokerages,1931,$10+ billion (USD)
"Northrop Grumman
4.0",4.0,"Palmdale, CA",Principal/Sr. Engineer Systems Test (Data Acquisition Engineer),"Requisition ID: R10127943
Category: Engineering
Location: Palmdale, California, United States of America
Citizenship required: United States Citizenship
Clearance Type: Secret
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
This role may be selected at the higher grade based on requirements listed below.
Northrop Grumman Aeronautics Systems has an opening for a Principal or Senior Principal Electronics Engineer (Data Acquisition) to join our team of qualified, diverse individuals within our Test and Evaluation organization. This role is located in Palmdale.
The primary job responsibilities are, but not limited, to the following:
Responsible for turning engineer requirement into data acquisition.
Provide mission load files to Curtiss Wright KSM-500, Omega Next, System 550, MCS, and IADS.
Develop software application for instrumentation.
Performs a variety of duties, including development, testing, and procedure writing.
This role may be selected at the higher grade based on requirements listed below.
Essential Functions
Responsible for turning engineer requirement into data acquisition.
Provide mission load files to Curtiss Wright KSM-500, Omega Next, System 550, MCS, and IADS.
Develop software application for instrumentation.
Performs a variety of duties, including development, testing, and procedure writing.
Basic Qualifications for a Principal level 3:
BS in STEM (Science, Technology, Engineering or Mathematics) and 5 years equivalent experience In Instrumentation / Data Acquisition career field or 3 years with a Master's degree and 0 years with a Ph D.
DOD Secret clearance is required to be considered
Ability to obtain Special Program Access prior to start
Familiar with ACRA Airborne Data Acquisition System KSM-500 series or industry equivalent.
Experience with ground telemetry frontends and IADS
IT working experience, candidate must have solid understanding of client and server applications
Experience with software development and maintenance
Overtime, odd shifts, and weekend work will occasionally be required
Basic Qualifications for a Sr. Principal level 4:
BS in STEM (Science, Technology, Engineering or Mathematics) and 9 years equivalent experience In Instrumentation / Data Acquisition career field or 7 years with a Master's degree and 4 years with a Ph D
DOD Secret clearance is required to be considered
Ability to obtain Special Program Access prior to start
Familiar with ACRA Airborne Data Acquisition System KSM-500 series or industry equivalent.
Experience with ground telemetry frontends and IADS
IT working experience, candidate must have solid understanding of client and server applications
Experience with software development and maintenance
Overtime, odd shifts, and weekend work will occasionally be required
Preferred Qualifications:
Active DOD Top Secret
Experience working with IRIG-106 standard, particularly chapters 4, 7, and 10
Experience working with SQL, XML, and C#, and is willing to adapt to special software projects
Active Security+ certification
9+ years of data acquisition experience working with over-the-air RF telemetry transmission and onboard recording systems
9+ experience working with ground station mission control room and test ranges
9+ years of experience working with various ICDs written for various digital bus mediums such as Ethernet, Mil-Std-1553, Arinc-429, Serial, 1394, etc
Ideal candidate must have an ability to digest different data formats and apply best filtering criteria for capturing data
5+ years of experience working with RT Station IENA data format
Experience in supporting test activities, anomaly resolution and process improvement initiatives
Familiar with the engineering development cycle, along with engineering configuration management concepts

The selected candidate will work in a dynamic people-focused environment while interacting with customers and other design engineers.
The position will be based out of Palmdale, CA.
Salary Range: $95,000 - $142,400
Salary Range 2: $117,700 - $176,500
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$118,700 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"Stark Dev, LLC",#N/A,"Washington, DC","Data Engineer/Clearance Required/Washington, DC","This position is open for United States Citizens ONLY with the Interim Secret Clearance or higher.
Contract job directly with the candidates.
NOT C2C
What we’re looking for:
Someone with a solid background developing solutions for high volume, low latency applications and can operate in a fast paced, highly collaborative environment.
A candidate with distributed computer understanding and experience with SQL, Spark, ETL.
A person who appreciates the opportunity to be independent, creative and challenged.
An individual with a curious mind, passionate about solving problems quickly and bringing innovative ideas to the table.
Basic Qualifications:
4+ years of experience with SQL
4+ years of experience developing data pipelines using modern Big Data ETL technologies like NiFi or StreamSets.
4+ years of experience with a modern programming language such as Python or Java
4 years of experience working in a big data and cloud environment
Secret Clearance or higher
Additional Qualifications:
2 years of experience working in an agile development environment
Ability to quickly learn technical concepts and communicate with multiple functional groups
Ability to display a positive, can-do attitude to solve the challenges of tomorrow
Possession of excellent verbal and written communication skills
Preferred experience at the respective command with an understanding of analytical and data paint points and challenges across the J-Codes.
Job Type: Contract
Pay: From $60.00 per hour
Compensation package:
Hourly pay
Experience level:
4 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Washington, DC: Reliably commute or planning to relocate before starting work (Required)
Application Question(s):
What is your current location?
Experience:
SQL: 4 years (Required)
modern programming language such as Python or Java: 4 years (Required)
NiFi or StreamSets: 4 years (Preferred)
Spark: 4 years (Preferred)
developing data pipelines using modern Big Data ETL: 4 years (Required)
License/Certification:
Interim Secret Clearance (Required)
Security clearance:
Secret (Preferred)
Work Location: In person",$60.00 /hr (est.),1 to 50 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"AURA TECHNOLOGIES LLC.
4.8",4.8,North Carolina,Senior Data Engineer [USA- Remote],"AURA TECHNOLOGIES, LLC (AURA) is an advanced research and development (R&D) and technology company creating game-changing innovations for the US Department of Defense in Artificial Intelligence (AI) and in other systems-level implementation of cutting-edge technology. We are creating advanced intelligent power systems for the US Army; unconventional tactical lights for the US Marines; revolutionary satellite manufacturing for the US Air Force; and a range of AI platforms for DoD implementation. AURA partners with some of the best companies in the world, such as Boeing, Northrop Grumman, and Lockheed Martin. We also collaborate with the best and brightest at our nation’s universities, including Georgia Tech and NC State University.

If you are a smart, capable, and talented individual who possesses high integrity, thrives in a fast-paced environment, wants to chart your own course based on your capabilities, and is willing to be accountable for failures and successes, then continue reading because you may be the ideal candidate to join our growing R&D business.


AURA has an immediate opening for a full-time Senior Data Engineer (remote).

ESSENTIAL DUTIES AND RESPONSIBILITIES:
You will work side-by-side with other team members to provide technical direction and recommendations on how to: standardize, normalize, and format data; extract valuable features from large data sets; develop data pipelines and write preprocessing algorithms; and train others to use and maintain developed tools/applications.

Work on projects involving time-series data, image recognition, computer vision, and geometric shape modeling
Preprocess and extract features from sensor-based, three-dimensional, and visual data
Develop applications to sustain data pipelines, interact with databases, and ensure uptime
Interact with big data applications for visual, video, and geometric information
Collaborate closely with data scientists to ensure that data throughput and preprocessing requirements are met
Work in a team environment to collaborate with coworkers, partners, and clients to produce an integrated solution. Given the demanding, diverse, and fast-paced environment, the Senior Data Engineer must also possess exceptional attention to detail.

WORK EXPERIENCE, EDUCATION & TECHNICAL REQUIREMENTS:

Minimum Years of Work Experience:
Minimum of 3 years of experience in a data engineer, cloud engineer, database management, or similar role (advanced degrees may be substituted for experience in the case of a qualified candidate)

Minimum Education:
Masters degree in Computer Science, Engineering, Data Science, Statistics, or a related technical degree

Minimum Technical Requirements:
At least 3 years of experience (in a professional setting) developing data pipelines and preprocessing algorithms
Expertise in one or more structured database management system types/vendors such as MySQL, Oracle, or SQLite
Expertise in one or more unstructured data management systems
Programming expertise in one or more scripting languages, such as Python or R
Awareness of big data design for cloud applications such as AWS or Azure, including design, provisioning, and tuning

and EITHER:

At least 1-2 years of practical experience with storing and preprocessing visual data, including the development of data pipelines for large image datasets. Past experience working with large open-source visual datasets such as OpenImages, ImageNet, or MS-COCO is preferred.
At least 1-2 years of practical expertise working with three-dimensional geometric data, such as computer-aided design (CAD) files, bounding boxes, and shape data. Past experience working with large open-source 3D datasets such as ShapeNet, ModelNet, or ABC is preferred.

PREFERRED REQUIREMENTS
Prior DoD or military experience
Doctorate degree in Computer Science, Engineering, Data Science, Statistics, or a related technical degree

ADDITIONAL REQUIREMENTS:
US citizenship status is required for this position due to AURA’s contractual obligations to the US Department of Defense (DoD) requiring all employees working in performance of DoD contracts to be US citizens.


BENEFITS:
401(k) Safe Harbor Contribution
Flexible schedule
Health insurance
Discretionary Leave
14 Paid holidays

TO APPLY FOR THIS POSITION:
Submit your resume/CV in PDF format via instructions at the following link: http://aura.company/careers/
No phone calls after submission. We will let candidates know via automated reply that we have received their resumes and will contact them if there is a good fit after the closing date for this job.

AURA Technologies, LLC is an Equal Opportunity Employer and affirmative action employer of veterans protected under the Vietnam Era Veterans’ Readjustment Assistant Act (VEVRAA). We are a Drug Free Workplace and thus, all job offers are contingent on successful criminal background check and drug screen. As a US Federal Contractor, AURA uses the Department of Homeland Security e-Verify system to determine eligibility to legally work in the United States. Most of AURA’s work is for the federal government, and federal regulations may in the future require AURA’s employees to be fully vaccinated against the COVID-19 virus.

Write a carefully crafted, well-written cover letter that elaborates on your interest in this position and why you think you are the best candidate for the job. Submit your cover letter, CV and three professional references (one of which must be from a current or former supervisor) in PDF format ONLY via BambooHR.

Any attachments must be in PDF format or will not be opened due to virus concerns. No phone calls after submission. We will let candidates know via automated reply that we have received their resumes and will contact them if there is a good fit after the closing date for this job.",#N/A,1 to 50 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,2015,Unknown / Non-Applicable
"xScion Solutions
4.1",4.1,"McLean, VA",Senior Cloud Data Engineer,"As an employee, you Turn Change Into Value® - for our clients, for our company, for your professional growth, for the consumers. We hire the best and brightest, who are driven to create lasting value. At xScion, you aren't just another team member, you're impactful. You're empowered. You're driven. You're an xScioneer.
Location: Remote (United States)
As a Senior Cloud Data Engineer, You Will:
Support our Public Sector customers, primarily focused on designing, implementing, and maintaining cloud-based solutions using the latest AWS services and tools. This role requires a dynamic individual capable of managing multiple projects, upholding compliance guidelines, and ensuring data integrity across multi-region cloud setups.
AWS Management: Utilize AWS cloud services to design, architect and support cloud data solutions that align with company objectives and client needs
Infrastructure as Code (IaC): Develop, deploy, and maintain infrastructure pipelines using Terraform, ensuring smooth CI/CD processes
Compliance Management: Work alongside our compliance team to ensure all cloud solutions adhere to multi-compliance guidelines
Python Development: Write clean, scalable, and effective Python code, employing multi-threading techniques to enhance performance and efficiency
Data Validation: Use SQL queries to verify, analyze, and ensure data integrity and accuracy across all cloud solutions
Multi-region Cloud Deployment: Design and maintain data cloud solutions across multiple AWS regions ensuring high availability, fault tolerance, and scalability.
To Be Successful, You Need:
Bachelor's degree in Computer Science, Engineering, or a related field (or equivalent experience). Masters degree preferred
7+ years experience as a Data Engineer or a similar role
Proven experience working with AWS cloud services
Expertise in building and deploying IaC using Terraform
Strong experience in working with multi-compliance guidelines (Fed Ramp, GovCloud, NIST)
Proficiency in Python with a keen understanding of multi-threading
Solid experience with SQL for data validation
Hands-on experience with multi-region cloud deployments and related best practices
US Citizenship required.

Why xScion?
We have an amazing culture– We were named a Best Places to Work in Virginia 7 times, including 2023.
We are poised for rapid growth– We are on the cutting edge of digital transformation in Financial Services, Healthcare, Nonprofit and Public Sector and continuously welcome new clients to the xScion family.
We believe in your continuous development– We invest in our teams' development, including our Communities of Practice, technology partnerships, sandbox and paying for certifications and trainings to improve their skills because we are committed to collectively being the best at what we do.
We want you to make an impact in whatever you do– Our people are given the opportunity to provide impactful change to our clients and team.
We believe in equality - As a woman-owned organization, we believe in an inclusive and diverse culture where everyone's uniqueness makes us stronger.
Great Benefits: Medical, dental, 401(k) match, flexible spending and more, but we also have unique perks such as up to 27 days off a year (including your birthday!), remote work opportunities, parental leave, wellness benefits and many other things that inspire balance and flexibility.
We're Transforming RegTech Organizations:
At xScion, we Turn Change Into Value. We help clients in highly regulated industries start or accelerate their digital transformation initiatives by shifting their mindset and goals into smaller, actionable steps that create lasting value. With more than 20 years of experience supporting Regulatory Technology (RegTech), xScion provides both domain experts and tailored solutions to help organizations navigate complex compliance and technology requirements. We specialize in Business Agility, Cloud Transformation and Organizational Change Management solutions for clients in Financial Services, Public Sector, Nonprofits and Healthcare. Our experts help prepare and create change to clients' processes, technology and culture in order to improve operational efficiencies and the customer experience. As a certified Woman-Owned Small Business, we are proud to be the most trusted solutions partner that business and technology leaders count on to deliver lasting, impactful value.
All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or protected veteran status. xScion takes affirmative action in support of its policy to employ and advance in employment individuals who are minorities, women, protected veterans and individuals with disabilities.
Want to Learn More about xScion?
Check us at out on www.xscion.com or socially at LinkedIn, Twitter and Glassdoor.
At xScion, we celebrate diversity in all forms. xScion is an Equal Opportunity Employer- Females/Minorities/Protected Veterans/Individuals with Disabilities.","$125,743 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2002,$5 to $25 million (USD)
"Alogent
3.7",3.7,"Peachtree Corners, GA",Data Center Applications Engineer,"Alogent is the market leader in providing solutions for deposit automation and content management to some of the largest banks in the world. We have over 25 years’ experience in providing the technology, support, and expertise to overcome business challenges in premier financial institutions everywhere such as reliability, efficiency, and quality. Our partnership-based approach to working through business issues has been recognized by our clients and partners through maintaining long-term relationships as their business needs evolve. Alogent continues to forge ahead through the creation of specialized technologies and services that utilize imaging and automation to achieve proven results. Our goal is to be the premier financial technology partner to institutions everywhere.

The company is headquartered in Peachtree Corners, GA, with regional teams across the United States.

Job Overview:
The Data Center Applications Engineer works with the Data Center team, Development, Support and other internal Alogent Departments assisting them in resolving application and operational issues regarding Alogent’s proprietary software in our hosted environment. Excellent communication, analytical, troubleshooting, and organizational skills are crucial, in addition to a desire to understand how our solutions drive value and improve the growth of the Alogent Data Center and its operations.

This position is hybrid working from our Headquarters in Peachtree Corners, GA, or can be remote within the United States.

Important Note: Applicants for employment in the United States must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Alogent.

Responsibilities:
Assists with the maintenance, support, and upgrades of existing Alogent software applications and systems within our Alogent Cloud Environment. This includes Deploying application to pre-production and production environments, during schedule maintenance windows.
Works closely with the Alogent Cloud Data Center Infrastructure team to provide necessary application deployment requirements necessary to properly host Alogent applications
Manages application and data access for internal implementation and support teams
Assists with coordinating and communicating upgrades, enhancements, and changes within Alogent’s cloud environment
Partners with Development, Data Center and Product teams to troubleshoot and develop enhanced processes around business critical applications
Develops best practices for application implementations within Alogent’s Data Center
Supports Alogent Customer onboarding into the Data Center environment
Develops and documents functioning specs detailing Alogent application upgrade process
Creates/Documents application support knowledgebase and/or training articles
Approves onboarding application changes in Alogent Cloud Environment
Identifies, documents and reports potential issues with Alogent Application Interfaces and data import/export methodologies
Pre-performs Alogent Cloud Application testing prior to upgrading Production
Works closely with Development and Product to identify, evaluate and recommend application modifications to Alogent’s solutions
Reports and tracks any defects associated with Alogent Hosted Products pertaining to Alogent Cloud
Works Alogent Cloud internal ticketing system requests
The above statements are intended only to describe the general nature of the job, and should not be construed as an all-inclusive list of position responsibilities.

Knowledge, Skills, and Abilities:
At least 2 years of experience in a technical proprietary application support role
At least 2 years of experience in a Data Center
Provide great customer service under pressure
Experience with Microsoft Windows Desktop and Server Operating Systems
Experience with MS SQL Server, IIS, Active Directory
Experience with .NET Applications
Experience with WCF Windows Services and IIS Applications
Experience with Monitoring tools such as Splunk and Wireshark
Excellent written and verbal communication skills
Excellent troubleshooting and problem-solving skills
Strong communication, organization, prioritization, and written skills
Networking knowledge – LAN/WAN/Router/Firewall a plus
CITRIX XenApp/XenDesktop, VMWare Horizon experience a plus
Financial services IT/IS experience a plus
Platform performance monitoring / evaluation a plus
Technical degree or equivalent experience
Must be able to work weekends, nights and on Call Shifts when necessary
Ability to travel if required

Working Conditions:
Must be able to work with possible distractions in the work environment
May require sitting, standing or being on phone calls for long periods of time
Must be able to work weekend, nights and on call shifts

BENEFITS:
Competitive benefits including medical, dental, vision, life, disability, Employee Assistance Program, Flexible Spending Account, Group Accident, Critical Illness, Pet Insurance, Identity Protection Program and long-term care
Excellent 401(k) plan with company match
Paid time off (PTO) and Holidays
Paid voluntary time off (VTO) day
Wellness programs
Monthly educational sessions for employees
A knowledgeable, high-achieving, experienced, and fun team
A diverse work atmosphere

Employee Polygraph Protection Act
Equal Employment Opportunity
Family and Medical Leave Act

Notice To Third-Party Agencies:
Alogent does not accept unsolicited resumes from recruiters or agencies. Any staffing/employment agency, person or entity that submits an unsolicited resume to this site does so with the understanding that the applicant's resume will become the property of Alogent. Alogent will have the right to hire that applicant at its discretion and without any fee owed to the submitting staffing/employment agency, person, or entity.

Alogent is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected Veteran status, or any other characteristic protected by federal, state or local laws.","$80,775 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,1995,Unknown / Non-Applicable
"UniGroup
3.4",3.4,"Fenton, MO","STAFF SOFTWARE ENGINEER, DATA","Under general supervision, formulates and defines system scope and objectives through research and fact-finding, documentation, coding, and testing required to develop or modify moderately complex information systems. This position is tasked with building modern software to connect people with the transportation and moving industries through technology.

The work location for this role is flexible if approved by UniGroup except this position may not be performed remotely from Colorado and California. You may read over the UniGroup privacy policy by clicking HERE.

Essential Duties and Responsibilities:
Technical Skills:
Consistently writes production-ready code that is easily testable, easily understood by other developers, and accounts for edge cases and errors. Understands when it is appropriate to leave comments, but biases towards self-documenting code.
Understands the testing approach of several teams and uses quality metrics to identify gaps. Works with those teams to recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Influences organization wide testing strategy.
Proficient at using systematic debugging to diagnose all issues within a set of related domains.
Fosters a culture of observability across several teams and helps them use operational data to improve stability and performance of their domains.
Has expertise in a set of related team's domains, including the breadth of services, how they interact, and data flows between systems.
Works across teams to foster a culture of architecture that allows for iterative, autonomous development and future scaling. Guides several teams in anticipation of future use cases and helps them make design decisions that minimize the cost of future changes.
Actively works with the security team, as well as across several teams, to apply the organization's security strategy. Fosters a security first mindset across those teams, leading by example.
Delivery:
Reviews cross-team work critically and ensures it’s appropriately broken down and prioritized, and well understood by all involved teams.
Ensures cross-team dependencies are noted and well understood by all teams involved and other relevant stakeholders. Works across teams to foster a culture of priority setting and urgency in alignment with organizational strategy.
Effectively handles risk, change, and uncertainty across several teams. Decides and acts responsibly in their work across teams without having the total picture during routine business, as well as when in high pressure situations.
Successfully manages cross-team commitments, their progress, and roadmap to delivery. Anticipates and communicates blockers, delays, and cost ballooning across teams, before they require escalation. Ensures expectations across teams and stakeholders are clarified between all parties involved.
When taking action, weighs cost and value in order to make the most economic action. Uses this thinking in their own work, and to foster a culture across several teams where people apply economic thinking to make timely decisions.
Feedback, Communication, Collaboration:
Fosters a culture of delivering praise and constructive feedback across several teams as well as their respective business stakeholders. Actively demonstrates these behaviors.
Works across several teams and with their business stakeholders to foster a culture of seeking out feedback and using it as a tool for growth. Actively demonstrates these behaviors.
Is able to communicate effectively with a diverse set of teams. Fosters a culture of clear, concise, effective, audience-oriented communication across several teams, ensuring teammates actively listen to others and are understood. Actively demonstrates these behaviors. Pays attention to nonverbal communication.
Fosters a culture of documentation and knowledge sharing across several teams and their respective business stakeholders; actively demonstrates these behaviors.
Consistently works across teams to help them resolve blockers, and complete work tasks. Ensures that credit is shared and given where due.
Works to build and improve strong relationships with engineers and managers across the organization as well as relevant business stakeholders for several teams. Leverages relationships to better plan for and position those teams.
Fosters a culture across several teams where people are encouraged to share their opinions and contribute to discussions in a respectful manner, approach disagreement non-defensively with inquisitiveness, and use contradictory opinions as a basis for constructive, productive conversations. Works through surface-level disagreements to expose the concerns of disagreeing voices and integrates these concerns into their perspective and plans.
Leadership:
Takes ownership of decisions made across teams by helping them make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success. Raises awareness for how biases impact decisions and ensures accountability is practiced throughout those teams. Demonstrates these behaviors themselves.
Fosters a culture across several teams of having conversations based on organizational strategy and principles to create alignment. Strongly oriented towards goals and ensures several teams are continuously working towards their goals.
Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation. Usually collaborates with others to improve organizational practices and processes.
Facilitates discussions across teams, ensuring that everyone has an opportunity to share their opinion and be heard, and that discussion outcomes tie to stated goals. Ensures relevant parties are included in discussions. Guides discussions toward decisions, clarifies and gets buy-in.
Mentors across teams in an open, respectful, flexible, empathetic manner. Fosters a culture of mentoring across teams by seeking out mentoring opportunities for themselves and others and supports others in their growth as mentors.
Strategic Impact:
Usually involved in strategic organizational decisions and plans. Leads cross-team strategic efforts, influencing decisions to achieve cross-team alignment on major goals.
Recognizes product opportunities and differentiators in relation to the competition. Often helps refine roadmaps across teams based on technical strategy & constraints. Helps to define & create new product abilities by changing technical strategy or constraints.
Technical expertise with data modelling and data mining techniques:
Experience with programming languages (e.g. Python and JavaScript/Typescript)
Experience with relational SQL and NoSQL databases, including Postgres and MongoDB.
Experience with cloud environments (Microservices / AWS / Docker / Kubernetes)
Experience of using Git / GitLab /GitHub
Hands-on experience with SQL database design
Experience with big data tools such as Kafka, etc.
Experience with data pipeline and workflow management tools
Great numerical and analytical skills
Education, License or Certification:
Bachelor’s degree in Information Systems or equivalent experience.
Experience:
6-8 years of experience in IS Development
We foster diversity, in part, by imposing a strict policy of non-discrimination. Employment decisions are made without regard to race, color, ethnicity, national origin, sex, sexual orientation, gender identity, age, religion, disability, veteran or military status, genetic information or other status protected by the law.

We value the unique skills and experiences that veterans and separated service members bring to our workforce. While serving our country you have gained skills such as leadership, flexibility, and agility, which will help to make you successful here. We are dedicated to supporting military families and ensuring that we provide a welcoming environment for our country’s heroes. We hope you consider joining the UniGroup family.

UniGroup is committed to the full inclusion of all qualified individuals. As part of this commitment, UniGroup will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact careers@unigroup.com","$106,109 /yr (est.)",1001 to 5000 Employees,Company - Private,Transportation & Logistics,Taxi & Car Services,1920,$1 to $5 billion (USD)
"Contact Government Services, LLC
4.7",4.7,"Washington, DC",Data Engineer,"CGS is seeking a passionate and driven Data Engineer to support a rapidly growing Data Analytics and Business Intelligence platform focused on providing solutions that empower our Federal customers with the tools and capabilities needed to turn data into actionable insights. The ideal candidate is a critical thinker and perpetual learner; excited to gain exposure and build skillsets across a range of technologies while solving some of our clients’ toughest challenges. As a Data Engineer, you will be integral to data operations for the development and integration of multiple data types across a range of data sets and sources.

You will be responsible for the day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner. Processing data will include managing, manipulating, storing and parsing data in a data pipeline for variety of target sources. You will also support maintenance of applications and tools that reside on these systems such as upgrades, patches, configuration changes, etc. The work is performed in a multidisciplinary team environment using agile methodologies. The candidate we seek must be highly motivated and enthusiastic about implementing new technologies and learning about new data in a small team environment where deadlines are important.
Responsibilities:
Complete development efforts across data pipeline to store, manage, store, and provision to data consumers
Being an active and collaborating member of an Agile/Scrum team and following all Agile/Scrum best practices
Write code to ensure the performance and reliability of data extraction and processing
Support continuous process automation for data ingest
Achieve technical excellence by advocating for and adhering to lean-agile engineering principles and practices such as API-first design, simple design, continuous integration, version control, and automated testing
Work with program management and engineers to implement and document complex and evolving requirements
Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork
Collaborate with others as part of a cross-functional team that includes user experience researchers and designers, product managers, engineers, and other functional specialists
Required Skills:
Must be a US Citizen
Must be able to obtain a Public Trust Clearance
7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.
Experience with developing data pipelines from many sources from structured and unstructured data sets in a variety of formats
Proficiency developing ETL processes, and performing test and validation steps
Proficiency to manipulate data (Python, R, SQL, SAS)
Strong knowledge of big data analysis and storage tools and technologies
Strong understanding of the agile principles and ability to apply them
Strong understanding of the CI/CD pipelines and ability to apply them
Experience with relational database, such as, PostgreSQL
Work comfortably in version control systems, such as, Git Repositories
Contact Government Services strives to simplify and enhance government bureaucracy through the optimization of human, technical, and financial resources. We combine cutting edge technology with world class personnel to deliver customized solutions that fit specific needs and solve the most challenging, dynamic problems. Our team emphasizes technical expertise and an empathy to public service to provide unique top tier support for our government engagements.
SOME BENEFITS OF THIS POSITION INCLUDE:
Health, Dental, & Vision insurance
Life Insurance
401k
Flexible Spending Account (Health, Dependent Care, and Commuter)
Paid Time Off & Observance of State/Federal Holidays
For more information about CGS please visit: https://www.cgsfederal.com
pzeFkWk6kc","$105,919 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Asplundh Tree Expert, LLC - 010",#N/A,"Willow Grove, PA",Data Engineer - Asplundh Innovate,"Data Engineer- Asplundh Innovate
Job Type: Exempt
Pay: Salary
Are you a real go-getter looking for an amazing opportunity with a nationwide full-service-utility contractor offering competitive wages and incredible benefits? Keep reading because this job might be for you!
Since 1928, Asplundh has been dedicated to safe, efficient, and innovative line clearance services for the utility industry. Reliable, uninterrupted power is an important service provided by the world's electrical utilities and Asplundh has the expertise to help keep the power flowing. Over the years, diversification has opened vegetation management services to other specialized markets such as municipalities, railroads, pipelines, helicopter vegetation services, and departments of transportation.
A family-owned and operated corporation headquartered near Philadelphia, Pennsylvania, Asplundh has grown to employ over 33,000 service professionals throughout the United States, Canada, Australia, and New Zealand.
Benefits:
Benefits Available and vary per position and location.
About the Opportunity
Asplundh Tree Expert (Asplundh) is seeking a Data Engineer to join the Asplundh Innovate Team reporting to the Application Development Manager. The Innovate Team provide digital technology & solutions across key parts of the business and have international relations with the Australian Tech Team. They are a diverse international team that operate across all levels of the business. This position can be virtual.
The successful candidate will:
Work with the Innovate Team to develop and support critical business solutions & projects, including the Vegetation & Asset Management Solution.
Collaborate with development, reporting and business intelligence platforms
Building Cloud Data Marts & Warehouse, Data as a Service & Business Intelligence Solutions
Identify, design, and implement internal process improvements: automate manual processes, optimizing data delivery, re-designing workflow for improved efficiency
Maintain a stable data integration, delivery, and storage solution for the organization & our customers
Design, build and maintain scalable, automated data pipelines to enable field-based data capture and desktop reporting, visualization & analysis.
Continually improve processes and solutions, seeking ways to use new tools, features, and capabilities.
Knowledge, Skills and Experience
Tertiary qualifications in information technology, computer science, business, mathematics, engineering, or related field
Minimum 5 years professional experience in data engineering
Solid experience with data warehouse or modern data platform solutions
Experience in ETL development for different frequencies (real-time, near real-time, batch) and data streams.
Solid knowledge of architecture and design for Data Marts, DWH, and Data Lakes.
An understanding of microservice architectures
Good knowledge of Python, Java, and/or JavaScript.
Experience with software development life cycle
Docker and Kubernetes exposure is desirable
Exceptional listener and communicator who effectively conveys information verbally and in writing.
Understanding of technology platforms including FME, Integromat/Make & Power BI is preferred.
Knowledge of or experience working with utility and or government clients (desirable).
Pre-Screen
Upon offer, employees may be required to complete and pass a pre-employment drug screen, background, and/or MVR check.
Physical Requirements:
Rarely: walking, Kneeling, Squatting, Crawling, Climbing, Color Vision, Lifting, Carrying, Pushing, Pulling, Climbing Ladders, Balancing, Lifting up to 10lbs, Lifting 10lbs to 50lbs, Lifting over 50lbs.
Occasionally: Standing, Stooping, Body Twisting, Seeing Distant, Climbing On/Off Truck, Gripping, Reaching, Range of Motion, Depth Perception, Climbing Stairs.
Frequently: Sitting, Sense of Touch, Manual Dexterity, Speaking Clearly, Reading, Hearing-Speech Range.
Constantly: Seeing.
Safety
Due to the inherently dangerous nature of the industry and requirements to work with or around hazardous equipment, employees must have sufficient eyesight to judge distance/coordination of equipment and tools, be able to maintain attention and concentration for extended periods, be able to withstand exposure to all kinds of weather while completing work assignments, be able to wear personal protective equipment as necessary, be able to enter and exit a vehicle numerous times a day, have the endurance necessary to traverse various terrain, be capable of performing job duties throughout a standard 8- or 10-hour day, be able to communicate with others, read, write, and comprehend written/verbal job instructions and information, and communicate and handle conflict professionally.
Able to identify job site hazards.
Exhibits and carries out cognitive problem-solving skills.
Able to read, comprehend, and visualize job build and all prints.
Works near/around energized, hazardous parts and equipment.
Exposed to traffic.
Works around excessive noise from machines (bore drill, backhoe, trencher, mini excavator, bucket trucks, digger derricks, concrete saw, jackhammers).
May be exposed to hot and cold environments, poisonous plants or reptiles, and stinging insects.
About Us:
As a full-service utility contractor, Asplundh performs tree pruning and removals, right-of-way clearing and maintenance, vegetation management with herbicides, and emergency storm work and logistical support. Asplundh is the parent company of UtiliCon Solutions whose subsidiaries provide overhead and underground line construction, planning and design, meter reading and AMR/AMI installation, electrical testing, and street lighting/traffic signal services. Asplundh also operates Rotor Blade Airborne Utilities Management, overhead electric distribution, and transmission lines using MD 500 helicopters.
Individuals must be able to perform the essential functions of the position with or without reasonable accommodation. Individuals with a disability who desire a reasonable accommodation should contact the ADA Coordinator at 1-800-248-8733, ext. 1339.
An Equal Opportunity Employer.",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Meta
3.9",3.9,"Fremont, CA","Civil Engineer, Data Center Design","Meta is seeking a high-performing Civil Engineer to join the DEC Design Team. In this role, you will provide civil engineering subject matter expertise and leadership for Data Center designs and systems with the goal of deploying concepts at scale in a global environment.The Design Leadership & Standards (DL&S) Team is comprised of in-house engineers and architects who focus on streamlining our Data Center design program to enable fast deployment by the site-specific design teams. We also focus on technical evaluation of new data center concepts and technologies as well as staying engaged with emerging industry trends and building codes.The ideal candidate will have strong leadership skills, a proven track record in proactive cross-functional and team leadership, a strong background in all aspects of site development as well as experience working on large industrial development projects within a global portfolio. A thorough understanding of interdependent disciplines, such as electrical and fiber, is strongly desired. This person shall be detail-oriented, possess strong organizational skills, and be a self-starter that can excel with little direction. As an Owner Rep, the individual will be required to negotiate between competing priorities, manage risk to the business, and be held accountable for consultant performance.Our data centers are the foundation upon which our software operates enabling innovation for the company. Building and operating data centers the ""right"" way from the day they go live is synonymous with ensuring capacity availability and capital conservatism. The data center design team approaches facility design from the chips on the server boards to the facility mechanical and electrical distribution systems which ensure and maximize efficiency of our compute infrastructure. This position is full-time.


Civil Engineer, Data Center Design Responsibilities:
Provide Civil and Geotechnical technical review and oversight of new data center designs
Provide Civil and Geotechnical technical support for site selection, due diligence, master planning and permitting.
Engage with Meta stakeholders, external architectural and engineering consultant teams, authorities having jurisdiction and site contractors to ensure that Meta’s data center design standards and quality are met.
Typical work tasks can include geotechnical report review, topographic and boundary survey review, traffic impact study evaluation, evaluation of site-specific schedules , review of offsite infrastructure plans, review of site civil plans including mass grading, site utilities or early enablement packages, coordination with AHJs and consultant teams.
Provide guidance as needed associated to overall construction schedule impacts from early civil works across all disciplines.
Lead program improvements to Meta’s civil and geotechnical design standards and support development of new products for civil discipline.
Travel (around 25%) to datacenter sites when needed for engineering studies, systems audits, testing, and commissioning
Participate in system failure or related incident Root-Cause-Analysis (RCA)
Respond on an as-needed basis to emergencies



Minimum Qualifications:
Bachelor’s Degree in Civil Engineering, or related field
Professional Engineer registration, or European equivalent
Experience creating technical playbooks, standards, and template documentation for use within a portfolio of facilities
Experience working on a program which includes global engineering
Minimum of seven (7) years professional experience supporting large industrial campus site and utility planning and construction
Experience managing the production of site infrastructure documents including preliminary utility, grading, and drainage plans as well as roadway infrastructure
Knowledge of Geophysics and Geotechnical engineering, including soil mechanics, grading, stormwater management, and erosion/sediment control engineering
Knowledge of campus planning strategies and regulatory processes, entitlement, and permitting
Knowledge of mission critical building systems, including mechanical, electrical, fire protection, structural, and architectural systems
Knowledge of industry standards, building codes and safety standards including IBC, ASCE, and European equivalents
Experience with troubleshooting and problem solving
Experience providing solutions to complex projects under pressure
Effective communications skills, fluent in English
Working knowledge of AutoCAD Civil 3D, Infraworks, ArcGIS, MS office, StormCAD, Hydroflow, ICPR or other industry accepted software



Preferred Qualifications:
Knowledge of mission critical projects (e.g. data centers, aviation, industrials, etc.)
Master’s Degree in Civil Engineering or related field
LEED Accreditation
Experience performing Program or Project Management, PMP Certification
Experience directly supporting data center engineering and construction
Experience in managing design consultants from the owner’ side



About Meta:
Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.


Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$198,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Encore Technologies
4.5",4.5,"Louisville, KY",Data Center (ACI/Nexus) Network Engineer/Architect,"Data Center (ACI/Nexus) Network Engineer/Architect
Job Details
City :
Louisville
State :
KY

Job Description:
Encore is seeking a Data Center (ACI/Nexus) Network Engineer/Architect. Focus is on route/switch/network management in a large enterprise data center environment.

Responsibilities:
Perform design and deployments for the Cisco data switching technology including Nexus/ACI with Nexus Dashboard
Troubleshoot and resolve tier2/3 data center network issues
Address and resolve escalated issues for routing/switching in a large data center environment.
Assist in the design/deployment of new locations and new solutions.
Design/deploy solutions that scale and adhere to data security standards
Manage project tasks
On-call one week every 2 months

Qualifications:
Experience with Aruba 3810/5412/6200/6300 switches, Cisco 5K,7K,9Ks, ASR platforms and the associated management platforms (IOS, NXOS, ArubaOS, Aruba CX)
Strong understanding of routing/switching protocols
Experience with Aruba ClearPass as a NAC solution would be valuable in this role
Data center experience with load-balancing and firewalls would be a plus
Must be a self-starter, able to manage project tasks on your own

Encore Technologies is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills, and experiences within our workforce.","$112,806 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,2014,$100 to $500 million (USD)
"Northrop Grumman
4.0",4.0,"Annapolis Junction, MD","Principal / Sr. Principal Configuration Data Management Systems Engineer, TC","Requisition ID: R10127942
Category: Engineering
Location: Linthicum, Maryland, United States of America | Annapolis Junction, Maryland, United States of America+ 1 more
Citizenship required: United States Citizenship
Clearance Type: Polygraph
Telecommute: No- Teleworking not available for this position
Shift: 1st Shift (United States of America)
Travel Required: Yes, 10% of the Time
Relocation Assistance: Relocation assistance may be available
Positions Available: 1
At Northrop Grumman, our employees have incredible opportunities to work on revolutionary systems that impact people's lives around the world today, and for generations to come. Our pioneering and inventive spirit has enabled us to be at the forefront of many technological advancements in our nation's history - from the first flight across the Atlantic Ocean, to stealth bombers, to landing on the moon. We look for people who have bold new ideas, courage and a pioneering spirit to join forces to invent the future, and have fun along the way. Our culture thrives on intellectual curiosity, cognitive diversity and bringing your whole self to work — and we have an insatiable drive to do what others think is impossible. Our employees are not only part of history, they're making history.
Join Northrop Grumman on our continued mission to push the boundaries of possible across land, sea, air, space, and cyberspace. Enjoy a culture where your voice is valued and start contributing to our team of passionate professionals providing real-life solutions to our world’s biggest challenges. We take pride in creating purposeful work and allowing our employees to grow and achieve their goals every day by Defining Possible. With our competitive pay and comprehensive benefits, we have the right opportunities to fit your life and launch your career today.
The Northrop Grumman Mission Systems (NGMS) Advanced Processing Solutions Business pushes the boundaries of innovation, redefines the leading edge of exotic new technologies, and drives advances in the sciences. One of our most challenging new fields is Transformational Computing, which combines the unique properties of superconductivity and quantum mechanics to develop radical new energy-efficient computing systems. Our team is chartered with providing the skills to transform computing beyond Moore’s Law, advancing development of computer architectures, processing/memory subsystems, and large-scale high-performance computing systems. You’ll work in a R&D environment alongside a broad array of scientists and engineers to make these processing solutions a reality and deliver remarkable new advantages to the warfighter.
The Systems Engineering Integration & Test (SEIT) section is seeking a dedicated Configuration Data Management representative to join our team of qualified and diverse individuals to assist Engineering with Product Lifecycle Management (PLM) System support.
This role functions as a Configuration Data Management (CDM) System Engineer, primarily supporting SEIT, Software developers, and customers for the audit, configuration, and release of software products, test procedures and documentation to the various testing and operation environments. The CDM representative contributes to the product configuration and release management of products supporting the TC OU day-to-day activities.
In this role, the selected candidate, will perform the following responsibilities:
Identification
Assign and control program hardware / software data identification control numbers per program & Functional Home Room (FHR) mandates.
Enforce & assign part & serial number requirements.

Change Management
Perform Technical Review Board and Configuration Control Board activities.
Establish agendas, publish minutes & track meeting actions.
Process change packages through lifecycle include disposition & documentation / hardware implementation.
Perform program data release functions via Product Lifecycle Mgmt. tools.

Configuration Status Accounting
Development & maintain various CDM reports for program support. Example, Configured Item Identification List, Engineering Change Request status, CDM performance metrics.
Verification and Audits
Support internal program CDM audits against program SOW & Functional Command Media mandates.
Provide aid to Functional Configuration Audits & perform Physical Configuration Audit.
Document Management for deliverable CDRLs and non-CDRL documents.
This position will serve on-site in Linthicum/ Annapolis Junction, MD.
This position can be filled at a higher grade based on the requirements below.
Basic Qualifications for Principal Configuration Data Management Systems Engineer:
Bachelor's Degree or higher in a STEM discipline (Science, Technology, Engineering, Math) such as Electrical Engineering, Computer Engineering, Computer Science, Aerospace Engineering, Physics, or a similar technical discipline with 5 years of related experience, or 3 years with a Master's Degree, or 0 years with a PhD.
Experience working in a configuration management product life cycle system (i.e., Agile PLM, Teamcenter, CMPro, etc.)
Excellent written, verbal communication and presentation skills, strong social skills, and ability to build consensus among peers while buildings solid relationships and trusts with internal team members and customers.
Work overtime and weekends when necessary to support mission goals.
This position requires the applicant to be a U.S. citizen with the ability to obtain and maintain a TS/SCI with poly clearance per business requirements.
Basic Qualifications for Sr. Principal Configuration Data Management Systems Engineer:
Bachelor's Degree or higher in a STEM discipline (Science, Technology, Engineering, Math) such as Electrical Engineering, Computer Engineering, Computer Science, Aerospace Engineering, Physics, or a similar technical discipline with 9 years of related experience, or 7 years with a Master's Degree, or 4 years with a PhD.
Experience working in a configuration management product life cycle system (i.e., Agile PLM, Teamcenter, CMPro, etc.)
Excellent written, verbal communication and presentation skills, strong social skills, and ability to build consensus among peers while buildings solid relationships and trusts with internal team members and customers.
Work overtime and weekends when necessary to support mission goals.
This position requires the applicant to be a U.S. citizen with the ability to obtain and maintain a TS/SCI with poly clearance per business requirements.
Preferred Qualifications of Principal / Sr. Principal CDM Systems Engineer:
Active TS/SCI with poly security clearance.
Ability to adjust to changing priorities and requirements.
Ability to analyze/audit software products and documentation handoff from the developers.
Familiar with Git/Gitlab commands and continuous integration/development (CI/CD) methodology.
Experience working in an Enterprise Resource Planning (ERP) or Material Requirements Planning tool (MRP) (i.e. Oracle, SAP, etc.)
Salary Range: $99,800 - $149,800
Salary Range 2: $123,800 - $185,800
Employees may be eligible for a discretionary bonus in addition to base pay. Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results. Employees in Vice President or Director positions may be eligible for Long Term Incentives. In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.
The health and safety of our employees and their families is a top priority. The company encourages employees to remain up-to-date on their COVID-19 vaccinations. U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO. U.S. Citizenship is required for most positions.","$124,800 /yr (est.)",10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1939,$10+ billion (USD)
"Lockheed Martin
4.1",4.1,"Nellis AFB, NV",Flight Test Data Processing Engineer - Level 4,"Job ID: 652409BR
Date posted: Sep. 19, 2023

Description:We are Lockheed Martin

Lockheed Martin Aeronautics Be More Than You Can Imagine.

At Lockheed Martin Aeronautics, we're taking innovation to the next level. From designing the most advanced air vehicle to designing aircraft that defies gravity, our engineers live on the cutting edge of technology. Never have the opportunities for a technical career been so limitless.

Join us as a Lockheed Martin Aeronautics Flight Test Data Processing Engineer. In this role, you'll interact directly with the customer as you perform tasks in preparing pre- and post-processing flight test data products, act as the system administration and IT system build expert, and otherwise support the world's premier aircraft.

Some shift, extended hours, weekend work and travel may be required

** Must be a US Citizen. This position is located at a facility that requires special access. No dual citizenship will be considered.

**

A level 4 employee typically has 9-14 years of professional experience.

What's In It For You
Our employees play an active role in strengthening the quality of life where we live and work by volunteering more than 850,000 hours annually.

Here are some of the benefits you can enjoy:
Medical, dental, 401k, paid time off, work/life balance, career development, mentorship opportunities, rewards & recognition

Learn more about Lockheed Martin's comprehensive benefits package here.
REF: Engineering, Aeronautics, aeroTE, aeroFTDPE

Basic Qualifications:
Bachelor's degree.
At least nine years of professional experience.
Data processing expertise in preparing for flight tests, post-processing, and resolving network and instrumentation issues.

Desired Skills:
ABET-accredited bachelor's or higher degree in computer science, engineering, or related field.
Security+ certification.
Understanding of IRIG 106 Standards.
System administration abilities such as software installation, server and workstation administration, Active Directory management, user account setup, database support, scripting, Linux and Solaris use, backups, security audit compliance, etc.
Software programming and scripting experience.
Hardware troubleshooting background in communication protocols using related test equipment and tools.

Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.
Clearance Level: Secret
Other Important Information You Should Know
Expression of Interest: By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.
Ability to Work Remotely: Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.
Work Schedules: Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.
Schedule for this Position: 9x80 every other Friday off
Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They're dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin's vast team works with partners around the world to bring proven performance to our customers' toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.
Experience Level: Experienced Professional
Business Unit: AERONAUTICS COMPANY
Relocation Available: Possible
Career Area: Aeronautical Engineering
Type: Full-Time
Shift: First",#N/A,10000+ Employees,Company - Public,Aerospace & Defense,Aerospace & Defense,1995,$10+ billion (USD)
"NSC Global
3.9",3.9,"Waukegan, IL",Data Center Engineer,"Job Title: Data Center - Smart Hands Engineer
Location: Waukegan, Illinois 60085
Duration: Fulltime/Permanent
Job Description:
On General network failure with Back Office support infrastructure then Hands and Eyes resource will be guided by the BO teams to find a resolution in line with the account TDA
Responsibilities:
Daily backup Tape change in LR data centre (Approx 40 Servers)
Weekly Tape change at Weekend in LR data centre (on Saturday as per rota)
Yearly Tape schedule for Abbotts to be created
ITSM change, stage, and call management to be managed for the Hands & Eyes support group in ITSM.
Daily Restore requests when raised to be managed with the Back Office (BO) team. Tape mounting box recalls, and management of tape boxes
Assist with Server room Audits
Take direction from Wintel and backup teams on hardware issues
Escort 3rd party vendors in to LR data centre as arranged by BO teams.
Ensure that work undertaken is managed via the ITSM management system
Effective communication with both Service Delivery Management Team and the client as required.
To perform ITSM stages (relevant to Hands & Eyes role) in line with the clients DR procedure at Greenwich DC
Qualifications:
Excellent written and verbal communication skills, comfortable taking a lead role in client communication.
Familiar with: Incident, Problem and Change Management,
Demonstrable organizational, analytical and methodical problem solving abilities, prioritizing and escalating when required
Experience of working within Data Centres
Escalation of potential serious or business impacting issues where necessary
Proven ability to ‘own’ issues and apply initiatives to ensure all delegated tasks are followed through to conclusion
Expected to take part in an weekly tape change rota, work overtime as and when required and may need to visit other 3rd party associated sites
nscglobal provides global network implementation and support solutions to world-class organizations, delivering cost savings and operational simplicity. Our goal is to partner with world-class enterprises, helping them become more agile, create commercial advantage and build quality through design, deployment, support and management of their global IT communications. nscglobal are a US & European CISCO Technology GOLD PARTNER with a corporate headquarters in London, UK and a US headquarters in New York, NY. Please review our website at www.nscglobal.comfor more information on our organization.
Title: Data Center - Smart Hands Engineer
Length: Full Time/Permanent
Location: Waukegan, Illinois 60085
PLEASE NOTE– WE ARE NOT AN AGENCY BUT THE ACTUAL EMPLOYER.
I would love to discuss this opportunity in greater detail and will make myself available at your convenience – let me know what works best for you.
Thanks in advance and I look forward to hearing from you!
Job Type: Full-time
Pay: $28.00 per hour
Schedule:
8 hour shift
Ability to commute/relocate:
Waukegan, IL 60085: Reliably commute or planning to relocate before starting work (Required)
Experience:
Computer networking: 1 year (Preferred)
LAN: 1 year (Preferred)
Security clearance:
Confidential (Preferred)
Work Location: In person",$28.00 /hr (est.),1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,1997,Unknown / Non-Applicable
"Amazon Data Services, Inc.
3.7",3.7,"Chicago, IL","Data Center Cable Infrastructure Engineer , DCC Communities","2+ years of Data Center Experience
2+ years of Structured Cable Support
Experience working with vendors and managing vendors for project related work
Experience deploying and installing capacity either server or network
Amazon Web Services (AWS) is looking for an Cable Infrastructure Engineer to join our growing team within infrastructure operations. This Engineer is the go-to for Network and Server Capacity expansion projects. This person is involved with installation and troubleshooting of structured cabling, management of infrastructure inventory at multiple levels, physical installation of network and server racks and/or devices and management of data center services vendors. This person is also the prime go-to for project managers and site management to ensure expansion projects are completed on time and meet Amazon Deadlines.

You will work in a dynamic environment to drive the stability and sustainability of our next-generation networks and assist in the development of innovative ways to automate and scale our network.

To be successful in this role you should possess technical aptitude, written and oral communications skills and the ability to deal effectively with people in a wide variety of situations. In addition, you must possess strong analytical skills with demonstrated problem solving ability. You will be able to leverage your experience exercising high levels of initiative, judgment, and diplomacy.

Key job responsibilities
Partnering and working closely with Cabling vendors
Microsoft excel
Ensuring vendors are adhering to cabling standards
Work with network engineer to define physical layer topology of network links.
Define cabling pathway for devices within the racks and perform position audit to ensure cable pathway accuracy
Vendor engagement and supervision.
Define scope of work (SoW) for external vendor depending on project needs.
Manage work and priorities through ticketing system and workflows to complete customer requests and projects
Respond to communication, information, and emergencies via internal tools
Up to 25% travel within geographical work area may be required; some travel outside traditional work area may be requested
A day in the life
Report current status via ticketing system, status reports, and email
project tracking systems, updating tasks that need to be completed
Maintain accurate records and document problems and processes
Coordinate/escalate with project stakeholders to resolve project blockers.
Exhibit quality workmanship on all work and maintain site cleanliness
Manage, check and coordinate all materials to be delivered to site daily
Ensure that the Data Center Installations comply with all installation practices
Installation and maintenance of copper and fiber cable infrastructure
About the team
Chicago's Edge team, up until 2023, consists of Burrows and Edge cages throughout the metro region. We are excited to bring up ORD064 as a new site in our portfolio and the increased complexity and scaling for our customers.

We are open to hiring candidates to work out of one of the following locations:

Chicago, IL, USA

3+ years Data center experience
Industry standard certifications (BICSI, CompTIA, Cisco, CCNA etc.)
Working knowledge of Layer 1 troubleshooting
Knowledge of network cabling, optic types, and test equipment
Experience with medium to large, complex project scopes and ambiguous details within work environment
Proficient with MS Excel
Switch configuration experience
Experience creating and executing SOPs
Experience creating and issueing SOW (Scope of Work) to venders
Ability to manage small to medium site projects
Ability to multitask and take direction from multiple peers, managers and project managers.
BS degree in a technical field
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","$80,202 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Amaze Systems
5.0",5.0,"Houston, TX",Sr. Data Engineer ( W2 ONLY) (10 years of experience),"TOP SKILLS
5+ years of experience as a Data Engineer (Designing and Maintaining Data Pipeline Architectures)
5+ years of Programming Experience (Python & SQL)
Experience with ETL, ELT, Pub/Sub, and Change Data
Experience with pandas, Numpy, PyArrow, PyTest, Boto3
**Experience with implementing a Data Lakehouse using Apache Airflow, Kubernetes, and S3 Object Storage
Job Type: Contract
Salary: $65.00 - $70.00 per hour
Ability to commute/relocate:
Houston, TX 77002: Reliably commute or planning to relocate before starting work (Required)
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: In person",$67.50 /hr (est.),Unknown,Company - Public,Media & Communication,Advertising & Public Relations,#N/A,Unknown / Non-Applicable
"GlobalLogic
3.9",3.9,"Dallas, TX",Data engineer IRC191735,"Job:
IRC191735

Location:
United States - Dallas TX

Designation:
Senior Software Engineer

Experience:
5-10 years

Function:
Engineering

Skills:
Python

Work Model:
On-Site/Office

Description:
Experience in working with different Cloud Environment/s (AWS preferred)
Hands-on experience with SQL database design, ETL Tools/scripts
Requirements:
Preparing relevant documentation
Reporting of progress and delivered scope.
Bachelor’s or Master’s degree in Computer Science, Computer or Electrical Engineering, Mathematics, or a related field.


Preferences:
Previous experience as a data engineer or in a similar role
Technical expertise in data models, data mining, and segmentation techniques
Good Knowledge of programming languages (e.g. Scala and Python (Preferred))


Job Responsibilities:
Great numerical and analytical skills.
Implementing, and optimizing data pipelines
Working with different stakeholders and other team members


What We Offer
Exciting Projects:Come take your place at the forefront of digital transformation! With clients across all industries and sectors, we offer an opportunity to work on market-defining products using the latest technologies.
Collaborative Environment: You can expand your skills by collaborating with a diverse team of highly talented people in an open, laidback environment — or even abroad in one of our global centers or client facilities!
Work-Life Balance:GlobalLogic prioritizes work-life balance, which is why we offer flexible work schedules and opportunities to work from home.
Professional Development:We provide continuing education classes, professional certification and training (technical, soft skills, language, and communication skills) to help you realize your professional goals. Being part of a global organization, there are additional learning opportunities through international knowledge exchanges.
Excellent Benefits:We provide our employees with competitive salaries, health and life insurance, short-term and long-term disability insurance, a matched contribution 401K plan, flexible spending accounts, and PTO and holidays
About GlobalLogic
GlobalLogic is a leader in digital engineering. We help brands across the globe design and build innovative products, platforms, and digital experiences for the modern world. By integrating experience design, complex engineering, and data expertise—we help our clients imagine what’s possible, and accelerate their transition into tomorrow’s digital businesses. Headquartered in Silicon Valley, GlobalLogic operates design studios and engineering centers around the world, extending our deep expertise to customers in the automotive, communications, financial services, healthcare and life sciences, manufacturing, media and entertainment, semiconductor, and technology industries. GlobalLogic is a Hitachi Group Company operating under Hitachi, Ltd. (TSE: 6501) which contributes to a sustainable society with a higher quality of life by driving innovation through data and technology as the Social Innovation Business.","$120,462 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2000,$500 million to $1 billion (USD)
"Amazon Data Services, Inc.
3.7",3.7,"Herndon, VA","Data Center Regional Mechanical Engineer (Field Engineering), Field Engineering - AMER","Bachelor’s Degree in Mechanical Engineering or equivalent experience.
6+ cumulative years of experience with industrial or commercial engineering in Mission Critical facilities including but not limited to: data centers, power generation, oil / gas facilities. (Experienced Engineer)
As an Amazon Field Engineer, you will provide full life-cycle support to AWS Data Centers from design inception through site improvement and maintenance. You will be the ‘go to’ engineering resource for your region when technical advice is needed, and will use your subject matter expertise and engage with diverse teams to:
Troubleshoot, conduct Root Cause Analysis (RCA) and create Corrective Action (CA) documentation for site/equipment failures.
Directly support operational issues with ad-hoc training, complex operating procedure reviews, including critical equipment, and event support.
Own the conceptual design for existing data center upgrades and design-solutions, which add capacity, improve availability, and increase efficiency.
Interface with internal data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.
Work on concurrent projects, sometimes in multiple geographical regions.
Initiate and lead engineering audits including on-site visits within Amazon’s owned or colo data centers. Produce reports outlining risks with recommended mitigations and remediations
Act as resident engineer during new construction projects. Support construction, commissioning, and turnover.
A day in the life
Amazon's vision is to be the world's most customer-centric company, and this role is key to that vision. As a Field Engineer, you will be leading projects to fit out our data centers to meet ever-evolving customer needs as we continue expanding our fleet to hyper-scale. As an ideal candidate you:
Possess Strong Engineering Judgement and are able to provide recommendations despite uncertainty
Are detail and data oriented
Have experience managing engineering projects and consultants.
Build trust and relationships with different stakeholders (e.g., Operations, Commissioning, Construction and Design)
Are adaptable and inclined to get into the field to see things up close
Each day you will interact with different teams responsible for all aspects of the data centers. You will prioritize your activities to support data center capacity availability and safety focusing on the actions that are most impactful. You will have the opportunity to work on projects locally and globally.

We have an immediate opening for a Field Engineer in northern Virginia. If you meet these qualifications, exude passion, and enjoy the challenge of innovative projects at hyper-scale, this job is for you!

About the team
Why AWS?
About AWS
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud
platform. We pioneered cloud computing and never stopped innovating — that’s why customers
from the most successful startups to Global 500 companies trust our robust suite of products and
services to power their businesses.

Inclusive Team Culture
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster
a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning
experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender
diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth
We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.
That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing
resources here to help you develop into a better-rounded professional.

We are open to hiring candidates to work out of one of the following locations:

Herndon, VA, USA

Organized and have the ability to set priorities and meet deadlines and budget
Possess leadership and problem-solving skills
Experience using a variety of web based and other software tools for calculation and data processing.
Direct experience with the design, construction, operation, or maintenance of mission critical facilities, especially data centers.
Experience as resident engineer or hands-on (in the field) design consultant.
Knowledge of building codes and regulations for your region.
Experience reading, interpreting, and creating construction drawings, specifications, and submittal documents.
Ability to carry design concepts through exploration, development, and into deployment/mass production
Possess excellent communication and writing skills, attention to detail, maintain high quality standards
Basic understanding of both mechanical, instrumentation, and electrical equipment/design related to data centers (Including but not limited to: uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc...)
EPMS/SCADA/BMS Controls system experience (software and/or hardware)
Registered Professional Engineer
Advanced degree in engineering, business, or related field.
Have fluent knowledge of continuous operating redundant electrical systems, cooling systems, air flow containment systems and building management systems. (Including but not limited to: uninterruptable power sources, AC/DC conversion, P&ID loops, diesel generators systems and complex arrangements, direct evaporative cooling systems, etc...)
Ability to develop solutions and execute plans on complex projects
Previous ownership of fast track design/build projects and or multiple significant upgrade projects
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","$101,618 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Finch Computing
3.3",3.3,"Chantilly, VA",Data Engineer - TS/SCI with Polygraph,"Clearance: ** TS/SCI with POLYGRAPH REQUIRED**
Location: Chantilly, VA ** ONSITE EVERY DAY***
Data Engineer

Finch AI is a fast-growing, fast-paced software development organization; our mission is to build new ways of interacting with information. We do that by leveraging game-changing intellectual property, cloud infrastructure expertise, and a staff that is second to none. Together, we build and support products that address complex, real-time data and analytics needs in the enterprise.
As a Finch AI Data Engineer, you join a dynamic and agile team in the development of new Finch products. We look for strong Data Engineers that thrive on solving challenges associated with creating new products and developing intellectual property. Our teams are comprised of successful people that enjoy solving problems, engaging in substantive technical discussions and have passion for their work. We have very high expectations in terms of skill, motivation, self-organization and productivity. We look for people who excel working in groups, virtual and collocated, as well as those who are comfortable with fast paced agile development.
We are seeking multiple Data Engineers to work with a federal client to rapidly develop innovative solutions for the clients’ immediate mission challenges. In your role, you will work with a team of developers, data scientists, SMEs, and cyber analysts to design, develop, build, and analyze data management systems. You will be asked to analyze our client’s challenges and provide solutions by identifying and applying new tools and technologies to help design new data repositories. Working alongside the team and cyber analysts, you will perform data engineering to identified data sets. As a Data Engineer your responsibilities will include designing, developing, optimizing, and maintaining data architecture and ETL pipelines.

Responsibilities:
Develop robust data platforms for analytics platforms
• Develop and perform ETL on large datasets
• Develop data visualizations to showcase valuable insights extracted from large volumes of data
• Create and optimize data pipeline architectures
• Support infrastructure and data querying process
• Work in an Agile environment
Required Skills:
Open to all levels: Junior through Expert
Programming languages include: Python, SQL, Java.
Database experience with any of the following: PostgreSQL, MySQL, Oracle, MongoDB
Experience working with Docker, Kubernetes
Proficient with git and pull request workflows.
ETL experience for data pipelines
Ability to perform API service development.
Bachelors degree in related field

Preferred:
Hadoop and Spark","$95,045 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2014,Unknown / Non-Applicable
"Texas Comptroller of Public Accounts
3.5",3.5,"Austin, TX","THECB - Data Analyst IV, Data Engineer","THECB - Data Analyst IV, Data Engineer (00036495)
Organization: TEXAS HIGHER EDUCATION COORDINATING BOARD
Primary Location: Texas-Austin
Work Locations: TX Hghr Edu Coordinating Board 1801 Congress Ave Austin 78701

Job: Computer and Mathematical
Employee Status: Regular
Schedule: Full-time
Standard Hours Per Week: 40.00
Travel: Yes, 5 % of the Time
State Job Code: 781U
Salary Admin Plan: N/A
Grade: 00
Salary (Pay Basis): 6,597.00 - 7,431.00 (Monthly)
Number of Openings: 1
Overtime Status: Exempt
Job Posting: Sep 21, 2023, 3:59:09 PM
Closing Date: Oct 12, 2023, 11:59:00 PM
Description

THECB is observing a hybrid telecommuting schedule with employees required to be in the office at least two (2) days per week.
The agency is located at the George Herbert Walker Bush Building located in the Capitol Complex at 1801 N Congress Ave. Austin, TX 78701.

General Description:
Performs complex (journey-level) data engineering and analysis work within the Data Management and Reporting (DMR) division. Assists with the development and integration of a data analytics and business intelligence environment that aligns with the mission, vision, strategy, and goals of THECB leadership. Work involves building data pipelines; integrating, consolidating, cleansing, and structuring data for analytical applications; data modeling; and implementing and managing database systems, data warehouses, and data marts. May provide guidance to others. Works under general supervision, with moderate latitude for the use of initiative and independent judgment. This position reports directly to the Director of Data DevOps on the Data Management team.
General Duties and Responsibilities:
Analyzes data using standard statistical tools, methods, and techniques
Consults with internal and external customers to identify user needs
Compiles and queries data
Identifies data gaps, errors, anomalies, inconsistencies, and redundancies by analyzing the content, structure, and relationships within data
Interprets results to identify significant differences in data
Identifies and interprets data patterns and trends and assesses data quality
Cleans and prunes data to discard irrelevant information
Prepares concise, comprehensive technical reports to present and interpret data, identify alternatives, and make and justify recommendations on data revisions
Assists in defining, developing, and implementing data standards
Assists in developing data quality measures, analyzing data quality results, and implementing necessary changes to ensure data quality improvement
Assists in developing software applications or programming to use for statistical modeling and graphic analysis
Assists in developing and implementing databases, data collection systems, data analytics, and other strategies that optimize statistical efficiency and quality
May perform quality assurance and serve as a subject matter expert on data integrity, extraction, and compilation
May guide the selection of data management tools, and the development of standards, usage guidelines, and procedures for those tools
Knowledge, Skills, and Abilities:
Expertise in data pipelines and end-to-end data product lifecycle
Knowledge of industry standard project frameworks to deliver data platform and products (examples: Agile/Scrum Development & Management, Scaled Agile Framework)
Expertise in DataOps lifecycle (build, deploy, and production support)
Prior exposure to cloud infrastructure in AWS, Azure or GCP for analytic and data platform solutions spanning a range of services including storage, data movement, data lake management, and analytics
Broad understanding of data engineering and/or machine learning lifecycles and enablement, experiment and project tracking, and data version control
Prior work in a dynamic and complex solution ecosystem
Effective and engaging interpersonal skills with technical team members as well as business partners and able to distill complex ideas into straightforward language
Military Crosswalk: https://hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_PlanningResearchandStatistics.pdf

Qualifications

Required Minimum Education and Experience:
Graduation from an accredited four-year college or university with major coursework in data science, business analytics, computer science, computer information systems, or management information systems
2+ years’ experience working as a data analyst and/or modeler in a data warehouse, data lake, operational data store, or similar
Master’s degree from an accredited college or university, in a related field, may substitute for one year of required work experience for candidates
Preferred:
Experience working with Snowflake platform
3+ years of experience with advanced, end-user, data preparation and manipulation tools and languages: SAS, R, Python, Trifacta, SQL; be willing to adapt to new tools compliant with standards
Experience in technology platform architecture design, code refactoring and migration
Experience with ETL processes and skill in data transformation
Experience contributing to data transformation coding and documentation standards, code and data re-use approaches, designs and guidelines
Demonstrated experience working with supporting tooling aimed at workload management or tracking
Understanding of metadata management, data profiling and data quality rules
Work with data analysts and supporting IT teams to implement automated quality checks

Physical Requirements and/or Working Conditions:
Work is performed in a standard office environment and requires:
Regular, reliable, and punctual attendance at work;
Frequent use of personal computer, copiers, printers, and telephones;
Frequent sitting, and
Frequently working under deadlines, as a team member, and in direct contact with others.
Workforce:
Must be able to:
Demonstrate knowledge of customer service deliverables.
Show flexibility and adaptability toward changes in assignments and work schedules, working extended hours as necessary.
Adhere to the organization’s internal management policies and procedures.
Contribute to the agency’s performance measures and mission.
Travel occasionally for work assignments and training.

Application Requirements:
The Texas Higher Education Coordinating Board is an Equal Opportunity Employer. A State of Texas application is required to apply. For more information on how to apply for this position, go to the Coordinating Board’s employment opportunities website at http://www.thecb.state.tx.us/about-us/human-resources/career-opportunities/.
The Texas Higher Education Coordinating Board participates in E-Verify for each new employees’ Form I-9 to confirm work authorization. For questions, please call the HR Department at 512-427-6190. For vocal and/or hearing assistance call 7-1-1.
Notes to Applicant:
If you require any reasonable accommodation for the interview process, please inform the hiring representative who calls to schedule your interview. This position has been designated as a security sensitive position. A criminal background investigation will be conducted on the final candidate for this position.
Your job application must be completely filled out. Your application must contain dates of employment, job titles, name of employer and a description of duties performed in a way that demonstrates you meet the minimum qualifications for the position for which you are applying. Resumes do not take the place of the requirement to include this information on the application. If this information is not submitted, your application may be rejected because it is incomplete.
Veterans Information: THECB is committed to hiring Veterans. To receive Veteran’s Preference, a copy of the FORM DD214 -member #4, must be attached when submitting your application.
AN EQUAL EMPLOYMENT OPPORTUNITY EMPLOYER: THECB does not discriminate on the basis, of race, color, religion, sex, national origin, age, or disability in employment or the provision of services.
Job offer and continuation of employment with THECB is contingent upon:
Proof of education and experience listed on the application.
Eligibility/authorization to work in the U.S.
Satisfactory results from a pre-employment criminal history background check.
Compliance with the Selective Service Law for males ages 18-25. Please be advised that under Texas law, names and other information concerning applicants or nominees may be subject to disclosure upon request.
THECB does not allow dual employment with other state of Texas agencies or institutions.
Skills assessment may be conducted at time of interview
No phone calls or emails, please. Due to the high volume of applications, we do not accept telephone calls and cannot reply to all email inquiries. Only candidates selected for interview will be contacted.","$7,014 /mo (est.)",1001 to 5000 Employees,Government,Government & Public Administration,State & Regional Agencies,1835,Unknown / Non-Applicable
"Amazon Data Services, Inc.
3.7",3.7,"Austin, TX","Electrical Design Engineer, Data Center Design Engineering","Bachelor’s degree in an electrical engineering, or 6+ years of relevant electrical experience.
1+ year of experience with industrial or commercial electrical design.
1+ year experience developing design documentation (plans, specifications, etc) for construction and/or permitting.
Amazon Web Services is seeking a Jr. Electrical Engineer to become part of a global engineering team, responsible for the design and continuous innovation of our rapidly expanding data center foot print.

Engineers at Amazon work to design resilient, cost effective electrical distribution systems. As engineers at Amazon we are responsible for achieving a world class uptime for our customers. We justify and communicate the technical decisions we make to Sr. Management and work hard to drive continuous advancements and improvements with our designs. As an engineer at Amazon you have the ability to drive change and define/design the systems our customers rely on.

Amazon offers a fast paced, fun, and exciting work environment. We continue to grow at exponential rates and are looking for individuals that can support our speed to market, enjoy a challenge, and have a desire for professional growth and continuous learning experiences. Amazon’s work environment is unique in every aspect and offers an exceptional opportunity for the right candidate.

If you are a creative, smart and driven individual that enjoys working with complex problems we want YOU! At Amazon you will be responsible for working on multi-million dollar designs that support our array of businesses and wide variety of customers. Great ideas are encouraged and supported. Ingenuity is the main mechanism which supports our focus on quality, speed, and cost.

We are looking for engineers with hands on electrical design experience. If you can design an electrical system, have an understanding of the critical equipment needs for a data center, and understand the constructability of varying designs you may be a good fit. As we grow we are structuring our team to own more of our engineering in house. Engineers will be responsible for taking designs from concept to the permit and construction document set. You must be capable of defining critical equipment specifications and approving equipment submittals. Engineers will directly support construction and be a part of the process from site selection review through commissioning and ultimately turnover. At Amazon we highly support continued learning opportunities and focus on continued employee development.

At Amazon team work is absolutely necessary for us to accomplish our goals. You must be able to work within a team and depend on others to accomplish the required work. As an electrical engineer at Amazon you will be working with other internal groups as well as external groups including utilities, manufacturers, vendors, and contractors.

Amazon has a global presence. As this position is based out of Herndon, VA, travel to our data centers (located Northern Virginia and throughout AMER region), yearly team off-sites and vendor factory visits are required. Travel could be up to 20% of your time.

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Key job responsibilities

Responsibilities of the Jr. Electrical Engineer:
Under the direction of a senior engineer, the Jr. Electrical Engineer will be responsible for the following:
Data center electrical designs and collaboration with other disciplines to create a construction document set.
Creation of designs which meet or exceed our quality requirements and fall within our budgetary requirements.
Work with local agencies having jurisdiction to ensure compliance with federal, state and municipal requirements and building codes.
Review and approval of equipment submittals.
Define project scope and provide technical support for information requests prior to, and during construction phases.
Work with commissioning teams to properly test and validate installation, operation, and performance of electrical systems.
Ability to work on concurrent projects in multiple geographical regions.
Travel to sites for site review and work with onsite field engineers, as well as provide engineering evaluations, electrical systems audits, and startup as needed.
Having fun and offering creative, out of the box solutions.
About the team
Our team also puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren’t focused on how many hours you spend at work or online. Instead, we’re happy to offer a flexible schedule so you can have a more productive and well-balanced life—both in and outside of work.

Why AWS? About AWS Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.

Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.

We are open to hiring candidates to work out of one of the following locations:

Austin, TX, USA | Columbus, OH, USA | Herndon, VA, USA | Seattle, WA, USA

1+ years of experience directly related to data center or mission critical facility design.
Experience with large scale technical operations or large-scale compute farms.
Understanding of uninterruptable power sources, diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches and other mission critical electrical equipment.
Basic understanding of mechanical equipment and system design.
Experience with fast track design/build projects and or multiple significant upgrade projects.
Ability to research new designs, technologies, and construction methods of data center equipment and facilities.
An ability and willingness to think outside of the box to find creative and innovative solutions to reduce costs with no impact on quality, reliability, or maintainability.
Understanding of the National Electrical Code requirements.
Knowledge of building codes and regulations including Life Safety, IBC, NFPA, NEC, and OSHA.
Organized and have the ability to set priorities and meet deadlines.
Possess excellent communication skills, attention to detail, maintain high quality standards.
Possess leadership and problem solving skills.
Be a motivated, highly dependable individual.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $77,300/year in our lowest geographic market up to $219,700/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$77,300 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Paycom
3.5",3.5,"Oklahoma City, OK",Sr. Data Engineer,"This position will be located within the Development and IT space and work closely with computer scientists, IT and data scientists to build, deploy and optimize data pipelines and integrate data infrastructure for enabling analytics, reporting, and machine learning workloads at scale.

RESPONSIBILITIES
Build, test, and validate robust production-grade data pipelines that can ingest, aggregate, and transform large datasets according to the specifications of the internal teams who will be consuming the data
Deploy data pipelines and data connectors to production environments
Configure connections to source data systems and validates schema definitions with the teams responsible for the source data
Monitor data pipelines and data connectors and troubleshoot issues as the arise
Monitor data lake environment for performance and data integrity
Manage data infrastructure such as Kafka and Kubernetes clusters
Collaborate with IT and database teams to maintain the overall data ecosystem
Assist data science, business intelligence, and other teams in using the data provided by the data pipelines
Deploy machine learning models to production environments
Test proof-of-concept deployments of new technologies
Serve as on-call for production issues related to data pipelines and other data infrastructure maintained by the data engineering team
Education/Certification:
BS degree in Computer Science or related field
Experience:
3+ years of data engineering work experience
Experience coding in Java or Scala and build tools such as Maven, Gradle, and SBT
Experience with SQL databases
Experience working with HDFS or S3 storage environments
Experience with Apache Spark or Databricks and reading and writing Parquet, Avro and JSON
Experience working in a Unix or Linux environment, including writing shell scripts
Experience with ETL and ELT processes in data pipelines
Experience with Docker and Kubernetes highly preferred
Experience with workflow orchestration tools like Apache Airflow, Control-M, or Arrow highly preferred
Experience with Apache Kafka or Confluent is preferred

PREFERRED QUALIFICATIONS
Experience:
Experience coding in Python
Experience with NoSQL solutions is helpful
Skills/Abilities:
Strong expertise in computer science fundamentals: data structures, performance complexities, algorithms, and implications of computer architecture on software performance such as I/O and memory tuning.
Working knowledge software engineering fundamentals: version control systems such as Git and Github, workflows, ability to write production-ready code.
Knowledge of data architecture and data processing engines such as Spark and Hadoop.
Ability to create SQL queries of moderate complexity.
Knowledge of Java or Scala.
Knowledge of Apache Spark
Knowledge of Python, R, C#, or PHP is helpful.
Knowledge of HDFS and S3 storage environments
Strong trouble-shooting skills.
Knowledge of technical infrastructure.
Strong technical aptitude.
Has strong critical thinking skills and the ability to relate them to the products of Paycom.
Demonstrates excellent verbal and written communication skills.

Paycom is an equal opportunity employer and prohibits discrimination and harassment of any kind. Paycom makes employment decisions on the basis of business needs, job requirements, individual qualifications and merit. Paycom wants to have the best available people in every job. Therefore, Paycom does not permit its employees to harass, discriminate or retaliate against other employees or applicants because of race, color, religion, sex, sexual orientation, gender identity, pregnancy, national origin, military and veteran status, age, physical or mental disability, genetic characteristic, reproductive health decisions, family or parental status or any other consideration made unlawful by applicable laws. Equal employment opportunity will be extended to all persons in all aspects of the employer-employee relationship. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, training, promotion, discipline, compensation benefits, and separation of employment. The Human Resources Department has overall responsibility for this policy and maintains reporting and monitoring procedures. Any questions or concerns should be referred to the Human Resources Department. ****To learn more about Paycom's affirmative action policy, equal employment opportunity, or to request an accommodation - Click on the link to find more information: paycom.com/careers/eeoc

#LI-Hybrid","$90,582 /yr (est.)",1001 to 5000 Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1998,$1 to $5 billion (USD)
"Amazon Data Services, Inc.
3.7",3.7,"Hermiston, OR","Data Center Regional Electrical Engineer (Field Engineering), Field Engineering","Bachelor’s Degree in Electrical Engineering or equivalent experience.
As an Amazon Field Engineer, you will provide full life-cycle support to AWS Data Centers from design inception through site improvement and maintenance. You will be the ‘go to’ engineering resource for your region when technical advice is needed, and will use your subject matter expertise and engage with diverse teams to:
Perform design and equipment submittal review for new Data Centers in your region.
Troubleshoot, conduct Root Cause Analysis (RCA) and create Corrective Action (CA) documentation for site/equipment failures.
Directly support operational issues with ad-hoc training, complex operating procedure reviews, including critical equipment, and event support.
Own the conceptual design for existing data center upgrades and design-solutions, which add capacity, improve availability, increase efficiency and sustainability.
Interface with internal data center operations team, data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.
Develop innovative solutions for AWS’s data centers.
Work on concurrent projects, sometimes in multiple geographical regions.
Initiate and lead engineering audits including on-site visits within Amazon’s data centers. Produce reports outlining risks with recommended mitigations and remediations.
Act as resident engineer during new construction projects. Support construction, commissioning, and turnover.
Key job responsibilities
Amazon's vision is to be the world's most customer-centric company, and this role is key to that vision. As a Field Engineer, you will be leading projects to fit out our data centers to meet ever-evolving customer needs as we continue expanding our fleet to hyper-scale. As an ideal candidate you:
Possess Strong Engineering Judgement and are able to provide recommendations despite uncertainty/ambiguity.
Are detail and data oriented.
Have experience solving problems with engineered solutions.
Have experience managing engineering projects and consultants.
Build trust and relationships with different stakeholders (e.g., Operations, Controls, Construction, Design, Commissioning, Product Managers, Technical Program Managers, ).
Are adaptable and inclined to get into the field to see things up close.
Excited about a mix of office and field work.
Each day you will interact with different teams responsible for all aspects of the data centers. You will prioritize your activities to support data center capacity availability and safety focusing on the actions that are most impactful. You will have the opportunity to work on projects locally and globally.

About the team
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud
platform. We pioneered cloud computing and never stopped innovating — that’s why customers
from the most successful startups to Global 500 companies trust our robust suite of products and
services to power their businesses.

Inclusive Team Culture
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster
a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning
experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender
diversity) conferences, inspire us to never stop embracing our uniqueness.

Mentorship & Career Growth
We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.
That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing
resources here to help you develop into a better-rounded professional.

We are open to hiring candidates to work out of one of the following locations:

Hermiston, OR, USA

Coursework in commercial/industrial power systems and/or mechanical systems
Organized and have the ability to set priorities and meet deadlines and budget
Possess leadership and problem-solving skills
Possess excellent communication and writing skills, attention to detail, maintain high quality standards
Experience using a variety of web based and other software tools for calculation and data processing.
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","$105,893 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Palo Alto Networks
4.2",4.2,"Santa Clara, CA","Sr Principal Data Software Engineer (SASE, Cloud)","Company Description

Our Mission
At Palo Alto Networks® everything starts and ends with our mission:
Being the cybersecurity partner of choice, protecting our digital way of life.
Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.
FLEXWORK is an employee-centric reimagining of how we work. We built FLEXWORK based on employee feedback – it is about flexibility, trust, and choice whenever possible. It’s been a journey of disruption that has yielded the best of our values. We offer as much flexibility as possible, and choices that enable you to be most productive, including benefits that meet your needs and learning opportunities that you feel passionate about.
Our Approach to Work
At Palo Alto Networks, we believe in the power of collaboration and value in-person interactions. This is why our employees generally work from the office three days per week, leaving two days for choice and flexibility to work where you feel most effective. This setup fosters casual conversations, problem-solving, and trusted relationships. While details may evolve, our goal is to create an environment where innovation thrives, with office-based teams coming together three days a week to collaborate and thrive, together!

Job Description

Your Career
We are seeking an experienced Big Data Software Engineer to design, develop and deliver next-generation technologies within our SASE team. We want passionate engineers who love to code and build great products. Engineers who bring new ideas in all facets of software development. Collaboration and teamwork are at the foundation of our culture and we need engineers who can communicate and work well with others towards achieving a common goal.
At Palo Alto Networks, leaders of engineering are -
Technical experts and thought leaders that help accelerate the adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends, and practices
Visionaries who help deliver on critical business needs and are recognized across the company as go-to engineering resources on given domains
Role models and mentors who exemplify the best of Palo alto Networks culture - They do the right thing even when it’s hard, treat challenges as a chance to learn, and provide honest opinions so the team can improve
Leaders who can communicate cogently with hands-on engineers as well as executives
Your Impact
Design, develop and implement highly scalable software features on our next-generation security platform as part of our Prisma Access
Work with different development and quality assurances groups to achieve the best quality
Suggest and implement improvements to the development process
Work with DevOps and the Technical Support teams to troubleshoot customer issues

Qualifications

Your Experience
M.S./B.S. degree in Computer Science or Electrical Engineering or equivalent military experience required
10+ years of development experience
Experience to developing services in the cloud/Kubernetes
Experience with building data pipelines and analytics pipelines using like dataflow, pubsub, GKE
Strong understanding of message queuing, stream processing, and highly scalable ‘big data’ data stores
Experience with RESTful interfaces and Build Management tools (Gradle, maven)
Experience in continuous integration and design
Experience with Test-Driven Development
Experience with distributed computing and object-oriented design and analysis
Strong understanding of microservices-based deployments with the ability to design services
Showcase your ability of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, peer review, and operations
Familiarity with Agile (e.g., Scrum Process)
Familiarity in Big Data technologies like Hive, Kafka, Hadoop, SQL, developing APIs
Familiarity working with GCP or other Cloud platforms such as AWS and Azure
High energy and the ability to work in a fast-paced environment with a can-do attitude
Enjoys working with many different teams with strong collaboration and communications skills
Fast learner and eager to absorb new emerging technologies

Additional Information

The Team
Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before.
We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.
Our Commitment
We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.

We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.

Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.
All your information will be kept confidential according to EEO guidelines.
The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $144,200/yr to $233,200/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here.

#LI-TD1","$188,700 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2005,$1 to $5 billion (USD)
Talent Groups,#N/A,Remote,"Fulltime // Data Engineer (H4 EADs, L2 EADs, Green Card, US Citizen)","Position: Data engineer (Live Table Structured streaming exp)
Location: Remote
Type: Fulltime
As a Data Engineer, You will do streaming analytics and emphasize on Live Table Structured streaming, Kafka, Event Hub, Apache Spark. These technologies are definitely required to do near real-time data integration.
Responsibility:
Design, build, optimize, and manage modern large scale data pipelines ETL/ELT processing to support data integration for analytics, machine learning and AI in real-time at scale.
Consume data from a variety of sources and formats, such as streaming, flat files, structured data, unstructured data, or APIs.
Engineer scalable, reliable, and performant data system and platform leveraging reusable data engineering patterns and frameworks with best practices and standards.
Establish robust data integrity monitoring to ensure machine learning and AI solutions are based on accurate data.
Write advanced / complex SQL with performance tuning and optimization.
Identify ways to improve data reliability, data integrity, system efficiency and quality.
Experience:
BS, MS, or PhD in Computer Science, Information Technology, Management Information Systems (MIS), Data Science or related field
2+ years of experience in Apache Spark (PySpark / Spark SQL)
2+ years of experience in Python
Experience with large scale streaming platforms (e.g., Kafka, Event Hub, Databricks Live Table / Structured Streaming), processing frameworks (e.g. Spark, Databricks) and storage engines – stream analytics
3+ years of experience in data engineering, data integration, data modeling, data architecture, and ETL/ELT processes to provide quality data and analytics solutions.
3+ years of experience in SQL with designing complex data schemas and query performance optimization.
Highly proficient working in Azure cloud environment (e.g., Blob / ADLS, Databricks, Azure Data Factory, Event Hub)
Excellent communication skills – ability to communicate technical concepts to both technical and non-technical audiences.
Experience in Regular Expression, CI/CD technology, Terraform and Git
Job Type: Full-time
Pay: $120,000.00 - $140,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
10 years
11+ years
8 years
9 years
Schedule:
8 hour shift
Monday to Friday
Work Location: Remote","$130,000 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Gainwell Technologies LLC
3.4",3.4,"Roseville, CA","Cloud Data Engineer - Hybrid - Roseville, CA","Be part of a team that unleashes the power of leading-edge technologies to help improve the health and well-being of those most vulnerable in our country and communities. Working at Gainwell carries its rewards. You’ll have an incredible opportunity to grow your career in a company that values work flexibility, learning, and career development. You’ll add to your technical credentials and certifications while enjoying a generous, flexible vacation policy and educational assistance. We also have comprehensive leadership and technical development academies to help build your skills and capabilities.

Summary

This is an exciting opportunity to join the Data Analytics team at Gainwell Technologies and support building market-leading products. The analytics group is responsible for the design and deployment of analytics platforms and solutions to support Gainwell clients. We are looking for a cross-functional senior AWS developer with Analytics background. In this role, you will work with AWS using Agile/Infrastructure as Code (IaC) methodologies to plan, test and deploy AWS infrastructure to support the organization’s analytic goals & vision.

Your role in our mission

Develop your career as you support Gainwell’s focus on creating innovative, purpose-built technologies and solutions to deliver better health and human services outcomes.
Work collaboratively to architect, develop, test and deploy infrastructure on AWS to support analytic workloads.
Develop scalable, resilient, reproducible solutions that meet the business, technical and security needs of the organization
Develop and support CI/CD infrastructure as code (IaC) pipelines for cloud environment.
Contribute to developing proof-of-concept use-cases as necessary.
Automate repeatable tasks and create efficiencies in the workflows.
Provide senior level guidance or lead in the planning and direction of the project to meet required objectives.
Document and champion good engineering practices within product development teams.
What we're looking for

Basic Qualifications
Bachelor's degree in computer science, MIS, or related area, or equivalent combination of education and experience
4+ years of relevant experience in analytics, 2+ years’ experience in deploying infrastructure on AWS to support analytic pipelines.
2+ years’ experience deploying infrastructure as code (IaC) using CloudFormation or Terraform, Dev-ops practices, CI/CD pipelines (e.g. Github Actions).
Familiarity with AWS-native tools such as Lambda, S3, RDS, Glue/Spark, Redshift, CloudWatch, CloudTrail, API Gateway, EKS, ECS etc.
Familiarity with cloud security and compliance paradigms (HIPAA/HiTRUST/FedRAMP).

Other Qualifications
Strong presentation and written communication skills.
Strong Gainwell team relationship management to understand direction and assist in resolving technical issues
Work successfully as part of an onshore/offshore technical team to successfully implement the required solution
Familiarity with Databricks Administration (or willingness to learn) desired
AWS Solution Architect – Associate certification preferred
What you should expect in this role

Client or office environment
Hybrid role
Occasional evening and weekend work
Must reside in the State of California
Video cameras must be used during all interviews, as well as during the initial week of orientation.

The pay range for this position is $81,400 - $116,300 per year, however, the base pay offered may vary depending on geographic region, internal equity, job-related knowledge, skills, and experience among other factors. Put your passion to work at Gainwell. You’ll have the opportunity to grow your career in a company that values work flexibility, learning, and career development. All salaried, full-time candidates are eligible for our generous, flexible vacation policy, a 401(k) employer match, comprehensive health benefits, and educational assistance. We also have a variety of leadership and technical development academies to help build your skills and capabilities.

We believe nothing is impossible when you bring together people who care deeply about making healthcare work better for everyone. Build your career with Gainwell, an industry leader. You’ll be joining a company where collaboration, innovation, and inclusion fuel our growth. Learn more about Gainwell at our company website and visit our Careers site for all available job role openings.

Gainwell Technologies is committed to a diverse, equitable, and inclusive workplace. We are proud to be an Equal Opportunity Employer, where all qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We celebrate diversity and are dedicated to creating an inclusive environment for all employees.","$98,850 /yr (est.)",10000+ Employees,Company - Private,Information Technology,Information Technology Support Services,2020,Unknown / Non-Applicable
