company,company_rating,location,job_title,job_description,salary_estimate,company_size,company_type,company_sector,company_industry,company_founded,company_revenue
"HCA Healthcare
3.3",3.3,"Nashville, TN",Data Engineer,"Introduction
Do you want to join an organization that invests in you as a Data Engineer? At HCA Healthcare, you come first. HCA Healthcare has committed up to $300 million in programs to support our incredible team members over the course of three years.
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

You contribute to our success. Every role has an impact on our patients’ lives and you have the opportunity to make a difference. We are looking for a dedicated Data Engineer like you to be a part of our team.
Job Summary and Qualifications
Data Engineers within HCA’s Information and Analytics organization are responsible for defining and implementing data management practices across the enterprise. This position will focus primarily on enterprise data management and migrating of data to the cloud. This role requires working closely with the different data teams and requires ‘self-starters’ who are proficient in problem solving and capable of bringing clarity to complex situations.
Data Engineers are expected to source and incorporate new data sources into the Enterprise Data Ecosystem. The responsibilities will include writing, testing, and reviewing ETL pipelines for defining and implementing data management practices across the enterprise
This candidate will have a history of increasing responsibility in a small multi-role team. This position requires a candidate who can analyze business requirements, perform design tasks, construct, test, and implement solutions with minimal supervision. This candidate will have a record of accomplishment of participation in successful projects in a fast-paced, mixed team environment.
Major Responsibilities:
Responsible for building and supporting a Cloud based ecosystem designed for enterprise-wide analysis of structured, semi-structured, and unstructured data. Direct the transformation from HCA Healthcare’s current on premise Teradata platform to Google Cloud Platform to enable analytics and machine learning at scale.
Implement enterprise data management practices, standards, and frameworks for Data Integration
Develop, manage, and own full data lifecycle from raw data acquisition through transformation to end user consumption.
Analyze requirements, design data pipelines and integrate those solutions for customer environments
Translate business requirements into technical design specifications
Closely collaborates with team members to successfully execute development initiatives using Agile practices and principles
Maintains a holistic view of information assets by creating and maintaining artifacts that illustrate how information is stored, processed, and accessed
Provide guidance on technology choices and design considerations for migrating data to the Cloud
Experience with building consumable data lakes, analytics applications and tools
Designing the cloud environment from a comprehensive perspective, ensuring that it satisfies all of the company’s needs.
Performs activities such as deployment, maintenance, monitoring, and management inside the cloud framework that has been created
Work closely with individuals across the technology organizations to help promote awareness of the data architecture and ensure that enterprise assets of competence are leveraged
Education & Experience:
Bachelor's degree required
Master's degree preferred
7+ years of experience in Information Technology required
3+ years of experience in Cloud Technologies required
Knowledge, Skills, Abilities, Behaviors:
Teradata ETL experience using BTEQ and SQL scripts.
Extensive experience with relational database management systems; Teradata, Oracle or SQL Server preferred.
Ability to troubleshoot, maintain, reverse engineer, and optimize existing ETL pipelines
Advanced SQL skills, including the ability to write, tune, and interpret SQL queries
Experience developing and supporting data pipelines from various source types (on-prem RDBMS, AWS, GCS bucket, flat file) to Big Query utilizing Google Cloud Platform native technologies
Scripting experience with Python/Unix/Linux.
Experience with Git and GitHub version control.
Experience with relational databases such as Teradata and public cloud technologies such as, GCP Big Query, GCP Data Catalog and Azure Data Bricks preferred
Experience with Cloud Data Flow, Airflow, Cloud Composer, Streamsets or managing streaming data is strongly preferred
Ability to troubleshoot, maintain, reverse engineer and optimize existing ETL pipelines.
Experience with Cloud Data Flow, Airflow, Cloud Composer, Cloud Data Fusion, Data Catalog, gsutil, GCS, Pub/Sub, Kafka, DataProc, github
Experience with handling streaming data is strongly preferred
NoSQL, Hbase, Cassandra, MongoDB, In-memory, Columnar, other emerging technologies
Ability to analyze and interpret complex data, and offer solutions to complex clinical problems.
Ability to work independently on assigned tasks.
Strong written and verbal communication skills including the ability to explain complex technical issues in a way that non-technical people may understand.
Excellent problem-solving and critical thinking skills.
Knowledge of IT governance and operations.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Good people beget good people.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
We are a family 270,000 dedicated professionals! Our Talent Acquisition team is reviewing applications for our Data Engineer opening. Qualified candidates will be contacted for interviews. Submit your resume today to join our community of caring!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$90,975 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"HCA Healthcare
3.3",3.3,"Nashville, TN",Data Science Engineer,"Introduction
Do you want to join an organization that invests in you as a(an) Data Science Engineer? At HCA Healthcare, you come first. HCA Healthcare has committed up to $300 million in programs to support our incredible team members over the course of three years.
Benefits
HCA Healthcare, offers a total rewards package that supports the health, life, career and retirement of our colleagues. The available plans and programs include:
Comprehensive medical coverage that covers many common services at no cost or for a low copay. Plans include prescription drug and behavioral health coverage as well as free telemedicine services and free AirMed medical transportation.
Additional options for dental and vision benefits, life and disability coverage, flexible spending accounts, supplemental health protection plans (accident, critical illness, hospital indemnity), auto and home insurance, identity theft protection, legal counseling, long-term care coverage, moving assistance, pet insurance and more.
Free counseling services and resources for emotional, physical and financial wellbeing
401(k) Plan with a 100% match on 3% to 9% of pay (based on years of service)
Employee Stock Purchase Plan with 10% off HCA Healthcare stock
Family support through fertility and family building benefits with Progyny and adoption assistance.
Referral services for child, elder and pet care, home and auto repair, event planning and more
Consumer discounts through Abenity and Consumer Discounts
Retirement readiness, rollover assistance services and preferred banking partnerships
Education assistance (tuition, student loan, certification support, dependent scholarships)
Colleague recognition program
Time Away From Work Program (paid time off, paid family leave, long- and short-term disability coverage and leaves of absence)
Employee Health Assistance Fund that offers free employee-only coverage to full-time and part-time colleagues based on income.
Learn more about Employee Benefits
Note: Eligibility for benefits may vary by location.

You contribute to our success. Every role has an impact on our patients’ lives and you have the opportunity to make a difference. We are looking for a dedicated Data Science Engineer like you to be a part of our team.
Job Summary
Position Summary
This engineer delivers on development commitments from start to finish for assigned component of the Data Science organization within Information Technology Group (ITG). This technically focused position is responsible for designing, developing, testing and deploying components of our data products across the Enterprise.
Major Responsibilities
This engineer can quickly learn and maintain existing solutions as well as new development. They will provide key problem resolutions for production systems as needed. They have an in depth understanding of the services provided by Information Technology Group, Accelerated Technologies (AT) and can develop relationships throughout the organization to assist in accomplishing its goals for the company. This engineer strategically designs, constructs, and implements software in a software development environment. This includes selecting, gathering requirements for, designing, and implementing solutions for consumers throughout the enterprise. This engineer is a highly motivated self-starter and is committed to delivering high quality solutions within agreed upon timelines. This table illustrates the relative experience/expertise of the Data Science Engineer.
Development Activities
Build life-changing healthcare technology
Act as technical developer within AT and project integrations, including requirements gathering, design, development, and testing
Participate in requirements validation and feasibility analysis with respect to AT
Participate in creation of design specification that will enable day to day build activities and troubleshooting
Estimate work effort required in delivering features keeping DS capabilities in mind
Produce modular, reusable code that incorporates coding best practices and serves as an example for less experienced developers
Write code and assist in development of new products/features and enhance and/or maintain existing ones
Help design and execute DevOps strategies and processes, driving the change management which accompanies these types of transformative solutions
Help design and implement highly scalable applications that take advantage of distributed infrastructure on physical and cloud servers with technologies such as Docker, Kubernetes, OpenShift, and Rancher
Help design, build and maintain automated deployment frameworks (Continuous Integration, Continuous Delivery), to reduce the software development cycle time
Work collaboratively with infrastructure team to evolve data product configuration/customization for different environments
Accurately report issues and status to project management
Create and execute test cases (both automated and manual)
Participate in various code review activities
Help produce and review enterprise-level system design documentation, including: XML schemas, WSDL's, Use Cases, Software Architecture Documentation, Service Mapping (i.e., map service schema to backend source systems), Consumer Guide (i.e., end user documentation), and transition documentation to support the team.
Create Service Level Agreements (states the agreed upon availability-uptime/downtime, maintenance windows, etc. for a Service) and Supplementary Specifications (i.e., non-functional specifications). Ensure implementations are up to current standards for coding, naming, security, and versioning. Possess knowledge and experience with different phases of testing (unit testing, integration testing, performance testing).
Possess excellent communication skills to interface with various stakeholders from business consumer to technical staff.
Be incorporated into development teams from design to deployment of enterprise services.
Oversee and participate in the day-to-day support and maintenance activities.
Understand assigned applications and system architecture
Support troubleshooting activities
Work on assignments involving the use of various technologies both old and new.
Develop software with a focus on delivering reusable code.
Complete assignments on time.
Work as part of a team and work independently.
Provide after hours/on-call support as needed
Knowledge, Skills, Abilities, Behaviors:
Technology Experience: 2+ years of experience in most of the following: We are looking for experts in these areas. If you don’t have experience in some of these, you are able to work collaboratively on a cross-functional team that builds Data Science signal delivery, data pipeline, and DevOps infrastructure.
Full stack application development (e.g. JavaScript, Node, Vue.js, HTML/CSS and other web stack technologies)
Extensive experience in ANSI SQL languages (e.g., MSSQL, Teradata, Postgres) required.
Extensive expertise/experience in data acquisition, data cleansing and parsing required.
Experience with container-based platforms such as Docker, Kubernetes, OpenShift, Mesosphere, Rancher, and CoreOS
ETL experience required
Experience using a distributed version control system (DVCS; e.g., GitHub, TFS) required.
Extensive expertise/experience in data analysis, modeling and visualization required
Experience with business intelligence platforms (e.g., Tableau, Qlik, MicroStrategy) required.
Extensive experience with container monitoring applications such as Prometheus and Grafana
Experience with Hadoop, Spark, Kafka, Cassandra (i.e. distributed compute and storage) SQL experience / database interrogation techniques
Linux command line skill is required
Mastery of one or more formal development languages (e.g., Python, R, JavaScript, Ruby, Scala, or Clojure) required
Extensive expertise/experience in the areas of data structures, warehousing, and profiling
Scrum, Agile, Lean Product Development, Domain Driven Design
Excellent communication skills, both written and verbal
Experience and knowledge with Service Oriented Architecture (SOA)
Healthcare experience, preferable
Exposure to the fundamentals of Enterprise Architecture (preferred)
Adaptability
Treats change and new situations as opportunities for learning or growth.
Focuses on the beneficial aspects of change and speaks positively about the change to others.
Seeks to understand changes in work tasks, situations, and environment as well as the logic or basis for change.
Demonstrates the ability to help others adapt to change and to personally adapt to various work environments.
Adaptability - Expected Level of Competency
Willingness to network with corporate and field contacts.
Occasional inter-departmental contact and presentations.
Collaboratively works with customers on a 1:1 basis, as well as in teams.
Working Standards
Continues to refine development and analytical skills.
Applies a consistent development approach to provide creative solutions to problems.
Contribute to the design, construction and implementation of software and analytics solutions in the data science engineering environment.
Works to build technical knowledge by taking advantage of internal team mentoring and attending professional development opportunities.
Education & Experience
Bachelor Degree Required
Masters Degree Preferred
2+ Years Relevant Work Experience Required
Travel Requirement
The job may require up to 25% travel.
HCA Healthcare has been recognized as one of the World’s Most Ethical Companies® by the Ethisphere Institute more than ten times. In recent years, HCA Healthcare spent an estimated $3.7 billion in cost for the delivery of charitable care, uninsured discounts, and other uncompensated expenses.

""Good people beget good people.""- Dr. Thomas Frist, Sr.
HCA Healthcare Co-Founder
We are a family 270,000 dedicated professionals! Our Talent Acquisition team is reviewing applications for our Data Science Engineer opening. Qualified candidates will be contacted for interviews. Submit your resume today to join our community of caring!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","$98,676 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1968,$10+ billion (USD)
Tail Wind Informatics,#N/A,Minnesota,Data Engineer - Azure,"About Us:
Tail Wind is an IT Consulting Services company—Microsoft Solutions Partner—that delivers Data Architecture and Business Intelligence solutions. We offer cloud and on-premise Data Architecture, ETL Development, Data Migration, Reporting and Dashboard solutions. We’ve established an excellent reputation providing these services to awesome customers! We are building a talented crew of data savvy individuals for local and national projects in data. We offer excellent compensation (salary, bonus, benefits). Most importantly, our people have an incredible opportunity to build their skills in a team environment.

We are currently seeking candidates for our Data Engineer position to do the following:
Responsibilities
Using Data Science techniques to preform predictive modeling services.
Building data sets in data warehouses using SQL, Azure and Python.
Experience with Databricks or Snowflake
Work across multiple different teams and projects.
Requirements
3+ years experience using Azure Data Factory
Must have strong backend development skills with SQL Server and writing complex SQL queries
Strong understanding of predictive modeling
Working in a fast paced, deadline heavy environment
Benefits
401k + match
Health Insurance
Dental Insurance
Vision
Long-Term Disability Insurance
Life Insurance
The Tail Wind Team: A healthy work-life balance. We look for people that love what they do, want to learn, earn and enjoy life to the fullest.
Equal Opportunity Employer - No Agencies Please","$120,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Teamware Solutions (quantum leap consulting).
4.5",4.5,Remote,Sr. Data Engineer,"Job Duties:
# Experience in SQL Programming language Cosmos Scope scripting.
# Knowledge of Big Data pipelines Data Engineering.
# Working experience on Azure DevOps is a must
# Working Knowledge on MSBI stack on Azure.
# Working Knowledge on Azure Data factory, Azure Data Lake and Azure Data lake storage.
# Hands-on in Visualization like PowerBI.
# Implement end-end data pipelines using cosmos Azure Data factory.
# Should have good analytical thinking and Problem solving.
# Experience with Data quality implementations assessing data correctness, completeness, uniqueness etc
# Experience working on PII, GDPR, handling sensitive data (encryption/decryption)
# Good communication and co-ordination skills.
# Able to work as Individual contributor.
# Requirement Analysis.
# Create Maintain and Enhance Big Data Pipeline.
# Daily status reporting, interacting with Leads.
# Version control ADO GIT, CI CD.
# Marketing Campaign experiences.
# Data Platform, Product telemetry, Analytical thinking.
# Data Validation of the new streams.
# Data quality check of the new streams.
# Monitoring of data pipeline created in Azure Data factory.
# updating the Tech spec and wiki page for each implementation of pipeline.
# Updating ADO on daily basis.
Job Type: Full-time
Schedule:
8 hour shift
Work Location: Remote",#N/A,1001 to 5000 Employees,Company - Private,Information Technology,Information Technology Support Services,2003,Unknown / Non-Applicable
"RFA Engineering
4.0",4.0,"Urbandale, IA",Data Engineer,"RFA Engineering (www.rfamec.com) supports industry-leading clients through the full software development lifecycle to build cutting-edge precision agriculture, machine guidance, vehicle automation and autonomy applications. We are seeking passionate, talented engineers to work on exciting projects using the latest tools and technologies including robotics, computer-vision, machine learning, IoT, cloud computing, and much more. Collaborate with a team of industry experts onsite at our client's world-class engineering center and contribute to developing innovative solutions that drive sustainable agriculture practices.
This is a full-time position with a full benefit package listed below that includes opportunities for professional growth, direct hire by our customers, and additional opportunities within our own organization.
Data Engineer
You will be working with a high-velocity team of multi-disciplined engineers, developers, and architects that are developing big data pipelines to enable next-generation autonomous vehicles.
Responsibilities
Developing and maintaining data pipelines that ingest and post-process video streams, sensor data logs, and related metadata to be stored and used for ML model training, regression testing, and analysis.
Collaborate with data platform developers to perform functional verification and integration validation of data transformation processes.
Develop and document common practices for data registration and config generation
Participate in code reviews, code optimization, and refactoring
Requirements
Bachelor's degree or higher in Software Engineering, Computer Engineering, Electrical Engineering, Computer Science, or similar field or industry experience
3+ years of Python coding experience, familiar with utilizing packages such as pandas, boto3, subprocess, argparse, json, csv, os
3+ years Git/GitHub experience and knowledge of branching best practices
2+ years experience with AWS cloud tools such as S3, ECR, Lambda, SQS/SNS, CloudFormation, or IAM role.
2+ years experience with SQL, relational databases, and tools such as MongoDB, AWS Athena, or Databricks Delta Lake
1+ year experience with large-scale data operations and transformation utilizing tools like PySpark, Kubeflow, or Docker containers
Desired Attributes
Familiarity with CAN J1939 communication protocol
Excellent interpersonal communication skills with the ability to lead conversations and collaborate
Strong, demonstrated problem-solving and debugging skills
Ability to influence others without authority
Ability to work in a well-organized manner, provide clear status updates, and deliver results in a timely manner
Visa sponsorship is NOT available for this position.
About RFA Engineering
RFA Engineering has provided product development and engineering services to industry leading customers since 1943. Our primary focus is the development of off highway equipment including agricultural, construction, mining, recreational, industrial, and special machines. Our work includes concept development, product design, documentation, problem-solving, simulation, optimization, and testing of components, systems and complete machines. Our engineering staff is located at our Engineering Center in Minneapolis, branch office in Dubuque, IA, and at numerous customer sites throughout the U.S.

Competitive Benefits
Health and Dental Insurance
TelaDoc Healthiest You
Supplemental Vision Insurance
Company Paid Life Insurance
Company Paid Long-Term Disability
Short-term Disability
Retirement Savings Account (Traditional 401k & Roth 401k)
Flexible Spending Plan Dependent Care
HSA for Medical Expenses
Bonus Plan (Exempt Employees Only)
Paid Time Off (PTO)
Paid Holidays
Bereavement Leave
Employee Assistance Programs (EAP)
Education Assistance
Equal Opportunity and Veteran Friendly
Education
Preferred
Bachelors of Science or better in Data Science or related field
Bachelors of Science or better in Computer Engineering
Bachelors of Science or better in Computer Science or related field
Skills
Preferred
Data Analytics Data Mining
Data Analytics Big Data
Data Analytics","$76,303 /yr (est.)",201 to 500 Employees,Company - Private,"Construction, Repair & Maintenance Services",Architectural & Engineering Services,1967,$5 to $25 million (USD)
"Momentum
3.6",3.6,"Chantilly, VA",Data Engineer,"Welcome to the MOMENTUM Family!
MOMENTUM is not just our company name; it is the highest value we deliver to our customers. We are a rapidly growing technology solutions company delivering innovative technology, engineering, and intelligence solutions across the DoD sector. The efforts of our high-capacity team ultimately strengthen our Nation and the warfighter.

Our team is dispersed throughout the US, which means we value the diversity and unique collaboration fostered throughout our team. We work incredibly hard for our customers and believe deeply in our core values. We're a high-energy, high-growth team and we love to win.

Data Engineer
The Data Engineer provides engineering support to the data science and software engineering team members. Includes augmenting technical support in the area of data science, data engineering, and systems engineering, and reviewing and providing technical assessments. Provides current system architecture documentation, engineering/web development programming support for program/project requirements defined tasks, data science/data engineering related technical assessments, effective communication with users and managers, and server administration, including hardware and software support to existing servers.

In this role, you will:
Design and optimize Data Pipelines using Spark, Hudi, EMR cloud services, and Kubernetes containers
Make sure the pedigree and provenance of the data are maintained such that access to data is protected
Clean and preprocess data to enable analytic access
Collaborate with enterprise working groups to advance the state of data standards
Collaborate with the engineering team, data stewards, and mission partners to aid in processes getting actionable value out of the data holdings architects' complex, repeatable ETL
Provide Advanced Database Administration support in Oracle, MySQL, MariaDB, MongoDB, Elastic, and others
Supports Experience with Targeting using Sponsor Tools, Reverse Engineering
Support ad-hoc data analysis requirements defined by the client's Leadership.
Reporting solutions will encompass multiple technology platforms used by the client and will drive business process re-design and raining/change management initiatives.
Knowledge of business intelligence reporting tools and data visualization software including Tableau.
Will work on Data cleaning and transformation efforts in the delivery of CDRLs.
Experienced in extracting and aggregating structured and unstructured data.
Experienced in data programming languages and tools such as Python and R.
Experience with SQL or similar database language.
Experience designing and implementing data models to enable, sustain and enhance the value of the information they contain.
Strong analytical and critical thinking skills.
Ability to work collaboratively and effectively in a team environment.

If you're suitable for this role, you have:
Top Secret SCI with FULL SCOPE POLY REQUIRED


To learn more about us, check out our website at www.gomomentum.tech!

MOMENTUM is an EEO/M/F/Veteran/Disabled Employer:
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The qualifications listed above are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform essential functions.

Accommodations:
Consistent with the Americans with Disabilities Act (ADA) and Alabama civil rights law, it is the policy of Momentum to provide reasonable accommodation when requested by a qualified applicant or employee with a disability, unless such accommodation would cause an undue hardship. The policy regarding requests for reasonable accommodation applies to all aspects of employment, including the application process. If reasonable accommodation is needed, please include a request when applying.","$155,000 /yr (est.)",501 to 1000 Employees,Company - Public,Media & Communication,Advertising & Public Relations,1987,$100 to $500 million (USD)
"MP RPO
2.8",2.8,"Mansfield, MA",Data Engineer,"Who you are:
We are seeking a skilled and highly motivated Data Engineer to join our team and play a critical role in building the foundation for our data management practice. This is an exciting opportunity to contribute to the growth and success of our organization by providing and enhancing data-driven insights. This is also an opportunity to directly influence and drive the direction and capabilities of the function and organization.
ABOUT OUR CLIENT:
With over 80 years of experience in the alcohol industry, MGX understands the complex US beverage alcohol business and enables our customers to navigate it more efficiently. We collaborate with retailers and suppliers to design and implement supply chain solutions to optimize a product's route to market. MGX provides a single point-of-contact across the entire beverage alcohol supply chain, bringing together the services of our affiliated companies Gordon Logistics, Milton's Distributing, and Hope Beverage.
We recognize that nothing happens without our people and that our team members are our most important asset. We're a family-owned and operated business committed to building a culture that recognizes, respects, and rewards our employees. We offer competitive wages and comprehensive benefits coverage including medical, dental, 401K, profit sharing, and tuition reimbursement.
Duties and Responsibilities:
Data Modeling: Design and develop efficient and scalable data models to support business reporting and analytics requirements in PowerBI. Work closely with stakeholders to understand their needs and translate them into effective data structures.
Data Integration: Collaborate with cross-functional teams to identify and gather relevant data from various sources, including internal databases, third-party APIs, and other external data sources. Ensure data quality and integrity through data cleansing, transformation, and validation processes.
Data Transformation: Implement data transformation logic, including data cleansing, aggregation, enrichment, and normalization, to ensure accurate and relevant data for analysis.
ETL Development: Design and implement Extract, Transform, Load (ETL) processes to extract data from multiple sources, transform it into usable formats, and load it into the data models. Optimize ETL workflows for performance and efficiency.
Data Governance: Establish data governance practices, standards, and guidelines to ensure data consistency, accuracy, and security across the organization. Implement appropriate data access controls and permissions for different user groups.
Performance Optimization: Monitor and analyze the performance of data models and queries in PowerBI. Identify and resolve performance bottlenecks through query optimization, indexing, and other techniques. Continuously improve the performance and responsiveness of the data infrastructure.
Documentation: Create comprehensive documentation, including data dictionaries, data flow diagrams, and technical specifications. Maintain up-to-date documentation of data models, ETL processes, and data lineage for future reference and knowledge sharing.
Collaboration and Communication: Collaborate with data analysts, business intelligence teams, and other stakeholders to understand their reporting and analytics requirements. Communicate effectively with both technical and non-technical stakeholders, presenting complex technical concepts in a clear and concise manner.
MINIMUM EDUCATION AND WORK EXPERIENCE
Bachelor's degree in Computer Science, Engineering, or a related field. A master's degree is a plus. Significant experience and training in lieu of a degree will be considered
5+ years proven experience as a Data Engineer, Database Developer, or similar role, with a focus on designing and building data models for consumption in PowerBI andor other analytical tools.
Strong expertise in data modeling concepts and methodologies. Experience with dimensional modeling and Data MartsWarehouses is highly desirable.
Knowledge of data integration techniques and tools. Experience with data extraction from various sources (including unstructured data), data cleansing, and transformation is required.
Strong proficiency in Informatica Data Management Cloud, including experience in data integration, data transformation, and workflow automation.
Proficiency PowerBI and other data visualization tools. Familiarity with Power Query and DAX is preferred.
Proficiency in SQL and programming languages such as Python for data manipulation, analysis, and automation.
Extensive knowledge and experience building and optimizing multidimensional models using SQL Analysis Services for complex analysis and reporting
Familiarity with data governance and data security best practices. Understanding of data privacy regulations and compliance (e.g., GDPR, CCPA) is a plus.
Strong problem-solving skills and attention to detail. Ability to analyze complex data requirements and translate them into practical solutions.
Excellent communication and interpersonal skills. Ability to work effectively in a team environment and collaborate with stakeholders at all levels of the organization.
Strong organizational and time management skills. Ability to handle multiple priorities and meet deadlines in a fast-paced environment.
Professional certifications and training in applicable technologies is a plus","$96,400 /yr (est.)",201 to 500 Employees,Company - Private,Manufacturing,Machinery Manufacturing,2005,$25 to $100 million (USD)
"HelloFresh
3.7",3.7,"Aurora, CO",Data Engineer,"Data Engineer( can be based in Newark NJ, Newnan GA, Aurora CO, Phoenix AZ, Irving, TX or Swedesboro, NJ)
Come see what’s cookin’ at HelloFresh!
At HelloFresh, we want to revolutionize the way we eat by making it more convenient and exciting to cook meals from scratch. We have offices all over the world and we deliver delicious meals to millions of people.
We are the industry leader in meal-kit subscription services and we’re growing all the time. We have distinct meal-kit services that cater to everyone with the most menu variety in the market, which allows us to reach an incredibly wide population of people.
The HelloFresh team is diverse, high-performing, and international, and our work environment is an inspiring space where you can thrive as a result.

Job Description
As a Data Engineer, you will work with the Fulfillment Planning Technology team to help build the next generation suite of internal tools that enable Planning and Operations teams to see and act quickly to changing business conditions. The Data Engineer will build scalable data pipelines, infrastructure and tools that power our products and services.

You will …
Work with analysts, engineers and planners to design, build, and maintain efficient, scalable and reliable data pipelines to support our business-critical needs in data ingestion, processing, and analysis
Develop and maintain efficient, scalable and reliable code in Python and SQL
Collaborate with other team members to troubleshoot, perform root cause analysis and optimize existing data pipelines and tools
Work with other team members to ensure effective tool integration with other systems and workflows

At a minimum, you have …
Bachelor’s or Master’s degree in Computer Science, Engineering or related field
2+ years of data engineering experience in Fulfillment, Logistics, Supply Chain, Production, or related field working with physical goods
Strong proficiency in Python and SQL
Experience working with distributed systems, building and maintaining pipelines using cloud technologies (AWS, Snowflake)
Experience in containerization and orchestration (Docker, Kubernetes, Airflow, GCP)
Startup experience a plus
You'll get...
Competitive Salary & 401k company match that vests immediately upon participation
Generous parental leave of 4 weeks & PTO policy, as well as paid holidays off
$0 monthly premium and other flexible health plans
Amazing discounts, including up to 75% off HelloFresh subscription
Flexible shift scheduling & advancement opportunities
Emergency child and adult care services
Snacks & monthly catered lunches
Collaborative, dynamic work environment within a fast-paced, mission-driven company
It is the policy of HelloFresh not to discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because he or she is a protected veteran.
Colorado Pay Range
$99,200—$124,000 USD","$111,600 /yr (est.)",5001 to 10000 Employees,Company - Public,Restaurants & Food Service,Catering & Food Service Contractors,2011,Unknown / Non-Applicable
"NAVEX Global
3.5",3.5,"Charlotte, NC","Staff Software Engineer, Data","It's fun to work in a company where people truly BELIEVE in what they're doing!
We're committed to bringing passion and customer focus to the business.
Position Summary:
At NAVEX, you will help design and implement our NAVEX One data platform part of our newest engineering team. Our Product Engineering team shares a passion for designing quality solutions, embracing new technologies and delivering powerful products that help our customers protect their reputation and bottom line.
As a Data Staff Software Engineer, you will influence technical designs and implement our new data platform. You will focus on quality implementation while guiding the other data engineers. You will help us build a data platform that will ingest other teams’ content and then provide application specific data sets. We are looking for a candidate who is strong in data engineering. In this role, you will have ample opportunity to explore new value-added capabilities, invest in data development and tool research, mentor software developers and grow your career all while balancing your life priorities.
We Offer You:
An Inspiring Culture. Invested teammates, belonging groups, and a socially determined culture
Meaningful Work. Innovative products and solutions with real life impact for people and organizations
Career Growth. Stellar training and an unwavering commitment to your growth and success
Life Flexibility. Time to care for yourself, your loved ones, and your community
Industry Leadership. A highly reputable, fast growing and consistently profitable organization
Real Rewards. Competitive and transparent pay practices, wellbeing programs and benefits with choice
What You Will Do:
Work with a team of data engineers and be accountable for designs and high-quality deliveries as an individual contributor
Help team members grow by mentoring newer engineers
Participate in the innovative advancements of our product platform and collaborate with our awesome agile team members
Promote opportunities for refactoring and identify areas of optimization
Research and leverage commercial products, libraries, and tools that can be used to solve problems
Participate in design sessions with other engineers, architects, and product managers, providing constructive and honest feedback during sprint retrospectives with a team mindset
Use automation, including continuous integration, automated deployments, and automated unit and functional testing
What You Will Need:
A Bachelor’s degree in Computer Science or be good enough that we won’t notice through equivalent prior work-related experience
5+ years’ experience in an Agile, full-stack software development environment with a focus on big data designs and implementations, ideally with SaaS and/or micro service-based systems
Expert knowledge of data management and pipeline systems, practices, and standards
Expert analytical and design skills, including the ability to abstract information requirements from real-world processes to understand information flows in computer systems
Expertise in the fields of data transformations (ELT, ETL), data quality, data cleansing, and data profiling using dbt Labs’ DBT
Expertise in Data Cataloging and Master Data Management concepts
Expertise in both SQL and NoSQL implementations; experience with Microsoft SQL Server, Snowflake, and Postgres database platforms
Experience with SQL profiling, performance tuning, and data ingestion into Data Warehouses
Strong problem solving and critical thinking skills with the ability to identify and influence others on the best solution
Ability to work well in a team environment and attitude to focus on team specific goals and objectives
Excellent verbal and written communication skills and a commitment to engage and collaborate with people across a variety of levels with diverse backgrounds
We believe each member of our team deserves to see a path forward to achieving their career and financial goals.
Each team member is required to have a career plan in place and reviewed with their manager after six months with our team.
The minimum starting pay range for this role is $110,000 per annum with 5% MBO.
Pay progression is based on performance.
Our pay programs are just one element of our commitment to Be the ONE place you want to thrive in life. Check out NAVEX’s career page to learn about our innovative people programs designed to create one powerful life experience for YOU!
NAVEX is an equal opportunity employer, including disability/vets.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
Job Type: Full-time
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Day shift
Monday to Friday
Experience:
Software Engineering: 5 years (Required)
Snowflake: 2 years (Required)
Work Location: Hybrid remote in Charlotte, NC 28277","$110,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2012,$100 to $500 million (USD)
Technovant inc,#N/A,"New Haven, CT",Data Movement Engineer,"Client required information:
***They need Someone who has strong Talend Experience minimum of 5 years***.
Talend API is Desirable, But any API is also fine like snowflake as a last option.
They are working on Data Base Movement from Talend to ETL/ELT.
Formally they need ETL/ELT Developers or Talend Developers with ETL/ELT data movement experience.
Implementation and Configuration Talend is Mandate.
They also need to take a an on call support after work hours for ongoing production Support team, this might happen on weekends too.
They are going to implement more API’s, so having extra API experience is plus.
They need to understand the baseline of Insurance( The Basic work or Knowledge on Insurance Modules).
They can Work Remote, But need only from EST Zones.
Manager is not going to accept any profiles without Talend Experience.
Skill Qualifications Required:
· Minimum of 5 years of relevant experience in data warehousing, business intelligence tools, and the analysis of data
· Minimum of 3 years of SQL query development, preferably in multiple database management platforms, and working with normalized relational databases and dimensional data warehouse implementations
· Proficiency in ETL/ELT concepts and tools (Informatica IICS and PowerCenter preferred)
· Some experience with cloud-based database technologies required
· Working knowledge of data warehousing concepts, structures and ETL best practices
· Experience using query tools (e.g. AQT, MS Query)
· Ability to problem solve using analytical thinking skills
· Must work well independently - must be inquisitive and seek answers to complex questions without being prompted
· Strong organizational and time management skills
· Strong communication skills including verbal and written to communicate effectively with clients and management
· Strong project management skills to ensure that projects get done on time and within budget
· Effectively participates in teams and moves the team toward completion of goals
Job Types: Full-time, Contract
Salary: From $55.00 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Schedule:
8 hour shift
Experience:
Data entry: 1 year (Preferred)
Work Location: Remote",$55.00 /hr (est.),#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Plaxonic Technologies
4.6",4.6,"Charlotte, NC",Snowflake Data Engineer,"Snowflake, SQL, Relational Databases
Exposure to Data warehousing and various ingestion patterns from multiple sources.
Good hands-on experience in Snowflake migration projects with good understanding of Snowflake architecture and building pipelines for ingestion.
Good hands-on experience in building complex SQL queries. ? Experience in Insurance domain ? Guide team on overall mapping and ETL process
Co-ordinate with multiple source systems team to get the required data in file formats and work with Architect to resolve any data issues or dependencies.
Analyzing and identifying the risks and dependencies.
Interaction with team and client stakeholders to ensure the project deliverables are on track & as per expectations.
Resolve blockers for the offshore team and track the daily deliverables.
Job Type: Full-time
Salary: $130,000.00 - $135,000.00 per year
Experience level:
10 years
Schedule:
8 hour shift
Experience:
Data Engineer: 10 years (Required)
Snowflake: 10 years (Required)
SQL: 10 years (Required)
Work Location: On the road","$132,500 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2013,$1 to $5 million (USD)
"Seven Hills Group Technologies inc.
3.0",3.0,Remote,Quantexa Data Engineer,"Minimum of 5 years experience in Data Engineering
Quantexa Data Engineer certification is mandatory
A fundamental understanding of Scala and Spark
Experience of having worked on a financial money laundering project using Quantexa
Experience in having worked on Networks, Documents, Entities, and Entity Resolution
Data ingestion and data preparation using ETL
Strong SQL background including strong data management skills
Thanks and Regards
Nick Awasth
Job Type: Contract
Salary: $40.61 - $87.01 per hour
Experience:
financial money laundering: 1 year (Preferred)
Quantexa: 4 years (Preferred)
Work Location: Remote",$63.81 /hr (est.),Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Catalytic Data Science
4.2",4.2,"Boston, MA",Data Engineer,"Data Engineer
Engineering
REMOTE OPPORTUNITY

About Catalytic Data Science (CDS):
Catalytic Data Science is a groundbreaking cloud R&D platform designed to integrate the volumes of scientific resources, data, and analytic tools while providing the ability to network with colleagues in one secure and scalable environment. By enabling R&D teams to work more collaboratively and improving productivity company-wide, the Catalytic platform helps teams achieve key R&D milestones faster and with greater accuracy. Our customers are passionate about making the world a better place, and we are inspired by the opportunity to help them.

The Role:
You are a Data Engineer with experience in processing terabytes of data. You have experience in creating and automating scalable, fault-tolerant and reproducible data pipelines using Amazon AWS technologies. You are interested in helping to create a platform completely built on top of AWS. You are eager to join a team of Life Scientists and Software Engineers that believe the brightest minds in research should have the best tools to drive innovation.

What You’ll Do:

Build & operate automated ETL pipelines that process terabytes of text data nightly
Develop service frontends around our various backend datastores (AWS Aurora MySQL, Elasticsearch, S3)
Perform technical analyses and requirements specification with our product team on data service integrations
Help customers bring their data to the platform

What You Know:

Must Haves:

Python 3 or Java programming experience, preferably both
Day-to-day experience using AWS technologies such as Lambda, ECS Fargate, SQS, & SNS
Experience building and operating cloud-native data pipelines
Experience extracting, processing, storing, and querying of petabyte-scale datasets
Familiarity with building and using containers
Familiarity with event-based microservices

Nice-to-Haves:

Prior experience with Elasticsearch (custom development and/or administration) is a huge plus
Prior work with text and natural-language processing
Knowledge of Graph databases

What do we love in team members?

Your specialization is less important than your ability to learn fast and adapt to shifting technologies. We’re especially fond of people who:

Focus on customer’s needs and our company’s goals, not just writing code
Iterate until customers love what you’ve built
Self-start and initiate
Self-organize
Strive to grow personally and professionally, beyond just expanding technical abilities
Love to experiment with new technology and share knowledge with the team

In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","$102,838 /yr (est.)",1 to 50 Employees,Company - Private,Information Technology,Computer Hardware Development,#N/A,$1 to $5 million (USD)
"ProIT Inc.
4.9",4.9,"Charlotte, NC",Data Engineer,"Database Technologies:
Snowflake, SQL, Relational Databases
Exposure to Data warehousing and various ingestion patterns from multiple sources.
Good hands-on experience in Snowflake migration projects with good understanding of Snowflake architecture and building pipelines for ingestion.
Good hands-on experience in building complex SQL queries. ? Experience in Insurance domain ? Guide team on overall mapping and ETL process
Co-ordinate with multiple source systems team to get the required data in file formats and work with Architect to resolve any data issues or dependencies.
Analyzing and identifying the risks and dependencies.
Interaction with team and client stakeholders to ensure the project deliverables are on track & as per expectations.
Resolve blockers for the offshore team and track the daily deliverables.
Technical Skills (Secondary – Nice to have, NOT MANDATORY):
Knowledge on Data analysis and Data Modeling
Python
Familiar with Agile software development methodologies
Soft Skills
As this is an onsite role, must have strong written and oral communication skills.
Insurance Domain Knowledge
Strong ability to work with client stakeholders.
Requirement Review and Work Effort Estimation
Job Type: Contract
Pay: $54.45 - $65.57 per hour
Benefits:
401(k)
Dental insurance
Health insurance
Compensation package:
Performance bonus
Experience level:
6 years
Schedule:
8 hour shift
Day shift
Monday to Friday
Ability to commute/relocate:
Charlotte, NC: Reliably commute or planning to relocate before starting work (Required)
Experience:
Snowflake migration: 5 years (Preferred)
ETL process: 5 years (Preferred)
Snowflake architecture: 3 years (Preferred)
Work Location: In person",$60.01 /hr (est.),51 to 200 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Trissential
4.1",4.1,"Minneapolis, MN",Data Engineer,"Overview
Trissential is a trusted partner for end-to-end quality services and management consulting for digital transformation. As a part of our parent company, Expleo, we are a global organization partnering with major corporations and leading non-profits in over 30 countries. Guided by our mission and values, Trissential puts people at the heart of our organization.
Come join an experience! Add your talent to a team of forward-thinking game changers that make an impact by driving innovative solutions.
Trissential is currently seeking a Data Engineer to join our dynamic team in Minneapolis, MN (Remote).
Responsibilities
Position Summary:
A Data Engineer is a professional responsible for designing, building, and maintaining the client’s data infrastructure that supports data-centric operations, and decision-making.
The Data Engineer is responsible for creating and maintaining data pipelines, data storage systems, and data processing systems, as well as ensuring data is accurate, secure, and easily accessible.
Primary Responsibilities and Accountabilities:
Data pipeline and workflow development: This includes designing and implementing client data pipelines and workflows to ensure that data is being collected, processed, and stored in an efficient and timely manner. Understand and incorporate data quality principals that ensure optimal performance, impact, and user experience.
Data storage and processing: This includes designing and implementing data storage systems and developing and maintaining code to process and analyze data.
Data integration: This includes working with the client on designing data integration strategies, integrating data from multiple sources, and ensuring data quality.
Data security: This includes defining and implementing client data security policies and procedures, including access control and data encryption.
Data governance: This includes defining data governance policies and procedures, monitoring data quality, and ensuring compliance with data privacy regulations.
Performance tuning: This includes optimizing data access, indexing, and query performance to ensure the data infrastructure can scale as required.
Monitoring and troubleshooting: This includes monitoring data systems and troubleshooting any issues that arise, identifying and resolving performance bottlenecks, and working with other team members to resolve any problems.
Collaboration and Communication: This includes working closely with client’s Data Architects, Data Analysts, Business Intelligence and Data Science team members, and other stakeholders to understand their data needs and develop solutions that meet those needs while adhering to industry best practices.
Qualifications
Extensive experience in ETL, preferably with transitioning from legacy systems to more advanced ones.
Strong data analysis skills, with the ability to identify areas of improvement in the current process.
In-depth knowledge of automation strategy development and implementation.
Ability to work in an advisory capacity, providing insights and recommendations to improve data management capabilities.
Excellent problem-solving skills to identify potential errors and propose solutions to enhance efficiency.
Skills
Works independently or well within a team
Wants to continuously grow knowledge base and skill set
Collaborative, consultative mindset
Works well in a fast paced environment
Strong technical background
Deep knowledge and curiosity about technology and systems
Agile mindset
Job Type: Contract
Work Location: Remote","$95,769 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2003,$25 to $100 million (USD)
"Abotts consulting
4.1",4.1,Remote,Informatica Data Engineer,"Description
(Candidates MUST HAVE: Informatica IICS, Azure, Azure Data Factory, Snowflake Informatica Powercenter, Informatica Powerexchange)
Support data pipelines ensuring that ETL jobs run as scheduled, complete successfully and that there are no data quality issues resulting from the jobs runs.
Ensure that supported data pipelines meet any predefined SLAs.
Address errors/incidents with data pipeline runs to ensure business data delivery is not interrupted.
Work with Enterprise Scheduling team to resubmit failed jobs and make schedule adjustments due to routine maintenance as needed.
Work with Data Governance and Business Consumers to address any data quality issues resulting from errant runs.
Address defects related to support pipelines as needed and assigned.
Collaborate with Data Development team as needed for any changes introduced to existing pipelines due to new deployments.
Track job performance to identify increasing processing times and implement optimizations as needed.
Create RCA’s for large problems and document fixes or updates to SOPs to prevent future occurrences.
Document any changes to supported jobs for incident resolution and/or defect fixes.
Provides resolution to a diverse range of recognizable complex problems.
Analysis is required to identify root cause.
Uses judgment within defined boundaries to develop and iterate solutions, both long and short term.
Top Skills Details
1. 6+ Years of experience as a data engineer with the ability to work with large data set, multiple databases and Data Warehouses
2. 6+ years of experience in Informatica Development with extensive experience with Informatica IICS (Intelligent Cloud Integration Services)
3. Strong experience with Informatica PowerCenter and Informatica PowerExchange
4. Strong Experience working in Azure Cloud Environments (including Azure Data Factory)
5. Strong experience working with Snowflake as the Enterprise Data Warehouse
6. Strong experience working with Oracle/SQL Server databases
7. Strong SQL Querying skills with the ability to do simple and complex queries and inner/outer joins
Job Type: Contract
Pay: From $50.00 per hour
Experience level:
1 year
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",$50.00 /hr (est.),51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,2014,$1 to $5 million (USD)
"Rehrig Pacific Company
3.8",3.8,"Richardson, TX",Data Engineer,"Role Description
Position Title: Data Engineer
Manager: Sr. Manager, Enterprise Solution
Position Location: Rehrig Technology Center, TX
Manager Once Removed: Director - IT & Security
Level of Work: Individual Contributor
Date Prepared: 08/09/2023
Brief Role Description
The Data Engineer will be responsible for developing and managing the enterprise overall data architecture, which includes the data models, data warehouses, data pipelines, and other systems that will be used to store, manage, and analyze data.
This role also requires a fair amount of knowledge on designing, implementing, and maintaining Microsoft SQL Servers, Data analytics using Power BI and azure data pipeline and implementing security and working with stakeholders to understand their data needs and deliver solutions that meet those needs.
Accountabilities
Database Management:
Design, create, and maintain optimal database systems for various applications and services.
Monitor and optimize database performance, security, and integrity.
Handle database backups, recovery, and regular updates to ensure data accuracy and availability.
Collaborate with IT teams to maintain server infrastructure and ensure database reliability.
Configuring, solving problems, and supporting SQL Servers in production and non-production environments running in cloud environments and Windows operating systems
Develop and maintain a disaster recovery plan to measure ensure that critical data systems are available in the event of outages.
Develop and maintain a capacity plan to measure utilization and plan for growth in demand for database resources.
Design scripts and utilities to automate day to day database administration.
Assist with the monitoring performance analysis of existing applications and ensuring that the system is consistent with ongoing need
Create technical documentation, operational procedures, Incident, and Problem communications and reporting.
Quickly restore service during system outages, provide troubleshooting support to team members, perform proactive problem prevention, and advance technical details to technical lead and/or to vendor support
Maintaining, detail and deliver Microsoft SQL 2012+ in accordance with certified specifications and security guidelines.
Data Engineering:
Design and construct scalable, maintainable, and efficient data pipelines.
Implement and manage ETL processes, ensuring the accuracy, reliability, and timeliness of data processes.
Design and maintain enterprise level data model and data flow
Cloud and Integration:
Design and implement solutions in Azure, with a particular focus on Azure data pipeline.
Integrate Power BI solutions, ensuring that data sources are accessible and optimized for visualization.
Stay updated with the latest Azure features and Power BI advancements to recommend and implement improvements.
Collaboration & Training:
Collaborate with cross-functional teams, assisting with data-related technical issues, and ensuring optimal data delivery architecture.
Provide training and support to junior team members and stakeholders on database management and data engineering best practices.
Qualifications
BS in Information Technology or a related technical field plus 4-6 or more years related overall experience.
3-5 years of experience in data engineering
Strong understanding of data engineering principles and practices
Experience with Power BI and Azure Data Pipeline
Experience with SQL, Python, and other programming languages
Strong expertise in Azure data pipeline, including Azure Data Factory, Azure Data Lake, and other Azure data services.
Proficiency in Power BI, including designing and deploying insightful dashboards and data visualizations.
Strong knowledge of SQL and MS SQL databases, including optimization techniques.
Excellent understanding of data pipeline and workflow management tools.
Strong analytical skills with a problem-solving attitude.
Good interpersonal and communication skills, with the ability to collaborate effectively across diverse teams.
Certifications in Cloud and/or Microsoft SQL Server highly desired
A minimum of 3 years of experience in on-premises and cloud-based Database Technologies - AWS RDS and/or Azure SQL PAAS
Devise Strategy and Engage with IT leadership and business partners to define a Database & Analytics strategy for Rehrig
Implement automation of database operations like upgrades and patching
Demonstrated Experience in Defining and Implementing Production Proactive Health Monitoring of Database Technologies
Strong Incident Root Cause Analysis on Database Execution and Application Interaction with Database Technology
Experience with Data migration and SQL upgrades across Microsoft Server versions
Ability to travel approximately 15%-20% of the time
General Responsibilities
Provide periodic reporting on workforce capacity and utilization.
Provide periodic reporting on the availability and health of software development process.
Other duties as assigned.","$92,430 /yr (est.)",501 to 1000 Employees,Company - Private,Manufacturing,Machinery Manufacturing,1913,$100 to $500 million (USD)
"hire IT people
4.4",4.4,Remote,Senior Data Engineer,"Position- Data Engineer
Location- San Francisco, CA- Remote
Duration- 7 Months
MUST HAVE
Kubernetes – Very Strong and #1 – 4 to 5 years
Data Pipelines – ETL Preferred – Bring data to send back to other team
Understanding of Python is good and will code in Python – Not working on API’s
Good Understanding of Machine Learning Pipelines
Argo WorkFlow Experience
Docker and Jenkins – Would be good
Workflow Experience – Would be good
Job Description:
Can you please provide a summary of the project/initiatives which describes what’s being done? Will be part of Data Engineering Software Product development team and will be playing a role in Designing and developing high-volume, low-latency stream applications for mission-critical systems.
• What are the top 5-10 responsibilities for this position? (Please be detailed as to what the candidate is expected to do or complete on a daily basis)
o Responsible for developing software product which requires Spark on K8s with scala & Python programming skills.
o Responsible for building test automation suite
o Refactoring of existing code base to the high standards and detect hotspots.
o Responsible for enhancing the code base and meet the code coverage of 80%
o Responsible for supporting end customer use cases, identify gaps, bugs and new features required to fulfil end customer requirement.
o Responsible for building automation utilities to reduce redundant work.
• What skills/technologies are required (please include the number of years of experience required)?
o Spark on K8s
o Cloud knowledge
o Spark with scala/Java
o Python to support/contribute to Airflow orchestration.
o ETL knowledge
o Spark structured streaming
o Knowledge on Kafka
o Knowledge on Splunk
What skills/attributes are preferred (these are a desired, not required)?
o Apache Flink for real-time streaming.
o Azure knowledge
o Springboot microservice knowledge
What does the interview process look like?
o How many rounds? 1
o Video, phone, or in person? Video
o How technical will the interviews be? Will focus on all the required skills shared above.
Participates in the technical design of application systems. Develops and implements application systems by participating through the software development lifecycle from inception to delivery and beyond. The role is high touch position with a notable amount of collaboration across product teams and stakeholders to define requirements and understand how they fit into the end objective.
ESSENTIAL FUNCTIONS:
Designs and writes complex code in several languages relevant to our existing product stack, with a focus on automation
Configures, tunes, maintains and installs applications systems and validates system functionality
Installs new software releases and application system upgrades. Evaluates and installs software patches
Monitors and fine tunes applications system to achieve optimum performance levels and works with hardware teams to resolve issues with hardware and software
Assists with application system problem resolution by working with application developers, vendors, and internal infrastructure teams member to troubleshoot
Addresses product backlog and provide continuous delivery of high-quality features
Maintains a comprehensive operating system hardware and software configuration database/library of all supporting documentation to ensure data integrity
Acts to improve the overall reliability of systems and to increase efficiency
Works collaboratively with cross functional teams, using Agile / DevOps principles to bring products to life, achieve business objectives and serve customer needs
Job Type: Full-time
Salary: From $75.00 per hour
Experience level:
10 years
8 years
9 years
Schedule:
8 hour shift
Experience:
Informatica: 1 year (Preferred)
SQL: 1 year (Preferred)
Data warehouse: 1 year (Preferred)
Work Location: Remote",$75.00 /hr (est.),51 to 200 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1998,Unknown / Non-Applicable
"PBS Distribution
4.6",4.6,"Arlington, VA",Senior Data Engineer (Hybrid),"POSITION TITLE: Senior Data Engineer (Hybrid)
DEPARTMENT: Analytics and Technology
LOCATION: Arlington, VA
STATUS: Full-time, Exempt
MANAGER: Director, Data Engineering
PBS Distribution (PBSd)* is a leading distributor of public media content around the world, entertaining audiences across platforms and formats. The company, a joint venture of PBS and GBH Boston, provides premium content through multiple digital channels and video services. PBS Distribution operates six subscription streaming channels — PBS Masterpiece (US and CA), PBS KIDS, PBS Living, PBS Documentaries, and PBS America (U.K.) as well as numerous Free Ad-supported Streaming TV (FAST) Channels in the U.S and U.K. In addition, the company reaches viewers through transactional video-on-demand (TVOD), subscription video-on-demand (SVOD) licensing, Advertising-based Video on Demand (AVOD), DVD and Blu-ray, theatrical releasing, educational platforms, non-theatrical and inflight sales, and serves broadcasters and producers providing program sales and co-production financing.
At PBS Distribution, we want to best represent the communities that we serve. The global community is diverse, and we are our best when we have a team that reflects that. PBS Distribution is proud to be an equal opportunity workplace, celebrating, supporting, and thriving when our team is able to show up fully and authentically.

POSITION SUMMARY:
The Senior Data Engineer is responsible for the department's data value add work, including developing data models, maintaining a data warehouse and analytics environment, and writing scripts for data integration and analysis. This role will work closely and collaboratively with members of the Analytics and Technology teams to define requirements, mine and analyze data, integrate data from a variety of sources, and deploy high quality data pipelines in support of the analytics needs across the enterprise. They will also support the comprehensive Enterprise Data Catalog and manage other proprietary systems.

RESPONSIBILITIES:
Build, operate, and maintain ETL processes that gather data from video partners.
Model data pipelines in DBT to prepare data for analysis.
Write internal tools to assist with data cleaning and labeling.
Adhere to high standards for code quality and testing.
Clarify data requirements and priorities with other project teams.
WORK EXPERIENCE:
5+ years of experience building backend software or services
3+ years of experience working with large scale data. (1+ TBs, 100M+ rows)
EDUCATION/TRAINING:
Bachelor’s degree in computer science, Engineering, or related field
SKILLS:
5+ years of experience building complex server-side Python applications, processing data with Pandas, optimizing complex SQL queries at scale, and consuming REST APIs
3+ years of experience modeling data in relational and columnar databases, building data pipelines in DBT, managing cloud infrastructure with Terraform, and building internal tools using Django, Streamlit, or an equivalent framework
Able to work independently with minimal supervision while adhering to company policies, legal requirements, and customer specifications
Strong verbal, written, and interpersonal communication skills
PBS Distribution (PBSd) is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind.
PBS Distribution is a for-profit organization with a mission to drive profitable growth by building key partnerships and distributing inspiring content. PBS Distribution is headquartered in Arlington, VA with an additional office In Boston, MA.","$124,287 /yr (est.)",51 to 200 Employees,Unknown,Media & Communication,Broadcast Media,2009,Unknown / Non-Applicable
"MGX Beverage Group
3.4",3.4,"Mansfield, MA",Data Engineer,"With over 80 years of experience in the alcohol industry, MGX understands the complex US beverage alcohol business and enables our customers to navigate it more efficiently. We collaborate with retailers and suppliers to design and implement supply chain solutions to optimize a product’s route to market. MGX provides a single point-of-contact across the entire beverage alcohol supply chain, bringing together the services of our affiliated companies Gordon Logistics, Milton’s Distributing, and Hope Beverage.
We recognize that nothing happens without our people and that our team members are our most important asset. We’re a family-owned and operated business committed to building a culture that recognizes, respects, and rewards our employees. We offer competitive wages and comprehensive benefits coverage including medical, dental, 401K, profit sharing, and tuition reimbursement.

Job Summary:
We are seeking a skilled and highly motivated Data Engineer to join our team and play a critical role in building our data management practice and providing thought leadership in your area of expertise. This is an exciting opportunity to contribute to the growth and success of our company by providing and enhancing data-driven insights. This is also an opportunity to directly influence and drive the direction and capabilities of a new function that will be critically important to the company’s success.

Essential Functions:
Data Modeling: Design and develop efficient and scalable data models to support business reporting and analytics requirements in PowerBI. Work closely with stakeholders to understand their needs and translate them into effective data structures.
Data Integration: Collaborate with cross-functional teams to identify and gather relevant data from various sources, including internal databases, third-party APIs, and other external data sources. Ensure data quality and integrity through data cleansing, transformation, and validation processes.
Data Transformation: Implement data transformation logic, including data cleansing, aggregation, enrichment, and normalization, to ensure accurate and relevant data for analysis.
ETL Development: Design and implement Extract, Transform, Load (ETL) processes to extract data from multiple sources, transform it into usable formats, and load it into the data models. Optimize ETL workflows for performance and efficiency.
Data Governance: Establish data governance practices, standards, and guidelines to ensure data consistency, accuracy, and security across the organization. Implement appropriate data access controls and permissions for different user groups.
Performance Optimization: Monitor and analyze the performance of data models and queries in PowerBI. Identify and resolve performance bottlenecks through query optimization, indexing, and other techniques. Continuously improve the performance and responsiveness of the data infrastructure.
Documentation: Create comprehensive documentation, including data dictionaries, data flow diagrams, and technical specifications. Maintain up-to-date documentation of data models, ETL processes, and data lineage for future reference and knowledge sharing.
Collaboration and Communication: Collaborate with data analysts, business intelligence teams, and other stakeholders to understand their reporting and analytics requirements. Communicate effectively with both technical and non-technical stakeholders, presenting complex technical concepts in a clear and concise manner.

Skills and Qualifications:
Bachelor's degree in Computer Science, Engineering, or a related field. A master's degree is a plus. Significant experience and training in lieu of a degree will be considered
5+ years proven experience as a Data Engineer, Database Developer, or similar role, with a focus on designing and building data models for consumption in PowerBI and'or other analytical tools.
Strong expertise in data modeling concepts and methodologies. Experience with dimensional modeling and Data Marts'Warehouses is highly desirable.
Knowledge of data integration techniques and tools. Experience with data extraction from various sources (including unstructured data), data cleansing, and transformation is required.
Strong proficiency in Informatica Data Management Cloud, including experience in data integration, data transformation, and workflow automation.
Proficiency in PowerBI and other data visualization tools. Familiarity with Power Query and DAX is preferred.
Proficiency in SQL and programming languages such as Python for data manipulation, analysis, and automation.
Extensive knowledge and experience building and optimizing multidimensional models using SQL Analysis Services for complex analysis and reporting
Familiarity with data governance and data security best practices. Understanding of data privacy regulations and compliance (e.g., GDPR, CCPA) is a plus.
Strong problem-solving skills and attention to detail. Ability to analyze complex data requirements and translate them into practical solutions.
Excellent communication and interpersonal skills. Ability to work effectively in a team environment and collaborate with stakeholders at all levels of the organization.
Strong organizational and time management skills. Ability to handle multiple priorities and meet deadlines in a fast-paced environment.
Professional certifications and training in applicable technologies is a plus

EEO","$98,322 /yr (est.)",51 to 200 Employees,Unknown,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Voloridge Investment Management
4.7",4.7,"Jupiter, FL",Sr Data Engineer,"At Voloridge Investment Management our quantitative systems are deeply dependent on vast quantities of data. The Senior Data Engineer must understand the many different and evolving use cases for data at Voloridge and design systems that supply high-performance datasets for advanced analytics. In this role the Sr. Data Engineer / Architect will provide mentorship and impart experience to the data engineering team.
Summary of Job Functions
Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Analysts, QA Analysts, DBAs, and Data Engineers
Build and maintain data pipelines based on functional and non-functional requirements
Proactively seek out information and overcome obstacles to deliver projects efficiently
Ensure that data pipelines incorporate best practices related to performance, scaling, extensibility, fault tolerance, instrumentation, and maintainability
Ensure that data pipelines are kept simple and not overly engineered
Produce and maintain design and operational documentation
Analyze complex data problems and engineer elegant solutions
Stay abreast of emerging technologies and make relevant recommendations
Upgrade existing data models and pipelines leveraging newer features and techniques
Work in a Kanban environment
Mentor less experienced data engineers
Participate in engineering standards and best practices evolution
Participate in an on-call rotation
Lead investigations to troubleshoot pipeline issues
Minimum Requirements
10+ years with hands-on data engineering and deep knowledge of data architecture fundamentals including:
Extensive experience building ETL/ELT pipelines from a variety of data sources
Broad experience with SQL Server 2019+, including advanced SQL Server features such as Table Partitioning, Columnstore
Deep knowledge and measurable experience in performance tuning TSQL, execution plan analysis blocking/deadlock analysis and index optimization
Extensive experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures, and user-defined table types
Comprehensive experience with data modeling indexes, Temporal tables, CLR, and Service Broker
Deep understanding of the development of data pipelines with either SSIS or Python and building data pipelines using multiple external data sources and transport mechanisms
Strong initiative, collaboration, accountability, impartiality, and communication
Strong analytical skills, a real passion for working with data and strong interest in solving data problems
Strong track record for judging core requirements and meeting deadlines
Experience managing master data
Experience writing C#, PowerShell, and Python
Experience with Git source control integration with SSMS
Experience working in a Kanban SDLC and a strong understanding of traditional Kanban SDLC workflows
Experience with deploying changes through segregated Development, QA, UAT and Production SDLC stages
Experience owning mission-critical processes
Bachelor’s degree in Computer Science, Information Systems, or related disciplines
Ability to work onsite in our Jupiter, FL office
Preferred Skills and Previous Experience
Python programming using libraries such as Pandas, Numpy, csv, Traceback, JSON, PyODBC, Math
Experience with source code branching and pull requests / code reviews
Experience with AWS
Experience working with trading / financial / investment / accounting data
Experience with tools such as Red Gate, Grafana, OpsGenie and JAMS
Experience with MPP databases such as Greenplum
MS/PhD in Computer Science, Information Systems, or related disciplines
Compensation and Benefits
Highly competitive base salary
Profit sharing bonus
Health, dental, vision, life, and disability insurance
401K
Additional Information
Voloridge Investment Management is an SEC registered investment advisor. A private investment company founded in 2009, our mission is to deliver superior risk-adjusted returns for qualified investors, using advanced proprietary modeling technology, conservative investment tactics and sophisticated risk management.
Voloridge Investment Management is an Equal Opportunity Employer. All qualified applicants are encouraged to apply and will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other legally protected characteristic or status.","$130,714 /yr (est.)",51 to 200 Employees,Company - Private,Financial Services,Investment & Asset Management,2009,Unknown / Non-Applicable
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Grand Valley State University
4.2",4.2,"Allendale, MI",Data Engineer,"Summary
This position provides leadership in data management and data architecture infrastructure across the University. They are responsible for building and maintaining data pipelines that enable the flow of data from various sources into a data warehouse for analysis, visualization, and reporting purposes. The person in this position will work with I.T. and university stakeholders to create a modern framework for institutional analytical decisions to optimize student success and university business operations.
PRIMARY DUTIES
Support a data architecture to dynamically address data ingestion from various sources, integration, and data warehousing and analytics processes.
Consult with stakeholders and build data pipelines to collect data from different sources and process it to provide context for data analytics.
Build and maintain data warehouses and data lakes.
Develop and maintain data APIs and services for accessing data.
Ensure data quality and accuracy through data validation, cleansing, and other best practices for data management and data governance.
Monitor and troubleshoot data pipelines and systems.
Work closely with Data and Business Analysts to ensure data is available and accessible for analysis and modeling.
Collaborate on the research of emerging technologies supporting data platform efforts and recommend technologies that increase cost-effectiveness and systems flexibility. For example, identifying opportunities to automate repeatable and time-consuming data preparation and integration tasks.
Communicate the status of work to leadership and team members.
Education and training on data management infrastructure and data and analytics capabilities
Performs other duties as required/assigned by the manager.
KNOWLEDGE, SKILLS AND ABILITIES REQUIRED
Minimum 3 years of experience in a Data Engineer role and a Bachelor’s Degree in Computer Science, Statistics, Applied Mathematics, Engineering, or Information Systems.
A successful history of manipulating, processing, and extracting value from large disconnected datasets, including relational SQL and NoSQL databases.
Experience building and optimizing big data pipelines, architectures, and data sets.
Deep understanding of database design and management.
Experience in cloud infrastructure and cloud computing platforms.
Advanced working knowledge and experience with SQL, Python, Spark, and Hadoop.
Experience with REST APIs and JSON
Demonstrated experience with Analytics and Business Intelligence solutions or any data discovery tools.
Knowledge of Linux.
Strong project management and organizational skills to prioritize and execute tasks in a high-pressure environment and the ability to work collegially and interact effectively with a diverse constituency.
Experience working in an agile environment and applying DevOps and DataOps principles to improve communication, integration, reuse, and automation of data flows between data stewards and consumers across an organization.
KNOWLEDGE, SKILLS AND ABILITIES PREFERRED
Experience in Azure
Experience in Data Science
Experience using ERP in a higher-ed setting
This position does not require driving a company/university vehicle.
WORKING CONDITIONS
Normal office environment. Some travel may be required.
Physical Demands: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Must have the physical stamina to work long hours and/or more than 5 days per week. The requirements listed are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The information contained in this job description is for compliance with the Americans with Disabilities Act (A.D.A.) and is not an exhaustive list of the duties performed for this position. Additional duties are performed by the individual currently holding this position and additional duties may be assigned.
Salary: Commensurate with experience
Department/Division: Data and Analytics/ Information Technology
Campus: Allendale
How To Apply: Apply online at jobs.gvsu.edu and select ""Apply now"". Please include a cover letter and resume. The online application will allow you to attach these documents electronically. On the application, you will be required to provide names, phone numbers, and e-mail address for three professional references. Applicants selected for interviews will be required to submit official transcripts prior to the interview. If you need assistance, call Human Resources at 616-331-2215.
Application Deadline: Consideration of applications will begin August 29, 2023 after which the posting may be closed at any time at the discretion of the University.","$73,730 /yr (est.)",1001 to 5000 Employees,College / University,Education,Colleges & Universities,1960,Unknown / Non-Applicable
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Optimal Inc.
3.6",3.6,"Dearborn, MI",Data Engineer,"Position Description:
Create data tools for data scientist team members that assist them in building and optimizing our products
Product And Requirements Management: Participate in and/or lead the development of requirements, features, user stories, use cases, and test cases. Participate in stand-up operations meetings. Analyze and verify requirements for completeness, consistency, comprehensibility, feasibility, and conformity to standards.
Operations: Generate Metrics, Perform User Access Authorization, Perform Password Maintenance for Data Catalog team jobs, and Build Deployment Pipelines. Create detailed business analysis, outline challenges, opportunities, and solutions for the team and applications Incident, Problem, And Change/Service
Requests: Participate and/or lead incident, problem, change and service request-related activities. Includes root cause analysis (RCA). Includes proactive problem management/defect prevention activities. Design/Develop/Test/Deploy: Work with the Business Customer, Product Owner, Architects, Product Designer, Software Engineers, and Security Controls Champion on solution design, development, and deployment Plan and coordinate user acceptance testing of new application feature.
Skills and Experience Required:
3+ years of Qliksense/Qlikview experience
3+ years of Java and API experience
3+ years' experience with GIT
3+ years with SQL language and database management
3+ years' experience developing process documentation and reports.
Big data platform experience (Google Cloud Platform)
Strong critical and analytical thinking skills
Knowledge of automotive industry business processes
Programming in Python with data visualization experience, Java
Proficient Data management and processing technology skills including relational (PostgreSQL, SQL Server) and non-relational database technologies (Hive, Spark)
Education Required:
Bachelor's or Master's degree in computer science, STEM or related fields","$86,648 /yr (est.)",1 to 50 Employees,Nonprofit Organization,Education,Education & Training Services,2004,Unknown / Non-Applicable
"RADcube, LLC
3.6",3.6,"Cincinnati, OH",Data Engineer,"Description:
Role Must Haves:
ETL Packages: IBM DataStage 11.7/11.5/9.1/8.7(Designer) Languages/Tools: SQL, PL/SQL, Scripting Experience (examples: C++, Perl, Python, UNIX Shell Scripting) Hybrid Work: 2-3 days per week with team in the office Desire to learn new things and be taught 5/3s Data Product Strategy and Tools
Role Nice To Haves:
Databases: Hands on Snowflake development, Python, DBT, DB2, Oracle 11g/10g/9i Bigdata Tools: HDFS, MapReduce, Hive, Kafka, Sqoop, Impala Minimum of 2 years hands on technical experience – junior level is ok JOB SUMMARY Data Engineer
JOB DESCRIPTION CONTRACT ONLY UNTIL 12/2024. ONSITE 2-3 DAYS/WEEK. SOW Title: Data Engineer for Finance IT Data Product Team Current Time Frame: September 2023 – December 2024 Role Summary:Join the Enterprise Modernization Finance IT team as we develop and support the Data Product Strategy for Finance, Accounting, and Treasury. You will work with other Data Engineers on various Snowflake, DataStage, and SQL efforts. We have a strong culture of collaboration and mentorship. You will work with two of our Principal Data Engineers who will mentor you on our Data Product Strategy.
GENERAL FUNCTION:
The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data. The person in this role creates scalable and reusable solutions for gathering, collecting, storing, processing, and serving data on both small and very large (i.e. Big Data) scales. These solutions can include on-premise and cloud-based data platforms, and solutions in any of the following domains ETL, business intelligence, analytics, persistence (relational, NoSQL, data lakes), search, messaging, data warehousing, stream processing, and machine learning. Responsible and accountable for risk by openly exchanging ideas and opinions, elevating concerns, and personally following policies and procedures as defined. Accountable for always doing the right thing for customers and colleagues, and ensures that actions and behaviors drive a positive customer experience. While operating within the Bank's risk appetite, achieves results by consistently identifying, assessing, managing, monitoring, and reporting risks of all types.
GENERAL ESSENTIAL DUTIES AND RESPONSIBILITIES: -
Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities. - Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the Bank. - Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc. - Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics. - Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes. - Evaluate software products and Provide documented recommendations as needed. - Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents. - Participate in the planning process for hardware and software. - Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation. - Provide technical guidance and mentoring for other team members. - Manage and prioritize multiple assignments.
MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED: -
Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience. - Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group. - Fundamental understanding of distributed computing principles - Knowledge of application and data security concepts, best practices, and common vulnerabilities. - Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, Bi and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.
Requirements:
Role Must Haves:
ETL Packages: IBM DataStage 11.7/11.5/9.1/8.7(Designer) Languages/Tools: SQL, PL/SQL, Scripting Experience (examples: C++, Perl, Python, UNIX Shell Scripting) Hybrid Work: 2-3 days per week with team in the office Desire to learn new things and be taught 5/3s Data Product Strategy and Tools
Role Nice To Haves:
Databases: Hands on Snowflake development, Python, DBT, DB2, Oracle 11g/10g/9i Bigdata Tools: HDFS, MapReduce, Hive, Kafka, Sqoop, Impala Minimum of 2 years hands on technical experience – junior level is ok JOB SUMMARY Data Engineer
JOB DESCRIPTION CONTRACT ONLY UNTIL 12/2024. ONSITE 2-3 DAYS/WEEK. SOW Title: Data Engineer for Finance IT Data Product Team Current Time Frame: September 2023 – December 2024 Role Summary:Join the Enterprise Modernization Finance IT team as we develop and support the Data Product Strategy for Finance, Accounting, and Treasury. You will work with other Data Engineers on various Snowflake, DataStage, and SQL efforts. We have a strong culture of collaboration and mentorship. You will work with two of our Principal Data Engineers who will mentor you on our Data Product Strategy.
GENERAL FUNCTION:
The data engineer designs and builds platforms, tools, and solutions that help the bank manage, secure, and generate value from its data. The person in this role creates scalable and reusable solutions for gathering, collecting, storing, processing, and serving data on both small and very large (i.e. Big Data) scales. These solutions can include on-premise and cloud-based data platforms, and solutions in any of the following domains ETL, business intelligence, analytics, persistence (relational, NoSQL, data lakes), search, messaging, data warehousing, stream processing, and machine learning. Responsible and accountable for risk by openly exchanging ideas and opinions, elevating concerns, and personally following policies and procedures as defined. Accountable for always doing the right thing for customers and colleagues, and ensures that actions and behaviors drive a positive customer experience. While operating within the Bank's risk appetite, achieves results by consistently identifying, assessing, managing, monitoring, and reporting risks of all types.
GENERAL ESSENTIAL DUTIES AND RESPONSIBILITIES: -
Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities. - Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the Bank. - Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc. - Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics. - Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes. - Evaluate software products and Provide documented recommendations as needed. - Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents. - Participate in the planning process for hardware and software. - Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation. - Provide technical guidance and mentoring for other team members. - Manage and prioritize multiple assignments.
MINIMUM KNOWLEDGE, SKILLS, AND ABILITIES REQUIRED: -
Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience. - Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group. - Fundamental understanding of distributed computing principles - Knowledge of application and data security concepts, best practices, and common vulnerabilities. - Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, Bi and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.","$92,108 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,#N/A,Unknown / Non-Applicable
"BlueSnap
3.8",3.8,"Waltham, MA",Lead Data Engineer,"BlueSnap is a rapid-growth international FinTech company, headquartered in Waltham, MA, with offices in Israel, Ireland, and the UK. We are thrilled to be one of the fastest growing companies in the payments industry. Our team works collaboratively building a world-class payments orchestration platform that provides our clients with extensive capabilities, technologies, and services to accept payments in an optimized fashion.
BlueSnap is looking for an experienced and enthusiastic Senior Data Engineer who will work as a member of our global Business Intelligence team. This position can be considered either remote or hybrid in the New England area or on-site hybrid at our office in Waltham, MA.
Position Description:
Lead, Develop and maintain BlueSnap's Business Intelligence and Safeguarding solutions.
End to End responsibility of BI and Data Engineering projects: requirements, design, development, implementation and maintenance
Explore ways to enhance data quality, reliability and performance
Analyze and organize raw and structured data from different sources
Evaluate business needs and objectives
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Develop analytical tools and programs
Collaborate with BI Engineers and Finance team members on several projects
On-Call Duty
Requirements:
Technical expertise with data models, data mining, and segmentation techniques
Proven experience with ETL and Data Integration tools
Experience with Groovy and SQL
Strong analytic skills
Ability to independently troubleshoot
Strong team player skills and the ability to work harmoniously with diverse employees
Good oral and written communication skills, including ability to communicate complex ideas in a simple way
Experience in Oracle’s BI and EPM product suites is an advantage
Database maintenance skills is an advantage
Qualifications:
Bachelor’s Degree in Information Systems or any Business Intelligence related discipline
5+ years professional experience as a Data Engineer or BI Developer
2+ years of experience leading projects, assigning work and mentoring other engineers
As an eligible full-time BlueSnap team member you will receive a competitive salary, along with an excellent benefits package which will include BlueCross BlueShield medical and dental insurance, FSA, HRA, vision, life, disability and more! You will have the opportunity to save for retirement through our 401K plan which includes a generous company match. We find some of our best team members through employee referrals, which is why we provide you with the opportunity to earn significant referral bonuses. In addition, we provide our team members with a PTO plan that will help you enjoy nice work/life balance. These are just a few of the great benefits we offer. We look forward telling you more during the interview process with BlueSnap!
BlueSnap is an equal opportunity employer. We celebrate differences in both background and perspective. All our applicants are considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran, or disability status. We support equality of treatment in employment and are committed to having procedures to determine equal pay for our employees that do not discriminate and are free from bias.","$135,321 /yr (est.)",201 to 500 Employees,Company - Private,Financial Services,Financial Transaction Processing,2002,$100 to $500 million (USD)
Egen Solutions Inc,#N/A,"Naperville, IL",Staff Data Engineer,"Egen Data Engineering teams build scalable data pipelines using Python, Spark, and cloud services (GCP and AWS). The pipelines we build typically integrate with technologies such as Kafka, Storm, and Elasticsearch. We are working on a continuous deployment pipeline that leverages rapid on-demand releases. Our developers work in an agile process to efficiently deliver high value applications and product packages.
As a Staff Data Engineer at Egen, you will leverage Spark and GCP (preferred) to architect and implement cloud-native data pipelines and infrastructure to enable analytics and machine learning on rich datasets.
Required Experience:
Built and run resilient data pipelines in production and have implemented ETL/ELT to load a multi-terabyte enterprise data warehouse.
Implemented analytics applications using multiple database technologies, such as relational, multidimensional (OLAP), key-value, document, or graph.
Defined data contracts, and wrote specifications including REST APIs.
Transformed data between data models and formats with the most modern PySpark practices. Have built cloud-native applications and supporting technologies / patterns / practices including: Cloud Services, Docker, CI/CD, DevOps, and microservices.
Planned and designed artifacts that describe software architectures involving multiple systems and technologies
You've worked in agile environments and are comfortable iterating quickly.
Nice to have's (but not required):
GCP expertise is preferred but will consider AWS
Experience moving trained machine learning models into production data pipelines.
Experience in biotech, genomics, clinical research or precision medicine.
Expert knowledge of relational database modeling concepts, SQL skills, proficiency in query performance tuning, and desire to share knowledge with others.
This is full-time, On-site, and Remote. We are based out in Naperville, IL.
Looking forward to striking up a conversation with you on the opportunity!, Kindly visit our website egen.solutions
Job Type: Full-time
Pay: $116,284.90 - $140,042.03 per year
Benefits:
401(k)
Dental insurance
Health insurance
Experience level:
5 years
Schedule:
Monday to Friday
Experience:
Data Engineer: 5 years (Preferred)
Work Location: Hybrid remote in Naperville, IL 60540","$128,163 /yr (est.)",#N/A,#N/A,#N/A,#N/A,#N/A,#N/A
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Barbaricum
4.0",4.0,"Omaha, NE",Data Engineer,"Barbaricum is a rapidly growing government contractor providing leading-edge support to federal customers, with a particular focus on Defense and National Security mission sets. We leverage more than 15 years of support to stakeholders across the federal government, with established and growing capabilities across Intelligence, Analytics, Engineering, Mission Support, and Communications disciplines. Founded in 2008, our mission is to transform the way our customers approach constantly changing and complex problem sets by bringing to bear the latest in technology and the highest caliber of talent.

Headquartered in Washington, DC's historic Dupont Circle neighborhood, Barbaricum also has a corporate presence in Tampa, FL and Dayton, OH, with team members across the United States and around the world. As a leader in our space, we partner with firms in the private sector, academic institutions, and industry associations with a goal of continually building our expertise and capabilities for the benefit of our employees and the customers we support. Through all of this, we have built a vibrant corporate culture diverse in expertise and perspectives with a focus on collaboration and innovation. Our teams are at the frontier of the Nation's most complex and rewarding challenges. Join us.


Barbaricum is seeking a Data Engineer to provide support an emerging capability for the USSTRATCOM J2 at Offutt Air Force Base near Omaha, Nebraska.
This individual will work to migrate existing ad hoc data flows to JWICS AWS available to the enterprise. Initially, the Data Engineer will use Python to automate data gathering and data cleaning efforts. Using these foundational efforts, the Data Engineer will then develop, implement, and operate a data management system for the intelligence enterprise.
Due to security requirements, this position is primarily required to be performed on-site. However, subject to project and customer requirements, team members may be provided flexibility for limited remote support.
Responsibilities
Design, implement, and operate data management systems for intelligence needs
Use Python to automate data workflows
Design algorithms databases, and pipelines to access, and optimize data retrieval, storage, use, integration and management by different data regimes and digital systems
Work with data users to determine, create, and populate optimal data architectures, structures, and systems; and plan, design, and optimize data throughput and query performance
Participate in the selection of backend database technologies (e.g. SQL, NoSQL, etc.), its configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness
Assist and advise the Government with developing, constructing, and maintaining data architectures
Research, study, and present technical information, in the form of briefings or written papers, on relevant data engineering methodologies and technologies of interest to or as requested by the Government
Align data architecture, acquisition, and processes with intelligence and analytic requirements
Prepare data for predictive and prescriptive modeling deploying analytics programs, machine learning and statistical methods to find hidden patterns, discover tasks and processes which can be automated and make recommendations to streamline data processes and visualizations
Design, implement, and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests
Utilize Amazon Web Services (AWS) hosted big data technologies to store, format, process, compute, and manipulate data in order to draw conclusions and make predictions
Qualifications
Active DoD Top Secret clearance required
8+ years of demonstrated experience in software engineering
Bachelor’s degree in computer science or a related field. A degree in the physical/hard sciences (e.g., physics, chemistry, biology, astronomy), or other science disciplines (i.e., behavioral, social, and life) may be considered if it includes a concentration of coursework (typically 5 or more courses) in advanced mathematics and/or other relevant experience
8+ years of experience working with AWS big data technologies (S3, EC2) and demonstrate experience in distributed data processing, Data Modeling, ETL Development, and/or Data Warehousing
Demonstrated mid-level knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
3+ years of experience using analytical concepts and statistical techniques
8+ years of demonstrated experience across Mathematics, Applied Mathematics, Statistics, Applied Statistics, Machine Learning, Data Science, Operations Research, or Computer Science especially around software engineering and/or designing/implementing machine learning, data mining, advanced analytical algorithms, programming, data science, advanced statistical analysis, artificial intelligence
Preferred Experience
ArcGIS expertise
Experience using Python’s NumPy
Familiar with git-based revision control
Familiar with DevSecOps analytics development
Additional Information

For more information about Barbaricum, please visit our website at www.barbaricum.com. We will contact candidates directly to schedule interviews. No phone calls please.","$82,437 /yr (est.)",51 to 200 Employees,Company - Private,Management & Consulting,Business Consulting,2008,$5 to $25 million (USD)
"Rivian
3.4",3.4,"Irvine, CA",Sr. Data Engineer,"About Rivian:
Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.

As a company, we constantly challenge what’s possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.
Role Summary:
In this position, you will contribute to the data engineering needs of Rivian's Product Development Organization. You will manage the back end data from enterprise engineering applications and non enterprise applications such as our internal engineering applications. Additionaly you will be responsible for preparing, analyzing and serving data as needed for our development tools that deliver insights to the Product Development Organization.

To deliver you must be a team player, technicaly capable and able to think critically. To excel at this position you will have to navigate technical IT discussions, Enterprise Technology platforms, data architecture, and and colaborate cross fucntionally. You will also have to stay up to speed on the latest tools and technology in the data engineering world.
Responsibilities:
Create Big Data Solutions with high volumes & variety of data from PLM and other engineering applications and machines.
Collaborate with other technology teams to implement a framework of tools and technologies to ingest high volume of data to support engineering analytics, data science and machine learning use cases.
Solve complex analytical requirements using software engineering tools.
Support and utilize tools and technologies to provide data governance – data catalog and lineage.
Create data applications with ability to do searches, real time data alerts, APIs to pull the data on a large volume of data.
Build data applications to provide real-time data alerts & high throughput analytics
Qualifications:
Bachelors/Masters in data science, computer science, engineering, mathematics, or a related technical discipline preferred
Strong communication and leadership & collaboration skills.
Prior experience with PLM and handling product data management (PDM) in high volume manufacturing environment.
Passion for software & data engineering, pioneering data technologies and architecture. Ability to understand complex business problems and provide software solutions.
3+ years of experience in building petabyte scale data platforms and Big Data architecture using AWS services & open-source technologies.
Extensive hands-on experience in using AWS & open-source services like Glue, Spark Kinesis/Kafka, S3, Athena, Sagemaker
Hands-on experience in one or more programming languages like Python, Java, Scala.
Real-life production experience in creating architectural framework and tools for Data Science teams to build, train & scale machine learning models.
Strong hands-on experience with NOSQL, Columnar and Relational databases.
Understanding of data catalog solutions like Alation, Collibra, Atlas
Experience in building CI/CD framework for the data teams
Experience with infrastructure as code
Pay Disclosure:
Salary Range California-Based Applicants: $150,000 -$173,000 (actual compensation will be determined based on experience, and other factors permitted by law).
Company Statements:
Equal Opportunity
Rivian is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law.

Rivian is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at candidateaccommodations@rivian.com.
Candidate Data Privacy
Rivian may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Rivian may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law.

Rivian may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our People Team, Finance, Legal, and the team(s) with the position(s) for which you are applying; (ii) Rivian affiliates; and (iii) Rivian’s service providers, including providers of background checks, staffing services, and cloud services.

Rivian may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions.

Please note that we are currently not accepting applications from third party application services.","$103,502 /yr (est.)",5001 to 10000 Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2009,Unknown / Non-Applicable
"Elevance Health
3.7",3.7,Remote,Data Engineer Sr (contract),"Job ID: #JP00043626

Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. Previously known as Anthem, Inc., we have evolved into a company focused on whole health and updated our name to better reflect the direction the company is heading.

We are looking for contract workers (via BCforward) who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact?

Primary duties may include, but are not limited to:
Undertakes complex assignments requiring additional specialized technical knowledge.
Develops very complex and varied strategic report applications from a Data Warehouse.
Establishes and communicates common goal and direction for team.
Establishes and maintains advanced knowledge of data warehouse database design, data definitions, system capabilities, and data integrity issues.
Acts as a source of direction, training and guidance for less experienced staff.
Monitors project schedules and costs for own and other projects.
Develops and supports very complex Data Warehouse-related applications for business areas requiring design and implementation of database tables. Conducts training on use of applications developed.

Requirements:
Requires a BS/BA degree; 6 years experience; or any combination of education and experience, which would provide an equivalent background.
Expert level PC, spreadsheet, and database skills, as well as experience in standard Business Information tools and programming/query languages is also required.
Ability to communicate effectively with multiple levels within the organization.
This job is focused on spending time thinking about programming and how it would be used to design solutions as compared to the Bus Info Developer Consultant job
SQL, Visual Studio, VB, SSRS, Power BI, Tableau, SSIS

Additional Details:
40 hours/week centered around EST hours - flexible with shift times as long as they are available for meetings during EST (typically around 9am-3pm would be when our meetings would happen). Open to candidates anywhere in the US - 100% remote.
Possible Temp to hire

BCForward is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Privacy Notice for California Residents",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2004,$10+ billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Iron Systems
3.3",3.3,"Malvern, PA",Data Engineer,"Date Posted:
8/16/2023

Job Function:
Software Development

Location:
Malvern PA - USA

Offered Salary:
Competitive


Iron Systems is an innovative, customer-focused provider of custom-built computing infrastructure platforms such as network servers, storage, OEM/ODM appliances & embedded systems. For more than 15 years, customer have trusted us for our innovative problem solving combined with holistic design, engineering, manufacturing, logistic and global support services.

Job Title: Data Engineer
Location: Malvern PA

Responsibilities:
Participate in agile team meetings, analyze requirements, design and build data pipelines using AWS infrastructureQualifications:
Pyspark, SQL, Python, AWS Glue ETL, AWS EMR, AWS S3, Control M","$97,212 /yr (est.)",201 to 500 Employees,Company - Private,Information Technology,Information Technology Support Services,1987,$25 to $100 million (USD)
"Disney
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"Associate Data Engineer- Machine Learning
Job ID
10058063
Location
Seattle, Washington, United States
Business
The Walt Disney Company (Corporate)
Date posted
Aug. 16, 2023
Job Summary:
At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"OneStudyTeam
3.2",3.2,Remote,Senior Data Engineer,"At OneStudyTeam (a Reify Health company), we specialize in speeding up clinical trials and increasing the chance of new therapies being approved with the ultimate goal of improving patient outcomes. Our cloud-based platform, StudyTeam, brings research site workflows online and enables sites, sponsors, and other key stakeholders to work together more effectively. StudyTeam is trusted by the largest global biopharmaceutical companies, used in over 6,000 research sites, and is available in over 100 countries. Join us in our mission to advance clinical research and improve patient care.
One mission. One team. That’s OneStudyTeam.
Our unique, rapidly growing data streams are enabling novel opportunities to manage clinical trials more efficiently and predictably. The Data Engineering team is looking for talented Senior Data Engineers to build, expand, and support a cutting-edge data architecture which is the analytical backbone of our company. If you are empathetic, business-driven, and want to use your data engineering and data architecture skills to make a tangible impact in the clinical research community then this may be the role for you.
We're looking for people who can effectively balance rapid execution and delivery with sustainable and scalable architectural initiatives to serve the business most effectively. You have strong opinions, weakly held, and while well-versed technically know when to choose the right tool, for the right job, at the right level of complexity. You will work closely with the rest of our Data Engineering team and our Data Science teams to help collect, stream, transform, and effectively manage data for integration into critical reporting, data visualizations, and ModelOps systems for emerging data science products.
What You’ll Be Working On
Build reliable and robust data integrations with external partners
Supporting the development and expansion of modern, privacy-aware, data warehouse and data mesh architectures
Helping to build, manage, orchestrate, and integrate streaming data sources, data lakes, ELT processes, columnar storage systems, and distributed query execution solutions
Establishing proactive data quality/freshness dashboards, monitoring, alerting, and anomaly remediation systems
Building practical data onboarding tooling and process automation solutions
Learning to effectively understand and deftly navigate the global compliance ecosystem (HIPAA, GDPR, etc.) to ensure your work respects the rights, regulations, and consent preferences of all stakeholders, including historical underserved or underrepresented populations
Developing a deep understanding of the clinical ecosystem, our products, and our business and how they all uniquely interact to help people
What You’ll Bring to OneStudyTeam
4+ years of experience successfully developing and deploying data pipelines and distributed architectures, ideally in a space similar to ours (startup, healthcare, regulated data)
Hands-on experience implementing ETL/ELT best practices at scale and demonstrated practical experience or familiarity with a good portion of our stack, including: AWS services (Redshift, MSK, Lambda, ECS, ECR, EC2, Glue, Quicksight, Spectrum, S3, etc.), Postgres, dbt, Kafka, Prefect, Docker, Terraform
Excellent programming skills in Python and deep comfort with SQL. Clojure experience is also highly appreciated
Experience or interest in developing and managing enterprise-scale data, distributed data architectures
Able to independently ship medium-to-large features and start to support or participate in architectural design
Excellent written and verbal communication skills
Strong attention to detail is key, especially when considering correctness, security, and compliance
Solid software testing, documentation, and debugging practices in the context of distributed systems
Learn more about our global benefits offerings on our careers site: https://careers.onestudyteam.com/us-benefits
We value diversity and believe the unique contributions each of us brings drives our success. We do not discriminate on the basis of race, sex, religion, color, national origin, gender identity, age, marital status, veteran status, or disability status.
Note: OneStudyTeam is unable to sponsor work visas at this time. If you are a non-U.S. resident applicant, please note that OST works with a Professional Employer Organization.
As a condition of employment, you will abide by all organizational security and privacy policies.
For a detailed overview of OneStudyTeam's candidate privacy policy, please visit https://careers.onestudyteam.com/candidate-privacy-policy. This organization participates in E-Verify (E-Verify's Right to Work guidance can be found here).",#N/A,201 to 500 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2012,Unknown / Non-Applicable
"Credit One Bank
3.2",3.2,"Las Vegas, NV",Data Engineer II,"Position Summary
This position is a part of the Data Strategy, Governance, and Analytics (DSGA) group. The Data Ops team is part of the DSGA, and its principal responsibility is to build and run the processes to capture the data created during the business’s day-to-day operations, validate, integrate, and bring it all together to make it available across the business for analytical purposes. The key success factor for data ops is that business can get their hands on high-quality, well-curated data in a timely, accurate, and integrated fashion.
The mission of the data ops team is to support the data and analytical needs of the business which are growing rapidly with the business growth, new products, partners, technological ecosystem, and expectations of a data-driven business environment.
The Data Ops Data Engineer is an experienced data / IT professional with a demonstrable background in data warehouses/data lakes and has been involved in analysis, design, development, and delivery tasks for data applications supporting very large volumes.
In addition to strong technical skills, the successful candidate also exhibits a highly collaborative and team-oriented attitude and has good interpersonal skills, oral and written presentation skills, and critical thinking skills. The successful technical lead is open and flexible to new ideas, and a fast learner who does not hesitate to dive into learning new tools, and practices to upgrade the bank’s data applications to the future state of data analytics.

Essential Job Functions:
Lead, develop, and maintain high-quality and optimal solutions related to data ingestion, loading, and data curation.
Design and develop data pipelines and the underlying architecture to support disparate patterns of analytical usage by partner teams within DSGA and business, in a stable and high-performant way.
Work with Scrum masters, product owners, Subject Matter Experts, and other data engineers within the team to drive agile data programs.
Ensure adherence to published development standards and database best practices resulting in consistent and efficient implementation of solutions.
Translate business requirements into data solutions leading the development team’s data analysis and ETL design efforts.
Provide crisp communication to stakeholders on the progress of data projects and escalates issues in a timely manner.
Ensure that work and processes are well documented.
Interact with process SMEs and senior/executive leaders across the business.
Anticipate issues based on knowledge of internal data trends and propose solutions.
Serve as an expert consultant to internal technical and line of business teams.
Promote data validation, data quality, and governance goals, ensure the accuracy of deliverables, and communicate precisely.
Perform other duties as assigned.
Position Requirements
3+ years’ experience building Data Warehouse and Business intelligence solutions.
1+ years of experience with Big Data tools (Python, Spark, HDFS, Hive) and technologies.
Expertise in Data Analysis, Database Design, and Data Architecture; strong SQL skills.
Should be able to effectively identify test scenarios to assist with systems and user testing.
Provides input on the development of project plans, test plans, and implementation plans including determining estimates on time frames and needed resources.
Ability to work in a collaborative environment on complex problems.
Ability to troubleshoot Code and Data quality issues.
Strong communication and documentation skills.
Solid planning, priority setting, and time management skills
Preferred
Experience in financial industry, like retail banking or credit card business.
Credit One Bank, N.A. is a data-driven financial services company based in Las Vegas. Founded in 1984, Credit One Bank offers a spectrum of credit card products for people in all stages of financial life. Credit One Bank is an equal opportunity employer committed to diversity and inclusion and does not discriminate against any employee or applicant for employment because of age, race, religion, color, disability, sex, sexual orientation, or national origin. Reasonable accommodations can be made for those who require them, including access to job applications and workplace accommodations. Employment at Credit One Bank is based on mutual consent (also known as at-will). This means that employees and the Bank may terminate the employment relationship at any time, with or without cause and with or without notice. Please contact the recruiter for this position to learn more. Credit One Bank does not accept unsolicited resumes from agencies and is not responsible for related fees.","$97,015 /yr (est.)",501 to 1000 Employees,Company - Private,Financial Services,Banking & Lending,1984,Unknown / Non-Applicable
Hummingbird,#N/A,Remote,Data Engineer,"Hummingbird is a remote-first, fully distributed team united by the shared mission of helping fight financial crime. Since our launch in 2017, we’ve helped major financial institutions and tech-savvy trailblazers alike (e.g. Stripe, Affirm, etc.) orchestrate their compliance programs through our thoughtfully designed, intuitive SaaS product. We believe finding and stopping financial crime is a problem rooted in code, language and design, so we built the product that the heroes doing this work deserve.
We are customer-obsessed, and we love building and shipping great products. We set a high bar, challenge our assumptions, seek diverse opinions, and support each other to do our best work.
We do our best to write inclusive, descriptive and accurate job descriptions, but we’re not always perfect. If you’re interested in the role, we’d love to hear from you even if you don’t feel like you meet everything we’re looking for. We’re always iterating and improving, and it’s possible that your experience is even more impactful than we could have imagined.

About the Role
We are looking for a driven data engineer to join our team and champion the use of data at Hummingbird. Data plays a crucial role in our mission to fight financial crime and you will help us find new and innovative ways to leverage it to provide powerful tools for our users, and allow us to better understand the usage of our product. Hummingbird is uniquely positioned at the intersection of financial technology, security, policy, and law enforcement and as such we have built up a one of a kind data set that we can now use to give our customers the edge in their efforts to stay ahead of criminals. As an employee at a small startup, you will have the opportunity to wear many hats, working from product discovery through implementation.
What you’re looking to do:
Level up our use of data to make better decisions, build more powerful features, and fight financial crime
Leverage Infrastructure as Code (IaC) to manage and deploy infrastructure that supports a variety of different projects, such as data replication and orchestration for machine learning workflows
Build new data pipelines for ingesting data into our data warehouse via both batch and streaming architectures
Work closely with data science to enable us to build products that benefit our customers while keeping compliance and security at the forefront
Achieve goals through a combination of independent building, educating your peers, and influencing others to contribute towards your vision
What we’re looking for:
A data engineer with a history of taking projects from the earliest stages through successful rollout to production
Someone who is excited by the prospect of pioneering data as a practice at a fast growing startup and who is unafraid to dig in to discover what is possible
A flexible self starter that will cut across organizational lines to understand the business and identify the most valuable work
An engineer who brings a pragmatic approach to problem solving, favoring simplicity and shortening delivery cycles
Experience building data pipelines for sensitive data, including best practices for de-identification and data security
Experience deploying infrastructure via terraform or a similar infrastructure as code tool
Expertise in SQL and one or more programming languages, especially python
What’s in it for you:
The chance to help build from the ground up. The hires we’re making now are foundational to our growth as a company, so you will have an opportunity to help shape the future of Hummingbird.
Competitive compensation including cash and equity.
Remote-first, fully distributed company with flexible working hours.
Awesome health, vision & dental benefits, and 401k.
Safe, respectful & comfortable work environment with colleagues and leadership who prioritize diversity, equity, inclusion, and belonging.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please don't hesitate to contact us to request accommodation.",#N/A,Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
The position requires a Master’s degree in Computer Science, Engineering (any), or any technical/analytical field that is closely related to the specialty, plus one (1) year of experience in an IT/Computer-related position.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"CarOffer
3.9",3.9,"Addison, TX",Sr. Data Engineer,"We are an innovative and customer-centric company that revolutionizes car selling and buying. With a transparent and trustworthy approach, we simplify the process, providing fair valuations and quick offers for sellers, and an extensive, thoroughly inspected inventory for buyers. Join us in driving towards a sustainable automotive future, where the car trading experience becomes seamless and enjoyable for all.
Role overview
As a Principal Analytics Data Engineer at our organization, you will be at the forefront of revolutionizing the way we leverage data to drive insights and decision-making. Your primary focus will be designing, developing, and maintaining a robust and scalable data analytics infrastructure, enabling efficient data storage, retrieval, and analysis. Collaborating closely with data analysts, scientists, and cross-functional teams, you will craft interactive visualizations and dashboards to empower stakeholders with actionable insights. With a keen eye for data governance and performance optimization, you will ensure that our analytics ecosystem operates transparently, delivering a seamless and rewarding experience for all users. Your expertise and leadership will be instrumental in shaping our data-driven future and guiding our organization towards data excellence.
What you'll do
Data Analytics Infrastructure: Lead the design, development, and maintenance of a cutting-edge data analytics infrastructure. You will build robust data models, warehouses, and pipelines to enable efficient data storage, retrieval, and processing, ensuring the seamless flow of data throughout the organization.
Actionable Insights: Collaborate closely with data analysts, scientists, and business stakeholders to understand data requirements and translate them into actionable insights. You will develop interactive visualizations and dashboards that empower teams to make informed decisions and drive business growth.
Data Governance and Performance Optimization: Ensure adherence to data governance principles, data security, and privacy standards while continuously optimizing data pipelines and analytics queries for top-notch performance. Your focus on efficiency will enhance the speed and accuracy of data-driven processes.
Innovation and Best Practices: Stay at the forefront of data engineering and analytics technologies, evaluating and implementing emerging tools and best practices. Your expertise will shape our data strategy, maximizing the value derived from our data assets.
Leadership and Mentorship: Act as a subject matter expert and mentor for data engineering teams, providing guidance, support, and technical leadership. Your collaborative approach will foster a culture of innovation and continuous improvement within the organization.
Cross-Functional Collaboration: Work closely with cross-functional teams, including product managers, developers, and data scientists, to align data engineering efforts with business objectives. Your ability to communicate complex technical concepts to non-technical stakeholders will be invaluable in driving successful projects.
Scalable Solutions: Architect data solutions that can scale to accommodate growing data volumes and evolving business needs, ensuring our analytics ecosystem remains agile and adaptable.
What you'll bring
The successful candidate will be required to perform their duties onsite in the CarOffer's Addison, Tx office.
Bachelor's degree in Computer Science, Data Science, Statistics, or a related field required. Master's preferred or equivalent practical experience and relevant certifications will also be considered.
4+ years of experience as a software engineer, including 3+ years as a Data Engineer
Professional experience developing and executing on a data warehouse and/or data platform strategy using a modern data stack
Confident and experienced looking at data platform architecture as a whole and helping to drive strategic roadmap decisions
Ability to move quickly in a dynamic and cross-functional team environment
Expertise in SQL, Python, and system architecture – with the ability to understand the context of a business need and build a system that addresses it
Job Type: Full-time
Pay: Up to $130,000.00 per year
Benefits:
401(k) matching
Health savings account
Life insurance
Paid time off
Referral program
Retirement plan
Vision insurance
Compensation package:
Bonus pay
Experience level:
5 years
Schedule:
Monday to Friday
Ability to commute/relocate:
Addison, TX 75001: Reliably commute or planning to relocate before starting work (Required)
Experience:
SQL: 5 years (Preferred)
Data warehouse: 5 years (Preferred)
Work Location: In person","$130,000 /yr (est.)",201 to 500 Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2019,Unknown / Non-Applicable
"SWJ TECHNOLOGY, LLC
3.7",3.7,"Peoria, IL",Data Quality Engineer,"What Is the Opportunity?

We create trusted strategic products and services to unlock the power of our data. We enhance and measure our ability to access, govern, manage, connect and integrate internal and external data assets and ensure our employees understand the value of data and the impacts to our business. As a Data Quality Engineer, you will develop strategies to promote effective data governance practices to ensure that data is consistent, trustworthy, and doesn't get misused. You will measure accuracy, completeness, consistency, and reliability of data to embody and promote Traveler's data culture values. Consulting with business partners, you will assist in the design implementation, and drive the adoption of data management, governance, and metadata policies, standards, and best practices. You will develop and own project timelines and plans for assigned projects. Leveraging your understanding of the data ecosystem, business process and decision-making, as well as the data value chain, you will analyze medium complexity customer requests for changes to data management tools in order to determine impact on existing systems, process and develop appropriate specifications, enhancements, and procedures to comply.

What Will You Do?

Govern the process of managing the availability, usability, integrity security and privacy of the data

Collaborate with partners and assist with the design, development and implementation of innovative governance practices, roles, responsibilities.

Develop procedures, processes, and support the development of remediation plans to assure data quality for business purposes

Perform complex data profiling and analysis; communicates results in support of data quality processes.

Partner with business customers to recommend, develop, maintain and prioritize business data quality requirements, specifications, and rules.
Assist in defining metadata repository, data catalog, reference data management, and data lineage capabilities.

Work with business customers to ensure appropriate naming definitions and standards are being followed.

Facilitate the root cause analysis and resolution of business data management issues, including proposal and implementation of specification or procedural changes to address issue, working with impacted areas.

Leverage knowledge of data models, data relationships, mapping lineage and business rules to ensure that solutions meet operational and business needs.

Analyze medium complexity customer requests (internal or external, e.g., data calls) for changes to production systems, determine impact on existing systems, process and develop appropriate specifications, enhancements, and/or procedures to comply.

Leverage tools, processes, and workflows to capture knowledge, find information and maintain its relevance.

Design the creation, maintenance and governance of taxonomies and ensures its applicability to content and/or data.
SWJ TECHNOLOGY and all of its subsidiaries (i.e., NGE EQUIPMENT and ProjectOne US) are Equal Opportunity Employers and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender, disability status, protected veteran status, or any other characteristic protected by law.
JhzRi7OWMr","$87,931 /yr (est.)",51 to 200 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Starbucks
3.7",3.7,"Seattle, WA",data engineer sr,"Senior data engineer
Job Summary and Mission
This position contributes to Starbuck's success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing, and support for data pipelines and data products to enable continuous data processing for data exploration, data preparation, and real-time business analytics.
Summary of Key Responsibilities
Responsibilities and essential job functions include but are not limited to the following:
Demonstrate deep knowledge of the data engineering domain, including non-interactive (batch, distributed) & real-time, highly available data, data pipelines
Deep knowledge of data as a concept and the development of domain driven data products.
Optimization of data products to service customer personas, Data science, AI/ML and data visualization.
Knowledge of semantic data concepts.
Build fault-tolerant, self-healing, adaptive, and highly accurate data computational pipelines
Provide consultation and lead the implementation of complex programs
Develop and maintain documentation relating to all assigned systems and projects
Perform root cause analysis to identify permanent resolutions to software or business process issues
Basic Qualifications
Bachelor’s degree in computer science, management information systems, or related discipline, or equivalent work experience
MUST HAVE Technology skills (7/10 or higher):
Strong/expert Spark (PySpark) Using Jupyter Notebooks, Colab or DataBricks
Hands-on data pipeline development, ingest patterns in Azure
Orchestration tools, ADF or Airflow
SQL
Denormalized Data modeling for big data systems
MUST HAVE competencies:
Collaborative, able to work remotely, and still be an engaging team member.
Strong analytical and design skills.
Years
Architect and design large scale high performance distributed systems 7-10
SQL Platform 7-10
No-SQL Platform 3+
Spark 3+
Data platform implementation on Azure or AWS 3+
CI/CD experience 2+
Exposure to SOA architecture 2+

div>
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

We are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.

Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at applicantaccommodation@starbucks.com.","$128,868 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1971,$10+ billion (USD)
"DraftKings
4.0",4.0,Remote,SENIOR DATA ENGINEER,"REMOTE - US
ENGINEERING
JR07222
FULL TIME
At DraftKings, we're inspired by our shared passion for developing creative solutions to complex challenges and empowering the people around us to do their best work. We are industry leaders in the digital entertainment and technology space and are propelled by constant curiosity and diverse perspectives.
LOVE DATA? WE DO TOO.
We are looking for a Senior Data Engineer to join our BI Dashboarding team, who will play a vital role in our organization's data-driven approach. Your responsibilities will include designing and developing visually compelling and insightful reports and dashboards to provide actionable insights to various stakeholders. Additionally, you will optimize report performance, and data pipelines, create and optimize Directed Acyclic Graphs (DAGs), automate reports and processes, create Tableau reports, and maintain the Tableau server. Sounds good to you? Join us.
WHAT YOU’LL DO AS A SENIOR DATA ENGINEER:
Design processes that support data transformation, structures, metadata, dependency, and workload management.
Work with product owners and tech leads to implement high-quality, production-grade data pipelines and ETL processes.
Partner with our stakeholders to build reports that provide insights about key business metrics.
Leverage your strong communication skills and experience working with global teams to be an evangelist for data engineering across the organization.
Be flexible and able to adapt rapidly. We roll out products very quickly, and priority management is critical.
Utilize your experience to mentor, guide, and advise on best practices for delivering performant solutions.
Drive an organizational focus on performance analysis, optimization, and tuning.
WHAT YOU’LL BRING:
3+ years of hands-on experience with business intelligence and data engineering, including data warehousing, delivery, and operations.
The ability to leverage new technologies to test, build, and optimize data pipelines, transformations, architectures, and data sets.
Strong knowledge of various data engines (SQL Server, MySQL, Amazon Aurora, Redshift). Snowflake experience is a big plus.
A solid understanding of dimensional modeling is required.
Excellent communication and interpersonal skills to effectively communicate with business and technical teams.
Experience with data reporting tools (e.g., Tableau), data cataloging tools (e.g., Alation), and data logging/monitoring tools (e.g., Datadog) is preferred.
Experience in the i-Gaming industry is a big plus.
#LI-CG1
JOIN US!
Our teams are fueled by innovation. We are looking ahead, building what’s next, and continuously reinventing the industry. We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston, with teams around the world and an expanding global presence.
We strive to create a place where all feel safe, empowered, engaged, championed, and inspired. DraftKings is proud to be an equal opportunity employer. This means we do not tolerate discrimination of any kind and are committed to providing equal employment opportunities regardless of your gender identity, race, nationality, religion, sexual orientation, status as a protected veteran, or status as an individual with a disability.
READY TO BUILD WHAT’S NEXT? APPLY NOW.
As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment.
The US base salary range for this full-time position is $116,800.00 - $175,200.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Internet & Web Services,2012,Unknown / Non-Applicable
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Analytica
3.4",3.4,Remote,Data Engineer,"Analytica is seeking a remote Data Engineer to support a high-profile financial regulatory client with developing data pipeline and ETL solutions in an AWS cloud environment.
Analytica has been recognized by Inc. Magazine as a fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.
Responsibilities include (but not limited to):
Develops tools and infrastructure for data processing use cases
Designs and builds data pipelines that ingest and transform data using programming languages such as Python and SQL, and data orchestration tools
Designs, builds, and maintains data storage and processing infrastructure that allows working nimbly through extensive amounts of analytics data
Build and deliver data lake, integrate with existing data catalog prototype, and migrate to big data applications from on-premise to the new computing platform by leveraging new technologies (such as Apache Spark)
Qualifications:
Bachelor's degree in information systems, computer science, engineering, finance, or related degree or functional discipline
At least three (3) years of experience building flexible and scalable ETL processes and data pipelines
Extensive experience developing in Python and SQL
Should be well organized, thorough, and able to handle competing priorities
Knowledge and experience with Agile, Scrum, and DevOps principles and practices
Experience in any big data technologies - Hadoop, Amazon Redshift, AWS DevOps, Azure CosmosDB, Azure Data Lake, AWS DynamoDB, or advanced analytics tools will be plus
VeDM6NPQva",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2009,$5 to $25 million (USD)
"Telos Health, Inc.",#N/A,"Campbell, CA",Software Engineer II - Data,"Why Telos Health?
At Telos Health we are developing novel robotic-assisted technologies and interventional capabilities that will forever change the disparate outcomes of ischemic stroke – a disease that impacts close to a million people a year in the U.S., and 10 million worldwide. Not only is Telos changing the way stroke is treated, but also bringing this treatment to the greater population who is currently without. We are actively building a team who is focused on developing novel solutions for this complex disease – a disease in which one in four adults will face in their lifetime.

What You’ll Do:
We are looking for a talented Software Engineer to work at the crossing of DevOps, MLOps, and Data Engineering. You would be responsible to help the Software teams to be more effective by implementing the infrastructure for all data generated by the Telos robotic platform. As one of the key members of the team, you will design and implement our data lakes, databases, and data pipelines to ingest seamlessly vast amount of data generated by the system as well as building out our capabilities of CI/CD, artifact storage, dependency management for the software team as well as enabling the machine learning team to be effective in handling data, annotations, model development and experiment tracking. You will be employing a wide range of technologies and expand your skillset in software development, cloud management, and operations. You will work closely with other software engineers as well as system engineers to design and implement solutions that meet clinical and engineering needs.

What You’ll Bring:
BS in Computer Science, Data Engineering or equivalent and 2+ years of related experience; or MS in Computer Science; or equivalent combination of education and 1+ years of work
Experience with code hosting and ci/cd platforms such as GitLab, GitHub
Experience selecting and configuring databases, data warehouses and data lakes
Experience setting up data, and processing pipelines with tools such as Airflow.
Experience with MLOps concept and tools
Strong programming skills with Python and SQL
Experience with infrastructure as code and language such as Terraform
Experience with data visualization tools
Excellent communication and documentation skills

Desired Knowledge
Experience with software development in a regulated industry (IEC62304 preferred).
Experience with C++/ CMake software environments
Experience with dependency/ package managers like conan (C++), vcpkg (C++), pip (python), conda (python), poetry (python)
Background in cloud computing technologies and data analytics with tools such as Spark and Hadoop
Experience with data anonymization and HIPAA regulation
Experience setting up data storage that follows GDPR requirements
Experience with managing video and audio data storage and pipelines

Salary Range:
$120,000 - 152,000 annually
Please note that the salary information is a general guideline only. Imperative Care considers factors such as scope and responsibilities of the position, candidate's work experience, education/training, key skills, and internal equity, as well as location, market and business considerations when extending an offer. As part of our total rewards package, Imperative Care offers comprehensive benefits including a 401k plan, health benefits, generous PTO, a parental leave program and emotional health resources.
XPvmV6Olmz","$136,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"PAYLOCITY CORPORATION
3.9",3.9,Remote,Senior Engineer Software - Data Practice,"Location: Remote (Must be based anywhere in the Czech Republic)

Don’t just land a job. Launch your future.
There are jobs and then there are careers. Since 1997, Paylocity has been hiring talented people, giving them big challenges, and providing the right resources to help them succeed. Our award-winning culture ensures all employees feel truly welcome, appreciated, and free to be themselves. While other companies talk about it, we make it happen. Join Paylocity and launch your career!? Our emergence in the Czech Republic began with our acquisition of Samepage in 2020! With over 70 employees in the Czech Republic, we will continue investing in steady growth, with stability and longevity always being at the forefront. We continue to produce 20% year-over-year growth alongside 100% increase in our product suite since 2014. Want to develop the strategies and principles needed to deliver compelling software? Join our team and help us enhance our all-in-one software platform, elevate our one-of-a-kind technology, and improve the employee experience.??
Software Engineers are members of our data practice organization, responsible for implementing our event base strategy and working side-by-side with the Product Engineering teams. They are actively implementing event-based data exports from various Paylocity domains. They are actively involved in the complete software development life cycle in an agile environment, including technical design, hands-on coding, unit testing, integration testing, performance tuning, maintenance, test automation, deploys, and upgrades. They work very closely with teams owning the data for specific domains by designing, implementing, and testing the most effective solution supporting event-based data exports.

Are you the teammate we are looking for?

Who you are:
Engineering is the function that applies principles and techniques of engineering, mathematics, and computer/data science to the design, development, and testing of applications. The Product & Technology engineering family consists of software development, testing, database, devops, virtualization & network.
Enthusiastic about developing the best software available and providing the ultimate customer experience
An advocate for continuous improvement of our software development process
Interested in staying current by applying new technologies
Able to work in a collaborative environment with a willingness to share your ideas
Able to work independently on modules and complete tasks with high quality and contribute to high velocity, but unafraid to seek out suggestions from other team members
Excited to work on cutting-edge technology
Passionate about coaching/mentoring peers and more junior engineers
During the first six months, you will:
Understand customer needs and business goals.
Often act as a technical lead for features or epics and complete features or epics where the approach is loosely defined and requires technical & design discovery prior to implementation
Advocate for best practices and a healthy balance of tech debt versus delivery
Actively mentor/coach less-experienced team members
Ensure code is flexible, reusable, extensible performant, and high quality through feedback on code reviews
Decompose outcomes into solutions composed of multiple software components interacting with each other
Understand and consider technical dependencies
Provide feedback via decision-making frameworks for proposed changes from across the org
Work within the scope of a team and participate in driving cross-team collaboration
Build something that you are proud of
Learn something that you are excited about
Do the best work of your career so far
Find innovative ways to increase the quality and velocity of your work
Exercise creativity and solve cool problems
Demonstrate passion for writing quality software
Contribute to a shared code base
Demonstrate software quality through unit and integration test automation
Strengthen your team by sharing your knowledge and interests with others
Build relationships and communicate with various types and levels of stakeholders across the organization
Analyze and spearhead improvements to the systems and software that are important to your team
Manage risks, escalate priorities and help to resolve issues that could impact production quality
Required Experience:
Bachelor's degree in a computer science, engineering, technology-related field or equivalent experience
Must be advanced in object-oriented design and development and unit-testing, Web Services, and web pages using ASP.NET and/or ASP.NET MVC with C# (5 years)
Hands on experience with cloud (preferably AWS) (2-3 years)
As this position will have much cooperation with US teams, willingness to work later hours twice per week (11 am – 7 pm) is a big plus.
A big plus is experience with event-bases systems
A firm grasp of object-oriented analysis and design
Passion for writing great, simple, clean, efficient code
Good knowledge of relational databases
Experience with unit testing and integration test automation
Must be adaptable to change and have a willingness to learn
Must have a strong sense of curiosity
Must commit to their role and take responsibility for their tasks
Must be able to work effectively in an agile and team environmen
Must be effective and creative in problem solving
Able to work off-hours and weekends as the need arises
Our journey forward.
Paylocity strives to create an organizational culture where every employee has a voice, feels truly welcome, appreciated, and free to be themselves, and is empowered and enabled to do their best work. A strong commitment to diversity, equity, and inclusion is critical to creating such a culture.We’ve made great strides to support diversity, equity, and inclusion. That being said, we realize there’s still room for improvement. Our current focus is on the following initiatives:
Education & Awareness
Client Community
Company Representation
Advocacy & Support
Fairness & Equality
PCTY Gives
Want to learn more, click here to access our DEI flipbook. https://www.flipsnack.com/paylocitycom/diversity-equity-and-inclusion.htmlThis job description has been written to provide an accurate reflection of the current job and to include the general nature of the work performed. It is not designed to contain a comprehensive detailed inventory of all duties, responsibilities, and qualifications required of the employees assigned to the job. Management reserves the right to revise the job or require that other or different tasks be performed when circumstances change.
EEO and accessibility StatementPaylocity is an equal opportunity employer.Paylocity is committed to the full inclusion of all individuals. We comply with federal and state disability laws and make reasonable accommodations for applicants and employees with disabilities. To request reasonable accommodation in the job application or interview process, please contact accessibility@paylocity.com.

#LIRemote",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1997,$100 to $500 million (USD)
"Cirkul Inc
3.6",3.6,"Watertown, MA",Senior Data Engineer,"About Cirkul, Inc.
Cirkul is a venture backed, direct-to-consumer startup company that develops transformational hydration products that reimagine how flavored beverages are created, personalized, and enjoyed at home and on-the-go. You may have read about us going viral on TikTok (https://www.bizjournals.com/tampabay/inno/stories/news/2021/06/15/tampa-startup-hires-100-after-going-viral-on-tikto.html) or partnering with some great investors here (https://www.bevnet.com/news/2021/cirkul-closes-30m-series-b-led-by-af-ventures/).
Overview
Cirkul is a rapidly growing beverage technology company (Avg. Revenue CAGR of >150% over the past 4 years).
We are looking for a Senior Data Engineer to join our growing data team. Our new team member will manage Cirkul’s data pipeline architecture and optimize data flow and collection. The ideal candidate has a background in site reliability and devops, configuring tooling to ensure health, uptime and reliability of our cloud infrastructure.
The Senior Data Engineer will support our data initiatives and will ensure an optimal data delivery architecture that is consistent throughout ongoing projects. They must be a self-starter, and comfortable supporting the data needs of multiple teams, systems and products. The right candidate should be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities
Manage infrastructure and configuration of data platform in the Cloud, ensuring health, reliability and uptime
Create and maintain optimal data pipeline architecture
Integrate DevOps/SRE practices on the data team by solving for performance, monitoring, and alerting
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Python and/or Node.js, SQL (using dbt for transformation), commercial SaaS and OSS offerings, and AWS ‘big data’ technologies
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs
Qualifications

4+ years of experience in a Data Engineer role at a fast-paced organization
3+ years of production experience with AWS, including EC2, EMR, RDS
3+ years of experience in devops or site reliability engineering (SRE), directly responsible for automated configuration, management and scalability of Cloud and infrastructure processes
Hands-on experience in Infrastructure-as-Code and Configuration management tools and technologies: Terraform, Kubernetes, and Docker
Advanced working knowledge of Python or similar scripting language
Exceptional fluency with SQL; you conquered the join venn diagram long ago and have moved on to explaining cost based optimization to your peers on the engineering team
Experience with orchestration tools such as Airflow, Dagster, or Prefect, with big data tools such as Kafka & Spark, and with dbt
Experience with modern columnar data warehouses such as Snowflake, Redshift, BigQuery
Experience ingesting, processing, and visualizing data sources of varying types - structured/relational and unstructured
Experience developing, managing, and manipulating large, complex datasets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Strong project management and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment
A Little More About Cirkul
Cirkul is a rapidly growing beverage technology company on a mission to make a healthier world by helping people enjoy drinking more water. The company has developed an innovative beverage delivery system that makes drinking more water delicious, fun, and personalized. The technology reduces the shipping weight of bottled beverages by 99% and uses 84% less plastic. Cirkul offers its customers over 50 unique flavors, all with no sugar, zero calories, zero carbs, no artificial colors or flavors, and a range of functional enhancements. Hundreds of thousands of consumers are using Cirkul to transition away from single-use plastics and sugar-filled beverages to healthier, better-for-you alternatives. The company is growing at a tremendous pace, is consistently profitable, and is backed by world class investors.
Cirkul, Inc. is an Equal Opportunity Employer. We believe in hiring a diverse workforce and are committed to sustaining an equitable and inclusive, people-first environment. We do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status. If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents.","$106,014 /yr (est.)",1001 to 5000 Employees,Company - Private,Manufacturing,Food & Beverage Manufacturing,2016,Unknown / Non-Applicable
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Dimensional Thinking LLC
4.7",4.7,"Atlanta, GA",Azure Data Engineer,"We are looking for an Azure Data Engineer to be part of our data & analytics team. You will develop solutions leveraging Azure cloud platform to create a Modern Enterprise data platform. You will work with cross-functional teams to ensure data is collected, stored, processed, and analyzed in a timely, efficient, and accurate manner. You will support digital transformation journey of data and analytics team. This exciting transformation will enable new cloud technologies that will transform the way we derive value from our data assets.
WHAT YOU'LL NEED:
Bachelor’s Degree in Computer Science or Data Analytics/engineering related streams
0 – 2 years of experience
Strong Understanding of Data Warehouse/Lakehouse, Data Mesh, Dimensional data Modelling, ETL/ELT, CDC concepts.
Knowledge of Cloud Infrastructure and services including Azure Data Factory(ADF), Azure Synapse, Azure Synapse Pipeline, Spark Notebooks, Azure Synapse Dedicated SQL Pool Warehouse ,Azure Databricks, Azure Functions, Power BI and Azure Data Lake storage
Understanding of with various data formats like relational, json, parquet, delta, streaming and others
Proficiency in SQL,T-SQL and Python/PySpark
Excellent problem-solving and analytical skills. Aptitude to adapt to new technologies
Excellent business facing and internal communication skills
Job Type: Full-time
Salary: $78,095.06 - $80,000.00 per year
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Compensation package:
Bonus opportunities
Signing bonus
Experience level:
1 year
2 years
No experience needed
Under 1 year
Schedule:
8 hour shift
Ability to commute/relocate:
Atlanta, GA 30303: Reliably commute or planning to relocate before starting work (Required)
Experience:
Azure: 1 year (Preferred)
Synapse: 1 year (Preferred)
Work Location: In person","$79,048 /yr (est.)",201 to 500 Employees,Company - Private,Human Resources & Staffing,HR Consulting,2018,Unknown / Non-Applicable
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
The position requires a Master’s degree in Computer Science, Engineering (any), or any technical/analytical field that is closely related to the specialty, plus one (1) year of experience in an IT/Computer-related position.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Disney
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"Associate Data Engineer- Machine Learning
Job ID
10058063
Location
Seattle, Washington, United States
Business
The Walt Disney Company (Corporate)
Date posted
Aug. 16, 2023
Job Summary:
At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Elevance Health
3.7",3.7,Remote,Data Engineer Sr (contract),"Job ID: #JP00043626

Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. Previously known as Anthem, Inc., we have evolved into a company focused on whole health and updated our name to better reflect the direction the company is heading.

We are looking for contract workers (via BCforward) who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact?

Primary duties may include, but are not limited to:
Undertakes complex assignments requiring additional specialized technical knowledge.
Develops very complex and varied strategic report applications from a Data Warehouse.
Establishes and communicates common goal and direction for team.
Establishes and maintains advanced knowledge of data warehouse database design, data definitions, system capabilities, and data integrity issues.
Acts as a source of direction, training and guidance for less experienced staff.
Monitors project schedules and costs for own and other projects.
Develops and supports very complex Data Warehouse-related applications for business areas requiring design and implementation of database tables. Conducts training on use of applications developed.

Requirements:
Requires a BS/BA degree; 6 years experience; or any combination of education and experience, which would provide an equivalent background.
Expert level PC, spreadsheet, and database skills, as well as experience in standard Business Information tools and programming/query languages is also required.
Ability to communicate effectively with multiple levels within the organization.
This job is focused on spending time thinking about programming and how it would be used to design solutions as compared to the Bus Info Developer Consultant job
SQL, Visual Studio, VB, SSRS, Power BI, Tableau, SSIS

Additional Details:
40 hours/week centered around EST hours - flexible with shift times as long as they are available for meetings during EST (typically around 9am-3pm would be when our meetings would happen). Open to candidates anywhere in the US - 100% remote.
Possible Temp to hire

BCForward is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Privacy Notice for California Residents",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2004,$10+ billion (USD)
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
"JPMorgan Chase & Co
4.0",4.0,"Jersey City, NJ",Data Engineer III,"JOB DESCRIPTION

We are looking for an experienced Data Engineer to join our AI Services team of talented technologists/Data Scientists. This is a highly visible and exciting role in a small team building out ML, NLP, and Deep Learning based products/services for various business use cases.
As a Senior Data Engineer, you will be actively involved with architecting, building, deploying, and maintaining a cloud-native data platform with aspirations of maturing into an insights and machine learning platform. You will be a part of an innovative team and work with our product owners, data engineers and software engineers to build new systems.
The successful candidate will have a passion for data, ML, Software Development with an emphasis on understanding the data landscape in large and complex organizations.
Job Responsibilities
Develop the required data pipelines for moving the data from On-prem to AWS/Cloud platforms.
Setup mechanism to capture and store feedback data (model misclassifications corrected by the operating users) so it be pushed to S3 on schedule
Perform user acceptance testing and deliver demos to stakeholders by SQL queries or Python scripts.
Perform data analysis to define / support model development including metadata and data dictionary documentation that will enable data analysis and analytical exploration
Participate in strategic projects and provide ideas and inputs on ways to leverage quantitative analytics to generate actionable business insights and/or solutions to influence business strategies and identify opportunities to grow
Partners closely with business partners to identify impactful projects, influence key decisions with data, and ensure client satisfaction
Required qualifications, capabilities, and skills:
Academic qualification in a computer science or STEM (science, technology, engineering or mathematics) related field or the foreign equivalent
Professional experience working in an agile, dynamic and customer facing environment and Several years of recent hands-on professional experience (actively coding) working as a data engineer (back-end software engineer considered)
Understanding of distributed systems and cloud technologies (AWS, GCP, Azure, etc.) and Experience with a scheduling system (Airflow, Azkaban, etc.)
Understanding of data streaming and scalable data processing frameworks (Kafka, Spark Structured Streaming, Flink, Beam etc.) and Experience with SQL (any dialect) and Data tools (ie. Dbt)
Experience in all stages of software development lifecycle (requirements, design, architecture, development, testing, deployment, release, and support) and Experience with large scale datasets, data lake and data warehouse technologies on at least TB scale (ideally PB scale of datasets) with at least one of {BigQuery, Redshift, Snowflake}
Experience in Infrastructure as Code (ideally Terraform) for Cloud based data infrastructure. Good experience with using a JVM language (Java/Scala/Kotlin, preferably Java 8+) or extensive knowledge of Python.
Experience with a scheduling system (Airflow, Azkaban, etc.) and Understanding of (distributed and non-distributed) data structures, caching concepts, CAP theorem.
Preferred qualifications, capabilities, and skills
Ability to work in a collaborative environment and coach other team members on coding practices, design principles, and implementation patterns that lead to high-quality maintainable solutions.
Ability to work in a dynamic, agile environment within a geographically distributed team and ability to focus on promptly addressing customer needs
Ability to work within a diverse and inclusive team
Technically curious, self-motivated, versatile and solution oriented
ABOUT US

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.



ABOUT THE TEAM

Commercial Banking is focused on helping our clients succeed and making a positive difference in our communities. We provide credit and financing, treasury and payment services, international banking and real estate services to clients including corporations, municipalities, institutions, real estate investors and owners, and nonprofit organizations.","$134,625 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1799,$10+ billion (USD)
"Discover Financial Services
3.9",3.9,Illinois,Data Engineer - Abinitio,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.
Job Description: The Data Engineer is responsible designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community.
Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members
Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies
Demonstrates strong technical aptitude across data engineering practices:
Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting
Designing advanced SQL queries
Leveraging metadata-driven framework for solutions
Developing test scripts for unit and integration testing
Develops test methodologies for specific products
Leads code review sessions and other process and operational improvement initiatives
Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)
Works on holistic solutions, driving feature and story delivery (Agile)
Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline
Participates in the on-call rotation for support
Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities
Builds strong collaborative working relationship both within the team and cross-functionally

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field
3+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale

Preferred Qualifications

If we had our say, we’d also look for:
ETL/ELT Tools (AbInitio, DataStage, Informatica)
Cloud Tools and Databases (AWS, Snowflake)
Other programming languages (Unix scripting, Python, etc.)
Leverage CI/CD framework for data integration, Open Source
Experience working in cloud platforms (AWS, GCP, Azure)
Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs
Experience optimizing SQL both relational and nosql
External applicants will be required to perform a technical interview.

#LI-CM

Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$113,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Meow Wolf
3.1",3.1,Remote,Data Engineer,"Privacy Notice for California Applicants and Employees
Meow Wolf opens portals of possibility. Come as you are!
We are individuals who inspire creativity in people's lives through art and exploration, so that our combined imaginations can transform the world we live in. We create immersive and interactive experiences that transport audiences into fantastic realms of story and exploration. Our Vision is to be the world’s leading creative company, reimagining the paradigm of art and storytelling, to make a positive difference in the world.
We share a strong commitment to Belonging through our values of:
Collaborative Creativity: We believe the act of creating together amplifies possibilities.
Provocative Playfulness: We celebrate the unexpected because it is the doorway to discovery.
Outsiders Welcome: We are all outsiders at heart, and we create space for everyone to feel like they belong.
Authentic Compassion: We are “kind punks” - supportive to each other and standing up for what we believe in.
Audacious Courage: We have the courage to radically reinvent ourselves to push the boundaries of art.
If this all sounds like YOU, read on….
Job Description:
Purpose: To help improve Meow Wolf’s customer experience ecosystem via data-driven products.
Location: This position is remote/ hybrid-eligible, provided the candidate resides within the following markets: Santa Fe, Denver, Las Vegas, Dallas, or Los Angeles.
Compensation: Compensation for this role is $70,700 to $101,545. Compensation varies depending on location and experience.
In a collaborative effort, the Data Engineer will help build enhancements to Meow Wolf’s customer experience ecosystem. This is a highly technical position that will require a good breadth of web technology and database experience, coupled with a strong drive to innovate.
As a Data Engineer, you will be a key member of our Product and Engineering team. You are responsible for activities throughout the data engineering lifecycle, which ultimately makes our data accessible and ensures the uninterrupted flow of data in order for us to best evaluate and optimize performance. Your work will touch on security, data management, data architecture, systems orchestration, and software engineering. You will be instrumental in supporting the development of next-generation products and experiences that integrate cutting edge technology into the broader Meow Wolf experience.
Please write a short cover letter (max. 1 page all inclusive, ideally less) in which you answer the following questions:
What experience makes you suitable for this job? Please provide some highlights, no need to cover all the things that are obvious from the work experience listed on your CV. Here is also your chance to include experiences and skills gained outside of your employment (e.g. hobbies, education, travels, etc) should they help you strengthen your case. No need to pretend to be superhuman.
What do you hope Meow Wolf, and the position you are applying for, can offer you in terms of career and/or personal development? We are aware that a job description is always an incomplete picture into the workings of a company and the role you are applying for. But we assume something caught your eye. Keep it real, no need to state that working for Meow Wolf is your life’s sole purpose.
What Muppet are you, and why? You can choose from either the Muppet show (
https://en.wikipedia.org/wiki/List_of_Muppets
) or Sesame Street (
https://en.wikipedia.org/wiki/List_of_Sesame_Street_Muppets
). Be concise and have fun with it.
You will improve data quality, availability, and accessibility which will allow Meow Wolf to continue to deliver the ultimate guest experience.
How you will do it…
Participate in requirements gathering: work with key department leads and our Project Manager to understand department-level data needs for data flows.
Build and maintain critical data ETLs leveraging best practices in security and data fidelity.
Integrate data from first/third party databases and platforms into data lakes and warehouses including BigQuery and Cloud Storage inside Google Cloud Platform.
Maintain and optimize our data warehouse (BigQuery) in collaboration with the data engineering team.
Plan and architect new data flows for our current and future data gaps.
Support Operations: remediate triage alerts channeled to you.
Technical Documentation: create clear, simple, and comprehensive documentation for data flows and ETLs.
Coordinate releases, leverage issues tracking, and manage pull requests for the data projects.
To be successful in this role…
You come with 3+ years of experience in Python, including building ETLs and/or other types of data pipelines.
You have 2+ years of experience in SQL, including use of nested and complex queries.
You bring extensive experience working with REST-based APIs, with some experience in implementing ETLs using APIs for connecting to ecommerce, ticketing, gaming, analytics, and/or interaction tracking systems.
You possess strong analytical thinking and problem-solving skills with the ability to navigate highly complex and ambiguous situations.
You are adaptable, enterprising, and willing to be a technical leader on projects.
You set a high-quality bar: just-enough documentation, unit testing, code reviews, test automation, continuous integration & deployment.
You demonstrate excellent communication skills with the ability to think creatively and adapt the message to the audience.
You are comfortable working independently as well as engaging in close collaboration with colleagues via pair programming, workshops, and code reviews.
You do not need a traditional Data Engineering or Computer Science background. We value lived experience and curiosity in addition to professional experience and formal education.
It would be nice to have…
Experience with Flask and/or FastAPI, Python web frameworks we commonly use.
Knowledge of Google Cloud Platform in general, but experience with BigQuery, Cloud Storage, Cloud SQL, and Cloud Run are especially valuable.
Experience with PostgreSQL.
Experience using Agile methodologies and Scrum and/or Kanban in particular.
Experience with Javascript, either for scripting or as a server-side language.
Familiarity writing ETLs for CRMs in general, or HubSpot in particular.
Experience working with translating (research) questions into data needs and (novel) analysis techniques, if that includes experience with Data Fusion, data forensics and/or data reconstruction – even better.
Essential tools to set you up for success…
Python, including basic packages and data-specific packages.
SQL, to create, edit, and review table and query definitions in our data warehouse via Dataform and BigQuery.
Git, specifically Github, for version control, code reviews, and our CI-CD pipeline.
Docker, to create microservices that can be run in serverless cloud environments.
Work environment & physical demands…
This position is remote friendly and a company laptop will be provided.
There is potential for infrequent travel to exhibition sites or company headquarters (if remote) for this position.
This is a full-time position averaging 40 hours a week, Monday to Friday – very infrequently requiring flexibility to work during weekends based on business needs.
All employees will comply with company and OSHA standard workplace safety protocols. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
You will get to know Meow Wolf by…
Structured and supportive onboarding to the team and our projects over your first 90 days.
Taking a deep dive into departmental inner workings and reviewing project goals.
Exploring Meow Wolf Origins.
Attending Meow Wolf’s Immersiversity©.
Are you…
Passionate about bringing these new experiences to life while incorporating learnings along the way?
Highly organized with the ability to prioritize multiple tasks?
The kind of person who enjoys ensuring that quality and utility remain high for a variety of internal and external products?
Able to exhibit professional judgment and decision-making skills?
Experienced in managing processes or projects and driving change through positive influence and by leading by example?
Creative in your approach to problem solving with the ability to identify process improvement opportunities?
Swift at familiarizing yourself with new concepts and disciplines, as well as learning and deepening your understanding of computer languages and tools?
IMPACT: Meow Wolf is committed to our DIY roots and grassroots community support principles. To document that commitment, we converted our legal designation into a Delaware Public Benefit Corporation and have certified as a B Corporation. As a B Corp, we have a triple bottom line of supporting financial, social and environmental wellbeing in our community.
INCLUSION: Meow Wolf is an equal opportunity employer and prohibits discrimination and harassment of any kind. We are committed to ensuring all employees enjoy and thrive in a work environment where differences make us the vibrant, wonderful community we are! All employment decisions at Meow Wolf are based on business need, job requirements, and individual qualifications, without regard to race, color, ancestry, national origin, gender, pregnancy, sexual orientation, marital status, religion, age, disability, gender identity, results of genetic testing, veteran status, service in the military or any other characteristic protected by federal, state or local law.
BENEFITS:
The choices we make concerning our benefits during enrollment periods are among the most important we select for ourselves and our families. As part of the total compensation package for full-time employees, Meow Wolf offers a comprehensive benefits package that includes various options to meet individual healthcare and financial needs along with many perks.
Medical Insurance options: PPO & HSA
Dental & Vision Insurance
401k Retirement Plan
Company Paid Life Insurance Policy & Long-Term Disability Coverage
Voluntary Short-term Disability & Critical Illness Policies
Company Paid Employee Assistance Program
Paid Parental Leave for 12 weeks
Discount off Meow Wolf Gift Shop Merch
Admission to Meow Wolf attractions for employees and guests
Please visit
www.meowwolf.com/careers
for more information.","$86,123 /yr (est.)",201 to 500 Employees,Company - Private,"Arts, Entertainment & Recreation",Culture & Entertainment,2008,$1 to $5 million (USD)
"PAYLOCITY CORPORATION
3.9",3.9,Remote,Senior Engineer Software - Data Practice,"Location: Remote (Must be based anywhere in the Czech Republic)

Don’t just land a job. Launch your future.
There are jobs and then there are careers. Since 1997, Paylocity has been hiring talented people, giving them big challenges, and providing the right resources to help them succeed. Our award-winning culture ensures all employees feel truly welcome, appreciated, and free to be themselves. While other companies talk about it, we make it happen. Join Paylocity and launch your career!? Our emergence in the Czech Republic began with our acquisition of Samepage in 2020! With over 70 employees in the Czech Republic, we will continue investing in steady growth, with stability and longevity always being at the forefront. We continue to produce 20% year-over-year growth alongside 100% increase in our product suite since 2014. Want to develop the strategies and principles needed to deliver compelling software? Join our team and help us enhance our all-in-one software platform, elevate our one-of-a-kind technology, and improve the employee experience.??
Software Engineers are members of our data practice organization, responsible for implementing our event base strategy and working side-by-side with the Product Engineering teams. They are actively implementing event-based data exports from various Paylocity domains. They are actively involved in the complete software development life cycle in an agile environment, including technical design, hands-on coding, unit testing, integration testing, performance tuning, maintenance, test automation, deploys, and upgrades. They work very closely with teams owning the data for specific domains by designing, implementing, and testing the most effective solution supporting event-based data exports.

Are you the teammate we are looking for?

Who you are:
Engineering is the function that applies principles and techniques of engineering, mathematics, and computer/data science to the design, development, and testing of applications. The Product & Technology engineering family consists of software development, testing, database, devops, virtualization & network.
Enthusiastic about developing the best software available and providing the ultimate customer experience
An advocate for continuous improvement of our software development process
Interested in staying current by applying new technologies
Able to work in a collaborative environment with a willingness to share your ideas
Able to work independently on modules and complete tasks with high quality and contribute to high velocity, but unafraid to seek out suggestions from other team members
Excited to work on cutting-edge technology
Passionate about coaching/mentoring peers and more junior engineers
During the first six months, you will:
Understand customer needs and business goals.
Often act as a technical lead for features or epics and complete features or epics where the approach is loosely defined and requires technical & design discovery prior to implementation
Advocate for best practices and a healthy balance of tech debt versus delivery
Actively mentor/coach less-experienced team members
Ensure code is flexible, reusable, extensible performant, and high quality through feedback on code reviews
Decompose outcomes into solutions composed of multiple software components interacting with each other
Understand and consider technical dependencies
Provide feedback via decision-making frameworks for proposed changes from across the org
Work within the scope of a team and participate in driving cross-team collaboration
Build something that you are proud of
Learn something that you are excited about
Do the best work of your career so far
Find innovative ways to increase the quality and velocity of your work
Exercise creativity and solve cool problems
Demonstrate passion for writing quality software
Contribute to a shared code base
Demonstrate software quality through unit and integration test automation
Strengthen your team by sharing your knowledge and interests with others
Build relationships and communicate with various types and levels of stakeholders across the organization
Analyze and spearhead improvements to the systems and software that are important to your team
Manage risks, escalate priorities and help to resolve issues that could impact production quality
Required Experience:
Bachelor's degree in a computer science, engineering, technology-related field or equivalent experience
Must be advanced in object-oriented design and development and unit-testing, Web Services, and web pages using ASP.NET and/or ASP.NET MVC with C# (5 years)
Hands on experience with cloud (preferably AWS) (2-3 years)
As this position will have much cooperation with US teams, willingness to work later hours twice per week (11 am – 7 pm) is a big plus.
A big plus is experience with event-bases systems
A firm grasp of object-oriented analysis and design
Passion for writing great, simple, clean, efficient code
Good knowledge of relational databases
Experience with unit testing and integration test automation
Must be adaptable to change and have a willingness to learn
Must have a strong sense of curiosity
Must commit to their role and take responsibility for their tasks
Must be able to work effectively in an agile and team environmen
Must be effective and creative in problem solving
Able to work off-hours and weekends as the need arises
Our journey forward.
Paylocity strives to create an organizational culture where every employee has a voice, feels truly welcome, appreciated, and free to be themselves, and is empowered and enabled to do their best work. A strong commitment to diversity, equity, and inclusion is critical to creating such a culture.We’ve made great strides to support diversity, equity, and inclusion. That being said, we realize there’s still room for improvement. Our current focus is on the following initiatives:
Education & Awareness
Client Community
Company Representation
Advocacy & Support
Fairness & Equality
PCTY Gives
Want to learn more, click here to access our DEI flipbook. https://www.flipsnack.com/paylocitycom/diversity-equity-and-inclusion.htmlThis job description has been written to provide an accurate reflection of the current job and to include the general nature of the work performed. It is not designed to contain a comprehensive detailed inventory of all duties, responsibilities, and qualifications required of the employees assigned to the job. Management reserves the right to revise the job or require that other or different tasks be performed when circumstances change.
EEO and accessibility StatementPaylocity is an equal opportunity employer.Paylocity is committed to the full inclusion of all individuals. We comply with federal and state disability laws and make reasonable accommodations for applicants and employees with disabilities. To request reasonable accommodation in the job application or interview process, please contact accessibility@paylocity.com.

#LIRemote",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1997,$100 to $500 million (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Rivian
3.4",3.4,"Irvine, CA",Sr. Data Engineer,"About Rivian:
Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.

As a company, we constantly challenge what’s possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.
Role Summary:
In this position, you will contribute to the data engineering needs of Rivian's Product Development Organization. You will manage the back end data from enterprise engineering applications and non enterprise applications such as our internal engineering applications. Additionaly you will be responsible for preparing, analyzing and serving data as needed for our development tools that deliver insights to the Product Development Organization.

To deliver you must be a team player, technicaly capable and able to think critically. To excel at this position you will have to navigate technical IT discussions, Enterprise Technology platforms, data architecture, and and colaborate cross fucntionally. You will also have to stay up to speed on the latest tools and technology in the data engineering world.
Responsibilities:
Create Big Data Solutions with high volumes & variety of data from PLM and other engineering applications and machines.
Collaborate with other technology teams to implement a framework of tools and technologies to ingest high volume of data to support engineering analytics, data science and machine learning use cases.
Solve complex analytical requirements using software engineering tools.
Support and utilize tools and technologies to provide data governance – data catalog and lineage.
Create data applications with ability to do searches, real time data alerts, APIs to pull the data on a large volume of data.
Build data applications to provide real-time data alerts & high throughput analytics
Qualifications:
Bachelors/Masters in data science, computer science, engineering, mathematics, or a related technical discipline preferred
Strong communication and leadership & collaboration skills.
Prior experience with PLM and handling product data management (PDM) in high volume manufacturing environment.
Passion for software & data engineering, pioneering data technologies and architecture. Ability to understand complex business problems and provide software solutions.
3+ years of experience in building petabyte scale data platforms and Big Data architecture using AWS services & open-source technologies.
Extensive hands-on experience in using AWS & open-source services like Glue, Spark Kinesis/Kafka, S3, Athena, Sagemaker
Hands-on experience in one or more programming languages like Python, Java, Scala.
Real-life production experience in creating architectural framework and tools for Data Science teams to build, train & scale machine learning models.
Strong hands-on experience with NOSQL, Columnar and Relational databases.
Understanding of data catalog solutions like Alation, Collibra, Atlas
Experience in building CI/CD framework for the data teams
Experience with infrastructure as code
Pay Disclosure:
Salary Range California-Based Applicants: $150,000 -$173,000 (actual compensation will be determined based on experience, and other factors permitted by law).
Company Statements:
Equal Opportunity
Rivian is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law.

Rivian is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at candidateaccommodations@rivian.com.
Candidate Data Privacy
Rivian may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Rivian may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law.

Rivian may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our People Team, Finance, Legal, and the team(s) with the position(s) for which you are applying; (ii) Rivian affiliates; and (iii) Rivian’s service providers, including providers of background checks, staffing services, and cloud services.

Rivian may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions.

Please note that we are currently not accepting applications from third party application services.","$103,502 /yr (est.)",5001 to 10000 Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2009,Unknown / Non-Applicable
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"OneStudyTeam
3.2",3.2,Remote,Senior Data Engineer,"At OneStudyTeam (a Reify Health company), we specialize in speeding up clinical trials and increasing the chance of new therapies being approved with the ultimate goal of improving patient outcomes. Our cloud-based platform, StudyTeam, brings research site workflows online and enables sites, sponsors, and other key stakeholders to work together more effectively. StudyTeam is trusted by the largest global biopharmaceutical companies, used in over 6,000 research sites, and is available in over 100 countries. Join us in our mission to advance clinical research and improve patient care.
One mission. One team. That’s OneStudyTeam.
Our unique, rapidly growing data streams are enabling novel opportunities to manage clinical trials more efficiently and predictably. The Data Engineering team is looking for talented Senior Data Engineers to build, expand, and support a cutting-edge data architecture which is the analytical backbone of our company. If you are empathetic, business-driven, and want to use your data engineering and data architecture skills to make a tangible impact in the clinical research community then this may be the role for you.
We're looking for people who can effectively balance rapid execution and delivery with sustainable and scalable architectural initiatives to serve the business most effectively. You have strong opinions, weakly held, and while well-versed technically know when to choose the right tool, for the right job, at the right level of complexity. You will work closely with the rest of our Data Engineering team and our Data Science teams to help collect, stream, transform, and effectively manage data for integration into critical reporting, data visualizations, and ModelOps systems for emerging data science products.
What You’ll Be Working On
Build reliable and robust data integrations with external partners
Supporting the development and expansion of modern, privacy-aware, data warehouse and data mesh architectures
Helping to build, manage, orchestrate, and integrate streaming data sources, data lakes, ELT processes, columnar storage systems, and distributed query execution solutions
Establishing proactive data quality/freshness dashboards, monitoring, alerting, and anomaly remediation systems
Building practical data onboarding tooling and process automation solutions
Learning to effectively understand and deftly navigate the global compliance ecosystem (HIPAA, GDPR, etc.) to ensure your work respects the rights, regulations, and consent preferences of all stakeholders, including historical underserved or underrepresented populations
Developing a deep understanding of the clinical ecosystem, our products, and our business and how they all uniquely interact to help people
What You’ll Bring to OneStudyTeam
4+ years of experience successfully developing and deploying data pipelines and distributed architectures, ideally in a space similar to ours (startup, healthcare, regulated data)
Hands-on experience implementing ETL/ELT best practices at scale and demonstrated practical experience or familiarity with a good portion of our stack, including: AWS services (Redshift, MSK, Lambda, ECS, ECR, EC2, Glue, Quicksight, Spectrum, S3, etc.), Postgres, dbt, Kafka, Prefect, Docker, Terraform
Excellent programming skills in Python and deep comfort with SQL. Clojure experience is also highly appreciated
Experience or interest in developing and managing enterprise-scale data, distributed data architectures
Able to independently ship medium-to-large features and start to support or participate in architectural design
Excellent written and verbal communication skills
Strong attention to detail is key, especially when considering correctness, security, and compliance
Solid software testing, documentation, and debugging practices in the context of distributed systems
Learn more about our global benefits offerings on our careers site: https://careers.onestudyteam.com/us-benefits
We value diversity and believe the unique contributions each of us brings drives our success. We do not discriminate on the basis of race, sex, religion, color, national origin, gender identity, age, marital status, veteran status, or disability status.
Note: OneStudyTeam is unable to sponsor work visas at this time. If you are a non-U.S. resident applicant, please note that OST works with a Professional Employer Organization.
As a condition of employment, you will abide by all organizational security and privacy policies.
For a detailed overview of OneStudyTeam's candidate privacy policy, please visit https://careers.onestudyteam.com/candidate-privacy-policy. This organization participates in E-Verify (E-Verify's Right to Work guidance can be found here).",#N/A,201 to 500 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2012,Unknown / Non-Applicable
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"PG&E Corporation
4.0",4.0,"Oakland, CA",Expert Data Engineer,"Requisition ID # 150917

Job Category: Information Technology
Job Level: Individual Contributor
Business Unit: Information Technology
Work Type: Hybrid
Job Location: Oakland; Sacramento; San Francisco; San Jose; San Ramon

Department Summary

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively to deliver high quality technology solutions.

The IT Data, Analytics, & Insights organization is an enterprise team that is responsible for working collaboratively across various lines of business (e.g., , Gas Operations, Electric Operations, Safety, Energy Procurement, etc.) and is focused on unlocking the value of PG&E’s data to support the company’s Wildfire Safety Program and True North Strategy. As part of that focus, we focus on delivering data and AI/ML centric products to support these initiatives. Some of the products that are being delivered include Remote Inspections, AI Enabled Inspections, Vegetation Management through LiDAR capabilities, Transmission Line Asset Master, Electric Distribution Asset Master, Asset Risk Modeling, and a Cloud Native Foundational Platform.

A critical part of how we operate is to apply design thinking, work and observe the Agile development methodology, and co-location. Through these principles, we work as product teams to help deliver a valuable product to our business.

Position Summary

We are looking for an experienced and talented Data Engineer to join our growing team of analytics experts. You will have a unique opportunity to be at the forefront of the utility industry and gain a comprehensive view of the nation’s most advance smart grid! In this role, you will work as part of cross functional teams, including data scientists, other data engineers, technology experts, and subject matter experts to develop data driven solutions. Successful candidates will be responsible for building, expanding, and optimizing our data, data storage, and data pipeline. This individual will support team members and decision products to ensure that data delivery is reliable and optimized. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. It is the perfect role for someone who would like to continue to build upon their professional experience and help advance PG&E’s sustainability goals.

The role is hybrid working primarily from your remote office and the Oakland General Office, in-person, 1-2x monthly for collaboration or as business needs require.

PG&E is providing the salary range that the company in good faith believes it might pay for this position at the time of the job posting. This compensation range is specific to the locality of the job. The actual salary paid to an individual will be based on multiple factors, including, but not limited to, specific skills, education, licenses or certifications, experience, market value, geographic location, and internal equity. This job is also eligible to participate in PG&E’s discretionary incentive compensation programs.

A reasonable salary range is:

Bay Area Minimum: $128,000
Bay Area Maximum: $218,000

Job Responsibilities

Data Engineering:
Leads moderate to high complexity data engineering activities which have broad impact and require in-depth analysis to obtain desired results.
Design and build data pipelines required for optimal extraction, transformation, and loading of data using Pyspark.
Build analytics products that utilize the data pipelines to provide actionable insights.
Identifies, designs, and implements internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Resolves application programming analysis problems of broad scope within procedural guidelines.
Actively participates in agile/scrum ceremonies (stand ups, planning, retrospectives, etc.)
Promotes a continuous improvement mindset by engaging in after action reviews and sharing learnings.

Data System and Architecture Maturity:
Assesses performance of individual data pipeline and broader data systems, suggests and may implement changes as required to meet individual project or enterprise maturity objectives.
Evaluates end-to-end data system interaction to proactively identify any potential pitfalls of the total solution.
Works with the team to help develop best practices and scalable design patterns.
Helps other engineers/analysts on unusual or especially complex problems that cross multiple functional/technology areas. May require creative/non-standard approaches to solve problems that will have significant impact across the company.
Conceptualizes and generates infrastructure that allows big data to be accessed and analyzed with verified data quality and metadata is appropriately captured and catalogued.
Work with team leadership to continually improve data driven decision making at PG&E via demonstrations, mentoring, disseminating best practices, etc.

Qualifications

Minimum:
BA/BS in computer science, management information systems or related technical discipline or equivalent work experience
7 years of experience as a data engineer or in a similar role
Complete proficiency in Python and/or Pyspark
Strong SQL skills and experience working with large datasets and complex data structures in a data warehouse/data lake environment.
Experience creating reports, dashboards, and visualizations using commercial tools (Tableau, Power BI, or other BI tools)

Desired:
Experience with Palantir Foundry application development and data visualization tools
Databases – familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.
Git – knowledge of version control / collaboration workflows and best practices
Agile – familiarity with agile and iterative working methodology and rapid user feedback gathering concepts
UX design – knowledge of best practices and applications
Experience in Typescript (preferred) or Javascript
Data literacy – data analysis and statistical basics to ensure correctness in data aggregation and visualization
Experience leading development teams
Excellent problem-solving and analytical skills with a strong attention to detail","$142,802 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1905,$10+ billion (USD)
"BTI Solutions
3.6",3.6,Remote,Data Engineer / Remote / Logistics / SC702786,"Why Work for Us?

Established in 2006, continues to grow dramatically within the IT, telecommunications, Automotive and SCM industry. We encourage our employees in personal development with a passion to succeed and we offer an excellent benefit package. Every employee has access to Medical, Vision, Dental, Life and 401K plus many more.

401K with Employer Match
Company Paid Dental, Vision, Life and Medical up to 100%
Paid Sick Leave
Chance for VISA sponsoring
SUMMARY OF ESSENTIAL JOB FUNCTIONS
Design and develop analytical models and be the face to the data consumers
Perform data curation to meet the business requirements
Build batch and streaming data pipelines
Develop processes for automating, testing, and deploying your work
Identify risks and opportunities of potential logic and data issues within the data environment
Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUN REUIREMENTS
Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
3+ years of experience as Data Engineer or in a similar role
Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
Cloud to Cloud migration experience preferred
Strong PySpark skill is a must have
Have knowledge of data management fundamentals and data storage principles
Have knowledge of systems as it pertains to data storage and computing
Strong source to target mapping experience and ETL principles/knowledge
Excellent verbal and written communication skills.
Strong quantitative and analytical skills with accuracy and attention to detail
Ability to work well independently with minimal supervision and can manage multiple priorities

BTI Solutions, Inc. is an equal opportunity employer m/f/d/v.",#N/A,201 to 500 Employees,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,2006,$25 to $100 million (USD)
"Humana
3.9",3.9,Rhode Island,Senior Data Engineer,"The Delaware Valley ACO (DVACO) is an accountable care organization that participates in the Centers for Medicare and Medicaid Services’ Medicare Shared Savings Program (MSSP). DVACO is as a joint venture among three stakeholders: Humana, Main Line Health System, and Jefferson Health System. Humana takes the lead in providing administrative support in various areas including HR.

DVACO’s MSSP participation accounts for the region’s largest Medicare ACO grouping, with more than 2,000 physicians and approximately 70,000 Medicare fee-for-service beneficiaries. Additionally, DVACO currently holds performance-based contracts with private payers and manages population health initiatives for the employees and dependents of Jefferson Health and Main Line Health, enhancing DVACO’s total number of beneficiaries to over 200,000.

DVACO’ s primary focus is outlined by the three-part aim:
Improve the Health of our Patient Population
Improve our Patients’ Experiences
Reduce the per-capita Cost of Care delivered to our Population

These goals are achieved through enhanced coordination of patient care and by dedication to quality improvement initiatives that increase the efficiency of care delivery within the outpatient setting.
Responsibilities
The Senior Data Engineer will be responsible for validating and interpreting data to support population health management analytical tools and applications. Works directly with other DVACO and Cloud Service Provider (CSP) staff to support engineering operations within the Azure Cloud.
Designs, builds, and maintains data processing architectures and solutions enabling the efficient conversion of structured and unstructured data to insights at enterprise scale. Ingests data from internal and external sources utilizing cloud native platforms and software development best practices and patterns. Develops software tools and solutions that leverage artificial intelligence, machine learning, and big-data techniques to cleanse, organize, and transform data into insights and actions that enables Humana to better serve our members.
Develops a deep understanding of the DVACO population health applications to consult and strategize on complex issues and implement solutions
Responsible for payer data integration and implementation; data acquisition and data management, SQL programming, quantitative and qualitative data analysis
Works in conjunction with external Cloud Service Provider (CSP) and other DVACO staff to build and manage Azure pipelines, data lakes, data warehouses, etc. to support DVACO's goals and objectives
Responsible for the coordination of claims and roster load activity between Microsoft Azure and the DVACO population health applications
Coordinates population health application interfaces and extracts in accordance with user workflows for DVACO stakeholders
Maintains and supports connectivity with DVACO payer partners and vendors
In addition to being a great place to work, Humana also offers industry leading benefits for all employees, starting your FIRST day of employment. Benefits include:
Medical Benefits
Dental Benefits
Vision Benefits
Health Savings Accounts
Flex Spending Accounts
Life Insurance
401(k)
PTO including 8 paid holidays, one personal holiday, one day of volunteer time off, 23 days of annual PTO, parental leave, caregiving leave, and weekly well-being time
And more
Required Qualifications:
Bachelor's Degree
Experience using MS Data factory, Data Bricks or Synapse
Development experience with MS SQL databases, data lakes and lakehouse architecture
Development experience using database tables, stored procedures and views
ETL experience leveraging Python or other similar tools
Willingness and ability to learn new skills and adapt to a fast paced environment
Preferred Qualifications:
Bachelor's Degree in Computer Science or Information Technology
Experience working with FHIR or other HL7 integration options
Knowledge of healthcare coding structures and payment methodologies
Understanding of clinical or payer operational processes and ability to evaluate impacts on data compilation and reporting
Effective verbal and written communication and presentation skills with both internal and external stakeholders
Additional Information:
Work at Home/Remote Requirements
Work-At-Home Requirements
To ensure Home or Hybrid Home/Office associates’ ability to work effectively, the self-provided internet service of Home or Hybrid Home/Office associates must meet the following criteria:
At minimum, a download speed of 25 Mbps and an upload speed of 10 Mbps is recommended to support Humana applications, per associate.
Wireless, Wired Cable or DSL connection is suggested.
Satellite, cellular and microwave connection can be used only if they provide an optimal connection for associates. The use of these methods must be approved by leadership. (See Wireless, Wired Cable or DSL Connection in Exceptions, Section 7.0 in this policy.)
Humana will not pay for or reimburse Home or Hybrid Home/Office associates for any portion of the cost of their self-provided internet service, with the exception of associates who live or work from Home in the state of California, Illinois, Montana, or South Dakota. Associates who live and work from Home in the state of California, Illinois, Montana, or South Dakota will be provided a bi-weekly payment for their internet expense.
Humana will provide Home or Hybrid Home/Office associates with telephone equipment appropriate to meet the business requirements for their position/job.
Work from a dedicated space lacking ongoing interruptions to protect member PHI / HIPAA information
Our Hiring Process
As part of our hiring process for this opportunity, we may contact you via text message and email to gather more information using a software platform called Modern Hire. Modern Hire Text, Scheduling and Video technologies allow you to interact with us at the time and location most convenient for you.
If you are selected to move forward from your application prescreen, you may receive correspondence inviting you to participate in a pre-recorded Voice, Text Messaging and/or Video interview. Your recorded interview will be reviewed and you will subsequently be informed if you will be moving forward to next round of interviews
If you have additional questions regarding this role posting and are an Internal Candidate, please send them to the Ask A Recruiter persona by visiting go/Buzz and searching Ask A Recruiter! Please be sure to provide the requisition number so we may be able to research your request quicker.
Humana is more than an equal opportunity employer, Humana’s dedication to promoting diversity, multiculturalism, and inclusion is at the heart of what we do in all of our Humana roles. Diversity is more than a commitment to us, it is the foundation of what we do. We are fully focused on diversity of race, gender, sexual orientation, religion, ethnicity, national origin and all of the other fascinating characteristics that make us each uniquely wonderful.
This is a remote position.
#LI-LM1
#LI-Remote
Scheduled Weekly Hours
40

Not Specified
0",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1961,$10+ billion (USD)
"SWJ TECHNOLOGY, LLC
3.7",3.7,"Peoria, IL",Data Quality Engineer,"What Is the Opportunity?

We create trusted strategic products and services to unlock the power of our data. We enhance and measure our ability to access, govern, manage, connect and integrate internal and external data assets and ensure our employees understand the value of data and the impacts to our business. As a Data Quality Engineer, you will develop strategies to promote effective data governance practices to ensure that data is consistent, trustworthy, and doesn't get misused. You will measure accuracy, completeness, consistency, and reliability of data to embody and promote Traveler's data culture values. Consulting with business partners, you will assist in the design implementation, and drive the adoption of data management, governance, and metadata policies, standards, and best practices. You will develop and own project timelines and plans for assigned projects. Leveraging your understanding of the data ecosystem, business process and decision-making, as well as the data value chain, you will analyze medium complexity customer requests for changes to data management tools in order to determine impact on existing systems, process and develop appropriate specifications, enhancements, and procedures to comply.

What Will You Do?

Govern the process of managing the availability, usability, integrity security and privacy of the data

Collaborate with partners and assist with the design, development and implementation of innovative governance practices, roles, responsibilities.

Develop procedures, processes, and support the development of remediation plans to assure data quality for business purposes

Perform complex data profiling and analysis; communicates results in support of data quality processes.

Partner with business customers to recommend, develop, maintain and prioritize business data quality requirements, specifications, and rules.
Assist in defining metadata repository, data catalog, reference data management, and data lineage capabilities.

Work with business customers to ensure appropriate naming definitions and standards are being followed.

Facilitate the root cause analysis and resolution of business data management issues, including proposal and implementation of specification or procedural changes to address issue, working with impacted areas.

Leverage knowledge of data models, data relationships, mapping lineage and business rules to ensure that solutions meet operational and business needs.

Analyze medium complexity customer requests (internal or external, e.g., data calls) for changes to production systems, determine impact on existing systems, process and develop appropriate specifications, enhancements, and/or procedures to comply.

Leverage tools, processes, and workflows to capture knowledge, find information and maintain its relevance.

Design the creation, maintenance and governance of taxonomies and ensures its applicability to content and/or data.
SWJ TECHNOLOGY and all of its subsidiaries (i.e., NGE EQUIPMENT and ProjectOne US) are Equal Opportunity Employers and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender, disability status, protected veteran status, or any other characteristic protected by law.
JhzRi7OWMr","$87,931 /yr (est.)",51 to 200 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Reify Health
3.2",3.2,Remote,Senior Data Engineer,"At OneStudyTeam (a Reify Health company), we specialize in speeding up clinical trials and increasing the chance of new therapies being approved with the ultimate goal of improving patient outcomes. Our cloud-based platform, StudyTeam, brings research site workflows online and enables sites, sponsors, and other key stakeholders to work together more effectively. StudyTeam is trusted by the largest global biopharmaceutical companies, used in over 6,000 research sites, and is available in over 100 countries. Join us in our mission to advance clinical research and improve patient care.
One mission. One team. That’s OneStudyTeam.
Our unique, rapidly growing data streams are enabling novel opportunities to manage clinical trials more efficiently and predictably. The Data Engineering team is looking for talented Senior Data Engineers to build, expand, and support a cutting-edge data architecture which is the analytical backbone of our company. If you are empathetic, business-driven, and want to use your data engineering and data architecture skills to make a tangible impact in the clinical research community then this may be the role for you.
We're looking for people who can effectively balance rapid execution and delivery with sustainable and scalable architectural initiatives to serve the business most effectively. You have strong opinions, weakly held, and while well-versed technically know when to choose the right tool, for the right job, at the right level of complexity. You will work closely with the rest of our Data Engineering team and our Data Science teams to help collect, stream, transform, and effectively manage data for integration into critical reporting, data visualizations, and ModelOps systems for emerging data science products.
What You’ll Be Working On
Build reliable and robust data integrations with external partners
Supporting the development and expansion of modern, privacy-aware, data warehouse and data mesh architectures
Helping to build, manage, orchestrate, and integrate streaming data sources, data lakes, ELT processes, columnar storage systems, and distributed query execution solutions
Establishing proactive data quality/freshness dashboards, monitoring, alerting, and anomaly remediation systems
Building practical data onboarding tooling and process automation solutions
Learning to effectively understand and deftly navigate the global compliance ecosystem (HIPAA, GDPR, etc.) to ensure your work respects the rights, regulations, and consent preferences of all stakeholders, including historical underserved or underrepresented populations
Developing a deep understanding of the clinical ecosystem, our products, and our business and how they all uniquely interact to help people
What You’ll Bring to OneStudyTeam
4+ years of experience successfully developing and deploying data pipelines and distributed architectures, ideally in a space similar to ours (startup, healthcare, regulated data)
Hands-on experience implementing ETL/ELT best practices at scale and demonstrated practical experience or familiarity with a good portion of our stack, including: AWS services (Redshift, MSK, Lambda, ECS, ECR, EC2, Glue, Quicksight, Spectrum, S3, etc.), Postgres, dbt, Kafka, Prefect, Docker, Terraform
Excellent programming skills in Python and deep comfort with SQL. Clojure experience is also highly appreciated
Experience or interest in developing and managing enterprise-scale data, distributed data architectures
Able to independently ship medium-to-large features and start to support or participate in architectural design
Excellent written and verbal communication skills
Strong attention to detail is key, especially when considering correctness, security, and compliance
Solid software testing, documentation, and debugging practices in the context of distributed systems
Learn more about our global benefits offerings on our careers site: https://careers.onestudyteam.com/us-benefits
We value diversity and believe the unique contributions each of us brings drives our success. We do not discriminate on the basis of race, sex, religion, color, national origin, gender identity, age, marital status, veteran status, or disability status.
Note: OneStudyTeam is unable to sponsor work visas at this time. If you are a non-U.S. resident applicant, please note that OST works with a Professional Employer Organization.
As a condition of employment, you will abide by all organizational security and privacy policies.
For a detailed overview of OneStudyTeam's candidate privacy policy, please visit https://careers.onestudyteam.com/candidate-privacy-policy. This organization participates in E-Verify (E-Verify's Right to Work guidance can be found here).",#N/A,201 to 500 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2012,Unknown / Non-Applicable
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Lovelytics
4.4",4.4,Remote,AWS Redshift Data Engineer,"Lovelytics is seeking a skilled consultant with experience delivering cloud and data engineering client engagements.
This Lead Consultant will play the role of a Redshift Administrator and data engineer for Lovelytics clients. Overall, your role as an Amazon Redshift administrator involves managing the entire lifecycle of the data warehouse environment, from initial setup to ongoing maintenance, optimization, and security management.

In addition to the technical capabilities for this role, we are looking for someone who wants to work in a collaborative, dynamic, and inclusive environment and has a passion for bringing meaning to data through thought leadership and execution.
Role Location: Open to remote candidates in the US and Ontario, Canada.
Primary Job Responsibilities:
Fill the role of data engineer and Redshift developer for one of Lovelytics' complex client engagements
Deploy and configure Amazon Redshift clusters based on the client's requirements.
Set up network configurations, security groups, and access control to ensure secure communication with the clusters.
Overseeing data loading processes into Amazon Redshift from various sources, ensuring efficient ETL (Extract, Transform, Load) processes and data transformation workflows.
Manage the security, monitoring, alerting, compliance, and performance of our client's administration in Redshit
Apply your skills with Databricks, using python, and big data streaming to pioneer client technologies and data
Manage your own performance on projects to ensure project milestones are reached
Collaborating with data engineers, data scientists, and analysts to understand their requirements and optimize the data warehouse for their needs.
Integrate Databricks with 3rd-party applications to support customers' architectures
Troubleshooting data issues on the fly with prospects and clients
Our Ideal Candidate's Skills and Experiences:
B.S. in Computer Science or equivalent
3-5 years in data engineering working with cloud-based data analytics architectures
2-3 years experience engineering and administering Redshift and Redshift Serverless in an operational support environment
Extensive knowledge of data warehousing and data lake concepts and hands-on experience deploying pipelines using Databricks
Databricks Data Engineer Professional is a plus
Excellent communication skills are a MUST, all our employees are client-facing, and this role requires both written and verbal client management skills.
Hands-on experience with Big Data technologies, including Spark, Hadoop, Cassandra, and others
Ability to extract and transform data via Python, deep exposure and understanding of data warehousing, ETL pipelines, etc.
Overall understanding of analytics from analytic engineering to visualization tools
What We Promise You:
Exciting projects with great clients in varying departments and verticals across the world
The ability to work closely with experienced data engineers and quickly grow and expand your skillset
The ability to work closely with all sizes of companies, ranging from Fortune 100 to small local businesses
A workplace where you are encouraged to challenge the status quo and develop new technologies, methodologies, and processes
A diverse team consisting of data gurus, experience seekers, and entrepreneurial minds that are always pushing to be better

Lovelytics is an Equal Opportunity Employer. This means you don’t have to worry about whether your application process will be fair. We consider all applicants without regard to race, color, religion, age, ancestry, ethnicity, gender, gender identity, gender expression, sexual orientation, veteran status, or disability.
LRrFqS4Et9",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2017,$5 to $25 million (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Reify Health
3.2",3.2,Remote,Senior Data Engineer,"At OneStudyTeam (a Reify Health company), we specialize in speeding up clinical trials and increasing the chance of new therapies being approved with the ultimate goal of improving patient outcomes. Our cloud-based platform, StudyTeam, brings research site workflows online and enables sites, sponsors, and other key stakeholders to work together more effectively. StudyTeam is trusted by the largest global biopharmaceutical companies, used in over 6,000 research sites, and is available in over 100 countries. Join us in our mission to advance clinical research and improve patient care.
One mission. One team. That’s OneStudyTeam.
Our unique, rapidly growing data streams are enabling novel opportunities to manage clinical trials more efficiently and predictably. The Data Engineering team is looking for talented Senior Data Engineers to build, expand, and support a cutting-edge data architecture which is the analytical backbone of our company. If you are empathetic, business-driven, and want to use your data engineering and data architecture skills to make a tangible impact in the clinical research community then this may be the role for you.
We're looking for people who can effectively balance rapid execution and delivery with sustainable and scalable architectural initiatives to serve the business most effectively. You have strong opinions, weakly held, and while well-versed technically know when to choose the right tool, for the right job, at the right level of complexity. You will work closely with the rest of our Data Engineering team and our Data Science teams to help collect, stream, transform, and effectively manage data for integration into critical reporting, data visualizations, and ModelOps systems for emerging data science products.
What You’ll Be Working On
Build reliable and robust data integrations with external partners
Supporting the development and expansion of modern, privacy-aware, data warehouse and data mesh architectures
Helping to build, manage, orchestrate, and integrate streaming data sources, data lakes, ELT processes, columnar storage systems, and distributed query execution solutions
Establishing proactive data quality/freshness dashboards, monitoring, alerting, and anomaly remediation systems
Building practical data onboarding tooling and process automation solutions
Learning to effectively understand and deftly navigate the global compliance ecosystem (HIPAA, GDPR, etc.) to ensure your work respects the rights, regulations, and consent preferences of all stakeholders, including historical underserved or underrepresented populations
Developing a deep understanding of the clinical ecosystem, our products, and our business and how they all uniquely interact to help people
What You’ll Bring to OneStudyTeam
4+ years of experience successfully developing and deploying data pipelines and distributed architectures, ideally in a space similar to ours (startup, healthcare, regulated data)
Hands-on experience implementing ETL/ELT best practices at scale and demonstrated practical experience or familiarity with a good portion of our stack, including: AWS services (Redshift, MSK, Lambda, ECS, ECR, EC2, Glue, Quicksight, Spectrum, S3, etc.), Postgres, dbt, Kafka, Prefect, Docker, Terraform
Excellent programming skills in Python and deep comfort with SQL. Clojure experience is also highly appreciated
Experience or interest in developing and managing enterprise-scale data, distributed data architectures
Able to independently ship medium-to-large features and start to support or participate in architectural design
Excellent written and verbal communication skills
Strong attention to detail is key, especially when considering correctness, security, and compliance
Solid software testing, documentation, and debugging practices in the context of distributed systems
Learn more about our global benefits offerings on our careers site: https://careers.onestudyteam.com/us-benefits
We value diversity and believe the unique contributions each of us brings drives our success. We do not discriminate on the basis of race, sex, religion, color, national origin, gender identity, age, marital status, veteran status, or disability status.
Note: OneStudyTeam is unable to sponsor work visas at this time. If you are a non-U.S. resident applicant, please note that OST works with a Professional Employer Organization.
As a condition of employment, you will abide by all organizational security and privacy policies.
For a detailed overview of OneStudyTeam's candidate privacy policy, please visit https://careers.onestudyteam.com/candidate-privacy-policy. This organization participates in E-Verify (E-Verify's Right to Work guidance can be found here).",#N/A,201 to 500 Employees,Company - Private,Pharmaceutical & Biotechnology,Biotech & Pharmaceuticals,2012,Unknown / Non-Applicable
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Rivian
3.4",3.4,"Irvine, CA",Sr. Data Engineer,"About Rivian:
Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.

As a company, we constantly challenge what’s possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.
Role Summary:
In this position, you will contribute to the data engineering needs of Rivian's Product Development Organization. You will manage the back end data from enterprise engineering applications and non enterprise applications such as our internal engineering applications. Additionaly you will be responsible for preparing, analyzing and serving data as needed for our development tools that deliver insights to the Product Development Organization.

To deliver you must be a team player, technicaly capable and able to think critically. To excel at this position you will have to navigate technical IT discussions, Enterprise Technology platforms, data architecture, and and colaborate cross fucntionally. You will also have to stay up to speed on the latest tools and technology in the data engineering world.
Responsibilities:
Create Big Data Solutions with high volumes & variety of data from PLM and other engineering applications and machines.
Collaborate with other technology teams to implement a framework of tools and technologies to ingest high volume of data to support engineering analytics, data science and machine learning use cases.
Solve complex analytical requirements using software engineering tools.
Support and utilize tools and technologies to provide data governance – data catalog and lineage.
Create data applications with ability to do searches, real time data alerts, APIs to pull the data on a large volume of data.
Build data applications to provide real-time data alerts & high throughput analytics
Qualifications:
Bachelors/Masters in data science, computer science, engineering, mathematics, or a related technical discipline preferred
Strong communication and leadership & collaboration skills.
Prior experience with PLM and handling product data management (PDM) in high volume manufacturing environment.
Passion for software & data engineering, pioneering data technologies and architecture. Ability to understand complex business problems and provide software solutions.
3+ years of experience in building petabyte scale data platforms and Big Data architecture using AWS services & open-source technologies.
Extensive hands-on experience in using AWS & open-source services like Glue, Spark Kinesis/Kafka, S3, Athena, Sagemaker
Hands-on experience in one or more programming languages like Python, Java, Scala.
Real-life production experience in creating architectural framework and tools for Data Science teams to build, train & scale machine learning models.
Strong hands-on experience with NOSQL, Columnar and Relational databases.
Understanding of data catalog solutions like Alation, Collibra, Atlas
Experience in building CI/CD framework for the data teams
Experience with infrastructure as code
Pay Disclosure:
Salary Range California-Based Applicants: $150,000 -$173,000 (actual compensation will be determined based on experience, and other factors permitted by law).
Company Statements:
Equal Opportunity
Rivian is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law.

Rivian is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at candidateaccommodations@rivian.com.
Candidate Data Privacy
Rivian may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Rivian may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law.

Rivian may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our People Team, Finance, Legal, and the team(s) with the position(s) for which you are applying; (ii) Rivian affiliates; and (iii) Rivian’s service providers, including providers of background checks, staffing services, and cloud services.

Rivian may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions.

Please note that we are currently not accepting applications from third party application services.","$103,502 /yr (est.)",5001 to 10000 Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2009,Unknown / Non-Applicable
"Discover Financial Services
3.9",3.9,Illinois,Data Engineer - Abinitio,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.
Job Description: The Data Engineer is responsible designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community.
Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members
Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies
Demonstrates strong technical aptitude across data engineering practices:
Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting
Designing advanced SQL queries
Leveraging metadata-driven framework for solutions
Developing test scripts for unit and integration testing
Develops test methodologies for specific products
Leads code review sessions and other process and operational improvement initiatives
Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)
Works on holistic solutions, driving feature and story delivery (Agile)
Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline
Participates in the on-call rotation for support
Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities
Builds strong collaborative working relationship both within the team and cross-functionally

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field
3+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale

Preferred Qualifications

If we had our say, we’d also look for:
ETL/ELT Tools (AbInitio, DataStage, Informatica)
Cloud Tools and Databases (AWS, Snowflake)
Other programming languages (Unix scripting, Python, etc.)
Leverage CI/CD framework for data integration, Open Source
Experience working in cloud platforms (AWS, GCP, Azure)
Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs
Experience optimizing SQL both relational and nosql
External applicants will be required to perform a technical interview.

#LI-CM

Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$113,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Humana
3.9",3.9,Rhode Island,Senior Data Engineer,"The Delaware Valley ACO (DVACO) is an accountable care organization that participates in the Centers for Medicare and Medicaid Services’ Medicare Shared Savings Program (MSSP). DVACO is as a joint venture among three stakeholders: Humana, Main Line Health System, and Jefferson Health System. Humana takes the lead in providing administrative support in various areas including HR.

DVACO’s MSSP participation accounts for the region’s largest Medicare ACO grouping, with more than 2,000 physicians and approximately 70,000 Medicare fee-for-service beneficiaries. Additionally, DVACO currently holds performance-based contracts with private payers and manages population health initiatives for the employees and dependents of Jefferson Health and Main Line Health, enhancing DVACO’s total number of beneficiaries to over 200,000.

DVACO’ s primary focus is outlined by the three-part aim:
Improve the Health of our Patient Population
Improve our Patients’ Experiences
Reduce the per-capita Cost of Care delivered to our Population

These goals are achieved through enhanced coordination of patient care and by dedication to quality improvement initiatives that increase the efficiency of care delivery within the outpatient setting.
Responsibilities
The Senior Data Engineer will be responsible for validating and interpreting data to support population health management analytical tools and applications. Works directly with other DVACO and Cloud Service Provider (CSP) staff to support engineering operations within the Azure Cloud.
Designs, builds, and maintains data processing architectures and solutions enabling the efficient conversion of structured and unstructured data to insights at enterprise scale. Ingests data from internal and external sources utilizing cloud native platforms and software development best practices and patterns. Develops software tools and solutions that leverage artificial intelligence, machine learning, and big-data techniques to cleanse, organize, and transform data into insights and actions that enables Humana to better serve our members.
Develops a deep understanding of the DVACO population health applications to consult and strategize on complex issues and implement solutions
Responsible for payer data integration and implementation; data acquisition and data management, SQL programming, quantitative and qualitative data analysis
Works in conjunction with external Cloud Service Provider (CSP) and other DVACO staff to build and manage Azure pipelines, data lakes, data warehouses, etc. to support DVACO's goals and objectives
Responsible for the coordination of claims and roster load activity between Microsoft Azure and the DVACO population health applications
Coordinates population health application interfaces and extracts in accordance with user workflows for DVACO stakeholders
Maintains and supports connectivity with DVACO payer partners and vendors
In addition to being a great place to work, Humana also offers industry leading benefits for all employees, starting your FIRST day of employment. Benefits include:
Medical Benefits
Dental Benefits
Vision Benefits
Health Savings Accounts
Flex Spending Accounts
Life Insurance
401(k)
PTO including 8 paid holidays, one personal holiday, one day of volunteer time off, 23 days of annual PTO, parental leave, caregiving leave, and weekly well-being time
And more
Required Qualifications:
Bachelor's Degree
Experience using MS Data factory, Data Bricks or Synapse
Development experience with MS SQL databases, data lakes and lakehouse architecture
Development experience using database tables, stored procedures and views
ETL experience leveraging Python or other similar tools
Willingness and ability to learn new skills and adapt to a fast paced environment
Preferred Qualifications:
Bachelor's Degree in Computer Science or Information Technology
Experience working with FHIR or other HL7 integration options
Knowledge of healthcare coding structures and payment methodologies
Understanding of clinical or payer operational processes and ability to evaluate impacts on data compilation and reporting
Effective verbal and written communication and presentation skills with both internal and external stakeholders
Additional Information:
Work at Home/Remote Requirements
Work-At-Home Requirements
To ensure Home or Hybrid Home/Office associates’ ability to work effectively, the self-provided internet service of Home or Hybrid Home/Office associates must meet the following criteria:
At minimum, a download speed of 25 Mbps and an upload speed of 10 Mbps is recommended to support Humana applications, per associate.
Wireless, Wired Cable or DSL connection is suggested.
Satellite, cellular and microwave connection can be used only if they provide an optimal connection for associates. The use of these methods must be approved by leadership. (See Wireless, Wired Cable or DSL Connection in Exceptions, Section 7.0 in this policy.)
Humana will not pay for or reimburse Home or Hybrid Home/Office associates for any portion of the cost of their self-provided internet service, with the exception of associates who live or work from Home in the state of California, Illinois, Montana, or South Dakota. Associates who live and work from Home in the state of California, Illinois, Montana, or South Dakota will be provided a bi-weekly payment for their internet expense.
Humana will provide Home or Hybrid Home/Office associates with telephone equipment appropriate to meet the business requirements for their position/job.
Work from a dedicated space lacking ongoing interruptions to protect member PHI / HIPAA information
Our Hiring Process
As part of our hiring process for this opportunity, we may contact you via text message and email to gather more information using a software platform called Modern Hire. Modern Hire Text, Scheduling and Video technologies allow you to interact with us at the time and location most convenient for you.
If you are selected to move forward from your application prescreen, you may receive correspondence inviting you to participate in a pre-recorded Voice, Text Messaging and/or Video interview. Your recorded interview will be reviewed and you will subsequently be informed if you will be moving forward to next round of interviews
If you have additional questions regarding this role posting and are an Internal Candidate, please send them to the Ask A Recruiter persona by visiting go/Buzz and searching Ask A Recruiter! Please be sure to provide the requisition number so we may be able to research your request quicker.
Humana is more than an equal opportunity employer, Humana’s dedication to promoting diversity, multiculturalism, and inclusion is at the heart of what we do in all of our Humana roles. Diversity is more than a commitment to us, it is the foundation of what we do. We are fully focused on diversity of race, gender, sexual orientation, religion, ethnicity, national origin and all of the other fascinating characteristics that make us each uniquely wonderful.
This is a remote position.
#LI-LM1
#LI-Remote
Scheduled Weekly Hours
40

Not Specified
0",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1961,$10+ billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"BNY Mellon
3.6",3.6,Florida,Data Engineer- Big Data,"Overview
Big Data Data Engineer
Bring your ideas. Make history.
BNY Mellon offers an exciting array of future-forward careers at the intersection of business, finance, and technology. We are one of the world's top asset management and banking firms that manages trillions of dollars in assets, custody and/or administration. Known as the “bank of banks” - 97% of the world’s top banks work with us as we lead and serve our customers into the new era of digital.
With over 238 years of rich history and industry firsts, BNY Mellon has been built upon our proven ability to evolve, lead, and drive new ideas at every turn. Today, we’re approximately 50,000 employees across 35 countries with a culture that empowers you to grow, take risks, experiment and be yourself. This is what #LifeAtBNYMellon is all about.
We’re seeking a future team member in the role of Big Data Data Engineer to join our Asset Servicing team. This role is in Pittsburgh, PA HYBRID.
UCM is bank new client master data platform. It is golden source of truth about our clients and their accounts. As an enterprise level platform, API is one of the channels that multiple applications across multiple line of businesses use to get client data relevant for their application use. The data is huge and data security and privacy is top priority while giving data to businesses.

The UCM platform technology team is looking for an experienced mid-level Java developer to assist with delivering value added secure APIs. The candidate will be a key developer who will be ultimately develop cloud ready APIs using Java 11, Spring Boot, Spring Framework, including Oracle and ElasticSearch data repository, and our internal cloud-based solution for containerization. The developer will design and development APIs as per industry standard RESTFul API.

In this role, you’ll make an impact in the following ways:
Strong analytical skills and ability to articulate ideas and design to a group of peers.
Solid Java 8/11 and Spring enterprise developer and matching SQL skills.
Ability to work with Oracle and be able to write complex SQLs.
Experience with Docker, GitLab CI/CI, Junit, Mockito, or other automated build and testing frameworks is also being sought.

To be successful in this role, we’re seeking the following:
3-5 years of experience in software development required.
Experience working in fast-paced environment.
Should have thorough knowledge of the software development cycle.
Must have experience developing RESTFul APIs in Java and SpringBoot.
Must have experience writing SQLs, Spring JDBC/JPA Repositories.
Should have experience writing quality Junit tests using Mockito.
Good to have knowledge on API security using OAuth2.
Good to have knowledge on Kafka, ElasticSearch, Redis or distributed caching.
At BNY Mellon, our inclusive culture speaks for itself. Here’s a few of our awards:
Fortune World’s Most Admired Companies & Top 20 for Diversity and Inclusion
Bloomberg’s Gender Equality Index (GEI)
Best Places to Work for Disability Inclusion , Disability: IN – 100% score
100 Best Workplaces for Innovators, Fast Company
Human Rights Campaign Foundation, 100% score Corporate Equality Index
CDP’s Climate Change ‘A List’

Our Benefits:
BNY Mellon offers highly competitive compensation, benefits, and wellbeing programs rooted in a strong culture of excellence and our pay-for-performance philosophy. We provide access to flexible global resources and tools for your life’s journey. Focus on your health, foster your personal resilience, and reach your financial goals as a valued member of our team, along with generous paid leaves that can support you and your family through moments that matter.
BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer - Underrepresented racial and ethnic groups/Females/Individuals with Disabilities/Protected Veterans.

REGULATIONS/REQUIREMENTSBachelor's degree in computer science engineering or a related discipline, or equivalent work experience required2-6 years of experience in software development required; experience in the securities or financial services industry is a plus; should have thorough knowledge of the software development cycle S/he must also have experience developing in backend environment Job holder must be knowledgeable about cross-platform interoperability (multiple platforms. NT, Intranet, etc.) , major tools in a toolkit for a specific platform and features of multiple toolkits. S/he must be experienced at resolving hardware, software, and communications malfunctions and understand the business impact of resolving complications.. BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer. Minorities/Females/Individuals with Disabilities/Protected Veterans. Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.

Employer Description:
For over 230 years, the people of BNY Mellon have been at the forefront of finance, expanding the financial markets while supporting investors throughout the investment lifecycle. BNY Mellon can act as a single point of contact for clients looking to create, trade, hold, manage, service, distribute or restructure investments and safeguards nearly one-fifth of the world's financial assets. BNY Mellon remains one of the safest, most trusted and admired companies. Every day our employees make their mark by helping clients better manage and service their financial assets around the world. Whether providing financial services for institutions, corporations or individual investors, clients count on the people of BNY Mellon across time zones and in 35 countries and more than 100 markets. It's the collective ambition, innovative thinking and exceptionally focused client service paired with a commitment to doing what is right that continues to set us apart. Make your mark: bnymellon.com/careers.

EEO Statement:
BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer. Minorities/Females/Individuals With Disabilities/Protected Veterans. Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.",#N/A,10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1784,$10+ billion (USD)
"Moen
4.0",4.0,"North Olmsted, OH",Data Operations Engineer,"Company Description

Fortune Brands Innovations is a global Fortune 500 company specializing in home, outdoors, plumbing, and security products. Our portfolio includes famous brands such as Moen, Master Lock, Fiberon, and Therma-Tru.

Job Description

Data Operations Engineer, full-time from North Olmsted, Cleveland, Toledo, and Columbus.

Our IT/Tech division is transforming digitally to boost our innovation, competitiveness, and efficiency. We're investing in IT and Engineering and assembling a team of experts. The Data & Analytics team is building a data, ML, and analytical platform using modern tech such as Cloud and DevOps. We need a DataOps engineer to join us in developing this platform. It's a new initiative with great career and technical leadership opportunities.

Our Stack
Infrastructure: Hybrid - a mix of on-premise infrastructure and public Cloud, primarily Azure.
Data systems: ERP systems, including SAP and Oracle. Snowflake as Enterprise Datawarehouse.
Platform infrastructure and DevOps: Azure Pipelines, GitHub, Kubernetes, IaC.
Data tools: dbt, Talend, and python.

We have a blend of legacy systems and tools while assessing and introducing new tools where it makes sense. This is a hybrid role where you will be working primarily from home with the flexible option of coming into work at our North Olmstead office for deeper engagement with the team and stakeholders on a needed basis.

Responsibilities
Own, develop, manage, and optimize the orchestration of data pipelines and source code version control that adhere to our data governance principles.
Own, develop, manage, and enhance the tools for the data engineers.
Work closely with stakeholders in Business Intelligence, Data Governance, Infrastructure, and business units to gather functional and non-functional requirements, and deliver the appropriate tooling and systems to produce high-quality data and analytics in a timely manner.
Build systems and automation to overcome the limitations of existing systems and integrate new modern-day tech stack into the company’s IT infrastructure.
Establish system monitoring, cost monitoring/mitigation, and alerting.
Define and enforce best practices and standards for the Data & Analytics team.

Qualifications
Bachelor’s degree in computer science, information systems, science, or engineering; or equivalent years of experience in IT, software engineering, or a relevant field.
4+ years of experience in Python or/and an equivalent language, such as bash or Powershell.
4+ years of experience in Linux system administration, network administration, or working at a data center.
2+ years of experience in working with a Cloud provider, including AWS, GCP, or Azure.
2+ years in developing and managing SDLC workflow, DevOps tools, and CI/CD.
Basic understanding of data architecture, data warehousing, and gitflow.
Experience in observability, including cost monitoring, log management, alerting, monitoring, and tuning.
Self-driven with the ability to work in a multi-stakeholder environment and deal with ambiguity.
Good analytical & problem-solving skills and the ability to incorporate multiple perspectives.
Good written and verbal communication skills.

Preferred Qualifications

Big plus if you have these skills.
Big Plus: Snowflake or a Cloud Warehouse product like Google BigQuery or AWS RedShift.
Big Plus: Experience in data orchestration.
Experience in infrastructure as code, including Terraform, Pulumi, Chef, or Puppet.
Experience in SQL querying language.
Quick learner.
Great sense of humor.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.","$70,958 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"PG&E Corporation
4.0",4.0,"Oakland, CA",Expert Data Engineer,"Requisition ID # 150917

Job Category: Information Technology
Job Level: Individual Contributor
Business Unit: Information Technology
Work Type: Hybrid
Job Location: Oakland; Sacramento; San Francisco; San Jose; San Ramon

Department Summary

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively to deliver high quality technology solutions.

The IT Data, Analytics, & Insights organization is an enterprise team that is responsible for working collaboratively across various lines of business (e.g., , Gas Operations, Electric Operations, Safety, Energy Procurement, etc.) and is focused on unlocking the value of PG&E’s data to support the company’s Wildfire Safety Program and True North Strategy. As part of that focus, we focus on delivering data and AI/ML centric products to support these initiatives. Some of the products that are being delivered include Remote Inspections, AI Enabled Inspections, Vegetation Management through LiDAR capabilities, Transmission Line Asset Master, Electric Distribution Asset Master, Asset Risk Modeling, and a Cloud Native Foundational Platform.

A critical part of how we operate is to apply design thinking, work and observe the Agile development methodology, and co-location. Through these principles, we work as product teams to help deliver a valuable product to our business.

Position Summary

We are looking for an experienced and talented Data Engineer to join our growing team of analytics experts. You will have a unique opportunity to be at the forefront of the utility industry and gain a comprehensive view of the nation’s most advance smart grid! In this role, you will work as part of cross functional teams, including data scientists, other data engineers, technology experts, and subject matter experts to develop data driven solutions. Successful candidates will be responsible for building, expanding, and optimizing our data, data storage, and data pipeline. This individual will support team members and decision products to ensure that data delivery is reliable and optimized. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. It is the perfect role for someone who would like to continue to build upon their professional experience and help advance PG&E’s sustainability goals.

The role is hybrid working primarily from your remote office and the Oakland General Office, in-person, 1-2x monthly for collaboration or as business needs require.

PG&E is providing the salary range that the company in good faith believes it might pay for this position at the time of the job posting. This compensation range is specific to the locality of the job. The actual salary paid to an individual will be based on multiple factors, including, but not limited to, specific skills, education, licenses or certifications, experience, market value, geographic location, and internal equity. This job is also eligible to participate in PG&E’s discretionary incentive compensation programs.

A reasonable salary range is:

Bay Area Minimum: $128,000
Bay Area Maximum: $218,000

Job Responsibilities

Data Engineering:
Leads moderate to high complexity data engineering activities which have broad impact and require in-depth analysis to obtain desired results.
Design and build data pipelines required for optimal extraction, transformation, and loading of data using Pyspark.
Build analytics products that utilize the data pipelines to provide actionable insights.
Identifies, designs, and implements internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Resolves application programming analysis problems of broad scope within procedural guidelines.
Actively participates in agile/scrum ceremonies (stand ups, planning, retrospectives, etc.)
Promotes a continuous improvement mindset by engaging in after action reviews and sharing learnings.

Data System and Architecture Maturity:
Assesses performance of individual data pipeline and broader data systems, suggests and may implement changes as required to meet individual project or enterprise maturity objectives.
Evaluates end-to-end data system interaction to proactively identify any potential pitfalls of the total solution.
Works with the team to help develop best practices and scalable design patterns.
Helps other engineers/analysts on unusual or especially complex problems that cross multiple functional/technology areas. May require creative/non-standard approaches to solve problems that will have significant impact across the company.
Conceptualizes and generates infrastructure that allows big data to be accessed and analyzed with verified data quality and metadata is appropriately captured and catalogued.
Work with team leadership to continually improve data driven decision making at PG&E via demonstrations, mentoring, disseminating best practices, etc.

Qualifications

Minimum:
BA/BS in computer science, management information systems or related technical discipline or equivalent work experience
7 years of experience as a data engineer or in a similar role
Complete proficiency in Python and/or Pyspark
Strong SQL skills and experience working with large datasets and complex data structures in a data warehouse/data lake environment.
Experience creating reports, dashboards, and visualizations using commercial tools (Tableau, Power BI, or other BI tools)

Desired:
Experience with Palantir Foundry application development and data visualization tools
Databases – familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.
Git – knowledge of version control / collaboration workflows and best practices
Agile – familiarity with agile and iterative working methodology and rapid user feedback gathering concepts
UX design – knowledge of best practices and applications
Experience in Typescript (preferred) or Javascript
Data literacy – data analysis and statistical basics to ensure correctness in data aggregation and visualization
Experience leading development teams
Excellent problem-solving and analytical skills with a strong attention to detail","$142,802 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1905,$10+ billion (USD)
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"Maximus
3.4",3.4,"Annapolis, MD",Data Analytics Engineer,"Job Description Summary:
Salary Range: $60,000 - $140,000

Maximus is seeking a Data Analytics Engineer to provide expertise to a federal client in support of their mission critical systems in defense of our Homeland.

We are seeking an experienced Data Analytics Engineer to join our team. As a Data Analytics Engineer, you will be responsible for collecting, processing, analyzing, and visualizing large datasets to extract meaningful insights and support data-driven decision-making. Your role will involve working with cross-functional teams to identify business requirements, develop data models, and implement data analytic solutions.

Specific Responsibilities:

Work with languages related to data manipulation, analysis, and
visualization.
Collect, clean, transform, and process large volumes of data from various
sources to ensure data integrity and accuracy.
Apply statistical techniques and data mining methods to extract
meaningful insights from complex datasets.
Develop and maintain risk patterns to perform predictive analysis.
Create data visualization to effectively communicate insights to technical
and non-technical stakeholders/managements.
Stay updated on emerging technologies, tools, and techniques.
Ensure data privacy, security, and compliance with relevant regulations in
all data analytic activities.
Work with data processing frameworks, such as Apache Spark or Hadoop.

Requirements:

Due to federal requirements, only US Citizens can be considered.
Candidates with dual citizenship cannot be considered.
Candidates with an existing Secret clearance are highly desirable. However,
applicants without a current Secret clearance, who have the ability to obtain
and maintain one, will also be considered for this position.
Must be based around the Annapolis Junction, MD area. This position
requires onsite work; however, a limited amount of telework can be
available, subject to approval.
This individual will be responsible for the daily operation of mission critical
systems on a 24x7x365 workday basis. Shift work will be required
7 or more years of experience in data analytics or in a related field.
7 or more years of experience in the following:
Database systems such as MYSQL
Common software and tools such as Jenkins, Ansible, Jira, VMware,
etc.

#techjobs #clearance #NSO
Job Summary:
Maximus TCS (Technology and Consulting Services) Internal Job Profile Code: TCS069, T3, Band 6
MAXIMUS Introduction: Since 1975, Maximus has operated under its founding mission of Helping Government Serve the People, enabling citizens around the globe to successfully engage with their governments at all levels and across a variety of health and human services programs. Maximus delivers innovative business process management and technology solutions that contribute to improved outcomes for citizens and higher levels of productivity, accuracy, accountability and efficiency of government-sponsored programs. With more than 30,000 employees worldwide, Maximus is a proud partner to government agencies in the United States, Australia, Canada, Saudi Arabia, Singapore and the United Kingdom. For more information, visit https://www.maximus.com. EEO Statement: EEO Statement: Active military service members, their spouses, and veteran candidates often embody the core competencies Maximus deems essential, and bring a resiliency and dependability that greatly enhances our workforce. We recognize your unique skills and experiences, and want to provide you with a career path that allows you to continue making a difference for our country. We’re proud of our connections to organizations dedicated to serving veterans and their families. If you are transitioning from military to civilian life, have prior service, are a retired veteran or a member of the National Guard or Reserves, or a spouse of an active military service member, we have challenging and rewarding career opportunities available for you. A committed and diverse workforce is our most important resource. Maximus is an Affirmative Action/Equal Opportunity Employer. Maximus provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disabled status. Pay Transparency: Maximus compensation is based on various factors including but not limited to job location, a candidate's education, training, experience, expected quality and quantity of work, required travel (if any), external market and internal value analysis including seniority and merit systems, as well as internal pay alignment. Annual salary is just one component of Maximus's total compensation package. Other rewards may include short- and long-term incentives as well as program-specific awards. Additionally, Maximus provides a variety of benefits to employees, including health insurance coverage, life and disability insurance, a retirement savings plan, paid holidays and paid time off. Compensation ranges may differ based on contract value but will be commensurate with job duties and relevant work experience. An applicant's salary history will not be used in determining compensation. Maximus will comply with regulatory minimum wage rates and exempt salary thresholds in all instances. Posted Max: USD $140,000.00/Yr. Posted Min: USD $57,300.00/Yr.","$140,000 /yr (est.)",10000+ Employees,Company - Public,Government & Public Administration,National Agencies,1975,$1 to $5 billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Elevance Health
3.7",3.7,Remote,Data Engineer Sr (contract),"Job ID: #JP00043626

Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. Previously known as Anthem, Inc., we have evolved into a company focused on whole health and updated our name to better reflect the direction the company is heading.

We are looking for contract workers (via BCforward) who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact?

Primary duties may include, but are not limited to:
Undertakes complex assignments requiring additional specialized technical knowledge.
Develops very complex and varied strategic report applications from a Data Warehouse.
Establishes and communicates common goal and direction for team.
Establishes and maintains advanced knowledge of data warehouse database design, data definitions, system capabilities, and data integrity issues.
Acts as a source of direction, training and guidance for less experienced staff.
Monitors project schedules and costs for own and other projects.
Develops and supports very complex Data Warehouse-related applications for business areas requiring design and implementation of database tables. Conducts training on use of applications developed.

Requirements:
Requires a BS/BA degree; 6 years experience; or any combination of education and experience, which would provide an equivalent background.
Expert level PC, spreadsheet, and database skills, as well as experience in standard Business Information tools and programming/query languages is also required.
Ability to communicate effectively with multiple levels within the organization.
This job is focused on spending time thinking about programming and how it would be used to design solutions as compared to the Bus Info Developer Consultant job
SQL, Visual Studio, VB, SSRS, Power BI, Tableau, SSIS

Additional Details:
40 hours/week centered around EST hours - flexible with shift times as long as they are available for meetings during EST (typically around 9am-3pm would be when our meetings would happen). Open to candidates anywhere in the US - 100% remote.
Possible Temp to hire

BCForward is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Privacy Notice for California Residents",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2004,$10+ billion (USD)
"Runway AI
5.0",5.0,Remote,"Staff Software Engineer, Data Infrastructure","At Runway, we believe everyone has a story to tell. Our mission is to make professional video and content creation accessible to all. We are taking recent advancements in computer graphics, the web, and machine learning to push the boundaries of creativity and in turn, lower the barriers of content creation; unfastening a new wave of storytelling
Over the last four years, we’ve raised funding from top-tier investors and partners including Amplify, Coatue, Compound, Felicis, Google, Lux, NVIDIA, and Salesforce. Our team consists of creative, open minded, caring, and entrepreneurial individuals from all walks of life. We aspire to build incredible things which starts with building an incredible team, so we’d love to hear from you!
About the role
We’re looking for a strong Staff Software Engineer to help us build scalable and robust data infrastructure to power Runway’s applied research. You will be the first hire in a new team that’s focused on building data pipelines to support all of Runway’s generative model training and continuous model improvement. The best fit for this role has experience with building large-scale systems for analysis, curation, and retrieval of multimodal data, as well as strong system design and collaboration skills.
What you’ll do
Build out pipelines for the creation, curation, and processing of large-scale multimodal datasets
Create internal tooling to enable Runway’s applied research team to build workflows and run experiments on that infrastructure
What you’ll need
Strong knowledge of Python
Experience with one or more frameworks for large-scale data processing (e.g. Spark, Ray, etc) and one or more ML frameworks (e.g. PyTorch, JAX)
Experience building out data pipelines from scratch and optimizing those pipelines for high performance and great developer experience
Familiarity and experience with AWS and/or GCP is a bonus
Runway strives to recruit and retain exceptional talent from diverse backgrounds while ensuring pay equity for our team. Our salary ranges are based on competitive market rates for our size, stage and industry, and salary is just one part of the overall compensation package we provide.
There are many factors that go into salary determinations, including relevant experience, skill level and qualifications assessed during the interview process, and maintaining internal equity with peers on the team. The range shared below is a general expectation for the function as posted, but we are also open to considering candidates who may be more or less experienced than outlined in the job description. In this case, we will communicate any updates in the expected salary range.
Lastly, the provided range is the expected salary for candidates in the U.S. Outside of those regions, there may be a change in the range, which again, will be communicated to candidates.
Salary range: $190,000-230,000

Working at Runway
We are a small and growing team of artists, engineers, researchers, and dreamers working together to reimagine creativity. And we’re building a unique team of talented individuals from diverse backgrounds. We believe that this will allow us to continue to up-level each other, our company, and our product. We’re looking for people that will add to our culture, not just fit in.
We’re committed to creating a space where our employees can bring their full selves to work and have equal opportunity to succeed. So regardless of race, gender identity or expression, sexual orientation, religion, origin, ability, age, veteran status, if joining this mission speaks to you, we encourage you to apply!","$210,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Software Development,2018,Unknown / Non-Applicable
"ASK Consulting
3.7",3.7,"Austin, TX",Senior Data Engineer (Snowflake),"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 230574@accuick.com
Job Title: Senior Data Engineer (Snowflake)
Location: Hybrid in Austin, TX 78759 (1-2 Day per week)
Job Description
Want someone who can have experiences and opinions around best practices and core philosophies pertaining to an enterprise level data platform that involves snowflake at its core.
Must be able to bringing opinions and experiences to the table.
Not looking for someone to just implement things that have been figured out for them and spoon fed.
Designs, builds and oversees deployment and operation of AWS Cloud solutions to capture, manage, store and utilize structured and unstructured data from multiple client data sources.
Utilizing Snowflake establishes and builds data structures based on business and technical requirements to meet analysis, reporting and analytical needs across client, all while ensuring integrity of the data.
Provides Data Engineering support for areas such as Finance, Sales, Business Intelligence, Product Development and/or other business users.
Works with data consumers and Project Managers to determine logical and physical database designs for analytics models.
Creates and maintains optimal data pipeline architectures.
Ensures architectures are aligned with and support business requirements.
Ensures that required data is available, can be trusted and is readily accessible by those who need it.
Influences the data infrastructure roadmap.
Identifies, designs and implements internal data management process improvements.
Plays a key role in application development projects to evolve the companys database architecture and design.
Works with internal and external data providers on data validation, providing feedback and making customized changes to data feeds and data mappings for analytical and operational use.
Automates manual processes, transforming them into repeatable capabilities.
Works with fellow team members to ensure design, development and execution align with and support adjacencies and adhere to established architectural standards.
What we will require from you:
Bachelors degree in Computer Science or related field plus 4+ years of relevant work experience; or a Master's degree plus 2+ years of relevant work experience; or a PhD plus 0-1 years of relevant experience.
In lieu of a degree, qualified candidates would require 8+ years of relevant professional experience.
Excellent with SQL.
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages.
Excellent understanding of patterns for data ingest into data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, star.
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse.
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.
Experience utilizing reporting and data insights tools.
Experience in supporting analytics teams data needs, in addition to customer and business reporting.
Target Years of Exp:
Ideally 8+ in Data Engineering
Top 5 Must Haves:
Excellent with SQL.
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages.
Excellent understanding of patterns for data ingest into data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, star.
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse.
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$92,211 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Ancestry
3.6",3.6,"San Francisco, CA","Data Engineer, DNA Science","About Ancestry:
When you join Ancestry, you join a human-centered company where every person’s story is important. Ancestry®, the global leader in family history, empowers journeys of personal discovery to enrich lives. With our unparalleled collection of more than 40 billion records, over 3 million subscribers and over 23 million people in our growing DNA network, customers can discover their family story and gain a new level of understanding about their lives. Over the past 40 years, we’ve built trusted relationships with millions of people who have chosen us as the platform for discovering, preserving and sharing the most important information about themselves and their families.

We are committed to our location flexible work approach, allowing you to choose to work in the nearest office, from your home, or a hybrid of both (subject to location restrictions and roles that are required to be in the office- see the full list of eligible US locations HERE). We will continue to hire and promote beyond the boundaries of our office locations, to enable broadened possibilities for employee diversity.

Together, we work every day to foster a work environment that's inclusive as well as diverse, and where our people can be themselves. Every idea and perspective is valued so that our products and services reflect the global and diverse clients we serve.

Ancestry encourages applications from minorities, women, the disabled, protected veterans and all other qualified applicants. Passionate about dedicating your work to enriching people’s lives? Join the curious.
We are looking for an experienced Data Engineer to join our DNA Science team. You will be responsible for the design, construction, and maintenance of our large-scale data systems and infrastructure. You'll work closely with our scientists, bioinformatics specialists, and product teams to ensure efficient and reliable data processing, enabling us to provide insightful and meaningful data to our customers.
Responsibilities
Design and implement complex, scalable big data architectures for our genomic and genealogical data.
Develop and maintain robust ETL pipelines to ensure efficient and reliable data flow.
Ensure data quality and implement measures for data integrity and security.
Collaborate with scientists and bioinformatics specialists to understand their data needs and implement systems to meet these needs.
Continually optimize our data systems for cost, performance, scalability, and security.
Stay up-to-date with industry trends and advancements in data engineering technologies and best practices.
Qualifications
Bachelor's degree in Computer Science, Information Systems, or a related field.
Minimum 3 years of experience in a Data Engineering or similar role.
Proficiency in big data technologies (e.g., Hadoop, Spark) and database systems (SQL and NoSQL).
Strong programming skills, preferably in Python.
Knowledge of data architecture principles, data modeling, and data warehousing.
Experience in the genomics or bioinformatics field.
Familiarity with AWS cloud computing platform.
Knowledge of machine learning and data science concepts.
Experience with data visualization tools.
#IND2
#LI-JE1
As a signatory of the ParityPledge in Support of Women and the ParityPledge in Support of People of Color, Ancestry values pay transparency and pay equity. We are pleased to share the base salary range for this position: $104,400 - $154,350 with eligibility for bonus, equity and comprehensive benefits including health, dental and vision. The actual salary will vary by geographic region and job experience. We will share detailed compensation data for a specific location during the recruiting process. Read more about our benefits HERE.

Note: Disclosure as required by sb19-085(8-5-20) and sb1162(1-1-23)

Additional Information:
Ancestry is an Equal Opportunity Employer that makes employment decisions without regard to race, color, religious creed, national origin, ancestry, sex, pregnancy, sexual orientation, gender, gender identity, gender expression, age, mental or physical disability, medical condition, military or veteran status, citizenship, marital status, genetic information, or any other characteristic protected by applicable law. In addition, Ancestry will provide reasonable accommodations for qualified individuals with disabilities.
All job offers are contingent on a background check screen that complies with applicable law. For San Francisco office candidates, pursuant to the San Francisco Fair Chance Ordinance, Ancestry will consider for employment qualified applicants with arrest and conviction records.
Ancestry is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Ancestry via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Ancestry. No fee will be paid in the event the candidate is hired by Ancestry as a result of the referral or through other means.","$129,375 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,1983,$1 to $5 billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"USAA
3.4",3.4,"San Antonio, TX",Data Engineer II,"Why USAA?
At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation’s military, but we all share in the mission to give back to those who did. We’re working as one to build a great experience and make a real impact for our members.

We believe in our core values of honesty, integrity, loyalty and service. They’re what guides everything we do – from how we treat our members to how we treat each other. Come be a part of what makes us so special!
The Opportunity
The candidate selected for this position is going to get work with the CFO Data & Analytics Team in USAA’s Corporate technology office. They will work with modern data technologies in like snowflake, dbt , container-based API’s , python and Kafka to build data pipelines to enable business with developing and implementing financial models on inputs and also build reporting capabilities on the model outputs within the treasury space in CFO.
This Data Engineer II position is a hybrid work type and can be based in one of our following office locations: San Antonio, TX or Plano, TX. Hybrid roles help employees gain the best of both worlds – collaborating in-person in the office and working from home when needed to achieve focused results.
What you'll do:
Participates in the full life cycle of data engineering to include analysis, solution design, data pipeline engineering, testing, deployment, scheduling, and production support with guidance from senior team members.
Assists in the implementation of technical solutions for data reporting and analytic systems.
Assists with designing and writing test scripts to verify data integrity and application of functionality. Reviews functionality of existing test scripts for understanding.
Demonstrates familiarity with IT Change and Release Management best practices. Deploys data pipeline code with assistance from senior team members.
Participate in design and code review sessions.
Actively participates in Agile ceremonies such as daily standup, iteration planning, backlog grooming, and retrospective sessions.
Develops intermediate familiarity of data management best practices by participating in trainings, reviewing documentation, and reading code from existing solutions.
Demonstrates knowledge and understanding of business products and processes.
Assists senior team members in breaking down business features into technical stories and approaches.
Actively learns about new and emerging technologies in the data engineering space. Seeks to apply learnings in current and future projects.
Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.
What you have:
Bachelor’s degree; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree; OR Approved certification from CodeUp, Galvanize, VetFIT (Veterans for IT) or eFIT
2 years of data engineering, data analysis or software development experience implementing data solutions.
Working Experience in SQL and Relational Databases.
Strong analytical and problem-solving skills.
Basic understanding of cloud technologies and tools.
What sets you apart:
2+ years of working experience with Snowflake.
1+ years of container-based APIs using container frameworks like OpenShift, Docker, or Kubernetes
2+ years of Python and Unix shell/Batch scripting experience
1+ years of experience with Kafka streaming technologies
Working experience with Gradle, yml, GIT, GitHUB, GITLab, etc. around continuous integration and continuous delivery infrastructure
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
What we offer:
Compensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $71,490 - $136,690.
Employees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.
Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.
For more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.
Relocation assistance is not available for this position.
USAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",#N/A,10000+ Employees,Company - Private,Insurance,Insurance Carriers,1922,$25 to $100 million (USD)
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Nationwide
4.0",4.0,Remote,"Specialist, Business Insight (Business Data Engineer)","If you’re passionate about helping people protect what matters most to them, as well as innovating and simplifying processes and operations to provide the best customer value, then Nationwide’s Property and Casualty team could be the place for you!
Compensation Grade (for internal use only): F4
Job Description Summary
We are a versatile group of individuals, working together to meet the needs of our customers. We value knowledge, analytical aptitude and collaboration. If you thrive in a busy, engaging work environment, we want to know more about you!

As a Specialist, Business Insights, you'll extract and manipulate internal and external data through R/SAS/SQL/Python, perform diagnostic and inferential analysis, and communicate actionable insights to business partners. You’ll also work with business partners to determine data and information needs to aid the business with decision making and build statistical and visual solutions using sophisticated business intelligence tools. And you may serve as a lead to others for information and data needs. Your focus will be to maximize the insight gained from internal and external data, ensuring that business partners are making decisions in an optimally informed way.
Job Description
Key Responsibilities:
Functions as the specialist in data extraction from databases, tables, data warehouses and other sources through R/SAS/SQL/Python. Develops, produces, and maintains inferential, statistical, ad hoc and custom analyses and modeling for functional business areas. May use various data access tools to pull information for reports and solutions.
Builds and maintains relationships and serves as a trusted financial and operational measurement resource to clients, internal risk partners and other stakeholders.
Creates and presents financial and operational results. Ensures that insights are action oriented. May develop new statistical and visual solutions for relevant insights.
Consults with business partners to understand, align and deliver work that supports business objectives and priorities.
Leverages statistical inferencing when conducting analysis. Communicates significance in findings when working with business partners. May build business intelligence applications using statistical, database and/or general programming languages and tools.
May assist other associates with preparation of reports and use of information systems, software and related sources of information and may train other users on report preparation and data base access.
Serves as a single point of contact and consultant for business areas for the intake and prioritization of data, reporting, analysis, and advanced statistical work.
Leads and serves as a main point of contact for projects. Monitors, reviews and analyzes the external environment to support the research and analysis done with data extracted from internal sources. Presents and discusses these findings with customers.
May perform other responsibilities as assigned.
Reporting Relationships: Reports to Manager/Director and does not have direct reports.
Typical Skills and Experiences:
Education:Undergraduate studies in data or business analytics, computer science, management information, business, mathematics or related field with post-graduate studies preferred
Experience: Six or more years of related experience with data extraction, data manipulation, data visualization analysis, and problem solving; working with large database. Professional experience in insurance, financial services, or a related industry preferred.
Knowledge, Abilities and Skills:
In-depth knowledge of business policies and procedures, customer service concepts and practices. In-depth understanding of and working knowledge to build data visualization and business intelligence tools. Strong communication skills to interact with others. Ability to understand business processes and the data produced by them. Understanding of functional and operational measurement needs, analyze data requests and interpret business problems into solutions. Ability to work under tight time constraints. Capable of developing distinctive and understandable data visualizations. Other criteria, including leadership skills, competencies and experiences may take precedence. Staffing exceptions to the above must be approved by the hiring manager’s leader and Human Resources Business Partner.
Values: Regularly and consistently demonstrates the Nationwide Values.
Job Conditions:
Overtime Eligibility: Not Eligible (Exempt)
Working Conditions: Normal office environment. Occasional travel, nonstandard or extended work may be required based on project needs.
ADA: The above statements cover what are generally believed to be principal and essential functions of this job. Specific circumstances may allow or require some people assigned to the job to perform a somewhat different combination of duties.
Benefits
We have an array of benefits to fit your needs, including: medical/dental/vision, life insurance, short and long term disability coverage, paid time off with newly hired associates receiving a minimum of 18 days paid time off each full calendar year pro-rated quarterly based on hire date, nine paid holidays, 8 hours of Lifetime paid time off, 8 hours of Unity Day paid time off, 401(k) with company match, company-paid pension plan, business casual attire, and more. To learn more about the benefits we offer,
click here
.
Nationwide is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive culture where everyone feels challenged, appreciated, respected and engaged. Nationwide prohibits discrimination and harassment and affords equal employment opportunities to employees and applicants without regard to any characteristic (or classification) protected by applicable law.
Smoke-Free Iowa Statement: Nationwide Mutual Insurance Company, its affiliates and subsidiaries comply with the Iowa Smokefree Air Act. Smoking is prohibited in all enclosed areas on or around company premises as well as company issued vehicles. The company offers designated smoking areas in which smoking is permitted at each individual location. The Act prohibits retaliation for reporting complaints or violations. For more information on the Iowa Smokefree Air Act, individuals may contact the Smokefree Air Act Helpline at 888-944-2247.
For NY residents please review the following state law information: Notice of Employee Rights, Protections, and Obligations LS740 (ny.gov)
Nationwide pays on a geographic-specific salary structure and placement within the actual starting salary range for this position will be determined by a number of factors including the skills, education, training, credentials and experience of the candidate; the scope, complexity and location of the role as well as the cost of labor in the market; and other conditions of employment. If a Sales job, Sales Incentives, based on performance goals are possible in addition to this range.
The national salary range for Specialist, Business Insights : 73,500.00-152,000.00
The expected starting salary range for Specialist, Business Insights : 81,500.00 - 122,500.00",#N/A,10000+ Employees,Company - Public,Insurance,Insurance Carriers,1925,$10+ billion (USD)
"Texas Children's Hospital
4.0",4.0,"Houston, TX",Data Operations Engineer,"We're looking for a Data Operations Engineer, someone who's ready to grow with our company. In this position you will lead integrated, complex projects and manage the on-going build and maintenance of data marts and reporting visualizations. You will investigate processes to understand data, workflow and communication to meet end user needs within Texas Children's clinical departments, by working closely with the Information Services (IS) data and reporting team. Additionally, you will also provide systems support, communicate system updates, and provide other system support as needed to its assigned department.
Think you've got what it takes?
Job Duties & Responsibilities
Analyze and coordinate the designing of new & existing applications to support clinical business operations.
Create and refine data visualization tools to empower Operational users to more effectively utilize data in their daily practice management.
Coordinate new development and make sure it is consistent and well-integrated with existing information data structure.
Collaborate with TCH internal core stakeholders to identify data and analytics application systems and process needs.
Work with department to identify operational and business needs relating to department-specific reporting needs.
Act as liaison between department(s) and the TCH Information Services (IS) data and analytics team to troubleshoot and provide immediate support to end users.
Analyze system problems and modifications and manage data integrity.
Analyze clinical & business use of existing systems to identify problems to be resolved and define system applications or process improvements.
Recommend modifications to application design or current procedures to maximize advantages of existing resources.
Communicate/Collaborate with IS Data and Analytics team to manage testing and approval of updates/upgrades and modifications.
Work with the appropriate department(s) to review functionality in test environment before migration of updates/upgrades and modifications to production environment, in partnership with the IS data and analytics team.
Develop new processes to address identified needs and assure completion of new processes.
Facilitate improvements and actively seek ways to use technology to improve productivity and business processes.
Skills & Requirements
Being fully vaccinated against COVID-19, including any booster dose(s) of the COVID-19 vaccine recommended by the Centers for Disease Control when eligible, is required for all employees unless approved for a medical or religious exemption.
Bachelor's Degree Computer In Science, Business Administration, Healthcare Administration, Business Or Technology Field Required
Master's Degree In Computer Science, Business Administration, Healthcare Administration, Business Or Technology Field Preferred
5 Years Experience In Information Systems Management, Physician Practice Management, And/Or Other Related Operational Or Clinical Field RequiredSince 1954, Texas Children's has been leading the charge in patient care, education and research to accelerate health care for children and women around the world. When you love what you do, it truly shows in the smiles of our patient families, employees and our numerous accolades such as being consistently ranked as the best children's hospital in Texas, and among the top in the nation by U.S.News & World Report as well as recognition from Houston Business Journal as one of this city's Best Places to Work for ten consecutive years.
Texas Children's comprehensive health care network includes our primary hospital in the Texas Medical Center with expertise in over 40 pediatric subspecialties; the Jan and Dan Duncan Neurological Research Institute (NRI); the Feigin Center for pediatric research; Texas Children's Pavilion for Women, a comprehensive obstetrics/gynecology facility focusing on high-risk births; Texas Children's Hospital West Campus, a community hospital in suburban West Houston; and Texas Children's Hospital The Woodlands, the first hospital devoted to children's care for communities north of Houston. We have also created the nation's first HMO for children, established the largest pediatric primary care network in the country and a global health program that is channeling care to children and women all over the world. Texas Children's Hospital is also academically affiliated with Baylor College of Medicine, one of the largest, most diverse and successful pediatric programs in the nation.
To join our community of 14,000+ dedicated team members, visit texaschildrenspeople.org for career opportunities. You can also learn more about our amazing culture at infinitepassion.org .
Texas Children's is proud to be an equal opportunity employer. All applicants and employees are considered and evaluated for positions at Texas Children's without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, gender identity, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.","$80,757 /yr (est.)",10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1954,$1 to $5 billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Runway AI
5.0",5.0,Remote,"Staff Software Engineer, Data Infrastructure","At Runway, we believe everyone has a story to tell. Our mission is to make professional video and content creation accessible to all. We are taking recent advancements in computer graphics, the web, and machine learning to push the boundaries of creativity and in turn, lower the barriers of content creation; unfastening a new wave of storytelling
Over the last four years, we’ve raised funding from top-tier investors and partners including Amplify, Coatue, Compound, Felicis, Google, Lux, NVIDIA, and Salesforce. Our team consists of creative, open minded, caring, and entrepreneurial individuals from all walks of life. We aspire to build incredible things which starts with building an incredible team, so we’d love to hear from you!
About the role
We’re looking for a strong Staff Software Engineer to help us build scalable and robust data infrastructure to power Runway’s applied research. You will be the first hire in a new team that’s focused on building data pipelines to support all of Runway’s generative model training and continuous model improvement. The best fit for this role has experience with building large-scale systems for analysis, curation, and retrieval of multimodal data, as well as strong system design and collaboration skills.
What you’ll do
Build out pipelines for the creation, curation, and processing of large-scale multimodal datasets
Create internal tooling to enable Runway’s applied research team to build workflows and run experiments on that infrastructure
What you’ll need
Strong knowledge of Python
Experience with one or more frameworks for large-scale data processing (e.g. Spark, Ray, etc) and one or more ML frameworks (e.g. PyTorch, JAX)
Experience building out data pipelines from scratch and optimizing those pipelines for high performance and great developer experience
Familiarity and experience with AWS and/or GCP is a bonus
Runway strives to recruit and retain exceptional talent from diverse backgrounds while ensuring pay equity for our team. Our salary ranges are based on competitive market rates for our size, stage and industry, and salary is just one part of the overall compensation package we provide.
There are many factors that go into salary determinations, including relevant experience, skill level and qualifications assessed during the interview process, and maintaining internal equity with peers on the team. The range shared below is a general expectation for the function as posted, but we are also open to considering candidates who may be more or less experienced than outlined in the job description. In this case, we will communicate any updates in the expected salary range.
Lastly, the provided range is the expected salary for candidates in the U.S. Outside of those regions, there may be a change in the range, which again, will be communicated to candidates.
Salary range: $190,000-230,000

Working at Runway
We are a small and growing team of artists, engineers, researchers, and dreamers working together to reimagine creativity. And we’re building a unique team of talented individuals from diverse backgrounds. We believe that this will allow us to continue to up-level each other, our company, and our product. We’re looking for people that will add to our culture, not just fit in.
We’re committed to creating a space where our employees can bring their full selves to work and have equal opportunity to succeed. So regardless of race, gender identity or expression, sexual orientation, religion, origin, ability, age, veteran status, if joining this mission speaks to you, we encourage you to apply!","$210,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Software Development,2018,Unknown / Non-Applicable
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Austin, TX",Senior Data Engineer (Snowflake),"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 230574@accuick.com
Job Title: Senior Data Engineer (Snowflake)
Location: Hybrid in Austin, TX 78759 (1-2 Day per week)
Job Description
Want someone who can have experiences and opinions around best practices and core philosophies pertaining to an enterprise level data platform that involves snowflake at its core.
Must be able to bringing opinions and experiences to the table.
Not looking for someone to just implement things that have been figured out for them and spoon fed.
Designs, builds and oversees deployment and operation of AWS Cloud solutions to capture, manage, store and utilize structured and unstructured data from multiple client data sources.
Utilizing Snowflake establishes and builds data structures based on business and technical requirements to meet analysis, reporting and analytical needs across client, all while ensuring integrity of the data.
Provides Data Engineering support for areas such as Finance, Sales, Business Intelligence, Product Development and/or other business users.
Works with data consumers and Project Managers to determine logical and physical database designs for analytics models.
Creates and maintains optimal data pipeline architectures.
Ensures architectures are aligned with and support business requirements.
Ensures that required data is available, can be trusted and is readily accessible by those who need it.
Influences the data infrastructure roadmap.
Identifies, designs and implements internal data management process improvements.
Plays a key role in application development projects to evolve the companys database architecture and design.
Works with internal and external data providers on data validation, providing feedback and making customized changes to data feeds and data mappings for analytical and operational use.
Automates manual processes, transforming them into repeatable capabilities.
Works with fellow team members to ensure design, development and execution align with and support adjacencies and adhere to established architectural standards.
What we will require from you:
Bachelors degree in Computer Science or related field plus 4+ years of relevant work experience; or a Master's degree plus 2+ years of relevant work experience; or a PhD plus 0-1 years of relevant experience.
In lieu of a degree, qualified candidates would require 8+ years of relevant professional experience.
Excellent with SQL.
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages.
Excellent understanding of patterns for data ingest into data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, star.
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse.
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.
Experience utilizing reporting and data insights tools.
Experience in supporting analytics teams data needs, in addition to customer and business reporting.
Target Years of Exp:
Ideally 8+ in Data Engineering
Top 5 Must Haves:
Excellent with SQL.
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages.
Excellent understanding of patterns for data ingest into data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, star.
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse.
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$92,211 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"NVR, Inc
3.7",3.7,"Frederick, MD",Data Engineer,"NVR is looking for a talented Data Enginneer to work onsite in Frederick, MD. Join our industry leading technology organization and be a part of making someone’s dream home a reality!
As a Data Engineer, you will be responsible for the day-to-day operations of data-dependent systems to ensure data is properly processed and securely transferred to its appropriate location, in a timely manner. If you are a recent graduate or an engineer early in your career, this is a great opportunity for you to leverage your computer knowledge and analytical skills by getting involved in projects and gaining exposure to cloud technologies, data and analytics!
Key Job Responsibilities:
Keeping the data flowing by working with SQL, SQL Server, SSRS and SSIS
Managing, manipulating, storing, and parsing data on premises and in the cloud.
Collaborate with the team to solve support issues.
Interact with business and IT teams of various applications to understand their data, database, and flow within the systems.
Create logical mapping of source data into target data models, based on business process and data/reporting requirements.
Job Qualifications:
0-3 years of experience in data management (integration, modeling, optimization, and quality).
Experience or coursework with databases and queries
Excellent written and verbal communication skills, interpersonal and collaborative skills.
Must have strong problem-solving and analytical skills.
High degree of initiative and be well organized.
Ability to manage multiple projects with strict timelines.
Here’s what will put you ahead of the pack:
Understanding of data modeling, structured and unstructured data, and data transformation techniques.
Experience or coursework using visualization tools like Tableau or Power BI.
Microsoft Azure Certifications.
About Us & Life at NVR
NVR has been helping families build their happily ever after since 1948. As a Top 5 US homebuilder, we’re committed to quality and to our customers and we take pride in the over 500,000 new homes we have sold and built across the country. Working in the homebuilding industry is tangible and rewarding, but not every job at NVR requires a hard hat. We don’t just sell and build new homes; we also manage teams, acquire land, manufacture materials, provide mortgages to our customers, and provide corporate support to NVR’s multi-billion dollar business operations.
At NVR, we value our teams and provide opportunities to learn new technologies and skills to grow your career. Your desire to excel is matched by our commitment to your success and we’ll give you the tools and industry knowledge you need. Our management team is tenured and talented, nearly 80% of them promoted from within, so you’ll find mentors who can share their knowledge, provide career guidance and encourage your success.
NVR also offers benefits among the best in the industry that reflect the strong commitment we have to all of our employees.
Competitive Compensation
Home Purchase Discount
Mortgage and Settlement Services Discounts
Comprehensive Health, Life and Disability Insurance
401(k) (Full-time employees are eligible to contribute immediately)
Employee Stock Ownership Program
Vacation and Holidays
In addition to the traditional benefits, we offer all our employees stock ownership through a profit sharing trust as part of our retirement savings package. NVR has had the highest Earnings Per Share growth rate in the homebuilding industry for the past 10 years, so as we grow financially, so do you.
We are an Equal Opportunity Employer.
Drug Testing and Credit Check are required.
Applicants must be legally entitled to work in the United States, as NVR does not provide visa sponsorships.","$71,504 /yr (est.)",5001 to 10000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Construction,1948,$10+ billion (USD)
"Ancestry
3.6",3.6,"San Francisco, CA","Data Engineer, DNA Science","About Ancestry:
When you join Ancestry, you join a human-centered company where every person’s story is important. Ancestry®, the global leader in family history, empowers journeys of personal discovery to enrich lives. With our unparalleled collection of more than 40 billion records, over 3 million subscribers and over 23 million people in our growing DNA network, customers can discover their family story and gain a new level of understanding about their lives. Over the past 40 years, we’ve built trusted relationships with millions of people who have chosen us as the platform for discovering, preserving and sharing the most important information about themselves and their families.

We are committed to our location flexible work approach, allowing you to choose to work in the nearest office, from your home, or a hybrid of both (subject to location restrictions and roles that are required to be in the office- see the full list of eligible US locations HERE). We will continue to hire and promote beyond the boundaries of our office locations, to enable broadened possibilities for employee diversity.

Together, we work every day to foster a work environment that's inclusive as well as diverse, and where our people can be themselves. Every idea and perspective is valued so that our products and services reflect the global and diverse clients we serve.

Ancestry encourages applications from minorities, women, the disabled, protected veterans and all other qualified applicants. Passionate about dedicating your work to enriching people’s lives? Join the curious.
We are looking for an experienced Data Engineer to join our DNA Science team. You will be responsible for the design, construction, and maintenance of our large-scale data systems and infrastructure. You'll work closely with our scientists, bioinformatics specialists, and product teams to ensure efficient and reliable data processing, enabling us to provide insightful and meaningful data to our customers.
Responsibilities
Design and implement complex, scalable big data architectures for our genomic and genealogical data.
Develop and maintain robust ETL pipelines to ensure efficient and reliable data flow.
Ensure data quality and implement measures for data integrity and security.
Collaborate with scientists and bioinformatics specialists to understand their data needs and implement systems to meet these needs.
Continually optimize our data systems for cost, performance, scalability, and security.
Stay up-to-date with industry trends and advancements in data engineering technologies and best practices.
Qualifications
Bachelor's degree in Computer Science, Information Systems, or a related field.
Minimum 3 years of experience in a Data Engineering or similar role.
Proficiency in big data technologies (e.g., Hadoop, Spark) and database systems (SQL and NoSQL).
Strong programming skills, preferably in Python.
Knowledge of data architecture principles, data modeling, and data warehousing.
Experience in the genomics or bioinformatics field.
Familiarity with AWS cloud computing platform.
Knowledge of machine learning and data science concepts.
Experience with data visualization tools.
#IND2
#LI-JE1
As a signatory of the ParityPledge in Support of Women and the ParityPledge in Support of People of Color, Ancestry values pay transparency and pay equity. We are pleased to share the base salary range for this position: $104,400 - $154,350 with eligibility for bonus, equity and comprehensive benefits including health, dental and vision. The actual salary will vary by geographic region and job experience. We will share detailed compensation data for a specific location during the recruiting process. Read more about our benefits HERE.

Note: Disclosure as required by sb19-085(8-5-20) and sb1162(1-1-23)

Additional Information:
Ancestry is an Equal Opportunity Employer that makes employment decisions without regard to race, color, religious creed, national origin, ancestry, sex, pregnancy, sexual orientation, gender, gender identity, gender expression, age, mental or physical disability, medical condition, military or veteran status, citizenship, marital status, genetic information, or any other characteristic protected by applicable law. In addition, Ancestry will provide reasonable accommodations for qualified individuals with disabilities.
All job offers are contingent on a background check screen that complies with applicable law. For San Francisco office candidates, pursuant to the San Francisco Fair Chance Ordinance, Ancestry will consider for employment qualified applicants with arrest and conviction records.
Ancestry is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Ancestry via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Ancestry. No fee will be paid in the event the candidate is hired by Ancestry as a result of the referral or through other means.","$129,375 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,1983,$1 to $5 billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Rivian
3.4",3.4,"Irvine, CA",Sr. Data Engineer,"About Rivian:
Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.

As a company, we constantly challenge what’s possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.
Role Summary:
In this position, you will contribute to the data engineering needs of Rivian's Product Development Organization. You will manage the back end data from enterprise engineering applications and non enterprise applications such as our internal engineering applications. Additionaly you will be responsible for preparing, analyzing and serving data as needed for our development tools that deliver insights to the Product Development Organization.

To deliver you must be a team player, technicaly capable and able to think critically. To excel at this position you will have to navigate technical IT discussions, Enterprise Technology platforms, data architecture, and and colaborate cross fucntionally. You will also have to stay up to speed on the latest tools and technology in the data engineering world.
Responsibilities:
Create Big Data Solutions with high volumes & variety of data from PLM and other engineering applications and machines.
Collaborate with other technology teams to implement a framework of tools and technologies to ingest high volume of data to support engineering analytics, data science and machine learning use cases.
Solve complex analytical requirements using software engineering tools.
Support and utilize tools and technologies to provide data governance – data catalog and lineage.
Create data applications with ability to do searches, real time data alerts, APIs to pull the data on a large volume of data.
Build data applications to provide real-time data alerts & high throughput analytics
Qualifications:
Bachelors/Masters in data science, computer science, engineering, mathematics, or a related technical discipline preferred
Strong communication and leadership & collaboration skills.
Prior experience with PLM and handling product data management (PDM) in high volume manufacturing environment.
Passion for software & data engineering, pioneering data technologies and architecture. Ability to understand complex business problems and provide software solutions.
3+ years of experience in building petabyte scale data platforms and Big Data architecture using AWS services & open-source technologies.
Extensive hands-on experience in using AWS & open-source services like Glue, Spark Kinesis/Kafka, S3, Athena, Sagemaker
Hands-on experience in one or more programming languages like Python, Java, Scala.
Real-life production experience in creating architectural framework and tools for Data Science teams to build, train & scale machine learning models.
Strong hands-on experience with NOSQL, Columnar and Relational databases.
Understanding of data catalog solutions like Alation, Collibra, Atlas
Experience in building CI/CD framework for the data teams
Experience with infrastructure as code
Pay Disclosure:
Salary Range California-Based Applicants: $150,000 -$173,000 (actual compensation will be determined based on experience, and other factors permitted by law).
Company Statements:
Equal Opportunity
Rivian is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law.

Rivian is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at candidateaccommodations@rivian.com.
Candidate Data Privacy
Rivian may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Rivian may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law.

Rivian may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our People Team, Finance, Legal, and the team(s) with the position(s) for which you are applying; (ii) Rivian affiliates; and (iii) Rivian’s service providers, including providers of background checks, staffing services, and cloud services.

Rivian may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions.

Please note that we are currently not accepting applications from third party application services.","$103,502 /yr (est.)",5001 to 10000 Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2009,Unknown / Non-Applicable
"BTI Solutions
3.6",3.6,Remote,Data Engineer / Remote / Logistics / SC702786,"Why Work for Us?

Established in 2006, continues to grow dramatically within the IT, telecommunications, Automotive and SCM industry. We encourage our employees in personal development with a passion to succeed and we offer an excellent benefit package. Every employee has access to Medical, Vision, Dental, Life and 401K plus many more.

401K with Employer Match
Company Paid Dental, Vision, Life and Medical up to 100%
Paid Sick Leave
Chance for VISA sponsoring
SUMMARY OF ESSENTIAL JOB FUNCTIONS
Design and develop analytical models and be the face to the data consumers
Perform data curation to meet the business requirements
Build batch and streaming data pipelines
Develop processes for automating, testing, and deploying your work
Identify risks and opportunities of potential logic and data issues within the data environment
Collaborate effectively with the global team and ensure day to day deliverables are met
MINIMUN REUIREMENTS
Bachelor’s degree and 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets
3+ years of experience as Data Engineer or in a similar role
Proven experiences with AWS and/or GCP, Hadoop, Vertica, Talend, Tableau, and other modern technology platforms is required
Cloud to Cloud migration experience preferred
Strong PySpark skill is a must have
Have knowledge of data management fundamentals and data storage principles
Have knowledge of systems as it pertains to data storage and computing
Strong source to target mapping experience and ETL principles/knowledge
Excellent verbal and written communication skills.
Strong quantitative and analytical skills with accuracy and attention to detail
Ability to work well independently with minimal supervision and can manage multiple priorities

BTI Solutions, Inc. is an equal opportunity employer m/f/d/v.",#N/A,201 to 500 Employees,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,2006,$25 to $100 million (USD)
"Discover Financial Services
3.9",3.9,Illinois,Data Engineer - Abinitio,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.
Job Description: The Data Engineer is responsible designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community.
Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members
Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies
Demonstrates strong technical aptitude across data engineering practices:
Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting
Designing advanced SQL queries
Leveraging metadata-driven framework for solutions
Developing test scripts for unit and integration testing
Develops test methodologies for specific products
Leads code review sessions and other process and operational improvement initiatives
Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)
Works on holistic solutions, driving feature and story delivery (Agile)
Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline
Participates in the on-call rotation for support
Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities
Builds strong collaborative working relationship both within the team and cross-functionally

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field
3+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale

Preferred Qualifications

If we had our say, we’d also look for:
ETL/ELT Tools (AbInitio, DataStage, Informatica)
Cloud Tools and Databases (AWS, Snowflake)
Other programming languages (Unix scripting, Python, etc.)
Leverage CI/CD framework for data integration, Open Source
Experience working in cloud platforms (AWS, GCP, Azure)
Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs
Experience optimizing SQL both relational and nosql
External applicants will be required to perform a technical interview.

#LI-CM

Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$113,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Veho
2.9",2.9,Remote,"Senior Staff Engineer, Data Platform","About Veho

Veho is the post-purchase experience company that unlocks the potential of everyday consumers and brands to fully participate in e-commerce. Building an entirely new end-to-end logistics infrastructure, powered by the latest technology and designed for the modern era of shopping, Veho is reinventing shipping, and all parts of the post-purchase experience as we know it. By removing the pain from delivery and returns, Veho is creating powerful opportunities for brands to engage and build deep loyalty with their customers like never before.

You will be part of a team that is building the infrastructural foundations for data aggregation, management, and insights at Veho. Our data and engineering teams build products that power our operations (warehouse, transportation, and marketplace), help drivers successfully deliver packages with care, and provide consumers visibility into everything that is happening. Data and AI is central to our roadmap and you will be critical to its success.

In this role, your immediate focus will be to assemble our first data platform using a combination of technologies from the modern data stack and set up the data platform to support Veho’s growth and operational outlook.
Responsibilities Include:
Assembling a data intensive platform that is used by Veho engineers, data scientists, analysts, and business users from across the company.
Drive and deliver the foundational infrastructure to support the product vision for data products. Applying systems thinking to data product development.
Providing thought leadership on how to leverage data infrastructure in analytical and operational contexts.Excelling at mentoring and guiding a fast growing organization by setting the right architectural patterns, partnering and driving build vs buy decisions, partnering with the Head of Data in driving our data strategy.
Being adept at identifying and pursuing quick wins while prioritizing for the long-term.
Breaking down large systems so they can be built iteratively while delivering continuous customer value.
Rolling up your sleeves and getting down to the lowest level of details when appropriate.
Collaborating with stakeholders, peer leaders, and business leaders across Veho.
Projects you'll be involved in:
Scale and stabilize the BI stack that uses Metabase, Redshift, and Fivetran.
Set up data science workbench with distributed compute (eg: Spark) to open up data exploration policiesBuild Veho’s data lake using Iceberg or Delta
Establish best practices for data engineering and data management.Partner with engineering teams on rolling out operational analytics datastore to support leveraging data outcomes for operational decision making (in the product or real-time in warehouses)
Build a MLops workflow for machine learning teams.
About You:
You are an experienced technical leader with a proven track record of delivering impactful results.
You have a deep technical engineering background in one of more areas of the modern data stack.
You are comfortable with ambiguity and have a sufficient understanding of all parts of the modern data stack.
Exceptional communication skills and ability to translate technical concepts into easy to understand language for our stakeholders.
Excitement for working with a remote team; you value collaborating on problems, asking questions, delivering feedback, and supporting others in their goals whether they are in your vicinity or entire cities apart.
The salary range for this role is $205,000-228,000. The actual salary is dependent upon many factors, such as: education, experience, and skills. The pay range is subject to the discretion of the Company.
Veho is a growth company that looks for team members to grow with it. Veho offers a generous ownership package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Veho employee shares one galvanizing mission: to revolutionize the world of package delivery by creating exceptional experiences for customers and drivers. We are deeply value-driven (Ownership, Candor, Team Success, Human) and care tremendously about investing in people. We are committed to creating a diverse team and an environment that provides everyone with the opportunity to do the work of their lifetime. Veho is unable to provide sponsorship at this time.

Veho is committed to nurturing, cultivating and preserving a diverse and inclusive work environment. Empathy and respect for each other is core to our values and a central part of working here every day. The diversity of our employees, drivers and applicants is welcomed and encouraged.","$216,500 /yr (est.)",51 to 200 Employees,Company - Private,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"BNY Mellon
3.6",3.6,Florida,Data Engineer- Big Data,"Overview
Big Data Data Engineer
Bring your ideas. Make history.
BNY Mellon offers an exciting array of future-forward careers at the intersection of business, finance, and technology. We are one of the world's top asset management and banking firms that manages trillions of dollars in assets, custody and/or administration. Known as the “bank of banks” - 97% of the world’s top banks work with us as we lead and serve our customers into the new era of digital.
With over 238 years of rich history and industry firsts, BNY Mellon has been built upon our proven ability to evolve, lead, and drive new ideas at every turn. Today, we’re approximately 50,000 employees across 35 countries with a culture that empowers you to grow, take risks, experiment and be yourself. This is what #LifeAtBNYMellon is all about.
We’re seeking a future team member in the role of Big Data Data Engineer to join our Asset Servicing team. This role is in Pittsburgh, PA HYBRID.
UCM is bank new client master data platform. It is golden source of truth about our clients and their accounts. As an enterprise level platform, API is one of the channels that multiple applications across multiple line of businesses use to get client data relevant for their application use. The data is huge and data security and privacy is top priority while giving data to businesses.

The UCM platform technology team is looking for an experienced mid-level Java developer to assist with delivering value added secure APIs. The candidate will be a key developer who will be ultimately develop cloud ready APIs using Java 11, Spring Boot, Spring Framework, including Oracle and ElasticSearch data repository, and our internal cloud-based solution for containerization. The developer will design and development APIs as per industry standard RESTFul API.

In this role, you’ll make an impact in the following ways:
Strong analytical skills and ability to articulate ideas and design to a group of peers.
Solid Java 8/11 and Spring enterprise developer and matching SQL skills.
Ability to work with Oracle and be able to write complex SQLs.
Experience with Docker, GitLab CI/CI, Junit, Mockito, or other automated build and testing frameworks is also being sought.

To be successful in this role, we’re seeking the following:
3-5 years of experience in software development required.
Experience working in fast-paced environment.
Should have thorough knowledge of the software development cycle.
Must have experience developing RESTFul APIs in Java and SpringBoot.
Must have experience writing SQLs, Spring JDBC/JPA Repositories.
Should have experience writing quality Junit tests using Mockito.
Good to have knowledge on API security using OAuth2.
Good to have knowledge on Kafka, ElasticSearch, Redis or distributed caching.
At BNY Mellon, our inclusive culture speaks for itself. Here’s a few of our awards:
Fortune World’s Most Admired Companies & Top 20 for Diversity and Inclusion
Bloomberg’s Gender Equality Index (GEI)
Best Places to Work for Disability Inclusion , Disability: IN – 100% score
100 Best Workplaces for Innovators, Fast Company
Human Rights Campaign Foundation, 100% score Corporate Equality Index
CDP’s Climate Change ‘A List’

Our Benefits:
BNY Mellon offers highly competitive compensation, benefits, and wellbeing programs rooted in a strong culture of excellence and our pay-for-performance philosophy. We provide access to flexible global resources and tools for your life’s journey. Focus on your health, foster your personal resilience, and reach your financial goals as a valued member of our team, along with generous paid leaves that can support you and your family through moments that matter.
BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer - Underrepresented racial and ethnic groups/Females/Individuals with Disabilities/Protected Veterans.

REGULATIONS/REQUIREMENTSBachelor's degree in computer science engineering or a related discipline, or equivalent work experience required2-6 years of experience in software development required; experience in the securities or financial services industry is a plus; should have thorough knowledge of the software development cycle S/he must also have experience developing in backend environment Job holder must be knowledgeable about cross-platform interoperability (multiple platforms. NT, Intranet, etc.) , major tools in a toolkit for a specific platform and features of multiple toolkits. S/he must be experienced at resolving hardware, software, and communications malfunctions and understand the business impact of resolving complications.. BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer. Minorities/Females/Individuals with Disabilities/Protected Veterans. Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.

Employer Description:
For over 230 years, the people of BNY Mellon have been at the forefront of finance, expanding the financial markets while supporting investors throughout the investment lifecycle. BNY Mellon can act as a single point of contact for clients looking to create, trade, hold, manage, service, distribute or restructure investments and safeguards nearly one-fifth of the world's financial assets. BNY Mellon remains one of the safest, most trusted and admired companies. Every day our employees make their mark by helping clients better manage and service their financial assets around the world. Whether providing financial services for institutions, corporations or individual investors, clients count on the people of BNY Mellon across time zones and in 35 countries and more than 100 markets. It's the collective ambition, innovative thinking and exceptionally focused client service paired with a commitment to doing what is right that continues to set us apart. Make your mark: bnymellon.com/careers.

EEO Statement:
BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer. Minorities/Females/Individuals With Disabilities/Protected Veterans. Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.",#N/A,10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1784,$10+ billion (USD)
"PG&E Corporation
4.0",4.0,"Oakland, CA",Expert Data Engineer,"Requisition ID # 150917

Job Category: Information Technology
Job Level: Individual Contributor
Business Unit: Information Technology
Work Type: Hybrid
Job Location: Oakland; Sacramento; San Francisco; San Jose; San Ramon

Department Summary

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively to deliver high quality technology solutions.

The IT Data, Analytics, & Insights organization is an enterprise team that is responsible for working collaboratively across various lines of business (e.g., , Gas Operations, Electric Operations, Safety, Energy Procurement, etc.) and is focused on unlocking the value of PG&E’s data to support the company’s Wildfire Safety Program and True North Strategy. As part of that focus, we focus on delivering data and AI/ML centric products to support these initiatives. Some of the products that are being delivered include Remote Inspections, AI Enabled Inspections, Vegetation Management through LiDAR capabilities, Transmission Line Asset Master, Electric Distribution Asset Master, Asset Risk Modeling, and a Cloud Native Foundational Platform.

A critical part of how we operate is to apply design thinking, work and observe the Agile development methodology, and co-location. Through these principles, we work as product teams to help deliver a valuable product to our business.

Position Summary

We are looking for an experienced and talented Data Engineer to join our growing team of analytics experts. You will have a unique opportunity to be at the forefront of the utility industry and gain a comprehensive view of the nation’s most advance smart grid! In this role, you will work as part of cross functional teams, including data scientists, other data engineers, technology experts, and subject matter experts to develop data driven solutions. Successful candidates will be responsible for building, expanding, and optimizing our data, data storage, and data pipeline. This individual will support team members and decision products to ensure that data delivery is reliable and optimized. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. It is the perfect role for someone who would like to continue to build upon their professional experience and help advance PG&E’s sustainability goals.

The role is hybrid working primarily from your remote office and the Oakland General Office, in-person, 1-2x monthly for collaboration or as business needs require.

PG&E is providing the salary range that the company in good faith believes it might pay for this position at the time of the job posting. This compensation range is specific to the locality of the job. The actual salary paid to an individual will be based on multiple factors, including, but not limited to, specific skills, education, licenses or certifications, experience, market value, geographic location, and internal equity. This job is also eligible to participate in PG&E’s discretionary incentive compensation programs.

A reasonable salary range is:

Bay Area Minimum: $128,000
Bay Area Maximum: $218,000

Job Responsibilities

Data Engineering:
Leads moderate to high complexity data engineering activities which have broad impact and require in-depth analysis to obtain desired results.
Design and build data pipelines required for optimal extraction, transformation, and loading of data using Pyspark.
Build analytics products that utilize the data pipelines to provide actionable insights.
Identifies, designs, and implements internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Resolves application programming analysis problems of broad scope within procedural guidelines.
Actively participates in agile/scrum ceremonies (stand ups, planning, retrospectives, etc.)
Promotes a continuous improvement mindset by engaging in after action reviews and sharing learnings.

Data System and Architecture Maturity:
Assesses performance of individual data pipeline and broader data systems, suggests and may implement changes as required to meet individual project or enterprise maturity objectives.
Evaluates end-to-end data system interaction to proactively identify any potential pitfalls of the total solution.
Works with the team to help develop best practices and scalable design patterns.
Helps other engineers/analysts on unusual or especially complex problems that cross multiple functional/technology areas. May require creative/non-standard approaches to solve problems that will have significant impact across the company.
Conceptualizes and generates infrastructure that allows big data to be accessed and analyzed with verified data quality and metadata is appropriately captured and catalogued.
Work with team leadership to continually improve data driven decision making at PG&E via demonstrations, mentoring, disseminating best practices, etc.

Qualifications

Minimum:
BA/BS in computer science, management information systems or related technical discipline or equivalent work experience
7 years of experience as a data engineer or in a similar role
Complete proficiency in Python and/or Pyspark
Strong SQL skills and experience working with large datasets and complex data structures in a data warehouse/data lake environment.
Experience creating reports, dashboards, and visualizations using commercial tools (Tableau, Power BI, or other BI tools)

Desired:
Experience with Palantir Foundry application development and data visualization tools
Databases – familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.
Git – knowledge of version control / collaboration workflows and best practices
Agile – familiarity with agile and iterative working methodology and rapid user feedback gathering concepts
UX design – knowledge of best practices and applications
Experience in Typescript (preferred) or Javascript
Data literacy – data analysis and statistical basics to ensure correctness in data aggregation and visualization
Experience leading development teams
Excellent problem-solving and analytical skills with a strong attention to detail","$142,802 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1905,$10+ billion (USD)
"Discover Financial Services
3.9",3.9,"Riverwoods, IL",Senior Associate Data Engineer,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.

Job Description:
At Discover, be part of a culture where diversity, teamwork and collaboration reign. Join a company that is just as employee-focused as it is on its customers and is consistently awarded for both. We’re all about people, and our employees are why Discover is a great place to work. Be the reason we help millions of consumers build a brighter financial future and achieve yours along the way with a rewarding career.

The Senior Associate Data Engineer is responsible for designing, developing, maintaining , and testing data solutions for the product using the enterprise framework. This role will apply learned software delivery capabilities and have the desire to learn higher levels of craftmanship. Senior Associate Data Engineers contribute opinions to design decisions and actively participate in agile ceremonies. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Responsibilities

Independently executes a variety of data integration solutions, recognizes data related patterns, and solicits advice on potential approaches

Contributes opinions to design decisions and understands design tradeoffs

Develops skills in data warehouse tools, Cloud, agile and other technologies involved in data integration

Demonstrates and applies knowledge of:
Data Integration concepts and tools

DW Design concepts and Metadata documentation

Data Profiling tools

Data Security

Data Quality

Regularly contributes to team agile ceremonies and helps new engineers with onboarding

Troubleshoots production issues and defects

Identifies and executes test scenarios and shares test results

Participates in the on-call rotation for support

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field

1 + years of experience in Data Platform Administration/Engineering

Internal applicants only: technical proficiency rating of advanced beginner on the Dreyfus engineering scale
Preferred Qualifications

If we had our say, we’d also look for:
Experience in supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)

ETL/ELT Tools ( AbInitio , DataStage, Informatica)

Experience working with relational or no-SQL databases, Cloud Tools

Other programming languages (Unix scripting, Python, etc.)

Knowledge of cloud platforms (AWS, GCP, Azure)

Basic knowledge of DevOps CI/CD framework, Open-Source concepts, key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs

External applicants will be required to perform a technical interview.

Compensation: The base pay for this position generally ranges between $70,000.00 to $118,400.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$94,200 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"ServiceNow
4.4",4.4,"Waltham, MA",Sr Staff Data Platform Software Engineer,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

Team
As part of the AI Search team, you will be responsible for building the Next-Gen Search Experience for the ServiceNow platform powered by AI used by thousands of customers.
What you get to do in this role:
Design, and build innovative search capabilities with high scalability and quality.
Design and build innovative Cloud Automation capabilities with high scalability and quality.
Implement cutting edge search capabilities and technologies ranging from keyword search and
word/paragraph vectorization to knowledge graphs and ML.
Implement Cloud Automation capabilities with dev-ops and ServiceNow technologies.
Design and build tools, libraries, and frameworks with long term platform implications for high
modularity, extensibility, configurability, and maintainability.
Collaborate and work cross-functionally with other teams.
Design and deliver outstanding search experiences for our customers and developers.
To be successful in the role:
Passion for problem solving, software architecture, and development.
Experience with open-source technologies like Linux, Apache/Tomcat, and MySQL
Experience in one or more programming languages – Java, Python, JavaScript
Experience with relational databases or NoSQL Databases
Experience writing or using REST APIs
Experience with Cloud technologies
Adapt to changing Business and project priorities

WJ23

Qualifications
10+ years of software research and development experience
8+ years of Development experience in Java or JavaScript
Nice to have:
Experience with Search Technologies like Elastic Search, Lucene and Solr
Experience with container technologies like Docker, Kubernetes
Experience with Puppet, Ansible

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$144,232 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Moen
4.0",4.0,"North Olmsted, OH",Data Operations Engineer,"Company Description

Fortune Brands Innovations is a global Fortune 500 company specializing in home, outdoors, plumbing, and security products. Our portfolio includes famous brands such as Moen, Master Lock, Fiberon, and Therma-Tru.

Job Description

Data Operations Engineer, full-time from North Olmsted, Cleveland, Toledo, and Columbus.

Our IT/Tech division is transforming digitally to boost our innovation, competitiveness, and efficiency. We're investing in IT and Engineering and assembling a team of experts. The Data & Analytics team is building a data, ML, and analytical platform using modern tech such as Cloud and DevOps. We need a DataOps engineer to join us in developing this platform. It's a new initiative with great career and technical leadership opportunities.

Our Stack
Infrastructure: Hybrid - a mix of on-premise infrastructure and public Cloud, primarily Azure.
Data systems: ERP systems, including SAP and Oracle. Snowflake as Enterprise Datawarehouse.
Platform infrastructure and DevOps: Azure Pipelines, GitHub, Kubernetes, IaC.
Data tools: dbt, Talend, and python.

We have a blend of legacy systems and tools while assessing and introducing new tools where it makes sense. This is a hybrid role where you will be working primarily from home with the flexible option of coming into work at our North Olmstead office for deeper engagement with the team and stakeholders on a needed basis.

Responsibilities
Own, develop, manage, and optimize the orchestration of data pipelines and source code version control that adhere to our data governance principles.
Own, develop, manage, and enhance the tools for the data engineers.
Work closely with stakeholders in Business Intelligence, Data Governance, Infrastructure, and business units to gather functional and non-functional requirements, and deliver the appropriate tooling and systems to produce high-quality data and analytics in a timely manner.
Build systems and automation to overcome the limitations of existing systems and integrate new modern-day tech stack into the company’s IT infrastructure.
Establish system monitoring, cost monitoring/mitigation, and alerting.
Define and enforce best practices and standards for the Data & Analytics team.

Qualifications
Bachelor’s degree in computer science, information systems, science, or engineering; or equivalent years of experience in IT, software engineering, or a relevant field.
4+ years of experience in Python or/and an equivalent language, such as bash or Powershell.
4+ years of experience in Linux system administration, network administration, or working at a data center.
2+ years of experience in working with a Cloud provider, including AWS, GCP, or Azure.
2+ years in developing and managing SDLC workflow, DevOps tools, and CI/CD.
Basic understanding of data architecture, data warehousing, and gitflow.
Experience in observability, including cost monitoring, log management, alerting, monitoring, and tuning.
Self-driven with the ability to work in a multi-stakeholder environment and deal with ambiguity.
Good analytical & problem-solving skills and the ability to incorporate multiple perspectives.
Good written and verbal communication skills.

Preferred Qualifications

Big plus if you have these skills.
Big Plus: Snowflake or a Cloud Warehouse product like Google BigQuery or AWS RedShift.
Big Plus: Experience in data orchestration.
Experience in infrastructure as code, including Terraform, Pulumi, Chef, or Puppet.
Experience in SQL querying language.
Quick learner.
Great sense of humor.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.","$70,958 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"Maximus
3.4",3.4,"Annapolis, MD",Data Analytics Engineer,"Job Description Summary:
Salary Range: $60,000 - $140,000

Maximus is seeking a Data Analytics Engineer to provide expertise to a federal client in support of their mission critical systems in defense of our Homeland.

We are seeking an experienced Data Analytics Engineer to join our team. As a Data Analytics Engineer, you will be responsible for collecting, processing, analyzing, and visualizing large datasets to extract meaningful insights and support data-driven decision-making. Your role will involve working with cross-functional teams to identify business requirements, develop data models, and implement data analytic solutions.

Specific Responsibilities:

Work with languages related to data manipulation, analysis, and
visualization.
Collect, clean, transform, and process large volumes of data from various
sources to ensure data integrity and accuracy.
Apply statistical techniques and data mining methods to extract
meaningful insights from complex datasets.
Develop and maintain risk patterns to perform predictive analysis.
Create data visualization to effectively communicate insights to technical
and non-technical stakeholders/managements.
Stay updated on emerging technologies, tools, and techniques.
Ensure data privacy, security, and compliance with relevant regulations in
all data analytic activities.
Work with data processing frameworks, such as Apache Spark or Hadoop.

Requirements:

Due to federal requirements, only US Citizens can be considered.
Candidates with dual citizenship cannot be considered.
Candidates with an existing Secret clearance are highly desirable. However,
applicants without a current Secret clearance, who have the ability to obtain
and maintain one, will also be considered for this position.
Must be based around the Annapolis Junction, MD area. This position
requires onsite work; however, a limited amount of telework can be
available, subject to approval.
This individual will be responsible for the daily operation of mission critical
systems on a 24x7x365 workday basis. Shift work will be required
7 or more years of experience in data analytics or in a related field.
7 or more years of experience in the following:
Database systems such as MYSQL
Common software and tools such as Jenkins, Ansible, Jira, VMware,
etc.

#techjobs #clearance #NSO
Job Summary:
Maximus TCS (Technology and Consulting Services) Internal Job Profile Code: TCS069, T3, Band 6
MAXIMUS Introduction: Since 1975, Maximus has operated under its founding mission of Helping Government Serve the People, enabling citizens around the globe to successfully engage with their governments at all levels and across a variety of health and human services programs. Maximus delivers innovative business process management and technology solutions that contribute to improved outcomes for citizens and higher levels of productivity, accuracy, accountability and efficiency of government-sponsored programs. With more than 30,000 employees worldwide, Maximus is a proud partner to government agencies in the United States, Australia, Canada, Saudi Arabia, Singapore and the United Kingdom. For more information, visit https://www.maximus.com. EEO Statement: EEO Statement: Active military service members, their spouses, and veteran candidates often embody the core competencies Maximus deems essential, and bring a resiliency and dependability that greatly enhances our workforce. We recognize your unique skills and experiences, and want to provide you with a career path that allows you to continue making a difference for our country. We’re proud of our connections to organizations dedicated to serving veterans and their families. If you are transitioning from military to civilian life, have prior service, are a retired veteran or a member of the National Guard or Reserves, or a spouse of an active military service member, we have challenging and rewarding career opportunities available for you. A committed and diverse workforce is our most important resource. Maximus is an Affirmative Action/Equal Opportunity Employer. Maximus provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disabled status. Pay Transparency: Maximus compensation is based on various factors including but not limited to job location, a candidate's education, training, experience, expected quality and quantity of work, required travel (if any), external market and internal value analysis including seniority and merit systems, as well as internal pay alignment. Annual salary is just one component of Maximus's total compensation package. Other rewards may include short- and long-term incentives as well as program-specific awards. Additionally, Maximus provides a variety of benefits to employees, including health insurance coverage, life and disability insurance, a retirement savings plan, paid holidays and paid time off. Compensation ranges may differ based on contract value but will be commensurate with job duties and relevant work experience. An applicant's salary history will not be used in determining compensation. Maximus will comply with regulatory minimum wage rates and exempt salary thresholds in all instances. Posted Max: USD $140,000.00/Yr. Posted Min: USD $57,300.00/Yr.","$140,000 /yr (est.)",10000+ Employees,Company - Public,Government & Public Administration,National Agencies,1975,$1 to $5 billion (USD)
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"AT&T
3.6",3.6,"Plano, TX",Senior-Big Data Engineer,"Join AT&T and reimagine the communications and technologies that connect the world. Our Consumer Technology experience team is delivering innovative and reliable technology solutions to power differentiated, simplified customer experiences. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won’t just imagine the future-you’ll create it.
As a Senior Big Data Engineer, you will be responsible for interpreting the requirements of various Big Data Analytic Use Cases and Scenarios, and driving the design and implementation of specific data. Work on projects that support Mobility, Retail and Broadband.
About the job:
Architect and develop solutions using BI applications to provide business with insights and visualizations.
Manage and support users on Business Intelligence applications such as Power BI and Tableau.
Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the Big Data Environment.
Support the standardization, customization and ad-hoc data analysis and will develop the mechanisms to ingest, analyze, validate, normalize and clean data.
Implement statistical data quality procedures on new data sources and by applying rigorous iterative data analytics, supports Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value.
Work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data.
Develop and maintain data engineering best practices and contribute to Insights on data analytics and visualization concepts, methods and techniques.
Qualifications – External

Bachelor’s of Science in Computer Science, Math or Scientific Computing preferred.
5-8 years of experience in Power BI, Tableau and Azure
Ability to manage Business Intelligence applications end-to-end.
Requires Daily Office Presence in Plano, Texas.
Our Senior-Big Data Engineers earn between $115,600 - $231,100. Not to mention all the other amazing rewards that working at AT&T offers. Individual starting salary within this range may depend on geography, experience, expertise, and education/training.
Joining our team comes with amazing perks and benefits:
Medical/Dental/Vision Coverage
401(k) plan
Tuition reimbursement program
Paid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)
Paid Parental Leave
Paid Caregiver Leave
Additional sick leave beyond what state and local law require may be available but is unprotected
Adoption Reimbursement
Disability Benefits (short term and long term)
Life and Accidental Death Insurance
Supplemental benefit programs: critical illness/accident hospital indemnity/group legal
Employee Assistance Programs (EAP)
Extensive employee wellness programs
Employee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone
AT&T is leading the way to the future – for customers, businesses and the industry. We're developing new technologies to make it easier for our customers to stay connected to their world. Together, we’ve built a premier integrated communications and entertainment.
Apply Now
#BigData","$173,350 /yr (est.)",10000+ Employees,Company - Public,Telecommunications,Telecommunications Services,1876,$10+ billion (USD)
"Disney Media & Entertainment Distribution
3.9",3.9,"Santa Monica, CA",Sr Data Engineer,"The Ad Platforms organization within Disney Entertainment and ESPN Technology is fully responsible for building, enhancing and maintaining the high-performance, distributed, microservice-based Advertising Platform across all of Disney online properties, including Hulu and ESPN+. We build and maintain proprietary technology, ranging from ad serving and ad delivery, campaign management, reporting as well as all the integrations internal and external that come with evolving and maintaining a best-in-class video advertising business.
The Ad Intelligence team is under Ad Platforms and its mission is to transform advertising and Disney's Ad platform with data and AI across TV and streaming video. We build solutions to measure and optimize every aspect of the advertising life cycle. Our tenant is a strong cross-domain team to deliver E2E solutions covering tech areas ranging from machine learning, big data, microservices to data visualization. Our team is seeking a senior data engineer who will be a core team member for our advertising data platform engineering group. This engineering group focuses on BI solutions for Disney’s Addressable Sales, revenue and business operations teams. The right person for this role should have experience with big data pipelines, analytics and reporting services. If you are proactive, hardworking, and enthusiastic in these domains, this is a phenomenal role for you!
WHAT YOU’LL DO
Expansion of the Ads BI ecosystem, including reporting platform design, reporting development and pipeline development.
Design and Develop reports and visualizations
Enable data modeling, analysis, and data mining to uncover trends and actionable insights
Partner with product analysts and analytics stakeholders to provide ongoing reporting and analysis of business KPIs/metrics to inform and support business, product, and marketing decisions, including ad loads and programmatic yield optimization.
Create operational dashboards to facilitate data self-service for stakeholders
In partnership with product, evangelize data accessibility and educate end users on how to interpret data
Optimize reporting performance and, in partnership with the data governance team, ensure data quality and protect sensitive data.
Partner with internal teams to improve processes and standardize best practices (such as data modeling, documentation, automation)
WHAT TO BRING
Bachelor or above in computer science or statistics
At least 5+ years of experience in data engineering and 2+ years of experience in reporting development
Proficiency with data visualization tools such as Tableau, Looker, Microstrategy
Strong analytical and technical skills with the ability to apply business strategy to data analysis and communicate impact with stakeholders
Experience translating complex reporting needs into technical specifications
Rich experiences in the design and development of large BI projects
Proficiency in at least one DML programming language - Java, Scala, Python
Experience in AWS Big Data technologies including S3.
Passion for technology, and openness to interdisciplinary work
Willingness to go above and beyond to provide insights that drive positive experiences for our viewers and revenue for our businesses.
NICE-TO-HAVES
Experience in digital video advertising or digital marketing domain
Big data system design experience
Data processing experience with Spark (batch), Flink (streaming)
Job orchestration experience with Airflow and Nifi
Analytics DB experience with Snowflake.
Working with streaming event queues such as Kinesis, Kafka, etc.
Experience with Distributed Relational Databases like Druid, Single Store, DynamoDB
Experience with Hadoop/HDFS in local data centers.

The hiring range for this position in Santa Monica, CA is $136,038 to $182,490 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$159,264 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"USAA
3.4",3.4,"San Antonio, TX",Data Engineer II,"Why USAA?
At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation’s military, but we all share in the mission to give back to those who did. We’re working as one to build a great experience and make a real impact for our members.

We believe in our core values of honesty, integrity, loyalty and service. They’re what guides everything we do – from how we treat our members to how we treat each other. Come be a part of what makes us so special!
The Opportunity
The candidate selected for this position is going to get work with the CFO Data & Analytics Team in USAA’s Corporate technology office. They will work with modern data technologies in like snowflake, dbt , container-based API’s , python and Kafka to build data pipelines to enable business with developing and implementing financial models on inputs and also build reporting capabilities on the model outputs within the treasury space in CFO.
This Data Engineer II position is a hybrid work type and can be based in one of our following office locations: San Antonio, TX or Plano, TX. Hybrid roles help employees gain the best of both worlds – collaborating in-person in the office and working from home when needed to achieve focused results.
What you'll do:
Participates in the full life cycle of data engineering to include analysis, solution design, data pipeline engineering, testing, deployment, scheduling, and production support with guidance from senior team members.
Assists in the implementation of technical solutions for data reporting and analytic systems.
Assists with designing and writing test scripts to verify data integrity and application of functionality. Reviews functionality of existing test scripts for understanding.
Demonstrates familiarity with IT Change and Release Management best practices. Deploys data pipeline code with assistance from senior team members.
Participate in design and code review sessions.
Actively participates in Agile ceremonies such as daily standup, iteration planning, backlog grooming, and retrospective sessions.
Develops intermediate familiarity of data management best practices by participating in trainings, reviewing documentation, and reading code from existing solutions.
Demonstrates knowledge and understanding of business products and processes.
Assists senior team members in breaking down business features into technical stories and approaches.
Actively learns about new and emerging technologies in the data engineering space. Seeks to apply learnings in current and future projects.
Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.
What you have:
Bachelor’s degree; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree; OR Approved certification from CodeUp, Galvanize, VetFIT (Veterans for IT) or eFIT
2 years of data engineering, data analysis or software development experience implementing data solutions.
Working Experience in SQL and Relational Databases.
Strong analytical and problem-solving skills.
Basic understanding of cloud technologies and tools.
What sets you apart:
2+ years of working experience with Snowflake.
1+ years of container-based APIs using container frameworks like OpenShift, Docker, or Kubernetes
2+ years of Python and Unix shell/Batch scripting experience
1+ years of experience with Kafka streaming technologies
Working experience with Gradle, yml, GIT, GitHUB, GITLab, etc. around continuous integration and continuous delivery infrastructure
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
What we offer:
Compensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $71,490 - $136,690.
Employees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.
Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.
For more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.
Relocation assistance is not available for this position.
USAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",#N/A,10000+ Employees,Company - Private,Insurance,Insurance Carriers,1922,$25 to $100 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Moen
4.0",4.0,"North Olmsted, OH",Data Operations Engineer,"Company Description

Fortune Brands Innovations is a global Fortune 500 company specializing in home, outdoors, plumbing, and security products. Our portfolio includes famous brands such as Moen, Master Lock, Fiberon, and Therma-Tru.

Job Description

Data Operations Engineer, full-time from North Olmsted, Cleveland, Toledo, and Columbus.

Our IT/Tech division is transforming digitally to boost our innovation, competitiveness, and efficiency. We're investing in IT and Engineering and assembling a team of experts. The Data & Analytics team is building a data, ML, and analytical platform using modern tech such as Cloud and DevOps. We need a DataOps engineer to join us in developing this platform. It's a new initiative with great career and technical leadership opportunities.

Our Stack
Infrastructure: Hybrid - a mix of on-premise infrastructure and public Cloud, primarily Azure.
Data systems: ERP systems, including SAP and Oracle. Snowflake as Enterprise Datawarehouse.
Platform infrastructure and DevOps: Azure Pipelines, GitHub, Kubernetes, IaC.
Data tools: dbt, Talend, and python.

We have a blend of legacy systems and tools while assessing and introducing new tools where it makes sense. This is a hybrid role where you will be working primarily from home with the flexible option of coming into work at our North Olmstead office for deeper engagement with the team and stakeholders on a needed basis.

Responsibilities
Own, develop, manage, and optimize the orchestration of data pipelines and source code version control that adhere to our data governance principles.
Own, develop, manage, and enhance the tools for the data engineers.
Work closely with stakeholders in Business Intelligence, Data Governance, Infrastructure, and business units to gather functional and non-functional requirements, and deliver the appropriate tooling and systems to produce high-quality data and analytics in a timely manner.
Build systems and automation to overcome the limitations of existing systems and integrate new modern-day tech stack into the company’s IT infrastructure.
Establish system monitoring, cost monitoring/mitigation, and alerting.
Define and enforce best practices and standards for the Data & Analytics team.

Qualifications
Bachelor’s degree in computer science, information systems, science, or engineering; or equivalent years of experience in IT, software engineering, or a relevant field.
4+ years of experience in Python or/and an equivalent language, such as bash or Powershell.
4+ years of experience in Linux system administration, network administration, or working at a data center.
2+ years of experience in working with a Cloud provider, including AWS, GCP, or Azure.
2+ years in developing and managing SDLC workflow, DevOps tools, and CI/CD.
Basic understanding of data architecture, data warehousing, and gitflow.
Experience in observability, including cost monitoring, log management, alerting, monitoring, and tuning.
Self-driven with the ability to work in a multi-stakeholder environment and deal with ambiguity.
Good analytical & problem-solving skills and the ability to incorporate multiple perspectives.
Good written and verbal communication skills.

Preferred Qualifications

Big plus if you have these skills.
Big Plus: Snowflake or a Cloud Warehouse product like Google BigQuery or AWS RedShift.
Big Plus: Experience in data orchestration.
Experience in infrastructure as code, including Terraform, Pulumi, Chef, or Puppet.
Experience in SQL querying language.
Quick learner.
Great sense of humor.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.","$70,958 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Maximus
3.4",3.4,"Annapolis, MD",Data Analytics Engineer,"Job Description Summary:
Salary Range: $60,000 - $140,000

Maximus is seeking a Data Analytics Engineer to provide expertise to a federal client in support of their mission critical systems in defense of our Homeland.

We are seeking an experienced Data Analytics Engineer to join our team. As a Data Analytics Engineer, you will be responsible for collecting, processing, analyzing, and visualizing large datasets to extract meaningful insights and support data-driven decision-making. Your role will involve working with cross-functional teams to identify business requirements, develop data models, and implement data analytic solutions.

Specific Responsibilities:

Work with languages related to data manipulation, analysis, and
visualization.
Collect, clean, transform, and process large volumes of data from various
sources to ensure data integrity and accuracy.
Apply statistical techniques and data mining methods to extract
meaningful insights from complex datasets.
Develop and maintain risk patterns to perform predictive analysis.
Create data visualization to effectively communicate insights to technical
and non-technical stakeholders/managements.
Stay updated on emerging technologies, tools, and techniques.
Ensure data privacy, security, and compliance with relevant regulations in
all data analytic activities.
Work with data processing frameworks, such as Apache Spark or Hadoop.

Requirements:

Due to federal requirements, only US Citizens can be considered.
Candidates with dual citizenship cannot be considered.
Candidates with an existing Secret clearance are highly desirable. However,
applicants without a current Secret clearance, who have the ability to obtain
and maintain one, will also be considered for this position.
Must be based around the Annapolis Junction, MD area. This position
requires onsite work; however, a limited amount of telework can be
available, subject to approval.
This individual will be responsible for the daily operation of mission critical
systems on a 24x7x365 workday basis. Shift work will be required
7 or more years of experience in data analytics or in a related field.
7 or more years of experience in the following:
Database systems such as MYSQL
Common software and tools such as Jenkins, Ansible, Jira, VMware,
etc.

#techjobs #clearance #NSO
Job Summary:
Maximus TCS (Technology and Consulting Services) Internal Job Profile Code: TCS069, T3, Band 6
MAXIMUS Introduction: Since 1975, Maximus has operated under its founding mission of Helping Government Serve the People, enabling citizens around the globe to successfully engage with their governments at all levels and across a variety of health and human services programs. Maximus delivers innovative business process management and technology solutions that contribute to improved outcomes for citizens and higher levels of productivity, accuracy, accountability and efficiency of government-sponsored programs. With more than 30,000 employees worldwide, Maximus is a proud partner to government agencies in the United States, Australia, Canada, Saudi Arabia, Singapore and the United Kingdom. For more information, visit https://www.maximus.com. EEO Statement: EEO Statement: Active military service members, their spouses, and veteran candidates often embody the core competencies Maximus deems essential, and bring a resiliency and dependability that greatly enhances our workforce. We recognize your unique skills and experiences, and want to provide you with a career path that allows you to continue making a difference for our country. We’re proud of our connections to organizations dedicated to serving veterans and their families. If you are transitioning from military to civilian life, have prior service, are a retired veteran or a member of the National Guard or Reserves, or a spouse of an active military service member, we have challenging and rewarding career opportunities available for you. A committed and diverse workforce is our most important resource. Maximus is an Affirmative Action/Equal Opportunity Employer. Maximus provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disabled status. Pay Transparency: Maximus compensation is based on various factors including but not limited to job location, a candidate's education, training, experience, expected quality and quantity of work, required travel (if any), external market and internal value analysis including seniority and merit systems, as well as internal pay alignment. Annual salary is just one component of Maximus's total compensation package. Other rewards may include short- and long-term incentives as well as program-specific awards. Additionally, Maximus provides a variety of benefits to employees, including health insurance coverage, life and disability insurance, a retirement savings plan, paid holidays and paid time off. Compensation ranges may differ based on contract value but will be commensurate with job duties and relevant work experience. An applicant's salary history will not be used in determining compensation. Maximus will comply with regulatory minimum wage rates and exempt salary thresholds in all instances. Posted Max: USD $140,000.00/Yr. Posted Min: USD $57,300.00/Yr.","$140,000 /yr (est.)",10000+ Employees,Company - Public,Government & Public Administration,National Agencies,1975,$1 to $5 billion (USD)
"NVR, Inc
3.7",3.7,"Frederick, MD",Data Engineer,"NVR is looking for a talented Data Enginneer to work onsite in Frederick, MD. Join our industry leading technology organization and be a part of making someone’s dream home a reality!
As a Data Engineer, you will be responsible for the day-to-day operations of data-dependent systems to ensure data is properly processed and securely transferred to its appropriate location, in a timely manner. If you are a recent graduate or an engineer early in your career, this is a great opportunity for you to leverage your computer knowledge and analytical skills by getting involved in projects and gaining exposure to cloud technologies, data and analytics!
Key Job Responsibilities:
Keeping the data flowing by working with SQL, SQL Server, SSRS and SSIS
Managing, manipulating, storing, and parsing data on premises and in the cloud.
Collaborate with the team to solve support issues.
Interact with business and IT teams of various applications to understand their data, database, and flow within the systems.
Create logical mapping of source data into target data models, based on business process and data/reporting requirements.
Job Qualifications:
0-3 years of experience in data management (integration, modeling, optimization, and quality).
Experience or coursework with databases and queries
Excellent written and verbal communication skills, interpersonal and collaborative skills.
Must have strong problem-solving and analytical skills.
High degree of initiative and be well organized.
Ability to manage multiple projects with strict timelines.
Here’s what will put you ahead of the pack:
Understanding of data modeling, structured and unstructured data, and data transformation techniques.
Experience or coursework using visualization tools like Tableau or Power BI.
Microsoft Azure Certifications.
About Us & Life at NVR
NVR has been helping families build their happily ever after since 1948. As a Top 5 US homebuilder, we’re committed to quality and to our customers and we take pride in the over 500,000 new homes we have sold and built across the country. Working in the homebuilding industry is tangible and rewarding, but not every job at NVR requires a hard hat. We don’t just sell and build new homes; we also manage teams, acquire land, manufacture materials, provide mortgages to our customers, and provide corporate support to NVR’s multi-billion dollar business operations.
At NVR, we value our teams and provide opportunities to learn new technologies and skills to grow your career. Your desire to excel is matched by our commitment to your success and we’ll give you the tools and industry knowledge you need. Our management team is tenured and talented, nearly 80% of them promoted from within, so you’ll find mentors who can share their knowledge, provide career guidance and encourage your success.
NVR also offers benefits among the best in the industry that reflect the strong commitment we have to all of our employees.
Competitive Compensation
Home Purchase Discount
Mortgage and Settlement Services Discounts
Comprehensive Health, Life and Disability Insurance
401(k) (Full-time employees are eligible to contribute immediately)
Employee Stock Ownership Program
Vacation and Holidays
In addition to the traditional benefits, we offer all our employees stock ownership through a profit sharing trust as part of our retirement savings package. NVR has had the highest Earnings Per Share growth rate in the homebuilding industry for the past 10 years, so as we grow financially, so do you.
We are an Equal Opportunity Employer.
Drug Testing and Credit Check are required.
Applicants must be legally entitled to work in the United States, as NVR does not provide visa sponsorships.","$71,504 /yr (est.)",5001 to 10000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Construction,1948,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Austin, TX",Senior Data Engineer (Snowflake),"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 230574@accuick.com
Job Title: Senior Data Engineer (Snowflake)
Location: Hybrid in Austin, TX 78759 (1-2 Day per week)
Job Description
Want someone who can have experiences and opinions around best practices and core philosophies pertaining to an enterprise level data platform that involves snowflake at its core.
Must be able to bringing opinions and experiences to the table.
Not looking for someone to just implement things that have been figured out for them and spoon fed.
Designs, builds and oversees deployment and operation of AWS Cloud solutions to capture, manage, store and utilize structured and unstructured data from multiple client data sources.
Utilizing Snowflake establishes and builds data structures based on business and technical requirements to meet analysis, reporting and analytical needs across client, all while ensuring integrity of the data.
Provides Data Engineering support for areas such as Finance, Sales, Business Intelligence, Product Development and/or other business users.
Works with data consumers and Project Managers to determine logical and physical database designs for analytics models.
Creates and maintains optimal data pipeline architectures.
Ensures architectures are aligned with and support business requirements.
Ensures that required data is available, can be trusted and is readily accessible by those who need it.
Influences the data infrastructure roadmap.
Identifies, designs and implements internal data management process improvements.
Plays a key role in application development projects to evolve the companys database architecture and design.
Works with internal and external data providers on data validation, providing feedback and making customized changes to data feeds and data mappings for analytical and operational use.
Automates manual processes, transforming them into repeatable capabilities.
Works with fellow team members to ensure design, development and execution align with and support adjacencies and adhere to established architectural standards.
What we will require from you:
Bachelors degree in Computer Science or related field plus 4+ years of relevant work experience; or a Master's degree plus 2+ years of relevant work experience; or a PhD plus 0-1 years of relevant experience.
In lieu of a degree, qualified candidates would require 8+ years of relevant professional experience.
Excellent with SQL.
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages.
Excellent understanding of patterns for data ingest into data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, star.
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse.
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.
Experience utilizing reporting and data insights tools.
Experience in supporting analytics teams data needs, in addition to customer and business reporting.
Target Years of Exp:
Ideally 8+ in Data Engineering
Top 5 Must Haves:
Excellent with SQL.
Excellent programming skills in Python and ideally demonstrating an aptitude via experience with multiple languages.
Excellent understanding of patterns for data ingest into data warehouse, ingest, cleansing, standardizing, etc., in addition to different data structures like normalized, denormalized, star.
Excellent experience supporting Snowflake Data Warehouse, including Snowpipe (including streams), tasks, transformations, views, dynamic tables. This should include advanced skills in ensuring efficient utilization of Snowflake compute and the ability to optimize workloads and warehouse.
Broad experience with Cloud PaaS capabilities, ideally AWS CloudWatch, Lambda, Step Functions, SNS/SQS, DynamoDB, etc.

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$92,211 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"BNY Mellon
3.6",3.6,Florida,Data Engineer- Big Data,"Overview
Big Data Data Engineer
Bring your ideas. Make history.
BNY Mellon offers an exciting array of future-forward careers at the intersection of business, finance, and technology. We are one of the world's top asset management and banking firms that manages trillions of dollars in assets, custody and/or administration. Known as the “bank of banks” - 97% of the world’s top banks work with us as we lead and serve our customers into the new era of digital.
With over 238 years of rich history and industry firsts, BNY Mellon has been built upon our proven ability to evolve, lead, and drive new ideas at every turn. Today, we’re approximately 50,000 employees across 35 countries with a culture that empowers you to grow, take risks, experiment and be yourself. This is what #LifeAtBNYMellon is all about.
We’re seeking a future team member in the role of Big Data Data Engineer to join our Asset Servicing team. This role is in Pittsburgh, PA HYBRID.
UCM is bank new client master data platform. It is golden source of truth about our clients and their accounts. As an enterprise level platform, API is one of the channels that multiple applications across multiple line of businesses use to get client data relevant for their application use. The data is huge and data security and privacy is top priority while giving data to businesses.

The UCM platform technology team is looking for an experienced mid-level Java developer to assist with delivering value added secure APIs. The candidate will be a key developer who will be ultimately develop cloud ready APIs using Java 11, Spring Boot, Spring Framework, including Oracle and ElasticSearch data repository, and our internal cloud-based solution for containerization. The developer will design and development APIs as per industry standard RESTFul API.

In this role, you’ll make an impact in the following ways:
Strong analytical skills and ability to articulate ideas and design to a group of peers.
Solid Java 8/11 and Spring enterprise developer and matching SQL skills.
Ability to work with Oracle and be able to write complex SQLs.
Experience with Docker, GitLab CI/CI, Junit, Mockito, or other automated build and testing frameworks is also being sought.

To be successful in this role, we’re seeking the following:
3-5 years of experience in software development required.
Experience working in fast-paced environment.
Should have thorough knowledge of the software development cycle.
Must have experience developing RESTFul APIs in Java and SpringBoot.
Must have experience writing SQLs, Spring JDBC/JPA Repositories.
Should have experience writing quality Junit tests using Mockito.
Good to have knowledge on API security using OAuth2.
Good to have knowledge on Kafka, ElasticSearch, Redis or distributed caching.
At BNY Mellon, our inclusive culture speaks for itself. Here’s a few of our awards:
Fortune World’s Most Admired Companies & Top 20 for Diversity and Inclusion
Bloomberg’s Gender Equality Index (GEI)
Best Places to Work for Disability Inclusion , Disability: IN – 100% score
100 Best Workplaces for Innovators, Fast Company
Human Rights Campaign Foundation, 100% score Corporate Equality Index
CDP’s Climate Change ‘A List’

Our Benefits:
BNY Mellon offers highly competitive compensation, benefits, and wellbeing programs rooted in a strong culture of excellence and our pay-for-performance philosophy. We provide access to flexible global resources and tools for your life’s journey. Focus on your health, foster your personal resilience, and reach your financial goals as a valued member of our team, along with generous paid leaves that can support you and your family through moments that matter.
BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer - Underrepresented racial and ethnic groups/Females/Individuals with Disabilities/Protected Veterans.

REGULATIONS/REQUIREMENTSBachelor's degree in computer science engineering or a related discipline, or equivalent work experience required2-6 years of experience in software development required; experience in the securities or financial services industry is a plus; should have thorough knowledge of the software development cycle S/he must also have experience developing in backend environment Job holder must be knowledgeable about cross-platform interoperability (multiple platforms. NT, Intranet, etc.) , major tools in a toolkit for a specific platform and features of multiple toolkits. S/he must be experienced at resolving hardware, software, and communications malfunctions and understand the business impact of resolving complications.. BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer. Minorities/Females/Individuals with Disabilities/Protected Veterans. Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.

Employer Description:
For over 230 years, the people of BNY Mellon have been at the forefront of finance, expanding the financial markets while supporting investors throughout the investment lifecycle. BNY Mellon can act as a single point of contact for clients looking to create, trade, hold, manage, service, distribute or restructure investments and safeguards nearly one-fifth of the world's financial assets. BNY Mellon remains one of the safest, most trusted and admired companies. Every day our employees make their mark by helping clients better manage and service their financial assets around the world. Whether providing financial services for institutions, corporations or individual investors, clients count on the people of BNY Mellon across time zones and in 35 countries and more than 100 markets. It's the collective ambition, innovative thinking and exceptionally focused client service paired with a commitment to doing what is right that continues to set us apart. Make your mark: bnymellon.com/careers.

EEO Statement:
BNY Mellon is an Equal Employment Opportunity/Affirmative Action Employer. Minorities/Females/Individuals With Disabilities/Protected Veterans. Our ambition is to build the best global team – one that is representative and inclusive of the diverse talent, clients and communities we work with and serve – and to empower our team to do their best work. We support wellbeing and a balanced life, and offer a range of family-friendly, inclusive employment policies and employee forums.",#N/A,10000+ Employees,Company - Public,Financial Services,Investment & Asset Management,1784,$10+ billion (USD)
"Rivian
3.4",3.4,"Irvine, CA",Sr. Data Engineer,"About Rivian:
Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.

As a company, we constantly challenge what’s possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.
Role Summary:
In this position, you will contribute to the data engineering needs of Rivian's Product Development Organization. You will manage the back end data from enterprise engineering applications and non enterprise applications such as our internal engineering applications. Additionaly you will be responsible for preparing, analyzing and serving data as needed for our development tools that deliver insights to the Product Development Organization.

To deliver you must be a team player, technicaly capable and able to think critically. To excel at this position you will have to navigate technical IT discussions, Enterprise Technology platforms, data architecture, and and colaborate cross fucntionally. You will also have to stay up to speed on the latest tools and technology in the data engineering world.
Responsibilities:
Create Big Data Solutions with high volumes & variety of data from PLM and other engineering applications and machines.
Collaborate with other technology teams to implement a framework of tools and technologies to ingest high volume of data to support engineering analytics, data science and machine learning use cases.
Solve complex analytical requirements using software engineering tools.
Support and utilize tools and technologies to provide data governance – data catalog and lineage.
Create data applications with ability to do searches, real time data alerts, APIs to pull the data on a large volume of data.
Build data applications to provide real-time data alerts & high throughput analytics
Qualifications:
Bachelors/Masters in data science, computer science, engineering, mathematics, or a related technical discipline preferred
Strong communication and leadership & collaboration skills.
Prior experience with PLM and handling product data management (PDM) in high volume manufacturing environment.
Passion for software & data engineering, pioneering data technologies and architecture. Ability to understand complex business problems and provide software solutions.
3+ years of experience in building petabyte scale data platforms and Big Data architecture using AWS services & open-source technologies.
Extensive hands-on experience in using AWS & open-source services like Glue, Spark Kinesis/Kafka, S3, Athena, Sagemaker
Hands-on experience in one or more programming languages like Python, Java, Scala.
Real-life production experience in creating architectural framework and tools for Data Science teams to build, train & scale machine learning models.
Strong hands-on experience with NOSQL, Columnar and Relational databases.
Understanding of data catalog solutions like Alation, Collibra, Atlas
Experience in building CI/CD framework for the data teams
Experience with infrastructure as code
Pay Disclosure:
Salary Range California-Based Applicants: $150,000 -$173,000 (actual compensation will be determined based on experience, and other factors permitted by law).
Company Statements:
Equal Opportunity
Rivian is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, ancestry, sex, sexual orientation, gender, gender expression, gender identity, genetic information or characteristics, physical or mental disability, marital/domestic partner status, age, military/veteran status, medical condition, or any other characteristic protected by law.

Rivian is committed to ensuring that our hiring process is accessible for persons with disabilities. If you have a disability or limitation, such as those covered by the Americans with Disabilities Act, that requires accommodations to assist you in the search and application process, please email us at candidateaccommodations@rivian.com.
Candidate Data Privacy
Rivian may collect, use and disclose your personal information or personal data (within the meaning of the applicable data protection laws) when you apply for employment and/or participate in our recruitment processes (“Candidate Personal Data”). This data includes contact, demographic, communications, educational, professional, employment, social media/website, network/device, recruiting system usage/interaction, security and preference information. Rivian may use your Candidate Personal Data for the purposes of (i) tracking interactions with our recruiting system; (ii) carrying out, analyzing and improving our application and recruitment process, including assessing you and your application and conducting employment, background and reference checks; (iii) establishing an employment relationship or entering into an employment contract with you; (iv) complying with our legal, regulatory and corporate governance obligations; (v) recordkeeping; (vi) ensuring network and information security and preventing fraud; and (vii) as otherwise required or permitted by applicable law.

Rivian may share your Candidate Personal Data with (i) internal personnel who have a need to know such information in order to perform their duties, including individuals on our People Team, Finance, Legal, and the team(s) with the position(s) for which you are applying; (ii) Rivian affiliates; and (iii) Rivian’s service providers, including providers of background checks, staffing services, and cloud services.

Rivian may transfer or store internationally your Candidate Personal Data, including to or in the United States, Canada, the United Kingdom, and the European Union and in the cloud, and this data may be subject to the laws and accessible to the courts, law enforcement and national security authorities of such jurisdictions.

Please note that we are currently not accepting applications from third party application services.","$103,502 /yr (est.)",5001 to 10000 Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2009,Unknown / Non-Applicable
"PG&E Corporation
4.0",4.0,"Oakland, CA",Expert Data Engineer,"Requisition ID # 150917

Job Category: Information Technology
Job Level: Individual Contributor
Business Unit: Information Technology
Work Type: Hybrid
Job Location: Oakland; Sacramento; San Francisco; San Jose; San Ramon

Department Summary

PG&E’s Information Technology (IT) organization is comprised of various unified departments which collaborate effectively to deliver high quality technology solutions.

The IT Data, Analytics, & Insights organization is an enterprise team that is responsible for working collaboratively across various lines of business (e.g., , Gas Operations, Electric Operations, Safety, Energy Procurement, etc.) and is focused on unlocking the value of PG&E’s data to support the company’s Wildfire Safety Program and True North Strategy. As part of that focus, we focus on delivering data and AI/ML centric products to support these initiatives. Some of the products that are being delivered include Remote Inspections, AI Enabled Inspections, Vegetation Management through LiDAR capabilities, Transmission Line Asset Master, Electric Distribution Asset Master, Asset Risk Modeling, and a Cloud Native Foundational Platform.

A critical part of how we operate is to apply design thinking, work and observe the Agile development methodology, and co-location. Through these principles, we work as product teams to help deliver a valuable product to our business.

Position Summary

We are looking for an experienced and talented Data Engineer to join our growing team of analytics experts. You will have a unique opportunity to be at the forefront of the utility industry and gain a comprehensive view of the nation’s most advance smart grid! In this role, you will work as part of cross functional teams, including data scientists, other data engineers, technology experts, and subject matter experts to develop data driven solutions. Successful candidates will be responsible for building, expanding, and optimizing our data, data storage, and data pipeline. This individual will support team members and decision products to ensure that data delivery is reliable and optimized. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. It is the perfect role for someone who would like to continue to build upon their professional experience and help advance PG&E’s sustainability goals.

The role is hybrid working primarily from your remote office and the Oakland General Office, in-person, 1-2x monthly for collaboration or as business needs require.

PG&E is providing the salary range that the company in good faith believes it might pay for this position at the time of the job posting. This compensation range is specific to the locality of the job. The actual salary paid to an individual will be based on multiple factors, including, but not limited to, specific skills, education, licenses or certifications, experience, market value, geographic location, and internal equity. This job is also eligible to participate in PG&E’s discretionary incentive compensation programs.

A reasonable salary range is:

Bay Area Minimum: $128,000
Bay Area Maximum: $218,000

Job Responsibilities

Data Engineering:
Leads moderate to high complexity data engineering activities which have broad impact and require in-depth analysis to obtain desired results.
Design and build data pipelines required for optimal extraction, transformation, and loading of data using Pyspark.
Build analytics products that utilize the data pipelines to provide actionable insights.
Identifies, designs, and implements internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Resolves application programming analysis problems of broad scope within procedural guidelines.
Actively participates in agile/scrum ceremonies (stand ups, planning, retrospectives, etc.)
Promotes a continuous improvement mindset by engaging in after action reviews and sharing learnings.

Data System and Architecture Maturity:
Assesses performance of individual data pipeline and broader data systems, suggests and may implement changes as required to meet individual project or enterprise maturity objectives.
Evaluates end-to-end data system interaction to proactively identify any potential pitfalls of the total solution.
Works with the team to help develop best practices and scalable design patterns.
Helps other engineers/analysts on unusual or especially complex problems that cross multiple functional/technology areas. May require creative/non-standard approaches to solve problems that will have significant impact across the company.
Conceptualizes and generates infrastructure that allows big data to be accessed and analyzed with verified data quality and metadata is appropriately captured and catalogued.
Work with team leadership to continually improve data driven decision making at PG&E via demonstrations, mentoring, disseminating best practices, etc.

Qualifications

Minimum:
BA/BS in computer science, management information systems or related technical discipline or equivalent work experience
7 years of experience as a data engineer or in a similar role
Complete proficiency in Python and/or Pyspark
Strong SQL skills and experience working with large datasets and complex data structures in a data warehouse/data lake environment.
Experience creating reports, dashboards, and visualizations using commercial tools (Tableau, Power BI, or other BI tools)

Desired:
Experience with Palantir Foundry application development and data visualization tools
Databases – familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.
Git – knowledge of version control / collaboration workflows and best practices
Agile – familiarity with agile and iterative working methodology and rapid user feedback gathering concepts
UX design – knowledge of best practices and applications
Experience in Typescript (preferred) or Javascript
Data literacy – data analysis and statistical basics to ensure correctness in data aggregation and visualization
Experience leading development teams
Excellent problem-solving and analytical skills with a strong attention to detail","$142,802 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1905,$10+ billion (USD)
"USAA
3.4",3.4,"San Antonio, TX",Data Engineer II,"Why USAA?
At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation’s military, but we all share in the mission to give back to those who did. We’re working as one to build a great experience and make a real impact for our members.

We believe in our core values of honesty, integrity, loyalty and service. They’re what guides everything we do – from how we treat our members to how we treat each other. Come be a part of what makes us so special!
The Opportunity
The candidate selected for this position is going to get work with the CFO Data & Analytics Team in USAA’s Corporate technology office. They will work with modern data technologies in like snowflake, dbt , container-based API’s , python and Kafka to build data pipelines to enable business with developing and implementing financial models on inputs and also build reporting capabilities on the model outputs within the treasury space in CFO.
This Data Engineer II position is a hybrid work type and can be based in one of our following office locations: San Antonio, TX or Plano, TX. Hybrid roles help employees gain the best of both worlds – collaborating in-person in the office and working from home when needed to achieve focused results.
What you'll do:
Participates in the full life cycle of data engineering to include analysis, solution design, data pipeline engineering, testing, deployment, scheduling, and production support with guidance from senior team members.
Assists in the implementation of technical solutions for data reporting and analytic systems.
Assists with designing and writing test scripts to verify data integrity and application of functionality. Reviews functionality of existing test scripts for understanding.
Demonstrates familiarity with IT Change and Release Management best practices. Deploys data pipeline code with assistance from senior team members.
Participate in design and code review sessions.
Actively participates in Agile ceremonies such as daily standup, iteration planning, backlog grooming, and retrospective sessions.
Develops intermediate familiarity of data management best practices by participating in trainings, reviewing documentation, and reading code from existing solutions.
Demonstrates knowledge and understanding of business products and processes.
Assists senior team members in breaking down business features into technical stories and approaches.
Actively learns about new and emerging technologies in the data engineering space. Seeks to apply learnings in current and future projects.
Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.
What you have:
Bachelor’s degree; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree; OR Approved certification from CodeUp, Galvanize, VetFIT (Veterans for IT) or eFIT
2 years of data engineering, data analysis or software development experience implementing data solutions.
Working Experience in SQL and Relational Databases.
Strong analytical and problem-solving skills.
Basic understanding of cloud technologies and tools.
What sets you apart:
2+ years of working experience with Snowflake.
1+ years of container-based APIs using container frameworks like OpenShift, Docker, or Kubernetes
2+ years of Python and Unix shell/Batch scripting experience
1+ years of experience with Kafka streaming technologies
Working experience with Gradle, yml, GIT, GitHUB, GITLab, etc. around continuous integration and continuous delivery infrastructure
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
What we offer:
Compensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $71,490 - $136,690.
Employees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.
Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.
For more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.
Relocation assistance is not available for this position.
USAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",#N/A,10000+ Employees,Company - Private,Insurance,Insurance Carriers,1922,$25 to $100 million (USD)
"ServiceNow
4.4",4.4,"Waltham, MA",Sr Staff Data Platform Software Engineer,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

Team
As part of the AI Search team, you will be responsible for building the Next-Gen Search Experience for the ServiceNow platform powered by AI used by thousands of customers.
What you get to do in this role:
Design, and build innovative search capabilities with high scalability and quality.
Design and build innovative Cloud Automation capabilities with high scalability and quality.
Implement cutting edge search capabilities and technologies ranging from keyword search and
word/paragraph vectorization to knowledge graphs and ML.
Implement Cloud Automation capabilities with dev-ops and ServiceNow technologies.
Design and build tools, libraries, and frameworks with long term platform implications for high
modularity, extensibility, configurability, and maintainability.
Collaborate and work cross-functionally with other teams.
Design and deliver outstanding search experiences for our customers and developers.
To be successful in the role:
Passion for problem solving, software architecture, and development.
Experience with open-source technologies like Linux, Apache/Tomcat, and MySQL
Experience in one or more programming languages – Java, Python, JavaScript
Experience with relational databases or NoSQL Databases
Experience writing or using REST APIs
Experience with Cloud technologies
Adapt to changing Business and project priorities

WJ23

Qualifications
10+ years of software research and development experience
8+ years of Development experience in Java or JavaScript
Nice to have:
Experience with Search Technologies like Elastic Search, Lucene and Solr
Experience with container technologies like Docker, Kubernetes
Experience with Puppet, Ansible

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$144,232 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Ancestry
3.6",3.6,"San Francisco, CA","Data Engineer, DNA Science","About Ancestry:
When you join Ancestry, you join a human-centered company where every person’s story is important. Ancestry®, the global leader in family history, empowers journeys of personal discovery to enrich lives. With our unparalleled collection of more than 40 billion records, over 3 million subscribers and over 23 million people in our growing DNA network, customers can discover their family story and gain a new level of understanding about their lives. Over the past 40 years, we’ve built trusted relationships with millions of people who have chosen us as the platform for discovering, preserving and sharing the most important information about themselves and their families.

We are committed to our location flexible work approach, allowing you to choose to work in the nearest office, from your home, or a hybrid of both (subject to location restrictions and roles that are required to be in the office- see the full list of eligible US locations HERE). We will continue to hire and promote beyond the boundaries of our office locations, to enable broadened possibilities for employee diversity.

Together, we work every day to foster a work environment that's inclusive as well as diverse, and where our people can be themselves. Every idea and perspective is valued so that our products and services reflect the global and diverse clients we serve.

Ancestry encourages applications from minorities, women, the disabled, protected veterans and all other qualified applicants. Passionate about dedicating your work to enriching people’s lives? Join the curious.
We are looking for an experienced Data Engineer to join our DNA Science team. You will be responsible for the design, construction, and maintenance of our large-scale data systems and infrastructure. You'll work closely with our scientists, bioinformatics specialists, and product teams to ensure efficient and reliable data processing, enabling us to provide insightful and meaningful data to our customers.
Responsibilities
Design and implement complex, scalable big data architectures for our genomic and genealogical data.
Develop and maintain robust ETL pipelines to ensure efficient and reliable data flow.
Ensure data quality and implement measures for data integrity and security.
Collaborate with scientists and bioinformatics specialists to understand their data needs and implement systems to meet these needs.
Continually optimize our data systems for cost, performance, scalability, and security.
Stay up-to-date with industry trends and advancements in data engineering technologies and best practices.
Qualifications
Bachelor's degree in Computer Science, Information Systems, or a related field.
Minimum 3 years of experience in a Data Engineering or similar role.
Proficiency in big data technologies (e.g., Hadoop, Spark) and database systems (SQL and NoSQL).
Strong programming skills, preferably in Python.
Knowledge of data architecture principles, data modeling, and data warehousing.
Experience in the genomics or bioinformatics field.
Familiarity with AWS cloud computing platform.
Knowledge of machine learning and data science concepts.
Experience with data visualization tools.
#IND2
#LI-JE1
As a signatory of the ParityPledge in Support of Women and the ParityPledge in Support of People of Color, Ancestry values pay transparency and pay equity. We are pleased to share the base salary range for this position: $104,400 - $154,350 with eligibility for bonus, equity and comprehensive benefits including health, dental and vision. The actual salary will vary by geographic region and job experience. We will share detailed compensation data for a specific location during the recruiting process. Read more about our benefits HERE.

Note: Disclosure as required by sb19-085(8-5-20) and sb1162(1-1-23)

Additional Information:
Ancestry is an Equal Opportunity Employer that makes employment decisions without regard to race, color, religious creed, national origin, ancestry, sex, pregnancy, sexual orientation, gender, gender identity, gender expression, age, mental or physical disability, medical condition, military or veteran status, citizenship, marital status, genetic information, or any other characteristic protected by applicable law. In addition, Ancestry will provide reasonable accommodations for qualified individuals with disabilities.
All job offers are contingent on a background check screen that complies with applicable law. For San Francisco office candidates, pursuant to the San Francisco Fair Chance Ordinance, Ancestry will consider for employment qualified applicants with arrest and conviction records.
Ancestry is not accepting unsolicited assistance from search firms for this employment opportunity. All resumes submitted by search firms to any employee at Ancestry via-email, the Internet or in any form and/or method without a valid written search agreement in place for this position will be deemed the sole property of Ancestry. No fee will be paid in the event the candidate is hired by Ancestry as a result of the referral or through other means.","$129,375 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,1983,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Data Infrastructure Software Engineer, Machine Learning Platform and Technologies","Summary
Posted: May 16, 2023
Weekly Hours: 40
Role Number:200479379
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure.
Key Qualifications
5 years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Texas Children's Hospital
4.0",4.0,"Houston, TX",Data Operations Engineer,"We're looking for a Data Operations Engineer, someone who's ready to grow with our company. In this position you will lead integrated, complex projects and manage the on-going build and maintenance of data marts and reporting visualizations. You will investigate processes to understand data, workflow and communication to meet end user needs within Texas Children's clinical departments, by working closely with the Information Services (IS) data and reporting team. Additionally, you will also provide systems support, communicate system updates, and provide other system support as needed to its assigned department.
Think you've got what it takes?
Job Duties & Responsibilities
Analyze and coordinate the designing of new & existing applications to support clinical business operations.
Create and refine data visualization tools to empower Operational users to more effectively utilize data in their daily practice management.
Coordinate new development and make sure it is consistent and well-integrated with existing information data structure.
Collaborate with TCH internal core stakeholders to identify data and analytics application systems and process needs.
Work with department to identify operational and business needs relating to department-specific reporting needs.
Act as liaison between department(s) and the TCH Information Services (IS) data and analytics team to troubleshoot and provide immediate support to end users.
Analyze system problems and modifications and manage data integrity.
Analyze clinical & business use of existing systems to identify problems to be resolved and define system applications or process improvements.
Recommend modifications to application design or current procedures to maximize advantages of existing resources.
Communicate/Collaborate with IS Data and Analytics team to manage testing and approval of updates/upgrades and modifications.
Work with the appropriate department(s) to review functionality in test environment before migration of updates/upgrades and modifications to production environment, in partnership with the IS data and analytics team.
Develop new processes to address identified needs and assure completion of new processes.
Facilitate improvements and actively seek ways to use technology to improve productivity and business processes.
Skills & Requirements
Being fully vaccinated against COVID-19, including any booster dose(s) of the COVID-19 vaccine recommended by the Centers for Disease Control when eligible, is required for all employees unless approved for a medical or religious exemption.
Bachelor's Degree Computer In Science, Business Administration, Healthcare Administration, Business Or Technology Field Required
Master's Degree In Computer Science, Business Administration, Healthcare Administration, Business Or Technology Field Preferred
5 Years Experience In Information Systems Management, Physician Practice Management, And/Or Other Related Operational Or Clinical Field RequiredSince 1954, Texas Children's has been leading the charge in patient care, education and research to accelerate health care for children and women around the world. When you love what you do, it truly shows in the smiles of our patient families, employees and our numerous accolades such as being consistently ranked as the best children's hospital in Texas, and among the top in the nation by U.S.News & World Report as well as recognition from Houston Business Journal as one of this city's Best Places to Work for ten consecutive years.
Texas Children's comprehensive health care network includes our primary hospital in the Texas Medical Center with expertise in over 40 pediatric subspecialties; the Jan and Dan Duncan Neurological Research Institute (NRI); the Feigin Center for pediatric research; Texas Children's Pavilion for Women, a comprehensive obstetrics/gynecology facility focusing on high-risk births; Texas Children's Hospital West Campus, a community hospital in suburban West Houston; and Texas Children's Hospital The Woodlands, the first hospital devoted to children's care for communities north of Houston. We have also created the nation's first HMO for children, established the largest pediatric primary care network in the country and a global health program that is channeling care to children and women all over the world. Texas Children's Hospital is also academically affiliated with Baylor College of Medicine, one of the largest, most diverse and successful pediatric programs in the nation.
To join our community of 14,000+ dedicated team members, visit texaschildrenspeople.org for career opportunities. You can also learn more about our amazing culture at infinitepassion.org .
Texas Children's is proud to be an equal opportunity employer. All applicants and employees are considered and evaluated for positions at Texas Children's without regard to mental or physical disability, race, color, religion, gender, national origin, age, genetic information, military or veteran status, sexual orientation, gender identity, marital status or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.","$80,757 /yr (est.)",10000+ Employees,Nonprofit Organization,Healthcare,Health Care Services & Hospitals,1954,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Raleigh, NC",Software Development Engineer [DEPT: WPC-Analytics/Data Science AP],"Summary
Posted: Aug 14, 2023
Weekly Hours: 40
Role Number:200496347
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 2 years of experience in the job offered or related occupation. Alternatively, employer will accept a Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 5 years of progressive, post-baccalaureate experience in the job offered or related occupation.
1 year of experience with each of the following skills is required:
ETL, BI and Data analytics
Apache Hadoop, Apache Hive, Apache Sqoop or Apache Spark
Extract data and implement data pipelines & SQL friendly data structures
Apache AVRO, Apache Parquet and common methods in data transformation
Dependency driven job schedulers
Teradata or ANSI SQL
Description
Multiple positions available in Cary, North Carolina. Translate business requirements by business team into data and engineering specifications. Build scalable data sets based on engineering specifications from the available raw data. Work with engineering and business partners to define and implement the data engagement relationships required with partners. Understand and Identify server APIs that needs to be instrumented for data analytics and reporting and align the server events for execution in already established data pipelines. Analyze complex data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reporting. Process, clean and validate the integrity of data used for analysis. Develop Python and Shell Scripts for data ingestion from external data sources for business insights. Work hand in hand with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. Mentor a team of hardworking engineers. 40 hours/week.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"Disney Media & Entertainment Distribution
3.9",3.9,"Santa Monica, CA",Sr Data Engineer,"The Ad Platforms organization within Disney Entertainment and ESPN Technology is fully responsible for building, enhancing and maintaining the high-performance, distributed, microservice-based Advertising Platform across all of Disney online properties, including Hulu and ESPN+. We build and maintain proprietary technology, ranging from ad serving and ad delivery, campaign management, reporting as well as all the integrations internal and external that come with evolving and maintaining a best-in-class video advertising business.
The Ad Intelligence team is under Ad Platforms and its mission is to transform advertising and Disney's Ad platform with data and AI across TV and streaming video. We build solutions to measure and optimize every aspect of the advertising life cycle. Our tenant is a strong cross-domain team to deliver E2E solutions covering tech areas ranging from machine learning, big data, microservices to data visualization. Our team is seeking a senior data engineer who will be a core team member for our advertising data platform engineering group. This engineering group focuses on BI solutions for Disney’s Addressable Sales, revenue and business operations teams. The right person for this role should have experience with big data pipelines, analytics and reporting services. If you are proactive, hardworking, and enthusiastic in these domains, this is a phenomenal role for you!
WHAT YOU’LL DO
Expansion of the Ads BI ecosystem, including reporting platform design, reporting development and pipeline development.
Design and Develop reports and visualizations
Enable data modeling, analysis, and data mining to uncover trends and actionable insights
Partner with product analysts and analytics stakeholders to provide ongoing reporting and analysis of business KPIs/metrics to inform and support business, product, and marketing decisions, including ad loads and programmatic yield optimization.
Create operational dashboards to facilitate data self-service for stakeholders
In partnership with product, evangelize data accessibility and educate end users on how to interpret data
Optimize reporting performance and, in partnership with the data governance team, ensure data quality and protect sensitive data.
Partner with internal teams to improve processes and standardize best practices (such as data modeling, documentation, automation)
WHAT TO BRING
Bachelor or above in computer science or statistics
At least 5+ years of experience in data engineering and 2+ years of experience in reporting development
Proficiency with data visualization tools such as Tableau, Looker, Microstrategy
Strong analytical and technical skills with the ability to apply business strategy to data analysis and communicate impact with stakeholders
Experience translating complex reporting needs into technical specifications
Rich experiences in the design and development of large BI projects
Proficiency in at least one DML programming language - Java, Scala, Python
Experience in AWS Big Data technologies including S3.
Passion for technology, and openness to interdisciplinary work
Willingness to go above and beyond to provide insights that drive positive experiences for our viewers and revenue for our businesses.
NICE-TO-HAVES
Experience in digital video advertising or digital marketing domain
Big data system design experience
Data processing experience with Spark (batch), Flink (streaming)
Job orchestration experience with Airflow and Nifi
Analytics DB experience with Snowflake.
Working with streaming event queues such as Kinesis, Kafka, etc.
Experience with Distributed Relational Databases like Druid, Single Store, DynamoDB
Experience with Hadoop/HDFS in local data centers.

The hiring range for this position in Santa Monica, CA is $136,038 to $182,490 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$159,264 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"CBRE
4.0",4.0,"Van Nuys, CA",Union Data Center Engineer,"Posted
16-Aug-2023
Service line
GWS Segment
Role type
Full-time
Areas of Interest
Engineering/Maintenance
Location(s)
Van Nuys - California - United States of America
About the role
Applies sophisticated skills to perform preventive maintenance and corrective repair of buildings, industrial systems, vehicles, equipment and grounds. Working under limited supervision, monitors building system operations and performance. Uses several trade skills such plumbing, electrical, roofing, heating and cooling.
What you’ll do
Follows all applicable codes, regulations, governmental agency and Company directives related to building operations and work safety.
Inspects building systems including fire alarms, HVAC, and plumbing to ensure operation of equipment is within design capabilities and achieves environmental conditions prescribed by client.
Reviews assigned work orders. Estimates time and materials needed to complete repair. Orders vital materials and supplies to finish the tasks.
Maintains an energy management program to ensure measures are taken to operate all systems in the most efficient manner to keep operating costs at a minimum.
Maintains the building lighting system, including element and ballast repairs or replacements.
Responds quickly to emergency situations, summoning additional assistance as needed.
What you’ll need
High school diploma or GED and a minimum of four years of related experience or trade school training.
Data center, hospital or any critical environment experience is helpful
Universal CFC certification preferred. Additional certification in one or more of the following: electrical, mechanical, HVAC and refrigeration systems, process controls, mechanical power transmissions, painting, plumbing, carpentry or engine repair. Certifications/licenses as may be required by local or state jurisdictions.
Disclaimers
Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future
The pay range for this position is subject to an applicable Collective Bargaining Agreement. The negotiated rate for the Union Data Center Engineer position is $48.64 per hour. Please refer to the Collective Bargaining Agreement regarding pay scale.
CBRE is an equal opportunity employer that values diversity. We have a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law. We also provide reasonable accommodations, as needed, throughout the job application process. If you have a disability that inhibits your ability to apply for a position through our online application process, you may contact us via email at recruitingaccommodations@cbre.com or via telephone at +1 866 225 3099 (U.S.) and +1 866 388 4346 (Canada).
NOTE: Some, but not all, of our positions may have an additional requirement to comply with COVID-19 health and safety protocols, including COVID-19 vaccination proof and/or rigorous testing. If you have questions about the requirement(s) for this position, please inform your Recruiter.",$48.64 /hr (est.),10000+ Employees,Company - Public,Real Estate,Real Estate,1906,Unknown / Non-Applicable
"Discover Financial Services
3.9",3.9,"Riverwoods, IL",Senior Associate Data Engineer,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.

Job Description:
At Discover, be part of a culture where diversity, teamwork and collaboration reign. Join a company that is just as employee-focused as it is on its customers and is consistently awarded for both. We’re all about people, and our employees are why Discover is a great place to work. Be the reason we help millions of consumers build a brighter financial future and achieve yours along the way with a rewarding career.

The Senior Associate Data Engineer is responsible for designing, developing, maintaining , and testing data solutions for the product using the enterprise framework. This role will apply learned software delivery capabilities and have the desire to learn higher levels of craftmanship. Senior Associate Data Engineers contribute opinions to design decisions and actively participate in agile ceremonies. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Responsibilities

Independently executes a variety of data integration solutions, recognizes data related patterns, and solicits advice on potential approaches

Contributes opinions to design decisions and understands design tradeoffs

Develops skills in data warehouse tools, Cloud, agile and other technologies involved in data integration

Demonstrates and applies knowledge of:
Data Integration concepts and tools

DW Design concepts and Metadata documentation

Data Profiling tools

Data Security

Data Quality

Regularly contributes to team agile ceremonies and helps new engineers with onboarding

Troubleshoots production issues and defects

Identifies and executes test scenarios and shares test results

Participates in the on-call rotation for support

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field

1 + years of experience in Data Platform Administration/Engineering

Internal applicants only: technical proficiency rating of advanced beginner on the Dreyfus engineering scale
Preferred Qualifications

If we had our say, we’d also look for:
Experience in supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)

ETL/ELT Tools ( AbInitio , DataStage, Informatica)

Experience working with relational or no-SQL databases, Cloud Tools

Other programming languages (Unix scripting, Python, etc.)

Knowledge of cloud platforms (AWS, GCP, Azure)

Basic knowledge of DevOps CI/CD framework, Open-Source concepts, key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs

External applicants will be required to perform a technical interview.

Compensation: The base pay for this position generally ranges between $70,000.00 to $118,400.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$94,200 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"Ascendion
4.3",4.3,"Saint Louis, MO",Product Data Management Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:

Job Title: Product Data Mgmt Engr

Key Responsibilities:
Job Description:
Collaborates with teams in the development, analysis, management and compliance verification of process and product baselines of complex products.
Defines, plans, coordinates and conducts product and subsystem level technical design reviews and audits for new and derivative products.
Analyzes complex product trades and/or changes and develops technically complete change proposals.
Contributes to the development and implementation of Configuration and Data Management standards, processes and tools.
Defines and allocates Configuration and Data Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Coordinates the integration of product elements and analyzes & resolves issues with engineering product structure.
Develops, integrates and implements engineering technical program plans including impacts, risks and incorporation of lessons learned spanning multiple engineering functions.

Location: St. Louis, MO

Salary Range: The salary for this position is between $99,000 – $1,12,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
Preferred Skills:
Data Mangement
Configuration
Job details
Job ID
328163
Job Requirements
Product Data Management Engineer
Location
St. Louis, Missouri, US
Recruiter
Ashok
Email
ashok.kundu@ascendion.com","$96,323 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Hashmap
3.4",3.4,"Mexico, MO",Data Engineer,"NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.
We are currently seeking a Data Engineer to join our team in Remote, Guanajuato (MX-GUA), Mexico (MX).
Data Engineer
(Remote position in Mexico)
Responsibilities:
Implement data engineering pipelines on Enterprise Data Hub
Review solution design and ensure that the defined data engineering standards are followed.
Review and validate logical and physical design to ensure alignment with the defined solution architecture.
Create/review technical documentation for all new and modified objects.
Ensure quality assurance plans and cases are comprehensive to validate the solution thoroughly.
Support QA, UAT and performance testing phases of the development cycle.
Understand and incorporate required security framework in the developed ETL and ELT objects.
Evaluate, determine root cause and resolve production issues.
Work closely with other IT development groups to deliver coordinated software solutions.
Required Qualifications
Deep understanding of data warehousing concepts, relational star-schema database designs and big data platforms and associated tools.
Experience and understanding of Python, Snowflake, Airflow and AWS ecosystems.
Deep and strong knowledge of SQL and relational database models.
Experience working in an agile environment is required, must have a clear understanding of the role and responsibility of a Scrum Master.
Nice to have Qualifications (Not Mandatory)
Bachelor’s degree in computer science, MIS, or related discipline, with 5+ years related information systems experience in Data Warehousing and delivery of BI solutions.
Hands-on experience with creating Unix shell scripts.
Hands-on experience in data modeling
Excellent team player able to work with virtual and global across functional teams at all levels.
Excellent spoken and written communication as well as receptive listening skills, with ability to present complex ideas in a clear, concise fashion to technical and nontechnical audiences.
#LIT-LATAM
About NTT DATA Services
NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients’ long-term success. Visit nttdata.com or LinkedIn to learn more.
NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.","$91,506 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1967,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Sr Machine Learning Engineer, Data & ML Innovation","Summary
Posted: May 17, 2023
Role Number:200464615
Do you want to innovate at the intersection of Machine Learning and Data to make Apple products smarter for our users? The Data and Machine Learning Innovation team is looking deeply into the end-to-end lifecycle of ML product development, and finding innovative ways to make it scalable and efficient. We are a R&D team with strong expertise in Applied Machine Learning, Data Engineering and Distributed Infrastructure. The team works broadly with Machine Learning teams across the company to advance capabilities in the data centric machine learning world. As part of our team, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional, and you will collaborate very closely with various highly skilled machine learning and software development teams developing groundbreaking solutions!
Key Qualifications
10+ years of technical leadership experience.
Excellent knowledge and experienced practical skills in major machine learning algorithms.
Extensive knowledge in design and development of large scale distributed and big data processing systems.
Mastery of one of following languages: Python, Java or C++, demonstrating strong background in algorithms and data structures.
Excellent interpersonal skills, ability to work independently as well as in a team.
Creativity and curiosity for solving highly complex problems.
Excellent data analytical skills.
Description
As a member of our fast-paced group you’ll have the unique and rewarding opportunity to shape upcoming products from Apple. Our team includes a diversity of background engineers focusing on making ML development lifecycle scalable and efficient. As such we are looking for candidates with both strong applied machine learning experiences and engineering skills.
Education & Experience
MS or Ph.D in Computer Science, Machine Learning or related field. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $242,700 and $364,100, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"JLL
3.9",3.9,"Phoenix, AZ",Data Center Lead Engineer,"JLL supports the Whole You, personally and professionally.

Our people at JLL are shaping the future of real estate for a better world by combining world class services, advisory and technology to our clients. We are committed to hiring the best, most talented people in our industry; and we support them through professional growth, flexibility, and personalized benefits to manage life in and outside of work. Whether you’ve got deep experience in commercial real estate, skilled trades, and technology, or you’re looking to apply your relevant experience to a new industry, we empower you to shape a brighter way forward so you can thrive professionally and personally.

Job Description
Data Center Lead Operating Engineer

Overview: This is an exciting opportunity to join a world class facility team conducting data center maintenance and operations for a well-established yet fast growing financial services company. This position reports to the data center Chief Engineer and supervises one shift of a 24x7 team of operating engineers supporting a client’s data center.

Roles and Responsibilities:
This position supervises the first shift team of operating engineers in the data center environment. As a lead operating engineer, you will direct rounds, perform tests, and analyze data to ensure the proper functioning of data center equipment. You will be responsible for monitoring operation of the mechanical/electrical operating systems - with the goal of maintaining continuous availability and avoiding unplanned outages. Other responsibilities may include:
Performance of preventative maintenance on data center critical system equipment and associated buildings;
Oversee or participate in major repairs and maintenance of data center systems and equipment;
Routine and ongoing assessments of building operations;
Monitoring the operations of the data center environment and associated buildings – making adjustments to refrigeration, heat exchangers, HVAC, electrical, and emergency backup systems;
Monitoring the operations, adjusting, and maintaining Central Plant, chilled water, and air conditioning equipment, ventilating and hot water heaters, pumps, valves, piping and filters;
Installation, repair, and maintenance of critical data center electrical equipment and controls;
Installation, repair, and maintenance of plumbing, piping and associated equipment and components;
Installation, repair, and maintenance of mechanical operating equipment and machinery;
Reviews and/or performs rounds, and analyzes data to ensure proper functioning of data center equipment;
Record and analyze readings and adjust where necessary to ensure proper operation of support equipment;
Analyze the operations of various systems, determine the cause of any problems/malfunctions, and take corrective action as required;
Perform preventive maintenance on all data center critical system equipment, and complete preventive task sheets and other required documentation;
Assign, manage and verify work orders and other work using CMMS (Corrigo), with accuracy and good documentation;
Develop operating procedures (SOPs, MOPs, EOPs) and oversee implementation of critical scheduled activity according to documented procedures;
Mentor data center operating engineers on electrical and mechanical systems, critical paths, and best practices;
Install and repair plumbing/piping/tubing; wire single and three phase motors (single & two speed); pull wiring to machinery, motors, operating parts, etc.; install and rebuild pumps and motors; install and rebuild air compressors; heat exchangers; replace bearings in all types of motors; replace seals on pumps; install and repair piping, valves, filters, and associated controls;
Install, repair, and maintain electrical controls, switching and motor controls;
Comply with departmental policy for the safe storage, use, and disposal of hazardous materials;
Maintain tools and order supplies as required for the support of equipment;
Perform other duties as assigned;

MINIMUM REQUIREMENTS, EXPERIENCE, and COMPETENCIES
High School diploma or equivalent;
Completion of apprentice program or two years of related trade schooling (or military experience) is desirable;
Minimum of four years of experience in an electrical trade, HVAC/refrigeration or a related field;
Minimum of four years of experience in emergency backup systems (Generators, UPS, etc.)
Practiced in the use of tools and machinery related to data center and building operations;
Proficient with one-line drawings (critical path), blueprints, schematics, technical manuals and procedures;
Excellent interpersonal skills; ability to communicate well in both oral and written communications;
Proficient with computer equipment and Microsoft Office software;
Will be required to complete ongoing certification/training programs with passing score(s);
Internal candidates must have consistently received a “meets expectations”
If this job description resonates with you, we encourage you to apply even if you don’t meet all of the requirements below. We’re interested in getting to know you and what you bring to the table!

Personalized benefits that support personal well-being and growth:

JLL recognizes the impact that the workplace can have on your wellness, so we offer a supportive culture and comprehensive benefits package that prioritizes mental, physical and emotional health.

About JLL –

We’re JLL—a leading professional services and investment management firm specializing in real estate. We have operations in over 80 countries and a workforce of over 102,000 individuals around the world who help real estate owners, occupiers and investors achieve their business ambitions. As a global Fortune 500 company, we also have an inherent responsibility to drive sustainability and corporate social responsibility. That’s why we’re committed to our purpose to shape the future of real estate for a better world. We’re using the most advanced technology to create rewarding opportunities, amazing spaces and sustainable real estate solutions for our clients, our people, and our communities.

Our core values of teamwork, ethics and excellence are also fundamental to everything we do and we’re honored to be recognized with awards for our success by organizations both globally and locally.

Creating a diverse and inclusive culture where we all feel welcomed, valued and empowered to achieve our full potential is important to who we are today and where we’re headed in the future. And we know that unique backgrounds, experiences and perspectives help us think bigger, spark innovation and succeed together.","$97,001 /yr (est.)",10000+ Employees,Company - Public,Real Estate,Real Estate,#N/A,$5 to $10 billion (USD)
"The Hartford
3.9",3.9,"Hartford, CT",Staff Data Platform Engineer (Business Intelligence) - HYBRID,"You are a driven and motivated problem solver ready to pursue meaningful work. You strive to make an impact every day & not only at work, but in your personal life and community too. If that sounds like you, then you've landed in the right place.
The Hartford’s Enterprise Data Office - Analytics Enablement Services team is seeking a Data Platform Engineer - Business Intelligence to work closely with business and technical partners across the enterprise to enable the implementation of end-to-end business intelligence solutions, with a primary focus on ThoughtSpot. In this full-time position, the candidate will help drive community engagement, train users, provide technical support, assist with Proof-of-Concept evaluations using modern self-service business intelligence and data consumption tools, and act as a business intelligence subject matter expert.

This role will provide the opportunity to research, learn, and master the business intelligence tools used at The Hartford, while engaging with various members of the technical and business communities. As part of a team that conducts evaluations and implementations of new data tools, the candidate will have exposure to cutting-edge cloud-based technology in the business intelligence, analytics, and data consumption spaces.
Analytics Enablement Services is an Agile team providing support for over 10,000 business users and thirty development teams across the enterprise. We are a lean, optimized team of data professionals working together to help The Hartford realize the value of data.

The ideal candidate will have strong customer service skills, technical aptitude, natural curiosity, a willingness to learn and work towards making technical concepts understandable to business users.

The candidate will need to think critically to tackle complex challenges, thrive in a fast-paced, dynamic environment and help drive a culture of delivering actionable data insights rapidly in a self-service manner.

Responsibilities:
Provide resident ‘super user’ BI&A tool expertise
Perform application administrative tasks, such as managing security, access, data connectivity, etc.
Train and advise developers, analysts, and business users with ThoughtSpot dashboard development and best practices
Utilize data platforms including Tableau, Tableau Prep, Dataiku, Dremio, and others
Assist with community engagement activities
Consult with business customers to develop strategies and governance practices that help move the business forward
Create and maintain enterprise training materials for supported tools
Collaborate with internal support teams to continuously improve processes and procedures
Design, build, and maintain internal reports, processes, and analyses with a variety of business intelligence technologies
Partner with various members of the BI&A community to understand and document tool usage, total cost, pain points, and value achieved through modern BI processes and tools
Assist with new self-service tool Proofs of Concept and demonstrations for business partners
Assist with evaluation and implementation of new data tools
Evangelize modern BI execution and tool strategies to create a data driven culture
Perform other job-related duties as assigned
Minimum Qualifications:
2+ years of hands-on experience with business intelligence and analytics tools such as ThoughtSpot, Tableau, IBM Cognos, Microsoft Business Intelligence (SSIS, SSAS, SSRS, Power BI), SAS, BusinessObjects, R, R-Shiny, Python, etc.
Knowledge of data warehouse design and usage
Experience with data modelling and analysis concepts
Intermediate level SQL skills
Experience with Amazon Web Services
Training material creation and delivery
Strong verbal and written communication skills
Natural curiosity with a strong desire to learn, maintain, and apply knowledge of emerging BI&A tools, strategy, methodology, and general best practices
Strong team player that has a direct approach and is solution oriented
Comfortable working independently and collaboratively in an ambiguous environment on multiple concurrent projects
Highly analytical person with exceptional conceptual thinking skills equally comfortable coding and interacting with business partners
Outstanding verbal and written communication skills, with an ability to express complex technical concepts in business terms to effectively interface with all levels of management.
Entrepreneurial spirit – self-motivated, strong sense of ownership/accountability, and results oriented with the ability to manage time and schedules effectively
Customer focus - strive to give customers the best service and takes the initiative to add value
Preferred Qualifications:
Insurance industry experience
Experience working in Agile teams (Scrum / Kanban)
Amazon Web Services (AWS) certification
Compensation
The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:
$116,000 - $174,000
Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression/Religion/Age",#N/A,10000+ Employees,Company - Public,Insurance,Insurance Carriers,1810,$10+ billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
The position requires a Master’s degree in Computer Science, Engineering (any), or any technical/analytical field that is closely related to the specialty, plus one (1) year of experience in an IT/Computer-related position.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Raleigh, NC",Software Development Engineer [DEPT: WPC-Analytics/Data Science AP],"Summary
Posted: Aug 14, 2023
Weekly Hours: 40
Role Number:200496347
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 2 years of experience in the job offered or related occupation. Alternatively, employer will accept a Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 5 years of progressive, post-baccalaureate experience in the job offered or related occupation.
1 year of experience with each of the following skills is required:
ETL, BI and Data analytics
Apache Hadoop, Apache Hive, Apache Sqoop or Apache Spark
Extract data and implement data pipelines & SQL friendly data structures
Apache AVRO, Apache Parquet and common methods in data transformation
Dependency driven job schedulers
Teradata or ANSI SQL
Description
Multiple positions available in Cary, North Carolina. Translate business requirements by business team into data and engineering specifications. Build scalable data sets based on engineering specifications from the available raw data. Work with engineering and business partners to define and implement the data engagement relationships required with partners. Understand and Identify server APIs that needs to be instrumented for data analytics and reporting and align the server events for execution in already established data pipelines. Analyze complex data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reporting. Process, clean and validate the integrity of data used for analysis. Develop Python and Shell Scripts for data ingestion from external data sources for business insights. Work hand in hand with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. Mentor a team of hardworking engineers. 40 hours/week.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Analytica
3.4",3.4,Remote,Data Engineer,"Analytica is seeking a remote Data Engineer to support a high-profile financial regulatory client with developing data pipeline and ETL solutions in an AWS cloud environment.
Analytica has been recognized by Inc. Magazine as a fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.
Responsibilities include (but not limited to):
Develops tools and infrastructure for data processing use cases
Designs and builds data pipelines that ingest and transform data using programming languages such as Python and SQL, and data orchestration tools
Designs, builds, and maintains data storage and processing infrastructure that allows working nimbly through extensive amounts of analytics data
Build and deliver data lake, integrate with existing data catalog prototype, and migrate to big data applications from on-premise to the new computing platform by leveraging new technologies (such as Apache Spark)
Qualifications:
Bachelor's degree in information systems, computer science, engineering, finance, or related degree or functional discipline
At least three (3) years of experience building flexible and scalable ETL processes and data pipelines
Extensive experience developing in Python and SQL
Should be well organized, thorough, and able to handle competing priorities
Knowledge and experience with Agile, Scrum, and DevOps principles and practices
Experience in any big data technologies - Hadoop, Amazon Redshift, AWS DevOps, Azure CosmosDB, Azure Data Lake, AWS DynamoDB, or advanced analytics tools will be plus
VeDM6NPQva",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2009,$5 to $25 million (USD)
"NAVEX Global
3.5",3.5,"Charlotte, NC","Staff Software Engineer, Data","It's fun to work in a company where people truly BELIEVE in what they're doing!
We're committed to bringing passion and customer focus to the business.
Position Summary:
At NAVEX, you will help design and implement our NAVEX One data platform part of our newest engineering team. Our Product Engineering team shares a passion for designing quality solutions, embracing new technologies and delivering powerful products that help our customers protect their reputation and bottom line.
As a Data Staff Software Engineer, you will influence technical designs and implement our new data platform. You will focus on quality implementation while guiding the other data engineers. You will help us build a data platform that will ingest other teams’ content and then provide application specific data sets. We are looking for a candidate who is strong in data engineering. In this role, you will have ample opportunity to explore new value-added capabilities, invest in data development and tool research, mentor software developers and grow your career all while balancing your life priorities.
We Offer You:
An Inspiring Culture. Invested teammates, belonging groups, and a socially determined culture
Meaningful Work. Innovative products and solutions with real life impact for people and organizations
Career Growth. Stellar training and an unwavering commitment to your growth and success
Life Flexibility. Time to care for yourself, your loved ones, and your community
Industry Leadership. A highly reputable, fast growing and consistently profitable organization
Real Rewards. Competitive and transparent pay practices, wellbeing programs and benefits with choice
What You Will Do:
Work with a team of data engineers and be accountable for designs and high-quality deliveries as an individual contributor
Help team members grow by mentoring newer engineers
Participate in the innovative advancements of our product platform and collaborate with our awesome agile team members
Promote opportunities for refactoring and identify areas of optimization
Research and leverage commercial products, libraries, and tools that can be used to solve problems
Participate in design sessions with other engineers, architects, and product managers, providing constructive and honest feedback during sprint retrospectives with a team mindset
Use automation, including continuous integration, automated deployments, and automated unit and functional testing
What You Will Need:
A Bachelor’s degree in Computer Science or be good enough that we won’t notice through equivalent prior work-related experience
5+ years’ experience in an Agile, full-stack software development environment with a focus on big data designs and implementations, ideally with SaaS and/or micro service-based systems
Expert knowledge of data management and pipeline systems, practices, and standards
Expert analytical and design skills, including the ability to abstract information requirements from real-world processes to understand information flows in computer systems
Expertise in the fields of data transformations (ELT, ETL), data quality, data cleansing, and data profiling using dbt Labs’ DBT
Expertise in Data Cataloging and Master Data Management concepts
Expertise in both SQL and NoSQL implementations; experience with Microsoft SQL Server, Snowflake, and Postgres database platforms
Experience with SQL profiling, performance tuning, and data ingestion into Data Warehouses
Strong problem solving and critical thinking skills with the ability to identify and influence others on the best solution
Ability to work well in a team environment and attitude to focus on team specific goals and objectives
Excellent verbal and written communication skills and a commitment to engage and collaborate with people across a variety of levels with diverse backgrounds
We believe each member of our team deserves to see a path forward to achieving their career and financial goals.
Each team member is required to have a career plan in place and reviewed with their manager after six months with our team.
The minimum starting pay range for this role is $110,000 per annum with 5% MBO.
Pay progression is based on performance.
Our pay programs are just one element of our commitment to Be the ONE place you want to thrive in life. Check out NAVEX’s career page to learn about our innovative people programs designed to create one powerful life experience for YOU!
NAVEX is an equal opportunity employer, including disability/vets.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
Job Type: Full-time
Benefits:
401(k)
Dental insurance
Health insurance
Paid time off
Vision insurance
Schedule:
Day shift
Monday to Friday
Experience:
Software Engineering: 5 years (Required)
Snowflake: 2 years (Required)
Work Location: Hybrid remote in Charlotte, NC 28277","$110,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Enterprise Software & Network Solutions,2012,$100 to $500 million (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Data Infrastructure Software Engineer, Machine Learning Platform and Technologies","Summary
Posted: May 16, 2023
Weekly Hours: 40
Role Number:200479379
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure.
Key Qualifications
5 years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
Tail Wind Informatics,#N/A,Minnesota,Data Engineer - Azure,"About Us:
Tail Wind is an IT Consulting Services company—Microsoft Solutions Partner—that delivers Data Architecture and Business Intelligence solutions. We offer cloud and on-premise Data Architecture, ETL Development, Data Migration, Reporting and Dashboard solutions. We’ve established an excellent reputation providing these services to awesome customers! We are building a talented crew of data savvy individuals for local and national projects in data. We offer excellent compensation (salary, bonus, benefits). Most importantly, our people have an incredible opportunity to build their skills in a team environment.

We are currently seeking candidates for our Data Engineer position to do the following:
Responsibilities
Using Data Science techniques to preform predictive modeling services.
Building data sets in data warehouses using SQL, Azure and Python.
Experience with Databricks or Snowflake
Work across multiple different teams and projects.
Requirements
3+ years experience using Azure Data Factory
Must have strong backend development skills with SQL Server and writing complex SQL queries
Strong understanding of predictive modeling
Working in a fast paced, deadline heavy environment
Benefits
401k + match
Health Insurance
Dental Insurance
Vision
Long-Term Disability Insurance
Life Insurance
The Tail Wind Team: A healthy work-life balance. We look for people that love what they do, want to learn, earn and enjoy life to the fullest.
Equal Opportunity Employer - No Agencies Please","$120,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"Elevance Health
3.7",3.7,Remote,Data Engineer Sr (contract),"Job ID: #JP00043626

Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. Previously known as Anthem, Inc., we have evolved into a company focused on whole health and updated our name to better reflect the direction the company is heading.

We are looking for contract workers (via BCforward) who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact?

Primary duties may include, but are not limited to:
Undertakes complex assignments requiring additional specialized technical knowledge.
Develops very complex and varied strategic report applications from a Data Warehouse.
Establishes and communicates common goal and direction for team.
Establishes and maintains advanced knowledge of data warehouse database design, data definitions, system capabilities, and data integrity issues.
Acts as a source of direction, training and guidance for less experienced staff.
Monitors project schedules and costs for own and other projects.
Develops and supports very complex Data Warehouse-related applications for business areas requiring design and implementation of database tables. Conducts training on use of applications developed.

Requirements:
Requires a BS/BA degree; 6 years experience; or any combination of education and experience, which would provide an equivalent background.
Expert level PC, spreadsheet, and database skills, as well as experience in standard Business Information tools and programming/query languages is also required.
Ability to communicate effectively with multiple levels within the organization.
This job is focused on spending time thinking about programming and how it would be used to design solutions as compared to the Bus Info Developer Consultant job
SQL, Visual Studio, VB, SSRS, Power BI, Tableau, SSIS

Additional Details:
40 hours/week centered around EST hours - flexible with shift times as long as they are available for meetings during EST (typically around 9am-3pm would be when our meetings would happen). Open to candidates anywhere in the US - 100% remote.
Possible Temp to hire

BCForward is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Privacy Notice for California Residents",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2004,$10+ billion (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Discover Financial Services
3.9",3.9,Illinois,Data Engineer - Abinitio,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.
Job Description: The Data Engineer is responsible designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community.
Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members
Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies
Demonstrates strong technical aptitude across data engineering practices:
Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting
Designing advanced SQL queries
Leveraging metadata-driven framework for solutions
Developing test scripts for unit and integration testing
Develops test methodologies for specific products
Leads code review sessions and other process and operational improvement initiatives
Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)
Works on holistic solutions, driving feature and story delivery (Agile)
Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline
Participates in the on-call rotation for support
Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities
Builds strong collaborative working relationship both within the team and cross-functionally

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field
3+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale

Preferred Qualifications

If we had our say, we’d also look for:
ETL/ELT Tools (AbInitio, DataStage, Informatica)
Cloud Tools and Databases (AWS, Snowflake)
Other programming languages (Unix scripting, Python, etc.)
Leverage CI/CD framework for data integration, Open Source
Experience working in cloud platforms (AWS, GCP, Azure)
Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs
Experience optimizing SQL both relational and nosql
External applicants will be required to perform a technical interview.

#LI-CM

Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$113,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"Starbucks
3.7",3.7,"Seattle, WA",data engineer sr,"Senior data engineer
Job Summary and Mission
This position contributes to Starbuck's success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing, and support for data pipelines and data products to enable continuous data processing for data exploration, data preparation, and real-time business analytics.
Summary of Key Responsibilities
Responsibilities and essential job functions include but are not limited to the following:
Demonstrate deep knowledge of the data engineering domain, including non-interactive (batch, distributed) & real-time, highly available data, data pipelines
Deep knowledge of data as a concept and the development of domain driven data products.
Optimization of data products to service customer personas, Data science, AI/ML and data visualization.
Knowledge of semantic data concepts.
Build fault-tolerant, self-healing, adaptive, and highly accurate data computational pipelines
Provide consultation and lead the implementation of complex programs
Develop and maintain documentation relating to all assigned systems and projects
Perform root cause analysis to identify permanent resolutions to software or business process issues
Basic Qualifications
Bachelor’s degree in computer science, management information systems, or related discipline, or equivalent work experience
MUST HAVE Technology skills (7/10 or higher):
Strong/expert Spark (PySpark) Using Jupyter Notebooks, Colab or DataBricks
Hands-on data pipeline development, ingest patterns in Azure
Orchestration tools, ADF or Airflow
SQL
Denormalized Data modeling for big data systems
MUST HAVE competencies:
Collaborative, able to work remotely, and still be an engaging team member.
Strong analytical and design skills.
Years
Architect and design large scale high performance distributed systems 7-10
SQL Platform 7-10
No-SQL Platform 3+
Spark 3+
Data platform implementation on Azure or AWS 3+
CI/CD experience 2+
Exposure to SOA architecture 2+

div>
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

We are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.

Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at applicantaccommodation@starbucks.com.","$128,868 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1971,$10+ billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
The position requires a Master’s degree in Computer Science, Engineering (any), or any technical/analytical field that is closely related to the specialty, plus one (1) year of experience in an IT/Computer-related position.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Data Infrastructure Software Engineer, Machine Learning Platform and Technologies","Summary
Posted: May 16, 2023
Weekly Hours: 40
Role Number:200479379
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure.
Key Qualifications
5 years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Apple
4.2",4.2,"Raleigh, NC",Software Development Engineer [DEPT: WPC-Analytics/Data Science AP],"Summary
Posted: Aug 14, 2023
Weekly Hours: 40
Role Number:200496347
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 2 years of experience in the job offered or related occupation. Alternatively, employer will accept a Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 5 years of progressive, post-baccalaureate experience in the job offered or related occupation.
1 year of experience with each of the following skills is required:
ETL, BI and Data analytics
Apache Hadoop, Apache Hive, Apache Sqoop or Apache Spark
Extract data and implement data pipelines & SQL friendly data structures
Apache AVRO, Apache Parquet and common methods in data transformation
Dependency driven job schedulers
Teradata or ANSI SQL
Description
Multiple positions available in Cary, North Carolina. Translate business requirements by business team into data and engineering specifications. Build scalable data sets based on engineering specifications from the available raw data. Work with engineering and business partners to define and implement the data engagement relationships required with partners. Understand and Identify server APIs that needs to be instrumented for data analytics and reporting and align the server events for execution in already established data pipelines. Analyze complex data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reporting. Process, clean and validate the integrity of data used for analysis. Develop Python and Shell Scripts for data ingestion from external data sources for business insights. Work hand in hand with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. Mentor a team of hardworking engineers. 40 hours/week.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"Capital One
4.1",4.1,"Plano, TX",Senior Data Engineer,"Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"Ascendion
4.3",4.3,"Saint Louis, MO",Product Data Management Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:

Job Title: Product Data Mgmt Engr

Key Responsibilities:
Job Description:
Collaborates with teams in the development, analysis, management and compliance verification of process and product baselines of complex products.
Defines, plans, coordinates and conducts product and subsystem level technical design reviews and audits for new and derivative products.
Analyzes complex product trades and/or changes and develops technically complete change proposals.
Contributes to the development and implementation of Configuration and Data Management standards, processes and tools.
Defines and allocates Configuration and Data Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Coordinates the integration of product elements and analyzes & resolves issues with engineering product structure.
Develops, integrates and implements engineering technical program plans including impacts, risks and incorporation of lessons learned spanning multiple engineering functions.

Location: St. Louis, MO

Salary Range: The salary for this position is between $99,000 – $1,12,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
Preferred Skills:
Data Mangement
Configuration
Job details
Job ID
328163
Job Requirements
Product Data Management Engineer
Location
St. Louis, Missouri, US
Recruiter
Ashok
Email
ashok.kundu@ascendion.com","$96,323 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Trissential
4.1",4.1,"Minneapolis, MN",Data Engineer,"Overview
Trissential is a trusted partner for end-to-end quality services and management consulting for digital transformation. As a part of our parent company, Expleo, we are a global organization partnering with major corporations and leading non-profits in over 30 countries. Guided by our mission and values, Trissential puts people at the heart of our organization.
Come join an experience! Add your talent to a team of forward-thinking game changers that make an impact by driving innovative solutions.
Trissential is currently seeking a Data Engineer to join our dynamic team in Minneapolis, MN (Remote).
Responsibilities
Position Summary:
A Data Engineer is a professional responsible for designing, building, and maintaining the client’s data infrastructure that supports data-centric operations, and decision-making.
The Data Engineer is responsible for creating and maintaining data pipelines, data storage systems, and data processing systems, as well as ensuring data is accurate, secure, and easily accessible.
Primary Responsibilities and Accountabilities:
Data pipeline and workflow development: This includes designing and implementing client data pipelines and workflows to ensure that data is being collected, processed, and stored in an efficient and timely manner. Understand and incorporate data quality principals that ensure optimal performance, impact, and user experience.
Data storage and processing: This includes designing and implementing data storage systems and developing and maintaining code to process and analyze data.
Data integration: This includes working with the client on designing data integration strategies, integrating data from multiple sources, and ensuring data quality.
Data security: This includes defining and implementing client data security policies and procedures, including access control and data encryption.
Data governance: This includes defining data governance policies and procedures, monitoring data quality, and ensuring compliance with data privacy regulations.
Performance tuning: This includes optimizing data access, indexing, and query performance to ensure the data infrastructure can scale as required.
Monitoring and troubleshooting: This includes monitoring data systems and troubleshooting any issues that arise, identifying and resolving performance bottlenecks, and working with other team members to resolve any problems.
Collaboration and Communication: This includes working closely with client’s Data Architects, Data Analysts, Business Intelligence and Data Science team members, and other stakeholders to understand their data needs and develop solutions that meet those needs while adhering to industry best practices.
Qualifications
Extensive experience in ETL, preferably with transitioning from legacy systems to more advanced ones.
Strong data analysis skills, with the ability to identify areas of improvement in the current process.
In-depth knowledge of automation strategy development and implementation.
Ability to work in an advisory capacity, providing insights and recommendations to improve data management capabilities.
Excellent problem-solving skills to identify potential errors and propose solutions to enhance efficiency.
Skills
Works independently or well within a team
Wants to continuously grow knowledge base and skill set
Collaborative, consultative mindset
Works well in a fast paced environment
Strong technical background
Deep knowledge and curiosity about technology and systems
Agile mindset
Job Type: Contract
Work Location: Remote","$95,769 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2003,$25 to $100 million (USD)
"Analytica
3.4",3.4,Remote,Data Engineer,"Analytica is seeking a remote Data Engineer to support a high-profile financial regulatory client with developing data pipeline and ETL solutions in an AWS cloud environment.
Analytica has been recognized by Inc. Magazine as a fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.
Responsibilities include (but not limited to):
Develops tools and infrastructure for data processing use cases
Designs and builds data pipelines that ingest and transform data using programming languages such as Python and SQL, and data orchestration tools
Designs, builds, and maintains data storage and processing infrastructure that allows working nimbly through extensive amounts of analytics data
Build and deliver data lake, integrate with existing data catalog prototype, and migrate to big data applications from on-premise to the new computing platform by leveraging new technologies (such as Apache Spark)
Qualifications:
Bachelor's degree in information systems, computer science, engineering, finance, or related degree or functional discipline
At least three (3) years of experience building flexible and scalable ETL processes and data pipelines
Extensive experience developing in Python and SQL
Should be well organized, thorough, and able to handle competing priorities
Knowledge and experience with Agile, Scrum, and DevOps principles and practices
Experience in any big data technologies - Hadoop, Amazon Redshift, AWS DevOps, Azure CosmosDB, Azure Data Lake, AWS DynamoDB, or advanced analytics tools will be plus
VeDM6NPQva",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2009,$5 to $25 million (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Sr Machine Learning Engineer, Data & ML Innovation","Summary
Posted: May 17, 2023
Role Number:200464615
Do you want to innovate at the intersection of Machine Learning and Data to make Apple products smarter for our users? The Data and Machine Learning Innovation team is looking deeply into the end-to-end lifecycle of ML product development, and finding innovative ways to make it scalable and efficient. We are a R&D team with strong expertise in Applied Machine Learning, Data Engineering and Distributed Infrastructure. The team works broadly with Machine Learning teams across the company to advance capabilities in the data centric machine learning world. As part of our team, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional, and you will collaborate very closely with various highly skilled machine learning and software development teams developing groundbreaking solutions!
Key Qualifications
10+ years of technical leadership experience.
Excellent knowledge and experienced practical skills in major machine learning algorithms.
Extensive knowledge in design and development of large scale distributed and big data processing systems.
Mastery of one of following languages: Python, Java or C++, demonstrating strong background in algorithms and data structures.
Excellent interpersonal skills, ability to work independently as well as in a team.
Creativity and curiosity for solving highly complex problems.
Excellent data analytical skills.
Description
As a member of our fast-paced group you’ll have the unique and rewarding opportunity to shape upcoming products from Apple. Our team includes a diversity of background engineers focusing on making ML development lifecycle scalable and efficient. As such we are looking for candidates with both strong applied machine learning experiences and engineering skills.
Education & Experience
MS or Ph.D in Computer Science, Machine Learning or related field. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $242,700 and $364,100, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Apple
4.2",4.2,"Cupertino, CA","AIML - Data Infrastructure Software Engineer, Machine Learning Platform and Technologies","Summary
Posted: May 16, 2023
Weekly Hours: 40
Role Number:200479379
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure.
Key Qualifications
5 years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"Ascendion
4.3",4.3,"Saint Louis, MO",Product Data Management Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:

Job Title: Product Data Mgmt Engr

Key Responsibilities:
Job Description:
Collaborates with teams in the development, analysis, management and compliance verification of process and product baselines of complex products.
Defines, plans, coordinates and conducts product and subsystem level technical design reviews and audits for new and derivative products.
Analyzes complex product trades and/or changes and develops technically complete change proposals.
Contributes to the development and implementation of Configuration and Data Management standards, processes and tools.
Defines and allocates Configuration and Data Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Coordinates the integration of product elements and analyzes & resolves issues with engineering product structure.
Develops, integrates and implements engineering technical program plans including impacts, risks and incorporation of lessons learned spanning multiple engineering functions.

Location: St. Louis, MO

Salary Range: The salary for this position is between $99,000 – $1,12,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
Preferred Skills:
Data Mangement
Configuration
Job details
Job ID
328163
Job Requirements
Product Data Management Engineer
Location
St. Louis, Missouri, US
Recruiter
Ashok
Email
ashok.kundu@ascendion.com","$96,323 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"Apple
4.2",4.2,"Raleigh, NC",Software Development Engineer [DEPT: WPC-Analytics/Data Science AP],"Summary
Posted: Aug 14, 2023
Weekly Hours: 40
Role Number:200496347
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 2 years of experience in the job offered or related occupation. Alternatively, employer will accept a Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 5 years of progressive, post-baccalaureate experience in the job offered or related occupation.
1 year of experience with each of the following skills is required:
ETL, BI and Data analytics
Apache Hadoop, Apache Hive, Apache Sqoop or Apache Spark
Extract data and implement data pipelines & SQL friendly data structures
Apache AVRO, Apache Parquet and common methods in data transformation
Dependency driven job schedulers
Teradata or ANSI SQL
Description
Multiple positions available in Cary, North Carolina. Translate business requirements by business team into data and engineering specifications. Build scalable data sets based on engineering specifications from the available raw data. Work with engineering and business partners to define and implement the data engagement relationships required with partners. Understand and Identify server APIs that needs to be instrumented for data analytics and reporting and align the server events for execution in already established data pipelines. Analyze complex data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reporting. Process, clean and validate the integrity of data used for analysis. Develop Python and Shell Scripts for data ingestion from external data sources for business insights. Work hand in hand with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. Mentor a team of hardworking engineers. 40 hours/week.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Trissential
4.1",4.1,"Minneapolis, MN",Data Engineer,"Overview
Trissential is a trusted partner for end-to-end quality services and management consulting for digital transformation. As a part of our parent company, Expleo, we are a global organization partnering with major corporations and leading non-profits in over 30 countries. Guided by our mission and values, Trissential puts people at the heart of our organization.
Come join an experience! Add your talent to a team of forward-thinking game changers that make an impact by driving innovative solutions.
Trissential is currently seeking a Data Engineer to join our dynamic team in Minneapolis, MN (Remote).
Responsibilities
Position Summary:
A Data Engineer is a professional responsible for designing, building, and maintaining the client’s data infrastructure that supports data-centric operations, and decision-making.
The Data Engineer is responsible for creating and maintaining data pipelines, data storage systems, and data processing systems, as well as ensuring data is accurate, secure, and easily accessible.
Primary Responsibilities and Accountabilities:
Data pipeline and workflow development: This includes designing and implementing client data pipelines and workflows to ensure that data is being collected, processed, and stored in an efficient and timely manner. Understand and incorporate data quality principals that ensure optimal performance, impact, and user experience.
Data storage and processing: This includes designing and implementing data storage systems and developing and maintaining code to process and analyze data.
Data integration: This includes working with the client on designing data integration strategies, integrating data from multiple sources, and ensuring data quality.
Data security: This includes defining and implementing client data security policies and procedures, including access control and data encryption.
Data governance: This includes defining data governance policies and procedures, monitoring data quality, and ensuring compliance with data privacy regulations.
Performance tuning: This includes optimizing data access, indexing, and query performance to ensure the data infrastructure can scale as required.
Monitoring and troubleshooting: This includes monitoring data systems and troubleshooting any issues that arise, identifying and resolving performance bottlenecks, and working with other team members to resolve any problems.
Collaboration and Communication: This includes working closely with client’s Data Architects, Data Analysts, Business Intelligence and Data Science team members, and other stakeholders to understand their data needs and develop solutions that meet those needs while adhering to industry best practices.
Qualifications
Extensive experience in ETL, preferably with transitioning from legacy systems to more advanced ones.
Strong data analysis skills, with the ability to identify areas of improvement in the current process.
In-depth knowledge of automation strategy development and implementation.
Ability to work in an advisory capacity, providing insights and recommendations to improve data management capabilities.
Excellent problem-solving skills to identify potential errors and propose solutions to enhance efficiency.
Skills
Works independently or well within a team
Wants to continuously grow knowledge base and skill set
Collaborative, consultative mindset
Works well in a fast paced environment
Strong technical background
Deep knowledge and curiosity about technology and systems
Agile mindset
Job Type: Contract
Work Location: Remote","$95,769 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2003,$25 to $100 million (USD)
"Elevance Health
3.7",3.7,Remote,Data Engineer Sr (contract),"Job ID: #JP00043626

Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. Previously known as Anthem, Inc., we have evolved into a company focused on whole health and updated our name to better reflect the direction the company is heading.

We are looking for contract workers (via BCforward) who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact?

Primary duties may include, but are not limited to:
Undertakes complex assignments requiring additional specialized technical knowledge.
Develops very complex and varied strategic report applications from a Data Warehouse.
Establishes and communicates common goal and direction for team.
Establishes and maintains advanced knowledge of data warehouse database design, data definitions, system capabilities, and data integrity issues.
Acts as a source of direction, training and guidance for less experienced staff.
Monitors project schedules and costs for own and other projects.
Develops and supports very complex Data Warehouse-related applications for business areas requiring design and implementation of database tables. Conducts training on use of applications developed.

Requirements:
Requires a BS/BA degree; 6 years experience; or any combination of education and experience, which would provide an equivalent background.
Expert level PC, spreadsheet, and database skills, as well as experience in standard Business Information tools and programming/query languages is also required.
Ability to communicate effectively with multiple levels within the organization.
This job is focused on spending time thinking about programming and how it would be used to design solutions as compared to the Bus Info Developer Consultant job
SQL, Visual Studio, VB, SSRS, Power BI, Tableau, SSIS

Additional Details:
40 hours/week centered around EST hours - flexible with shift times as long as they are available for meetings during EST (typically around 9am-3pm would be when our meetings would happen). Open to candidates anywhere in the US - 100% remote.
Possible Temp to hire

BCForward is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Privacy Notice for California Residents",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2004,$10+ billion (USD)
"NVR, Inc
3.7",3.7,"Frederick, MD",Data Engineer,"NVR is looking for a talented Data Enginneer to work onsite in Frederick, MD. Join our industry leading technology organization and be a part of making someone’s dream home a reality!
As a Data Engineer, you will be responsible for the day-to-day operations of data-dependent systems to ensure data is properly processed and securely transferred to its appropriate location, in a timely manner. If you are a recent graduate or an engineer early in your career, this is a great opportunity for you to leverage your computer knowledge and analytical skills by getting involved in projects and gaining exposure to cloud technologies, data and analytics!
Key Job Responsibilities:
Keeping the data flowing by working with SQL, SQL Server, SSRS and SSIS
Managing, manipulating, storing, and parsing data on premises and in the cloud.
Collaborate with the team to solve support issues.
Interact with business and IT teams of various applications to understand their data, database, and flow within the systems.
Create logical mapping of source data into target data models, based on business process and data/reporting requirements.
Job Qualifications:
0-3 years of experience in data management (integration, modeling, optimization, and quality).
Experience or coursework with databases and queries
Excellent written and verbal communication skills, interpersonal and collaborative skills.
Must have strong problem-solving and analytical skills.
High degree of initiative and be well organized.
Ability to manage multiple projects with strict timelines.
Here’s what will put you ahead of the pack:
Understanding of data modeling, structured and unstructured data, and data transformation techniques.
Experience or coursework using visualization tools like Tableau or Power BI.
Microsoft Azure Certifications.
About Us & Life at NVR
NVR has been helping families build their happily ever after since 1948. As a Top 5 US homebuilder, we’re committed to quality and to our customers and we take pride in the over 500,000 new homes we have sold and built across the country. Working in the homebuilding industry is tangible and rewarding, but not every job at NVR requires a hard hat. We don’t just sell and build new homes; we also manage teams, acquire land, manufacture materials, provide mortgages to our customers, and provide corporate support to NVR’s multi-billion dollar business operations.
At NVR, we value our teams and provide opportunities to learn new technologies and skills to grow your career. Your desire to excel is matched by our commitment to your success and we’ll give you the tools and industry knowledge you need. Our management team is tenured and talented, nearly 80% of them promoted from within, so you’ll find mentors who can share their knowledge, provide career guidance and encourage your success.
NVR also offers benefits among the best in the industry that reflect the strong commitment we have to all of our employees.
Competitive Compensation
Home Purchase Discount
Mortgage and Settlement Services Discounts
Comprehensive Health, Life and Disability Insurance
401(k) (Full-time employees are eligible to contribute immediately)
Employee Stock Ownership Program
Vacation and Holidays
In addition to the traditional benefits, we offer all our employees stock ownership through a profit sharing trust as part of our retirement savings package. NVR has had the highest Earnings Per Share growth rate in the homebuilding industry for the past 10 years, so as we grow financially, so do you.
We are an Equal Opportunity Employer.
Drug Testing and Credit Check are required.
Applicants must be legally entitled to work in the United States, as NVR does not provide visa sponsorships.","$71,504 /yr (est.)",5001 to 10000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Construction,1948,$10+ billion (USD)
"ADT
3.1",3.1,"Boca Raton, FL",Data Engineer,"Company Overview:

ADT has been in the business of helping save lives since 1874. As the #1 smart home security provider in the U.S., we help protect and connect families, businesses and larger commercial customer every day. Our continuous innovation, advanced technology and strategic partnerships deliver products and services that help protect life and valuables, whether at home, your business or on the go. And as times change, so do we. Above all, our mission is clear: we help save lives for a living. Looking for a career where you can make a real impact? Join our team today and put purpose behind your paycheck. #WeAreADT
Check out more about life at ADT here.
Position Summary: Senior Data Engineer is responsible for developing and governing our data and information strategy in order to drive business decisions and growth. You will develop data procedures and policies and work closely with the various departments to collect, prepare, organize, protect, and analyze data assents while ensuring that the company meets industry best practices. Other duties will include leading inter-disciplinary teams, improving and streamlining data systems within the company and driving innovation.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Thorough understanding of the business and data strategy.
Designing and implementing data strategies and systems.
Overseeing the collection, storage, management, quality and protection of data.
Implementing data privacy policies and complying with data projection regulations.
Determine where to cut costs and increase revenue based on insights derived from data.
Effectively communicate the status, value, and importance of data collection to executive members and staff.
Knowledge of relevant applications, big data solutions and tools.
Competencies: To perform the job successfully, an individual should demonstrate the following:
Achievement Focus - Demonstrates persistence and overcomes obstacles. Measures self against standard of excellence. Recognizes and acts on opportunities. Sets and achieves challenging goals. Takes calculated risks to accomplish goals.
Business Acumen - Aligns work with strategic goals. Conducts cost-benefit analyses. Demonstrates knowledge of market and competition. Displays orientation to profitability. Understands business implications of decisions.
Business Ethics - Inspires the trust of others. Keeps commitments. Treats people with respect. Upholds organizational values. Works with integrity and ethically.
Managing Customer Focus - Develops new approaches to meeting customer needs. Establishes customer service standards. Monitors customer satisfaction. Promotes customer focus. Provides training in customer service delivery.
Strategic Thinking - Adapts strategy to changing conditions. Analyzes market and competition. Develops strategies to achieve organizational goals. Identifies external threats and opportunities. Understands organization's strengths & weaknesses.
Visionary Leadership - Acts in accordance with vision. Communicates vision and gains commitment. Creates a clear, compelling vision. Displays passion and optimism. Mobilizes others to fulfill the vision.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education/Experience:
Bachelor’s degree in information technology of related field. Master’s degree preferred. 5 to 10 years’ experience in a senior level data management role.
Language Ability:
Read, analyze, and interpret scientific and technical journals, financial reports, and legal documents. Respond to inquiries or complaints from customers, agencies, or members of the business community. Write speeches and articles for publication.
Mathematical Ability:
Apply advanced concepts such as exponents, logarithms, quadratic equations, and permutations. Apply operations to such tasks as frequency distribution, test reliability/validity, variance analysis, correlation technique, sampling theory and factor analysis.
Reasoning Ability:
Define problems, collect data, establish facts, and draw valid conclusions. Interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The noise level in the work environment is usually moderate.
Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is frequently required to sit and use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand and walk. The employee must be able to occasionally lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
The above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow any other instructions, and perform any other related duties, as assigned by their supervisor.
Compensation:
The salary range for this role is $73,066-$146,131 and is based on experience and qualifications.
Certain roles are eligible for annual bonus and may include equity. These awards are allocated based on company and individual performance.
We offer employees access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, life insurance, wellbeing benefits and paid time off among others. Employees accrue up to 120 hours in their first year. Your accrual rate increases after your first year. We also offer 6 paid holidays.


ADT is an Equal Employment Opportunity (EEO) Employer. We celebrate diversity and are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. ADT strives to ensure every employee and applicant feels valued. Visit us at jobs.adt.com/diversity to learn more.","$109,599 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Security & Protective,1874,$5 to $10 billion (USD)
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Starbucks
3.7",3.7,"Seattle, WA",data engineer sr,"Senior data engineer
Job Summary and Mission
This position contributes to Starbuck's success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing, and support for data pipelines and data products to enable continuous data processing for data exploration, data preparation, and real-time business analytics.
Summary of Key Responsibilities
Responsibilities and essential job functions include but are not limited to the following:
Demonstrate deep knowledge of the data engineering domain, including non-interactive (batch, distributed) & real-time, highly available data, data pipelines
Deep knowledge of data as a concept and the development of domain driven data products.
Optimization of data products to service customer personas, Data science, AI/ML and data visualization.
Knowledge of semantic data concepts.
Build fault-tolerant, self-healing, adaptive, and highly accurate data computational pipelines
Provide consultation and lead the implementation of complex programs
Develop and maintain documentation relating to all assigned systems and projects
Perform root cause analysis to identify permanent resolutions to software or business process issues
Basic Qualifications
Bachelor’s degree in computer science, management information systems, or related discipline, or equivalent work experience
MUST HAVE Technology skills (7/10 or higher):
Strong/expert Spark (PySpark) Using Jupyter Notebooks, Colab or DataBricks
Hands-on data pipeline development, ingest patterns in Azure
Orchestration tools, ADF or Airflow
SQL
Denormalized Data modeling for big data systems
MUST HAVE competencies:
Collaborative, able to work remotely, and still be an engaging team member.
Strong analytical and design skills.
Years
Architect and design large scale high performance distributed systems 7-10
SQL Platform 7-10
No-SQL Platform 3+
Spark 3+
Data platform implementation on Azure or AWS 3+
CI/CD experience 2+
Exposure to SOA architecture 2+

div>
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

We are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.

Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at applicantaccommodation@starbucks.com.","$128,868 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1971,$10+ billion (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Ascendion
4.3",4.3,"Saint Louis, MO",Product Data Management Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:

Job Title: Product Data Mgmt Engr

Key Responsibilities:
Job Description:
Collaborates with teams in the development, analysis, management and compliance verification of process and product baselines of complex products.
Defines, plans, coordinates and conducts product and subsystem level technical design reviews and audits for new and derivative products.
Analyzes complex product trades and/or changes and develops technically complete change proposals.
Contributes to the development and implementation of Configuration and Data Management standards, processes and tools.
Defines and allocates Configuration and Data Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Coordinates the integration of product elements and analyzes & resolves issues with engineering product structure.
Develops, integrates and implements engineering technical program plans including impacts, risks and incorporation of lessons learned spanning multiple engineering functions.

Location: St. Louis, MO

Salary Range: The salary for this position is between $99,000 – $1,12,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
Preferred Skills:
Data Mangement
Configuration
Job details
Job ID
328163
Job Requirements
Product Data Management Engineer
Location
St. Louis, Missouri, US
Recruiter
Ashok
Email
ashok.kundu@ascendion.com","$96,323 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"Trissential
4.1",4.1,"Minneapolis, MN",Data Engineer,"Overview
Trissential is a trusted partner for end-to-end quality services and management consulting for digital transformation. As a part of our parent company, Expleo, we are a global organization partnering with major corporations and leading non-profits in over 30 countries. Guided by our mission and values, Trissential puts people at the heart of our organization.
Come join an experience! Add your talent to a team of forward-thinking game changers that make an impact by driving innovative solutions.
Trissential is currently seeking a Data Engineer to join our dynamic team in Minneapolis, MN (Remote).
Responsibilities
Position Summary:
A Data Engineer is a professional responsible for designing, building, and maintaining the client’s data infrastructure that supports data-centric operations, and decision-making.
The Data Engineer is responsible for creating and maintaining data pipelines, data storage systems, and data processing systems, as well as ensuring data is accurate, secure, and easily accessible.
Primary Responsibilities and Accountabilities:
Data pipeline and workflow development: This includes designing and implementing client data pipelines and workflows to ensure that data is being collected, processed, and stored in an efficient and timely manner. Understand and incorporate data quality principals that ensure optimal performance, impact, and user experience.
Data storage and processing: This includes designing and implementing data storage systems and developing and maintaining code to process and analyze data.
Data integration: This includes working with the client on designing data integration strategies, integrating data from multiple sources, and ensuring data quality.
Data security: This includes defining and implementing client data security policies and procedures, including access control and data encryption.
Data governance: This includes defining data governance policies and procedures, monitoring data quality, and ensuring compliance with data privacy regulations.
Performance tuning: This includes optimizing data access, indexing, and query performance to ensure the data infrastructure can scale as required.
Monitoring and troubleshooting: This includes monitoring data systems and troubleshooting any issues that arise, identifying and resolving performance bottlenecks, and working with other team members to resolve any problems.
Collaboration and Communication: This includes working closely with client’s Data Architects, Data Analysts, Business Intelligence and Data Science team members, and other stakeholders to understand their data needs and develop solutions that meet those needs while adhering to industry best practices.
Qualifications
Extensive experience in ETL, preferably with transitioning from legacy systems to more advanced ones.
Strong data analysis skills, with the ability to identify areas of improvement in the current process.
In-depth knowledge of automation strategy development and implementation.
Ability to work in an advisory capacity, providing insights and recommendations to improve data management capabilities.
Excellent problem-solving skills to identify potential errors and propose solutions to enhance efficiency.
Skills
Works independently or well within a team
Wants to continuously grow knowledge base and skill set
Collaborative, consultative mindset
Works well in a fast paced environment
Strong technical background
Deep knowledge and curiosity about technology and systems
Agile mindset
Job Type: Contract
Work Location: Remote","$95,769 /yr (est.)",201 to 500 Employees,Subsidiary or Business Segment,Management & Consulting,Business Consulting,2003,$25 to $100 million (USD)
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Nationwide
4.0",4.0,Remote,"Specialist, Business Insight (Business Data Engineer)","If you’re passionate about helping people protect what matters most to them, as well as innovating and simplifying processes and operations to provide the best customer value, then Nationwide’s Property and Casualty team could be the place for you!
Compensation Grade (for internal use only): F4
Job Description Summary
We are a versatile group of individuals, working together to meet the needs of our customers. We value knowledge, analytical aptitude and collaboration. If you thrive in a busy, engaging work environment, we want to know more about you!

As a Specialist, Business Insights, you'll extract and manipulate internal and external data through R/SAS/SQL/Python, perform diagnostic and inferential analysis, and communicate actionable insights to business partners. You’ll also work with business partners to determine data and information needs to aid the business with decision making and build statistical and visual solutions using sophisticated business intelligence tools. And you may serve as a lead to others for information and data needs. Your focus will be to maximize the insight gained from internal and external data, ensuring that business partners are making decisions in an optimally informed way.
Job Description
Key Responsibilities:
Functions as the specialist in data extraction from databases, tables, data warehouses and other sources through R/SAS/SQL/Python. Develops, produces, and maintains inferential, statistical, ad hoc and custom analyses and modeling for functional business areas. May use various data access tools to pull information for reports and solutions.
Builds and maintains relationships and serves as a trusted financial and operational measurement resource to clients, internal risk partners and other stakeholders.
Creates and presents financial and operational results. Ensures that insights are action oriented. May develop new statistical and visual solutions for relevant insights.
Consults with business partners to understand, align and deliver work that supports business objectives and priorities.
Leverages statistical inferencing when conducting analysis. Communicates significance in findings when working with business partners. May build business intelligence applications using statistical, database and/or general programming languages and tools.
May assist other associates with preparation of reports and use of information systems, software and related sources of information and may train other users on report preparation and data base access.
Serves as a single point of contact and consultant for business areas for the intake and prioritization of data, reporting, analysis, and advanced statistical work.
Leads and serves as a main point of contact for projects. Monitors, reviews and analyzes the external environment to support the research and analysis done with data extracted from internal sources. Presents and discusses these findings with customers.
May perform other responsibilities as assigned.
Reporting Relationships: Reports to Manager/Director and does not have direct reports.
Typical Skills and Experiences:
Education:Undergraduate studies in data or business analytics, computer science, management information, business, mathematics or related field with post-graduate studies preferred
Experience: Six or more years of related experience with data extraction, data manipulation, data visualization analysis, and problem solving; working with large database. Professional experience in insurance, financial services, or a related industry preferred.
Knowledge, Abilities and Skills:
In-depth knowledge of business policies and procedures, customer service concepts and practices. In-depth understanding of and working knowledge to build data visualization and business intelligence tools. Strong communication skills to interact with others. Ability to understand business processes and the data produced by them. Understanding of functional and operational measurement needs, analyze data requests and interpret business problems into solutions. Ability to work under tight time constraints. Capable of developing distinctive and understandable data visualizations. Other criteria, including leadership skills, competencies and experiences may take precedence. Staffing exceptions to the above must be approved by the hiring manager’s leader and Human Resources Business Partner.
Values: Regularly and consistently demonstrates the Nationwide Values.
Job Conditions:
Overtime Eligibility: Not Eligible (Exempt)
Working Conditions: Normal office environment. Occasional travel, nonstandard or extended work may be required based on project needs.
ADA: The above statements cover what are generally believed to be principal and essential functions of this job. Specific circumstances may allow or require some people assigned to the job to perform a somewhat different combination of duties.
Benefits
We have an array of benefits to fit your needs, including: medical/dental/vision, life insurance, short and long term disability coverage, paid time off with newly hired associates receiving a minimum of 18 days paid time off each full calendar year pro-rated quarterly based on hire date, nine paid holidays, 8 hours of Lifetime paid time off, 8 hours of Unity Day paid time off, 401(k) with company match, company-paid pension plan, business casual attire, and more. To learn more about the benefits we offer,
click here
.
Nationwide is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive culture where everyone feels challenged, appreciated, respected and engaged. Nationwide prohibits discrimination and harassment and affords equal employment opportunities to employees and applicants without regard to any characteristic (or classification) protected by applicable law.
Smoke-Free Iowa Statement: Nationwide Mutual Insurance Company, its affiliates and subsidiaries comply with the Iowa Smokefree Air Act. Smoking is prohibited in all enclosed areas on or around company premises as well as company issued vehicles. The company offers designated smoking areas in which smoking is permitted at each individual location. The Act prohibits retaliation for reporting complaints or violations. For more information on the Iowa Smokefree Air Act, individuals may contact the Smokefree Air Act Helpline at 888-944-2247.
For NY residents please review the following state law information: Notice of Employee Rights, Protections, and Obligations LS740 (ny.gov)
Nationwide pays on a geographic-specific salary structure and placement within the actual starting salary range for this position will be determined by a number of factors including the skills, education, training, credentials and experience of the candidate; the scope, complexity and location of the role as well as the cost of labor in the market; and other conditions of employment. If a Sales job, Sales Incentives, based on performance goals are possible in addition to this range.
The national salary range for Specialist, Business Insights : 73,500.00-152,000.00
The expected starting salary range for Specialist, Business Insights : 81,500.00 - 122,500.00",#N/A,10000+ Employees,Company - Public,Insurance,Insurance Carriers,1925,$10+ billion (USD)
"Elevance Health
3.7",3.7,Remote,Data Engineer Sr (contract),"Job ID: #JP00043626

Elevance Health is a health company dedicated to improving lives and communities – and making healthcare simpler. Previously known as Anthem, Inc., we have evolved into a company focused on whole health and updated our name to better reflect the direction the company is heading.

We are looking for contract workers (via BCforward) who are passionate about making an impact on our members and the communities we serve. You will thrive in a complex and collaborative environment where you take action and ownership to solve problems and lead change. Do you want to be part of a larger purpose and an evolving, high-performance culture that empowers you to make an impact?

Primary duties may include, but are not limited to:
Undertakes complex assignments requiring additional specialized technical knowledge.
Develops very complex and varied strategic report applications from a Data Warehouse.
Establishes and communicates common goal and direction for team.
Establishes and maintains advanced knowledge of data warehouse database design, data definitions, system capabilities, and data integrity issues.
Acts as a source of direction, training and guidance for less experienced staff.
Monitors project schedules and costs for own and other projects.
Develops and supports very complex Data Warehouse-related applications for business areas requiring design and implementation of database tables. Conducts training on use of applications developed.

Requirements:
Requires a BS/BA degree; 6 years experience; or any combination of education and experience, which would provide an equivalent background.
Expert level PC, spreadsheet, and database skills, as well as experience in standard Business Information tools and programming/query languages is also required.
Ability to communicate effectively with multiple levels within the organization.
This job is focused on spending time thinking about programming and how it would be used to design solutions as compared to the Bus Info Developer Consultant job
SQL, Visual Studio, VB, SSRS, Power BI, Tableau, SSIS

Additional Details:
40 hours/week centered around EST hours - flexible with shift times as long as they are available for meetings during EST (typically around 9am-3pm would be when our meetings would happen). Open to candidates anywhere in the US - 100% remote.
Possible Temp to hire

BCForward is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

Privacy Notice for California Residents",#N/A,10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,2004,$10+ billion (USD)
"Apple
4.2",4.2,"Raleigh, NC",Software Development Engineer [DEPT: WPC-Analytics/Data Science AP],"Summary
Posted: Aug 14, 2023
Weekly Hours: 40
Role Number:200496347
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 2 years of experience in the job offered or related occupation. Alternatively, employer will accept a Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 5 years of progressive, post-baccalaureate experience in the job offered or related occupation.
1 year of experience with each of the following skills is required:
ETL, BI and Data analytics
Apache Hadoop, Apache Hive, Apache Sqoop or Apache Spark
Extract data and implement data pipelines & SQL friendly data structures
Apache AVRO, Apache Parquet and common methods in data transformation
Dependency driven job schedulers
Teradata or ANSI SQL
Description
Multiple positions available in Cary, North Carolina. Translate business requirements by business team into data and engineering specifications. Build scalable data sets based on engineering specifications from the available raw data. Work with engineering and business partners to define and implement the data engagement relationships required with partners. Understand and Identify server APIs that needs to be instrumented for data analytics and reporting and align the server events for execution in already established data pipelines. Analyze complex data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reporting. Process, clean and validate the integrity of data used for analysis. Develop Python and Shell Scripts for data ingestion from external data sources for business insights. Work hand in hand with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. Mentor a team of hardworking engineers. 40 hours/week.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"ADT
3.1",3.1,"Boca Raton, FL",Data Engineer,"Company Overview:

ADT has been in the business of helping save lives since 1874. As the #1 smart home security provider in the U.S., we help protect and connect families, businesses and larger commercial customer every day. Our continuous innovation, advanced technology and strategic partnerships deliver products and services that help protect life and valuables, whether at home, your business or on the go. And as times change, so do we. Above all, our mission is clear: we help save lives for a living. Looking for a career where you can make a real impact? Join our team today and put purpose behind your paycheck. #WeAreADT
Check out more about life at ADT here.
Position Summary: Senior Data Engineer is responsible for developing and governing our data and information strategy in order to drive business decisions and growth. You will develop data procedures and policies and work closely with the various departments to collect, prepare, organize, protect, and analyze data assents while ensuring that the company meets industry best practices. Other duties will include leading inter-disciplinary teams, improving and streamlining data systems within the company and driving innovation.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Thorough understanding of the business and data strategy.
Designing and implementing data strategies and systems.
Overseeing the collection, storage, management, quality and protection of data.
Implementing data privacy policies and complying with data projection regulations.
Determine where to cut costs and increase revenue based on insights derived from data.
Effectively communicate the status, value, and importance of data collection to executive members and staff.
Knowledge of relevant applications, big data solutions and tools.
Competencies: To perform the job successfully, an individual should demonstrate the following:
Achievement Focus - Demonstrates persistence and overcomes obstacles. Measures self against standard of excellence. Recognizes and acts on opportunities. Sets and achieves challenging goals. Takes calculated risks to accomplish goals.
Business Acumen - Aligns work with strategic goals. Conducts cost-benefit analyses. Demonstrates knowledge of market and competition. Displays orientation to profitability. Understands business implications of decisions.
Business Ethics - Inspires the trust of others. Keeps commitments. Treats people with respect. Upholds organizational values. Works with integrity and ethically.
Managing Customer Focus - Develops new approaches to meeting customer needs. Establishes customer service standards. Monitors customer satisfaction. Promotes customer focus. Provides training in customer service delivery.
Strategic Thinking - Adapts strategy to changing conditions. Analyzes market and competition. Develops strategies to achieve organizational goals. Identifies external threats and opportunities. Understands organization's strengths & weaknesses.
Visionary Leadership - Acts in accordance with vision. Communicates vision and gains commitment. Creates a clear, compelling vision. Displays passion and optimism. Mobilizes others to fulfill the vision.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education/Experience:
Bachelor’s degree in information technology of related field. Master’s degree preferred. 5 to 10 years’ experience in a senior level data management role.
Language Ability:
Read, analyze, and interpret scientific and technical journals, financial reports, and legal documents. Respond to inquiries or complaints from customers, agencies, or members of the business community. Write speeches and articles for publication.
Mathematical Ability:
Apply advanced concepts such as exponents, logarithms, quadratic equations, and permutations. Apply operations to such tasks as frequency distribution, test reliability/validity, variance analysis, correlation technique, sampling theory and factor analysis.
Reasoning Ability:
Define problems, collect data, establish facts, and draw valid conclusions. Interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The noise level in the work environment is usually moderate.
Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is frequently required to sit and use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand and walk. The employee must be able to occasionally lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
The above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow any other instructions, and perform any other related duties, as assigned by their supervisor.
Compensation:
The salary range for this role is $73,066-$146,131 and is based on experience and qualifications.
Certain roles are eligible for annual bonus and may include equity. These awards are allocated based on company and individual performance.
We offer employees access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, life insurance, wellbeing benefits and paid time off among others. Employees accrue up to 120 hours in their first year. Your accrual rate increases after your first year. We also offer 6 paid holidays.


ADT is an Equal Employment Opportunity (EEO) Employer. We celebrate diversity and are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. ADT strives to ensure every employee and applicant feels valued. Visit us at jobs.adt.com/diversity to learn more.","$109,599 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Security & Protective,1874,$5 to $10 billion (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Data Infrastructure Software Engineer, Machine Learning Platform and Technologies","Summary
Posted: May 16, 2023
Weekly Hours: 40
Role Number:200479379
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure.
Key Qualifications
5 years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Capital One
4.1",4.1,"Wilmington, DE",Senior Data Engineer,"802 Delaware Avenue (18052), United States of America, Wilmington, Delaware
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance
Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"Analytica
3.4",3.4,Remote,Data Engineer,"Analytica is seeking a remote Data Engineer to support a high-profile financial regulatory client with developing data pipeline and ETL solutions in an AWS cloud environment.
Analytica has been recognized by Inc. Magazine as a fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.
Responsibilities include (but not limited to):
Develops tools and infrastructure for data processing use cases
Designs and builds data pipelines that ingest and transform data using programming languages such as Python and SQL, and data orchestration tools
Designs, builds, and maintains data storage and processing infrastructure that allows working nimbly through extensive amounts of analytics data
Build and deliver data lake, integrate with existing data catalog prototype, and migrate to big data applications from on-premise to the new computing platform by leveraging new technologies (such as Apache Spark)
Qualifications:
Bachelor's degree in information systems, computer science, engineering, finance, or related degree or functional discipline
At least three (3) years of experience building flexible and scalable ETL processes and data pipelines
Extensive experience developing in Python and SQL
Should be well organized, thorough, and able to handle competing priorities
Knowledge and experience with Agile, Scrum, and DevOps principles and practices
Experience in any big data technologies - Hadoop, Amazon Redshift, AWS DevOps, Azure CosmosDB, Azure Data Lake, AWS DynamoDB, or advanced analytics tools will be plus
VeDM6NPQva",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2009,$5 to $25 million (USD)
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"Nationwide
4.0",4.0,Remote,"Specialist, Business Insight (Business Data Engineer)","If you’re passionate about helping people protect what matters most to them, as well as innovating and simplifying processes and operations to provide the best customer value, then Nationwide’s Property and Casualty team could be the place for you!
Compensation Grade (for internal use only): F4
Job Description Summary
We are a versatile group of individuals, working together to meet the needs of our customers. We value knowledge, analytical aptitude and collaboration. If you thrive in a busy, engaging work environment, we want to know more about you!

As a Specialist, Business Insights, you'll extract and manipulate internal and external data through R/SAS/SQL/Python, perform diagnostic and inferential analysis, and communicate actionable insights to business partners. You’ll also work with business partners to determine data and information needs to aid the business with decision making and build statistical and visual solutions using sophisticated business intelligence tools. And you may serve as a lead to others for information and data needs. Your focus will be to maximize the insight gained from internal and external data, ensuring that business partners are making decisions in an optimally informed way.
Job Description
Key Responsibilities:
Functions as the specialist in data extraction from databases, tables, data warehouses and other sources through R/SAS/SQL/Python. Develops, produces, and maintains inferential, statistical, ad hoc and custom analyses and modeling for functional business areas. May use various data access tools to pull information for reports and solutions.
Builds and maintains relationships and serves as a trusted financial and operational measurement resource to clients, internal risk partners and other stakeholders.
Creates and presents financial and operational results. Ensures that insights are action oriented. May develop new statistical and visual solutions for relevant insights.
Consults with business partners to understand, align and deliver work that supports business objectives and priorities.
Leverages statistical inferencing when conducting analysis. Communicates significance in findings when working with business partners. May build business intelligence applications using statistical, database and/or general programming languages and tools.
May assist other associates with preparation of reports and use of information systems, software and related sources of information and may train other users on report preparation and data base access.
Serves as a single point of contact and consultant for business areas for the intake and prioritization of data, reporting, analysis, and advanced statistical work.
Leads and serves as a main point of contact for projects. Monitors, reviews and analyzes the external environment to support the research and analysis done with data extracted from internal sources. Presents and discusses these findings with customers.
May perform other responsibilities as assigned.
Reporting Relationships: Reports to Manager/Director and does not have direct reports.
Typical Skills and Experiences:
Education:Undergraduate studies in data or business analytics, computer science, management information, business, mathematics or related field with post-graduate studies preferred
Experience: Six or more years of related experience with data extraction, data manipulation, data visualization analysis, and problem solving; working with large database. Professional experience in insurance, financial services, or a related industry preferred.
Knowledge, Abilities and Skills:
In-depth knowledge of business policies and procedures, customer service concepts and practices. In-depth understanding of and working knowledge to build data visualization and business intelligence tools. Strong communication skills to interact with others. Ability to understand business processes and the data produced by them. Understanding of functional and operational measurement needs, analyze data requests and interpret business problems into solutions. Ability to work under tight time constraints. Capable of developing distinctive and understandable data visualizations. Other criteria, including leadership skills, competencies and experiences may take precedence. Staffing exceptions to the above must be approved by the hiring manager’s leader and Human Resources Business Partner.
Values: Regularly and consistently demonstrates the Nationwide Values.
Job Conditions:
Overtime Eligibility: Not Eligible (Exempt)
Working Conditions: Normal office environment. Occasional travel, nonstandard or extended work may be required based on project needs.
ADA: The above statements cover what are generally believed to be principal and essential functions of this job. Specific circumstances may allow or require some people assigned to the job to perform a somewhat different combination of duties.
Benefits
We have an array of benefits to fit your needs, including: medical/dental/vision, life insurance, short and long term disability coverage, paid time off with newly hired associates receiving a minimum of 18 days paid time off each full calendar year pro-rated quarterly based on hire date, nine paid holidays, 8 hours of Lifetime paid time off, 8 hours of Unity Day paid time off, 401(k) with company match, company-paid pension plan, business casual attire, and more. To learn more about the benefits we offer,
click here
.
Nationwide is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive culture where everyone feels challenged, appreciated, respected and engaged. Nationwide prohibits discrimination and harassment and affords equal employment opportunities to employees and applicants without regard to any characteristic (or classification) protected by applicable law.
Smoke-Free Iowa Statement: Nationwide Mutual Insurance Company, its affiliates and subsidiaries comply with the Iowa Smokefree Air Act. Smoking is prohibited in all enclosed areas on or around company premises as well as company issued vehicles. The company offers designated smoking areas in which smoking is permitted at each individual location. The Act prohibits retaliation for reporting complaints or violations. For more information on the Iowa Smokefree Air Act, individuals may contact the Smokefree Air Act Helpline at 888-944-2247.
For NY residents please review the following state law information: Notice of Employee Rights, Protections, and Obligations LS740 (ny.gov)
Nationwide pays on a geographic-specific salary structure and placement within the actual starting salary range for this position will be determined by a number of factors including the skills, education, training, credentials and experience of the candidate; the scope, complexity and location of the role as well as the cost of labor in the market; and other conditions of employment. If a Sales job, Sales Incentives, based on performance goals are possible in addition to this range.
The national salary range for Specialist, Business Insights : 73,500.00-152,000.00
The expected starting salary range for Specialist, Business Insights : 81,500.00 - 122,500.00",#N/A,10000+ Employees,Company - Public,Insurance,Insurance Carriers,1925,$10+ billion (USD)
"Apple
4.2",4.2,"Raleigh, NC",Software Development Engineer [DEPT: WPC-Analytics/Data Science AP],"Summary
Posted: Aug 14, 2023
Weekly Hours: 40
Role Number:200496347
Imagine what you can do here. Apple is a place where extraordinary people gather to do their lives best work. Together we create products and experiences people once couldn’t have imagined, and now, can’t imagine living without. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do.
Key Qualifications
Master’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 2 years of experience in the job offered or related occupation. Alternatively, employer will accept a Bachelor’s degree or foreign equivalent in Computer Science, Software Engineering, Electrical Engineering, Information Technology or related field and 5 years of progressive, post-baccalaureate experience in the job offered or related occupation.
1 year of experience with each of the following skills is required:
ETL, BI and Data analytics
Apache Hadoop, Apache Hive, Apache Sqoop or Apache Spark
Extract data and implement data pipelines & SQL friendly data structures
Apache AVRO, Apache Parquet and common methods in data transformation
Dependency driven job schedulers
Teradata or ANSI SQL
Description
Multiple positions available in Cary, North Carolina. Translate business requirements by business team into data and engineering specifications. Build scalable data sets based on engineering specifications from the available raw data. Work with engineering and business partners to define and implement the data engagement relationships required with partners. Understand and Identify server APIs that needs to be instrumented for data analytics and reporting and align the server events for execution in already established data pipelines. Analyze complex data sets, identify and formulate correlational rules between heterogenous sources for effective analytics and reporting. Process, clean and validate the integrity of data used for analysis. Develop Python and Shell Scripts for data ingestion from external data sources for business insights. Work hand in hand with the DevOps team and develop monitoring and alerting scripts on various data pipelines and jobs. Mentor a team of hardworking engineers. 40 hours/week.
Education & Experience
Additional Requirements",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"DIRECTV
3.5",3.5,"El Segundo, CA",Senior- Big Data Engineer,"Senior- Big Data Engineer needed by DIRECTV, LLC in El Segundo, CA [and various unanticipated locations throughout the U.S.; may work from home] to interpret the requirements of various big data analytics and use cases and scenarios. Drive the design and implementation of specific data models to drive better business decisions through insights from a combination of external and internal data assets. Develop enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a Big Data environment. Support standardization, customization, and ad-hoc data analysis. Develop mechanisms to ingest, analyze, validate, normalize, and clean data. Implement statistical data quality procedures on new data sources and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy, security teams, and legal to create data policies. Develop interfaces and retention models that require synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods, and techniques. Create architecture diagrams including conceptual and logical data models, data dictionaries, data flow diagrams, and data discovery. Analyze business requirements to create technical solutions for data. Partner with business analysts and enterprise and solution architects to understand data product needs and guide the solution development teams through best of breed design and implementation practices. Improve design, development, and operational management of data products through the introduction of new tools and practices. Apply working knowledge of delivering insight projects to businesses via a defined data architecture, cloud-based data warehousing, streaming, and batch processing. Utilize SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions. Apply knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
MINIMUM REQUIREMENT: Requires a Master’s degree, or foreign equivalent degree, in Computer Science or Computer and Information Science and two (2) years of experience in the job offered or two (2) years of experience in a related occupation developing enablers and data platforms in a Big Data Lake environment and maintaining its integrity during the life cycle phases; defining data requirements, gathering and mining large scale of structured and unstructured data, and validating data by running various data tools in a Big Data environment; supporting standardization, customization, and ad-hoc data analysis; developing mechanisms to ingest, analyze, validate, normalize, and clean data; implementing statistical data quality procedures on new data sources and applying rigorous iterative data analytics; working with big data policy, security teams, and legal to create data policies; developing interfaces and retention models that require synthesizing or anonymizing data; utilizing SQL, Snowflake, Vertica, Teradata, AWS, and Azure data solutions; and applying knowledge of implementing ML/AI across Azure and AWS leveraging Databricks MLOps.
Our Senior- Big Data Engineers earn between $159,650 to $192,050 yearly. DIRECTV, LLC offers amazing benefits from health insurance to tuition reimbursement and paid time off to discounts on products and services.","$175,850 /yr (est.)",10000+ Employees,Company - Private,Telecommunications,"Cable, Internet & Telephone Providers",1994,Unknown / Non-Applicable
"Apple
4.2",4.2,"Cupertino, CA","AIML - Sr Machine Learning Engineer, Data & ML Innovation","Summary
Posted: May 17, 2023
Role Number:200464615
Do you want to innovate at the intersection of Machine Learning and Data to make Apple products smarter for our users? The Data and Machine Learning Innovation team is looking deeply into the end-to-end lifecycle of ML product development, and finding innovative ways to make it scalable and efficient. We are a R&D team with strong expertise in Applied Machine Learning, Data Engineering and Distributed Infrastructure. The team works broadly with Machine Learning teams across the company to advance capabilities in the data centric machine learning world. As part of our team, you will work together with similar minds in a unique development team where your skills and expertise will be put into the Apple products. This role is highly multi-functional, and you will collaborate very closely with various highly skilled machine learning and software development teams developing groundbreaking solutions!
Key Qualifications
10+ years of technical leadership experience.
Excellent knowledge and experienced practical skills in major machine learning algorithms.
Extensive knowledge in design and development of large scale distributed and big data processing systems.
Mastery of one of following languages: Python, Java or C++, demonstrating strong background in algorithms and data structures.
Excellent interpersonal skills, ability to work independently as well as in a team.
Creativity and curiosity for solving highly complex problems.
Excellent data analytical skills.
Description
As a member of our fast-paced group you’ll have the unique and rewarding opportunity to shape upcoming products from Apple. Our team includes a diversity of background engineers focusing on making ML development lifecycle scalable and efficient. As such we are looking for candidates with both strong applied machine learning experiences and engineering skills.
Education & Experience
MS or Ph.D in Computer Science, Machine Learning or related field. Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $242,700 and $364,100, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","AIML - Data Infrastructure Software Engineer, Machine Learning Platform and Technologies","Summary
Posted: May 16, 2023
Weekly Hours: 40
Role Number:200479379
The Data Infrastructure group within the AI/ML organization powers the analytics, experimentation and ML feature engineering that powers the Machine Learning technologies we all love in our Apple devices. Our mission is to provide cutting edge, reliable and easy to use infrastructure for ingesting, storing, processing and interacting with data while keeping Apple’s users’ data private and secure.
Key Qualifications
5 years of experience in software engineering with deep knowledge in computer science fundamentals.
Strong in data structures and algorithms. Must write good quality code with test cases and review PR's in fast faced environment.
Expert in one or more functional or object-oriented programming languages (Scala, Java)
Fluent in at least one scripting or systems programming language (Python, Bash and Go etc.)
Experience or knowledge in distributed data systems like Hadoop, Spark, Kafka or Flink.
Experience or knowledge in public cloud is a big plus, preferably AWS.
Strong collaboration and communication (verbal and written) skills to work with diff
Description
The role involves managing petabytes of data for machine learning applications and designing and implementing new frameworks to build scalable and efficient data processing workflows and machine learning pipelines. The successful candidate will be responsible for ensuring complete data lineage and legal workflow integration while optimizing performance and scalability. You will also be responsible for monitoring the performance of the system, optimizing it for cost and efficiency, and solving any issues that arise. This is an exciting opportunity to work on cutting-edge technology and collaborate with cross-functional teams to deliver high-quality software solutions. The ideal candidate should have a strong background in software development, experience with public cloud platforms, and familiarity with distributed databases.
Education & Experience
BS, MS, or PhD degree in Computer Science or equivalent
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700 and $300,200, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"ADT
3.1",3.1,"Boca Raton, FL",Data Engineer,"Company Overview:

ADT has been in the business of helping save lives since 1874. As the #1 smart home security provider in the U.S., we help protect and connect families, businesses and larger commercial customer every day. Our continuous innovation, advanced technology and strategic partnerships deliver products and services that help protect life and valuables, whether at home, your business or on the go. And as times change, so do we. Above all, our mission is clear: we help save lives for a living. Looking for a career where you can make a real impact? Join our team today and put purpose behind your paycheck. #WeAreADT
Check out more about life at ADT here.
Position Summary: Senior Data Engineer is responsible for developing and governing our data and information strategy in order to drive business decisions and growth. You will develop data procedures and policies and work closely with the various departments to collect, prepare, organize, protect, and analyze data assents while ensuring that the company meets industry best practices. Other duties will include leading inter-disciplinary teams, improving and streamlining data systems within the company and driving innovation.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Thorough understanding of the business and data strategy.
Designing and implementing data strategies and systems.
Overseeing the collection, storage, management, quality and protection of data.
Implementing data privacy policies and complying with data projection regulations.
Determine where to cut costs and increase revenue based on insights derived from data.
Effectively communicate the status, value, and importance of data collection to executive members and staff.
Knowledge of relevant applications, big data solutions and tools.
Competencies: To perform the job successfully, an individual should demonstrate the following:
Achievement Focus - Demonstrates persistence and overcomes obstacles. Measures self against standard of excellence. Recognizes and acts on opportunities. Sets and achieves challenging goals. Takes calculated risks to accomplish goals.
Business Acumen - Aligns work with strategic goals. Conducts cost-benefit analyses. Demonstrates knowledge of market and competition. Displays orientation to profitability. Understands business implications of decisions.
Business Ethics - Inspires the trust of others. Keeps commitments. Treats people with respect. Upholds organizational values. Works with integrity and ethically.
Managing Customer Focus - Develops new approaches to meeting customer needs. Establishes customer service standards. Monitors customer satisfaction. Promotes customer focus. Provides training in customer service delivery.
Strategic Thinking - Adapts strategy to changing conditions. Analyzes market and competition. Develops strategies to achieve organizational goals. Identifies external threats and opportunities. Understands organization's strengths & weaknesses.
Visionary Leadership - Acts in accordance with vision. Communicates vision and gains commitment. Creates a clear, compelling vision. Displays passion and optimism. Mobilizes others to fulfill the vision.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education/Experience:
Bachelor’s degree in information technology of related field. Master’s degree preferred. 5 to 10 years’ experience in a senior level data management role.
Language Ability:
Read, analyze, and interpret scientific and technical journals, financial reports, and legal documents. Respond to inquiries or complaints from customers, agencies, or members of the business community. Write speeches and articles for publication.
Mathematical Ability:
Apply advanced concepts such as exponents, logarithms, quadratic equations, and permutations. Apply operations to such tasks as frequency distribution, test reliability/validity, variance analysis, correlation technique, sampling theory and factor analysis.
Reasoning Ability:
Define problems, collect data, establish facts, and draw valid conclusions. Interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The noise level in the work environment is usually moderate.
Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is frequently required to sit and use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand and walk. The employee must be able to occasionally lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
The above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow any other instructions, and perform any other related duties, as assigned by their supervisor.
Compensation:
The salary range for this role is $73,066-$146,131 and is based on experience and qualifications.
Certain roles are eligible for annual bonus and may include equity. These awards are allocated based on company and individual performance.
We offer employees access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, life insurance, wellbeing benefits and paid time off among others. Employees accrue up to 120 hours in their first year. Your accrual rate increases after your first year. We also offer 6 paid holidays.


ADT is an Equal Employment Opportunity (EEO) Employer. We celebrate diversity and are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. ADT strives to ensure every employee and applicant feels valued. Visit us at jobs.adt.com/diversity to learn more.","$109,599 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Security & Protective,1874,$5 to $10 billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"NVR, Inc
3.7",3.7,"Frederick, MD",Data Engineer,"NVR is looking for a talented Data Enginneer to work onsite in Frederick, MD. Join our industry leading technology organization and be a part of making someone’s dream home a reality!
As a Data Engineer, you will be responsible for the day-to-day operations of data-dependent systems to ensure data is properly processed and securely transferred to its appropriate location, in a timely manner. If you are a recent graduate or an engineer early in your career, this is a great opportunity for you to leverage your computer knowledge and analytical skills by getting involved in projects and gaining exposure to cloud technologies, data and analytics!
Key Job Responsibilities:
Keeping the data flowing by working with SQL, SQL Server, SSRS and SSIS
Managing, manipulating, storing, and parsing data on premises and in the cloud.
Collaborate with the team to solve support issues.
Interact with business and IT teams of various applications to understand their data, database, and flow within the systems.
Create logical mapping of source data into target data models, based on business process and data/reporting requirements.
Job Qualifications:
0-3 years of experience in data management (integration, modeling, optimization, and quality).
Experience or coursework with databases and queries
Excellent written and verbal communication skills, interpersonal and collaborative skills.
Must have strong problem-solving and analytical skills.
High degree of initiative and be well organized.
Ability to manage multiple projects with strict timelines.
Here’s what will put you ahead of the pack:
Understanding of data modeling, structured and unstructured data, and data transformation techniques.
Experience or coursework using visualization tools like Tableau or Power BI.
Microsoft Azure Certifications.
About Us & Life at NVR
NVR has been helping families build their happily ever after since 1948. As a Top 5 US homebuilder, we’re committed to quality and to our customers and we take pride in the over 500,000 new homes we have sold and built across the country. Working in the homebuilding industry is tangible and rewarding, but not every job at NVR requires a hard hat. We don’t just sell and build new homes; we also manage teams, acquire land, manufacture materials, provide mortgages to our customers, and provide corporate support to NVR’s multi-billion dollar business operations.
At NVR, we value our teams and provide opportunities to learn new technologies and skills to grow your career. Your desire to excel is matched by our commitment to your success and we’ll give you the tools and industry knowledge you need. Our management team is tenured and talented, nearly 80% of them promoted from within, so you’ll find mentors who can share their knowledge, provide career guidance and encourage your success.
NVR also offers benefits among the best in the industry that reflect the strong commitment we have to all of our employees.
Competitive Compensation
Home Purchase Discount
Mortgage and Settlement Services Discounts
Comprehensive Health, Life and Disability Insurance
401(k) (Full-time employees are eligible to contribute immediately)
Employee Stock Ownership Program
Vacation and Holidays
In addition to the traditional benefits, we offer all our employees stock ownership through a profit sharing trust as part of our retirement savings package. NVR has had the highest Earnings Per Share growth rate in the homebuilding industry for the past 10 years, so as we grow financially, so do you.
We are an Equal Opportunity Employer.
Drug Testing and Credit Check are required.
Applicants must be legally entitled to work in the United States, as NVR does not provide visa sponsorships.","$71,504 /yr (est.)",5001 to 10000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Construction,1948,$10+ billion (USD)
"Ascendion
4.3",4.3,"Saint Louis, MO",Product Data Management Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:

Job Title: Product Data Mgmt Engr

Key Responsibilities:
Job Description:
Collaborates with teams in the development, analysis, management and compliance verification of process and product baselines of complex products.
Defines, plans, coordinates and conducts product and subsystem level technical design reviews and audits for new and derivative products.
Analyzes complex product trades and/or changes and develops technically complete change proposals.
Contributes to the development and implementation of Configuration and Data Management standards, processes and tools.
Defines and allocates Configuration and Data Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Coordinates the integration of product elements and analyzes & resolves issues with engineering product structure.
Develops, integrates and implements engineering technical program plans including impacts, risks and incorporation of lessons learned spanning multiple engineering functions.

Location: St. Louis, MO

Salary Range: The salary for this position is between $99,000 – $1,12,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
Preferred Skills:
Data Mangement
Configuration
Job details
Job ID
328163
Job Requirements
Product Data Management Engineer
Location
St. Louis, Missouri, US
Recruiter
Ashok
Email
ashok.kundu@ascendion.com","$96,323 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"Three Ships Media
3.4",3.4,"Charlotte, NC",Data Analytics Engineer,"Role Overview:
3S Health is seeking a hands-on, self-motivated Data Analytics Engineer to own our data analytics pipeline for one of our fastest growing businesses. In this role, you will be responsible for collecting and modeling data through the deployment of modern cloud tools, and turning that data into insights through the building of dashboards and reports. This role is for the data engineer that seeks to get closer to the business, or the business analyst that seeks to dive deeper into understanding where their data comes from.
What you'll Do:
Create and maintain scalable data pipeline through combination of modern SaaS applications and custom-built solutions
Create and maintain business intelligence roadmap to help enable business goals
Partner with business users to gather and understand data requirements
Extract data from sources through custom-built data integrations (typically Python) with discipline towards automation
Write SQL-based transformations to turn raw data into production-ready business models
Develop and manage business and executive team dashboards
Create and maintain data storage systems
Develop data discoverability tools and data monitoring systems

What You'll Bring:
Proficiency in SQL and Python (and/or proven ability to pick up a new language)
Proven ability to operate autonomously to achieve results.
Optional experience in Data Build Tool (DBT) or other SQL-based transformation tools
General understanding of the Marketing Technology stack, components, and best-practices. An ideal candidate will have some familiarity with common marketing tools (Google Analytics, Tag Manager, Segment (CDP), Facebook Ads, etc.)
Experience with common enterprise analytics tools with proven ability to translate data insights into action (Tableau, PowerBI, Looker Studio, Superset, etc.)
Working knowledge of software development best practices as they apply to data engineering, including: Version Control, Unit Testing, and Continuous Integration/Continuous Delivery (CI/CD)
The Package
As a full-time employee of Three Ships, you’ll have access to competitive benefits, including flexible time off, health/dental/vision, 401k match, an annual Relax & Recharge Bonus, an annual Learning & Development stipend to enroll in class(es) of your choosing, and up to $75 mobile reimbursement. If you join us in person in our Raleigh or Charlotte locations, we have an office stocked with snacks, coffee, and just about every other beverage you can imagine.
How We Hire
All applicants are considered without regard to race, color, religion, sex, national origin, age, disability, veteran status, gender identity, or any other discriminatory factors. Please note that we do not provide immigration sponsorship for this role. All offers are subject to a background check.","$92,505 /yr (est.)",51 to 200 Employees,Company - Private,Media & Communication,Advertising & Public Relations,2009,Unknown / Non-Applicable
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Analytica
3.4",3.4,Remote,Data Engineer,"Analytica is seeking a remote Data Engineer to support a high-profile financial regulatory client with developing data pipeline and ETL solutions in an AWS cloud environment.
Analytica has been recognized by Inc. Magazine as a fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.
Responsibilities include (but not limited to):
Develops tools and infrastructure for data processing use cases
Designs and builds data pipelines that ingest and transform data using programming languages such as Python and SQL, and data orchestration tools
Designs, builds, and maintains data storage and processing infrastructure that allows working nimbly through extensive amounts of analytics data
Build and deliver data lake, integrate with existing data catalog prototype, and migrate to big data applications from on-premise to the new computing platform by leveraging new technologies (such as Apache Spark)
Qualifications:
Bachelor's degree in information systems, computer science, engineering, finance, or related degree or functional discipline
At least three (3) years of experience building flexible and scalable ETL processes and data pipelines
Extensive experience developing in Python and SQL
Should be well organized, thorough, and able to handle competing priorities
Knowledge and experience with Agile, Scrum, and DevOps principles and practices
Experience in any big data technologies - Hadoop, Amazon Redshift, AWS DevOps, Azure CosmosDB, Azure Data Lake, AWS DynamoDB, or advanced analytics tools will be plus
VeDM6NPQva",#N/A,51 to 200 Employees,Company - Private,Information Technology,Information Technology Support Services,2009,$5 to $25 million (USD)
"DraftKings
4.0",4.0,Remote,SENIOR DATA ENGINEER,"REMOTE - US
ENGINEERING
JR07222
FULL TIME
At DraftKings, we're inspired by our shared passion for developing creative solutions to complex challenges and empowering the people around us to do their best work. We are industry leaders in the digital entertainment and technology space and are propelled by constant curiosity and diverse perspectives.
LOVE DATA? WE DO TOO.
We are looking for a Senior Data Engineer to join our BI Dashboarding team, who will play a vital role in our organization's data-driven approach. Your responsibilities will include designing and developing visually compelling and insightful reports and dashboards to provide actionable insights to various stakeholders. Additionally, you will optimize report performance, and data pipelines, create and optimize Directed Acyclic Graphs (DAGs), automate reports and processes, create Tableau reports, and maintain the Tableau server. Sounds good to you? Join us.
WHAT YOU’LL DO AS A SENIOR DATA ENGINEER:
Design processes that support data transformation, structures, metadata, dependency, and workload management.
Work with product owners and tech leads to implement high-quality, production-grade data pipelines and ETL processes.
Partner with our stakeholders to build reports that provide insights about key business metrics.
Leverage your strong communication skills and experience working with global teams to be an evangelist for data engineering across the organization.
Be flexible and able to adapt rapidly. We roll out products very quickly, and priority management is critical.
Utilize your experience to mentor, guide, and advise on best practices for delivering performant solutions.
Drive an organizational focus on performance analysis, optimization, and tuning.
WHAT YOU’LL BRING:
3+ years of hands-on experience with business intelligence and data engineering, including data warehousing, delivery, and operations.
The ability to leverage new technologies to test, build, and optimize data pipelines, transformations, architectures, and data sets.
Strong knowledge of various data engines (SQL Server, MySQL, Amazon Aurora, Redshift). Snowflake experience is a big plus.
A solid understanding of dimensional modeling is required.
Excellent communication and interpersonal skills to effectively communicate with business and technical teams.
Experience with data reporting tools (e.g., Tableau), data cataloging tools (e.g., Alation), and data logging/monitoring tools (e.g., Datadog) is preferred.
Experience in the i-Gaming industry is a big plus.
#LI-CG1
JOIN US!
Our teams are fueled by innovation. We are looking ahead, building what’s next, and continuously reinventing the industry. We’re a publicly traded (NASDAQ: DKNG) technology company headquartered in Boston, with teams around the world and an expanding global presence.
We strive to create a place where all feel safe, empowered, engaged, championed, and inspired. DraftKings is proud to be an equal opportunity employer. This means we do not tolerate discrimination of any kind and are committed to providing equal employment opportunities regardless of your gender identity, race, nationality, religion, sexual orientation, status as a protected veteran, or status as an individual with a disability.
READY TO BUILD WHAT’S NEXT? APPLY NOW.
As a regulated gaming company, you may be required to obtain a gaming license issued by the appropriate state agency as a condition of employment.
The US base salary range for this full-time position is $116,800.00 - $175,200.00, plus bonus, equity, and benefits as applicable. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range and how that was determined during the hiring process.",#N/A,1001 to 5000 Employees,Company - Public,Information Technology,Internet & Web Services,2012,Unknown / Non-Applicable
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
The position requires a Master’s degree in Computer Science, Engineering (any), or any technical/analytical field that is closely related to the specialty, plus one (1) year of experience in an IT/Computer-related position.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Lexicon
3.2",3.2,"Maryland Heights, MO",Data Engineer,"Lexicon Data Engineer
The Lexicon Data Engineer will develop and optimize data pipelines for scalability and performance for datasets of all sizes. As the Data Engineer, you will work closely with the Database Administrator to build and maintain the Lexicon data warehouse; you will support data science by preparing data for data mining, modeling, and reporting; and you will support software development by assisting with database development and data migration efforts.
About Us
Lexicon is a legal services and technology provider with deep expertise in the legal industry. We provide a world-class practice management software suite, enabling attorneys to maximize productive use of their time when working cases. With expertise in marketing for law firms, revenue optimization, billing and collections, support services, and more, Lexicon is your trusted partner for all legal practice needs.
This is a Permanent (Hybrid), Full-time opportunity. 1099/C2C employees will not be considered.

Qualifications
Degree in Computer Science, IT or similar field from an accredited institution required, Master’s degree is a plus
5+ years’ experience as a Data Engineer or in a similar role
Strong T-SQL and data management skills
Experience with Data Model design and Data warehouse concepts
Experience with Azure Data Warehouse, Azure Data Factory, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Azure Data Engineer certification is a plus
Functional knowledge of programming languages (e.g., .NET framework, PowerShell, Python, R)
Technical expertise with data mining and machine learning techniques is preferred
Experience with PowerBI a plus
Familiarity with NoSQL data structures and search engine optimization is a plus
Strong communication, analytical, and numerical skills
Responsibilities
Develop algorithms to transform data into useful, actionable information.
Identify and acquire new data sources and assemble complex datasets that align with business needs.
Create and maintain data pipeline infrastructure for optimal extraction, transformation, and loading of data from various data sources using Azure and SQL technologies.
Identify, design, and implement internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.
Implement processes and systems to monitor data quality, troubleshoot and resolve data related issues, and improve data reliability and quality.
Work with stakeholders including the executive leadership, data science, and software development to evaluate business objectives, support data infrastructure needs, and assist with data-related technical issues.
Collaborate with data science team to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.
Ensure compliance with data governance and security policies
Maintain documentation for database and data pipeline infrastructure
Lexicon provides exceptional benefits and a great working environment including:
Participate in our Wellness Program and earn 100% Employer paid health premiums
Employer paid dental premiums
Employer paid Life, LTD & STD premiums
401k & Profit Sharing
Flexible spending plans
& More!","$88,164 /yr (est.)",51 to 200 Employees,Company - Private,Legal,Legal,2008,Unknown / Non-Applicable
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
Hummingbird,#N/A,Remote,Data Engineer,"Hummingbird is a remote-first, fully distributed team united by the shared mission of helping fight financial crime. Since our launch in 2017, we’ve helped major financial institutions and tech-savvy trailblazers alike (e.g. Stripe, Affirm, etc.) orchestrate their compliance programs through our thoughtfully designed, intuitive SaaS product. We believe finding and stopping financial crime is a problem rooted in code, language and design, so we built the product that the heroes doing this work deserve.
We are customer-obsessed, and we love building and shipping great products. We set a high bar, challenge our assumptions, seek diverse opinions, and support each other to do our best work.
We do our best to write inclusive, descriptive and accurate job descriptions, but we’re not always perfect. If you’re interested in the role, we’d love to hear from you even if you don’t feel like you meet everything we’re looking for. We’re always iterating and improving, and it’s possible that your experience is even more impactful than we could have imagined.

About the Role
We are looking for a driven data engineer to join our team and champion the use of data at Hummingbird. Data plays a crucial role in our mission to fight financial crime and you will help us find new and innovative ways to leverage it to provide powerful tools for our users, and allow us to better understand the usage of our product. Hummingbird is uniquely positioned at the intersection of financial technology, security, policy, and law enforcement and as such we have built up a one of a kind data set that we can now use to give our customers the edge in their efforts to stay ahead of criminals. As an employee at a small startup, you will have the opportunity to wear many hats, working from product discovery through implementation.
What you’re looking to do:
Level up our use of data to make better decisions, build more powerful features, and fight financial crime
Leverage Infrastructure as Code (IaC) to manage and deploy infrastructure that supports a variety of different projects, such as data replication and orchestration for machine learning workflows
Build new data pipelines for ingesting data into our data warehouse via both batch and streaming architectures
Work closely with data science to enable us to build products that benefit our customers while keeping compliance and security at the forefront
Achieve goals through a combination of independent building, educating your peers, and influencing others to contribute towards your vision
What we’re looking for:
A data engineer with a history of taking projects from the earliest stages through successful rollout to production
Someone who is excited by the prospect of pioneering data as a practice at a fast growing startup and who is unafraid to dig in to discover what is possible
A flexible self starter that will cut across organizational lines to understand the business and identify the most valuable work
An engineer who brings a pragmatic approach to problem solving, favoring simplicity and shortening delivery cycles
Experience building data pipelines for sensitive data, including best practices for de-identification and data security
Experience deploying infrastructure via terraform or a similar infrastructure as code tool
Expertise in SQL and one or more programming languages, especially python
What’s in it for you:
The chance to help build from the ground up. The hires we’re making now are foundational to our growth as a company, so you will have an opportunity to help shape the future of Hummingbird.
Competitive compensation including cash and equity.
Remote-first, fully distributed company with flexible working hours.
Awesome health, vision & dental benefits, and 401k.
Safe, respectful & comfortable work environment with colleagues and leadership who prioritize diversity, equity, inclusion, and belonging.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please don't hesitate to contact us to request accommodation.",#N/A,Unknown,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"ADT
3.1",3.1,"Boca Raton, FL",Data Engineer,"Company Overview:

ADT has been in the business of helping save lives since 1874. As the #1 smart home security provider in the U.S., we help protect and connect families, businesses and larger commercial customer every day. Our continuous innovation, advanced technology and strategic partnerships deliver products and services that help protect life and valuables, whether at home, your business or on the go. And as times change, so do we. Above all, our mission is clear: we help save lives for a living. Looking for a career where you can make a real impact? Join our team today and put purpose behind your paycheck. #WeAreADT
Check out more about life at ADT here.
Position Summary: Senior Data Engineer is responsible for developing and governing our data and information strategy in order to drive business decisions and growth. You will develop data procedures and policies and work closely with the various departments to collect, prepare, organize, protect, and analyze data assents while ensuring that the company meets industry best practices. Other duties will include leading inter-disciplinary teams, improving and streamlining data systems within the company and driving innovation.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Thorough understanding of the business and data strategy.
Designing and implementing data strategies and systems.
Overseeing the collection, storage, management, quality and protection of data.
Implementing data privacy policies and complying with data projection regulations.
Determine where to cut costs and increase revenue based on insights derived from data.
Effectively communicate the status, value, and importance of data collection to executive members and staff.
Knowledge of relevant applications, big data solutions and tools.
Competencies: To perform the job successfully, an individual should demonstrate the following:
Achievement Focus - Demonstrates persistence and overcomes obstacles. Measures self against standard of excellence. Recognizes and acts on opportunities. Sets and achieves challenging goals. Takes calculated risks to accomplish goals.
Business Acumen - Aligns work with strategic goals. Conducts cost-benefit analyses. Demonstrates knowledge of market and competition. Displays orientation to profitability. Understands business implications of decisions.
Business Ethics - Inspires the trust of others. Keeps commitments. Treats people with respect. Upholds organizational values. Works with integrity and ethically.
Managing Customer Focus - Develops new approaches to meeting customer needs. Establishes customer service standards. Monitors customer satisfaction. Promotes customer focus. Provides training in customer service delivery.
Strategic Thinking - Adapts strategy to changing conditions. Analyzes market and competition. Develops strategies to achieve organizational goals. Identifies external threats and opportunities. Understands organization's strengths & weaknesses.
Visionary Leadership - Acts in accordance with vision. Communicates vision and gains commitment. Creates a clear, compelling vision. Displays passion and optimism. Mobilizes others to fulfill the vision.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education/Experience:
Bachelor’s degree in information technology of related field. Master’s degree preferred. 5 to 10 years’ experience in a senior level data management role.
Language Ability:
Read, analyze, and interpret scientific and technical journals, financial reports, and legal documents. Respond to inquiries or complaints from customers, agencies, or members of the business community. Write speeches and articles for publication.
Mathematical Ability:
Apply advanced concepts such as exponents, logarithms, quadratic equations, and permutations. Apply operations to such tasks as frequency distribution, test reliability/validity, variance analysis, correlation technique, sampling theory and factor analysis.
Reasoning Ability:
Define problems, collect data, establish facts, and draw valid conclusions. Interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The noise level in the work environment is usually moderate.
Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is frequently required to sit and use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand and walk. The employee must be able to occasionally lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
The above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow any other instructions, and perform any other related duties, as assigned by their supervisor.
Compensation:
The salary range for this role is $73,066-$146,131 and is based on experience and qualifications.
Certain roles are eligible for annual bonus and may include equity. These awards are allocated based on company and individual performance.
We offer employees access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, life insurance, wellbeing benefits and paid time off among others. Employees accrue up to 120 hours in their first year. Your accrual rate increases after your first year. We also offer 6 paid holidays.


ADT is an Equal Employment Opportunity (EEO) Employer. We celebrate diversity and are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. ADT strives to ensure every employee and applicant feels valued. Visit us at jobs.adt.com/diversity to learn more.","$109,599 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Security & Protective,1874,$5 to $10 billion (USD)
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"NVR, Inc
3.7",3.7,"Frederick, MD",Data Engineer,"NVR is looking for a talented Data Enginneer to work onsite in Frederick, MD. Join our industry leading technology organization and be a part of making someone’s dream home a reality!
As a Data Engineer, you will be responsible for the day-to-day operations of data-dependent systems to ensure data is properly processed and securely transferred to its appropriate location, in a timely manner. If you are a recent graduate or an engineer early in your career, this is a great opportunity for you to leverage your computer knowledge and analytical skills by getting involved in projects and gaining exposure to cloud technologies, data and analytics!
Key Job Responsibilities:
Keeping the data flowing by working with SQL, SQL Server, SSRS and SSIS
Managing, manipulating, storing, and parsing data on premises and in the cloud.
Collaborate with the team to solve support issues.
Interact with business and IT teams of various applications to understand their data, database, and flow within the systems.
Create logical mapping of source data into target data models, based on business process and data/reporting requirements.
Job Qualifications:
0-3 years of experience in data management (integration, modeling, optimization, and quality).
Experience or coursework with databases and queries
Excellent written and verbal communication skills, interpersonal and collaborative skills.
Must have strong problem-solving and analytical skills.
High degree of initiative and be well organized.
Ability to manage multiple projects with strict timelines.
Here’s what will put you ahead of the pack:
Understanding of data modeling, structured and unstructured data, and data transformation techniques.
Experience or coursework using visualization tools like Tableau or Power BI.
Microsoft Azure Certifications.
About Us & Life at NVR
NVR has been helping families build their happily ever after since 1948. As a Top 5 US homebuilder, we’re committed to quality and to our customers and we take pride in the over 500,000 new homes we have sold and built across the country. Working in the homebuilding industry is tangible and rewarding, but not every job at NVR requires a hard hat. We don’t just sell and build new homes; we also manage teams, acquire land, manufacture materials, provide mortgages to our customers, and provide corporate support to NVR’s multi-billion dollar business operations.
At NVR, we value our teams and provide opportunities to learn new technologies and skills to grow your career. Your desire to excel is matched by our commitment to your success and we’ll give you the tools and industry knowledge you need. Our management team is tenured and talented, nearly 80% of them promoted from within, so you’ll find mentors who can share their knowledge, provide career guidance and encourage your success.
NVR also offers benefits among the best in the industry that reflect the strong commitment we have to all of our employees.
Competitive Compensation
Home Purchase Discount
Mortgage and Settlement Services Discounts
Comprehensive Health, Life and Disability Insurance
401(k) (Full-time employees are eligible to contribute immediately)
Employee Stock Ownership Program
Vacation and Holidays
In addition to the traditional benefits, we offer all our employees stock ownership through a profit sharing trust as part of our retirement savings package. NVR has had the highest Earnings Per Share growth rate in the homebuilding industry for the past 10 years, so as we grow financially, so do you.
We are an Equal Opportunity Employer.
Drug Testing and Credit Check are required.
Applicants must be legally entitled to work in the United States, as NVR does not provide visa sponsorships.","$71,504 /yr (est.)",5001 to 10000 Employees,Company - Public,"Construction, Repair & Maintenance Services",Construction,1948,$10+ billion (USD)
"KBX
3.8",3.8,"Green Bay, WI",Data Engineer,"Your Job
KBX Technology Solutions, LLC, a provider of transportation technology to industry leaders, is seeking a Data Engineer. This role will be responsible for designing, developing, and maintaining data systems and infrastructure required to support data processing and analysis. You will work closely with a team of professionals to understand business requirements and build scalable solutions to handle large volumes of data. A successful candidate will have strong programming skills, experience with database technologies, and a deep understanding of data management and processing.
This role is not open to Visa Sponsorship now or in the future.
What You Will Do

Collaborate with cross-functional teams to understand data requirements and design data pipelines that align with business needs.
Develop and implement ETL processes to ingest, cleanse, and transform data from diverse sources into the data warehouse.
Optimize and tune data pipelines to ensure high performance and reliability in handling large volumes of data.
Troubleshoot and resolve issues related to data pipeline failures, data quality, and data integration challenges.
Work closely with data architects and database administrators to ensure seamless integration and data consistency.
Design and implement data models and schemas to support data warehouse solutions efficiently.
Monitor data pipeline performance and implement improvements to enhance data processing efficiency.
Ensure data security and compliance with data privacy regulations throughout the data pipeline process.
Continuously explore and evaluate new technologies and tools to enhance data pipeline capabilities.
Document data pipelines, data flows, and technical specifications for future reference and team collaboration.
Provide technical guidance and mentorship to junior team members in data engineering best practices.
Who You Are (Basic Qualifications)

Strong knowledge in Python, SQL, data warehouse systems, data lake systems, and data pipelines on AWS or similar cloud environments
Professional experience of data engineering concepts (ETL, data warehousing, near-/real-time streaming, data structures, metadata, and workflow management)
Strong experience with ETL tools like Apache Spark, Talend, or AWS Glue.
Strong programming skills and experience using source control platforms like Gitlab, GitHub, etc.
Knowledge of data management, stewardship, and governance concepts
Experience delivering advance analytics solutions, reporting, and managing big data
What Will Put You Ahead

Strong communication & collaboration skills
Familiarity with cloud platforms like Snowflake, AWS, Azure, or Google Cloud, and hands-on experience with relevant data services.
Understanding of data streaming platforms like Apache Kafka for real-time data processing.
Experience with API integration and handling semi-structured data
Experience developing with dockers in a Kubernetes environment.
An understanding of modern cloud infrastructure, container-based deployments, and storage architectures
Has worked in an Agile environment and is proficient using tools like Azure DevOps, Jira, etc.
Experience with data visualization tools such as Tableau or Power BI
Experience working in transportation management
At Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.
For this role, we anticipate paying $95,000 - $135,000 per year. This role is eligible for variable pay, issued as a monetary bonus or in another form.
Hiring Philosophy
All Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here .
Who We Are
As a Koch company, KBX provides the global transportation, logistics and technology solutions that help our customers deliver life's essentials to people all over the world. We develop and deploy cutting-edge technologies to deliver better solutions for increasingly complex supply chains. Our team of tenacious problem-solvers are driven to create real, long-term value for our customers.
At Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.
Our Benefits
Our goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.
Equal Opportunities
Equal Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf","$115,000 /yr (est.)",10000+ Employees,Company - Private,"Energy, Mining & Utilities",Energy & Utilities,1940,$10+ billion (USD)
"Capgemini
3.8",3.8,"Seattle, WA",Data Engineer,"Duration: 4+ months

Job Description:

Support ML projects from strategy through implementation and on-going improvements.
Perform data collection, analysis, validation, cleansing, developing software in support of multiple machine learning workflows, integrating / deployment of code in a large-scale production environments and reporting.
Designs, codes, tests, debugs, and documents ML code - models, ETL processes, SQL queries, and stored procedures.
Extracts and analyzes data from various structured and unstructured sources, including databases, files, data lakes and external APIs/websites.
Responds to data inquiries from various groups within clients organization.
Requires experience with relational databases, document databases (NOSQL) and knowledge of
query tools and/or statistical software.
Responsible for other duties/projects as assigned by business management / leadership.

Qualifications Minimum Required:
7 plus years of experience in statistical modeling, data mining, analytics techniques, machine
learning software development and reporting
5 plus years of applied experience in building / deploying Machine Learning solutions using
various supervised/unsupervised ML algorithms such as Linear/Logistic Regression, Support Vector Machines, (Deep) Neural Networks, Random Forest, etc., and key parameters that affect their performance.
5 plus years of hands-on experience with Python and/or R programming and statistical packages, and ML libraries such as scikit-learn, TensorFlow, PyTorch, etc.
3 plus years of experience in building use cases / solutions especially around AI/ based on Cloud infrastructure and services such as Azure, GCP, AWS cloud platforms and Onpremise environments
Expertise with SQL, noSQL, Python, R, Javascript programming languages and big data environments (such as Splunk, Hadoop, Spark, Flink, Stream Analytics, Kafka, Docker, Kubernetes etc.)
Experience developing experimental and analytic plans for data modeling processes, using strong baselines, and determining cause and effect relations.
Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. in data analysis projects.
Expertise with scaling pilot machine learning solutions to a large scale production environment using databricks
Expertise with visualization tools such as PowerBI, D3JS etc.
Excellent written and verbal communication skills.

Desired:
Bachelor or Masters degree in highly quantitative field (computer science, or electrical engineering, mathematics, statistics) or equivalent domain specific experience in lieu of a degree.
Proficient in machine learning data workflows, data collection methodologies, and data analysis.
Experience with architecting, designing, developing software solution in Azure and on-prem

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","$102,887 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,1967,$10+ billion (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"Ascendion
4.3",4.3,"Saint Louis, MO",Product Data Management Engineer,"Description
About Ascendion
Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.
Ascendion | Engineering to elevate life
We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:
Build the coolest tech for world’s leading brands
Solve complex problems – and learn new skills
Experience the power of transforming digital engineering for Fortune 500 clients
Master your craft with leading training programs and hands-on experience
Experience a community of change makers!
Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.
About the Role:

Job Title: Product Data Mgmt Engr

Key Responsibilities:
Job Description:
Collaborates with teams in the development, analysis, management and compliance verification of process and product baselines of complex products.
Defines, plans, coordinates and conducts product and subsystem level technical design reviews and audits for new and derivative products.
Analyzes complex product trades and/or changes and develops technically complete change proposals.
Contributes to the development and implementation of Configuration and Data Management standards, processes and tools.
Defines and allocates Configuration and Data Management requirements for product hardware, software and engineering design data systems throughout the product lifecycle.
Coordinates the integration of product elements and analyzes & resolves issues with engineering product structure.
Develops, integrates and implements engineering technical program plans including impacts, risks and incorporation of lessons learned spanning multiple engineering functions.

Location: St. Louis, MO

Salary Range: The salary for this position is between $99,000 – $1,12,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.

Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day(s) accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day(s) of paid vacation time] [6 paid holiday(s) and 1 floating holiday per calendar year] [Ascendion Learning Management System]

Want to change the world? Let us know.
Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!
Preferred Skills:
Data Mangement
Configuration
Job details
Job ID
328163
Job Requirements
Product Data Management Engineer
Location
St. Louis, Missouri, US
Recruiter
Ashok
Email
ashok.kundu@ascendion.com","$96,323 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Software Development,2022,Unknown / Non-Applicable
"Runway AI
5.0",5.0,Remote,"Staff Software Engineer, Data Infrastructure","At Runway, we believe everyone has a story to tell. Our mission is to make professional video and content creation accessible to all. We are taking recent advancements in computer graphics, the web, and machine learning to push the boundaries of creativity and in turn, lower the barriers of content creation; unfastening a new wave of storytelling
Over the last four years, we’ve raised funding from top-tier investors and partners including Amplify, Coatue, Compound, Felicis, Google, Lux, NVIDIA, and Salesforce. Our team consists of creative, open minded, caring, and entrepreneurial individuals from all walks of life. We aspire to build incredible things which starts with building an incredible team, so we’d love to hear from you!
About the role
We’re looking for a strong Staff Software Engineer to help us build scalable and robust data infrastructure to power Runway’s applied research. You will be the first hire in a new team that’s focused on building data pipelines to support all of Runway’s generative model training and continuous model improvement. The best fit for this role has experience with building large-scale systems for analysis, curation, and retrieval of multimodal data, as well as strong system design and collaboration skills.
What you’ll do
Build out pipelines for the creation, curation, and processing of large-scale multimodal datasets
Create internal tooling to enable Runway’s applied research team to build workflows and run experiments on that infrastructure
What you’ll need
Strong knowledge of Python
Experience with one or more frameworks for large-scale data processing (e.g. Spark, Ray, etc) and one or more ML frameworks (e.g. PyTorch, JAX)
Experience building out data pipelines from scratch and optimizing those pipelines for high performance and great developer experience
Familiarity and experience with AWS and/or GCP is a bonus
Runway strives to recruit and retain exceptional talent from diverse backgrounds while ensuring pay equity for our team. Our salary ranges are based on competitive market rates for our size, stage and industry, and salary is just one part of the overall compensation package we provide.
There are many factors that go into salary determinations, including relevant experience, skill level and qualifications assessed during the interview process, and maintaining internal equity with peers on the team. The range shared below is a general expectation for the function as posted, but we are also open to considering candidates who may be more or less experienced than outlined in the job description. In this case, we will communicate any updates in the expected salary range.
Lastly, the provided range is the expected salary for candidates in the U.S. Outside of those regions, there may be a change in the range, which again, will be communicated to candidates.
Salary range: $190,000-230,000

Working at Runway
We are a small and growing team of artists, engineers, researchers, and dreamers working together to reimagine creativity. And we’re building a unique team of talented individuals from diverse backgrounds. We believe that this will allow us to continue to up-level each other, our company, and our product. We’re looking for people that will add to our culture, not just fit in.
We’re committed to creating a space where our employees can bring their full selves to work and have equal opportunity to succeed. So regardless of race, gender identity or expression, sexual orientation, religion, origin, ability, age, veteran status, if joining this mission speaks to you, we encourage you to apply!","$210,000 /yr (est.)",51 to 200 Employees,Company - Private,Information Technology,Software Development,2018,Unknown / Non-Applicable
"Otter Products, LLC
3.1",3.1,Remote,Sr. Data Engineer,"Overview:
Otter Products is currently recruiting for a Sr. Data Engineer. You can be based in our Fort Collins, CO office with flexibility to work a portion of your time remotely, or 100% Remote in the U.S.

The Sr. Data Engineer will play a pivotal role in building and operationalizing the minimally inclusive data necessary for the enterprise data initiatives following industry standard practices and tools. The bulk of the Sr. Data Engineer’s work would be in designing, managing and optimizing data pipelines and then moving these data pipelines effectively into production for key data and analytics consumers like business/data analysts, data scientists or any persona that needs curated data for data and analytics use cases across the enterprise. The Sr. Data Engineer also needs to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for data and analytics initiatives. Additionally, the Sr. Data Engineers will also be expected to collaborate with data scientists, data architects, data analysts and other data consumers and work on the models and algorithms developed by them in order to optimize them for data quality, security and governance and put them into production leading to potentially large productivity gains.
About Otter Products: At Otter Products, we grow to give. From our founder’s garage in 1998 to the global technology leader we are today, Otter Products continues to drive growth through innovation. Through our industry-leading brands — OtterBox, Liviri and OtterCares — we provide our partners the number-one selling and most trusted products in our categories. Our philanthropic spirit is the foundation on which we foster our partner relationships, allowing us to grow and to give — together. By way of our charitable arm, the OtterCares Foundation, we support our communities and invest in our future through education that inspires kids to change the world. And even as our global community of Otters continues to grow, our founder’s core values are still at the heart of everything we do. We measure our success by our ability to give back to our communities and strengthen opportunities for all. For more information visit otterproducts.com Responsibilities:
Responsible for the verification and validation of data moving into or out of systems providing information to identify issues or inaccuracies in ETL pipelines from internal and external systems
Manage Azure Data Catalog and Business Glossary Application ensuring linage and data sources are mapped within the application
Primary lead working with data architects to define the development of data systems, creating data pipelines and optimizing ETL processes for ingest of data internally and externally
Primary resources to collaborate with a cross-functional team to determine requirements for data needs and requirements
Provide technical guidance and coaching to members of the data team
Set the standards on Power BI Dashboard/Reporting creation
Define and manage standards, guidelines, and processes to ensure data quality.
Oversee the creation and maintenance of Data Quality Metrics that drive improvement in Otter Products data quality
Develop and maintain the standards on ETL development within Otter
Define and own the release management process for ETL code deployment, including version control
Evaluate and recommend emerging technologies for data management, storage, and analytics
Support and maintain a positive safety culture by following all safety policies and procedures and actively contributing to a safe working environment
Other duties as required
Qualifications:
Bachelor’s degree required. Degree in Computer Science or Mathematics preferred.
Minimum of six years of experience in an IT or analytical role required. Experience in database development, report writing and/or statistics preferred.
EEO: Otter Products, LLC is an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, marital status, pregnancy, sex, sexual orientation, gender, gender identity or expression, national origin, disability, veteran status, or any other characteristic or status protected by law. For US Based Roles Only - Compensation Range Minimum: USD $110,000.00/Yr. For US Based Roles Only - Compensation Range Maximum: USD $135,000.00/Yr.","$110,000 /yr (est.)",501 to 1000 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1998,Unknown / Non-Applicable
"Caterpillar
4.0",4.0,"Chicago, IL",Software Engineer (Data Platform),"Career Area:
Digital
Job Description:
Your Work Shapes the World at Caterpillar Inc.
When you join Caterpillar, you're joining a global team who cares not just about the work we do – but also about each other. We are the makers, problem solvers, and future world builders who are creating stronger, more sustainable communities. We don't just talk about progress and innovation here – we make it happen, with our customers, where we work and live. Together, we are building a better world, so we can all enjoy living in it.
Software Engineer required for development and support for a new cloud platform and build RESTful services that feed data to front end applications ultimately supporting Caterpillar dealers and industry customers.
JOB DUTIES: As a Software Engineer you will be is responsible for designing and developing backend RESTful API web services using Microservices architecture.
Competent to perform all programming, project management, and development assignments without close supervision; normally assigned the more complex aspects of systems work.
Works directly on complex application/technical problem identification and resolution, including responding to off-shift and weekend support calls.
Works independently on complex systems or infrastructure components that may be used by one or more applications or systems.
Drives application development focused around delivering business valuable features.
Mentor and assist software engineers, providing technical assistance and direction as needed.
Maintains high standards of software quality within the team by establishing good practices and habits.
Identifies and encourage areas for growth and improvement within the team.
Guide the team to develop a structured application/interface code, new program documentation, operations documentation and user guides in a casual, flexible environment.
Communicate with end users and internal customers to help direct development, debugging, and testing of application software for accuracy, integrity, interoperability, and completeness.
Performs integrated testing and customer acceptance testing of components that requires careful planning and execution to ensure timely, quality results.
Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.
Basic qualifications:
Position requires a four-year degree from an accredited college or university.
3+ years software development experience (Java, Python, etc..);1+ years’ experience with a Master’s degree.
1+ years of Java 8 or higher and SpringBoot RESTful API development.
1+ years of experience using cloud or serverless technologies and frameworks such as AWS, Kinesis, API Gateway, CloudFormation/Terraform, IAM, AWS Lambda, S3, SNS, SQS, etc.
Top candidates will also have:
Development of software applications using relational and NoSQL databases
Experience with CI/CD and DevOps technologies such as Azure DevOps Code Pipeline, Jenkins, shell scripts, etc. and an Agile software development methodology.
Designing, developing, deploying and maintaining software at scale.
Hands on experience with testing tools like Cucumber.
AWS Docker experience
Hands on experience with API tools such as Swagger or Postman
Bachelor’s degree in Computer science or Electrical engineering
#LI-Remote
#BI-Remote
Work from home - WFH - Remote
Visa sponsorship available for eligible applicants.
EEO/AA Employer. All qualified individuals - Including minorities, females, veterans and individuals with disabilities - are encouraged to apply.
Not ready to apply? Submit your information to our Talent Network here .","$127,338 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1925,$10+ billion (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"Capital One
4.1",4.1,"Wilmington, DE",Senior Data Engineer,"802 Delaware Avenue (18052), United States of America, Wilmington, Delaware
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance
Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Otter Products, LLC
3.1",3.1,Remote,Sr. Data Engineer,"Overview:
Otter Products is currently recruiting for a Sr. Data Engineer. You can be based in our Fort Collins, CO office with flexibility to work a portion of your time remotely, or 100% Remote in the U.S.

The Sr. Data Engineer will play a pivotal role in building and operationalizing the minimally inclusive data necessary for the enterprise data initiatives following industry standard practices and tools. The bulk of the Sr. Data Engineer’s work would be in designing, managing and optimizing data pipelines and then moving these data pipelines effectively into production for key data and analytics consumers like business/data analysts, data scientists or any persona that needs curated data for data and analytics use cases across the enterprise. The Sr. Data Engineer also needs to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for data and analytics initiatives. Additionally, the Sr. Data Engineers will also be expected to collaborate with data scientists, data architects, data analysts and other data consumers and work on the models and algorithms developed by them in order to optimize them for data quality, security and governance and put them into production leading to potentially large productivity gains.
About Otter Products: At Otter Products, we grow to give. From our founder’s garage in 1998 to the global technology leader we are today, Otter Products continues to drive growth through innovation. Through our industry-leading brands — OtterBox, Liviri and OtterCares — we provide our partners the number-one selling and most trusted products in our categories. Our philanthropic spirit is the foundation on which we foster our partner relationships, allowing us to grow and to give — together. By way of our charitable arm, the OtterCares Foundation, we support our communities and invest in our future through education that inspires kids to change the world. And even as our global community of Otters continues to grow, our founder’s core values are still at the heart of everything we do. We measure our success by our ability to give back to our communities and strengthen opportunities for all. For more information visit otterproducts.com Responsibilities:
Responsible for the verification and validation of data moving into or out of systems providing information to identify issues or inaccuracies in ETL pipelines from internal and external systems
Manage Azure Data Catalog and Business Glossary Application ensuring linage and data sources are mapped within the application
Primary lead working with data architects to define the development of data systems, creating data pipelines and optimizing ETL processes for ingest of data internally and externally
Primary resources to collaborate with a cross-functional team to determine requirements for data needs and requirements
Provide technical guidance and coaching to members of the data team
Set the standards on Power BI Dashboard/Reporting creation
Define and manage standards, guidelines, and processes to ensure data quality.
Oversee the creation and maintenance of Data Quality Metrics that drive improvement in Otter Products data quality
Develop and maintain the standards on ETL development within Otter
Define and own the release management process for ETL code deployment, including version control
Evaluate and recommend emerging technologies for data management, storage, and analytics
Support and maintain a positive safety culture by following all safety policies and procedures and actively contributing to a safe working environment
Other duties as required
Qualifications:
Bachelor’s degree required. Degree in Computer Science or Mathematics preferred.
Minimum of six years of experience in an IT or analytical role required. Experience in database development, report writing and/or statistics preferred.
EEO: Otter Products, LLC is an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, marital status, pregnancy, sex, sexual orientation, gender, gender identity or expression, national origin, disability, veteran status, or any other characteristic or status protected by law. For US Based Roles Only - Compensation Range Minimum: USD $110,000.00/Yr. For US Based Roles Only - Compensation Range Maximum: USD $135,000.00/Yr.","$110,000 /yr (est.)",501 to 1000 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1998,Unknown / Non-Applicable
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"ADT
3.1",3.1,"Boca Raton, FL",Data Engineer,"Company Overview:

ADT has been in the business of helping save lives since 1874. As the #1 smart home security provider in the U.S., we help protect and connect families, businesses and larger commercial customer every day. Our continuous innovation, advanced technology and strategic partnerships deliver products and services that help protect life and valuables, whether at home, your business or on the go. And as times change, so do we. Above all, our mission is clear: we help save lives for a living. Looking for a career where you can make a real impact? Join our team today and put purpose behind your paycheck. #WeAreADT
Check out more about life at ADT here.
Position Summary: Senior Data Engineer is responsible for developing and governing our data and information strategy in order to drive business decisions and growth. You will develop data procedures and policies and work closely with the various departments to collect, prepare, organize, protect, and analyze data assents while ensuring that the company meets industry best practices. Other duties will include leading inter-disciplinary teams, improving and streamlining data systems within the company and driving innovation.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Thorough understanding of the business and data strategy.
Designing and implementing data strategies and systems.
Overseeing the collection, storage, management, quality and protection of data.
Implementing data privacy policies and complying with data projection regulations.
Determine where to cut costs and increase revenue based on insights derived from data.
Effectively communicate the status, value, and importance of data collection to executive members and staff.
Knowledge of relevant applications, big data solutions and tools.
Competencies: To perform the job successfully, an individual should demonstrate the following:
Achievement Focus - Demonstrates persistence and overcomes obstacles. Measures self against standard of excellence. Recognizes and acts on opportunities. Sets and achieves challenging goals. Takes calculated risks to accomplish goals.
Business Acumen - Aligns work with strategic goals. Conducts cost-benefit analyses. Demonstrates knowledge of market and competition. Displays orientation to profitability. Understands business implications of decisions.
Business Ethics - Inspires the trust of others. Keeps commitments. Treats people with respect. Upholds organizational values. Works with integrity and ethically.
Managing Customer Focus - Develops new approaches to meeting customer needs. Establishes customer service standards. Monitors customer satisfaction. Promotes customer focus. Provides training in customer service delivery.
Strategic Thinking - Adapts strategy to changing conditions. Analyzes market and competition. Develops strategies to achieve organizational goals. Identifies external threats and opportunities. Understands organization's strengths & weaknesses.
Visionary Leadership - Acts in accordance with vision. Communicates vision and gains commitment. Creates a clear, compelling vision. Displays passion and optimism. Mobilizes others to fulfill the vision.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education/Experience:
Bachelor’s degree in information technology of related field. Master’s degree preferred. 5 to 10 years’ experience in a senior level data management role.
Language Ability:
Read, analyze, and interpret scientific and technical journals, financial reports, and legal documents. Respond to inquiries or complaints from customers, agencies, or members of the business community. Write speeches and articles for publication.
Mathematical Ability:
Apply advanced concepts such as exponents, logarithms, quadratic equations, and permutations. Apply operations to such tasks as frequency distribution, test reliability/validity, variance analysis, correlation technique, sampling theory and factor analysis.
Reasoning Ability:
Define problems, collect data, establish facts, and draw valid conclusions. Interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The noise level in the work environment is usually moderate.
Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is frequently required to sit and use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand and walk. The employee must be able to occasionally lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
The above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow any other instructions, and perform any other related duties, as assigned by their supervisor.
Compensation:
The salary range for this role is $73,066-$146,131 and is based on experience and qualifications.
Certain roles are eligible for annual bonus and may include equity. These awards are allocated based on company and individual performance.
We offer employees access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, life insurance, wellbeing benefits and paid time off among others. Employees accrue up to 120 hours in their first year. Your accrual rate increases after your first year. We also offer 6 paid holidays.


ADT is an Equal Employment Opportunity (EEO) Employer. We celebrate diversity and are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. ADT strives to ensure every employee and applicant feels valued. Visit us at jobs.adt.com/diversity to learn more.","$109,599 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Security & Protective,1874,$5 to $10 billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
Tail Wind Informatics,#N/A,Minnesota,Data Engineer - Azure,"About Us:
Tail Wind is an IT Consulting Services company—Microsoft Solutions Partner—that delivers Data Architecture and Business Intelligence solutions. We offer cloud and on-premise Data Architecture, ETL Development, Data Migration, Reporting and Dashboard solutions. We’ve established an excellent reputation providing these services to awesome customers! We are building a talented crew of data savvy individuals for local and national projects in data. We offer excellent compensation (salary, bonus, benefits). Most importantly, our people have an incredible opportunity to build their skills in a team environment.

We are currently seeking candidates for our Data Engineer position to do the following:
Responsibilities
Using Data Science techniques to preform predictive modeling services.
Building data sets in data warehouses using SQL, Azure and Python.
Experience with Databricks or Snowflake
Work across multiple different teams and projects.
Requirements
3+ years experience using Azure Data Factory
Must have strong backend development skills with SQL Server and writing complex SQL queries
Strong understanding of predictive modeling
Working in a fast paced, deadline heavy environment
Benefits
401k + match
Health Insurance
Dental Insurance
Vision
Long-Term Disability Insurance
Life Insurance
The Tail Wind Team: A healthy work-life balance. We look for people that love what they do, want to learn, earn and enjoy life to the fullest.
Equal Opportunity Employer - No Agencies Please","$120,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Moen
4.0",4.0,"North Olmsted, OH",Data Operations Engineer,"Company Description

Fortune Brands Innovations is a global Fortune 500 company specializing in home, outdoors, plumbing, and security products. Our portfolio includes famous brands such as Moen, Master Lock, Fiberon, and Therma-Tru.

Job Description

Data Operations Engineer, full-time from North Olmsted, Cleveland, Toledo, and Columbus.

Our IT/Tech division is transforming digitally to boost our innovation, competitiveness, and efficiency. We're investing in IT and Engineering and assembling a team of experts. The Data & Analytics team is building a data, ML, and analytical platform using modern tech such as Cloud and DevOps. We need a DataOps engineer to join us in developing this platform. It's a new initiative with great career and technical leadership opportunities.

Our Stack
Infrastructure: Hybrid - a mix of on-premise infrastructure and public Cloud, primarily Azure.
Data systems: ERP systems, including SAP and Oracle. Snowflake as Enterprise Datawarehouse.
Platform infrastructure and DevOps: Azure Pipelines, GitHub, Kubernetes, IaC.
Data tools: dbt, Talend, and python.

We have a blend of legacy systems and tools while assessing and introducing new tools where it makes sense. This is a hybrid role where you will be working primarily from home with the flexible option of coming into work at our North Olmstead office for deeper engagement with the team and stakeholders on a needed basis.

Responsibilities
Own, develop, manage, and optimize the orchestration of data pipelines and source code version control that adhere to our data governance principles.
Own, develop, manage, and enhance the tools for the data engineers.
Work closely with stakeholders in Business Intelligence, Data Governance, Infrastructure, and business units to gather functional and non-functional requirements, and deliver the appropriate tooling and systems to produce high-quality data and analytics in a timely manner.
Build systems and automation to overcome the limitations of existing systems and integrate new modern-day tech stack into the company’s IT infrastructure.
Establish system monitoring, cost monitoring/mitigation, and alerting.
Define and enforce best practices and standards for the Data & Analytics team.

Qualifications
Bachelor’s degree in computer science, information systems, science, or engineering; or equivalent years of experience in IT, software engineering, or a relevant field.
4+ years of experience in Python or/and an equivalent language, such as bash or Powershell.
4+ years of experience in Linux system administration, network administration, or working at a data center.
2+ years of experience in working with a Cloud provider, including AWS, GCP, or Azure.
2+ years in developing and managing SDLC workflow, DevOps tools, and CI/CD.
Basic understanding of data architecture, data warehousing, and gitflow.
Experience in observability, including cost monitoring, log management, alerting, monitoring, and tuning.
Self-driven with the ability to work in a multi-stakeholder environment and deal with ambiguity.
Good analytical & problem-solving skills and the ability to incorporate multiple perspectives.
Good written and verbal communication skills.

Preferred Qualifications

Big plus if you have these skills.
Big Plus: Snowflake or a Cloud Warehouse product like Google BigQuery or AWS RedShift.
Big Plus: Experience in data orchestration.
Experience in infrastructure as code, including Terraform, Pulumi, Chef, or Puppet.
Experience in SQL querying language.
Quick learner.
Great sense of humor.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.",#N/A,201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"Discover Financial Services
3.9",3.9,Illinois,Data Engineer - Abinitio,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.
Job Description: The Data Engineer is responsible designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community.
Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members
Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies
Demonstrates strong technical aptitude across data engineering practices:
Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting
Designing advanced SQL queries
Leveraging metadata-driven framework for solutions
Developing test scripts for unit and integration testing
Develops test methodologies for specific products
Leads code review sessions and other process and operational improvement initiatives
Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)
Works on holistic solutions, driving feature and story delivery (Agile)
Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline
Participates in the on-call rotation for support
Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities
Builds strong collaborative working relationship both within the team and cross-functionally

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field
3+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale

Preferred Qualifications

If we had our say, we’d also look for:
ETL/ELT Tools (AbInitio, DataStage, Informatica)
Cloud Tools and Databases (AWS, Snowflake)
Other programming languages (Unix scripting, Python, etc.)
Leverage CI/CD framework for data integration, Open Source
Experience working in cloud platforms (AWS, GCP, Azure)
Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs
Experience optimizing SQL both relational and nosql
External applicants will be required to perform a technical interview.

#LI-CM

Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$113,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"Three Ships Media
3.4",3.4,"Charlotte, NC",Data Analytics Engineer,"Role Overview:
3S Health is seeking a hands-on, self-motivated Data Analytics Engineer to own our data analytics pipeline for one of our fastest growing businesses. In this role, you will be responsible for collecting and modeling data through the deployment of modern cloud tools, and turning that data into insights through the building of dashboards and reports. This role is for the data engineer that seeks to get closer to the business, or the business analyst that seeks to dive deeper into understanding where their data comes from.
What you'll Do:
Create and maintain scalable data pipeline through combination of modern SaaS applications and custom-built solutions
Create and maintain business intelligence roadmap to help enable business goals
Partner with business users to gather and understand data requirements
Extract data from sources through custom-built data integrations (typically Python) with discipline towards automation
Write SQL-based transformations to turn raw data into production-ready business models
Develop and manage business and executive team dashboards
Create and maintain data storage systems
Develop data discoverability tools and data monitoring systems

What You'll Bring:
Proficiency in SQL and Python (and/or proven ability to pick up a new language)
Proven ability to operate autonomously to achieve results.
Optional experience in Data Build Tool (DBT) or other SQL-based transformation tools
General understanding of the Marketing Technology stack, components, and best-practices. An ideal candidate will have some familiarity with common marketing tools (Google Analytics, Tag Manager, Segment (CDP), Facebook Ads, etc.)
Experience with common enterprise analytics tools with proven ability to translate data insights into action (Tableau, PowerBI, Looker Studio, Superset, etc.)
Working knowledge of software development best practices as they apply to data engineering, including: Version Control, Unit Testing, and Continuous Integration/Continuous Delivery (CI/CD)
The Package
As a full-time employee of Three Ships, you’ll have access to competitive benefits, including flexible time off, health/dental/vision, 401k match, an annual Relax & Recharge Bonus, an annual Learning & Development stipend to enroll in class(es) of your choosing, and up to $75 mobile reimbursement. If you join us in person in our Raleigh or Charlotte locations, we have an office stocked with snacks, coffee, and just about every other beverage you can imagine.
How We Hire
All applicants are considered without regard to race, color, religion, sex, national origin, age, disability, veteran status, gender identity, or any other discriminatory factors. Please note that we do not provide immigration sponsorship for this role. All offers are subject to a background check.","$92,505 /yr (est.)",51 to 200 Employees,Company - Private,Media & Communication,Advertising & Public Relations,2009,Unknown / Non-Applicable
"USAA
3.4",3.4,"San Antonio, TX",Data Engineer II,"Why USAA?
At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation’s military, but we all share in the mission to give back to those who did. We’re working as one to build a great experience and make a real impact for our members.

We believe in our core values of honesty, integrity, loyalty and service. They’re what guides everything we do – from how we treat our members to how we treat each other. Come be a part of what makes us so special!
The Opportunity
The candidate selected for this position is going to get work with the CFO Data & Analytics Team in USAA’s Corporate technology office. They will work with modern data technologies in like snowflake, dbt , container-based API’s , python and Kafka to build data pipelines to enable business with developing and implementing financial models on inputs and also build reporting capabilities on the model outputs within the treasury space in CFO.
This Data Engineer II position is a hybrid work type and can be based in one of our following office locations: San Antonio, TX or Plano, TX. Hybrid roles help employees gain the best of both worlds – collaborating in-person in the office and working from home when needed to achieve focused results.
What you'll do:
Participates in the full life cycle of data engineering to include analysis, solution design, data pipeline engineering, testing, deployment, scheduling, and production support with guidance from senior team members.
Assists in the implementation of technical solutions for data reporting and analytic systems.
Assists with designing and writing test scripts to verify data integrity and application of functionality. Reviews functionality of existing test scripts for understanding.
Demonstrates familiarity with IT Change and Release Management best practices. Deploys data pipeline code with assistance from senior team members.
Participate in design and code review sessions.
Actively participates in Agile ceremonies such as daily standup, iteration planning, backlog grooming, and retrospective sessions.
Develops intermediate familiarity of data management best practices by participating in trainings, reviewing documentation, and reading code from existing solutions.
Demonstrates knowledge and understanding of business products and processes.
Assists senior team members in breaking down business features into technical stories and approaches.
Actively learns about new and emerging technologies in the data engineering space. Seeks to apply learnings in current and future projects.
Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.
What you have:
Bachelor’s degree; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree; OR Approved certification from CodeUp, Galvanize, VetFIT (Veterans for IT) or eFIT
2 years of data engineering, data analysis or software development experience implementing data solutions.
Working Experience in SQL and Relational Databases.
Strong analytical and problem-solving skills.
Basic understanding of cloud technologies and tools.
What sets you apart:
2+ years of working experience with Snowflake.
1+ years of container-based APIs using container frameworks like OpenShift, Docker, or Kubernetes
2+ years of Python and Unix shell/Batch scripting experience
1+ years of experience with Kafka streaming technologies
Working experience with Gradle, yml, GIT, GitHUB, GITLab, etc. around continuous integration and continuous delivery infrastructure
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
What we offer:
Compensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $71,490 - $136,690.
Employees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.
Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.
For more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.
Relocation assistance is not available for this position.
USAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",#N/A,10000+ Employees,Company - Private,Insurance,Insurance Carriers,1922,$25 to $100 million (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
"Concentrix
4.0",4.0,Remote,Data Engineer Job Ref #: 795218,"Job Title:
Data Engineer Job Ref #: 795218
Job Description
Concentrix CVG Customer Management Group Inc., Cincinnati OH, has multiple openings for the position of Data Engineer. Work will be performed in various unanticipated locations throughout the U.S. Travel and/or relocation is required. Telecommuting may be permitted.
The Data Engineer will write, update, and maintain software applications; perform production maintenance of code; gather solutions requirements. Own technical commitments to clients and work with the team to successful delivery of solutions. Analyze, design, and code for complex requirements as well as write programs of complexity. Responsible for defining problems, collecting data, establishing facts, drawing valid conclusions, and preparing appropriate reports.
The position requires a Master’s degree in Computer Science, Engineering (any), or any technical/analytical field that is closely related to the specialty, plus one (1) year of experience in an IT/Computer-related position.
To apply, send resume to ctlyst_postings@concentrix.com with Job Ref# 795218 in the subject line of the email.
#ConcentrixCatalyst
Location:
USA, OH, Work-at-Home
Language Requirements:
Time Type:
If you are a California resident, by submitting your information, you acknowledge that you have read and have access to the Job Applicant Privacy Notice for California Residents

Concentrix is an Equal Opportunity/Affirmative Action Employer including Disabled/Vets.
For more information regarding your EEO rights as an applicant, please visit the following websites:
English
Spanish
To request a reasonable accommodation please click here.
If you wish to review the Affirmative Action Plan, please click here.",#N/A,10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,2004,$1 to $5 billion (USD)
"Mastercard
4.3",4.3,"Arlington, VA","Data Engineer, Launch Program 2024 - United States","Our Purpose
We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments and businesses realize their greatest potential. Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. We cultivate a
culture of inclusion
for all employees that respects their individual strengths, views, and experiences. We believe that our differences enable us to be a better team – one that makes better decisions, drives innovation and delivers better business results.
Title and Summary
Data Engineer, Launch Program 2024 - United States
Be part of the Data & Services Technology Team at Mastercard, Data and Services

The Data Engineer I is a full time role within Mastercard Launch, a cohort based, graduate development program designed to build the skills you’ll leverage most as an innovator in the payments space. Eligibility requires that you currently be a graduating senior, pursuing a relevant degree.

Who is Mastercard?
Mastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.
Our decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.

Make an Impact as a Data Engineer

Data Engineers are fundamental to the success of our client engagements by acting as the bridge between raw client data and Mastercard's software. Data Engineers work closely with both Consultants while working on consulting engagements and Software Development Engineers while working to develop internal capabilities. Data Engineers are responsible for:

Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform
Sourcing data from clients, government and other third-party data sources, and Mastercard's transaction data warehouse
Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set
Tackling big data problems across various industries

Here are just a few of the benefits that you will get to experience during your first year as a Data Engineer:

Strategic problem solving with exceptional peers who are also passionate about data
Creative freedom to innovate with new technologies and to explore a variety of solutions
Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients
Flexibility to work on many new and challenging projects across diverse industries
A dynamic environment where you will have an impact and make an immediate difference
An immediate opportunity for increased responsibility, leadership, and professional growth
Committed mentoring and training by an experienced and driven leadership team
Cross-functional collaboration with others throughout Mastercard

Bring your passion and expertise

About You:

Currently enrolled in your final year of a bachelor’s or accelerated master’s program with an established history of academic success
Desire to work with data and help businesses make better data-driven decisions
Excellent written and verbal communication skills
Strong troubleshooting and problem solving capabilities
Demonstrated analytical and quantitative skills

The role also involves these skills. We don't require them, but it's helpful if you already have them:

Understanding of relational databases, SQL, and ETL Processes
Hands-on experience with the ETL process, SQL, and SSIS
Knowledge of at least one programming language
In the US, Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law. If you require accommodations or assistance to complete the online application process, please contact reasonable_accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.
Corporate Security Responsibility

All activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:
Abide by Mastercard’s security policies and practices;
Ensure the confidentiality and integrity of the information being accessed;
Report any suspected information security violation or breach, and
Complete all periodic mandatory security trainings in accordance with Mastercard’s guidelines.","$114,086 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Financial Transaction Processing,1966,Unknown / Non-Applicable
"Flowserve Corporation
3.8",3.8,"Irving, TX",Data Science Engineer,"Role Summary:
We are seeking an experienced Data Science Engineer to join our dynamic team. The ideal candidate will have a unique blend of technical expertise in both data engineering and data science, with a deep understanding of Azure cloud infrastructure and tools. You will play a pivotal role in developing, optimizing, and deploying machine learning models, data pipelines, and databases to facilitate the development of generative AI solutions that are scalable and integrated with existing enterprise systems.
As a Data Science Engineer, you will design and manage data pipelines and databases, develop and deploy scalable ML models, and collaborate with teams to integrate AI solutions into business processes. You will utilize data classification platforms and standard ML to continuously improve model performance. Stay informed about the latest in AI/ML advancements.
Responsibilities:
Design, build, and maintain robust data pipelines for sourcing, cleaning, and preprocessing data for machine learning models.
Develop, test, and deploy scalable machine learning models using Azure cloud infrastructure and tools.
Perform cross-validation to assess model performance on unseen data.
Engage in feature engineering to improve data input quality.
Update models periodically with fresh data to capture new patterns.
Implement reinforcement learning techniques for dynamic model adjustments using feedback.
Monitor and analyze model outcomes, identifying areas for further refinement.
Collaborate with cross-functional teams to integrate machine learning solutions into business processes.
Ensure efficient cloud resource utilization, optimizing cost and performance.
Leverage data labeling tools to manage datasets for supervised learning tasks.
Continuously enhance model performance and data quality through monitoring and validation.
Stay current with AI/ML advancements.
Requirements:
Strong proficiency in Python, with expertise in TensorFlow, Scikit-Learn, PyTorch, NumPy, and Pandas.
Solid experience in Azure cloud infrastructure, including Azure ML, Azure Data Factory, and Azure Databricks.
Proficiency in SQL, NoSQL, and vector databases.
Experience with Huggingface and Langchain.
Proven track record of developing and deploying machine learning models in a real-world environment.
Understanding of data warehousing, integration, cloud deployment, scalability, security, and backup strategies, including vector databases (e.g., Faiss, Pinecone, Milvus) for AI tasks.
Strong analytical skills to derive actionable insights from complex data structures.
Excellent problem-solving abilities with a focus on pragmatism and scalability.
Bachelor’s/master’s degree in computer science, Engineering, Data Science, or related field; significant work experience and a strong portfolio also considered.
Preferred Experience / Skills:
Familiarity with data labeling tools and platforms.
More details:
We are seeking candidates who do not currently require or anticipate requiring sponsorship to work in the United States in the present or future (e.g., H-1B, H-2B, F-1, F-2, J-1, J-2, TN, etc.).
Benefits:
Flowserve offers highly competitive pay, annual bonus, comprehensive benefits on day 1 of employment, generous paid vacation time, paid holidays, pension plan, 401(k) and many other excellent benefits
Req ID : R-6921
Job Family Group : Information Technology
Job Family : IT Business Analysis
EOE including Disability/Protected Veterans. Flowserve will also not discriminate against an applicant or employee for inquiring about, discussing or disclosing their pay or, in certain circumstances, the pay of their co-workers. Pay Transparency Nondiscrimination Provision
If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access flowservecareers.com as result of your disability. You can request a reasonable accommodation by sending an email to employment@flowserve.com. In order to quickly respond to your request, please use the words ""Accommodation Request"" as your subject line of your email. For more information, read the Accessibility Process.","$100,621 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Machinery Manufacturing,1997,$1 to $5 billion (USD)
"Ford Motor Company
4.0",4.0,"Allen Park, MI",Data Engineer,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world - together. At Ford, we’re all a part of something bigger than ourselves. Are you ready to change the way the world moves?
Ford Self-Service Analytics is looking for an experienced Data Engineer to join the team. The ideal candidate will be highly skilled in all aspects of data analytics, including mining, generation, and visualization. They will collaborate directly and continuously with data scientists, data engineers and business partners to drive data enablement and delivery.
What you'll do...
Lead connected vehicle data collection process.
Collect data from various sources. Streamline data collection methods to create automated and easy-to-use routines
Analyze collected data and transform it into insights that others can easily interpret
Collaborate cross-functionally with data scientists, business users, project managers and other engineers to achieve innovative solutions.
Provide technical support and troubleshoot reported problems for data integration, and support resolution
You'll have...
Bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or related field or a combination of education and equivalent work experience
3 + years of experience with SQL or similar query language.
3+ years of experience in NoSQL databases, such as MongoDB and Cassandra.
2 + years of experienced in data processing platforms/technologies like Hadoop, GCP, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.
Even better, you may have...
Master’s Degree in Computer Science, Computer Engineering, Electrical Engineering or related field
Experienced in data visualization software like Qliksense, Looker Studio, etc.
Adept at queries, writing reports, and making presentations
Experienced in connected vehicle architectures and telematics
Experienced in open-source data analytics programming languages, such as Python or R
Experienced in using source control systems (e.g. Git) to manage and deploy code
Strong Communication skills and ability to think above and beyond baseline requirements
You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!
As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all the above? No matter what you choose, we offer a work life that works for you, including:
Immediate medical, dental, and prescription drug coverage
Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up childcare and more
Vehicle discount program for employees and family members, and management leases
Tuition assistance
Established and active employee resource groups
Paid time off for individual and team community service
A generous schedule of paid holidays, including the week between Christmas and New Year’s Day
Paid time off and the option to purchase additional vacation time.
For a detailed look at our benefits, click here:
https://corporate.ford.com/content/dam/corporate/us/en-us/documents/careers/2023-benefits-and-comp-GSR-sal-plan-2.pdf
Visa sponsorship is available for this position
Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.
We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, if you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.
#LI- hybrid","$90,900 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,1903,$10+ billion (USD)
"The Walt Disney Company (Corporate)
3.9",3.9,"Seattle, WA",Associate Data Engineer- Machine Learning,"At Disney, we’re storytellers. We make the impossible, possible. The Walt Disney Company is a world-class entertainment and technological leader. Walt’s passion was to continuously envision new ways to move audiences around the world—a passion that remains our touchstone in an enterprise that stretches from theme parks, resorts and a cruise line to sports, news, movies and a variety of other businesses. Uniting each endeavor is a commitment to creating and delivering unforgettable experiences — and we’re constantly looking for new ways to enhance these exciting experiences.

The Enterprise Technology mission at Disney is to deliver technology solutions that align to business strategies while enabling enterprise efficiency and promoting cross- company collaborative innovation. We drive Disney's competitive advantage by enhancing our consumer experiences, enabling business growth, and advancing operational excellence!

You will be part of the Cloud & Data Transformation Engineering organization, that provides next-level cloud and data services to unleash digital magic for Disney. We use modern technologies, design patterns, culture, and organizational alignment to enable teams to seamlessly ship content, products, and magical experiences better, faster, safer, and happier.

The vision of the Data Engineering team at CDTE is to drive and enable business decisions by providing timely, trusted and accurate insights to our internal and external customers. Team is responsible for building data pipelines, curating, and publishing data products for consumption. The team is taking up the charter to increase ML adoption across the group by identifying and solving forecast, optimization, classification, and recommendation problems. The ML team’s output will include- data exploration, hypothesis development, preparing training/test data, increasing data quality, design and run experiments, model development/selection communicating results, and robust production deployment. In this role you will partner with business, software, analysts and cross-functional engineering groups to lead and drive data informed business decisions. Be part of the team which charters the course for the future!!!
Responsibilities
Work closely with Business, Product and Data teams to define problem statements.
Designing and developing machine learning systems and algorithms.
Build, deploy and maintain learning models.
Statistically analyze model performance and fine-tune.
Run machine learning tests and experiments.
Implementing appropriate ML algorithms.
Staying updated with the latest developments in the field and bring in best-in-class concepts, techniques and approaches.

Basic Qualifications
Bachelor’s degree in Computer Science or related field.
1+ years of experience in machine learning and related space.
Deep understanding of standard algorithms across all 4 approaches to ML(Supervised, Unsupervised, Deep Learning, Reinforcement Learning).
Strong programming skills in Python, Java, or R.
Experience with machine learning frameworks such as TensorFlow or PyTorch.
Experience with data analysis tools such as Pandas or NumPy.
Use Databricks/Jupyter notebooks for data analysis.

Preferred Qualifications
Masters degree or PhD in Computer Science or a related technical field
Exposure to architectural patterns of large scale software applications

The hiring range for this position in Seattle, WA is $89,298 to $119,790 per year. The base pay actually offer will take into account internal equity and also may vary depending on the candidate's geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","$104,544 /yr (est.)",10000+ Employees,Company - Public,Media & Communication,Film Production,1923,$10+ billion (USD)
"Meta
3.9",3.9,Remote,Data Center Facility Operations Reliability Engineer,"Meta is seeking an experienced and self-motivated Reliability Engineer to join our Global Asset Management team within Facility Operations. This person will work at the leading edge of Facility Operations to identify and manage asset reliability risks that could adversely affect data center operations. Managing stakeholders spread across time zones is a significant challenge and key to the success of our individual projects and overall asset management, quality and reliability program.


Data Center Facility Operations Reliability Engineer Responsibilities:
Support the asset care and maintenance strategies for critical assets based on Meta processes
Support the development of standards, guidelines and processes to execute reliability program function
Lead and facilitate asset criticality assessments, RCM studies, PM Optimization and other reliability studies
Perform reliability analytics include Weibull distribution, Monte Carlo simulation and other reliability analysis
Act as liaison between Reliability and other partner teams
Support the development of standardized PM template to facilitate trending
Works with appropriate technical teams to evaluate reliability and maintainability of data center equipment to significantly influence reliability and maintainability improvements
Works with Asset Management and Quality teams to evaluate the failure data and other information and build that into a global reliability database
Provides input for key documents such as reliability process playbooks, executive briefs/presentations and program metrics
Define, design, develop, monitor, and refine an asset maintenance plan that includes both (a) value-added preventive maintenance tasks and (b) predictive and other non-destructive testing methods designed to identify and isolate inherent reliability issues
Provide technical support to Operations, Maintenance management, and technical personnel
Apply value analysis to repair/replace, repair/redesign, and make/buy decision
Develop Reliability Improvement Process (RIP) reports on critical asset failures
Develop or recommend engineering solutions to repetitive failures and all other problems that adversely affect plant operations
Support Master Data and asset onboarding process
Support the development and stewardship of maintenance strategies
Support the spares development and sustainment program
Work with Maintenance to analyze asset characteristics, including: asset availability, overall equipment effectiveness and remaining useful life



Minimum Qualifications:
10+ years of experience in reliability engineering (related to electrical or mechanical cooling equipment)
Bachelor’s degree in Mechanical, Electrical Reliability Engineering or similar technical discipline
Certifications in Maintenance & Reliability such as CMRP, CRL, CRE
Knowledgeable of relevant ISO standards (ISO 14224, ISO 17359, ISO 55000)
Proficient in usage of EAM solutions to extract data and develop meaningful insights
Experienced in Reliability Centered Maintenance (RCM) and Failure Maintenance Effect Analysis activities for maintenance/process/equipment design optimization to meet reliability requirements



Preferred Qualifications:
Proficient in developing and executing Design for Reliability Activities (Reliability prediction models, accelerated life testing, environmental stress testing, equipment qualification criteria, etc.)
Experience in performing Reliability, Availability and Maintainability (RAM) models
Experience with data center equipment such as critical cooling systems, generators, main switchboards, network gear





Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","$162,500 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,2004,$10+ billion (USD)
"Apple
4.2",4.2,"Cupertino, CA","Data Engineer, AppleCare Business Insights","Summary
Posted: Aug 17, 2023
Weekly Hours: 40
Role Number:200494142
Imagine what you could do here. At Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. The people here at Apple don’t just craft products - they build the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it. AppleCare Business Insight is a dynamic strategy and decision support organization that provides insight to drive business impact. This role is for a full-stack data engineer within the AppleCare BI team to provide data driven insight to improve revenue and margin for AppleCareʼs extended warranty products. You will build data engineering assets and statistical/machine learning models to surface useful business insights. The role engages with cross functional business teams to define the problem statement, design analytical solutions and operationalize the solutions.
Key Qualifications
Advanced data modeling experience, strong SQL concepts skills, and understanding ETL
Advanced experience with Snowflake
Experience with advanced data analytics, data transformation and data management projects
Dimensional modeling and business intelligence concepts
Experience with commercial and emerging reporting tools and technologies (e.g. Tableau, ThoughtSpot)
Experience in Web-scale databases, Hadoop, PostGre or NoSQL technologies is a plus
Experience with big data and related data analytics and experience with R, Python or similar statistics tools is desirable
Knowledge of predictive analytics, statistics and modeling techniques to develop and improve sophistication of Business Intelligence solutions
In-depth experience of analyzing data and creating reports, data profiling, understanding anomaly detection and working with data to identify trends and make recommendations
Able to quickly learn new and existing technologies
Strong attention to detail and excellent analytical capabilities
Excellent oral and written interpersonal skills
Self-motivated, dedicated and solution-oriented individual
Description
Responsible for crafting and implementing infrastructure projects to help build next generation of semantic layers solution. Need to understand business requirement, build design document, create prototypes, impact assessment, playback the impact statement. The ability to build IT scripts helps in UAT is expected. Work closely with data warehouse architects and software developers to generate flawless business intelligence solutions for end users. Support production analytic solutions. Present results of analyses to business units.
Education & Experience
M.S. in Computer Science, Mathematics, Economics, Operations Research or related field or B.S. in related field with 4+ years experience applying analytical techniques to real business problems.
Additional Requirements
Pay & Benefits
At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $134,000 and $223,500, and your base pay will depend on your skills, qualifications, experience, and location.

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",#N/A,10000+ Employees,Company - Public,Information Technology,Computer Hardware Development,1976,$10+ billion (USD)
"Amazon.com Services LLC
3.7",3.7,"Seattle, WA","Software Development Engineer , Data, Analytics and Science (DAAS)","3+ years of non-internship professional software development experience
2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience
Experience programming with at least one software programming language
The Amazonian Experience and Tech (AET) Central Services, and Technology (CST) organization directly impacts the experience of all Amazonians through their Amazon careers by building innovative and mission critical solutions that power Amazon's massive workforce and its growth. We are looking for a passionate Software Development Engineer to help us fulfill our goal of becoming Earth’s Best Employer.

In this role, you will work in a multidisciplinary team of developers, scientists and data engineers and build solutions at the crossroads of engineering and science. You will be developing scalable solutions using data to solve critical data science problems in translation, intelligent routing, text autocompletion etc. and push the state of the art in natural language processing, machine learning and distributed systems.

As a Software Development Engineer on the team, you will play an important role in shaping the definition, vision, design, roadmap and development of product features from beginning to end.

Key job responsibilities
Write high quality distributed system software
Build production quality and large scale deployment of applications related to NLP and ML
Use software engineering best practices to ensure a high standard of quality for all team deliverables
Design, implement, test, deploy and maintain innovative software solutions to transform service performance, stability, cost and security
Help drive business decisions with your technical input
Work in an agile, startup-like development environment, where you're always working on the most important stuff
Mentor and lead junior developers on the team
About the team
The Amazonian Experience and Technology (AET) organization delivers 200+ services to Amazonians in 52 countries, in 18 languages, and from 11 regional hubs.

We support employees – regardless of their country, role, or line of business – from onboarding to exit, and throughout their transitions during their tenure.

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience
Bachelor's degree in computer science or equivalent
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $115,000/year in our lowest geographic market up to $223,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.","$115,000 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Internet & Web Services,1994,$10+ billion (USD)
"ASK Consulting
3.7",3.7,"Irving, TX",Network/Data Engineer,"Job Type:Contract
Posted 1 day ago

Expiry Date: 18 September 2023
Referral: 227624@accuick.com
Job Title: Network/Data Engineer
Job Description:
Job Details:
TOP 5 SKILLS NEEDED:
Project-based work in a team environment
Cisco CCNA certification
Experience in new build configuration on IOS, IOS-XR, Arista EOS, Ciena
Cloud computing / Whitebox
Ethernet/L2 & L3 Troubleshooting

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$101,484 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"TikTok
3.5",3.5,"San Jose, CA",Machine Learning Engineer - Data Cycling Center,"Responsibilities
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.

About the team
The success of data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.

We are looking for a highly capable machine learning engineer to deploy and optimize our machine learning systems. You will be evaluating existing machine learning (ML) lifecycle, understanding and productionizing the model pipeline, and enhancing and maintaining the performance of our AI model's predictive automation capabilities.

Responsibilities
Model optimization: collaborate with data scientists to improve existing machine learning model training and evaluation pipelines, optimize the model training pipeline speed for faster iteration
Model Deployment: optimize the model inferencing performance through quantization and model conversion, define and leverage appropriate resources for model hosting and inferencing
Inference Pipeline Productionization: work with data scientists and data engineers to design and implement the data pipelines for machine learning models that will support the current and future needs of our business
Service Deployment: build continuous integration, testing, and scalable deployment pipelines in cloud computing environments for machine learning services
Tracking: build logging, tracking, analyzing, monitoring and reporting pipelines for both data and model tracking in cloud computing environments to ensure correct model output and stable model performance
Maintenance: build scalable and reliable infrastructure that supports feature engineering, model training, deployment, inferencing, performance monitoring
What you will need
Ability to understand the business use case to optimize and implement scalable solution
Knowledge of machine learning concepts and fundamentals; deep learning proficiency in at least one of CV and NLP, with solid experience in model training/inferencing optimization such as quantization and conversion
Solid programming skills with experience writing and maintaining high-quality production code
Experience in ML pipeline, model training orchestration; large-scale/distributed training experience is desirable
Ability to work independently and complete projects from beginning to end and in a timely manner
Great communication skills, both written and oral; comfortable presenting findings and recommendations to non-technical audiences
Qualifications
Qualifications
BS or above in Computer Science, Software Engineering, Data Science or a related field
3+ years of industry experience building ML infrastructure at scale
At least 1 year of experience in developing and deploying large-scale systems, version control, scaling and monitoring
Experience in machine learning frameworks (scikit-learn, Tensorflow, Pytorch), big data frameworks (Spark/Hadoop/Flink) and experience in resource management and task scheduling for large scale distributed systems
Proficient in Python/SQL and one of C++/Go, with deep knowledge of Linux and CD tools (e.g. git); experience with any Go/Python microservice framework is highly desirable
Familiar with cloud infrastructure, good understanding of different data storages and message queues for data streaming and pipelining
Good communication and teamwork skills to clearly communicate technical concepts with other teammates
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at tac.accommodations@tiktok.com.
Job Information
The base salary range for this position in the selected city is $144000 - $300000 annually.



Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.



At ByteDance/TikTok our benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support ByteDancers to give their best in both work and life. We offer the following benefits to eligible employees:



We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.



Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off(PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.



We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","$222,000 /yr (est.)",1001 to 5000 Employees,Company - Private,Information Technology,Internet & Web Services,2016,Unknown / Non-Applicable
"Tesla
3.6",3.6,"Austin, TX","Data Engineer, Service","What to Expect
The Data and Analytics, Applications Engineering team drives business critical decision making, and ensures cross functional alignment of goals and execution for all of Tesla. We stay focused on aligning the highest-level company priorities with strong day-to-day operations and build capabilities to power hyper-growth.
As the Data Engineer, you will partner with members of the Data and Analytics team and its leadership in Applications Engineering to provide critical analysis operations to support our demanding and fast-paced environment where you will work on critical subsystems of an incredibly exciting product.
The candidate must be comfortable with data warehousing To be successful in this role, you will need strong data engineering skills, excellent interpersonal communication, and experience building, optimizing and managing ETL Pipelines.
What You’ll Do
Assist with implementation and maintenance of the internal Data and Analytics and reporting processes.
Research and keep abreast of rapidly evolving data requirements, ensuring necessary system and process changes are implemented to meet these requirements.
Identify potential process improvements and recommend implementation strategies.
Develop and demonstrate expertise in communicating data related topics, including reporting.
Analyze the need for new applications or enhancements to the existing application to suit business needs and make decisions if they are needed or not.
Recommend solutions that adhere to industry standards, keeping in mind the impact on upstream and downstream system and stakeholders.
Closely monitor the project from inception to completion and assist in User Acceptance Testing.
Work on special projects related to data as assigned.

What You’ll Bring
2+ years of prior experience Data Engineer or equivalent experience.
Experience with Tableau or any visualization tool, Data Warehousing, Data Modeling
Strong experience with relational databases like SQL Server, MySQL and Vertica. NoSQL databases experience is a plus
Experience with user-defined workflows (e.g., Airflow)
Experience with writing Kafka consumers and producers.
Experience Apache Spark Streaming and Hive is plus.
Problem solver that is action-oriented with the ability to look at problems in new ways.
Working knowledge of data management software like Airflow, or other ETL tools a plus.
Strong analytical and problem-solving ability to design an effective solution.
Ability to support multiple on-going projects in a fast-paced environment.
Strong communicational skills, organizational skills, negotiation skills, and flexibility to address competing demands.
Ability to explain Production / technical concepts and analysis implications clearly to a wide audience and be able to translate business objectives into actionable analyses.
Superior business judgement – ability to flex between big picture thinking, understand and distill complex ideas, and analyze data to drive strategic objectives.
Passion for Tesla’s products and belief in Tesla’s mission to accelerate the transition to sustainable energy
Experience with bug/enhancement tracking system like JIRA a plus.","$124,121 /yr (est.)",10000+ Employees,Company - Public,Manufacturing,Transportation Equipment Manufacturing,2003,$1 to $5 billion (USD)
"Dutch Bros
4.1",4.1,Oregon,Data Engineer,"It's fun to work in a company where people truly believe in what they are doing. At Dutch Bros Coffee, we are more than just a coffee company. We are a fun-loving, mind-blowing company that makes a difference one cup at a time.
Being part of the Dutch Family
You are adaptable, a servant leader, and community-minded. You view yourself as an unfinished product on the constant pursuit of personal and professional development. We rely on our people to uphold our core values of speed, quality, and service to protect our culture and ensure our growth remains limitless!

Dutch Bros mission statement
We are a fun-loving, mind-blowing company that makes a massive difference one cup at a time.

Who we are
Dutch Bros puts people first in everything we do. Joining our team gives you the opportunity to build a compelling future while making a massive difference in the lives of our customers and communities.
We love people and we love OUR people! Here’s what we offer
Here at Dutch Bros, we want our employees to feel valued, and we recognize there's more to value than a salary. The following benefits and perks were hand-picked to cater to our diverse employee base:
Medical/Dental/Vision/Short Term Disability/Life insurances
Paid Sick Days
401(k) plan with employer match after one year of employment
Education Benefit Program
Vacation/Floating Holidays/Paid Time Off
Paid Parental Leave
Flexible Schedule
Paid Volunteer Days
Various employee discounts
Office perks, such as hi-lo desks, snacks provided daily, casual dress code, and an in-house coffee bar with a dedicated Broista
Position Overview
The Data Engineer is a lifelong learner with deep knowledge of data warehouse and ETL solutions. This role engages in BI activities which include the design, development, and implementation of data assets, data governance policies, and data management processes. This role works with other teams to understand and collect requirements for designing data assets (data warehouses, pipelines,etc.) and deliver reliable and sustainable data products for internal use.
Key Result Areas (KRAs)
Design, develop, and improve ETL and data warehouse tools at Dutch Bros to deliver reliable, high quality and sustainable data solutions:
Design and develop new ETL solutions
Improve the performance and effectiveness of current ETL processes
Design and implement new data warehouses
Monitor and improve the performance of the current data warehouses
Perform ongoing preventive maintenance on data pipelines and related applications
Develop and improve the data asset documentation:
Build data catalog for the legacy and new data assets
Develop data architecture diagram
Develop data dictionaries for the legacy and new data assets
Categorize and tag the data to democratize the data assets to a wider group
Develop ETL and data warehouse description documentation
Develop and support the data governance efforts:
Develop data policies to manage the access and availability of data assets
Develop data policies to support privacy and security compliance efforts
Monitor the permissions, access and availability of data for different internal and external users
Apply the best practices to improve the data security for the data in motion or at rest
Other duties as assigned
Job Qualifications
Required Qualifications:
Minimum of 3 years of experience in a data engineering role, required
2 additional years of experience developing data warehouses on Snowflake platform, required
Bachelor's degree in Computer Science, Software or Computer Engineering, Applied Math, Physics, Statistics, or a related field, preferred
Experience with data warehousing concepts, SQL, and SQL Analytical functions, required
Experience in using the Azure platform to implement data solutions (ADF, SQL DBs, Purview, Storage Units, etc.), required
Data visualization and dashboarding experience (Power BI, Tableau, Looker, etc.)
Experience in data modeling (dimensional, normalized, key-value pair)
DevOps experience (Azure DevOps or Gitlab) delivering continuous improvements
Experience in management and maintenance of data pipelines in an enterprise setting
Problem-solving orientation with the ability to leverage both quantitative and qualitative analyses to drive decision-making
Preferred Qualifications:
Background and experience working in food and beverage industry
Working knowledge of data programming languages/solutions (Python, Java or R)
Working knowledge of big data and real-time pipelines (such as Spark, Kafka, Airflow, Hive, Elastic Search, etc.)
Experience in working with data catalog/quality/governance solutions (including Informatica, Collibra, Alation)
Familiar with real-time pipeline design and management principles and concepts
Experience building RESTful APIs to enable data consumption
Experience with Action Analytics (Microsoft D365 Analytics solution)
Familiarity with Azure Logic Apps
Preferred Certifications:
Azure platform (Developer/Architect/Data Engineer)
Snowflake platform (SnowPro Core/Advanced)
Competencies
Adaptable
Collaborative
Communication
Effective Prioritization
Functional and Tech. Expertise
Initiative
Physical Requirements
Occasional lifting up to ten pounds
Must be able to work in a climate-controlled office environment
Vision must be good, or corrected to normal, to perform normal job duties
Hearing must be good, or corrected to normal, to have the ability to understand information to perform job duties
Ability to read and write in English in order to process paperwork and follow up on any actions necessary
Sitting for extended periods of time
Manual dexterity needed for keyboarding and other repetitive tasks
This position is eligible for remote work within any state Dutch Bros currently resides in (AL, AZ, CA, CO, ID, KS, KY, MO, NM, NV, OK, OR, TN, TX, UT, and WA)
Compensation:
$104,788.59 - $121,478.69
If you like wild growth and working in a unique and fun environment, surrounded by positive community, you'll enjoy your career with us!","$113,134 /yr (est.)",10000+ Employees,Company - Public,Restaurants & Food Service,Restaurants & Cafes,1992,$500 million to $1 billion (USD)
"Visa
4.1",4.1,"Austin, TX",Staff Data Engineer - Visa Research,"Company Description

Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.
When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.
Join Visa: A Network Working for Everyone.

Job Description

As a Staff Data Engineer for Visa Research, you will discover, and maintain a variety of research projects in the Visa Research group. In this role, you will drive innovations by introducing technologies, methods, and solutions to deliver innovative products. You will drive innovation from conceptualization to implementation. The innovation will build on machine learning, artificial intelligence, and big data research. You will research and develop flawless, fast, reliable, and secure payment solutions using foundational and applied research techniques.
You will engage with different collaborators, senior executives, research scientists, software engineers and architects, as well as external parties like technology vendors, wallet providers, merchants, issuers and senior product regional managers. You will discover and propose research and development opportunities, build development plan, create, and implement the ideas.
Our team is focusing on building a new product suite for Visa’s real time payments options! This will have a fraud-management focus and be scaled across many markets at Visa. This suite will also bring ‘real-time fraud monitoring’ into play using the latest in Machine Learning & Deep Learning technologies. We are seeking Data Engineers that come from a wide array of backgrounds with the curiosity about creating something new and exciting for Visa.
You will have the opportunity and the responsibility to build the long-term vision for the payment industry and influence the direction of the research and development across Visa.
Key responsibilities include:
Implement the set of services needed to release AI and data science models capable of working with terabytes of data. This includes model related features like one time and ongoing automatic model training, deploying, and monitoring models, as well as platform related features such as model repository, feature stores, data access layer.
Provide technical leadership for efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects.
Work and partner with product delivery teams to fully implement the proof of concept and early product in Visa services and products.
Collaborate with research scientists, product owners and architects to deliver the fast-prototyping platform.
Champion the innovation across the organizations and industries as an expert in the subject, either by providing consulting or by contributing to technology talks and presentations.
Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a detailed and timely manner.
Make decision on tradeoffs/priority during the design and execution, such as tradeoff between performance and flexibility, scope and timelines, availability, and scalability, etc.
Present and demo the research solutions to a committee on the regular basis.
This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.

Qualifications

Basic Qualifications:
5+ years of relevant work experience with a Bachelor’s Degree or at least 2 years of work experience with an Advanced degree (e.g. Masters, MBA, JD, MD) or 0 years of work experience with a PhD, OR 8+ years of relevant work experience.
Preferred Qualifications:
6 or more years of work experience with a Bachelors Degree or 4 or more years of relevant experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or up to 3 years of relevant experience with a PhD in Computer Science/Computer Engineering or related field.
Experience programming in at least one or more in Java, Python, Scala and Go
Strong understanding of algorithms and data structures.
Experience in leading, building and supporting scalable and reliable data solutions, AI/machine learning powered systems that can enable fast prototyping and advanced analytics using modern big data and ML/AI technologies (Hadoop, Spark, Cloud, No-SQL, TensorFlow, H2O etc.) in an agile manner.
Hands-on experience developing and maintaining machine learning lifecycle: data preprocessing and feature extraction, model training and evaluation, and deployment and monitoring.
Hands-on experience and/or academic background partnering with data scientists and can speak knowledgeably about the major machine learning paradigms, algorithms, and software tools.
Hands-on experience and/or academic background translating data science problem statements into corresponding data, infrastructure, or workflow needs.
Familiarity with the associated open-source ecosystem (e.g., mlflow, cortex, seldon, Kubeflow, tfx) is a plus.
Knowledge and experience working with Frond-end web application frameworks (Angular/React) along with HTML, CSS, JavaScript is a plus.
Knowledge and experience working with REST/JSON-RPC services, SQL, and NoSQL database is a plus.

Additional Information

Work Hours: Varies upon the needs of the department.
Travel Requirements: This position requires travel 5-10% of the time.
Mental/Physical Requirements: This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.
Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.
Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.
U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 126,000.00 to 163,800.00 USD, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.","$122,449 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Information Technology Support Services,1958,$10+ billion (USD)
"Chevron
4.1",4.1,"Houston, TX",Data Engineer,"Chevron’s strategy is straight-forward: be a leader in efficient and lower carbon production of traditional energy, in high demand today and for decades to come, while growing lower carbon businesses that will be a bigger part of the future. To achieve these goals, we’ll build on the assets, experience, capabilities, and relationships we’ve developed over 140 years to incubate and grow new business.
Technology will play a crucial role in unlocking ever cleaner and more affordable sources of energy.
Chevron is seeking innovative, technology professionals with a desire to thrive in the global digital environment and help us lead the global energy transition.
An IT career at Chevron offers you the opportunity to work in a technical environment with a global reach. You’ll find that we make a business of investing in our people and encouraging your professional development through a learning culture and challenging on-the-job opportunities. We differentiate ourselves through the application of cutting-edge technology, and by taking a collaborative approach that includes in-house expertise, proprietary solutions, and strategic partnerships. We also offer flexible work schedules and very competitive benefits.
Join Chevron IT. Lend us your skills and enjoy a great career with Chevron.
Data Engineer:
A Data Engineer designs data products and data pipelines that are resilient to change, modular, flexible, scalable, reusable and cost effective.
Responsibilities for this position may include but are not limited to:
Understanding the business use of data and the stakeholders requirements to support work processes and strategic business objectives.
Leverage data and software engineering techniques, data science to create business value through data accessibility. Includes data ingestion, data preparation and analytics processing.
Identifying, acquiring, cleansing/preparing, storing data and developing reusable data products aligned with defined architecture patterns.
Enabling data scientists, making data available for advanced analytics models, and contributing to advanced analytics models.
Working with ML Engineers to scale and deploy solution including models, documentation, training, integration.
Contributing to the inner source development of foundational tools, and/or the deployment of technical services.
Required Qualifications:
Bachelor/master’s in computer science disciplines
5+ years in analytics, preferably for big data and cloud-based environment
Experiences in coding for analytics (batch and real time data processing), optimization for performance, reusability, and cost effectiveness
Cloud computing, big data computing
Data Acquisition, wrangling and preparation
Data movement and transformation
Fundamentals of core data architecture
Information security
Software engineering
Preferred Qualifications:
Analytical thinking
Critical thinking
Technical leadership
Consulting
Learning agility
Flexible Working
Chevron offers a complete package and provides career development opportunities to all employees. We do this through on-boarding, training and development, mentoring, volunteering opportunities and employee networking groups. We advocate work-life balance and offer employees access to various health and wellness programs.
What type of flex work does the position offer?
We offer alternative work schedules including 9/80 (work 9-hour days, with every other Friday off)
We offer a hybrid work model - work remotely from home 2-3 days a week
Relocation & International Considerations
Relocation[ may / will not be] considered.
Expatriate assignments [ may / will not be ] considered.
Chevron regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.
Working with us
Chevron is one of the world’s leading integrated energy companies. We believe affordable, reliable and ever-cleaner energy is essential to achieving a more prosperous and sustainable world. Chevron produces crude oil and natural gas; manufactures transportation fuels, lubricants, petrochemicals and additives; and develops technologies that enhance our business and the industry. We are focused on lowering the carbon intensity in our operations and seeking to grow lower carbon businesses along with our traditional business lines. More information about Chevron is available at www.chevron.com.
Pay Transparency & benefits
The compensation and reference to benefits for this role is listed on this posting in compliance with applicable law. The selected candidate’s compensation will be determined based on his or her skills, experience, and qualifications. Please note that the compensation and benefits listed below are only applicable to successful candidates who are hired onto local United States payroll.
The anticipated salary range for this position is $112,000 – $200,000.
Chevron offers competitive compensation and benefits programs which includes, but is not limited to, variable pay, health care coverage, retirement plan, protection coverage, time off and leave programs, training and development opportunities and a range of allowances connected to specific work situations. Details are available at http://hr2.chevron.com/.
Regulatory Disclosure for US Positions:
Chevron is an Equal Opportunity / Affirmative Action employer. Qualified applicants will receive consideration for employment without regard to race, color, religious creed, sex (including pregnancy, childbirth, breast-feeding and related medical conditions), sexual orientation, gender identity, gender expression, national origin or ancestry, age, mental or physical disability (including medical condition), military or veteran status, political preference, marital status, citizenship, genetic information or other status protected by law or regulation.
We are committed to providing reasonable accommodations for qualified individuals with disabilities. If you need assistance or an accommodation, please email us at emplymnt@chevron.com.
Chevron participates in E-Verify in certain locations as required by law.
Default Terms and Conditions
We respect the privacy of candidates for employment. This Privacy Notice sets forth how we will use the information we obtain when you apply for a position through this career site. If you do not consent to the terms of this Privacy Notice, please do not submit information to us.
Please access the linked document, select the country where you are applying for employment, then acknowledge that you have read and agree to the country specific statement by checking the box below.
Terms of Use","$156,000 /yr (est.)",10000+ Employees,Company - Public,"Energy, Mining & Utilities",Energy & Utilities,1879,$10+ billion (USD)
"Lyra Health, Inc
4.3",4.3,"Burlingame, CA",Data Engineer,"About Lyra Health
Lyra is transforming mental health care through technology with a human touch to help people feel emotionally healthy at work and at home. We work with industry leaders, such as Morgan Stanley, Uber, Amgen, and other Fortune 500 companies, to improve access to effective, high-quality mental health care for their employees and their families. With our innovative digital care platform and global provider network, 10 million people can receive the best care and feel better, faster. Founded by David Ebersman, former CFO of Facebook and Genentech, Lyra has raised more than $900 million.

Lyra Health seeks a Data Engineer in Burlingame, CA responsible for developing data infrastructure, pipelines, and data services in support of the ongoing development of our innovative digital care software platform.
Responsibilities
Specific duties include: (i) developing core pieces of our data infrastructure, pipelines, and data services underlying our product, including: designing mental health-related data pipelines using Python software from third-party data sources, such as CDPs and external medical API data sources; developing mental health-related data models in the data warehouse for use by data consumers within the company; and conducting tests on data quality and the accuracy of data models in the data warehouse as well as building new data monitoring systems; (ii) building and leveraging data warehouses for all data use cases, including: providing technical expertise to Lyra Health’s product team with respect to data warehouse management and scaling and establishing data governance with respect to how data is leveraged for data analytics purposes, including with respect to domain knowledge in mental health-related data elements for our consumers; and (iii) defining technical requirements and solutions for data pipelines and data views in support of Lyra Health’s development of mental health machine learning product line, including meeting with stakeholders on a regular basis to define and finalize technical data scopes and requirements for data pipelines and models and maintaining an optimal data backlog with respect to product prioritization and consumer insight/expectations.
Qualifications
Must have a bachelor’s degree in Computer Science or a directly computer-related academic discipline plus one (1) year of experience in a data engineering position.
Must have knowledge (through any completed University-level coursework, seminars, workshops, or real-world, hands-on experience) of: (i) advance level Python; (ii) SQL coding; (iii) data visualization & validation; (iv) designing data pipelines using Python software from third-party data sources using technologies such as Airflow; and (v) defining technical requirements and solutions for data pipelines and data views.
We are an Equal Opportunity Employer. We do not discriminate on the basis of race, color, religion, sex (including pregnancy), national origin, age (40 or older), disability, genetic information or any other category protected by law.","$114,514 /yr (est.)",1001 to 5000 Employees,Company - Private,Healthcare,Health Care Services & Hospitals,2015,$100 to $500 million (USD)
"ICS Global Soft
4.1",4.1,"Irving, TX",Data Science/ Machine Learning Engineer,"Come on board with pool of IT-experts who works as a family so that you can fit into a perfect place with your intelligent mind, motivate your creativity, pour in your dynamic knowledge and brighten-up your career. Join us if you want to fall in love with your professional life. Be a part of ICS Global Soft who believes in working and moving together and an entity that is comprised with dynamic innovations, integrity and delivering milestones and that too, every time. Join us for fulfilling your professional dreams, achieving something great and encouraging others to lead, just like you. Life at ICS is all about enriching a novice and mounting up with dynamism of an expert. It’s all about reinventing and creating victory mode, always.
Data Science/ Machine Learning Engineer
Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. If you also have knowledge of data science and software engineering, we’d like to meet you.
Responsibilities:
Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Requirements:
Proven experience as a Machine Learning Engineer or similar role
Understanding of data structures, data modeling and software architecture
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Java and R
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Excellent communication skills
Ability to work in a team
Mail Resume to ICS Global Soft, INC, 1231 Greenway Drive STE # 375, Irving TX 75038.

We appraise to boost, inspire to conquer. Join the league, apply with your resume to info@icsglobalsoftinc.com.","$104,181 /yr (est.)",Unknown,Company - Private,Human Resources & Staffing,Staffing & Subcontracting,#N/A,Unknown / Non-Applicable
"Stanford Health Care
3.9",3.9,"Palo Alto, CA",Associate Data Engineer,"If you're ready to be part of our legacy of hope and innovation, we encourage you to take the first step and explore our current job openings. Your best is waiting to be discovered.

Day - 08 Hour (United States of America)
This is a Stanford Health Care job.

A Brief Overview
The Associate Data Architect is a Level I Analyst role responsible for providing analytics supporting improvement efforts, generally within a defined value stream or strategic domain. This includes developing data architecture and solutions to sustain improvement efforts and provide ongoing support for existing applications.

Locations
Stanford Health Care

What you will do
Builds effective working relationships with cross discipline team members, including hospital staff, new users, line management, on/offshore team members, etc.
Guides user leadership in formulation of project plan, regular status reporting to IT and user management, issue management and escalation.
Develops business cases for new technology solutions. Confidently and professionally presents and defends recommended solution, approach, timeline, etc. to IT and user leadership and manages expectations accordingly.
Organizes and conducts regular project status meetings and design reviews sessions leveraging appropriate project artifacts.
With little supervision, performs analysis of the scope and requirements for projects.
Prepares specifications, designs, data models and diagrams from which databases can be developed.
Develops, tests, and deploys data structures using Entity Relationship Diagramming, SQL Server tools, and data modeling tools.
Troubleshoots incidents surrounding supported databases and solutions.
Tunes performance of databases, ETL processes and queries.

Education Qualifications
BS/BA Degree in information technology, information systems, business management, business analytics, business administration or a directly-related field from an accredited college or university. Required

Experience Qualifications
Zero (0) to Two (2) years of experience in analytics, business intelligence or healthcare technology Required

Required Knowledge, Skills and Abilities
Understanding of components of high-quality Reporting & Analytics solutions that meet user requirements with minimal on-going maintenance and a low volume of production incidents (production failures, help desk calls, etc.).
Understanding of best practices and common processes for developing solutions with SHC tools (i.e., SSIS, Crystal Reports, WebI, Qlikview, etc.) utilized in role.
Troubleshoots incidents and enhancement requests surrounding supported applications.
Basic working knowledge of SQL in an Oracle or SQL Server environment. Proficient with Select queries with inner/outer joins and common text and numeric functions.
Creates moderately complex Reports or Visualizations with SHC standard tools. Effectively implements these, scheduling, and user admin.
Effectively takes direction from supervisors to complete assigned tasks.
Reactive interaction up to Tier 4 levels of the organization
Demonstrates ability to manage assigned tasks on basic projects.
Seeks and embraces coaching and mentoring from team members in order to develop skills and integrate with the team.
Understands basic tenants of SHC vision and communicates them to others.
Developing expertise in a single domain.
Limited ability to anticipate problems.
Effective verbal, written, and interpersonal communication skills

Licenses and Certifications
None .

These principles apply to ALL employees:

SHC Commitment to Providing an Exceptional Patient & Family Experience

Stanford Health Care sets a high standard for delivering value and an exceptional experience for our patients and families. Candidates for employment and existing employees must adopt and execute C-I-CARE standards for all of patients, families and towards each other. C-I-CARE is the foundation of Stanford’s patient-experience and represents a framework for patient-centered interactions. Simply put, we do what it takes to enable and empower patients and families to focus on health, healing and recovery.

You will do this by executing against our three experience pillars, from the patient and family’s perspective:
Know Me: Anticipate my needs and status to deliver effective care
Show Me the Way: Guide and prompt my actions to arrive at better outcomes and better health
Coordinate for Me: Own the complexity of my care through coordination
Equal Opportunity Employer Stanford Health Care (SHC) strongly values diversity and is committed to equal opportunity and non-discrimination in all of its policies and practices, including the area of employment. Accordingly, SHC does not discriminate against any person on the basis of race, color, sex, sexual orientation or gender identity and/or expression, religion, age, national or ethnic origin, political beliefs, marital status, medical condition, genetic information, veteran status, or disability, or the perception of any of the above. People of all genders, members of all racial and ethnic groups, people with disabilities, and veterans are encouraged to apply. Qualified applicants with criminal convictions will be considered after an individualized assessment of the conviction and the job requirements.
Base Pay Scale: Generally starting at $46.36 - $60.27 per hour
The salary of the finalist selected for this role will be set based on a variety of factors, including but not limited to, internal equity, experience, education, specialty and training. This pay scale is not a promise of a particular wage.",$53.31 /hr (est.),10000+ Employees,Hospital,Healthcare,Health Care Services & Hospitals,1957,$1 to $5 billion (USD)
"Capital One
4.1",4.1,"Wilmington, DE",Senior Data Engineer,"802 Delaware Avenue (18052), United States of America, Wilmington, Delaware
Senior Data Engineer
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.
What You’ll Do:
Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance
Basic Qualifications:
Bachelor’s Degree
At least 4 years of experience in application development (Internship experience does not apply)
At least 1 year of experience in big data technologies
Preferred Qualifications:
5+ years of experience in application development including Python, SQL, Scala, or Java
2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
3+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)
2+ year experience working on real-time data and streaming applications
2+ years of experience with NoSQL implementation (Mongo, Cassandra)
2+ years of data warehousing experience (Redshift or Snowflake)
3+ years of experience with UNIX/Linux including basic commands and shell scripting
2+ years of experience with Agile engineering practices
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.
The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.
New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer
Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.
This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.
Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.
No agencies please. Capital One is an Equal Opportunity Employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.
For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com
Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.
Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).",#N/A,10000+ Employees,Company - Public,Financial Services,Banking & Lending,1994,$10+ billion (USD)
"Otter Products, LLC
3.1",3.1,Remote,Sr. Data Engineer,"Overview:
Otter Products is currently recruiting for a Sr. Data Engineer. You can be based in our Fort Collins, CO office with flexibility to work a portion of your time remotely, or 100% Remote in the U.S.

The Sr. Data Engineer will play a pivotal role in building and operationalizing the minimally inclusive data necessary for the enterprise data initiatives following industry standard practices and tools. The bulk of the Sr. Data Engineer’s work would be in designing, managing and optimizing data pipelines and then moving these data pipelines effectively into production for key data and analytics consumers like business/data analysts, data scientists or any persona that needs curated data for data and analytics use cases across the enterprise. The Sr. Data Engineer also needs to guarantee compliance with data governance and data security requirements while creating, improving and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse and vastly improved time-to-solution for data and analytics initiatives. Additionally, the Sr. Data Engineers will also be expected to collaborate with data scientists, data architects, data analysts and other data consumers and work on the models and algorithms developed by them in order to optimize them for data quality, security and governance and put them into production leading to potentially large productivity gains.
About Otter Products: At Otter Products, we grow to give. From our founder’s garage in 1998 to the global technology leader we are today, Otter Products continues to drive growth through innovation. Through our industry-leading brands — OtterBox, Liviri and OtterCares — we provide our partners the number-one selling and most trusted products in our categories. Our philanthropic spirit is the foundation on which we foster our partner relationships, allowing us to grow and to give — together. By way of our charitable arm, the OtterCares Foundation, we support our communities and invest in our future through education that inspires kids to change the world. And even as our global community of Otters continues to grow, our founder’s core values are still at the heart of everything we do. We measure our success by our ability to give back to our communities and strengthen opportunities for all. For more information visit otterproducts.com Responsibilities:
Responsible for the verification and validation of data moving into or out of systems providing information to identify issues or inaccuracies in ETL pipelines from internal and external systems
Manage Azure Data Catalog and Business Glossary Application ensuring linage and data sources are mapped within the application
Primary lead working with data architects to define the development of data systems, creating data pipelines and optimizing ETL processes for ingest of data internally and externally
Primary resources to collaborate with a cross-functional team to determine requirements for data needs and requirements
Provide technical guidance and coaching to members of the data team
Set the standards on Power BI Dashboard/Reporting creation
Define and manage standards, guidelines, and processes to ensure data quality.
Oversee the creation and maintenance of Data Quality Metrics that drive improvement in Otter Products data quality
Develop and maintain the standards on ETL development within Otter
Define and own the release management process for ETL code deployment, including version control
Evaluate and recommend emerging technologies for data management, storage, and analytics
Support and maintain a positive safety culture by following all safety policies and procedures and actively contributing to a safe working environment
Other duties as required
Qualifications:
Bachelor’s degree required. Degree in Computer Science or Mathematics preferred.
Minimum of six years of experience in an IT or analytical role required. Experience in database development, report writing and/or statistics preferred.
EEO: Otter Products, LLC is an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, marital status, pregnancy, sex, sexual orientation, gender, gender identity or expression, national origin, disability, veteran status, or any other characteristic or status protected by law. For US Based Roles Only - Compensation Range Minimum: USD $110,000.00/Yr. For US Based Roles Only - Compensation Range Maximum: USD $135,000.00/Yr.","$110,000 /yr (est.)",501 to 1000 Employees,Company - Private,Manufacturing,Consumer Product Manufacturing,1998,Unknown / Non-Applicable
"ASK Consulting
3.7",3.7,"Durham, NC",ETL Data Engineer - Remote,"Job Type:Contract
Posted 2 days ago

Expiry Date: 17 September 2023
Referral: 230553@accuick.com
Experience : 6 years
Job Description:
Independently:
Define and extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes
Document, and test complex data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages
Write and refine code to ensure the performance and reliability of data extraction and processing
Lead requirements gathering sessions with business and technical staff to distill technical requirements from business requests
Develop advanced SQL queries to extract data for analysis and model construction
Own delivery of large, complex data engineering projects
Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists
Ensure the performance and reliability of data processes
Document and test data processes including the performance of thorough data validation and verification
Collaborate with cross-functional teams to resolve data quality and operational issues and ensure the timely delivery of products
Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning
Analyze and evaluate databases in order to identify and recommend improvements and optimization
Design advanced eye-catching visualizations to convey information to users
Hiring Requirements:
Bachelor's degree and 5 years of experience with Data Integration, Data Warehouses, Operational Data Stores, Data Lakes, and Big Data platforms
Direct experience with at least one ETL development language/technology such as Ab Initio, DataStage, Informatica, Python, R
Advanced SQL knowledge and experience with database technologies such as DB2, Teradata, Snowflake, AWS
In lieu of a degree, 7 years of experience as stated above.
Hiring Preferences:
Experience in healthcare or insurance
Experience collaborating effectively with vendors and business partners for solution delivery


#LI-Remote

About ASK: ASK Consulting is an award-winning technology and professional services recruiting firm servicing Fortune 500 organizations nationally. With five nationwide offices, two global delivery centers, and employees in 42 states, Ask Consulting connects people with amazing opportunities.
ASK Consulting is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all associates.","$100,089 /yr (est.)",501 to 1000 Employees,Company - Private,Human Resources & Staffing,HR Consulting,1995,$25 to $100 million (USD)
"ServiceNow
4.4",4.4,"San Diego, CA",Sr Software Engineer - Data Platform,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.
With more than 7,700+ customers, we serve approximately 85% of the Fortune 500®, and we're proud to be one of FORTUNE 100 Best Companies to Work For® and World's Most Admired Companies™.
Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.
Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

*Flexible in-office*
Team:
Platform persistence group provides storage API for higher layer applications. Depending on the nature of the data, the storage systems include relational database, non-relational database such as columnar database, time series database, or message queue system. Our largest customers are always pushing the limits of the backend storage in terms of size of the data, speed of IO, as well as number of concurrent transactions. Performance, reliability, and scalability is always at the core of our work.
As a Senior Data Platform Software Engineer, you will have the opportunity to become a key member of the Platform Persistence group. Team members will be mentored in the necessary skills to become successful contributors to the team.
What you'll do and need to know:
You'll create the features exposing and leveraging capabilities on our underlying database engines.
Experience in Core Java development, object-oriented and modularized software.
Provide platform API to manage large data volume and record life cycles while keeping the database healthy and performing.
Demonstrated success completing complex projects.
Demonstrated aptitude for learning new technologies.
Nice to have:
Experience with concurrency issues
Good knowledge of java internals
Good knowledge of database internals
Experience programmatically handling large data volume on relational database.
Good understanding of a DevOps environment
Solid background in java backend programming solving problems at scale.

Qualifications
4+ years of software development experience with a bachelor’s degree in computer science OR equivalent experience
Experienced in writing Java code.
Experience developing a platform.
Experience in unit and integration test automation
Experience with relational databases: MySQL/MariaDB, PostgreSQL, Oracle, MS SQLServer
Familiarity with Unix shell
WJ23

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.
At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.
If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.
For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.
Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.
From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license.
Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","$137,260 /yr (est.)",10000+ Employees,Company - Public,Information Technology,Enterprise Software & Network Solutions,2004,$1 to $5 billion (USD)
"ADT
3.1",3.1,"Boca Raton, FL",Data Engineer,"Company Overview:

ADT has been in the business of helping save lives since 1874. As the #1 smart home security provider in the U.S., we help protect and connect families, businesses and larger commercial customer every day. Our continuous innovation, advanced technology and strategic partnerships deliver products and services that help protect life and valuables, whether at home, your business or on the go. And as times change, so do we. Above all, our mission is clear: we help save lives for a living. Looking for a career where you can make a real impact? Join our team today and put purpose behind your paycheck. #WeAreADT
Check out more about life at ADT here.
Position Summary: Senior Data Engineer is responsible for developing and governing our data and information strategy in order to drive business decisions and growth. You will develop data procedures and policies and work closely with the various departments to collect, prepare, organize, protect, and analyze data assents while ensuring that the company meets industry best practices. Other duties will include leading inter-disciplinary teams, improving and streamlining data systems within the company and driving innovation.
Essential Duties and Responsibilities: To perform this job successfully, an individual must be able to perform the following satisfactorily; other duties may be assigned. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Thorough understanding of the business and data strategy.
Designing and implementing data strategies and systems.
Overseeing the collection, storage, management, quality and protection of data.
Implementing data privacy policies and complying with data projection regulations.
Determine where to cut costs and increase revenue based on insights derived from data.
Effectively communicate the status, value, and importance of data collection to executive members and staff.
Knowledge of relevant applications, big data solutions and tools.
Competencies: To perform the job successfully, an individual should demonstrate the following:
Achievement Focus - Demonstrates persistence and overcomes obstacles. Measures self against standard of excellence. Recognizes and acts on opportunities. Sets and achieves challenging goals. Takes calculated risks to accomplish goals.
Business Acumen - Aligns work with strategic goals. Conducts cost-benefit analyses. Demonstrates knowledge of market and competition. Displays orientation to profitability. Understands business implications of decisions.
Business Ethics - Inspires the trust of others. Keeps commitments. Treats people with respect. Upholds organizational values. Works with integrity and ethically.
Managing Customer Focus - Develops new approaches to meeting customer needs. Establishes customer service standards. Monitors customer satisfaction. Promotes customer focus. Provides training in customer service delivery.
Strategic Thinking - Adapts strategy to changing conditions. Analyzes market and competition. Develops strategies to achieve organizational goals. Identifies external threats and opportunities. Understands organization's strengths & weaknesses.
Visionary Leadership - Acts in accordance with vision. Communicates vision and gains commitment. Creates a clear, compelling vision. Displays passion and optimism. Mobilizes others to fulfill the vision.
Qualifications: To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
Education/Experience:
Bachelor’s degree in information technology of related field. Master’s degree preferred. 5 to 10 years’ experience in a senior level data management role.
Language Ability:
Read, analyze, and interpret scientific and technical journals, financial reports, and legal documents. Respond to inquiries or complaints from customers, agencies, or members of the business community. Write speeches and articles for publication.
Mathematical Ability:
Apply advanced concepts such as exponents, logarithms, quadratic equations, and permutations. Apply operations to such tasks as frequency distribution, test reliability/validity, variance analysis, correlation technique, sampling theory and factor analysis.
Reasoning Ability:
Define problems, collect data, establish facts, and draw valid conclusions. Interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.
Work Environment: The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
The noise level in the work environment is usually moderate.
Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
While performing the duties of this job, the employee is frequently required to sit and use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand and walk. The employee must be able to occasionally lift and/or move up to 10 pounds. Specific vision abilities required by this job include close vision.
The above job description is not intended to be an all-inclusive list of duties and standards of the position. Incumbents will follow any other instructions, and perform any other related duties, as assigned by their supervisor.
Compensation:
The salary range for this role is $73,066-$146,131 and is based on experience and qualifications.
Certain roles are eligible for annual bonus and may include equity. These awards are allocated based on company and individual performance.
We offer employees access to healthcare benefits, a 401(k) plan and company match, short-term and long-term disability coverage, life insurance, wellbeing benefits and paid time off among others. Employees accrue up to 120 hours in their first year. Your accrual rate increases after your first year. We also offer 6 paid holidays.


ADT is an Equal Employment Opportunity (EEO) Employer. We celebrate diversity and are committed to building an inclusive team that represents a variety of backgrounds, perspectives, and skills. ADT strives to ensure every employee and applicant feels valued. Visit us at jobs.adt.com/diversity to learn more.","$109,599 /yr (est.)",10000+ Employees,Company - Public,Management & Consulting,Security & Protective,1874,$5 to $10 billion (USD)
"Abbott Laboratories
3.8",3.8,"Lake Forest, IL",Sr. Data Engineer,"Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.
Working at Abbott
At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:
Career development with an international company where you can grow the career you dream of.
Free medical coverage for employees* via the Health Investment Plan (HIP) PPO
An excellent retirement savings plan with high employer contribution
Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

The Opportunity
This position will work out of one of our two offices in the office of either site: Lake Forest J55 in IL or St. Paul in MN within the BI & DA organization.

The Sr. Data Engineer is responsible for designing, building, and maintaining pipelines and reusable components to support reporting and analytics data products. This position will be responsible for partnering with team members to implement the best technical solution with performance, governance, scalability, security, and maintainability in mind. The person hired in this role will also have the opportunity to participate in solution architecture with senior IT staff.
What You’ll Work On
If you enjoy organizing raw data, then this is a great job for you! The data that this team sees and organize in data bricks will then go to multiple groups in the company. This team has high exposure to projects companywide and worldwide at Abbott. If making a difference with data extraction and loading the data using Azure Cloud is your “superpower”, then please apply!
What your responsibilities would be if hired:
Create and maintain an optimal data pipeline architecture by assisting with the designing and implementation of data ingestion solutions on Azure using DataBricks and/or Datafactory.
Writing complex queries to transform raw data sources into accessible models.
Clean, prepare, transform, and optimize data at scale.
Assist with designing and optimizing data models on Azure cloud using Azure Analysis Services.
Read, extract, transform, stage and load data to selected tools and frameworks as required and requested.
Ensure your work remains backed-up and readily accessible to relevant co-workers using GIT or Azure Cloud for Doc Control or (other programs the team uses for this purpose).
Providing system support to end users and administrators to resolve business and technical problems. Including possible rotation on call on a third tier level on occasion at most.
Using/improving existing standards, methodologies, and processes and understanding other systems/business processes related to each other. In addition, you will understand SDLC in Waterfall or Agile methodologies in your current or past roles.
Working with CI/CD and version control tools such as GIT.
You will have knowledge of working with healthcare data for HIPPA Privacy and International Data Privacy Agreement Laws.
Competencies:
Strong problem-solving skills, attention to detail and organization / documentation skills
Ability to prioritize and triage deadline-driven tasks in a high-pressure environment.
Required:
Bachelor’s degree (± 16 years) in any of the following – Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences.
Minimum 7 years of experience in IT as a Data Engineer
At least one year of experience with developing ETL pipelines in one or more of the following tools: Azure Data Factory, Azure functions, Data Flow, Event hubs, Event grids, Informatica
At least one year of experience with Databricks and/or Spark
At least two years of experience with SQL and data modeling
At least two years of experience with Python and some ETL libraries like Pandas.
Preferred:
Degree in Data Science
Experience with CosmoDB, AzureSQL, Synapse
Experience with SCALA
Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.
Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com
Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.
Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

The base pay for this position is $80,700.00 – $161,300.00. In specific locations, the pay range may vary from the range posted.","$121,000 /yr (est.)",10000+ Employees,Company - Public,Healthcare,Health Care Services & Hospitals,1888,$10+ billion (USD)
Tail Wind Informatics,#N/A,Minnesota,Data Engineer - Azure,"About Us:
Tail Wind is an IT Consulting Services company—Microsoft Solutions Partner—that delivers Data Architecture and Business Intelligence solutions. We offer cloud and on-premise Data Architecture, ETL Development, Data Migration, Reporting and Dashboard solutions. We’ve established an excellent reputation providing these services to awesome customers! We are building a talented crew of data savvy individuals for local and national projects in data. We offer excellent compensation (salary, bonus, benefits). Most importantly, our people have an incredible opportunity to build their skills in a team environment.

We are currently seeking candidates for our Data Engineer position to do the following:
Responsibilities
Using Data Science techniques to preform predictive modeling services.
Building data sets in data warehouses using SQL, Azure and Python.
Experience with Databricks or Snowflake
Work across multiple different teams and projects.
Requirements
3+ years experience using Azure Data Factory
Must have strong backend development skills with SQL Server and writing complex SQL queries
Strong understanding of predictive modeling
Working in a fast paced, deadline heavy environment
Benefits
401k + match
Health Insurance
Dental Insurance
Vision
Long-Term Disability Insurance
Life Insurance
The Tail Wind Team: A healthy work-life balance. We look for people that love what they do, want to learn, earn and enjoy life to the fullest.
Equal Opportunity Employer - No Agencies Please","$120,000 /yr (est.)",1 to 50 Employees,Company - Public,#N/A,#N/A,#N/A,Unknown / Non-Applicable
"Chewy
3.5",3.5,"Bellevue, WA",Data Engineer I,"Our Opportunity:
Chewy’s Data Analytics team has an exciting opportunity for a Data Engineer I to join the pack. Leveraging your strong expertise and background in data engineering and data analysis, you will be a part of a team responsible for operational and tactical reporting generating insights to grow Customer Service operations and planning. This includes building high quality data pipelines that drives analytic solutions and creating data products for analytics and data scientist team members to improve their productivity. Our organization is a fast-paced environment with new challenges and new opportunities each day. You will be responsible for building and implementing data products and technologies which will handle the growing business needs and
play a key role in redefining what it means to be a world-class customer service organization
What You’ll Do:
Design, develop, optimize, and maintain data architecture and pipelines using design and programming patterns that follow best-in-class practices and principles.
Manage, maintain, and improve our SSOT tables and data marts, which drive critical business decisions every day.
Work closely with analytics teams and business partners, serving as a trusted partner who can advise, consult, and communicate data solutions.
Mentor and coach other data practitioners on data standards and practices.
Lead the evaluation, implementation and deployment of emerging tools and process for data engineering to improve overall productivity for the organization.
Partner with leaders, vendors, and other data practitioners across Chewy to develop technical architectures for strategic enterprise projects and initiatives.
Document technical details of work and follow agile sprint methodology, using tools like Jira, Confluence etc
What You’ll Need:
Bachelor of Science or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics or related field
0 - 3 years of enterprise experience as a data engineer and/or software engineer
0 - 3 years applying and implementing database and data modeling techniques
0 - 3 years working with enterprise data warehouse (ex. Snowflake, Vertica) and cloud environments (ex. AWS)
0 - 3 years of experience building data integrations and pipelines from data lake, APIs, relational databases, and third-party systems
Strong software development skills in SQL
Self-motivated with strong problem-solving and self-learning skills.

Bonus (if applicable):
Strong working knowledge of Python programming
Excellent communication and collaboration skills with ability to influence and guide stakeholders
Experience building dimensional models in data warehouses
Experience with data streaming tools and technologies like Kafka, Kinesis, or similar technologies
AWS Developer Certifications
E-commerce, Retail or startup experience
Experience in BI tools such as Tableau, Plotly, Power BI, etc.

Compensation & Benefits:
Our salary range for a Data Engineer I position is $86,500 - $120,500. The specific salary offered to a candidate may be influenced by a variety of factors including but not limited to the candidate’s relevant experience, education, and work location. In addition, this position is eligible for 401k and a new hire and annual equity grant.
We offer different types of insurance, such as medical/Rx, vision, dental, life, disability, hospital indemnity, critical illness, and accident. We offer parental leave, family services benefits, backup dependent care, flexible spending accounts, telemedicine, pet adoption reimbursement, employee assistance program, and many discounts including 10% off pet insurance and 20% off at Chewy.com.
Non-exempt hourly team members accrue paid time off (PTO) while salaried-exempt team members have unlimited PTO, subject to manager approval. Non-exempt hourly team members in Fulfillment Centers and Customer Service are also eligible for additional unplanned unpaid time off (UTO). Team members will receive six paid holidays per year. Team members may be eligible for paid sick and family leave in compliance with applicable state and local regulations.

Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact CAAR@chewy.com.

If you have a question regarding your application, please contact HR@chewy.com.

To access Chewy's Customer Privacy Policy, please click here. To access Chewy's California CPRA Job Applicant Privacy Policy, please click here.",#N/A,10000+ Employees,Company - Public,Retail & Wholesale,Pet & Pet Supplies Stores,2011,$5 to $25 million (USD)
"Moen
4.0",4.0,"North Olmsted, OH",Data Operations Engineer,"Company Description

Fortune Brands Innovations is a global Fortune 500 company specializing in home, outdoors, plumbing, and security products. Our portfolio includes famous brands such as Moen, Master Lock, Fiberon, and Therma-Tru.

Job Description

Data Operations Engineer, full-time from North Olmsted, Cleveland, Toledo, and Columbus.

Our IT/Tech division is transforming digitally to boost our innovation, competitiveness, and efficiency. We're investing in IT and Engineering and assembling a team of experts. The Data & Analytics team is building a data, ML, and analytical platform using modern tech such as Cloud and DevOps. We need a DataOps engineer to join us in developing this platform. It's a new initiative with great career and technical leadership opportunities.

Our Stack
Infrastructure: Hybrid - a mix of on-premise infrastructure and public Cloud, primarily Azure.
Data systems: ERP systems, including SAP and Oracle. Snowflake as Enterprise Datawarehouse.
Platform infrastructure and DevOps: Azure Pipelines, GitHub, Kubernetes, IaC.
Data tools: dbt, Talend, and python.

We have a blend of legacy systems and tools while assessing and introducing new tools where it makes sense. This is a hybrid role where you will be working primarily from home with the flexible option of coming into work at our North Olmstead office for deeper engagement with the team and stakeholders on a needed basis.

Responsibilities
Own, develop, manage, and optimize the orchestration of data pipelines and source code version control that adhere to our data governance principles.
Own, develop, manage, and enhance the tools for the data engineers.
Work closely with stakeholders in Business Intelligence, Data Governance, Infrastructure, and business units to gather functional and non-functional requirements, and deliver the appropriate tooling and systems to produce high-quality data and analytics in a timely manner.
Build systems and automation to overcome the limitations of existing systems and integrate new modern-day tech stack into the company’s IT infrastructure.
Establish system monitoring, cost monitoring/mitigation, and alerting.
Define and enforce best practices and standards for the Data & Analytics team.

Qualifications
Bachelor’s degree in computer science, information systems, science, or engineering; or equivalent years of experience in IT, software engineering, or a relevant field.
4+ years of experience in Python or/and an equivalent language, such as bash or Powershell.
4+ years of experience in Linux system administration, network administration, or working at a data center.
2+ years of experience in working with a Cloud provider, including AWS, GCP, or Azure.
2+ years in developing and managing SDLC workflow, DevOps tools, and CI/CD.
Basic understanding of data architecture, data warehousing, and gitflow.
Experience in observability, including cost monitoring, log management, alerting, monitoring, and tuning.
Self-driven with the ability to work in a multi-stakeholder environment and deal with ambiguity.
Good analytical & problem-solving skills and the ability to incorporate multiple perspectives.
Good written and verbal communication skills.

Preferred Qualifications

Big plus if you have these skills.
Big Plus: Snowflake or a Cloud Warehouse product like Google BigQuery or AWS RedShift.
Big Plus: Experience in data orchestration.
Experience in infrastructure as code, including Terraform, Pulumi, Chef, or Puppet.
Experience in SQL querying language.
Quick learner.
Great sense of humor.

Additional Information

Company Description:

At Fortune Brands Innovations, we believe that our innovation and success are fueled by the passion of our people and the strength of our teams. Together, we work to fulfill dreams of home by aligning around common goals, being agile in the face of change, holding ourselves accountable, and acting with integrity and transparency. We succeed when everyone belongs and strive to build a Home for All where all associates can be their true, authentic selves at work. Learn more about our culture here

At Fortune Brands Innovations, we support the overall health and wellness of our associates by offering comprehensive, competitive benefits that prioritize all aspects of wellbeing and provide flexibility for our teammates’ unique needs. This includes robust health plans, a market-leading 401(k) program with a company contribution, product discounts, flexible time off benefits (including half-day summer Fridays per policy), inclusive fertility / adoption benefits, and more. We offer numerous ERGs (Employee Resource Groups) to support inclusivity and our associates’ feeling of belonging at work.

Fortune Brands Innovation (FBIN) is built on industry-leading brands and innovation within our operating segments: water, outdoors and security. We have an impressive track record of strong financial results, market outperformance and growth, which translates into career and professional growth opportunities for associates. Please visit our website at fbin.com to learn more

Equal Employment Opportunity

FBIN is an equal opportunity employer. FBIN evaluates qualified applicants without regard to race, color, religion, sex, gender identity or expression, national origin, ancestry, age, disability/handicap status, marital status, protected veteran status, sexual orientation, genetic history or information, or any other legally protected characteristic.

Reasonable Accommodations

FBIN is committed to working with and providing reasonable accommodations to individuals with disabilities. If, because of a medical condition or disability, you need a reasonable accommodation for any part of the application or interview process, please contact us at FBIN.Recruiting@fbhs.com and let us know the nature of your request along with your contact information.",#N/A,201 to 500 Employees,Subsidiary or Business Segment,Retail & Wholesale,Wholesale,#N/A,$25 to $100 million (USD)
"Discover Financial Services
3.9",3.9,Illinois,Data Engineer - Abinitio,"Discover. A brighter future.
With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine.

Come build your future, while being the reason millions of people find a brighter financial future with Discover.
Job Description: The Data Engineer is responsible designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community.
Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management.
Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members
Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies
Demonstrates strong technical aptitude across data engineering practices:
Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting
Designing advanced SQL queries
Leveraging metadata-driven framework for solutions
Developing test scripts for unit and integration testing
Develops test methodologies for specific products
Leads code review sessions and other process and operational improvement initiatives
Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack)
Works on holistic solutions, driving feature and story delivery (Agile)
Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline
Participates in the on-call rotation for support
Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities
Builds strong collaborative working relationship both within the team and cross-functionally

Minimum Qualifications

At a minimum, here’s what we need from you:
Bachelor's Degree in Computer Science or related field
3+ years of experience in Data Platform Administration/Engineering
Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale

Preferred Qualifications

If we had our say, we’d also look for:
ETL/ELT Tools (AbInitio, DataStage, Informatica)
Cloud Tools and Databases (AWS, Snowflake)
Other programming languages (Unix scripting, Python, etc.)
Leverage CI/CD framework for data integration, Open Source
Experience working in cloud platforms (AWS, GCP, Azure)
Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs
Experience optimizing SQL both relational and nosql
External applicants will be required to perform a technical interview.

#LI-CM

Compensation: The base pay for this position generally ranges between $84,500.00 to $142,500.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position.

Benefits:
We also offer a range of benefits and programs based on eligibility. These benefits include:

Paid Parental Leave

Paid Time Off

401(k) Plan

Medical, Dental, Vision, & Health Savings Account

STD, Life, LTD and AD&D

Recognition Program

Education Assistance

Commuter Benefits

Family Support Programs

Employee Stock Purchase Plan

Learn more at MyDiscoverBenefits.com .

What are you waiting for? Apply today!

All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management.

Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)","$113,500 /yr (est.)",10000+ Employees,Company - Public,Financial Services,Banking & Lending,1985,$1 to $5 billion (USD)
"Three Ships Media
3.4",3.4,"Charlotte, NC",Data Analytics Engineer,"Role Overview:
3S Health is seeking a hands-on, self-motivated Data Analytics Engineer to own our data analytics pipeline for one of our fastest growing businesses. In this role, you will be responsible for collecting and modeling data through the deployment of modern cloud tools, and turning that data into insights through the building of dashboards and reports. This role is for the data engineer that seeks to get closer to the business, or the business analyst that seeks to dive deeper into understanding where their data comes from.
What you'll Do:
Create and maintain scalable data pipeline through combination of modern SaaS applications and custom-built solutions
Create and maintain business intelligence roadmap to help enable business goals
Partner with business users to gather and understand data requirements
Extract data from sources through custom-built data integrations (typically Python) with discipline towards automation
Write SQL-based transformations to turn raw data into production-ready business models
Develop and manage business and executive team dashboards
Create and maintain data storage systems
Develop data discoverability tools and data monitoring systems

What You'll Bring:
Proficiency in SQL and Python (and/or proven ability to pick up a new language)
Proven ability to operate autonomously to achieve results.
Optional experience in Data Build Tool (DBT) or other SQL-based transformation tools
General understanding of the Marketing Technology stack, components, and best-practices. An ideal candidate will have some familiarity with common marketing tools (Google Analytics, Tag Manager, Segment (CDP), Facebook Ads, etc.)
Experience with common enterprise analytics tools with proven ability to translate data insights into action (Tableau, PowerBI, Looker Studio, Superset, etc.)
Working knowledge of software development best practices as they apply to data engineering, including: Version Control, Unit Testing, and Continuous Integration/Continuous Delivery (CI/CD)
The Package
As a full-time employee of Three Ships, you’ll have access to competitive benefits, including flexible time off, health/dental/vision, 401k match, an annual Relax & Recharge Bonus, an annual Learning & Development stipend to enroll in class(es) of your choosing, and up to $75 mobile reimbursement. If you join us in person in our Raleigh or Charlotte locations, we have an office stocked with snacks, coffee, and just about every other beverage you can imagine.
How We Hire
All applicants are considered without regard to race, color, religion, sex, national origin, age, disability, veteran status, gender identity, or any other discriminatory factors. Please note that we do not provide immigration sponsorship for this role. All offers are subject to a background check.","$92,505 /yr (est.)",51 to 200 Employees,Company - Private,Media & Communication,Advertising & Public Relations,2009,Unknown / Non-Applicable
"USAA
3.4",3.4,"San Antonio, TX",Data Engineer II,"Why USAA?
At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation’s military, but we all share in the mission to give back to those who did. We’re working as one to build a great experience and make a real impact for our members.

We believe in our core values of honesty, integrity, loyalty and service. They’re what guides everything we do – from how we treat our members to how we treat each other. Come be a part of what makes us so special!
The Opportunity
The candidate selected for this position is going to get work with the CFO Data & Analytics Team in USAA’s Corporate technology office. They will work with modern data technologies in like snowflake, dbt , container-based API’s , python and Kafka to build data pipelines to enable business with developing and implementing financial models on inputs and also build reporting capabilities on the model outputs within the treasury space in CFO.
This Data Engineer II position is a hybrid work type and can be based in one of our following office locations: San Antonio, TX or Plano, TX. Hybrid roles help employees gain the best of both worlds – collaborating in-person in the office and working from home when needed to achieve focused results.
What you'll do:
Participates in the full life cycle of data engineering to include analysis, solution design, data pipeline engineering, testing, deployment, scheduling, and production support with guidance from senior team members.
Assists in the implementation of technical solutions for data reporting and analytic systems.
Assists with designing and writing test scripts to verify data integrity and application of functionality. Reviews functionality of existing test scripts for understanding.
Demonstrates familiarity with IT Change and Release Management best practices. Deploys data pipeline code with assistance from senior team members.
Participate in design and code review sessions.
Actively participates in Agile ceremonies such as daily standup, iteration planning, backlog grooming, and retrospective sessions.
Develops intermediate familiarity of data management best practices by participating in trainings, reviewing documentation, and reading code from existing solutions.
Demonstrates knowledge and understanding of business products and processes.
Assists senior team members in breaking down business features into technical stories and approaches.
Actively learns about new and emerging technologies in the data engineering space. Seeks to apply learnings in current and future projects.
Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.
What you have:
Bachelor’s degree; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree; OR Approved certification from CodeUp, Galvanize, VetFIT (Veterans for IT) or eFIT
2 years of data engineering, data analysis or software development experience implementing data solutions.
Working Experience in SQL and Relational Databases.
Strong analytical and problem-solving skills.
Basic understanding of cloud technologies and tools.
What sets you apart:
2+ years of working experience with Snowflake.
1+ years of container-based APIs using container frameworks like OpenShift, Docker, or Kubernetes
2+ years of Python and Unix shell/Batch scripting experience
1+ years of experience with Kafka streaming technologies
Working experience with Gradle, yml, GIT, GitHUB, GITLab, etc. around continuous integration and continuous delivery infrastructure
The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.
What we offer:
Compensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $71,490 - $136,690.
Employees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.
Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.
For more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.
Relocation assistance is not available for this position.
USAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.",#N/A,10000+ Employees,Company - Private,Insurance,Insurance Carriers,1922,$25 to $100 million (USD)
"ARES Corporation
3.9",3.9,"Merritt Island, FL",Operations and Data Analytics Engineer,"Job Description and Responsibilities
Kennedy Space Center (KSC) is preparing to launch Artemis to the Moon, and ARES is looking for talented people to help us get there. The rocket boosters will be delivered to KSC this year and Orion will be accepted shortly thereafter as the Artemis vehicle is built and prepared for launch to send astronauts to the moon. A key function in achieving this success is data analytics. ARES data analysts develop models, run simulations, and provide meaningful reporting and visualizations in support of the complex decision making associated with Artemis.
If you are an entry to mid-level career professional with data analysis skills, and 0-9 years of relevant experience, we hope you will consider this unique opportunity to be a part of the Artemis lunar mission.

Expectations
Candidate has experience in data analytics and has the ability to support EGS in providing simulation modeling and analysis, math modeling, data visualization and additional analysis products, as needed, in support of the Artemis Mission.
Candidate can support full time onsite position at KSC. At this time and for the foreseeable future, the onsite requirement is Tuesday through Thursday, with teleworking approved for Monday and Friday.
Candidate has excellent interpersonal skills with the ability to work in a team environment co-located with multiple cross program customers and contractors.
Candidate is flexible to changing work demands, schedule pressure, multi-tasking, operating with minimal direct supervision, and meeting all customer deadlines.
Candidate is a self-starter with outstanding organizational, analytical, and problem-solving skills.
Candidate is an effective and clear communicator with the ability to present technical issues to both technical and non-technical personnel.

Minimum Requirements
Demonstrated experience with developing analytical models and performing simulations to inform critical decisions.
Demonstrated experience with data visualization software (e.g., Tableau, Power BI, or other) to integrate, analyze and report data.
Demonstrated Launch flow processing experience preferred.
Proficiency in Microsoft Office Word, Excel, PowerPoint, Project, and Outlook, as well as commercial data analysis tools.

Education and Relevant Work Experience
Bachelor of Science in Engineering, Operations Research, Mathematics, Statistics, or other physical science.
Demonstrated engineering, mathematical/computational analysis, or Operations Research experience.
Engineer 1: 0 - 4 years of relevant work experience.
Engineer 2: 4 – 9 years of relevant work experience.

ARES offers a competitive compensation and benefit package. Full time employees may participate in:
Medical Insurance
Dental Insurance
Vision Insurance
HSA/FSA Accounts
Life & Disability Insurance
Critical Illness & Accident Insurance
401(k) Plan
Paid Time Off & Holidays
ARES is an EEO/AA/Disability/Vets Employer and complies with E-Verify.
ARES shall abide by the requirements of 41 CFR 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sexual orientation, gender identity, national origin, disability or veteran status.","$78,018 /yr (est.)",501 to 1000 Employees,Company - Private,Aerospace & Defense,Aerospace & Defense,1992,$100 to $500 million (USD)
